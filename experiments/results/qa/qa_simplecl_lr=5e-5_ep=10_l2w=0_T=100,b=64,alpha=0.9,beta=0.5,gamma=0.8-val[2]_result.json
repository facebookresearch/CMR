{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4380, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis", "Uncle Tom's Cabin", "The liver", "No man", "Martina Hingis", "Ukraine borders with seven countries"], "metric_results": {"EM": 0.875, "QA-F1": 0.8942708333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "Qur'an", "Brotherhood", "high demand", "Tolui", "legon, the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial", "the object's weight", "over half", "1960s", "two months", "his friends Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "decision problem in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in reasonable times in most cases", "1965", "quantum gravity", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "black", "leg leg"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6806074134199134}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.9714285714285714, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.06666666666666667, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7408", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-2547", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.59375, "CSR": 0.78125, "EFR": 1.0, "Overall": 0.890625}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "in committee", "the 19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652", "a double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "cilia", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "from 1910\u20131940", "pressure swing adsorption", "Luther", "English", "a lack of remorse", "the fundamental means by which forces are emitted and absorbed", "the A1 (Gateshead Newcastle Western Bypass", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail", "Orestes", "the Galapagos Islands", "the U.S. government", "the movement", "the Travel Detective", "a very liquid cereal", "a major raw", "the Mycenaean civilization", "a biological clock", "the Belasco Theatre", "the Normandy Landings", "a bank robber", "fibula", "Il Trovatore", "the South Pole", "the East Coast Main Line"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6403544372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-7435", "mrqa_squad-validation-3673", "mrqa_squad-validation-2132", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.609375, "CSR": 0.73828125, "EFR": 0.96, "Overall": 0.849140625}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "the Gaulish name", "the Gramme dynamo", "under the wing of the secular powers", "the Yuan dynasty", "Zhongtong", "11.1%", "1538", "Deacons", "the New Testament", "their prestige, \"experience, ideology, and weapons\"", "25 percent", "May 2013", "the Sarah Jane Adventures", "in capturing prey", "a four-carbon compound", "livestock pasture", "Ford", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen (20,000 soldiers)", "eight", "a computational problem", "WzzM and WOTV", "Orange", "tentilla (\"little tentacles\")", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "the Battle of Olustee", "observer status", "the 50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "magnitude 6.7+", "the European seaborne empires", "the domestic legislation of the Scottish Parliament", "tweed", "Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "the computer processing unit (CPU) market", "Matt Kuchar and Bubba Watson", "the fastest circumnavigation of the globe in a powerboat", "the man facing up, with his arms out to the side", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester City", "Savoie", "three", "change course", "Tsvangirai", "\"A Lion Among Men", "January 2, 1971", "a delicacy fit for the kings and queens", "the late-night talk show \"Chelsea Lately\" on the E! network", "Luxembourg"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6837908798576902}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.8, 1.0, 0.4, 1.0, 1.0, 0.06896551724137931, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.2, 0.0, 0.8333333333333333, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-1320", "mrqa_squad-validation-2288", "mrqa_squad-validation-8231", "mrqa_squad-validation-9645", "mrqa_squad-validation-7626", "mrqa_squad-validation-4947", "mrqa_squad-validation-4258", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4943", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-2798", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.5625, "CSR": 0.703125, "EFR": 1.0, "Overall": 0.8515625}, {"timecode": 5, "before_eval_results": {"predictions": ["with money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "the fact that chloroplasts are surrounded by a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal illegally", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "French", "Golden Super Bowl", "the constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "roughly spherical and highly refractive bodies", "Nurses", "New England Patriots", "Time magazine", "Class II MHC", "two plastid-dividing rings", "Westinghouse", "by disrupting their plasma membrane", "reciprocating (piston) steam engines", "indirectly, transmitted as gluons, which form part of the virtual pi and rho mesons,", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops", "Goa", "How I Met Your Mother", "France's famous Louvre museum", "Leo Frank", "Thessaloniki", "Graziano Transmissioni", "opposition parties", "1.2 million", "United's", "the release of the four men", "how health care can affect families", "Ed McMahon", "at least $20 million to $30 million", "No. 2 man (or woman)", "Friday", "Obama", "ballots", "Sodra nongovernmental organization", "cancer-causing toxic chemical", "fuel economy and safety", "resting heart rate over 100 beats per minute", "heavy breeds", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6755970285841609}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [0.7000000000000001, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.888888888888889, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.8181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-8715", "mrqa_squad-validation-3408", "mrqa_squad-validation-1090", "mrqa_squad-validation-3087", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-8826", "mrqa_squad-validation-8867", "mrqa_squad-validation-6644", "mrqa_squad-validation-3263", "mrqa_squad-validation-10444", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.5625, "CSR": 0.6796875, "EFR": 1.0, "Overall": 0.83984375}, {"timecode": 6, "before_eval_results": {"predictions": ["2:45 a.m.", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "The Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "a computational resource", "to denote unknown or unexplored territory", "John Michael Rysbrack", "in early Lutheran hymnals", "world line", "In the autumn of 1991", "William Smith", "William Pitt", "geochemical component called KREEP", "Theory of the Earth to the Royal Society of Edinburgh", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "Denver's Executive Vice President of Football Operations and General Manager", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "more convenient and private method rather than traveling to a community drugstore where another customer might overhear about the drugs that they take", "eliminate all multiples of 1", "nerves", "1687", "fabric", "poly-Carbohydrates", "Democratic National Committee (DNC)", "heart, blood, and blood vessels", "Troggs", "six", "Bratislava", "Diana, the Princess", "slave trade", "vena cava", "Virginia's", "bullseye", "Tartarus", "This kind of backdrop that often represents the sky is known", "Nancy Reagan", "Achaemenid Empire", "LAP", "German", "net worth", "64", "Datson, H., Birch,", "Dies at 65", "Judas", "Dr. Jack Shephard, Kate Austen, Sayid Jarrah, Hugo \" Hurley", "comic book", "Love Is All Around", "dance-oriented production company", "French", "morphine elixir is widely used to treat pain.", "18"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5415426587301588}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.5, 0.8571428571428571, 1.0, 1.0, 0.4, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2545", "mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2384", "mrqa_squad-validation-10477", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_squad-validation-3113", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_hotpotqa-validation-1029", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.453125, "CSR": 0.6473214285714286, "EFR": 1.0, "Overall": 0.8236607142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["the extinction of the dinosaurs", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "a lower level of economic mobility than all the continental European countries", "School corporal punishment", "cattle", "Mongol", "a maze of semantical problems and grammatical niceties", "five", "the \"gold standard\" of religion", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway/Eisenhower Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Ministry of War", "well into the nineteenth century", "\u201ccapability deprivation\u201d", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "The Swahili", "hymn-writer", "a site of starch accumulation in plants that contain them", "Bryant", "Earth", "Utica, Ill.", "Rodeo", "hog", "Barack Obama", "Kenny G", "a small, half size cup used for serving espresso", "a peacock unitard", "the Federated States of Micronesia", "spring", "strudel", "insecticides", "Allah", "bones", "Python", "the Bible", "Ada Monroe", "Faith Hill", "Ben Affleck", "U.S.", "V", "time", "the jazz saxophonist", "Sweden", "Indonesia", "atomic numbers", "Alexandria", "Perfume", "the New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state", "Georgetown", "Essex County Cricket Club", "Alzheimer's disease"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6226425438596491}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3157894736842105, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7399", "mrqa_squad-validation-6220", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8828", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7048", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_naturalquestions-validation-10073", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.59375, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu", "silent", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement", "Irish", "Red Army", "1700", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "the midseason forensic investigation drama Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "eagles", "leather", "George Mortimer Pullman", "red", "the Messiah", "Sappho", "the law", "plumeria", "the divisor", "Dreams", "Texas", "Rooty Tooty", "a black breed", "the eagles", "the SAT", "e nihilo", "Henry David Thoreau", "Santa Ana", "Dick Cheney", "an eagles", "Gustave eiffel", "Edward Hopper", "the CIA", "d'Artagnan", "green", "1993", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6161024305555556}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-1169", "mrqa_squad-validation-9837", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.5625, "CSR": 0.6319444444444444, "EFR": 1.0, "Overall": 0.8159722222222222}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Full Registration\" status after a year if there is sufficient evidence to show that the \"Standard for Full Registration\" has been met", "August 15, 1971", "Levi's Stadium", "Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "Exploration is still continuing to determine if there are more reserves", "prep schools", "its soft power", "strong Islamist", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "the helmeted honeyeater", "4:51", "Khrushchev", "Hera", "Preamble", "Elton John", "Cuba", "the Battle of Thermopylae", "Ukraine", "Kroc", "cricket", "white", "Washington", "Carmen", "Genoa", "one third", "C14", "972", "Yellowstone", "Ann Widdecombe", "a triangle", "the Old Kent Road", "Tuesday", "sodium pyroborate", "Ab Fab", "Massachusetts", "Scotland", "California", "the Susquehanna River", "80", "a Preamble", "Singapore", "Warriors", "Davos", "eight", "actor and filmmaker", "the Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "Mitt Romney", "Grover"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6139204545454546}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false], "QA-F1": [0.09090909090909091, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2040", "mrqa_squad-validation-8784", "mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-7509"], "SR": 0.53125, "CSR": 0.621875, "EFR": 1.0, "Overall": 0.8109375}, {"timecode": 10, "before_eval_results": {"predictions": ["tenggis", "environmental determinism", "4 August 2010", "King George III", "radio", "esen Khoroo", "the League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic Church", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sullivan Bay on Port Phillip", "five", "January 18, 1974", "Spanish", "Professional", "extremely difficult", "student populations", "Catholic", "the Parliament of the United Kingdom", "296", "terneuzen", "mulberry", "the Virus", "a binnate or bipinnate", "Ken Russell", "Dan Dare", "mucia", "the Smiths", "Mike Tyson", "Turkey", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "crimean", "crimea", "Ukraine", "Sydney", "Los Angeles", "Underground", "puck", "UV", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "Titanic", "William Tell", "Jean Dess\u00e8s", "the snail", "Mendip", "Wichita", "the Passover", "New Croton Reservoir", "yuri", "Epicurus", "Stephen King", "Venus Williams", "a firefighter", "Ponty Mython", "Roman Polanski"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6371685606060606}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6263", "mrqa_squad-validation-2998", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-856", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_hotpotqa-validation-2340", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.59375, "CSR": 0.6193181818181819, "EFR": 1.0, "Overall": 0.8096590909090909}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "jugs", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "Killer T cells", "The European Commission", "completed (or local) fields", "fundamental error", "Mongol and Turkic", "hez-buh-lah", "five", "Whist", "Nile River", "tuscany", "achromatopsia", "black", "Pluto", "chromium", "copper", "The Hague", "Vancouver Island", "Ironside", "george smiley", "Maxim Gorky", "brown trout", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "Prince of Abissinia", "Conrad Murray", "Mary Poppins", "Sid Ziff", "black leaf", "rod", "caesar", "shrek", "Oslo", "lions", "Rhododendron", "sweden", "Franklin D. Roosevelt", "Shanghai", "caesar", "an elevator with a counterbalance", "Billy Colman", "17 October 2006", "beer", "Hoover Dam", "2006", "Capuchin Church of the Immaculate Conception, Rome, Italy", "Edgar Allan Poe", "Sir Robert Peel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6644345238095238}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8226", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.609375, "CSR": 0.6184895833333333, "EFR": 1.0, "Overall": 0.8092447916666666}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "720p high definition", "five", "Maria Goeppert-Mayer", "the International Association of Methodist-related Schools, Colleges, and Universities", "three", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas", "The Handmaid's Tale", "chimpanzee", "The Fault in Our Stars", "car car", "a handheld game console", "1898", "400 MW", "Total Nonstop Action Wrestling", "galt\u00fcr avalanche", "the last Roman Catholic Archbishop of Canterbury", "1861", "Disneyland theme park in Anaheim, California", "David Villa", "Red and Assiniboine Rivers", "New Jersey", "Continental Army", "Jack Kilby", "Ryan Gunoemen", "Umar S. Israilov", "July 16, 1971", "1933", "The Heirs", "the Baudot code", "1959", "1887", "and Governor of Minnesota Jesse Ventura", "Marvel Comics", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point DuSable", "England", "glenn fishburne", "a basilica", "1994", "Ricky Nelson", "in Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and they poison economies and governments, and it is in everyone's interest to stop this proliferation.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties", "andrew johnson", "a dame", "pre-Columbian times"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6407315340909091}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.0, 0.125, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-5889", "mrqa_squad-validation-937", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-2706", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.5625, "CSR": 0.6141826923076923, "EFR": 1.0, "Overall": 0.8070913461538461}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "the Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "relatively low in Ireland compared to the rest of the world", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Ranulf de Gernon", "2017", "Dallas", "Rudolf Schenker", "William Steig's 1990 fairy tale picture book of the same name", "Lucille Ball", "\"Grimjack\" (from First Comics)", "16\u201321", "Vince Guaraldi", "Tony Burke", "Michael Redgrave", "8th", "Johns Creek", "Hawaii", "unclear, without any central line of frass", "Gilbert du Motier", "Gujarat", "three", "Winter Haven", "four", "Joel Embiid", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "\"All of the Lights\" by Jay-Z", "FCI Danbury", "a few", "the US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "(2007)", "Arlo Looking Cloud", "Rwandan genocide of 1994", "Larnelle Harris", "Commander in Chief of the United States Armed Forces", "2014 -- 2018", "1982", "6", "Chris Robinson", "unclear", "unclear", "unclear", "the Egyptian Goddess of Creation", "Richie Unterberger"], "metric_results": {"EM": 0.5, "QA-F1": 0.5848958333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-1441", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5, "CSR": 0.6060267857142857, "EFR": 1.0, "Overall": 0.8030133928571428}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "only the series from 2009 onwards", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "the Silk Road", "the kilogram-force", "ten times their own weight", "Quaternary", "1887", "other ctenophores", "symbiotic relationship", "mathematical models of computation", "Vistula River", "quarter", "iCloud service will now be integrated into the iOS 5 operating system", "a dorm parent mistreated students", "March 8", "Mike Meehan", "the Catholic League", "1,000 pounds", "\"This is probably not the best time to repeat the passage that was found to be offensive,\"", "Friday", "Movahedi", "stories of different women coping with breast cancer in five vignettes", "\"black rain\" of drilling fluid and a roar of escaping gas\"", "peter", "money", "Lance Cpl. Maria Lauterbach and her fetus", "Hyundai Steel", "London", "400", "Val d'Isere, France", "the test results by a chaplain about 1:45 p.m., per jail policy.", "a municipal building in Baghdad's Sadr City,", "12.3 million", "1616", "Sky", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls", "Buddhism", "J.Crew", "U.N. Security Council resolution in 2006", "Depression-era bank robber", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "the worst might not yet be over.", "the Irish capital", "Republican", "Spanishfork,", "Mandi Hamlin and that officer called over another officer, who told her she would need to remove them", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "quarter", "Sevens", "England", "Yemen", "Spanish painting", "peterfunk", "mercury"], "metric_results": {"EM": 0.375, "QA-F1": 0.4587171052631579}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.16666666666666669, 1.0, 0.6666666666666666, 0.7777777777777778, 0.15789473684210525, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.375, "CSR": 0.590625, "EFR": 0.975, "Overall": 0.7828124999999999}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "Camisards", "over $40 million", "GTE", "1,100", "spin", "Oligocene", "Melodie Rydalch", "Charles Darwin", "a Little Rock military recruiting center", "March 24,", "the Beatles", "Robert Park", "Adriano", "11ven people died and 36 were wounded in the Monday terror attack,", "2007", "new clashes", "\"They pretty much asked me if she was depressed,... how she acted around the baby, if she seemed stressed out,\"", "56", "Pittsburgh Steelers", "albino monk", "one of its diplomats", "These intravenous vitamin \"drips\" are part of the latest quick-fix, health fad catching on", "18 federal agents and two soldiers", "Atlanta", "resources", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "two Emmys for work on the 'Columbo' series starring Peter Falk.", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "his bodyguard-turned-informant", "President Bush", "Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "\"It's hard for everyone... I thought it was better for me here,\"", "\"The Kirchners have been weakened by this latest economic crisis,\"", "\"The Sopranos,\"", "sharia law", "\"The minister later apologized, telling CNN his comments had been taken out of context.", "Iran", "20% tax credit", "July 23.", "70,000", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "blue", "Capitol", "The Left Book Club", "holography"], "metric_results": {"EM": 0.5, "QA-F1": 0.5767016895141894}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.18181818181818185, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.09523809523809525, 1.0, 0.08, 0.2666666666666667, 1.0, 1.0, 1.0, 0.1111111111111111, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_triviaqa-validation-6296"], "SR": 0.5, "CSR": 0.5849609375, "EFR": 1.0, "Overall": 0.79248046875}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "the Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "a total of 183 people, including 137 children, have been taken away since law enforcement officers raided the compound Thursday night,", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Robert Mugabe", "voluntary wrongful after witnesses identified him and he was interviewed by police.", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "1979", "murder", "next year", "his plans to overhaul domestic policies,", "Paul Bruno,", "Anil Kapoor", "Afghanistan and India", "Dr. Albert Reiter,", "\"From Terror to Nuclearollah: The Significance of the Iranian Threat,\"", "brutal choice", "Matthew Fisher", "cancer,", "Courtney Love,", "to step up.\"", "\"Perfidia,\" \"Walk Don't Run '64\" and \"Diamond Head.\"", "its own environmental videos", "two women", "once in June,", "Monday,", "Roy Foster", "Yusuf Saad Kamel", "hokeriet,", "11 healthy eggs", "Russia and some European countries have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "around 1918 or 1919.", "in the 1950s,", "U.S. troops working in support of Iraqi soldiers were attacked by small-arms, machine-gun and RPG fire from buildings overlooking the road.", "it began guaranteeing free anti-retroviral treatment to HIV/AIDS patients.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow,", "gastrocnemius", "Ed Sheeran", "\"clock\"", "Australia", "three-part", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "California", "George Blake", "Cundinamarca"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5720371123818815}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 0.27272727272727276, 0.22222222222222224, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6874999999999999, 0.17391304347826086, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.453125, "CSR": 0.5772058823529411, "EFR": 1.0, "Overall": 0.7886029411764706}, {"timecode": 17, "before_eval_results": {"predictions": ["relatively equal distributions of wealth", "a pharmacy practice residency", "questions and answers", "Genesis", "the same architect,", "12 January 1943,", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich,", "\"Sesame Street's\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's", "fled Zimbabwe and found his qualifications mean little as a refugee.", "\"executioners\"", "Israel and the United States", "concerns about the missile defense system.", "Sharon Bialek", "Gary Brooker", "the exact cause of IBS remains unknown,", "Helmand province", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April.", "Derek Mears", "braving elements ranging from rain to wind and even one speeding ticket", "Player's", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards", "Virgin America", "Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "bin Laden", "how health care can affect families.\"", "United Nations", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "all the attackers were Pakistanis,", "Friday,", "\"Taxman,\"", "crocodile eggs", "more than 20 times", "hid his money", "congressional Democrats vowed to put into place since they took control of Congress", "senators", "five - year time jump", "JHU-APL", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan sailors", "surrealism", "C. S. Lewis", "7", "sake", "Nova Scotia"], "metric_results": {"EM": 0.375, "QA-F1": 0.4864233385123331}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.33333333333333337, 0.0, 0.0, 0.12500000000000003, 1.0, 0.0, 0.5, 0.15384615384615385, 0.5217391304347826, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_squad-validation-1570", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-1858", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-4857"], "SR": 0.375, "CSR": 0.5659722222222222, "EFR": 1.0, "Overall": 0.7829861111111112}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "Fort Edward and Fort William Henry.", "linear", "Advanced Steam movement", "Defensive ends", "the dot", "chastity", "European Court of Justice", "a bronze medal in the women's figure skating final,", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "UK", "\"Gandhi,\"", "Argentina", "Congress", "28", "Frank Ricci,", "\"Kurdistan Gas City.\"", "\"greatly moved\" by meeting victims of abuse in Valletta, Malta.", "Bill & Melinda Gates Foundation", "$106,482,500", "because everybody around me likes Obama,\"", "not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "North Korea", "\"Otherwise the weekend, we've effectively dealt with record-breaking crowds,\"", "\"Zed,\"", "\"global security, prosperity and freedom.\"", "because the federal government is asleep at the switch,", "Molotov cocktails, rocks and glass.", "\"wildcat\" strikes,", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Costa Rica", "Meira Kumar", "next week.", "clubs and bars in Hong Kong and Shenzhen,", "Lindsey Vonn", "\"They were nothing,\"", "Amnesty International.", "President Obama's race", "Los Ticos", "Form Design Center", "AbdulMutallab was in the bathroom for about 15 to 20 minutes, which seemed long to the passenger, Tukel said.", "two people", "40-year-old", "outside the Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "a leak in a Dike", "\"Sunny Aftermath\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6046919484419484}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.9696969696969697, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254"], "SR": 0.53125, "CSR": 0.5641447368421053, "EFR": 0.9333333333333333, "Overall": 0.7487390350877193}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Danny Trevathan", "11", "would be killed through overwork", "Japanese", "Muqali,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "the 3rd District of Utah.", "that suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid", "most of those who managed to", "that the Bainbridge would be getting backup shortly.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book", "he was in good health, contrary to media reports he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J. Jewell,", "17", "from her father's home in Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "home in rural California,", "has been killed in an attempted car-jacking as he dropped his children off at a relative's house,", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat", "clothing", "about 3,000 kilometers (1,900 miles),", "homicide", "The Ski Train", "Alicia Keys", "Robert De Niro", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "The governor", "$60 billion on America's infrastructure.", "protective shoes", "to defend our territory and our laws and our homeland and our government.\"", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "was depressed over a recent breakup,", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "\"Grandmasters\"", "Suffragist", "Cobblestone", "Abu Dhabi", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6612280537445011}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4210526315789474, 0.8, 1.0, 0.5, 0.8333333333333333, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.09523809523809522, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.4444444444444445, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2836", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-12322"], "SR": 0.515625, "CSR": 0.56171875, "EFR": 0.967741935483871, "Overall": 0.7647303427419355}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "the Hungarians under Ferenc De\u00e1k", "Greek physician Pedanius", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China,", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "the United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Kylie Minogue", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956", "1969", "New England Patriots", "Joseph Heller", "the north pole", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Yale University, her grandfather's alma mater,", "three", "the team", "November 2014", "Gavrilo Princip", "a central place in Christian eschatology", "October 1941", "peace between two entities ( especially between man and God or between two countries )", "hanjore Gardens", "Cee - Lo", "after Shawn's kidnapping", "generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Conservative Party", "three times", "November 25, 2002", "October 29, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "live animals", "American", "Rensselaer County,", "CEO of an engineering and construction company", "more than 1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "United States, Britain and France", "south-central Washington,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6293570788530466}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 0.4, 0.0, 0.25, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.967741935483871, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 0.0, 0.25, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-6314", "mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-3886", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-2446"], "SR": 0.5, "CSR": 0.5587797619047619, "EFR": 0.96875, "Overall": 0.7637648809523809}, {"timecode": 21, "before_eval_results": {"predictions": ["as far back as the early Cambrian, about 515 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "the ancestors of chloroplasts", "24 of the 32 songs", "Sauron", "in the Washington metropolitan area", "the base 10 logarithm of the molar concentration", "the breast or lower chest of beef or veal", "Sargon II", "Spanish", "around 1600 BC", "From 1976 to 1983", "American swimmer Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "his parents", "the St. Louis Cardinals", "Orangeville, Ontario, Canada", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "Janie Crawford,", "by the early 3rd century", "positions 14 - 15, 146 - 147 and 148 - 149", "Elk and Kanawha Rivers", "1961", "`` classic '' Mac OS,", "in rocks and minerals", "Michael Schumacher", "finance", "1957,", "1776", "1963,", "Field Marshal Paul von Hindenburg", "2018", "Ireland", "Kit Harington", "her boyfriend Lance", "Transvaginal ultrasonography", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "a Raja Dhilu", "In the 1979 -- 80 season,", "Guy Berryman", "Tessa Virtue and Scott Moir", "c. 497 / 6 -- winter 406 / 5 BC", "Tim Allen", "thick skin", "biscuit - sized cakes", "India", "three", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "12 April 1961", "American punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5247100122100122}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, false, false, true], "QA-F1": [0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.25, 0.0, 0.6666666666666666, 0.0, 1.0, 0.30769230769230765, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4472", "mrqa_squad-validation-8780", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10727", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-3013", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.390625, "CSR": 0.5511363636363636, "EFR": 1.0, "Overall": 0.7755681818181819}, {"timecode": 22, "before_eval_results": {"predictions": ["the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania).", "Stanford University and stayed at the Santa Clara Marriott", "linebacker", "Mongol and Turkic tribes", "1859", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16", "new wave rock band The Fixx", "President Andrew Johnson", "Hellenism", "Mark Jackson", "New York", "the Chainsmoker", "2015", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "the North Shore, at locations in Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "two", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan", "a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2014", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China, and features Kung Fu instead of Okinawan Karate", "Anthony Quinn", "Masha Skorobogatov", "February 27, 2007", "Felina Weissman", "6ft 1in Coltrane", "Owen Vaccaro", "bacteria", "on the lateral side of the tibia", "Lynda Carter", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefe 90 \u00b0N - 0 \u00b0 E \ufef5 / 90", "Canterbury to Canterbury", "in the bloodstream or surrounding tissue", "2015", "February 29", "1840s", "9.7", "Alabama", "Juliet", "\"I know, it's so boring. It's a song about the dark underbelly of the American Dream, and about excess in America which was something we knew about.\"", "the Queen", "eagles", "vocalist Eddie Vedder", "2005", "Dan Tyminski", "Elisabeth", "southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "at least nine", "Bashar al-Assad", "the New Revised Standard Version", "Biathlon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5905794615413491}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 1.0, 0.4210526315789474, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 0.4444444444444445, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 0.9523809523809523, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7586206896551724, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-322", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-4410", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-4139", "mrqa_triviaqa-validation-4546", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.453125, "CSR": 0.546875, "EFR": 0.9714285714285714, "Overall": 0.7591517857142858}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Division I history ( 61 )", "Thaddeus Rowe Luckinbill", "December 25", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development in the central part of each developing bone", "Ali", "Vijay Prakash", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Thomas Marvolo Riddle", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Brendan Graham", "1985", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Joyce Vincent Wilson", "on February 10, 2017", "Alex Skuby", "Colony of Virginia", "5 September, at which point it formally acceded to the community", "from 1922 to 1991", "Tom Goodman - Hill", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield", "In 1871 A.D. Pt. Buddhiballav Pant", "eye", "The History Boys", "caluga", "the White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "A staff sergeant in the U.S. Air Force,", "the most-wanted man in the world", "Antarctica", "california", "california"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5655528499278499}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.28571428571428575, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1445", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.453125, "CSR": 0.54296875, "EFR": 0.9714285714285714, "Overall": 0.7571986607142858}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no", "Stadtholder William III of Orange", "1933\u20131953", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "1996", "the onset and progression of Alzheimer's disease.", "Disco", "Kingdom of Dalmatia", "McKinsey", "Rockefeller Center", "Charles Whitman", "C. H. Greenblatt", "The Curious Case of Benjamin button", "Mold-Denbigh", "Corendon Dutch Airlines", "86 ft long", "Minneapolis, Minnesota", "Scottish Highlands", "Fatih Ozmen", "the U.S. military designation for a steel disintegrating link", "Pacific Place", "the Attorney General of Michigan from 1999 to 2003", "Paradise, Nevada", "Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's and Queen", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Lee Alexander", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Prussian Crusade", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "No Surprises", "Julie Frost", "2007 and 2008", "2001", "1966", "Cameron Diaz", "Allan Border", "Medellin", "his father's parenting skills.", "alternative-energy vehicles", "two weeks ago", "genes", "olive", "Stockholm"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5452752976190476}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.08333333333333334, 1.0, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.8, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 0.0, 0.5, 0.6666666666666666, 0.4, 0.4, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7092", "mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-979", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-1697", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-1676"], "SR": 0.390625, "CSR": 0.536875, "EFR": 0.9743589743589743, "Overall": 0.7556169871794871}, {"timecode": 25, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "DS Virgin Racing Formula E Team", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Leigh Lambert", "Shenandoah National Park", "the Royal Automobile Club's Tourist Trophy", "10 Years", "Honolulu", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern part", "coca wine", "Entrepreneur", "the lead roles", "PBS stations nationwide,", "second largest", "CARoccan clementine", "in 1911", "Johnnie Ray", "The Five", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "new, small and more expensive vessels", "1972", "Geographical Indication tag", "Ringo Starr", "Celtics", "World Championship Wrestling", "in New York", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "in 2005", "Tenochtitlan", "in 1986", "mike atherton", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "the Los Angeles County Coroner's Office,", "mike atherton", "\"Death, be not\"", "green"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6069320436507937}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.8, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-973", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-364", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.53125, "CSR": 0.5366586538461539, "EFR": 0.9666666666666667, "Overall": 0.7516626602564103}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu tribe", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Victor Garber", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Chris Hemsworth", "late eighteenth century", "\"The Snowman\"", "1979", "Premier League club Liverpool and the England national team", "port city of Aden, on the southern coast", "American", "Prince Louis of Battenberg", "2013", "Archie Andrews", "2 May 2015", "Hess 15", "Crystal Dynamic", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "the father of former England international striker", "Las Vegas, Nevada", "1919", "Kevin Spacey", "Love Streams", "Michael Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast, primary products, consumer cargoes and extensive passenger services", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Alumni Field", "Tudor music and English folk-song", "Pantone", "1600 BC", "The centuries - old Java Grand Master of an unknown species", "1963", "a palla", "Herald of Free Enterprise,", "A Nutshell", "361", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Edgar Rice Burroughs", "Japan", "a kite, no problem, there will be opportunities at this event"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5972727793040293}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.8, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-102", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-13669"], "SR": 0.53125, "CSR": 0.5364583333333333, "EFR": 1.0, "Overall": 0.7682291666666666}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "Fall 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services", "Paper", "Sir Matthew Alistair Grant", "Whitney Elizabeth Houston", "pneumatic tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "Josh Hartnett", "due to a leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei", "Kamehameha I", "Brigadier General Raden Panji Nugroho Notosusanto", "Don Bluth", "2008", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "I Won't Let You Down", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914", "Elena Verdugo", "Prussian leadership", "January 2004", "co-founder and lead guitarist", "ten", "seven", "October 25, 1881", "J. Robert Oppenheimer", "Rukmini", "Mark Jackson", "Road / Track", "the Colossus", "Equatorial Guinea", "corsets", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "Massachusetts", "corsets", "corsets", "infrared"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5496527777777778}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, true, false, false, false, true], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-2957", "mrqa_naturalquestions-validation-3536", "mrqa_triviaqa-validation-2051", "mrqa_triviaqa-validation-2520", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622"], "SR": 0.484375, "CSR": 0.5345982142857143, "EFR": 1.0, "Overall": 0.7672991071428572}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "London", "Henry Mancini", "tenno", "Barbata Hotel Casino & Spa", "Gorbachev", "M*A*S*H\" or the Bill Murray character", "the rose", "Princess Nefretiri", "London's Notting Hill", "a horse", "orchid", "Paddy Doherty", "smallpox", "colossus of rhodus", "the Central African Republic", "Chubby Checker", "F\u00fcr Elise", "Saudi Arabia", "Who's Who in David Copperfield", "The Names Make News", "a Musketeer of the Guard", "April", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Belle", "colossus goran Eriksson", "Stuyvestant", "Stoppard", "The Greatest", "the manager of Elvis Presley", "Northumberland in Northern England", "a Scotch bonnet", "pianist", "Everett", "colossus of Anglesey", "Cardiff", "Louisiana", "carburetors", "Tahrir Square", "Romanian", "flat region of the bathtub curve", "Michael Caine", "Lord Snooty", "colovetsian Dances", "James", "Meerkat", "Greek", "passion fruit", "Richard T. Jones", "Haikou on the Hainan Island", "the British associationists", "Denmark and Norway", "1966", "North America", "Florida's Everglades.", "the death of Michael Jackson,", "stylish, sexy and international.\"", "drive", "a set of steak knives", "Barbus Stark"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4353174603174603}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.5, 0.39999999999999997, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-3726", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-3909", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-627", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-3586", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-12186", "mrqa_searchqa-validation-15919"], "SR": 0.359375, "CSR": 0.5285560344827587, "EFR": 1.0, "Overall": 0.7642780172413793}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "ABC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "Blue laws", "Randy VanWarmer", "U.S. Senate", "Emma Watson", "9.1", "2018", "if the realization of one does not affect the probability distribution of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "in Pyeongchang County, Gangwon Province, South Korea", "the status line", "innermost in the eye", "Tom Brady", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "Nick Sager", "Buffalo Lookout", "Humpty Dumpty", "Charlene Holt", "1 US dollar", "Leonard Nimoy", "1960", "Sam", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "jimmy plunkett", "1995", "Everywhere", "technological advances in printing", "Cairo, Illinois", "1970s and'80s", "in the books of Exodus and Deuteronomy", "Chandler", "Psychomachia", "January 2, 1971", "The Miracles", "bacteria", "elbow", "jimmy james", "Charlie heston", "\"Twice in a Lifetime\"", "Nineteen Eighty-Four", "Bardot", "teenager", "Long Island convenience store", "Romney", "rock", "heart", "bronchitis"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6275632411305323}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7826086956521738, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.21052631578947367, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-2798", "mrqa_naturalquestions-validation-5069", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-6508", "mrqa_triviaqa-validation-3968", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.546875, "CSR": 0.5291666666666667, "EFR": 1.0, "Overall": 0.7645833333333334}, {"timecode": 30, "before_eval_results": {"predictions": ["San Jose", "the number of quality rental units", "sports tourism", "a circle", "(Polystichum munitum", "corey Lyn Charendoff", "Spanish Republic", "taxicab", "(coyote", "Jake Barnes", "Harry Reid", "Ray", "(Axial Tilt", "forge", "(St.) Thomas Edison", "(Why did he kill them?)", "Flowerbomb", "Blackbird", "Footprints", "(Sycorax", "LA Kings", "(St.) Brigantine", "Tommy Lee Jones", "( Zacchaeus", "The Memory Keeper", "George Eliot", "hubris", "Yahtzee", "(Who's the Boss?)", "HTML", "( coreyedema", "74.3", "William S. Hart", "( corey) joshua", "Pride and Prejudice", "(St.) Jesus", "kosher wine", "Munich", "Michael Jordan", "(St.) Andrew's Day", "Prospero", "(St.) James Tiberius Kirk", "( corey) Lion Tamarin", "corey", "(Aso-san)", "( Susan.)", "Boston", "(King Leonidis", "Arctic Ocean", "Pizza Margherita", "pumpkin soup", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland", "The Fortune cookie", "Monty Python's Spamalot", "April 25, 1995", "Both escorts, Harlow Cuadra and Joseph Kerekes", "( Isaac Newton's book \"Principia\"", "(Israel will also release two Israeli soldiers, Ehud \"Udi\" Goldwasser and Eldad Regev.", "Adidas", "anti-trust laws."], "metric_results": {"EM": 0.390625, "QA-F1": 0.4691592261904762}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.7499999999999999, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.8333333333333333, 0.8, 0.14285714285714288, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-315", "mrqa_squad-validation-7576", "mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-11558", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6519", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-10080", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-4718", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-1406"], "SR": 0.390625, "CSR": 0.5246975806451613, "EFR": 1.0, "Overall": 0.7623487903225806}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "stand-up", "satirical erotic romantic comedy", "Ferengi Quark", "Christian Kern", "1970", "Bloomingdale Firehouse", "Elena Stefanik", "Fleetwood Mac", "Odense Boldklub", "President", "Bangkok, Thailand", "The Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "January 19, 1943", "The Worm", "Eliot Cutler", "Mercury Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "Asbury Park, New Jersey", "Rockland", "\"Slaughterhouse-Five\"", "Tom Blankenship", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "The Highwaymen", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Lawton Mainor Chiles Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr.", "1935", "a lion", "slow", "The Miracles", "Winter Park at Union Station in Denver, Colorado.", "Microsoft", "Friday,", "the High Plains", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6555288461538461}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-2088", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055"], "SR": 0.5625, "CSR": 0.52587890625, "EFR": 1.0, "Overall": 0.762939453125}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Scarface", "Argentina", "Apollo 5", "jellyfish", "March", "a clogs", "Fauntleroy", "Dartmouth College", "\"I would use a mashie niblick Golfer 32 In the song who killed Cock Robin Sparrow 33 What do deciduous trees do Lose their leaves in winter 34", "Kofi Annan", "oxygen", "the right to print was strictly controlled in England", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "i second that emotion", "Sven Goran Eriksson", "Barry Taylor", "Route 66", "Brussels", "the Jacobite attack, charging into the teeth of murderous musket fire and grapeshot fired from the cannons", "John Poulson", "Orly", "the euro", "\"Jack\" Frost", "The Precambrian Shield", "Laurent Planchon", "the bottom of the Solent", "vomiting", "the Red Lion", "the Mark I with Hercules III engines and the Mark II with the Rolls Royce 'Merlin'", "Spinach", "Steve Davis", "i second that emotion", "Gemini", "Surrey", "1971", "chippenham", "London", "the Aconcagua Region", "William Shakespeare", "borax", "a \"metropolitano\" (in Turin) or \"surburbano\" ( in Milano)", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "The onset of rigor mortis and its resolution partially determine the tenderness of meat", "customary units", "Miller Brewing Company", "northwestern Italian coast", "Sydney", "\"I don't even think about music anymore.\"", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "anisodactyl, zygodactyl or... Most bird scales don't overlap significantly, except in the cases of...", "the Federal Council of Churchesthe predecessor of the National Council of... The organization is divided into administrative bodies"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4621503496503496}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 0.923076923076923, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7108", "mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7197", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.390625, "CSR": 0.521780303030303, "EFR": 1.0, "Overall": 0.7608901515151515}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "dors Del Rey", "1,228 km / h", "New England Patriots", "Doc '' Brown", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "775 rooms", "piety", "written dialogue", "a sweet alcoholic drink made with rum, fruit juice, and maple or dorsadine", "a snood", "Jesus'birth", "a habitat", "bristolen Simone Vangsness", "Central Germany", "Andrew Johnson", "Bart Cummings", "apamemnon", "electors", "Julia Ormond", "Sauron's assistance", "1961", "Mike Mushok", "2013", "March 1", "a book", "a usually red oxide formed by the redox reaction", "Spain", "Steffy Forrester", "Paul Lynde", "delivered the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "one of the most recognisable structures in the world", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "18", "Ramones", "1800", "Norman French waleis", "Frank Theodore `` Ted '' Levine", "New Jersey", "May 2010", "France", "charles ouzounian Theatre Critic", "dennis taylor", "a centaur", "an American actor", "cricket fighting", "Luis Resto", "the drama of the action in-and-around the golf course", "dennis taylor", "Islamabad", "Tunisia", "a research organization", "AIDS"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5054487602039066}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, true, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 0.6666666666666666, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.5263157894736842, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5161290322580646, 0.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-6061", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.421875, "CSR": 0.5188419117647058, "EFR": 1.0, "Overall": 0.7594209558823529}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "Brahmagupta's Brahmasputha Siddhanta ( 7th century )", "July 22, 2017", "her abusive husband", "September 29, 2017", "interstellar medium", "transmission", "Universal Pictures", "Vijay Prakash", "March 14, 1942", "Nick Sager", "local authorities", "prophets", "the state legislatures", "digestion of proteins", "Renishaw Hall, Derbyshire, England, UK", "accomplish the objectives of the organization", "pickup trucks", "Isabella Palmieri", "temperature at which the phase transition occurs", "`` mind your manners ''", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "Judy Parker", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "various submucosal membrane sites", "a set of components that included charting, advanced UI, and data services ( Flex Data Services )", "Steveston Outdoor pool in Richmond", "Robin Cousins", "a physiological reaction that occurs in response to a perceived harmful event, attack, or threat to survival", "Ukraine", "Lula", "1840", "if the car is slowed initially", "pre-dynastic period in Egypt, as well as amid the early cultures of Mesopotamia and Crete ''", "Derrick Henry", "lowest air temperature", "`` Mirror Image ''", "on a bronze plaque and mounted inside the pedestal's lower level", "krave", "czar", "Brian Close", "a hard rock/blues rock band", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "\"If Micheletti came forward with a public announcement, the odds of this being approved by congress are pretty good.", "Olympic medal", "Henry Ford", "Toyota", "a vice president", "a brain tumour"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5362413194444444}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 0.0, 0.375, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.29629629629629634, 0.07407407407407408, 0.28571428571428575, 1.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.07407407407407408, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.46875, "CSR": 0.5174107142857143, "EFR": 0.9117647058823529, "Overall": 0.7145877100840337}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists", "a supposed mild euphoric", "James McConkey", "Venezuela", "Milwaukee", "boxing", "Peter Pan", "hawke", "the Arctic Ocean", "the air going out causes a vacuum effect,", "man-made obstructions", "Lafayette", "Elijah Muhammad", "a doldrums", "the Royal Marines Band", "Alexander Pushkin", "Australia", "diana taylor", "banderas", "a night shift", "apollo", "Arkansas", "hawering", "Pierre-August Renoir", "hawke", "libretti", "Innsbruck", "Lance Ito", "Microsoft", "a fern", "an American Southern Baptist pastor", "Viking Museum Ship, Sea Stallion, Roskilde, Denmark", "Atlantic City's", "Blackwater USA", "elephants", "American Airlines", "a gerenuk", "Odysseus", "Geronimo", "Historic Royal Palaces", "charlie Bassett", "the Netherlands", "Pocahontas", "c.S. Lewis", "John Galt", "the amygdala", "Chicago Mercantile Exchange", "Las Vegas", "danskin", "hawke", "Pablo Casals", "an ostrich", "1942", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "House-passed bill that eliminates the 3% withholding requirement for government contractors --", "63", "\"We are resetting,"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5205729166666666}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-5219", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.453125, "CSR": 0.515625, "EFR": 1.0, "Overall": 0.7578125}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act", "The User State Migration Tool", "the Second Battle of Manassas", "William DeVaughn", "between 2 World Trade Center and 3 world Trade Center", "the Thames Estuary", "Santa Monica", "a modern state system", "Raza Jaffrey", "1934", "Filipino", "1773", "the particular types of RAM used for primary storage are also volatile, i.e. they lose the information when not powered )", "2012", "April 1917", "Etienne de Mestre", "1885", "Harishchandra", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "2016", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "as few as 5 photoreceptor cells", "1980s", "in soils", "card verification value", "presbyters", "bohrium", "Germany", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle '' -- of late Classical and Hellenistic Greece", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "Stalin", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "leftist Workers' Party", "his mother, Katherine Jackson", "cotton", "Dennis Haysbert", "Quinn", "The Weatherbys Novices' Hurdle Race"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5995896464646464}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.5454545454545454, 1.0, 0.18181818181818182, 1.0, 0.0, 0.5714285714285715, 1.0, 0.9523809523809523, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0909090909090909, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.1, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2833", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-1515", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-5744", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161", "mrqa_triviaqa-validation-5460"], "SR": 0.484375, "CSR": 0.5147804054054055, "EFR": 0.9393939393939394, "Overall": 0.7270871723996725}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "brazil", "South Africa", "first among equals", "shine", "a cappella", "sunburn", "a peterloo massacre", "an aglet", "Saturday Night Live", "Bayern", "winter", "Bonnie and Clyde", "a working language", "copper", "Dawn French", "Blackstar", "brazil", "Doris Lessing", "Scooby-Doo", "swaziland", "brazilia", "Kent", "a bumber", "bets", "a saddler", "Kent", "Rodgers & Hammerstein", "Culture Club", "Galileo Galilei", "Mata Hari", "brazil", "Marilyn Manson", "Medellin", "Tempest", "a piston", "brazil", "Boulder Dam", "painkillers", "brazil", "Belle de Jour", "Lancaster City", "a bba", "rainwater", "blue", "scientists of Laputa", "brazil", "Snowbell", "kunsky", "death", "Tracy Island", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "at least three bodies were trapped in a \"very compressed area.\"", "heavy turbulence", "women and breast cancer.", "a balloon", "a sunflower", "Madonna", "March 24,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.559281994047619}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-5520", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6503", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.515625, "CSR": 0.5148026315789473, "EFR": 0.967741935483871, "Overall": 0.7412722835314092}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "off the coast of Northumberland", "stomach", "40", "bicarbonate", "cuba", "cuba", "cubais", "Colin Cant", "Stevie Wonder", "head", "hound", "hanover", "a moon", "prince", "work", "scales", "Dirty Dancing", "henryes", "Diana Ross", "monzuma", "a 1934 Austin seven box saloon", "Paul Anka", "france", "albion", "diana taylor", "Blade Runner", "Jay-Z", "leopons", "cymbals", "cuba", "francesco Maria Piave's libretto", "davis taylor", "fidelio", "South Africa", "christian dior", "albion", "a toothed whale", "cuba", "france", "raspberries", "fasting", "Cyprus", "speed camera", "54-Marquesses", "a lizard", "cuba", "frauds", "a sea horse", "1", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "\"Traumnovelle\" (\"Dream Story\"),", "Anthony Ray Lynn", "piano", "tribute to pop legend", "former U.S. President Bill Clinton", "French Guiana", "cuba", "Bears", "Tiger Woods"], "metric_results": {"EM": 0.375, "QA-F1": 0.42924107142857143}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.5, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.375, "CSR": 0.5112179487179487, "EFR": 0.975, "Overall": 0.7431089743589743}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Aldi", "Midnight Cowboy", "charles", "seborrheic dermatitis", "Amanda Barrie", "ship", "Niger", "Stockholm", "Tangled", "dog", "jim davis", "Bulls Eye", "Napoleon", "bach", "Martin Clunes", "charles Darwin", "pembrokeshire", "Kevin macdonald", "peppers", "Paleozoic", "jim Boyd", "Brunel", "georgia", "1957", "Devon", "barles", "butter", "moctes", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "E. T. A. Hoffmann", "Shanghai", "Spain", "grow", "Tuesday", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "Ambrose Philips", "United States", "dolores humbert", "cuckoo bird", "policeman", "car", "Alice Cooper", "monearic", "blood", "Royal Bengal Tiger", "inward spiral", "dog", "American newspaper", "1999", "Sela Ward", "Body Works", "forgery and flying without a valid license,", "137", "a log cabin", "St. Patrick's Day", "defensive backs", "Marshall"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5044642857142858}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-1895", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-4297", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8554", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.453125, "CSR": 0.509765625, "EFR": 1.0, "Overall": 0.7548828125}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players-Lasky", "norway", "jimmy de Quincey", "indianapolis", "horse", "buffalo", "Octavian", "dove", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "jimmy boyigh", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor", "humbert humbert", "smith", "jane de Valence", "avunculicide", "smith taylor", "princess smith", "winds", "devonshire", "Sudan", "dog", "Washington", "indianapolis", "norway", "jimmy i", "charlie fenton", "indianapolis", "purple rain", "princess jane smith", "cuculidae", "princess", "rome", "2", "Southwest Airlines", "jimmy", "deaver", "The Comedy of Errors", "smith", "glyn Jones", "Betty Ford", "crossword clue", "norway", "al-Qaeda", "Frederic Robinson Ltd", "Jack and Jill, two murderous outlaws in ownership of legendary magical beans which lead to great fortune", "August 18, 1998", "Vijay Prakash", "the ENnies", "the 100th anniversary of the first \"Tour de France\" bicycle race", "the Mach number (M or Ma)", "Janet and La Toya", "more than 2.5 million", "researchers have developed technology that makes it possible to use thoughts to operate a computer, maneuver a wheelchair or even use Twitter", "the Matrix", "avian taylor", "irena", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.234375, "QA-F1": 0.31223958333333335}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.5, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-5371", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-878", "mrqa_triviaqa-validation-6152", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-3844", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-5262", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4337", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7346", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.234375, "CSR": 0.5030487804878049, "EFR": 0.9387755102040817, "Overall": 0.7209121453459433}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "oregon", "european", "nippon Sangyo", "mountain torrents", "roddy dixon", "abacus", "Robin Hood", "a king of ephyra", "Velazquez", "South Africa", "caracas", "oregon", "nymphomaniac", "oregon wrayburn", "us", "true stories", "davis Bowie", "Neil Armstrong", "spartre", "european", "jack james", "rust", "jane aniston", "Wiltshire", "georgia", "oregon hampshire", "othello", "sewing up of a small hole or tear in a piece of material", "Bob Balaban", "Lacock Abbey", "rumbustiously randy Squadron Commander Flashheart", "domestic cat", "anita Brookner", "james", "Golda Meir", "Black Sea", "bagram", "Susie Dent", "power outage", "Vienna", "archers", "lancelot Gobbo", "james ochs", "henry gee", "james boyd", "shakespears Sister", "the Marx Brothers", "tyne", "european", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "from 1993 to 1996", "james Gandolfini", "September 29, 2017", "one of 10 gunmen who attacked several targets in Mumbai on November 26", "June 6, 1944", "sniff out cell phones.", "a bassoon", "o.K. Corral", "a butternut squash", "phoenicia"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5333333333333333}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-1653", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-6097", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.46875, "CSR": 0.5022321428571428, "EFR": 0.9705882352941176, "Overall": 0.7364101890756303}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "if the TWU walked away from that offer,\"", "Eintracht Frankfurt", "encke gap", "a government-sponsored propaganda show", "Jeddah, Saudi Arabia", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "27,", "gordon brown", "executive director of the Americas Division of Human Rights Watch", "Salt Lake City, Utah", "dancy-Power Automotive Group showroom", "Michoacan Family", "64", "life in prison.", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007", "on the set at \"E! News\"", "off Haiti's coast", "Madeleine K. Albright", "an ice jam", "high levels of tetrachloroethylene, trichloro methylene, benzene and vinyl chloride in the tap water at the military base.\"", "shahnawaz", "July", "U.S. senators", "South Africa", "Larry Ellison", "Rihanna", "her fianc\u00e9", "cal Ripken", "Johannesburg", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning,", "byproducts", "about 5:20 p.m.", "Herman Thomas", "our victory in kicking out the invaders is your victory as well, because the main assailant on the nation and on Palestine is the American imperialism.", "a man's lifeless, naked body", "\"release\" civilians,", "Dodi Fayed", "our message has been warmly received.", "if a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "pyotr phnom penh", "Misery", "purdy", "Antonio Lippi", "Thorgan ganael Francis", "tweed", "brazil", "pyotr jimmy", "Cy Young", "pyotr witherspoon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5675740850333242}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.15384615384615383, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.7272727272727273, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.1111111111111111, 0.5714285714285715, 0.0, 1.0, 0.0, 0.09090909090909091, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.8, 0.043478260869565216, 1.0, 1.0, 0.3636363636363636, 0.0, 0.9090909090909091, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_hotpotqa-validation-3610", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-10019"], "SR": 0.453125, "CSR": 0.5010901162790697, "EFR": 1.0, "Overall": 0.7505450581395349}, {"timecode": 43, "before_eval_results": {"predictions": ["25,033", "the ancient aristocratic House of Borromeo", "Washington, D.C.", "1943", "Volvo 850", "the Mountain West Conference", "the Atlanta Hawks", "Western Europe", "movie scripts", "Continental AG", "English football", "from 1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "and musician Chris Brown,", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "My Backyard", "15 October 1988", "coaxial", "\"Northern Lights\"", "three different covers", "Malayalam cinema", "(1815\u20131867)", "August 11, 1946", "Vincent Landay", "May 26, 2010", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Nickelodeon Animation Studio", "Christian Duguay", "1985", "Gal Gadot-Varsano", "Meghan Markle", "Boeing B-17 Flying Fortress", "Erika Girardi", "Joe Scarborough", "British", "76,416", "Bonkyll Castle", "second cousin once removed", "the 2012 Summer Olympics", "Sony Computer Entertainment", "Brig Gen Augustine Warner Robins", "United Nations", "Alice's Adventures in Wonderland", "two occasions", "the UK\u2019s Trade Mark Registration Act 1875,", "blue", "the elbow", "Citizens are picking members of the lower house of parliament,", "the Employee Free Choice act in Lafayette Square in Washington", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "a royal tree"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6521300747863248}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.8, 0.888888888888889, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.6153846153846153, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3693", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-1800", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1464", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-7240", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070", "mrqa_newsqa-validation-2345", "mrqa_searchqa-validation-10888"], "SR": 0.53125, "CSR": 0.5017755681818181, "EFR": 1.0, "Overall": 0.7508877840909091}, {"timecode": 44, "before_eval_results": {"predictions": ["British Prime Minister Edward Heath", "former White Zombie bassist Sean Yseult", "Washington, D.C.", "over 12 million", "Tamaulipas Convention center", "Conservatorio Verdi", "George Herbert Walker Bush", "the backside", "\"the Gentle Don\"", "The Future", "the Knight Company", "Andrew Joseph", "Danish national ice hockey team", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer Guitars", "the Dominican Republic", "Humberside Airport", "1st round of 2017 Major League Baseball draft", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "William Lyon Mackenzie King", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Division of Fawkner", "Socrates", "American singer Toni Braxton", "Hindi", "Richard Masur", "Brian Patrick Friel", "311", "novel \"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda Capella", "102,984", "Roscoe Lee Browne", "1972", "John Goodman", "216", "Spectator magazine", "Easter Parade", "musical work", "last summer.", "100", "into the Southeast,", "a piece of the pie", "Great Balls of Fire", "heresy", "One Direction"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7040685876623376}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.6, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-2979", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-4710", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4996", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078"], "SR": 0.5625, "CSR": 0.503125, "EFR": 1.0, "Overall": 0.7515625}, {"timecode": 45, "before_eval_results": {"predictions": ["to take charge of Methodist activities there", "quod erat demonstrandum", "Elizabeth II", "part of the Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Stanley Winck", "Monty Hall", "mini-Golf", "CNN", "February 2,", "Bratislava", "yellow fever", "sea otters", "M&M's", "submarine", "rod", "Nixon", "horse", "astronomy", "Mickey Mouse", "anthers", "professor of Practice", "Part of the Foot", "Medusa", "a helix", "mottled", "a staff", "Voyager 1", "Farsi (Persian)", "glucose", "a tape measure", "China", "Helen of Sparta", "animal products", "peace sign", "Morrie Schwartz", "John, Harry Three", "Rajasthan", "Ben Kingsley", "a \"dirty blizzard\"", "NBA", "samt ar-ras", "How shall he cut it", "Part of office of, say, one-third of its members expires", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris", "Middle Eastern alchemy", "London", "Isle of Wight", "Peppercorn class", "\"Queen In-hyun's Man\"", "Oneida Limited", "San Antonio Spurs", "Libreville,", "$150 re-ticketing fee.", "his client, Brett Cummins,", "tuscaloosa"], "metric_results": {"EM": 0.390625, "QA-F1": 0.47925459956709954}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false], "QA-F1": [0.18181818181818182, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9923", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_naturalquestions-validation-9626", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3949", "mrqa_triviaqa-validation-888"], "SR": 0.390625, "CSR": 0.5006793478260869, "EFR": 1.0, "Overall": 0.7503396739130435}, {"timecode": 46, "before_eval_results": {"predictions": ["\"social classes\"", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "a torture chamber", "a faggot", "anser", "California Chrome", "Pluto", "Route 66", "Zagros Mountains", "the Arabian Sea", "a Space Cinema Movie", "desert", "German", "the British pop band Go West", "December 18, 1958", "In 1749,", "Portugal", "Operation Overlord", "Birmingham", "a snake", "Sedgefield in North East England", "the Coral Sea", "Iraqi President Ahmed Hassan al-Bakr", "Nadia Comaneci", "a tank museum", "South Korea", "pigs", "Fifteen", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "6", "the Potomac River", "Nicaragua", "\"Luke, I am Your Father\"", "Frankfurt", "a chipmunk", "Goldie Hawn", "Pulsar", "Belgium", "a horse", "a little extra juice and zest", "Portuguese giants Benfica", "sunny Leone", ", in whole or in part", "work in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "somatic cell nuclear transfer", "13th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the Louvre.", "Speed Racer", "H.G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6196924603174603}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5555555555555556, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-3840", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652"], "SR": 0.515625, "CSR": 0.5009973404255319, "EFR": 1.0, "Overall": 0.750498670212766}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Venice", "Sinclair Lewis", "a bear suit", "Renard", "a binder", "jodie Foster", "v\u00e1clav Havel", "Dick Van Dyke", "jimmy viillis", "Tina Turner", "1789", "coleraine", "glasses", "perfume", "sedge away for her", "iron", "germany", "The Apprentice", "a plimsoll line", "Cubism", "sahara", "sahomatosis", "eukharistos", "sahymn to the barn", "james Bond", "silks", "sahsein", "Adam", "rowing", "Corin Redgrave", "Call My Bluff", "a", "Argentina", "frank McCourt", "oats", "Caroline Aherne", "sedge", "carbon dioxide", "soap", "Donna Summer", "a balustrade", "nottingham", "gdansk", "Welcome Stranger", "taggart", "sedillia", "Chechnya", "Hong Kong Phooey", "maybe you can hire the A- Team", "football", "801,200", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "Speedway World Championship", "romantic and beautiful.", "36", "Michelle Obama", "kbenhavn", "the Proletariat", "a sara", "fluoroquinolones"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5366950757575757}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-7020", "mrqa_newsqa-validation-1804"], "SR": 0.484375, "CSR": 0.5006510416666667, "EFR": 1.0, "Overall": 0.7503255208333334}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "king \u00c6thelred the Unready", "Creature Comforts", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air Inc.", "Mineola, New York", "dzyha Vertov", "Strange Interlude", "Julia Compton Moore", "Olivia Newton-John's", "argentina", "early Romantic period", "The Gettysburg Address", "Harold Edward Holt", "Washington and Essex Streets", "Mathew Sacks", "the Processional Way", "second generation", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration", "Edward James Olmos", "Bury St Edmunds, Suffolk, England", "Prussian", "o", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848,", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "924", "381.6 days", "montgomery", "millheim, Pennsylvania", "her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine", "first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Peshmukh", "Challenger", "basil", "gold Georg Olden\u2013designed statuette", "The Rosie Show,\"", "North Korea", "over 1,000 pounds).", "octavius", "a palace", "the Library of Congress", "lumen"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6312127976190476}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, true, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-5048", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-5844", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028", "mrqa_naturalquestions-validation-4685"], "SR": 0.5625, "CSR": 0.5019132653061225, "EFR": 0.9642857142857143, "Overall": 0.7330994897959184}, {"timecode": 49, "before_eval_results": {"predictions": ["baseball, oin\u0103, ( Italy) and pes\u00e4pallo", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "Larry Lucchino", "James Woods", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Keitar\u014d Arima", "eastern India", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "44", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1928", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1988", "Canadian author Lucy Maud Montgomery", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "three Golden Globe Awards", "southwest Denver, Colorado", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec fox", "Netherlands", "Terry Malloy", "Golden Calf for Best Actor in 2013", "tomorrow May Never Come", "Thorgan Ganael Francis Hazard", "The closing scene of the final episode of the first season of the AMC original series The Bad and Detroit 1 - 8 - 7 in its 17th episode", "Fleetwood Mac", "Pandit Jawaharlal Nehru", "Honda", "j. M. W. Turner", "the Republic of Upper Volta", "56,", "Nkepile Mabuse", "Borussia Monchengladbach.", "U.S. Marines and other servicemen", "Hephaestus", "Amherst College", "six nice golf courses,\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6286868156353451}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 0.5333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2701", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-928", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_newsqa-validation-2144", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.515625, "CSR": 0.5021875, "EFR": 1.0, "Overall": 0.75109375}, {"timecode": 50, "UKR": 0.6640625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.837890625, "KG": 0.471875, "before_eval_results": {"predictions": ["Disha Patani", "\u00c6thelred", "St Andrews, Fife, Scotland", "26,000", "Spain, Mexico and France", "1981", "OS randolph", "February 26, 1948", "the National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line", "Epic Records", "IFFHS World's Best Goalkeeper", "Suggsy", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931 \u2013 May 31, 2016", "a mockingbird", "Picric acid", "Las Vegas", "ESPN's", "New Zealand food writer", "fantasy role-playing game", "explorer", "Dolly Records", "Bergen", "Marlon St\u00f6ckinger", "Feyenoord's Sekou Ciss\u00e9, WS Woluwe's Bassilia Sakanoko, UTA Arad's Leoh Digbeu", "1994", "the superhero Birdman", "Harrison County", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "ethereal gothic", "VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer University", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "21 December 2017", "1800", "the Behavioral Analysis Unit", "glycerine", "umbrellas", "sheep", "is the most high-profile amalgamation of Indian and western talent", "1.2 million people.", "84-year-old", "Genesis 45", "an accomplice", "Matt Damon", "Mitch Murray"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6302111950549449}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4599", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4130", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770"], "SR": 0.484375, "CSR": 0.5018382352941176, "EFR": 1.0, "Overall": 0.6951332720588235}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County, New York", "The Reich Chancellery", "Buskerud", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Daniel Espinosa", "1942", "water sprite", "Bury St Edmunds, Suffolk, England", "1981", "The Chiltern Shakespeare Company", "Cartoon Network Too", "MG Cars", "Jack Elam", "Patton Oswalt", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "Logan International Airport", "Blackpool Football Club", "American comic books", "Prince Rogers Nelson", "James Gregory", "Volvo 850", "1978", "July 25 to August 4", "Ann Ward", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom", "Oracle Corporation", "Pittsburgh, Pennsylvania", "John Andr\u00e9", "Three-card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Morozov", "It Andes or Andean Mountains", "The Dragon", "two", "Outside", "Traumnovelle", "Chechen Republic", "actress and model", "in the top division of English football", "Sierra Nevada mountains", "Guangzhou, China", "British", "Jaguar Land Rover", "Citgo Petroleum Corporation", "portrait painter", "B.R. Ambedkar", "Presley Smith", "the hydrological cycle or the hydrologic cycle", "William Snelgrave", "Jet Harris", "Melissa Duck", "in a tenement in the Mumbai suburb of Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.\"", "territory's autonomy.", "Popular Science", "a ton", "Latter-day Saints", "more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6111255931568431}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, true, false, false], "QA-F1": [0.6666666666666666, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.1904761904761905, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-2033", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-2929", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-2525", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-1209", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.484375, "CSR": 0.5015024038461539, "EFR": 0.9696969696969697, "Overall": 0.6890054997086247}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Japan", "St Augustine's Abbey in Canterbury, Kent.", "The Indianapolis Times and the Cleveland Press", "Yaphet Kotto", "Dizzy Dean", "UHF channel 44", "North Kesteven,", "West African descendants", "The Beatles", "\"Menace II Society\"", "September 1901", "March 30, 2025", "the Black Panther Party", "Pinellas County", "John Rockwell", "Imagine", "Evan Jonigkeit", "CBS", "\"Brickyard\"", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter Yarrow and Stookey", "Kathleen O'Brien", "private equity, credit and hedge fund investment strategies", "the River North Esk in Midlothian, Scotland", "several communes 25 km to the northeast of Paris", "rock music", "Yubin, Yeeun, Sunmi", "\"Complex\" magazine", "The Fight", "the University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"General Hospital\"", "David Dunn", "William Bradford", "FieldTurf", "My Beautiful Dark Twisted Fantasy", "Benj Pasek and Justin Paul", "a hand injury", "It replaced the earlier national arms, which had been in use since 1910", "U2", "the main pulmonary artery", "Pope Benedict XVI", "France", "Taekwondo", "The Tinkler", "since 1983.", "the legitimacy of that race.", "the Duke of Norfolk", "Italy", "chili pepper", "telescope"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6623387896825397}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.4, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.546875, "CSR": 0.5023584905660378, "EFR": 1.0, "Overall": 0.6952373231132075}, {"timecode": 53, "before_eval_results": {"predictions": ["a jedoublen/jeopardy", "Friedrich Nietzsche", "give up the ship", "the Mummy", "Ireland", "the glaciers", "bdellium", "Marie Antoinette", "Aunt Bee", "North Carolina", "the meadow grasshopper", "Ohiopyle", "Nostradamus", "the malignant disease", "The Flying Dutchman", "a light tan color", "hiawatha", "The Crow", "Athens", "John Keats", "Scott", "a new era in US-Central America", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "St. Petersburg", "Netflix", "Netflix", "Daughter", "a huge military parade", "the United Arab", "a new drowsy", "The Longest Night", "Netflix San Francisco", "Dred Scott", "josef de Beauharnais", "President McKinley", "a modern map", "Netflix", "the Crystal Light", "the Confederacy", "a Food Labeling", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "an ear", "India", "a new Boeing 707/320 commercial airframe", "the Director of National Intelligence", "Spinal fusion", "2018", "Peter Paul Rubenshuis Museum", "stalin", "David Bowie", "1 December 1948", "Lester Ben", "three centuries", "forgery and flying without a valid license,", "Michoacan state,", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5005952380952381}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-5257", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-16117", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-9523", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-66", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-238", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821"], "SR": 0.421875, "CSR": 0.5008680555555556, "EFR": 1.0, "Overall": 0.6949392361111111}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "318/92", "Phil Sedgmen", "Anthony Joshua", "Kansas", "purple", "F.W. de Klerk", "Denver", "George Blake", "Illinois", "armoured", "Adrian Cronauer", "Copenhagen", "the Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "Niagara Falls", "Dow", "@BBC", "jazz", "CompareCarRent", "Brazil", "aperitivo", "George Williams", "Michael Faraday", "George Bush Sr.", "Montmorency", "haddock", "Happy Ever After", "Helen Sharman", "Phil Redmond", "tamale", "Argentina", "St Moritz", "Bob Larbey and Esmonde", "Woody", "Jerry", "Sinclair Lewis", "mouse", "brazil", "Barry White", "Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "Coldplay", "the Wall Street Journal", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "The Worm", "The Golden Girls", "Immigrants Rights' Project", "the Bridgestone Invitational in Ohio in August.", "Easy Rawlins", "William McKinley", "Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.59375, "QA-F1": 0.640625}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-6992", "mrqa_triviaqa-validation-5245", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-6426", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-3131", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-1735", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187"], "SR": 0.59375, "CSR": 0.5025568181818182, "EFR": 1.0, "Overall": 0.6952769886363636}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there", "the man was dead,", "Gov. Bobby Jindal", "a vigilante group whose goal is the eradication of the Zetas cartel", "customers", "the Pentagon", "South Dakota State Penitentiary", "the Iranian consulate,", "crashing his private plane into a Florida swamp.", "lenin", "Matthew Chance", "in the north and west of the country,", "Bright Automotive", "NASCAR", "t.I.", "Muslim", "saint Takla Church", "adult reality show", "lenin", "unprecedented rise in American politics.", "urged NATO to take a more active role in countering the spread of the", "in 1831", "barks", "President Obama", "beetles", "lower house of parliament,", "walk over to me and slugged me on the arm.", "Prime Minister Benjamin Netanyahu", "Daniel Radcliffe", "has publicly criticized his father's parenting skills.", "Ronald Reagan UCLA Medical Center,", "he was ousted as prime minister in a military coup.", "six", "remains unknown,", "$89", "talked of an impromptu memorial for the late singer", "saint gagellan", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy", "looks at how children as young as eight would cope without their parents for two weeks.", "top winds", "rwanda", "two", "black Entertainment Television", "familiar answers", "Dancing With the Stars", "his club", "AMD", "two years", "U.S. President Abraham Lincoln", "Adam Sandler", "1,228 km / h ( 763 mph )", "Edward Yorke", "charlie sheen", "walker", "josef leason", "International Federation", "Valley Falls", "the Provisional Irish Republican Army", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.34375, "QA-F1": 0.47183325060573433}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 0.7368421052631579, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.25, 0.33333333333333337, 0.16666666666666666, 0.0, 1.0, 1.0, 0.8235294117647058, 0.0, 1.0, 1.0, 0.5, 1.0, 0.08695652173913043, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-475", "mrqa_newsqa-validation-110", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-1637", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2831", "mrqa_newsqa-validation-566", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-3914", "mrqa_naturalquestions-validation-6888", "mrqa_naturalquestions-validation-5983", "mrqa_triviaqa-validation-1475", "mrqa_triviaqa-validation-7529", "mrqa_hotpotqa-validation-5224", "mrqa_hotpotqa-validation-698", "mrqa_searchqa-validation-1388"], "SR": 0.34375, "CSR": 0.4997209821428571, "EFR": 0.9761904761904762, "Overall": 0.6899479166666665}, {"timecode": 56, "before_eval_results": {"predictions": ["a bomber", "the P", "deuterium", "corticosteroid", "Starship Troopers", "Stalin", "an aquifer", "Ovulation", "Python", "William Proxmire", "George Orwell", "indigenous", "turntable", "Coach Carter", "Brachiosaurus", "one small step for a man, one giant leap for mankind", "Psycho", "a believer", "Athina, Greece", "Extreme", "botanical", "Olivia Newton-John", "jimmy Lee Lewis", "Dwight L. Moody", "the staff", "Constantine XI Palaiologos", "tin", "Ganges River", "Captain Nemo", "the Dave Brubeck Quartet", "a Yellow Ribbon", "Stevie Wonder", "Danville, Virginia", "Jupiter", "spiders", "Apple", "Winter Depression", "the Mausoleum", "Act One", "a blue star sapphire", "Rhapsody", "the Ziegfeld Girl", "alcohol", "Ronald", "Mount Kilimanjaro", "a Militia", "Delaware", "Graceland", "the", "Sonny Corleone", "the 'oral phase' (second stage); the 'phallic", "John F. Kennedy", "Siddharth Arora / Vibhav Roy", "in the pouring rain at a rest stop, saying that he `` can't wait ''", "Munich", "Central London Railway", "in 1123", "Julie Kavner", "saint Benedict", "a Boltzmann machine", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5289569805194805}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-3167", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-11485", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-3447", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-16424", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-9015", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-1078"], "SR": 0.4375, "CSR": 0.49862938596491224, "EFR": 1.0, "Overall": 0.6944915021929824}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "disobedience", "Merlin", "sculpture", "Alien", "Large", "mariachi", "the first player to return after a kidney", "excruciating", "Kilimanjaro", "an opinion", "( Francis) Ford", "(Edward) Poe", "the Roman Empire", "Vancouver", "Twenty", "(Thomas) Edison", "turtles", "(Thomas) Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "the British band Tears for Fears", "the Discovery", "the Rhine", "blacksmith", "the mohs scale", "Katharine McPhee", "Henry Ford", "the Purple Rain", "Canute", "spiral", "(George) Stephanopoulos", "fish", "(Vijay) Singh", "a fractal", "Baton Rouge", "Daniel Boone", "(Emile) Stone", "a reptile", "Sweden", "pink", "a membrane", "Hong Kong", "the Addams Family", "vaccines", "Sanders", "the Bait-and-switch", "Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "(Jane) Clarke", "the University of Oxford", "1,467", "Columbia Records", "mistreated students", "Paul Schlesselman of West Helena, Arkansas,", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5917038690476191}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-2637", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-7113", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-13325", "mrqa_searchqa-validation-1930", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-9976", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-5688", "mrqa_triviaqa-validation-7432", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803", "mrqa_newsqa-validation-3265"], "SR": 0.515625, "CSR": 0.4989224137931034, "EFR": 0.967741935483871, "Overall": 0.6880984948553948}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht", "engaging with the Taliban in Afghanistan and Pakistan", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs", "\"No one on our end was ever contemplating pulling the plug,\"", "improve health and beauty.", "school", "Asashoryu", "fired employees attacked L.K. Chaudhary,", "China", "\"I never thought any of this was going to be easy,\"", "\"It is I, the chief executive officer, the one on the very top,", "longest domestic torch relay in the games' history", "a man's lifeless, naked body", "\"The death of their \"dear leader,\"", "military trials for some Guant Bay detainees.", "183", "Nirvana", "two Emmys", "55-year-old", "Zimbabwe", "new Touch,", "Dr. Maria Siemionow", "the International Polo Club Palm Beach in Florida.", "President Bush", "was burned over 65 percent of his body after being set on fire,", "1000 square meters in forward deck space", "can play an important role in Afghanistan as a reliable NATO ally.", "the sport of kings.", "a three-story residential building in downtown Nairobi.", "cancer", "Saddam Hussein's Revolutionary Command Council.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "funded by a German company and affiliated with the group Bread for the World.", "Christian bookstores", "Gov. Rod Blagojevich", "farmer Alan Graham", "February 12", "Oaxaca", "\"stressed and tired force\" made vulnerable by multiple deployments,", "allow sharia, or Islamic law, in the", "trading goods and services without exchanging money", "two people", "11 countries", "Many analog TV owners", "unfair competition for U.S. companies.", "Ben Roethlisberger", "Taylor Michel Momsen", "Stefanie Scott", "In November 2016", "Leicester Motorway", "Kinshasa, Zaire", "a dolcelatte", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "timothy Guthrie", "the Existentialism", "the Fallen Angels"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5342794923976989}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.17391304347826086, 1.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.1818181818181818, 0.6, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.14285714285714285, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.453125, "CSR": 0.498146186440678, "EFR": 1.0, "Overall": 0.6943948622881356}, {"timecode": 59, "before_eval_results": {"predictions": ["Tulsa", "Pakistan", "the DTM", "Vernon Kay", "Florida", "ten episodes", "Tim Andrew", "Betty Cohen", "Scandinavian design", "Hugh Hefner", "Pasek and Paul", "Toxics Release Inventory", "Oregon", "\"Mrs. Eastwood & Company\"", "Blackpool Football Club", "in southwest Denver, Colorado", "Ted Kennedy", "Boeing", "21st Century Fox", "Pennsylvania's", "Danielle Steel", "1970s and 1980s", "New York Knicks", "Hazel Keech", "NATO", "sometimes I. A. K. Pataudi", "more extreme nationalist, and nativist ideologies", "AOL", "World War II", "the coca wine", "Secretary of Labor", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Art Bell", "California Shipbuilding Corporation", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2 in C-sharp minor, S.244/2", "from the playing season, or before November 1", "Brian Steele", "from 35 to 40 hours per week", "kinsomniacs", "the Dieppe Raid", "hanover", "Capitol Records,", "in an almost constant series of thunderstorms.", "son of Gabon's former president", "in Colonial times, pig stealers were exposed to public derision at the pillory... those,", "Thomas Edison", "Han Solo", "Jeannie Longo-Ciprelli"], "metric_results": {"EM": 0.5, "QA-F1": 0.6181557158119659}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 0.923076923076923, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3372", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-1201", "mrqa_triviaqa-validation-5185", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-2346", "mrqa_searchqa-validation-10636", "mrqa_newsqa-validation-153"], "SR": 0.5, "CSR": 0.4981770833333333, "EFR": 1.0, "Overall": 0.6944010416666666}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "The Celebrity Apprentice", "'overcharged.'\"", "95", "Carrousel du Louvre,", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she had drowned on Anjuna beach after taking drugs,", "Carl", "43,000", "269,000", "flooding was so fast that the thing flipped over,\"", "The Frisky", "Patrick McGoohan,", "their ambassadors", "Afghan security forces", "body", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell,", "\"not generals but businessmen\"", "$55.7 million", "Noida, located in the outskirts of the capital New Delhi.", "body bags on the roadway near the bus,", "in the eastern Afghan province of Logar,", "10 to 15 percent", "The request caught Spanish authorities by surprise,", "Annie Duke", "an engineering and construction company", "Casa de Campo International Airport in the Dominican Republic", "At least 15", "the fires", "one-of-a-kind navy dress with red lining by the American-born Lintner,", "monthly allowance,", "Too many glass shards left by beer drinkers in the city center,", "the legitimacy of that race.", "Nigeria", "Andrew Morris,", "and renewable energy at home everyday,\"", "Drottningtorget", "the driver", "Haiti", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "golden", "Australia and Ireland", "1975", "1970", "Copenhagen", "The Pacemakers", "Khartoum", "Hisville, Oregon", "Italian"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6196412003566609}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.19047619047619047, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.08333333333333334, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.04761904761904762, 0.5, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-199", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2402", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-3782", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_searchqa-validation-6409", "mrqa_searchqa-validation-3563"], "SR": 0.53125, "CSR": 0.498719262295082, "EFR": 1.0, "Overall": 0.6945094774590164}, {"timecode": 61, "before_eval_results": {"predictions": ["allergic reaction to peanuts,", "The retired Navy F-14 fighter pilot is the commander of the current space shuttle mission to repair and upgrade the Hubble Space Telescope.", "Santaquin City, Utah, home", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "Carson", "Bob Bogle", "183", "--CNN-based Senior International Correspondent Matthew Chance", "Sunday when on-loan David Beckham claimed his first goal in Italian football.", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "The Maraachli case caught the attention of the group Priests for Life,", "General Motors'", "Four Americans -- two soldiers and two civilians from the Defense and State departments", "Mark Fields", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "the soldiers", "the body of the aircraft", "American third seed Venus Williams in the final of the Sony Ericsson Open in just 58 minutes.", "onto the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "the world's tallest building,", "Europe,", "44 firearms, 650 pounds of marijuana, 435 pounds of cocaine and $7.8 million in cash", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "City", "surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "CNN Moscow Correspondent at Star City, South Korea, China, South Africa.", "school,", "The eye of Hurricane Gustav", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "two", "outfit from designer", "Parts of a collapsed ConAgra Foods plant lies atop parked cars", "second-degree aggravated battery.", "the man facing up, with his arms out to the side. He is wearing socks but no shoes.", "British Prime Minister Gordon Brown's", "first of 1,500 Marines", "Thai", "Arsene Wenger", "The local Republican Party", "the Gulf", "Matthew Fisher,", "27,", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "The U.S. Department of Housing and Urban Development distributed $400 million in emergency aid Friday to eight states that experienced the biggest natural disasters in 2011.", "Television's Wolf Blitzer. \"They don't want democracy, they don't wants me back,", "short - circuit - proof extra-low voltage transformers for toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "the double-headed eagle of the Austrian and Russian empires", "Umberto II", "The Longest Yard", "Lucille Ball", "Louis XIV", "The Bronx", "flamboyant", "South Africa"], "metric_results": {"EM": 0.5, "QA-F1": 0.6068166685221739}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.22222222222222224, 0.2727272727272727, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 0.8, 0.0, 0.23529411764705882, 0.0, 0.33333333333333337, 0.0, 0.3157894736842105, 0.0, 0.16666666666666669, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.26666666666666666, 1.0, 0.72, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.13793103448275862, 0.0, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-237", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2970", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-4119", "mrqa_newsqa-validation-2306", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-531", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-2149", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_triviaqa-validation-5178"], "SR": 0.5, "CSR": 0.49873991935483875, "EFR": 1.0, "Overall": 0.6945136088709678}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0", "portrait of William Shakespeare", "Current TV", "200", "rapper T.I.", "the media", "Friday,", "the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Arizona", "Iran could be secretly working on a nuclear weapon", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "56,", "April 28", "former Boca Juniors teammate and national coach Diego Maradona,", "Former Argentina international defender Fernando Caceres", "license plate \"BADBUL,\"", "Kurt Cobain", "nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "East Java", "\"The Cycle of Life,\"", "diplomatic relations", "supermodel", "10 below", "1,073", "children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "fled Zimbabwe", "girls around 11 or 12.", "Israeli", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee.", "Bright Automotive,", "nuclear-armed Iran", "the invention of iTunes,", "\"Up,\"", "165-room", "\"She came to my rescue when my husband was not working.\"", "al Qaeda,", "the jury trials I've had,", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "the 20-month-old boy", "Omar", "Hu and other top Chinese officials", "United States", "Burj Dubai tower", "speaking out about a cause someone feels passionate about.", "25 years", "Anil Kapoor", "President Obama and Britain's Prince Charles", "Twickenham Stadium, London", "a receptor or enzyme", "9.0 -- 9.1", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Bob Mould", "331 episodes", "2008", "Ruth Bader Ginsburg", "The Big Sleep", "Seth", "hen"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5323937908496732}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.11764705882352942, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.26666666666666666, 0.8, 0.0, 0.0, 0.0, 1.0, 0.5, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3044", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-3409", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746", "mrqa_triviaqa-validation-3869"], "SR": 0.390625, "CSR": 0.49702380952380953, "EFR": 0.9487179487179487, "Overall": 0.6839139766483516}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the Dalai Lama", "The fourth gunshot wound,", "to help women \" learn how to dance and feel sexy,\"", "German Foreign Ministry,", "60 euros -- $89", "Ten South African ministers and the deputy president", "Pakistan", "Japanese officials", "The United Nations is calling on NATO to do more to stop the Afghan opium trade", "poor.", "bench", "Sixteen", "poems telling of the pain and suffering of children just like her;", "(3 degrees Fahrenheit),", "in Nuevo Leon,", "Orioles", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "and renewable energy at home everyday,\"", "The Obama chief of staff", "British military officials", "rich conditions for inmates, like Amnesty International.", "The minister later apologized, telling CNN his comments had been taken out of context.", "United's", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars.\"", "civilians,", "March 3,", "allergies to peanuts, nuts, shellfish and fish tend to be lifelong,", "Asashoryu", "a bag", "a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Buddhism", "Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "\"peregruzka\"", "for an independent homeland since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "a turlough, or turlach", "1910", "Kirk Douglas", "Radio City Music Hall", "Vijram, Jyothika", "Dutch Empire", "Royal Navy rank of Captain", "the Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6486130750377074}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 0.8235294117647058, 1.0, 0.8, 1.0, 1.0, 1.0, 0.07692307692307691, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 0.0, 0.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.25, 0.0, 0.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-1286", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-2470", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-800", "mrqa_newsqa-validation-3692", "mrqa_newsqa-validation-2353", "mrqa_newsqa-validation-372", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.53125, "CSR": 0.49755859375, "EFR": 1.0, "Overall": 0.6942773437499999}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear,", "15-year-old", "July 23.", "Alwin Landry", "a Korean-American missionary", "Chester Stiles, 38,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan and Egypt striker Amir Zaki", "Adriano", "poems", "Sgt. Barbara Jones", "Rip Markoff,", "sniff out cell phones.", "Longo-Ciprelli", "\"The Screening Room\"", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944", "\"I'm just getting started.\"", "light snow or flurries", "more than 30", "presidential salary", "determining which Guant detainees should be tried by a U.S. military commision,", "free laundry service.", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "the school.", "a plaque at the home of his great-grandfather", "for death squad killings", "a nuclear weapon", "Tina Constable,", "\"The missile defense system is not aimed at Russia,\"", "Oregon", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "stuck to with remarkably little internal drama. He won it with unparalleled fundraising and an overwhelming ground game. And he won it after facing various challenges and turning them to his advantage.", "$3 billion,", "photo album", "Larry King", "\"I'm glad to put this case behind me and I am really looking forward to the season ahead and concentrating on my football now.\"", "potential revenues from oil and gas", "Barack Obama", "no airbags, credit and other key indicators.", "cannonball", "180th meridian", "Darlene Cates", "Colette", "crows, ravens and jays", "douglas douumosu", "21 July 2015", "KULR-TV", "January 15, 2016", "piano", "4.5%", "Barnard", "Chiltern Hills,"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5870508181055056}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.22222222222222224, 0.888888888888889, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.4, 0.5, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.9666666666666666, 1.0, 0.3636363636363636, 0.0, 0.0625, 0.2857142857142857, 0.8, 0.15384615384615383, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-8", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-690", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516"], "SR": 0.4375, "CSR": 0.4966346153846154, "EFR": 1.0, "Overall": 0.6940925480769231}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Bobby Darin,", "The Ski Train", "housing, business and infrastructure repairs,", "Officer Joe Harn", "Port-au-Prince harbor", "Uzbekistan.", "Israel", "gas", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "identity documents", "Denver, Colorado.", "\"He hears what I'm saying, but there's just no coming through,\"", "the single-engine Cessna 206", "no need for such humility.", "police", "could be secretly working on a nuclear weapon", "was arrested Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Carol Barnett", "Scott Carolina Republican Party Chairwoman Karen Floyd", "people are going to look at the content of the speech, not just the delivery.", "April 22.", "Manuel Mejia Munera", "outfit from designer", "five", "Ozzy Osbourne", "British Prime Minister Gordon Brown's", "Steven Chu", "gas", "23", "Fullerton, California,", "Hawaii", "Bill Haas", "\"A Lion Among Men,\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Karl Kr\u00f8yer", "Gyanendra,", "to show that a visitor had been to the grave.", "Adam Yahiye Gadahn,", "Turkey", "Polo because \"it was the sport of kings.", "Texas and Oklahoma", "\u00a320 million ($41.1 million)", "her resources", "700,000", "at her 8th-grade graduation,", "woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "Chicago, in Lake County, Illinois", "Eran Kolirin", "cryptobiosis", "Clemson University", "Herod", "leopard"], "metric_results": {"EM": 0.375, "QA-F1": 0.4975678759646151}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.08695652173913043, 0.0, 0.8571428571428571, 0.17391304347826086, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-979", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-3839", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_hotpotqa-validation-3069", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.375, "CSR": 0.49479166666666663, "EFR": 1.0, "Overall": 0.6937239583333332}, {"timecode": 66, "before_eval_results": {"predictions": ["Spanish Davis Cup hero Fernando Verdasco,", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "uranium enrichment activities.", "green-card warriors", "space for aspiring entrepreneurs to brainstorm with like-minded people.", "Dilshan", "Columbia, Missouri.", "Two U.S. filmmakers were injured", "Harris won two awards.", "Bowe Bergdahl,", "many different", "Mugabe and Tsvangirai", "$17,000", "Employee Free Choice act", "Sadat signed the Camp David peace treaty with Israel", "Thomas,", "snowstorm", "Arnold Drummond", "Madonna", "\"I'm certainly not nearly as good of a speaker as he is.\"", "the military commissions", "\"It seems an unlikely musical style for the Pittsburgh native to pursue. Enka's fan based comes generally from an older generation and is practically unknown outside of Japan,", "Barack Obama: \"I'm certainly not nearly as good of a speaker as he is.\"", "as many as 250,000", "is not doing everything within its power to prevent more people from needlessly suffering tendon ruptures.", "managing his time.", "The tale told by Average -- whose name is not unusual in Zimbabwe", "Omar", "Scotland", "Mugabe's opponents", "inferior,", "possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "Millvina Dean,", "dental work", "future relations between the Middle East and Washington.", "fake his own death by crashing his private plane into a Florida swamp.", "\"I haven't seen any violence. I know [Wimunc's husband] was not living here anymore, but that's all I know,\"", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "\"stateless actors\"", "Henrik Stenson", "1995", "\"The Angels family has suffered a tremendous loss today,\"", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "Why he's more American than a German,", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "demonstrations", "American Indian allies", "naturalization law", "Sigurd the Dragonslayer", "blancmange", "apples", "Los Alamos National Laboratory", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "Potomac", "Balaam's treatment"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4135810050694919}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2105263157894737, 0.3333333333333333, 0.06666666666666667, 0.0, 0.4, 0.9696969696969697, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.4, 0.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2896", "mrqa_newsqa-validation-3301", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-659", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-571", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-12973", "mrqa_naturalquestions-validation-230"], "SR": 0.328125, "CSR": 0.49230410447761197, "EFR": 1.0, "Overall": 0.6932264458955224}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "road-building", "candle", "Thornbridge Jaipur", "tea concentrate", "the Ordovician", "Martin Pipe", "Wordsworth", "Ginger Rogers", "theatre", "borax", "United States Dollars", "peregrines", "3, 3, and 6", "muscle tissue", "\"tweener\"", "Derby Stakes", "Easter Parade", "Greek Home Management", "HMS Amethyst", "pig", "sargieg", "old WWII whistling tune, the Colonel Bogey March", "Cyprus", "King George VI", "a compact bone that sits between the calcaneus (heel bone) and the tibia and fibula (bones of the lower leg", "Greyfriars Bobby", "honey", "flea", "white robe", "Big Bopper", "the NBA", "Simonetta Perkins", "Leander", "West Ham", "entropy", "Wadsworth", "green", "Amelia Earhart", "James Hogg", "lacrimal", "Loki Laufeyiarson,", "Tall Story", "Manfred von Richthofen", "God", "1879", "Los Angeles", "Loch Awe", "right triangle", "black", "ballet", "the New York Yankees", "1967", "0 K", "Bolshoi Theatre", "My Boss, My Teacher", "mermaid", "death squad killings", "the Atlantic Ocean.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "36 months old"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5897693452380952}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.75, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-1352", "mrqa_triviaqa-validation-4293", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-1541", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6429", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-3798", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_hotpotqa-validation-3584", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.484375, "CSR": 0.4921875, "EFR": 0.9696969696969697, "Overall": 0.6871425189393939}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast", "smen", "the northern borders of West Virginia and Kentucky", "the Americans", "Australia", "2018", "along the coast of northern California", "Monkey", "257,083", "southwestern part of the island", "Norman", "the new government", "Shawn", "if the concentration of a compound exceeds its solubility", "the United States", "1623", "the `` round ''", "from 1957", "360", "one of the horizontal rows", "bile and pancreatic juice", "Lori McKenna", "Wisconsin", "Tbilisi", "100", "1799", "the eleventh book in the New Testament", "His last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles", "Elvis Presley", "2009", "Best Art Direction, Best Makeup, and Best Visual Effects", "long - standing policy of neutrality", "291 episodes", "Cairo, Illinois", "No Secrets", "spacewar", "22", "from 4 January 2011", "complex New Zealand to New Guinea subduction", "Bill Russell", "Seattle, Washington", "the temporal lobes of the brain and the pituitary gland", "2010", "Buddhism", "in the 7th century", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "early 1860s", "april", "mwestwood", "huff & puff:", "Brad Silberling", "1941", "Nickelodeon Studios", "Sunday", "new clock faces", "Thursday because they expelled me by force,", "bonobo", "toward", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.421875, "QA-F1": 0.525274489362191}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 0.14285714285714288, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.5185185185185185, 1.0, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.45161290322580644, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-10389", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-9277", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_newsqa-validation-2251", "mrqa_newsqa-validation-3931", "mrqa_searchqa-validation-12035"], "SR": 0.421875, "CSR": 0.4911684782608695, "EFR": 0.972972972972973, "Overall": 0.6875939152467685}, {"timecode": 69, "before_eval_results": {"predictions": ["The East End of London", "Kenya", "The Proposal", "Brazil", "Artemis", "three phases", "Bishopston", "Sunshine State", "pink", "tin", "Anita Roddick", "The phrase \"e pluribus unum\"", "Black Swan", "Cambridge", "deuteranapolis", "Cambodia", "new Volkssturm national militia", "Russia", "1925 novel", "a co-  operative", "180\u00b0", "blue", "Tommy Burns", "M in GoldenEye", "Andre Agassi", "eyas", "The Times", "john le Carr\u00e9", "Papua New Guinea", "Albania", "a particular animal group or category: the zoology of mammals", "Zelle", "the different levels of importance of human psychological and physical needs", "polo", "gulliver", "Nationally Recognized Statistical Rating Organization", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek,", "hydrogen", "Guinea", "ghee", "Marcus Antonius", "a convict", "Canary Wharf", "Charlie Brown", "Corvidae", "hunt for Snarks", "Union of Post Office Workers", "Tokyo Metropolitan Assembly", "knaresborough", "Walter Mondale", "to stable and reliable initiation of nuclear chain reaction in nuclear reactors", "the plane crash", "fictional character", "The Kingkiller Chronicle", "3.9 mi", "$1.5 million.", "Christianity and Judaism,", "The jury said it was split 10-2.", "Space Shuttle", "Smithfield, Virginia", "The labor camp also degrades its prisoners spiritually. By replacing prisoners'... At meal time, no matter how hungry he is, he insists on removing his cap before eating", "10 Years"], "metric_results": {"EM": 0.375, "QA-F1": 0.42671130952380953}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5011", "mrqa_triviaqa-validation-897", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1156", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-4999", "mrqa_searchqa-validation-16464"], "SR": 0.375, "CSR": 0.4895089285714286, "EFR": 0.975, "Overall": 0.6876674107142857}, {"timecode": 70, "before_eval_results": {"predictions": ["douglas", "three", "high jump", "diana", "p\u00e4rt", "watchmaking", "Edmund Cartwright", "grapevine", "evolutionary", "Philip Larkin", "shropshire", "Kent", "fox", "Jack Brabham", "peterborough", "hanover", "algebra precalculus", "florney", "woodbo", "prussian", "red sea", "cats", "wood", "eagles", "teenage Hogwarts student", "Milan", "eagles", "ceeLo Green", "photography", "Justin Bieber", "Greece", "m\u00e1qu\u00e8", "scar", "Stars on 45 Medley", "Cheltenham & Gloucester", "bowie knife", "Istanbul", "Margaret Thatcher", "Achille Lauro", "Botham", "stop motion effects", "mweelrea", "Ellis Island", "fijian", "triagon", "Dick Advocaat", "John Huston", "Tupac Shakur", "Anthony Hopkins", "richmond", "Moscow", "2005", "the governor of West Virginia", "Spanish", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition", "2010", "the Socceroos", "Jerry Rice", "leotard", "Ford", "hips"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5609375}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-6183", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-1704", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6305", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.515625, "CSR": 0.48987676056338025, "EFR": 1.0, "Overall": 0.692740977112676}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot: The Inside Story of America's Race to the Moon", "Kim Sung-su,", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "The Man from Jupiter", "L\u00edneas A\u00e9reas", "October 15, 2013", "Jeanne Tripplehorn", "japan", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York", "1853", "Kew", "\"Apprendi v. New Jersey\"", "the 4 km River Shiel", "from 1993 to 1996", "sierre", "University of Georgia", "Burning Man", "Arizona State University", "Pan Am Railways", "Jon Hamm", "11", "mid-tempo pop and R&B love song", "7 miles", "2016", "Pollywood", "Carver Dana Andrews", "July 25 to August 4", "1950s", "460", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "Major League Soccer", "special economic zone (SEZ)", "\"Knight of Cups\"", "California", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "detention camp", "France", "Wordsworth", "italy", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "to \"wipe out\" the United States if provoked.", "two years", "Yahtzee", "Hinduism", "60 Minutes", "two-platform medium"], "metric_results": {"EM": 0.625, "QA-F1": 0.7032772435897436}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.8, 1.0, 0.0, 0.0, 0.25, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.72, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-5430", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-5421", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-4299", "mrqa_hotpotqa-validation-4051", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-4412", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-381", "mrqa_naturalquestions-validation-5036", "mrqa_triviaqa-validation-3859", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-213", "mrqa_triviaqa-validation-4907"], "SR": 0.625, "CSR": 0.4917534722222222, "EFR": 1.0, "Overall": 0.6931163194444444}, {"timecode": 72, "before_eval_results": {"predictions": ["the conclusion of a syllogism", "the defendant owed a duty to the deceased to take care", "100,000", "2004", "the NFL", "9th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Joyce Vincent Wilson", "2014 Winter Olympics in Sochi, Russia", "Udhampur - Srinagar - Baramulla", "greater parallax", "Kansas", "1871", "the final episode of the series", "Wisconsin", "the magnetic stripe `` anomaly '' on the ocean floor", "stems and roots of certain vascular plants", "Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "the Rock", "2015 World Series", "Massachusetts", "Mark Jackson", "Arthur `` The President '' Flanders", "antimeridian", "\" Remember that you are dust, and to dust you shall return", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Kida", "Selena Gomez", "iron", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "the United States of America", "2013", "Twickenham", "near major hotels and in the parking areas of major Chinese supermarkets", "the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form", "79", "the League of Communists of Yugoslavia party and a ruling elite", "the nucleus", "1853", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "No. 16 seed", "Tom Hanks", "Daya Jethalal Gada", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "de Havilland Moth", "architecture", "Bermuda", "win world titles in four weight classes", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Neymar", "22", "opium", "Roger Federer", "parody", "prostitute", "Jude Law", "spain"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5540122066454787}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, false, false, false, true, false, true, true, false, false, true, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, true, false, false, false], "QA-F1": [0.35294117647058826, 1.0, 0.07999999999999999, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.22222222222222224, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.15384615384615383, 0.09523809523809523, 1.0, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-8610", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_searchqa-validation-1943", "mrqa_triviaqa-validation-4962"], "SR": 0.46875, "CSR": 0.4914383561643836, "EFR": 1.0, "Overall": 0.6930532962328767}, {"timecode": 73, "before_eval_results": {"predictions": ["the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "December 22, 2017", "Barbara Windsor", "ninth", "the Italian Campaign, which culminated in the downfall of the fascist government in Italy and the elimination of Germany's main European ally", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "Paul the Apostle", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "1927", "Taylor Michel Momsen", "Magnavox Odyssey", "Lightning thief", "2015", "2000", "Sara Gilbert", "1962", "The fifth studio album by English rock band the Beatles", "John Smith", "Jane Fonda", "the first type", "the Election Commission of India", "203 members", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Dracula", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Cecil B. DeMille", "1877", "`` help bring creative projects to life ''", "Joan Baez", "Joseph Nye Welch", "`` flawed democracy ''", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "the Jurchen Aisin Gioro clan in Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Hummer", "wooden", "Kev", "Tampa, Florida", "1874", "January 28, 2016", "Jaipur", "18th", "July", "taro", "You Bet Your Life", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6558000113921166}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, true], "QA-F1": [0.9696969696969697, 0.21052631578947367, 1.0, 0.4, 1.0, 0.6666666666666666, 0.10526315789473684, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-4500", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-10250", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-10525", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7794", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_hotpotqa-validation-1020", "mrqa_newsqa-validation-270"], "SR": 0.546875, "CSR": 0.4921875, "EFR": 0.9655172413793104, "Overall": 0.6863065732758621}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Russell Stover", "hub", "Starbucks", "the Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "unions", "togo", "blitz", "New Wave", "commune", "a ring", "the Thames", "chanteuse", "hockey", "Hans Christian Andersen", "David", "The Color Purple", "whales", "Jane Addams", "Judi Dench", "Tanzania", "Tucson", "an inch", "death", "Henry Wadsworth Longfellow", "Fred Thompson", "Geneva", "humility", "white", "Twelve Thirty", "diatomaceous", "$9 trillion", "pig", "Lake Titicaca", "Existentialism", "ashes", "Julius Caesar", "george Freeth", "Isaac Newton", "Charles I", "Kevin Costner", "Antichrist", "clef", "uranium", "Louisiana", "The Hot Chick", "composting", "2016", "April 2010", "67", "Spey", "Popeye", "Denmark", "Trappist beer", "4,530", "Steve Prohm", "at least seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitobaowoc County"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6494791666666666}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-13356", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-9751", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-15658", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-10139", "mrqa_hotpotqa-validation-1307", "mrqa_newsqa-validation-1696", "mrqa_hotpotqa-validation-3458"], "SR": 0.578125, "CSR": 0.4933333333333333, "EFR": 1.0, "Overall": 0.6934322916666666}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "John Nightingale", "the main highway entrance at California State Route 1", "The term `` AWD '', or all - wheel drive, is used for any vehicle which drives on all four wheels, but may not be designed for off - road use", "Turing", "B.F. Skinner", "hydrogen", "Spain", "William the Conqueror", "111", "1983", "Baker, California", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "Tennessee Hagerty", "the President", "Spanish missionaries", "Gustav Bauer", "art of the Persian Safavid dynasty from 1501 to 1722", "a vertebrate's immune system", "2.45 billion years ago", "Yente", "March 31, 2017", "a small synovial joint between the malleus ( hammer ) and the incus ( anvil", "Gina Tognoni", "the Gupta Empire", "maximum energy of 687 keV", "1 ( threshold 85 %, a distinction )", "1979", "John Roberts", "Spanish / Basque", "Arlington National Cemetery in Virginia", "1349", "Glenn Close", "Robert Remak", "the Yankees", "while studying All My Sons by Arthur Miller", "International System of Units ( SI )", "Lady Olenna Tyrell", "electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions", "Bill Belichick", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "the underground organization of the Irish Republican Brotherhood (see 2.272n) in the early twentieth century", "Blackburn", "April 20, 1967", "Yubin, Yeeun", "9.58 seconds", "sedative", "boat's hull,", "'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's Disease", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6531546435128519}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4210526315789474, 0.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.32558139534883723, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-438", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-5882", "mrqa_naturalquestions-validation-5634", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-6333", "mrqa_triviaqa-validation-2810", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-4180", "mrqa_hotpotqa-validation-2232", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_hotpotqa-validation-3909"], "SR": 0.578125, "CSR": 0.4944490131578947, "EFR": 0.9259259259259259, "Overall": 0.6788406128167641}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "honey", "repechage", "Scotland", "Victoria Rowell", "Barcelona", "hayland", "heavy birds", "Toby", "sain", "Chesney Wold", "four", "the Indus Valley", "sELFIE", "jaws", "charlie cairoli", "Hague", "Adidas", "parr St. Studios in Liverpool,", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "sistine Chapel, Vatican City, 2005", "Patrick Kielty", "8 minutes", "Tribbiani", "sraeli teenager wounded in Friday afternoon\u00e2\u0080\u0099s deadly terror attack in Beersheba.", "Schumann", "Margaret Thatcher", "Hooky Street", "sam & Mark", "Andrew Lloyd Webber", "Bonn", "vice-admiral", "snake", "the Coral Sea", "David II BRUCE", "Madonna", "par-5", "Millerlite beer", "leg", "Ice Age:", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "hayley Harvey Crippen", "fifty-six", "1803", "1979", "1976", "the Gupta Empire", "stunt performer", "2004", "Rwandan genocide", "Williams", "winter storm", "fight outside of an Atlanta strip club on October 9.", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6219866071428571}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-6005", "mrqa_triviaqa-validation-7046", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2600", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-2810", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.546875, "CSR": 0.4951298701298701, "EFR": 1.0, "Overall": 0.693791599025974}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "ATX Television Festival", "president of Guggenheim Partners", "Diamond Rio", "lola Dee", "master builder", "UFC 50: The War of '04", "Barbara Ryan Coleman", "Rounders", "24 hours a day and 7 days a week", "o", "Nobel Prize in Physics", "glee", "Chris Corbould", "his advocacy of young earth creationism and intelligent design", "2 November 1902", "December 1993", "orisha", "2006", "SS-Oberst-Gruppenf\u00fchrer", "Dziga Vertov", "loch lomond", "National Football Conference (NFC) West division", "brothers", "James Franco", "London", "Kelly Bundy", "British", "high Arctic tundra soil near Ny-\u00c5lesund in Norway", "astronomer and composer of German and Czech-Jewish origin, and brother of fellow astronomer Caroline Herschel, with whom he worked", "around 8000 BC", "2002", "Peter Seamus O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "Rugby Sevens Series", "Talbot School of Theology at Biola University in La Mirada, California", "playwright", "response-oriented therapy", "Formula One", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "A bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Noel Fielding", "Mel Gibson", "1980s and'90s", "San Francisco", "robert hartnell", "north Shore", "college campus.", "$106,482,500", "15-year-old's", "Cleopatra", "Arm & Hammer", "of Denmark", "keyboardist Bob Nave"], "metric_results": {"EM": 0.5, "QA-F1": 0.6240438230248013}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.4, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.3636363636363636, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.08695652173913043, 1.0, 0.0, 0.8, 0.8000000000000002, 1.0, 0.0, 0.3076923076923077, 0.25, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-3101", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-6460", "mrqa_triviaqa-validation-16", "mrqa_newsqa-validation-2168", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.5, "CSR": 0.4951923076923077, "EFR": 0.96875, "Overall": 0.6875540865384615}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "August 1991", "Nigel Lythgoe", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "1956", "Atlanta, Georgia", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "1990", "Gil", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "muscles", "the process always begins when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1957", "April 10, 2018", "the external genitalia", "May 2017", "September 19, 1977", "the S - stage of interphase", "1956", "13.5 %", "Great G minor", "Ye Hai Mohabbatein", "Newfoundland", "Ole Einar Bj\u00f8rndalen", "31 December 1960", "when they qualify as a medical practitioner following graduation with a Bachelor of Medicine", "pre-Christian festivals that were celebrated around the winter solstice", "from 1992", "Lesley Ann Warren", "All Hallows'Day", "November 1961", "midpiece", "2004", "about $1.09 trillion", "7000301604928199000 \u2660 3.016 049 281 99", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Cajun French", "March 16, 2018", "The Ballpark of The Palm Beaches", "Dorothy Gale", "Sachin Tendulkar", "international nations", "Andrew Lloyd Webber", "domestic cat", "Q", "liam fox", "sheepskin", "5,922", "1866", "2", "2006", "nine", "Lake Superior", "River Thames", "American popular singer widely known as the King of Rock and Roll", "red"], "metric_results": {"EM": 0.5, "QA-F1": 0.6061056998557}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.06060606060606061, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8823529411764706, 1.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.5, 0.8, 0.0, 0.2222222222222222, 1.0, 1.0, 0.11764705882352942, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9707", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-1886", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5102", "mrqa_newsqa-validation-3539", "mrqa_newsqa-validation-3297", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-10079", "mrqa_searchqa-validation-1302"], "SR": 0.5, "CSR": 0.495253164556962, "EFR": 1.0, "Overall": 0.6938162579113923}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "The 2003 LSU Tigers football team", "1869", "American heavy metal band", "Edison Koon-hei Chen", "1875", "The satirical News Network", "The pioneer of this technique is Constantin Stanislavski who sought to overcome the divisions between \u201cmind from body, knowledge from feeling, analysis from action", "Juilliard School", "World Outgames", "1812", "a pear or a nectarine", "1885", "Oregon Ducks", "Victorian England", "The War of '04", "Australian", "pinball machine designed by Steve Ritchie and manufactured by Stern Pinball that was first released in June 2007", "Alpine climate and landscapes, in particular for skiing and mountaineering", "a representation of the Baudot code", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "in the Estadio Victoria", "Jacques Dominique Wilkins", "Mattel v. MCA Records, Inc.", "New South Wales", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "American comedy-drama television series which airs on Showtime", "between 1252 and 1259", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1967", "London", "Bulgarian", "James Mitchum", "Nick on Sunset", "Ken Rutherford", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "gollum", "city", "eenezer Scrooge", "8,", "Muslim Eid-ul-Adha", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond", "Venezuela", "the Stone Age", "\"to do the right thing for himself, his family and our state."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5520280067155067}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.4615384615384615, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.13333333333333333]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-5741", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4744", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-808", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-2664", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-3615", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-261", "mrqa_hotpotqa-validation-4714", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4981", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-3221", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-3388", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-4640", "mrqa_triviaqa-validation-5027", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.4375, "CSR": 0.49453125, "EFR": 1.0, "Overall": 0.6936718749999999}, {"timecode": 80, "before_eval_results": {"predictions": ["a Roman Catholic Archdiocese of Miami", "wine", "\"The chief business of the American people is business\"", "volleyball", "a 1982 hit rock song written and performed by American singer-songwriter John Mellencamp, then performing as \"John Cougar.\"", "hot springs", "the Philosopher's Stone", "Sony", "pro bono", "an American politician and businessman who was the 46th Vice President", "an epitaph", "padd", "a dragon", "rats", "Division of Computational Systems Medicine", "The Merry Wives of Windsor", "kowtow", "Mars", "a Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "pane", "a liqueurs", "Cuisinart", "a travertine", "Bob Dole", "the Ross Ice Shelf", "director", "paddol", "California", "The Coachman", "Czech Republic", "the Palais Garnier", "a bison", "Athens", "Jodie Foster", "Cleopatra VII", "the Mummy", "Buck", "the bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "August 5, 1937", "53", "Lightning thief", "Brazil", "Edinburgh", "george", "Alicia", "University of California", "Saturday Night Live", "Sheik Mohammed Ali al-Moayad and Mohammed Mohsen Zayed,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy.", "Joanne Wheatley"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6015625}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4389", "mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-1639", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-14953", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-11708", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868"], "SR": 0.5625, "CSR": 0.49537037037037035, "EFR": 1.0, "Overall": 0.6938396990740741}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "Tasmanian", "georgia", "The Generation Game", "The Firm", "redhead", "12", "Spanish", "georgia", "Olivia Smith", "sows", "eucharist", "Greek", "Anastasia Dobromyslova", "half-way", "the Matterhorn", "Lake Placid", "$50", "Liverpool", "Count Basie", "Manhattan", "stone arch", "Esmeralda's Barn night", "Ajman", "the Duleep Trophy", "Mallard", "Harnoncourt", "Apollo", "1963", "Bologna", "bear", "Belfast", "Rebbie", "Lois", "Addis Ababa", "motorcycle", "kidney", "hangover", "chile", "Mark Twain", "Doctor Who", "Yosemite National Park", "Microsoft", "40", "the Somme", "passion fruit", "Sunk", "7", "Southampton", "100 years", "Benedict XVI", "Jesse Triplett", "Camping World Stadium in Orlando", "LED illuminated display", "41st", "Mel Blanc", "Mauthausen-Gusen", "the recent theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg, a spokesman for the Kunsthaus, said.", "an antihistamine and an epinephrine auto-injector for emergencies,", "the Cowardly Lion", "Danny Elfman", "Bolivia", "a leap year", "Sam Elliott"], "metric_results": {"EM": 0.46875, "QA-F1": 0.4982142857142857}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-3910", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-4361", "mrqa_triviaqa-validation-2707", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-1114", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-5322", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-4465", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-14665"], "SR": 0.46875, "CSR": 0.495045731707317, "EFR": 0.9705882352941176, "Overall": 0.6878924184002869}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "GZA", "Virginia", "1,691", "Melville, NY", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "Regional Rural Bank", "Tufts University", "Hammer", "birthplace of Sir Christopher Wren", "Isla de Agostini National Park, Isla Grande de Tierra del Fuego", "Sir William Bruce", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Whoopi Goldberg", "5.3 million", "six", "a polypeptide chain", "Brady John Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Adelaide", "Riyad Mahrez", "mainstream", "Pittsburgh Steelers", "pronghorn", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "Durban International Convention Centre (ICC Arena)", "Kentucky Music Hall of Fame", "President", "50th anniversary All-Time Team or NBA's Top 50", "American", "the Corps of Discovery, with William Clark", "pubs, bars and restaurants", "Andrew Johnson", "Canadian province of Ontario", "over 80% of the vote", "illnesses", "Thomas Joseph \"T. J. Lavin", "the bank's own funds and signed by a cashier", "16 December 1908", "President Lyndon Johnson", "Celsius", "pertussis", "Johannesburg", "the death from TV news coverage,", "Samuel Herr", "the sins of the members of the church,", "Superman", "Richard Nixon", "90", "Edward VIII"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6324156746031746}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.125, 0.0, 0.6666666666666666, 1.0, 1.0, 0.125, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-845", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4368", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-1186", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.546875, "CSR": 0.4956701807228916, "EFR": 1.0, "Overall": 0.6938996611445782}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding In Cars With Boys", "Mantle & Maris", "the Titanic disaster", "Mathematics", "Bill Clinton", "Graceland Mansion", "the Cardamom Mountains", "a dangerous speed", "David Copperfield", "Schwarzenegger", "the slithy", "w", "a goat", "\"Gump\"", "Town Nora", "Dracula", "the Atlas Mountains", "Bagpipes", "Fikkle Fame", "Day", "Italy", "a keynote", "animals", "Casey Jones", "Coward", "Hope", "the Third Reich", "Dresden", "flippant", "Bowie", "Duchamp", "The Pirate Manual", "toilet paper", "Sesame", "New Zealand", "a nocturnal mammal", "a goat", "a honey bee", "Janet Reno", "a connecticut yankee", "Gian Lorenzo Bernini", "Cologne", "Appomattox", "Thailand", "Lazarus", "cereal", "Pamela Anderson", "Stinky", "SIBERIA", "Scott McClellan", "Edd Kimber", "six", "Bradley Bell", "Twins", "John Denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two", "her abusive husband"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5828125}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-1463", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-6475", "mrqa_searchqa-validation-7801", "mrqa_searchqa-validation-15669", "mrqa_searchqa-validation-10171", "mrqa_searchqa-validation-11965", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-16440", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14643", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_triviaqa-validation-7594", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-3590"], "SR": 0.515625, "CSR": 0.49590773809523814, "EFR": 1.0, "Overall": 0.6939471726190476}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "roof", "Cuisinart", "lungs", "the Boston Massacre", "Aithur was not a boy to take jiart in such cruelties", "Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America Corporation", "Cleopatra", "Colorado Springs", "diamond", "Picasso", "AVA 22211", "John Paul II", "the hood", "Aulis", "South Dakota", "natural selection", "Department of the Interior", "Cyrus the Younger", "the White King", "Schembechler", "Gucci", "Vermont", "a chimp", "A-Z", "The Man in the Iron Mask", "the Fiji Islands", "Vladivostok", "Phil of the Future", "Kenny G", "Uruguay", "the Island of Dr. Moreau", "an organ", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the Flag of the United States of America", "herb", "a stiletto", "cheese", "the University of Kentucky", "Bora Bora", "Titanic", "1789-99", "the Fisherman\\'s ring", "RBIs", "FX", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "london", "an ocean", "Disney California Adventure", "Acharacle", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe and found his qualifications mean little as a refugee.", "Baku"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7170844780219781}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.9743589743589743, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-13797", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-2374", "mrqa_newsqa-validation-1793", "mrqa_newsqa-validation-2653", "mrqa_triviaqa-validation-5654"], "SR": 0.640625, "CSR": 0.497610294117647, "EFR": 1.0, "Overall": 0.6942876838235293}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "an Old Lady", "Opechancanough", "Anotated MST", "Acker", "Cannes", "a hangover", "endodontist", "a desktop microcomputer", "South Dakota", "Hercule Poirot", "Frasier Crane", "George Brinton McClellan", "Soundgarden", "Maximillian", "Superman Returns", "Yugoslavia", "I.M. Pei", "a razor", "a federal Congress", "Norway", "Meriwether Lewis", "St. Francis", "Steve McQueen", "a firebird", "Sweet Home Alabama", "Vietnam War", "Hercules", "John Edwards", "a charters", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "a menagerie", "Help Myself", "Boreal", "Madonna", "a turban", "Perseid", "Holstein-Friesian", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Jayne Torvill and Christopher Dean", "jagged Little Pill", "\"I think, therefore I am\"", "Bulgaria", "prophets and beloved religious leaders", "1987", "Toy Story 2", "Harriet Tubman", "Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Mildred", "in the city of San Pedro Garza Garcia in Nuevo Leon, along Mexico's border with the United States.", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.484375, "QA-F1": 0.591424851190476}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.7499999999999999, 1.0, 0.8, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-295", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-10582", "mrqa_searchqa-validation-4518", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-7163", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-9263", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-4130", "mrqa_searchqa-validation-625", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-2188", "mrqa_searchqa-validation-14158", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-5105", "mrqa_triviaqa-validation-3695", "mrqa_triviaqa-validation-1386", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.484375, "CSR": 0.49745639534883723, "EFR": 1.0, "Overall": 0.6942569040697675}, {"timecode": 86, "before_eval_results": {"predictions": ["cob", "Barbara Walters", "Turkey", "hoover", "Robert Frost", "Name", "Coffee", "Western Chorus Frogs", "Knott\\'s Berry Farm", "Narnia", "poland", "Frida Kahlo", "24", "the Russian Baroque architectural style", "the Piscis Austrinus", "Charles de Gaulle", "electrolyte", "Bernini", "Ovid", "Pablo Escobar", "Abraham Lincoln", "Anne Boleyn", "modify", "Eyelids", "bank of America", "copper", "Blackjack", "Kiss Me, Kate", "James J. Corbett", "plutonium", "Bi", "pamela", "\"Amistad\"", "a disillusioned war veteran, Capt. Rannulph Junah", "The Simpsons", "the Ladies Professional Golf Association", "Universal Studios Hollywood", "Russian", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge Family", "Kashmir", "the Great American Jaguar", "The Empire Strikes Back", "Nelson", "Billy Bob Thornton", "Clark", "Lima", "Will & Grace", "\"Dd> Robber Barons, standing for a Gilded Age of corruption, monopoly, and rampant individualism", "De Waynene Warren", "2017", "Venezuela", "Twitty", "golf", "Dialogues des Carm\u00e9lites", "England", "35,124", "between June 20 and July 20.", "the syndicate, founded by software magnate Larry Ellison, is the first American team to win yachting's most prestigious trophy since 1992.", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7160838293650793}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2666666666666667, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.1904761904761905, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-3046", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_searchqa-validation-1268", "mrqa_naturalquestions-validation-6903", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-2461"], "SR": 0.59375, "CSR": 0.49856321839080464, "EFR": 0.9615384615384616, "Overall": 0.6867859609858532}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "\"The Detainer\" (Daliah Lavi)", "Aldosterone", "late 19th and early 20th centuries", "Tom Jones", "\"Murder requests\"", "Bonnie Franklin", "Violet", "Route 37 East", "Martian Manhunter", "Easy", "First Street in downtown Dayton, Ohio, United States", "Gareth Barry", "Lucy Gichuhi (n\u00e9e Munyiri)", "\"Bambi, a Life in the Woods\"", "in 1904", "iPod Classic", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedoes", "Dante", "Glendale", "the Miami Marlins", "Netherlands", "Dallas/Fort Worth", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut", "Labrador", "Gurgaon", "1837", "Blackpool Football Club", "Diondre Cole", "Formula E", "people who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "1943", "Las Vegas", "Kim Yoon-seok and Ha Jung-woo", "1946", "1885", "2015", "Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "English", "Kairi", "1978", "- ase", "Turducken", "3000 BC", "adam devereux", "Gary Oldman", "Alanis Morissette", "Employee Free Choice act", "\"peregruzka\"", "Port-au-Prince", "the French Open", "Brazil", "Rocky & Bullwinkle", "baseball"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6427455357142857}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.2, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2294", "mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-2823", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_searchqa-validation-14393"], "SR": 0.59375, "CSR": 0.49964488636363635, "EFR": 1.0, "Overall": 0.6946946022727272}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "Apple Lisa", "S Pictures' \"Veyyil\" (2006)", "Victoria, Duchess of Kent", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide \" Addie\" Miethke", "the community southwest of the Pensacola city limits", "Consigliere", "Joseph Cotten", "14", "the Bologna Process", "Peoria, Illinois", "Indonesia", "Lorne Michaels", "Philip K. Dick", "University of Texas Longhorns football team", "\"O\" theatre", "An All-Colored Vaudeville Show", "the local midnight", "puppy", "The Vaudevillains", "Iftikhar Ali Khan Pataudi", "Robert L. Stone", "Price Chopper", "Bolton", "The chicken dance", "1,462", "Premier League", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island (Hawaiian:')", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State,", "Akshay Kumar", "2015", "diastema ( plural diastemata )", "Thames Street", "stoppard", "spain", "tried to steal his car,", "an average of 25 percent", "super-yacht designers Wally Island:", "a charcuterie", "Livin' On A Prayer", "the Electoral College (United States)", "Gunga Din"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6286458333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.4, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.4, 0.8571428571428571, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-2212", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-5078", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-3335", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-2952", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-2566", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_searchqa-validation-8904", "mrqa_triviaqa-validation-7531"], "SR": 0.484375, "CSR": 0.4994733146067416, "EFR": 1.0, "Overall": 0.6946602879213483}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "various bigfoot-like sightings", "World War II", "The United States presidential election of 2016 was the 58th quadrennial American presidential election", "The movie captured the late 1970s/early 1980s popularity of country music", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Simpsons", "First Street", "5249", "Raden Panji", "Tchaikovsky", "Ready to Die", "October 20, 2017", "Antilocapra americana", "Lord\\' Resistance Movement", "1965", "1943", "National Collegiate Athletic Association (NCAA).", "1959", "31 January 1933", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Seattle", "University of Kentucky", "The Sun", "Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "The Boeing B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four Academy Awards", "Berthold Heinrich K\u00e4mpfert", "Lismore", "EQT Plaza", "Panthera pardus", "Prudential Center", "from age ten", "Conservatorio Verdi", "north", "Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "Gildrose", "World War II", "Santayana", "The recent \"worry free\" meal event took place just days before the Food and Drug Administration's September 16 public hearing on food ingredient labels.", "an annual road trip,", "101", "salad", "hurt Tammy Wynette", "saliva", "Venus Williams"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6596816378066378}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-5509", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-330", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4717", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-5595", "mrqa_hotpotqa-validation-4489", "mrqa_hotpotqa-validation-4166", "mrqa_triviaqa-validation-6118", "mrqa_triviaqa-validation-4535", "mrqa_newsqa-validation-3736", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.578125, "CSR": 0.5003472222222223, "EFR": 1.0, "Overall": 0.6948350694444445}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "Jack Daniel", "an integument", "a motorcycle", "New Coke", "Abigail Adams", "unions", "University of Hawaii at Manoa", "the leg", "Cristina & Izzie Stevens", "The Omega Man", "Vincent van gogh", "jet streams", "Atlanta", "Alanis Morissette", "Paddington bear", "Google", "a skyscraper", "1950", "Edward R. Murrow", "Cheetah Rivera", "a good table", "seven", "Nike", "a buck", "Sweden", "Lamborghini", "an NFA trusts", "John Philip Sousa", "oros ganos", "New South Wales", "Carrie", "Nguyen the Patriot", "Martha\\'s Vineyard", "no. wore", "bread", "Transformers", "Joachim Raff", "Taiwan", "Mary Poppins", "Island Air Group", "Gustave Eiffel", "Jim Corbett", "David King\\'s Thinner", "The Firebird", "Sicily", "Bill Frist", "a dollar", "the Apocrypha Index", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "a monthly allowance,", "Aung San Suu Kyi", "75.", "quality of teaching and learning"], "metric_results": {"EM": 0.515625, "QA-F1": 0.592485119047619}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.20000000000000004]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-10254", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-14495", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-8688", "mrqa_searchqa-validation-12430", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.515625, "CSR": 0.5005151098901099, "EFR": 0.967741935483871, "Overall": 0.6884170340747962}, {"timecode": 91, "before_eval_results": {"predictions": ["the Channel Tunnel", "Hawaii", "Edwin Binney & Smith", "giant", "grease", "ice cream", "Chesapeake Bay", "the Devil\\'s Dictionary", "As I Lay Dying", "The Sound And The Fury", "the Suez Canal", "Stephen Hawking", "Ecuador", "Palatine", "the Federal Communications Commission", "acetylene", "Scrapple", "Tennessee", "Ramayana", "Seth", "Benz", "Frottage", "\"Titanic\"", "Dr. Quinn", "oblique", "Cracker Jack", "Ford", "the High Jump", "(James) Troy", "the Mugello region of the Tuscan countryside", "Alice", "Sid Vicious", "sand", "France", "sausage", "Venison", "South Africa", "a packer", "the Gifted", "the Andes Mountains", "Ovid", "1937", "Grendel", "sour cream", "ascomycota", "Dolley Madison", "Fiimore Cooper", "Lost in America", "eyes", "the sound barrier", "Cyprus", "the main section of the parade", "Nala", "Etienne de Mestre", "the PDSA Dickin Medal", "highest", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse", "Stuttgart", "The National Telecommunications and Information Administration offered a program to help people buy converter boxes that make old TVs work in the new era.", "both houses of the legislature", "Bed and breakfast"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6268795289855073}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.08695652173913042, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-1457", "mrqa_searchqa-validation-7631", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-10563", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_hotpotqa-validation-1014", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.5625, "CSR": 0.5011888586956521, "EFR": 1.0, "Overall": 0.6950033967391305}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie", "sharia", "Yente", "a malocclusion", "The first step in creating a new law", "alfalfa", "Phaedra", "Roosevelt", "Joseph Heller", "Alice Walker", "AILD", "Daniel", "(WAAAF)", "Beethoven", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "\"N\":", "The Secret", "(A perch)", "ancora", "Jesse Jackson", "William Conrad", "Jericho", "the Burning Bush", "a pteropod", "Indian tribes", "Australia", "The Thrilling Adventure", "Manet", "(The Help, Juno)", "Frdric Chopin", "a zipper", "Joan Van Ark and Donna Mills", "Amman", "Van Halen", "The Joint Committee on the Organization of Representatives", "amyotrophic lateral sclerosis", "coconut", "Nancy Lopez", "(The Magic Mountain)", "Hudson Bay", "delude", "hoo'zher", "a den", "bread", "a mead", "the Mossad", "mnagerie", "Aide-de-camp", "Judith Cynthia Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "de Goya", "(lock the *freak* up", "Panther", "paracyclist", "the XXIV Summer Universiade", "Asashoryu", "The tower", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5615699404761905}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, false, true, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.25, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-3483", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-12520", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-9804", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.5, "CSR": 0.5011760752688172, "EFR": 1.0, "Overall": 0.6950008400537634}, {"timecode": 93, "before_eval_results": {"predictions": ["Labor", "Standard Oil", "a modern oasis", "English", "Archbishop", "Clark", "India", "The Carpenters", "Wyoming", "Mary Stuart", "the Crimean War", "a parabola", "a thermostat", "Hasty", "a sapphire", "a florida", "trailers", "grace", "vehicles", "The Competition", "Blackbeard", "William of Orange", "Emily Dickinson", "a parabola", "Simon Wiesenthal", "Mercury & Venus", "Conrad Hilton", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "Halloween", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "the Canongate", "Orson Welles' real-life panic", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Ooh Betty", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO as well.", "a lump in Henry's nether regions", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7171875}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-5561", "mrqa_searchqa-validation-10246", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14358", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-10500", "mrqa_searchqa-validation-2159", "mrqa_naturalquestions-validation-8832", "mrqa_triviaqa-validation-6109", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-4022", "mrqa_hotpotqa-validation-751"], "SR": 0.671875, "CSR": 0.5029920212765957, "EFR": 1.0, "Overall": 0.695364029255319}, {"timecode": 94, "before_eval_results": {"predictions": ["assassination of the king", "fever", "the vase", "Janet Reno", "Harvard", "Don Quixote", "The Turn of the Screw", "David Lynch", "John the Baptist", "pine", "\"Wild Bill\" Hickok", "2D Focus", "uranium", "vodka", "the volcano", "the anthrax", "Jamaica", "the Sacher Torte", "(George) Allen", "a coyote", "CVS/pharmacy", "Sulfur", "the Civilessions of Nat Turner", "Jacques Marquette", "jaw", "Hannibal", "cytokinesis", "Thomas Jefferson", "a millimeter", "Megan Fox", "Alexander II", "2", "the Battle of the Little Bighorn", "Marie Curie", "Russian", "The Graduate", "Nebraska", "\"E-T\"", "vodka", "John", "LOUIS XIV", "a figurine", "a question", "Mazda", "Scout Finch", "Liechtenstein", "the Dark Knight", "Pulp Fiction", "Mao Zedong", "Neptune", "the Triassic period", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson", "Sir Giles Gilbert Scott", "Andrew Jackson", "long distance athletics", "Jeremy Hammond", "Traumnovelle", "1985", "Manuel Mejia Munera", "seven", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6004464285714285}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-10842", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-9813", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-7314", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-4661", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-11462", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.515625, "CSR": 0.503125, "EFR": 1.0, "Overall": 0.6953906249999999}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "a Genie", "a kagu", "Atonement", "a palette", "\"It\\'s Clint\"", "Cherry", "Tajikistan", "Theology", "Forrest Gump", "a piles of papers", "a hot dog", "Guy Ritchie", "Dixie", "Alfred Nobel", "Karen Blixen", "\"I've always walked by this place, but never walked in\"", "Sindbad", "the ziggurat", "the toe", "Pennsylvania", "War of the Worlds", "Hercules", "Steve Jobs", "Tommy Allsup", "a Manwich", "salinity", "Caesar", "Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "Cylon", "Rugby", "Titan", "Francis", "2 Samuel", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "1997", "a raccoon", "the Himalayan", "Barbary Coast", "a menagerie", "Bill Belichick", "a permanent, fast - drying painting medium consisting of colored pigments mixed with a water - soluble binder medium", "Reverend J. Long", "bridge", "mauritania", "\"special sauce\u201d (a variant of Thousand Island dressing)", "BBC and Cavalcade", "FIFA Women's World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "its fast burgers and fries will be available under the inverted glass pyramid of the Louvre."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6525568181818182}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.26666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365]}}, "before_error_ids": ["mrqa_searchqa-validation-14256", "mrqa_searchqa-validation-3494", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_searchqa-validation-5472", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.59375, "CSR": 0.5040690104166667, "EFR": 1.0, "Overall": 0.6955794270833333}, {"timecode": 96, "before_eval_results": {"predictions": ["the second U.S. Big Brother season to air outside the usual summer television season", "Stikkan Anderson", "a multinational chain of full service, upscale hotels catering to business travelers and to the meetings and conventions market", "Kaley Christine Cuoco", "1877", "`` Everywhere ''", "T.S. Eliot", "international relations based on sovereign states", "30 October 1918", "Florida", "Meri", "\"d `` always envisioned '' a `` talking section at the end '' on the song, but did not really know what `` to do with it ''", "Nicole Gale Anderson", "Tiffany Adams Coyne", "the last destination of Odysseus in his 10 - year journey before returning home to Ithaca", "Eddie Murphy", "2 September 1990", "Ben Savage", "Manuel Pessanha ( Pesagno )", "`` To the Colors ''", "Charles Carroll of Carrollton", "meaning `` save, rescue, savior ''", "Hudson Bay", "June 11, 2002", "Khrushchev", "Ciara Brady", "International Border ( IB )", "Ancylostoma duodenale", "the Scenic Highway between Gananoque and Brockville", "King T'Chaka of the African nation Wakanda", "the player character is recruited into the Grey Wardens, an ancient order that stands against demonic forces known as `` Darkspawn ''", "1988", "the south western escarpment of the Jos Plateau", "the Union's forces were slow in positioning themselves, allowing Confederate reinforcements time to arrive by rail", "Majandra Delfino", "August 29, 2017", "a convergent plate boundary", "ancient Mesopotamia", "the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "John Barry", "Bill Russell", "Kryptonite", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover Limited", "His son", "propofol,", "Courtney Love,", "near his Seattle home.", "a concert cantata", "East of Eden", "Andes", "1930"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5850227591036414}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.3333333333333333, 1.0, 0.0, 0.07142857142857142, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9367", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5468", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-8719", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_hotpotqa-validation-3348", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457"], "SR": 0.515625, "CSR": 0.5041881443298969, "EFR": 0.9354838709677419, "Overall": 0.6827000280595277}, {"timecode": 97, "before_eval_results": {"predictions": ["off - premises sales in one form or another on Sundays at some restricted time", "Dr. Sachchidananda Sinha", "2001 -- 2002 season", "late - 17th century New England", "Game 1", "two reservoirs in the eastern Catskill Mountains", "from the 1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear ''", "Arnold Schoenberg", "Steppe pika", "meditation", "Panzerkampfwagen VIII Maus", "An empty line", "Ian Hart", "a thirty - second call to one of a number of friends ( who provide their phone numbers in advance )", "1902", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices that began around September 4, 1929", "Fred Leighton necklace", "Human fertilization", "senators", "Lysander", "Hans Christian Andersen", "Procol Harum", "2018", "William Shakespeare's As You Like It", "James Rodr\u00edguez", "a nitrogenous base, a five - carbon sugar ( ribose or deoxyribose ), and at least one phosphate group", "Hathi Jr", "interstitial and intravascular", "1983", "Instagram", "Revelation", "the exchange of genetic material between homologous chromosomes that results in recombinant chromosomes during sexual reproduction", "Qutab Ud - Din - Aibak", "pulmonary heart disease ( cor pulmonale )", "Robert Jordan", "Michael Phelps", "Allison McMillan", "U.S. was not officially tied to the Allies by treaty", "Isa Moner", "April 29, 2009", "Laodicea", "Gibraltar", "red, white, and blue", "U.S. Fund for UNICEF", "Salt Lake City", "Schengen Area", "Arnold Palmer", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "\"The Da Vinci Code\"", "Diana Krall", "Brave New World", "a phobia", "cryogenics", "anxiety"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5904706014360745}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.6956521739130436, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.7692307692307692, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-8849", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-10182", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-564", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786", "mrqa_searchqa-validation-15118"], "SR": 0.453125, "CSR": 0.5036670918367347, "EFR": 0.8857142857142857, "Overall": 0.672641900510204}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "an American painter and writer who wrote the autobiography \"The Bite in the Apple\"", "Gene Serdena", "Rockbridge County", "Tata Consultancy Services Limited (TCS)", "Savannah, Georgia", "\"Perfect Strangers,\"", "public", "Bardstown", "survival horror video game", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp).", "alcoholic drinks for consumption on the premises", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall", "neo-Nazi", "FBI special investigator", "Bisexuality", "Adam Dawes", "1600", "Steven selling", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "1975", "Target Corporation", "Sofia the First", "writer", "Australian", "1968", "Shamrock Rovers F.C.", "Dirk Werner Nowitzki", "the highland regions of Scotland", "Kansas Jayhawks football team (variously \"Kansas\", \"KU\", or the \" Jayhawks\")", "London", "Timothy Dalton", "1924", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "`` 200 ''", "Dmitri Mendeleev", "Honda", "Utah", "Moby Dick", "two Metro transit trains that crashed the day before, killing nine,", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "\"I've never won a gift before,\"", "\"Sweet Home\"", "Great Expectations", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5996514724310777}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.14285714285714288, 0.5, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-5774", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-4863", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-4943", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-2545", "mrqa_searchqa-validation-3197"], "SR": 0.546875, "CSR": 0.5041035353535354, "EFR": 1.0, "Overall": 0.6955863320707071}, {"timecode": 99, "UKR": 0.4921875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.740234375, "KG": 0.42578125, "before_eval_results": {"predictions": ["The 2007 Trail Appliances", "The English Electric Canberra", "Alemannic", "November 13, 2007", "The Bears", "in 1987", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point Foundry", "Best Foreign Language Film", "satirical erotic romantic comedy", "The Process", "Vikram", "1949", "BAFTA TV Award", "Durham, North Carolina", "goalkeeper", "Levi Weeks", "from 140 to 219 passengers", "Esteban Ocon", "The S6 series", "Lamar Hunt", "Black Mountain College", "The Nashville Network", "People v. Turner", "in 1853", "1977", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"City of Ghosts\"", "Ludwig van Beethoven", "Morocco", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan", "Richard Arthur", "in a number of national and international media", "May 4, 2004", "3 mi", "Lord Gort", "Neighbourhoods", "Miracle", "1979", "John Alexander", "Seven", "in the pre -- Super Bowl era ( 1927 )", "last Ice Age", "North Carolina", "BBC Radio Lancashire", "Galliano", "Mark Fields", "Arlington National Cemetery's Section 60,", "Seoul", "Circumnavigate", "question mark", "in or every 10 years", "the Mollusca"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6339657738095238}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-2710", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_triviaqa-validation-6790", "mrqa_triviaqa-validation-5037", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.53125, "CSR": 0.504375, "EFR": 1.0, "Overall": 0.632515625}]}