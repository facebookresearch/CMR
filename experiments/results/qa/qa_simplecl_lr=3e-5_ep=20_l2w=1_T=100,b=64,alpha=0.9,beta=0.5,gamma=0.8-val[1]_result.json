{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8280, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "P,NP-complete, orNP-intermediate", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "Cleveland, Phoenix, Detroit and Denver", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "The Book of Discipline", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation of a drug treatment for an individual", "2014", "late 1970s", "30% less steam", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Mrs. Wolowitz", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8184937280399117}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.78125, "CSR": 0.7734375, "EFR": 0.9285714285714286, "Overall": 0.8510044642857143}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "accelerate to six times its normal speed", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "Jacob Leisler", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "1898", "Lunar Module Pilot", "citizenship", "immediately north of Canaveral at Merritt Island", "Chartered", "severed all relations with his family to hide the fact that he dropped out of school", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Alaska", "120 m ( 390 ft )", "The eighth and final season of the fantasy drama television series", "100 members", "photoelectric", "Welch, West Virginia", "Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "six points", "Merrimac", "Spain"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7795178129162504}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 0.375, 1.0, 0.4, 0.888888888888889, 0.3636363636363636, 1.0, 0.4, 1.0, 0.1875, 0.38095238095238093, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-3319", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-3840", "mrqa_squad-validation-1146", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_searchqa-validation-3996"], "SR": 0.6875, "CSR": 0.7447916666666667, "EFR": 0.9, "Overall": 0.8223958333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "his extensive spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "town of the Ubii", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown San Bernardino", "Capital Cities Communications", "the lamprey and hagfish", "physicians and other healthcare professionals", "the Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "September 1973", "the One Ring", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7492850899100899}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6798", "mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-384", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.640625, "CSR": 0.71875, "EFR": 1.0, "Overall": 0.859375}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Bruno Mars", "the Yuan dynasty", "same-gender marriages", "red algae red", "after their second year", "1960s", "narcotic drugs were controlled in all member states", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15 Saturn V rockets", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "remaining in jail, or by evading it", "the kettle and the Cricket, at one and the same", "Manilal", "Vlad III the Impaler", "The Little Foxes", "Betamax", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4, 2/3 or 3/4", "Danny Lee", "Arizona Territorial Capital", "Marshal Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "John F. Kennedy", "Light Amplification by Stimulated Emission by radiation", "Jean Dapra", "Juno", "Orchids and other rare plants are potted in peat moss to keep them from", "why", "Daya", "fear of riding in a car", "American", "Enrique Torres"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6206694347319348}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 0.13333333333333333, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.546875, "CSR": 0.684375, "EFR": 1.0, "Overall": 0.8421875}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles", "member state size", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million people", "the Lippe", "Video On Demand content", "mathematical models of computation", "semester calendar", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "the League of the Three Emperors", "science", "143,007", "Bill Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "(1980-1987)", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "(Hansi", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7993047862755525}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5161290322580645, 0.6666666666666666, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.75, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-4517", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-9753", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.703125, "CSR": 0.6875, "EFR": 1.0, "Overall": 0.84375}, {"timecode": 6, "before_eval_results": {"predictions": ["the 1540s", "the courts of member states", "its circle logo", "three", "a negative long-term impact", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "to overthrow a government", "entertainment", "A vote clerk", "high growth rates", "destructive", "Sony", "Stagecoach", "the Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural", "vice-chairman of the board", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "She has co-written twenty of Swift's officially-released songs and singles, including \"White Horse,\" \"Teardrops on My Guitar,\" and \"You Belong with Me", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "the Jasenovac concentration camp", "Rabat", "aged between 11 or 13 and 18", "Heather Elizabeth Langenkamp", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport", "It is based in Bury St Edmunds, Suffolk, England", "The WB supernatural drama series \"Charmed\"", "Cleopatra \" Cleo\" Demetriou", "Liverpool and England international player", "the Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "the Ashanti Region", "79", "Algeria", "a novel", "Biafra", "Polar Cub", "the first section of the Atlantic City Boardwalk"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7286081259426846}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.8, 0.6666666666666666, 1.0, 0.0, 0.5, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-5213", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.578125, "CSR": 0.671875, "EFR": 1.0, "Overall": 0.8359375}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "solution", "those who already hold wealth", "center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "papacy", "through homologous recombination", "a modern canalized section", "in protest against the occupation of Prussia by Napoleon", "improved", "nearly visible", "computer programs", "General Conference", "1996", "dreams", "The Judiciary", "deterministic", "Bart Starr", "allotrope", "Karluk Kara-Khanid", "Perth", "Ian Rush", "Gerry Adams", "New Orleans Saints", "1974", "four", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "Hanoi", "Two Pi\u00f1a Coladas", "fennec", "Bart Conner", "fantasy", "Martin McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "Father of Liberalism", "Garth Jennings", "Pablo Escobar", "African", "Teotihuacan", "Sleeping Beauty", "2005", "1985", "Big Ears", "Ali Bongo", "Honey Nut Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.625, "QA-F1": 0.70625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-716", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-1898", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-3510", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-1042", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.625, "CSR": 0.666015625, "EFR": 1.0, "Overall": 0.8330078125}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "fire", "the history of arms", "two independent mechanisms", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Central Asian Muslims", "Audio versions of all of the lost episodes exist from home viewers who made tape recordings of the show", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet-powered", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham, Greater London, England", "A55", "Ranulf de Gernon", "\u00c6thelstan", "Special economic zone", "44", "Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Shirley Horn", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7783752705627704}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.4, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.8, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3405", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170"], "SR": 0.703125, "CSR": 0.6701388888888888, "EFR": 1.0, "Overall": 0.8350694444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "its unpaired electrons", "French", "Museum of the Moving Image in London", "sent missionaries", "pyrenoid and thylakoids", "Woodward Park", "civil rebellion", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "a pivotal event", "youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure.", "a right-back for Premier League club Liverpool", "David Michael Bautista Jr.", "Black Friday", "American actor", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia, the Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "over 2500 ft", "Central Park", "Robert John Day", "Afroasiatic", "James Tinling", "Italy", "the PGA Tour", "Kristoffer Rygg", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "a North African dish of small steamed balls of semolina", "1.5 million", "morphine sulfate oral solution 20 mg/ml", "akus", "a species of freshwater airbreathing catfish"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6728075357003844}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.6640625, "EFR": 1.0, "Overall": 0.83203125}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "early vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "tight end Owen Daniels", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "impaired cell-mediated immunity, complement activity, phagocyte function, IgA antibody concentrations, and cytokine production", "counterflow", "John B. Goodenough", "rose to higher political office", "machine gun", "Cybermen", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "gauge bosons", "Tolui", "Rhine-Ruhr region", "lesson plan", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "the RATE project", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Massachusetts", "Ector County", "Jim Davis", "Buck Owens and the Buckaroos", "World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the cat", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets", "the city"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6693588811866429}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6495", "mrqa_squad-validation-6927", "mrqa_squad-validation-9815", "mrqa_squad-validation-1166", "mrqa_squad-validation-10309", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_hotpotqa-validation-5743", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.578125, "CSR": 0.65625, "EFR": 0.9629629629629629, "Overall": 0.8096064814814814}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "The climate is cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "a whole industry", "planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "on the Ohio River near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "he still is involved with the talks, and that the power-sharing deal with the MDC offshoot is part of larger deal that has not been signed by anyone", "there's no evidence as to the cause of death", "200", "pizza", "the U. S. Assistant Secretary of State for African Affairs", "Missouri", "he to step down as majority leader", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "the Employee Free Choice act", "Bush", "killed at least 63 people and wounded more than 200", "This is not a project for commercial gain", "the best-of-three series", "Kaka", "his Japanese ex-wife", "Dan Parris, 25, and Rob Lehr", "her apartment near Fort Bragg in North Carolina", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "Winehouse", "Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 )", "The truth was, that as she now stood excited, wild, and honest as the day, her alluring beauty bore out so fully the epithets he had bestowed upon it", "Richmondshire Museum", "1994", "The Conjuring", "The Gallipoli Campaign", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6361895377520377}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.4444444444444445, 0.5, 0.4, 1.0, 0.0, 0.16216216216216217, 0.4, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 0.5, 0.7692307692307693, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-6588", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.46875, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "every good work designed to attract God's favor is a sin.", "Napoleon", "new technology and machinery", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation,", "1227", "lower lake", "three", "Elders", "587,000 square kilometres", "Private Bill Committees", "Bruno Mars,", "the Catechism", "Stagg Field", "Ian Botham", "E. T. A. Hoffmann", "Vincent Motorcycle Company", "Al Shean", "Salvador Allende", "Harold Pinter", "Hawaii", "Erik Thorvaldson", "Marsyas", "Pal Joey", "Mary Seacole", "green", "Indonesia", "supreme religious leader", "Antonio Stradivari", "European Atomic Energy Community", "Christine Keeler", "Jesus", "Jack Nicholson", "four", "Netherlands", "Sugar Baby Love", "Rosa Parks", "Sean", "Bill and Taffy Danoff", "Stage 1", "Travis", "The Show", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "an author and philosopher", "barber", "Harry Hopman", "Murrah Federal Office Building", "Evita", "a litter of pipes on the mantelpiece", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's", "hardly ever any stories about male celebrities fighting,\"", "a delegation of American Muslim and Christian leaders", "Wolf", "USC Columbia", "Kim Clijsters."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5461309523809524}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929", "mrqa_newsqa-validation-1150"], "SR": 0.484375, "CSR": 0.6286057692307692, "EFR": 0.9696969696969697, "Overall": 0.7991513694638694}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Bo'orchu", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "Medieval Latin, 9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "moles", "Democritus", "concrete", "Catherine of Aragon", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz pianist", "two", "komando Pasukan Khusus", "Carlisle", "a liquid form", "Chillicothe and Zanesville", "Lucas McCain", "Antarctica", "matt-gilding", "achromatopsia", "Charles A. Carpenter", "River Forth", "woe", "NOW Magazine", "julius", "Italy", "Canada", "typhoid fever", "Tina Turner", "action figure", "Walt Kowalski-Gran Torino", "2010", "einasto's law", "Venezuela", "antonie Allen", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Christopher James \" Chris\" Weidman", "Drillers Stadium", "one", "Virgin America", "julius Stafford", "Administrative Professionals Week", "Iran's parliament speaker", "English Premier League Fulham produced a superb performance in Switzerland on Wednesday to eliminate opponents Basel from the Europa League with a 3-2 victory."], "metric_results": {"EM": 0.515625, "QA-F1": 0.5519412878787878}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0909090909090909]}}, "before_error_ids": ["mrqa_squad-validation-6078", "mrqa_squad-validation-1002", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_newsqa-validation-2281"], "SR": 0.515625, "CSR": 0.6205357142857143, "EFR": 1.0, "Overall": 0.8102678571428572}, {"timecode": 14, "before_eval_results": {"predictions": ["an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary civil disobedience", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public", "the most cost efficient bidder", "kung fu grip", "Continent", "the femur", "Olympia", "Ukraine", "kung fu grip", "kung fu grip", "kung fu grip", "amber", "stanley laurel", "his act of evil", "galaxy", "kung fu grip", "anamosa", "andrew johnson", "The Comedy of Errors", "Camelot", "television", "knife", "eyes", "Cologne", "the Oprah Winfrey Leadership Academy for Girls", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "kung fu grip", "kung fu grip", "andrew johnson", "kung fu grip", "kung fu grip", "kung fu grip", "thant", "Darrell Waltrip", "accordion", "andrew johnson", "andrew johnson", "Augusta", "counter clockwise", "March 31, 2013", "Tucker Crowe", "kung fu grip", "December 24, 1973", "David Weissman", "kung fu grip", "the Dalai Lama", "memories of his mother", "Israel"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4822916666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7000000000000001, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.4375, "CSR": 0.6083333333333334, "EFR": 1.0, "Overall": 0.8041666666666667}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "Deabolis", "April 20", "rijn", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "the New York World", "Cuba Gooding", "Strongsville, Ohio", "(dark green)", "MasterCard", "General Motors Corporation", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "a tan or brown macule", "a casino", "Toronto Maple Leaf", "Zsa Zsa Gabor", "konstantin Stanislavski", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "a little rabbit", "guten Morgen", "the University of Siena", "a candy store", "a beer", "Manfred von Richthofen", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the hemlock", "Mike Wallace", "National Poetry Month", "The Runza Way", "a meager allowance", "Casablanca", "squadrons", "aaron bennett", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a Tin Star", "(black)", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.515625, "QA-F1": 0.61875}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-14330", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-6772", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_newsqa-validation-2036"], "SR": 0.515625, "CSR": 0.6025390625, "EFR": 1.0, "Overall": 0.80126953125}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser River", "in a Milan", "Ho", "circum", "Inuit", "Detroit", "the Blue Jays", "Abraham Lincoln", "(Ray) Bradbury", "hate crimes", "King Julien", "Nicolas Sarkozy", "Rubicon", "(Conello)", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "(Bellerophon)", "Balaam", "the Wharton School", "The Caine Mutiny", "(Robert) Robertson", "F. W. Woolworth Company", "(John) Coltrane", "Peace", "oxygen", "the Sphinx", "Jan Hus", "The USA Network's original grassroots talent search", "blue", "Eugene Onegin", "Macy's", "cotton", "Santa Claus", "(Benicio) Snchez", "a nurse", "the courts", "chromosome 21 attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "( Brad) Blauser", "his salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6286057692307693}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-858", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1759"], "SR": 0.578125, "CSR": 0.6011029411764706, "EFR": 0.9629629629629629, "Overall": 0.7820329520697167}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Tesla", "a telephone ring", "the Party of National Unity", "22 miles", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "Kei", "Puerto Rico", "The Mausoleum", "The World Through More Than One lens", "Switzerland", "SABENA", "The Old Man and the Sea", "French", "Joe Louis", "the Nemean lion", "d'Artagnan", "the Bayeux Tapestry", "Porch", "China", "Sunni", "a designated part of the text above it", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "a beer company", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "pH", "Bromley", "the Ruul", "Cartoon Network", "Caylee Anthony", "love the environment and hate using fuel", "the Afghan peace council", "nuclear", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-12814", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.71875, "CSR": 0.6076388888888888, "EFR": 1.0, "Overall": 0.8038194444444444}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "computational resource", "same-gender marriages", "2006", "the mid-18th century", "orange", "A Raisin in the Sun", "Sistine Chapel", "White Russia", "a halfback", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "the Chalk in the Paris Basin", "Genoa", "Fanchette", "Jersey Boys", "the door of the Castle Church in", "Indiana", "Seattle", "George Field Bros", "The Hampton Inn", "21", "the Civil War", "alevin", "Paul McCartney", "omega-6", "Raphael", "Bachman Turner Overdrive", "horror", "Caddy Shack", "Tokyo", "Panama", "Confession", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "bears", "a larger earthquake", "a kiss of Judas", "elephant", "Mazur", "Finland", "a covert operations", "Nevada", "May 2010", "in the majority of the markets the company has entered", "Sugarloaf Mountain", "Thailand", "gender queer", "Minister for Social Protection", "National Archives", "the estate", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5577998088867655}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.15384615384615383, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_squad-validation-1696", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.453125, "CSR": 0.5995065789473684, "EFR": 0.9714285714285714, "Overall": 0.7854675751879698}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified plants", "Earth", "more than 53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "ambiguous", "Montreal", "the results show moved to Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Bill", "1991", "electron shells", "Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Lex Luger and Rick Rude", "Toledo", "a form of business network", "a cladding of a different glass, or plastic", "Abraham Gottlob Werner", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Necator americanus", "March 1", "a Lebanese limited production supercar", "the American Civil War", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "a man called Lysander", "Jupiter", "Greek", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "an olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6537071078431372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4705882352941177, 0.0, 0.2, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.578125, "CSR": 0.5984375, "EFR": 0.9629629629629629, "Overall": 0.7807002314814815}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "his Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape of a 15-year-old girl", "illegal crossings", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "over 1,000 pounds", "Egyptian dead-end", "Mutassim", "from Texas and Oklahoma to points east", "Polo", "Joe Jackson", "Amstetten", "computer problems", "Israel", "Climatecare", "Steve Wozniak", "12-hour", "prisoners", "September", "consumer confidence", "5:20 p.m.", "North vs. South,", "India", "1964", "Lula Bell Houston", "Pakistan's combustible Swat Valley", "Friday", "1979", "the United States", "GospelToday", "Akio Toyoda", "There's no chance of it being open on time.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "children that a French charity attempted to take to France from Chad for adoption", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "winter festivals", "Whitsunday", "Aberdeen", "\"Dumb and Dumber\"", "The Tigers won the BCS National Championship Game", "Minton", "focal point", "Etruscan root autu", "season five", "Revenge of the Sith"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5761538945338287}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.4, 1.0, 0.923076923076923, 0.8571428571428571, 0.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.052631578947368425, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.3333333333333333, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-2466", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.453125, "CSR": 0.5915178571428572, "EFR": 1.0, "Overall": 0.7957589285714286}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "San Diego-Carlsbad-San Marcos", "chief electrician", "Newton", "static friction, generated between the object and the table surface", "the assassination of US President John F. Kennedy", "responsibility", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "Belfast", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad, Iran.", "Amanda Knox's aunt", "jazz", "more than $17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "Dr. Conrad Murray", "Sarah", "\"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "1981", "\"17 Again,\"", "Nigeria", "$81,8709", "Republicans", "EU naval force", "Chris Robinson", "Omar Bongo,", "a calliope concert plays", "Hyundai Steel", "skeletal dysplasia, a bone-growth disorder that causes dwarfism,", "London Heathrow's Terminal 5.", "\"It was never our intention to offend anyone,\"", "February 12", "more than 30 Latin American and Caribbean nations", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military strike", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"Mortal Kombat X\"", "Northumbrian", "\"Get thee to a nunnery\"", "a Romanian Communist leader", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto von Bismarck"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6410357004107003}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.15384615384615383, 0.5, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.5, 0.3333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2221", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.53125, "CSR": 0.5887784090909092, "EFR": 1.0, "Overall": 0.7943892045454546}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Germans", "New York and Virginia", "two", "glowed even when turned off", "five female pastors", "sustain future exploration of the moon and beyond.", "to any resources that could be found there.", "April 6, 1994", "Prague", "backbreaking labor", "a federal judge in Mississippi", "the department has been severely affected by the earthquake,", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "Monday", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Kase Ng", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "veterans and their families", "ancient rituals in Olympia", "Zimbabwe's main opposition party", "No. 1", "nine", "ash and rubble", "Friday", "'City of Silk' in Kuwait", "a Muslim with Lebanese heritage", "Tuesday", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "scientists", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Fakih", "the Isthmus of Corinth", "Nalini Negi", "2017", "Runcorn", "collarbone", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Viva Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5870454937130928}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.19999999999999998, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.46875, "CSR": 0.5835597826086957, "EFR": 1.0, "Overall": 0.7917798913043479}, {"timecode": 23, "before_eval_results": {"predictions": ["phycoerytherin", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Hyundai", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over,\"", "threatening messages", "stop Noriko Savoie from being able to travel to Japan for summer vacation.", "drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "martial arts,", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank,", "Queen Elizabeth's birthday", "seeking help from Pakistani", "Zuma", "haute, bandeau-style little numbers", "five", "Iraq", "2000", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Jobs", "$81,880", "provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "REM sleep", "nouns", "Kent", "beer and soft drinks", "five aerial victories.", "Cherokee River", "Boxerloyal,", "Apollo 13", "Florida"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6397164510528872}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.962962962962963, 0.0, 0.5, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9787234042553191, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458"], "SR": 0.5625, "CSR": 0.5826822916666667, "EFR": 1.0, "Overall": 0.7913411458333334}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Lindsey Vonn", "one of the shocks of the year on Sunday by defeating favorite Venus Williams in straight sets to win the final of the Madrid Open.", "him to step down as majority leader.", "United Nations World Food Program vessels", "alleged gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "will be at the front of the line, self-righteously driving under the speed limit on his or her way to save the world.", "1979", "one of its diplomats in northwest Pakistan", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies", "Bangladesh", "Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "\"Britain's Got Talent\"", "military personnel", "placed behind the counter.", "11", "one Iraqi soldier,", "40 former U.S. Marines or sons of Marines who lived at Camp Lejeune", "her fianc\u00e9", "racial intolerance.", "all animal products.", "Vicente Carrillo Leyva", "Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "would compromise the public broadcaster's appearance of unbiasedity.", "\" you know -- black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "military veterans", "Washington.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance\"", "Russia's role in the international community.", "\"Stagecoach\"", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Vienna", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Spyker F1", "Viscount Cranborne", "Walt Disney World", "Iceland", "wedlock", "catalytic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5822101765536413}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, true, true, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.18181818181818182, 1.0, 0.4, 0.06896551724137931, 1.0, 0.0, 1.0, 0.8, 1.0, 0.2857142857142857, 0.23529411764705882, 0.33333333333333337, 0.05555555555555555, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.7499999999999999, 0.0, 1.0, 0.12500000000000003, 0.1142857142857143, 1.0, 1.0, 1.0, 0.4, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.46875, "CSR": 0.578125, "EFR": 0.9705882352941176, "Overall": 0.7743566176470589}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "permission to build a \"strong house\" at the mouth of the Monongahela River", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "beetle", "taxonomy", "Ub Iwerks", "Westminster Abbey", "holography", "Pelias", "Joshua Radin", "Northumbria", "Harvard", "cricket", "Seymour Hersh,", "quant", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "seborrheic", "33", "dark, spicy", "Joseph Smith,", "Huntington Beach,", "palladium", "the moon", "13", "a palla", "The Virgin Spring", "Canada", "Clement Attlee", "Stockholm", "Peter Parker", "Goldie Myerson", "Salvatore Ferragamo,", "bullfight", "Sparks", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "John", "Mr. Boddy", "Marie Van Brittan Brown", "southern California", "1995", "Bourbon", "Taylor Swift", "Adam Rex", "had his personal.40-caliber Glock when police found him.", "a class to help women \"learn how to dance and feel sexy,\"", "Amy Bishop,", "calathus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.5, "QA-F1": 0.5810000763125763}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.15384615384615383, 1.0, 0.8, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.7777777777777778, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10227", "mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.5, "CSR": 0.5751201923076923, "EFR": 0.96875, "Overall": 0.7719350961538461}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\",", "third", "affordable housing", "Mao Zedong", "Verona", "Pontiac", "elephants", "chicken cooked on a charcoal powered grill, stove or hot plate", "Frank McCourt", "jules Verne", "j Judy Cassab", "margo Leadbetter", "Schengen", "A", "city of chicago", "Famous Players-Lasky Corporation", "the Beatles", "Gerald Durrell", "jzebel", "Cork", "jason", "mare", "Halifax", "Noises Off", "jason mccartney", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "st mrs chulia Lipnitskaya", "jason", "1768", "\u201cFor Gallantry;\u201d", "a little brother", "chicago", "tuscaloosa", "The Good Life", "Tahrir Square", "uranium", "c. 1595", "27", "Jack Ruby", "Jacopo tintoretto", "Eric Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "US $5 billion", "a resting heart rate over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\",", "The Frost Place Advanced Seminar", "e-mail", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5010416666666666}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-4910", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.453125, "CSR": 0.5706018518518519, "EFR": 1.0, "Overall": 0.7853009259259259}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80 percent", "70", "resigned", "Benazir Bhutto", "Iran's nuclear program.", "Indians", "former Beatles Paul McCartney and Ringo Starr", "FBI Special Agent Daniel Cain,", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Afghanistan", "Florida Everglades", "made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "young self-styled anarchists", "$4.5 million", "unwanted baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions.", "ensenada, Mexico", "Orbiting Carbon Observatory", "Switzerland", "louis armstrong", "Janet and La Toya,", "Nine out of 10 children", "hours", "combat veterans", "get better skin, burn fat and boost her energy.", "U.S. Chamber of Commerce", "burned badly on the backs of his knees and every time he moves his knee, it pulls, and if it's healing, it starts to bleed.\"", "al-Shabaab", "posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opry Mills,", "Number one", "Ferry vessels have been crowded,", "he was diagnosed with skin cancer.", "al Qaeda", "louis gaffney", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "The oceans", "slapped their fingers with bricks, snip their backs open with wire cutters, carve them up with knives or simply shoot them", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "June 22, 1942", "between 1923 and 1925", "gilda", "Nahum Tate", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "British Prime Minister Benjamin Disraeli", "a rising sun"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5994413742027}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.5, 0.0, 0.4, 0.8, 0.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.11764705882352941, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.15384615384615383, 1.0, 0.19354838709677416, 1.0, 0.0, 1.0, 0.6, 1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2051", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.453125, "CSR": 0.56640625, "EFR": 1.0, "Overall": 0.783203125}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot (7.6 m)", "manipulates symbols", "Hyundai", "Monday night", "Bailey, Colorado,", "journalists and the flight crew will be freed,", "40", "brutalized", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "South America and Africa.", "Tetris", "outside influences in next month's run-off election,", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "immediate release", "the helicopter went down in Talbiya,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers program", "\"project work\"", "\"Oprah: A Biography,\"", "80 percent of the woman's face", "London's", "to try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Bill Klein,", "gun", "38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "West Side Story", "The Fifth Amendment", "Nepal", "Merck & Co.", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6816331192564745}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false], "QA-F1": [1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.4, 1.0, 0.3333333333333333, 0.4444444444444445, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.31578947368421056, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5100", "mrqa_squad-validation-1789", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.546875, "CSR": 0.5657327586206897, "EFR": 0.9655172413793104, "Overall": 0.765625}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "high pressure, 100% oxygen", "Betty Meggers", "priests and virgins", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis", "the Kingdom of Serbia", "diffuse interstellar medium", "August 6 and 9, 1945", "Doug Diemoz", "Virginia", "Monk's Caf\u00e9", "in the central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "cleanmgr. exe", "July 4, 1776", "pick yourself up and dust yourself off and keep going '", "John Ridgely", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "October 12, 1979", "Lorazepam", "Fort Riley, Kansas", "Cadillac", "Brenda", "ranking used in combat sports, such as boxing or mixed martial arts, of who the better fighters are relative to their weight", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar nerve", "Bill Irwin", "Watson and Crick", "Gorakhpur", "Greek", "The Rashidun Caliphs", "Lake Powell", "a star", "September 6, 2019", "two senators,", "substitute good", "Marries Veronica", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh", "the United States economy first went into an economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Carthage", "George", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Russia", "White Castle"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6013087300771125}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.5555555555555556, 0.0, 0.0, 0.42857142857142855, 0.9090909090909091, 0.0, 1.0, 0.4, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.13333333333333336, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.4, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.4375, "CSR": 0.5614583333333334, "EFR": 0.9444444444444444, "Overall": 0.7529513888888889}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "the cydippid Pleurobrachia", "1953", "AT&T", "North Carolina", "a chief of the Delaware nation", "shoes.", "novem", "Rashid Akmaev,", "acetylene", "'Archer' Jokes", "fiber.", "a fox", "a Montague", "Winston Rodney", "sand", "Nanjing", "Montana", "the Holy Grail", "Roi-Soleil", "\"What a joy to breathe the balmy air of Grosvenor Square\"", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "Song of Norway", "Frida Kahlo", "returned to his father in Holland,", "\"Y\" 2 \"K\": An Eskimo", "\"Fat man, you shoot a great game of pool.\"", "Hair", "William Randolph Hearst", "a crustal rock", "ale", "Homo", "dogs", "\"When You Look Me In The Eyes\"", "Casey Jones", "The New Colossus", "a bee stung.", "(Richard) Wagner", "Princess Beatrice of York", "Braddock", "middleweight champion", "bronchodilators", "Forty", "fluorescent lights", "Red", "Le Mans", "Earl Long", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "five", "albert juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan", "in Atlanta in 1996.", "an African-American woman for the job."], "metric_results": {"EM": 0.40625, "QA-F1": 0.4666666666666667}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.5, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-4455", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-13464", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-15632", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-6657", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.40625, "CSR": 0.5564516129032258, "EFR": 1.0, "Overall": 0.7782258064516129}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the macula", "a cylinder", "a crossword clue", "Joseph Conrad", "Diners' Club", "Christian Dior", "Pittsburgh", "Juliet", "Notre Dame", "the Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a placebo-blocker", "the \"Chance\" spaces", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "Ugly Betty", "a R", "Zechariah", "New Jersey", "Lake Pepin", "Matthew Perry", "Marissa Jaret Winokur", "John Ford", "fortune", "Willy Wonka", "Ukraine", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "a gravitational force", "Isis", "a quiveir", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Dr. A.G. Ekstrand", "Duke Ellington", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Arsene Wenger", "Tuesday"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5385416666666667}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16314", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-16714", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-9799", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-114", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.453125, "CSR": 0.55322265625, "EFR": 0.9714285714285714, "Overall": 0.7623256138392858}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "Black Death", "Kenneth", "John Stuart Mill", "Emperor Norton", "CIA", "pianissimo", "Rickey Henderson", "Indira Gandhi", "The Many Colours of Carrot Roots", "John Grunsfeld", "Llados", "1976", "Matteo Pericoli", "a quark", "The King Jesus Gospel:", "Rudy Giuliani,", "the Espionage Act", "Virginia", "Sif", "Pennsylvania", "The Omega Man", "a walk-in pantry", "a barrel", "the Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Tiger Woods", "Los Angeles", "the east wind", "King Edward", "Labour", "The pen", "Mexico", "Douglas Adams", "'Ken doll' Celso Santebanes", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Lewis Carroll", "Part 2", "Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "The son of Gabon's former president", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5972168305728088}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913042, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-5449", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-5516", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-3926"], "SR": 0.546875, "CSR": 0.553030303030303, "EFR": 1.0, "Overall": 0.7765151515151515}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "(pathogens, an allograft) trigger a destructive immune response", "a pool of blood beneath his head.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"Something's wrong with this lady.\"", "Saturday", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Bago", "the station", "protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "at a Little Rock military recruiting center", "Cash for Clunkers", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship", "different women coping with breast cancer in", "a missile", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space,", "CNN", "no chance", "St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "a portrait", "the self-styled revolutionary Symbionese Liberation Army", "the violent elbowing of Marcus McGee in the face", "two tickets to Italy on Expedia.", "Colombia", "a softer violet hue after dusk, and a deep, relaxing near-black on red-eyes when it's time to sleep", "horses", "1981", "Los Angeles", "16", "Pope Benedict XVI", "South Africa", "NATO", "some free milk.", "Kgalema Motlanthe,", "the Ming dynasty", "George II", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "a family of Portuguese descent", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "Spokescandy", "\"The Star-Spangled Banner'"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6263652146464647}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7999999999999999, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6585", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.53125, "CSR": 0.5523897058823529, "EFR": 1.0, "Overall": 0.7761948529411764}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "they couldn't accept an offer from the Southeastern Pennsylvania Transportation Authority", "Washington State's decommissioned Hanford nuclear site,", "in Yemen", "concerns expressed this week about a certain carrier based in Texas.", "nearly $2 billion", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Kenya", "the children of street cleaners and firefighters.", "Joan Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduras", "Brazil", "environmental", "strife in Somalia,", "Roy", "the WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "that former U.S. soldier Steven Green exhibited clear symptoms of acute stress disorder in Iraq and that a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "a lump in Henry's nether regions", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability", "glamour and hedonism", "J. Crew.", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient,", "Robert Gates", "Israel", "in rural Tennessee.", "confirmed that Coleman, 42, was being treated there after being admitted on Wednesday.", "Seoul,", "Nicole", "that she was going to be on the Olympic medals podium.", "next week", "Adam Lambert", "Minerals Management Service Director Elizabeth Birnbaum", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Indian monks", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1972", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5849749617212853}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.125, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.17647058823529413, 0.5, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.484375, "CSR": 0.5504464285714286, "EFR": 1.0, "Overall": 0.7752232142857143}, {"timecode": 35, "before_eval_results": {"predictions": ["removed some parts which they returned to Earth.", "Border Reiver", "July 4,", "wine", "Nantucket", "Islamic leadership position", "Kentucky", "Malibu", "Sisyphus", "sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Caliban", "Purple", "the Black Sea", "the Battle of the Little Bighorn", "the Shakers", "a bellwether", "The Disciple", "chips", "Boxer", "The Spiderwick Chronicles", "Florence Harding", "Las Vegas", "Acting out the Bible", "the Rose Bowl", "Degas", "aehive", "white meat", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "President Sadat", "a sundae", "Mary Shelley", "50 million cells per litre (quart)", "Volitan Lionfish", "HIV", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Ra ther", "Lou Gehrig", "nine", "1949", "Aamir Khan", "My Gorgeous Life", "Argentinean and 255 British military personnel died.", "Raymond Thomas", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6061789772727273}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, true], "QA-F1": [0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.25, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12977", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-1965"], "SR": 0.515625, "CSR": 0.5494791666666667, "EFR": 1.0, "Overall": 0.7747395833333334}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "risk", "bullion", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "(Henry) Hudson", "a gun blast tubes", "dry ice", "Roosevelt", "Entourage", "eel", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "(John C.) Fremont", "Russia", "(People)", "Hermann Hesse", "the Taj Mittal", "(Island)", "Carmen", "Margaret Mitchell", "the baby Quasimodo", "Sultans of Swing", "Pandarus", "(secondary)", "Burt Reynolds", "the Sphinx", "(Louis) Armstrong", "Saudi Arabia", "American New Wave", "Arby\\'s", "coffee", "the Lgion", "Robert Burns", "The Incredible Hulk", "Winnipeg", "the Memphis Belle", "Burkina Faso", "1,907-mile (3,069 km)", "Attorney General", "Icelandic", "a Usanguzee", "the Interruption", "Edith Piaf", "Ivan IV", "a prologue", "birch", "an investor couple in Austin, Texas", "Jack Gleeson", "(Phil) Primas,", "animals", "Massachusetts", "City of Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.65625, "QA-F1": 0.703125}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-2683", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_triviaqa-validation-3956", "mrqa_newsqa-validation-3951"], "SR": 0.65625, "CSR": 0.5523648648648649, "EFR": 1.0, "Overall": 0.7761824324324325}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "John Y. Brown Jr.", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "1927", "Egypt's embassy", "pi", "tin", "the Mississippi River", "Clark Griswold", "w", "Marriott", "the Principality of Monaco", "Canada", "The Secret", "the gold rush", "Collagen", "China", "compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Austin", "Euclid", "Eva Peron", "Cain", "Lou Grant", "X-Men", "the Louvre", "chinook", "Prison Break", "Mercury", "Maine", "sheep's milk cheese", "Meg", "the Sonnets", "deuce", "Hans", "Peter Bogdanovich", "Billy Joel", "Pilate\\'s Dream", "Henry VIII", "the Quaternary Period", "nolo contendere", "Junior Walker", "the Czech Republic", "a tuna", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"Sausage Party\" (2016)", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again\"", "Nelson County"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6755208333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.640625, "CSR": 0.5546875, "EFR": 1.0, "Overall": 0.77734375}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Wild Bill Hickok", "Leptospirosis", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "brushes", "a canoe", "Forget Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Shirley Schmidt", "order", "Spain", "the brain", "William McMaster Murdoch", "Macbeth", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "Not Throwing the baby out with the bathwater", "a second marriage", "Livin' On A Prayer", "Sherlock Holmes", "a lollipop", "Marie Antoinette", "Ford", "Mme Sklodovska", "Roger Brooke Taney", "reuleaux", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "The Queen of Spades", "Manganese", "forests", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Marlee Matlin", "Scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "human psychological and physical needs", "one", "Fraser Island", "the Wright brothers", "sexual activity", "Sam ticker", "Sandro Bondi", "voluntary manslaughter", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6159007352941177}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.11764705882352941, 1.0, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-7477", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_hotpotqa-validation-2005", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.5625, "CSR": 0.5548878205128205, "EFR": 1.0, "Overall": 0.7774439102564102}, {"timecode": 39, "before_eval_results": {"predictions": ["South America", "Boogie Woogie Bugle Boy", "European", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the Fall of Constantinople", "gay", "Jefferson", "Ford Madox Ford", "the Magdalena", "a Q-tip", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking", "Warren Harding", "engrave", "Shue", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "Westies, Scotties, schnauzers", "Ratatouille", "biological processes", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "a tailor", "a marathon", "Electric word life", "a root", "experience", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Danish", "Anna Murphy", "on March 15, 1945", "Charles Darwin", "Old Trafford", "Spider-Man", "Honey Irani", "a theme of global peace", "Kalahari Desert", "Alan Graham", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5555803571428571}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4408", "mrqa_searchqa-validation-459", "mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.5, "CSR": 0.553515625, "EFR": 1.0, "Overall": 0.7767578125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "horror", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "Drudge Report", "15,000 people", "Flavivirus", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "We Need a Little Christmas", "Tsavo East National Park", "the New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the Premier League", "The Gettysburg Address", "Whitney Houston", "Mbapp\u00e9", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas", "Edwin Mah Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "bronze", "2001", "Kansas City", "1999", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Golde", "Sir Tom Finney", "Cameroon", "taking blood samples from patients and correctly cataloging them for lab analysis", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "Portia", "the Mayor of Casterbridge", "Leonardo DiCaprio", "destructive ex-lover"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6871491304855275}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_naturalquestions-validation-6326"], "SR": 0.609375, "CSR": 0.5548780487804879, "EFR": 1.0, "Overall": 0.7774390243902439}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "the two dead at the scene were the female driver of the Mitsubishi and another male.", "Les Bleus", "2005", "more than 4,000", "Arlen Specter", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax", "Los Ticos", "acute stress", "Russia and China", "Facebook and Google,", "Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "Pakistan", "for these last 23 years.", "a head injury.", "Uzbekistan", "an open window", "Leo Frank", "Paul McCartney", "Washington", "Zimbabwe Electoral Commission", "don't have to visit laundromats", "one", "United Kingdom Dance Championships.", "on-loan David Beckham claimed his first goal in Italian football.", "\"He is more American than German.\"", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Authorities in Fayetteville, North Carolina,", "The crash destroyed four homes and killed two people who lived in at least one of the homes,", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "radius R of the turntable", "the right side of the heart", "54 Mbit / s", "Shadow Leader of the House", "a B-24 Liberator", "crunchy", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "FMCSA"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6819716722739821}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.625, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.5625, "CSR": 0.5550595238095238, "EFR": 1.0, "Overall": 0.7775297619047619}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona", "Zimbabwe", "Italian Serie A title", "Darrel Mohler", "her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "President Robert Mugabe", "42", "crafts poems telling of the pain and suffering of children", "some great travel spots to be altered or ruined by global climate change.", "80 percent", "1979", "Adam Sandler, Bill Murray, Chevy Chase and Will Smith", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "\"underwear bomber\" Umar Farouk AbdulMutallab", "Myanmar", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Bienvenido Latag of the Philippine National Police.", "poems telling of the pain and suffering of children", "the program was made with the parents' full consent.", "(the Democratic VP candidate delivers a big speech next Wednesday)", "The Red Cross, UNHCR and UNICEF", "Russian", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "at least 17", "a Daytime Emmy Lifetime Achievement Award.", "state senators", "31 meters (102 feet)", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl", "in shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "its nuclear ambitions are for peaceful means,", "1940's", "March 22,", "three different videos", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist.\"", "a major fall in stock prices", "John Adams and Benjamin Franklin", "Alexander Salkind", "Orion", "brown", "Selfie", "23 March 1991", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "the Pyrenees"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6615575396825397}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.8, 0.5, 0.8571428571428571, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 0.4, 0.4, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-5989", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.53125, "CSR": 0.5545058139534884, "EFR": 1.0, "Overall": 0.7772529069767442}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "that the assassination program, not the 2007 increase in U.S. forces in the war zone known as \"the surge,\" is primarily responsible for the reduction of violence in Iraq.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "nearly $2 billion", "The National Infrastructure Program,", "1941", "The Arkansas weatherman", "Krishna Rajaram,", "a hot tub alongside a man's lifeless, naked body", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Afghanistan's Helmand province,", "Saturday.", "$1.5 million", "government efforts at control and censorship remain rife across the Middle East and North Africa,", "could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Dangjin", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "Rima Fakih", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama,", "helicopters and unmanned aerial vehicles", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "Most of those who managed to survive the incident hid in a boiler room and storage closets", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960", "Aston Villa", "small-holder farmer", "snooker", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "The Wizard of Oz", "a frontal lobe"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6316556505355259}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7272727272727273, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.35294117647058826, 0.08695652173913043, 0.923076923076923, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.515625, "CSR": 0.5536221590909092, "EFR": 1.0, "Overall": 0.7768110795454546}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Duval County, Florida", "Pasek and Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire", "Operation Watchtower", "Dan Crow", "\"War & Peace\"", "Amberley", "the early 19th century", "Berea College", "the Chicago Bears", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "nationality law", "Radcliffe College", "James A. Garfield", "Ford", "If the citizen's heart was heavier than a feather", "India", "Lutheranism", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men: God Loves, Man Kills", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "\"the most influential private citizen in the America of his day\"", "I'm Shipping Up to Boston", "American", "Scottish singer and \"Britain's Got Talent\"", "China", "largest urban area", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "in a hotel,", "Chaucer", "rattlesnake", "suspicion", "healthy"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6368686868686868}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.546875, "CSR": 0.5534722222222221, "EFR": 1.0, "Overall": 0.7767361111111111}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "Indian Ocean", "three", "crocodile eggs", "A Colorado prosecutor", "Polis", "the second she got back from Mexico,", "on the family's blog", "in July", "sniff out cell phones.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "police", "Sen. Joe", "a crocodile", "a bronze medal", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers.", "Obama's", "King Birendra,", "the cause of the child's death will be listed as homicide by undetermined means,", "Casey Anthony,", "officers at a Texas  airport", "Arnoldo Rueda Medina,", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers,", "since 2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Donald Trump and Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "Latin liberalia studia", "Enid Blyton", "Johnny Mathis", "The son of a Brooklyn policeman who died when he was eight,", "Champion Jockey", "Luca Guadagnino", "Ms. Jackson", "the caged bird", "how timing shapes and supports brain function", "1-1/2 fl.", "unarmed"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6188883667502089}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.6666666666666666, 0.7499999999999999, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1582", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.484375, "CSR": 0.5519701086956521, "EFR": 1.0, "Overall": 0.775985054347826}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\"He's the most uniquely giving, loving, happy man,\"", "without bail", "12.3 million", "Mexico", "United", "Vivek Wadhwa,", "Brett Cummins,", "Indian army", "Saturday", "Nicole", "the legitimacy of that race.", "\"Football is our heart and our soul,\"", "Natalie Wood's", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards and identity theft", "on June 6, 1944,", "Middle East and North Africa,", "2-1", "October 19,", "\"It was a wrong thing to say,", "in Seoul,", "fuel economy and safety", "ALS6", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback forest-", "the children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "the helicopter went down in Talbiya,", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38", "Her husband and attorney, James Whitehouse,", "blacks, Hispanics and whites", "three", "most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "fox hunting", "New York", "travel diary", "16,116", "\"Cry-Baby\"", "sap", "bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.625, "QA-F1": 0.7044353268998299}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.8571428571428571, 1.0, 1.0, 1.0, 0.9090909090909091, 0.6666666666666666, 0.11764705882352941, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3968", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-2502", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.625, "CSR": 0.5535239361702128, "EFR": 1.0, "Overall": 0.7767619680851063}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Dennis H. Kux", "drawing the name out of a hat", "Billy Currington", "I-League", "two or three", "Jack Richardson", "Lady Frederick Windsor", "point-coloration pattern", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930s and 1940s", "5,112", "1979", "artists' lofts and art galleries,", "14,673", "6'5\" and 190 pounds", "Mickey Gilley", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport", "the Salzburg Festival", "McComb, Mississippi", "India", "1959", "Imelda Marcos", "Randall Boggs", "the Passion", "Bunker Hill", "lion", "Royal", "World War II", "Knoxville, Tennessee", "Three's Company", "P.O.S,", "Labour Party", "Linda McCartney's Life in Photography", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham,", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "cloaks", "the Treasury"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6652033730158731}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.4, 1.0, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-2757", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-3238", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5533854166666667, "EFR": 1.0, "Overall": 0.7766927083333334}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "sushi", "the line of scrimmage", "Vulcan", "Citation", "Fawn Hall", "waive", "Citation", "Barnum & Bailey Circus", "Johnny Weissmuller", "cathode", "a torque screw", "gold", "Marlon Brando", "Citation", "Renoir, Degas", "University of Kentucky", "reddish", "Brussels", "Macbeth", "General Lee", "$18.2 billion", "Fyodor Dostoevsky", "Martin Luther", "Clue", "London", "Norway", "Andrew Johnson", "15:1", "Mike Connors", "Citation Jim", "Jim Inhofe", "sancire", "Corpus Christi", "South Africa", "ostrich", "a preamble", "a night shift", "keller", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "Citation", "a bat", "West Virginia", "Thomas Jefferson", "movie house", "SeaWorld", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidextrous", "chariot", "Humberside Airport", "more than 265 million", "100 million", "financing to help poor families buy more energy-efficient electrical appliances.", "a head injury.", "Pope Benedict XVI", "Charles II"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5463541666666667}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-6362", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.484375, "CSR": 0.5519770408163265, "EFR": 0.9696969696969697, "Overall": 0.7608370052566481}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "Pamela Anderson", "carioca", "Treasure Island", "Pocahontas", "improvisation", "(Robert) Kennedy", "an", "an aerosol for cleaning ovens", "Great American Novel", "Matthew Broderick", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "the Percheron", "Ernest Lawrence", "a rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse", "Henry VIII", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "the small intestine", "the mouthpiece", "Cuba", "the Fellowship of the Ring", "Olivia Newton-John", "scalpels", "Manhattan", "February 2", "Leontyne Price", "manure", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Carrie Bradshaw", "the brain", "Sweden", "a hooded robe", "Philadelphia", "peanut butter", "Edgar Allan Poe", "rubber", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "\"Powelldenbeath", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "a man walked through an exit on the public side to the secure \"sterile\" side for passengers who had cleared screening,", "three", "poems", "Nebo Zovyot"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5916666666666666}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.13333333333333333, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-11420", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-8984", "mrqa_searchqa-validation-13674", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.515625, "CSR": 0.55125, "EFR": 1.0, "Overall": 0.775625}, {"timecode": 50, "UKR": 0.732421875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.828125, "KG": 0.5015625, "before_eval_results": {"predictions": ["Fatih Ozmen", "a facelifted 850 saloon", "Skyscraper", "Cadillac Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Robert Downey, Jr.", "J\u00fcrgen M. Geissinger", "band director", "Germanic", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "president", "19th-century", "Lady Antebellum", "Jeremy Hammond (born January 8, 1985)", "43rd President of the United States", "Tottenham Hotspur", "14 April 1958", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "political commentator", "Adelaide Lightning", "Landing Barge", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "on the Po di Volano,", "agricultural Experiment Station", "Indooroopilly Shopping Centre", "2006", "Matt Flynn", "American", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "the Senate", "February 16, 2018", "1980", "Nacio Herb Brown", "Geoff Hurst", "mya", "Mull", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "a tracheotomy at a children's hospital in St. Louis, Missouri.", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5645833333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.888888888888889, 0.0, 0.0, 0.0, 0.4, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-13015"], "SR": 0.46875, "CSR": 0.5496323529411764, "EFR": 1.0, "Overall": 0.7223483455882354}, {"timecode": 51, "before_eval_results": {"predictions": ["1898", "a Native American", "What You Will", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Kekaihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui", "Gothic Revival mansion", "Rochester", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237", "11,163", "an album", "its air-cushioned sole", "White Knights of the Ku Klux Klan", "WikiLeaks", "Three-card brag", "Montana State University", "Tool", "the Wikimedia Foundation", "Flashback", "ARY Group", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "February 21, 1961", "Rochdale, North West England", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward position", "2012", "United States", "Dame Eunice Mary Kennedy Shriver,", "35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "Brittas Bay", "a string of obscure words", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29 and November 5.", "Joseph Holt", "hunter sauce", "The Tolkien's", "carbon"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6574850063131313}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-5442", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-5493", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-1452", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.578125, "CSR": 0.5501802884615384, "EFR": 1.0, "Overall": 0.7224579326923076}, {"timecode": 52, "before_eval_results": {"predictions": ["My ntonia", "King Henry VIII", "lead", "the Rose Bowl", "a VC-25", "amber", "Denmark", "mixed-breeds and spayed or neutered purebreds", "Katrina & the Waves", "Nazareth", "freestyle", "celtic", "spores", "Stargate", "Lou Reed", "Stonewall Jackson", "Fennoscandia", "Emma Peel", "canvas", "potted plants", "The X-Files", "Frankie Muniz", "a giant cetacean", "Hudson Bay", "January 4, 1809", "kinetic", "Santera", "Starsky and Hutch", "a torch", "quicksand", "The Return of the Native", "Welcome, You've got mail, File's done, and Goodbye", "Pop-Tarts", "Minnesota", "the San Antonio River", "a cornucopia", "Bob Fosse", "Ankara", "condensation", "eight", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Like Water for Chocolate", "Niger-Congo", "TGI Fridays", "John Tyler", "Daniel Craig", "humility", "computer programming", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "when mixing solvents or changing their temperature", "Doctor Zhivago", "Bristol", "(Johnston) Dickinson", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "along the equator between South America and Africa.", "way American men and women dress but also on the way they imagine, sexy and international.", "fake his own death", "the Stockton & Darlington Railway"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6019345238095237}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, false, false, false, false], "QA-F1": [0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.625, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8750000000000001, 0.0, 0.5, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-6128", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-2686", "mrqa_triviaqa-validation-5426"], "SR": 0.53125, "CSR": 0.5498231132075472, "EFR": 1.0, "Overall": 0.7223864976415094}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "to manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "roofing material", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "In his first appearance, he flirts with Meredith Grey", "DNA", "global crowdfunding platform focused on creativity and merchandising", "Most days are sunny throughout the year", "David Motl", "The Portuguese", "Madison", "December 19, 1971", "2017", "Gustav Bauer", "the settlement of the sedimentation", "the motion of the continents", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "dromedary", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "Coriolis force", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "over 74", "warning signs", "various submucosal membrane sites of the body", "noble gas", "Immigration and Naturalization Service", "four distinct levels", "Janie Crawford", "Pepsi", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Paul Gauguin", "Islamophobia", "creeks, fringing the southwest mouth of Lagos Lagoon,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds).", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "The Palm Jumeirah", "the Inuit", "Uncle Vanya", "his clothes", "the death of a pregnant soldier"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5123454012462633}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.7692307692307692, 0.8, 0.08333333333333334, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.41379310344827586, 1.0, 0.2, 0.5, 1.0, 0.0, 0.5, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4748", "mrqa_hotpotqa-validation-3974", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5130", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.390625, "CSR": 0.546875, "EFR": 0.9487179487179487, "Overall": 0.7115404647435898}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "Texas - style chili con carne, nachos, hard tacos and fajitas", "George Harrison", "Kanawha Rivers", "1803", "the heads of federal executive departments who form the Cabinet of the United States", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Mountie Thomas Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "the Titanic never sank", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the federal government", "Malvolio", "Coldplay", "Arkansas", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Isaac Morris", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "John F. Kelly", "cylinder of glass or plastic that runs along the fiber's length", "no embryo", "741 weeks from 1973 to 1988", "Zimbabwe", "London", "Sarah Palin", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "the ship of violating Chinese and international laws during its patrols,", "beautiful childhood", "Tater Tots", "Yemen", "quod erat demonstrandum", "the Dalton Gang"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6025566988158899}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.56, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8, 0.058823529411764705, 0.4, 0.5714285714285715, 1.0, 1.0, 0.2857142857142857, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-9091", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-6092", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.46875, "CSR": 0.5454545454545454, "EFR": 0.9117647058823529, "Overall": 0.7038657252673797}, {"timecode": 55, "before_eval_results": {"predictions": ["wealthy businessman James Cotterell ( Ed Begley )", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "Celtic", "the Columbia River Gorge", "the Northeast Monsoon", "2005", "American country music group The Nitty Gritty Dirt Band", "the biosphere ( living and organic material ), such as forests and animals", "annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "`` Product / market fit", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose", "Ernest Rutherford", "depolarization of the cardiac muscle begins at the sinus node", "a strong, weight transferral synovial plane joint with irregular elevations and depressions that produce interlocking of the two bones", "png HTTP / 1.1", "the Brewster family", "1 mile ( 1.6 km ) in width in several places", "pop ballad", "8 December 1985", "during meiosis", "2005", "Arnold Schoenberg", "an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group family of brands", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "dead stratified squamous, keratinized", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Ben Rosenbaum", "Ferrari", "Alamodome in San Antonio, Texas", "Meg Optimus", "biological taxonomy", "is the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Tevin Campbell", "My Big Fat Gypsy Wedding", "Joseph V. Micallef", "\"The RockfordFiles.\"", "Oxford, UK", "Robert Jenrick", "Robert Matthew Hurley", "urging more help for military members, especially for those returning from war.", "five", "\"The Closer.\"", "St. Henry", "Madonna", "the Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5132350820795686}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.14285714285714288, 0.10526315789473684, 0.0, 0.0, 0.6153846153846153, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.7096774193548387, 0.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.1290322580645161, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.09090909090909091, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-5371", "mrqa_newsqa-validation-1887", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.421875, "CSR": 0.5432477678571428, "EFR": 0.972972972972973, "Overall": 0.7156660231660232}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "Harishchandra", "16", "1877", "1999", "Manchester United Football Club", "Tami Lynn", "U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "John Findley Wallace", "Nepal", "Aernoutsz", "4 September 1936", "heat", "1940", "Authority", "April 1st", "DJ Lance Rock", "24 hours later", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Lorenzo Lamas", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "septum", "Buddhism", "foreign exchange market", "`` Despacito '' by Luis Fonsi", "Sir Ernest Rutherford", "Nigel Lythgoe", "December 2, 2013", "gastrocnemius", "Al Pacino", "Thomas Hobbes in his Leviathan", "March 26, 1973", "1986", "on location", "President Lyndon Johnson", "week 4 of development", "rabanada", "1840", "2007", "Branson, Missouri", "first baseman", "Tumi Holdings", "River Shiel", "brewer", "Polo because \"it was the sport of kings.", "The iconic Abbey Road music studios made famous by the Beatles are not for sale,", "ego", "Nova Scotia", "Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6917162698412698}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.19047619047619047, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-2280", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-4571", "mrqa_triviaqa-validation-7674", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096"], "SR": 0.609375, "CSR": 0.544407894736842, "EFR": 0.96, "Overall": 0.7133034539473684}, {"timecode": 57, "before_eval_results": {"predictions": ["the Old French tailleur ( `` cutter '' )", "Massachusetts", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "acquire an advantage without deviating from basic strategy", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 )", "the coffee shop Monk's", "Fats Waller", "the January 2017 patch", "Ozzie Smith", "Mark Jackson", "2017", "Resident Commissioner", "January 2018", "in soils", "September 30", "pigs", "President Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "the nucleus", "1973", "Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "a key signature at the beginning to designate the pitches that make up that scale", "a thirty - second call to one of a number of friends ( who provide their phone numbers in advance )", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root ``k `` king ''", "P.V. Sindhu", "Carpenter", "Shinsuke Nakamura", "Wilt Chamberlain", "Scorpions", "Uzbekistan", "UNESCO / ILO Recommendation concerning the Status of Teachers", "issued upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "during prenatal development", "skeletal muscle and the brain", "Don Cook", "Ireland", "Felicity Huffman", "In 1908", "Sir Henry Cole", "Long Island", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Trevor Herbert Stanford", "the liver", "Heineken International", "Irish Chekhov", "Charlie Wilson", "Jenny Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5769010857801619}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.7499999999999999, 0.14285714285714288, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6956521739130436, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.8888888888888888, 0.0, 0.9600000000000001, 1.0, 0.8, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.3, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-9842", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-2713", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_triviaqa-validation-7305", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.4375, "CSR": 0.5425646551724138, "EFR": 0.9166666666666666, "Overall": 0.7042681393678161}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "mid-size four - wheel drive", "1986", "Idaho", "July 18, 2013", "Exodus", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "England and Wales", "iron", "the Reverse - Flash", "Los Angeles, California", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "biscuit - sized cake", "compartments known as Relieving Chambers", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "first appeared in serial format in Collier's Weekly magazine ( 27 January -- 16 April 1898 )", "on the slopes of Mt. Hood in Oregon", "Ewan McGregor", "LED illuminated display", "stuffing", "1917", "2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "the genome", "each state's DMV, which is required to drive", "Convention", "four", "divergent tectonic", "Steve Russell", "either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "began on 13 February", "291", "the early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zuzu & Zaza Zebra", "endometriosis", "1960", "Justin Trudeau,", "2006", "Walldorf", "superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\"", "pipelines and hostage-taking", "peppermint oil, and antispasmodic", "the FBI.", "a ferry", "Leland Stanford", "Mexico City", "Nepal"], "metric_results": {"EM": 0.484375, "QA-F1": 0.629053309297843}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.92, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.13333333333333333, 0.8750000000000001, 0.0, 0.2857142857142857, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5789473684210525, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.37037037037037035, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-10561", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231"], "SR": 0.484375, "CSR": 0.5415783898305084, "EFR": 0.9090909090909091, "Overall": 0.7025557347842835}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "9", "an expression of at least a moderate amount of manual dexterity", "quarterback", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "American country music singer George Strait", "climate on the Earth", "Herman Hollerith", "94 by 50 feet", "other sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential, which contains the final drive to provide further speed reduction at the wheels", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson", "Long Island", "1988", "Egypt", "a castle", "Michael Crawford", "the Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 17, 1945", "the 1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century", "to carry this message to alcoholics, and to practice these principles in all our affairs", "Italian architect and art theorist Leon Battista Alberti", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "A diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Joker Wild", "Chicago", "C\u00f4te d'Or", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office,", "15-year-old", "Sunday", "Vietnam", "bass", "Richard", "(Michael Badalucco)"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7051034902597402}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.9714285714285714, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.9090909090909091, 0.07142857142857144, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-34", "mrqa_triviaqa-validation-4764", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.609375, "CSR": 0.5427083333333333, "EFR": 0.96, "Overall": 0.7129635416666666}, {"timecode": 60, "before_eval_results": {"predictions": ["people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "a writ of certiorari", "silk floss", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "coffee", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Dennis C. Stewart", "Mahatma Gandhi", "people of France to the people of the United States", "the eighth", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Clare Torry", "ummat al - Islamiyah", "Uzbekistan", "Parashara ( c. 400 -- c. 500 AD )", "Domhnall Gleeson", "Spanish botanist and physician Petrus Jacobus Stevus ( Pedro Jaime Esteve 1500 -- 1556 ), a professor of botany at the University of Valencia", "agriculture", "St. John's, Newfoundland and Labrador", "from the Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "zootomy", "displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1931", "Jericho in the Levant region", "freeview", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker (Born Andreas Cornelis van Kuyk)", "Atlantic Ocean", "mistress of the Robes", "The Division of Fawkner", "Conway ( Arkansas)", "Kurt Cobain's", "\"Empire of the Sun,\"", "BERLIOZ", "The Killing Fields", "the Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6799305258085243}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [0.48275862068965514, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6956521739130436, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_newsqa-validation-2042", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.5625, "CSR": 0.5430327868852459, "EFR": 0.8571428571428571, "Overall": 0.6924570038056206}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "shared", "Jason Marsden", "New Mexico", "In 1889", "the poem was published posthumously in 1890 in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson.", "William the Conqueror", "March 2, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Emma Watson", "legislation ( i.e., `` statutes '' or `` statutory law ''", "2018", "from 6 -- 14 July", "2010", "4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson", "Elijah Wood", "Space is the Place", "Brad Dourif", "in a counter clockwise direction around the Sun", "Joanne Wheatley", "vice president", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The Union's forces", "American country music duo Brooks & Dunn", "a toast", "South America", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7342030638012782}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8163265306122449, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.8571428571428571, 0.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4444444444444445, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-1856", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.609375, "CSR": 0.5441028225806452, "EFR": 0.88, "Overall": 0.6972424395161291}, {"timecode": 62, "before_eval_results": {"predictions": ["1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "the Roman Empire", "toys or doorbell installations", "microfilament", "in positions Arg15 - Ile16", "the northernmost point on the Earth", "Alex Drake", "Eduardo", "1868 war veterans, such as Polish internationalist General Carlos Roloff and Seraf\u00edn S\u00e1nchez in Las Villas", "1971", "Leo Arnaud ( / \u02c8le\u026a. o\u028a \u0251\u02d0r \u02c8no\u028a /", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1912", "George Harrison", "Djokovic", "James Hutton", "late 1922", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Toronto", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the final scene of the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "the colonization of the Americas began and the cocoa plant was discovered in regions of Mesoamerica", "10.5 %", "subtropical forests and mountains", "White House Executive Chef", "the International Border ( IB )", "Bart Millard", "an informal term for mother", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "indie and metal", "Farmingville", "American Seung-Hui Cho who killed 32 students and himself at Virginia Tech and American John Wayne Gacy, Jr.", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "Mali", "the Chief Oshkosh Monument", "River Welland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6161398208273208}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.3636363636363636, 1.0, 1.0, 1.0, 0.5, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7211", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.53125, "CSR": 0.5438988095238095, "EFR": 1.0, "Overall": 0.7212016369047618}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "The Hustons", "sacroiliac joint", "Identification of alternative plans / policies", "Cuernavaca, Durango, and Tepoztl\u00e1n", "electronic computers", "Employers", "Balaam ( Numbers 22 : 28 )", "Bhupendranath Dutt", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "at luncheon", "Annie Potts", "Jakkur, Bangalore, India", "in a thousand years", "2001", "the European economy had collapsed", "Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "enterprise application development market", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander", "282,846", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "ten times", "Lori Rom", "a Czech word, robota", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser", "Austin and Pflugerville", "1933", "Exodus 20 : 7", "four", "Geothermal gradient", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "from the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "Trinidadian Calypso", "Jiles Perry (JP) Richardson Jr.", "The Pentagon", "Pisgah National Forest", "Johnnie Ray", "Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5577604380913204}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8571428571428571, 1.0, 0.6153846153846153, 0.3333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.4, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.18181818181818182, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3339", "mrqa_hotpotqa-validation-4240", "mrqa_searchqa-validation-8333"], "SR": 0.40625, "CSR": 0.541748046875, "EFR": 0.9210526315789473, "Overall": 0.7049820106907895}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough, Massachusetts", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Benjamin Burwell Johnston, Jr.", "Nia Temple Sanchez", "Vanessa Anne Hudgens", "Liga MX", "Amber Heard", "Peter Seamus O'Toole", "March 8, 1942", "a recurring dream of Stipe's", "January 30, 1930", "Doctor", "the Irish Government's Health Service Executive", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "Cher", "Kew Gardens", "7 January 1936", "Towards the Sun", "The Braes o' Bowhether", "Westminster system", "I. helicon", "For Love Alone", "October 4, 1970", "King of the House of Valois", "J. Robert Oppenheimer", "Transporter 3", "March 14, 2000", "Gauteng", "Vietnam War", "Bill Walton", "Darling River", "Brian Keith Bosworth", "140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season", "Wyoming", "Wee Jimmy Krankie", "Apeirophobia", "ordered the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "black, red or white,", "intelligence official said North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Rome", "a sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.5, "QA-F1": 0.6376104797979798}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 0.3333333333333333, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.48484848484848486, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071"], "SR": 0.5, "CSR": 0.5411057692307693, "EFR": 1.0, "Overall": 0.7206430288461538}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "\"Arrested Development\"", "Albert", "September 30, 2017", "322,520", "the New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire", "Odense Boldklub", "Stephen of Blois", "Jared Leto", "Gweilo", "Christian Universalists", "PrinceAimone of Savoy-Aosta", "1936", "The Wu-Tang Clan", "For Love Alone", "B.o.B", "melodic hard rock", "G\u00e9rard Depardieu", "rural", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse University", "Kings Point, New York", "Robbie Gould", "Paddy's Pub", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "Armidale, New South Wales", "Hurricane Faith", "turns out to be a terrible date", "the Celtics", "Girl Meets World", "CHO", "eight", "from 1848 to 1852", "Sippin' on Some Syrup", "Jim Harrison", "Sir Patrick Barnewall", "Arabella Churchill", "Benny", "two Grammy awards", "The S7 series", "2017", "Iltutmish", "September 2000", "the Thirteen Colonies", "Luxembourg", "Golda Meyerson", "the Muffin Man", "President George Bush", "250,000", "former boxing champion", "Yonkers King", "blown", "the supernatural", "Dan Aykroyd"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6288432921245422}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.4, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.0, 0.4, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.5625, "CSR": 0.5414299242424243, "EFR": 1.0, "Overall": 0.7207078598484848}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Hillsborough", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "a strata", "a living architect", "Guy the Gorilla", "a cat in the infrared", "Kimbe", "green", "K-141 Kursk", "pyrotechnic", "South Korea", "Eric Conway", "a goose", "stronger with an unfair advantage", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington James Monroe Thomas Jefferson", "Ellice Islands", "Meta", "'Flower of Scotland'", "about a mile north of the village of Dunvegan", "a violin", "The Spice Girls", "Mr Loophole", "Istanbul", "drinking song", "Texas", "Erik Aunapuu", "Yalta", "Rajasthan", "African violet", "Bali", "Glee", "Baron Brudenell of Stonton", "Ratonhnhak\u00e9 : ton and Haytham Kenway", "Djokovic", "1912", "a Fennec fox", "1927", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest,", "Linda Hogan,", "in the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "Andrew Wyeth", "viruses", "Steve Wynn", "a substitute good"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5680288461538462}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.15384615384615385, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-1930", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_triviaqa-validation-3214", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-16515"], "SR": 0.515625, "CSR": 0.541044776119403, "EFR": 1.0, "Overall": 0.7206308302238805}, {"timecode": 67, "before_eval_results": {"predictions": ["$249", "Phay Siphan, secretary of the Cambodian Council of Ministers.", "Les Bleus", "tranquil beaches,", "flooding", "bremen", "Secretary of State", "Obama", "21 percent", "Former Argentina international defender Fernando Caceres", "six Africans dead", "a homicide.", "the best-of-three series", "Preah Vihear temple", "Uzbekistan", "voluntary neglig after witnesses identified him and he was interviewed by police.", "Jenny Sanford,", "Isabella, Emma, Olivia, Sophia, Ava, Emily, Madison, Abigail, Chloe and Mia", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones.", "two contestants.", "Fiona MacKeown", "the Southern Baptist Convention", "Graeme Smith", "former U.S. secretary of state.", "he didn't elaborate.", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "the two remaining crew members", "hanging a noose in a campus library,", "two tickets to Italy", "Oxbow, a town of about 238 people", "the FAA received no reports from pilots in the air of any sightings but the agency recieved \"n Numerous\" calls from people on the ground from Dallas, Texas, south to Austin, Texas.", "21-year-old", "Jacob Zuma", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call,", "Pew Research Center", "to breathe through her nose, smell, eat solid foods and drink out of a cup,", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "a central place in Christian eschatology", "Phil Mickelson", "Dumbo", "guitarists", "1969", "\"$10,000 Kelly,\"", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "(Frank) Ippolito", "Perkins", "director", "batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.5, "QA-F1": 0.5916404476763605}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.5, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.24390243902439027, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.962962962962963, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-3044", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.5, "CSR": 0.5404411764705883, "EFR": 1.0, "Overall": 0.7205101102941176}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "auto loans", "3-2", "President Barack Obama,", "the Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday in Los Angeles.", "The family of a Korean-American missionary", "after nine years.", "at least 300", "Thursday,", "hot and humid and it rains almost every day of the year.", "Israeli Navy", "the same drama that pulls in the crowds", "2008.", "root out terrorists within its borders.", "25", "Zed,", "Ciudad Juarez,", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford,", "in a remote part of northwestern Montana", "genocide", "identity theft", "Bailey, Colorado,", "John Demjanjuk", "Aravane Rezai", "noose incident occurred two weeks after Black History Month", "\"Doogie Howser, M.D.\"", "British", "Six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man", "Taron Egerton", "Italy", "Josiah Bounderby", "purpurea", "Nellie Melba", "Clark Gable", "1979", "the backside", "Sweden", "spotted hyena", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5263210747585747}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.13333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-1280", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.421875, "CSR": 0.5387228260869565, "EFR": 0.972972972972973, "Overall": 0.7147610348119859}, {"timecode": 69, "before_eval_results": {"predictions": ["line the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise", "Detective Eddie Thawne", "Hathi Jr", "a liquid crystal on silicon ( LCoS ) ( based on an L CoS chip from Himax ), field - sequential color system, LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "by October 1986", "http://www.example.com/index.HTML", "343 m / s in air", "1997", "Carol Worthington", "September 6, 2019", "1972", "1902", "rootlets ( branch roots )", "into the air", "Battle of Antietam", "Rockfish Gap", "Clarence Anglin", "Andrew Garfield", "through Bachmann's bundle", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R.", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive Chef", "place of trade", "25 years after the release of their first record", "the bank's own funds", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "eucalyptus", "inflation", "Charlie Hall", "John M. Dowd", "December 17, 1974", "Northrop P-61 Black widow", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "the thyroid", "1965"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6781550448670014}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.9523809523809523, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.5, 0.3333333333333333, 1.0, 0.918918918918919, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.3636363636363636, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809525, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937"], "SR": 0.546875, "CSR": 0.5388392857142856, "EFR": 0.896551724137931, "Overall": 0.6995000769704434}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "long line", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "the Canadian rock band Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "the investment bank Friedman Billings Ramsey", "the NFL", "the world map", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "the sudden appearance of a worldwide storm causes 98 % of the world's population to disappear, and zombie - like creatures rise to attack the remainder", "somatic cell nuclear transfer", "The UN General Assembly", "anterograde amnesia", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "September 15, 2012", "Edward Furlong", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "a `` skin - changer '', a man who could assume the form of a great black bear", "South Dakota", "John F. Kennedy", "around 100,000", "1967", "Rajasthan", "Sodor", "the eye", "44,300", "2008", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6132601209807091}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1081081081081081, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.07142857142857144, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-4442", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.546875, "CSR": 0.5389524647887324, "EFR": 0.9310344827586207, "Overall": 0.7064192645094706}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Helvellyn Lower Man", "photographer", "clown", "the Titanic", "Brundisium", "Hadrian", "Madagascar", "Barbizon school", "Renzo Piano", "Manet", "Gary Sparrow", "Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Richard Jordan", "British", "'Hansel and Gretel' cottage", "autom\u00f3viles", "Greenock", "ABBA", "sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess", "Koninklijke Vlaamse Academie van Belgi\u00eb voor Wetenschappen en Kunsten", "Stieg Larsson", "music Stories", "October 4, 1957", "a menhir", "steel", "Rotherham United", "Joseph Priestley", "Persian greyhound, gazelle hound or tazi", "Tennis", "the Periodic Table", "CameroonCameroon", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Spanish", "armio", "Patience", "Chubby Checker", "Tim Roth", "smartphones and similar devices to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dali", "par three 12th hole", "in San Francisco", "after 5 years", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "January", "We wanted to be 100 percent carbon neutral from launch so we partnered with ClimateCare, one of Europe's most experienced providers of carbon offsets,", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "the Civil War", "in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past.", "peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6245540154467584}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.07142857142857142, 0.5, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.08695652173913042, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-4322", "mrqa_triviaqa-validation-391", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-512", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-10030", "mrqa_naturalquestions-validation-8965", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-11196"], "SR": 0.5625, "CSR": 0.5392795138888888, "EFR": 1.0, "Overall": 0.7202777777777778}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby darin", "Thames", "Altamont Speedway", "spain", "26.22", "talus anklele fracture", "jellyfish", "Samson", "Connecticut", "Daedalus", "hana", "martin", "a goad", "Miles Morales", "Fourteen", "radars", "Queen Elizabeth II", "bbc", "hippocampus", "Frank Miller", "Tennis", "Orwell", "Atlantic Ocean", "New Zealand History", "Chatsworth House", "spain", "Budapest", "eyes", "husqvarna", "augusta", "August 25", "taurine", "augusta", "South America", "Southwest Airlines", "SUNSET BOULEVARD", "Johnny Colla", "Derwill Water", "sesame", "Laos", "Allardyce", "General Henri-Philippe Petain", "alison bbc", "Miami", "Bill Haley", "bolognese", "1768", "Joan Rivers", "Ethiopia", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito", "Rembrandt Harmenszoon van Rijn", "Dumbo the Flying elephant", "\" Lost colony\" of 1580s North Carolina", "pythons"], "metric_results": {"EM": 0.359375, "QA-F1": 0.43854166666666666}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.4, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4380", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7364", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.359375, "CSR": 0.5368150684931507, "EFR": 0.975609756097561, "Overall": 0.7149068399181423}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Roswell", "Helen Mirren", "racehorse breeder", "Schutzstaffel", "Eddie Albert", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "pastels", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "7", "American television personality and film actress best known as the hostess of \" Wheel of Fortune\"", "1967", "spectroscopist", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "Michael Phelps", "suburb", "schoolteacher", "People v. Turner", "Bill Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "parashiyot", "paramitas", "1881", "comets", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Jobs", "Christianity and Judaism", "blintze", "cannibal", "DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6269374958598304}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_searchqa-validation-13349", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-10465"], "SR": 0.546875, "CSR": 0.5369510135135135, "EFR": 0.9655172413793104, "Overall": 0.7129155259785647}, {"timecode": 74, "before_eval_results": {"predictions": ["the Jesuits", "ribonucleic acid", "ketchup", "an igloo", "compound eyes of flies", "Timberland", "Former Texas governor", "republic", "Latvia", "a spleen", "auf wiedersehen", "The courage to do it and be great.", "Ramses II", "wine", "the esophagus", "The Dallas Cowboys", "the Bible", "a disco group", "Marie Tussaud", "Biscay", "The Ziz", "March", "Ferdinand Magellan", "Verbal Kint", "a brothel", "an oblate spheroid", "The Aviator", "Tancredi, Otello", "Veracruz", "a tail", "Nashville", "The Hanging Gardens of Babylon", "The Last Starfighter", "Billy Crystal", "a tan", "Henry Ford", "Qubec", "pontificio", "The Drew Carey Show", "Fiji", "Moonlighting", "Corpus Christi", "a friend", "Ruth Bader Ginsburg", "Edward R. Murrow", "Colombo", "in vitro fertilisation", "Diogenes Laertius", "foods", "a chocolate milk drink", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "\"Lady Madonna\"", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "demolishing American third seed Venus Williams in the final of the Sony Ericsson Open in Miami on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.421875, "QA-F1": 0.534375}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-391", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-2220", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-976", "mrqa_naturalquestions-validation-5096", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801"], "SR": 0.421875, "CSR": 0.5354166666666667, "EFR": 1.0, "Overall": 0.7195052083333333}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "AD 1600", "1963", "king Gautamiputra Satakarni", "Central Board of Artisans", "they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "In 1975", "MFSK", "28 July 1914", "St. Pauli Girl Special Dark", "908 mbar ( hPa ; 26.81 inHg )", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "Burbank, California", "everyone on board", "American singer - songwriter - actress Debbie Gibson", "Atticus Finch's", "31 January 1934", "Camp Green Lake", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "2002 Tamil film Ramanaa", "by fermenting dietary fiber into short - chain fatty acids ( SCFAs ), such as acetic acid and butyric acid", "Kyla Coleman", "Bill Belichick", "September 1972", "Dennis Locorriere", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Motorola", "Neil Young", "Indian English", "Chuck Noland", "many forested parts of the world", "arithmetic", "Finger Tab", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw", "Hapsburg", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6881552261796269}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.7027027027027027, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9863013698630138, 0.4, 1.0, 0.6, 0.5714285714285715, 0.6, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.85, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-1646"], "SR": 0.515625, "CSR": 0.53515625, "EFR": 0.967741935483871, "Overall": 0.7130015120967742}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "sovereignty", "Authority", "Jughead Jones", "American rock band Los Lonely Boys", "ecological regions", "cakes", "Kiss", "18 September to 31 October", "Julie Adams", "One day", "Anthony Quinn", "January 2004", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "Hank J. Deutschendorf II", "Tennesseeitans", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins, and the lyrics to most of the suite's sections consist of his thoughts about her and their imminent breakup", "southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or grenadine", "2014 -- 15", "October 28, 2007", "Laura Vallejo", "an anembryonic gestation", "by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "Nativity scene", "IV", "No. 1 seed Virginia and No. 4 seed Arizona", "Saphira hatches from the stone, which was really an egg", "September 2017", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "the British group Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "the Isthmus of Corinth", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "bomber", "Apple", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million.", "San Diego", "CNN.com", "a jazz funeral", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6429912109394017}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.375, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.4444444444444445, 0.6153846153846153, 0.5, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4850", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170"], "SR": 0.5625, "CSR": 0.5355113636363636, "EFR": 0.9285714285714286, "Overall": 0.7052384334415585}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Botticello", "metal", "pulsar", "Seth", "honda", "\"Erroneous\" Number One", "Adolf Hitler", "comedies", "FIFA World Cup", "Elizabeth I", "June", "Italy", "1960s", "Mel Brooks", "parisabeth", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "rum", "apple", "arbroath", "Roddy Doyle", "venezuelan", "Separate Tables", "human voice", "Beatrix Potter", "magpie", "comets", "norm skating", "Kansas City", "Ra\u00fal Castro", "mccartney", "Scotland", "Red Admiral", "Illinois", "green", "Splash", "Britain", "menorah", "A Beautiful Mind", "Smeagol", "otters", "John McCarthy", "John Mortimer", "Cheerios", "norm", "Asia", "Liam Cunningham", "Toodee", "Madrid", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "St Bernard", "France", "Barnard College", "travel across the Indian Ocean and the Suez Canal"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6107142857142858}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.09523809523809525, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-693", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7254", "mrqa_triviaqa-validation-101", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-2821", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.546875, "CSR": 0.5356570512820513, "EFR": 1.0, "Overall": 0.7195532852564102}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "gatada", "Verdi", "month of May", "Michael Corleone", "Mohanda Karamchand", "by increasing the number of arcs", "Mr. Golding", "a group of nuclei interconnected with the cerebral cortex, thalamus and brainstem, associated with a variety of functions: motor control, cognition, emotions, and learning", "vitamin B3", "director of the Security Service", "Hell Upside Down", "Funchal", "woman", "pasta", "Northern Ireland", "woman", "L.H.O.Q.", "The Quatermass Experiment", "Mumbai", "a statue of a man in fighting stance", "1875", "raven", "hound", "Ernie", "Estimate", "$12$", "Narendra Modi", "villa wahnfried", "quentin tarantino", "Argentina", "hard", "Kitzb\u00fchel", "Tunisia", "barbara mandrell", "tundras tundra", "Romania", "brindisi", "m", "Emeril Lagasse", "hit the beach at Larvotto", "tabitha", "hitler", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "Ireland", "'The Ipcress File' (1966)", "detective, and science fiction", "fifa", "country of the brave", "to the anterolateral corner of the spinal cord", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "English folk-song", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's", "Kenyan", "The Old Man and the Sea", "Edward I", "The Cranberries", "Air traffic delays began to clear up Tuesday evening after computer problems left travelers across the United States waiting in airports,"], "metric_results": {"EM": 0.375, "QA-F1": 0.4748818277310924}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.23529411764705885, 1.0, 1.0, 0.5714285714285715, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6742", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-7072", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5155", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-5696", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-1827", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.375, "CSR": 0.533623417721519, "EFR": 1.0, "Overall": 0.7191465585443038}, {"timecode": 79, "before_eval_results": {"predictions": ["astor", "Addis Ababa", "peacock", "francish", "HMS Amethyst", "Libya", "tomato", "Ky\u014dto, Japan", "Fancy Dress Shop", "Bull Moose Party", "know", "Jake La Motta", "resistance of an unknown resistor", "Hattie McDaniel", "south africa", "indigestion", "discretion", "pinhead", "william mountford", "Ernie Pyle", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "pearls", "kris Jenner", "gangsters", "bitches", "Duncan", "UKIP", "Argentina", "south Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "Rambo", "Julian Assange,", "IT Crowd", "nastase", "carters", "hitler", "Richard Curtis", "terms of endearment", "India", "lagertha", "1790", "greenock", "chamomile", "hitler", "orchid", "Hilary Swank", "Dee", "diametrically opposite the South Pole", "the 18th century", "eight hours ( UTC \u2212 08 : 00 )", "just 18 minutes", "England", "nationalism", "\"Steamboat Bill, Jr.\"", "into some of the most hostile war zones,", "Rodong Sinmun", "theology", "Cyd Charisse", "sanctions", "February"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5946875}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16, 0.6, 0.8, 1.0, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2433", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1338", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-889", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5872", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_hotpotqa-validation-5333", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-2116"], "SR": 0.515625, "CSR": 0.5333984375, "EFR": 1.0, "Overall": 0.7191015624999999}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2", "the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "on the reservation", "Steve Ford", "1969", "Billy Joe Walker, Jr.", "2003", "at 5 : 7 -- 8", "the Canadian Rockies continental divide east to central Saskatchewan", "base homeostasis", "Miami Heat", "began on March 29, 2018, and is scheduled to end on September 30", "four", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas, or tolled ( quota ) highways", "the probability of rejecting the null hypothesis given that it is true", "Tom Burlinson, Red Symons and Dannii Minogue", "The controlled synthesis of materials as thin films ( a process referred to as deposition ) is a fundamental step in many applications", "Tulsa, Oklahoma", "Kristy Swanson", "Corey Taylor", "Santa Fe, New Mexico", "Tbilisi, Capital of Georgia", "The genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria", "United Nations", "as of October 1, 2015", "2026", "318", "Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "number of times a pitcher pitches in a season", "the foreign exchange market ( FX )", "The Hustons", "The Sunday Post", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Buck Owens and the Buckaroos", "\"Up,\"", "\"Empire of the Sun,\"", "off east  Africa", "modify", "olly ringwald", "faerie", "the skull and crossbones"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6461314418859649}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.631578947368421, 0.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.1875, 1.0, 1.0, 0.0, 0.6, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-1373", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-8711", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.546875, "CSR": 0.5335648148148149, "EFR": 0.9310344827586207, "Overall": 0.7053417345146871}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Berenice I", "nuclear warheads", "capitals", "pizza roll", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "Christopher Darden", "Jenny", "gestation", "ravens", "Tolkien", "Dale", "the Blue Ridge Mountain Range", "Georgia", "nickel", "buddha", "Apple", "Southampton, Virginia", "a catfish", "A Chorus Line", "Naples", "Robbie Turner", "a feeling of sorrow", "Chloe Lattanzi", "Virginia", "College of William & Mary", "small", "Louisiana", "Vassar", "Japan", "cutlery", "The Police", "Air France", "Thomas Striggio", "Heracles", "trudge", "The Moody Blues", "Albert Camus", "Volvo", "Rhode Island", "Falsetto", "the Indian Ocean", "a hypodermic needle", "Charlotte Corday", "nanosecond", "Didelphodon vorax", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a forest", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Allerdale", "Mugabe's", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5912698412698413}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-13394", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390"], "SR": 0.484375, "CSR": 0.5329649390243902, "EFR": 0.9696969696969697, "Overall": 0.712954256744272}, {"timecode": 82, "before_eval_results": {"predictions": ["the USS Nautilus", "the Hopi", "the Vatican City", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "a therapist", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "an acre", "the Baha de Darwin,", "(Malle) Babbe", "the Black Sox Scandal", "(rooikat)", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "nouveau", "the Autobahn", "Anglo-Saxon", "the California quail", "curtsy", "lacrosse", "Toronto", "grave", "King David", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Rouge", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "(William) Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "laces", "(Lee) Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W \ufeff /\ufeff 48.63972 \u00b0 N 4.57028 \u00b0 W", "belgian", "the acai berry", "the Benedictine Order", "Pansexuality", "authorship of \"Titus Andronicus\"", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "2001"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6633333333333333}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5866666666666668, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-4646", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.5625, "CSR": 0.5333207831325302, "EFR": 1.0, "Overall": 0.719086031626506}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Starbuck (Island)", "Ebony", "Trinity College", "Algeria", "Joseph Haydn", "Dick Cheney", "the black market", "a number", "Saturday Night Fever", "AFGHANISTAN", "a pizza Napoletana", "a turtle", "the Empire State Building", "White blood cells", "a picayune", "dogwood", "Quebec", "Larry McMurtry", "Kellogg\\'s", "Helen of Troy", "a sweatshirt", "a pound", "Napoleon", "gold", "Lapland", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "AT&T", "Pancho Gonzales", "the Aleutians", "the Mormons", "Lady Jane Grey", "867-5309", "the crescent moon", "Iraq", "a spider", "Nicolaus Copernicus", "a chiles rellenos", "William Safire", "Leonardo da Vinci", "from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "\"Casablanca\"", "T. R. M. Howard", "Parlophone", "Wednesday.", "the U.N. aid agency", "1995", "four"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7630208333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.13333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-537"], "SR": 0.671875, "CSR": 0.5349702380952381, "EFR": 1.0, "Overall": 0.7194159226190476}, {"timecode": 84, "before_eval_results": {"predictions": ["Russia", "Henry VIII", "Judas", "Windsor, Ontario", "Douglas", "comrade", "The Great Gatsby", "a foxes", "Sexuality", "Salaries", "Solomon", "Federer", "a bicycle", "Johnson County", "Jericho", "push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Rosh Hashanah", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the Iroquoian family", "the Philippines", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "Jolly Roger", "engrave", "Daisy Miller", "The Stag", "a Y chromosome", "a ship", "Kamehameha I", "a fox", "Jamestown", "Jerry Maguire", "the north magnetic pole", "oyster", "a monkey", "Candlestick Park", "Zimbabwe", "a bowstring", "Duke", "I", "Hoffmann", "a calico", "Frankie Muniz", "season two", "A complex sentence", "40", "Neptune", "Nowhere Boy", "August 1973", "a nasal", "Richa Sharma", "Haiti", "financial gain,", "a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7354166666666666}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-109", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-16580", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-11433", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-10445", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.671875, "CSR": 0.5365808823529412, "EFR": 1.0, "Overall": 0.7197380514705882}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Tigger Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "The Fountainhead", "Saraswati", "Jon Stewart", "Suicide Squad", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "Strawberry Fields", "The Hague", "Geena Davis", "pharmacy", "Amos", "the NFL", "Doolittle", "pneuma", "Shakespeare in Love", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the money changers", "The X-Files", "Babar the elephant", "Mensa", "( Edward) Hopper", "oratorios", "steak", "a Zombies", "a toddler", "the Mormon Tabernacle Choir", "the Venetian", "a cucumber", "the Warsaw Pact", "Athens", "the Sunday New York Times", "anode", "boldly", "the National Teachers Hall of Fame", "the Bicentennial", "the Chickasaw", "the hair", "the Texas Rangers", "fluoxetine", "H CO ( equivalently OC ( OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight David \"Ike\" Eisenhower", "Battleship", "\"Shake It Off\"", "pizza,", "her landlord defaulted on the mortgage and the house fell into foreclosure.", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5520833333333334}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-10138", "mrqa_searchqa-validation-4035", "mrqa_searchqa-validation-5775", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-10858", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.515625, "CSR": 0.5363372093023255, "EFR": 1.0, "Overall": 0.719689316860465}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a crossword", "a real animal", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "Palatine Hill", "California", "the Mississippi", "Alpha", "Quebec", "a pearl", "Texas Chainsaw Massacre", "a rotunda", "a Medal of Honor", "Manet", "Plutarch", "Mediolanum", "Celia", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "Millard", "viyella", "Finnegans Wake", "aam", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "a croissant", "Rocky Down Mexico Way", "the lungs", "Fuchsia", "phalanges", "a pool", "Warsaw", "a trowel", "Mercury", "Taiwan", "Gettysburg", "Ibtihaj Muhammad,", "trout", "Kay Kyser", "1959", "season two", "$75,000", "Union Jack", "fifteen", "Stonemason's Yard", "Agent Carter", "Orson Welles", "Manhattan, New York City", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6602678571428572}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.609375, "CSR": 0.537176724137931, "EFR": 1.0, "Overall": 0.7198572198275862}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists and the Carlists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "$72", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Paris", "homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Robert Duvall", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "slavery", "Donny Osmond", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "Taiwan", "Anakin Skywalker", "Jeff East", "one", "Thomas Lennon", "Ed Roland", "Kevin Garnett", "a star", "Uzbekistan", "Selena Gomez", "Washington", "the 2nd century", "Triple threat", "1997", "Nicolas Anelka", "foreign investors", "Louis XVIII", "a U.S. design patent as `` teardrop - shaped marker icon including a shadow", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Crick", "Mount Aconcagua", "bake Off", "1924", "Eugene Levy", "zona glomerulosa", "Nicole Kidman", "last summer.", "to get involved in service and volunteerism in their communities.", "third", "banker", "an eyelid", "the Cubs", "a thief"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6670019455709064}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7741935483870968, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10256410256410257, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-5696", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.578125, "CSR": 0.5376420454545454, "EFR": 0.9259259259259259, "Overall": 0.7051354692760943}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff", "a bag", "Federer", "Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "\"The three were seized early Monday after police raided a bus station in Sargodha, a city located about 120 miles (190 km) south of Islamabad in Pakistan's Punjab province.", "Atlanta's Hartsfield-Jackson International Airport", "normal maritime", "formagruppen", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "These planning processes are urgently needed and have been a long time in coming.", "Two suspects are in custody.", "\"We want to reset our relationship and so we will do it together.\"", "club managers,", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "At least 14 bodies", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "the Defense of Marriage Act", "Europe,", "for not doing more since taking office.", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "Greeley, Colorado,", "Kansas City, Missouri", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "drugs", "Daniel Radcliffe", "1.2 million", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million people worldwide", "Krishna Rajaram,", "a rocket", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Jund Ansar Allah", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "This was the first time a U.S. president visited Turkey at the start of his term, sending a clear signal that this administration recognizes the importance of Turkey and wants to engage with it from the start.", "Yemeni port city of Aden", "federal officers' bodies", "Carl", "central business district of Bangkok", "journalists and the flight crew", "writ of certiorari", "pigs", "James Corden", "Norway", "Le Duel De Hamlet", "The Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England", "beef", "Sleyman", "woods", "Ramadan"], "metric_results": {"EM": 0.421875, "QA-F1": 0.544307185967712}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 0.058823529411764705, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.5555555555555556, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3157894736842105, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09302325581395349, 0.0, 1.0, 0.0, 0.33333333333333337, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_triviaqa-validation-486", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763", "mrqa_searchqa-validation-6846"], "SR": 0.421875, "CSR": 0.5363412921348314, "EFR": 1.0, "Overall": 0.7196901334269662}, {"timecode": 89, "before_eval_results": {"predictions": ["Pease Air National Guard Base", "Kim So-hyun", "president of Guggenheim Partners", "Comedy Central", "9\u201310 March 1945", "2011", "John D Rockefeller's Standard Oil Company", "during the early 1970s", "Asiana Town", "American R&B", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks for consumption on the premises", "Fiat Group", "Chrysler", "Australia", "the bonobo", "\"Traumnovelle\" (\"Dream Story\")", "Joshua Rowley", "Robert Digges Wimberly Connor", "Yitzhak Edward Asner", "the Beatles", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "\"Rated R\"", "95 AD", "1614", "French", "\"The Manhunter\"", "Mondays", "Daniel Richard \" Danny\" Green, Jr.", "Snowball II is killed off", "Bank of China Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "Home Rule Confederation", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act of 1854", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "elbow", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "CNN's \"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "Partridge Family", "Mickey Spillane", "housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6854166666666668}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [0.22222222222222224, 0.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.8, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-7701", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.578125, "CSR": 0.5368055555555555, "EFR": 1.0, "Overall": 0.7197829861111111}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2009", "actress", "Pakistan", "1754", "Na Na", "VfL Wolfsburg", "d\u00edsabl\u00f3t", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia,", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "London Heathrow", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama", "Scandinavian design", "Mike Pence", "Barack Obama's", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Beetlejuice\"", "Presbyterian Church", "138,535", "Ry\u016bky\u016ban", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gaseous matter", "ensures consistency", "Mexico", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "kite surfers", "Robert", "dolls", "diane cilento", "CO2", "Walgreens"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6245793269230768}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2564102564102564, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_triviaqa-validation-4655", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.578125, "CSR": 0.5372596153846154, "EFR": 0.9629629629629629, "Overall": 0.7124663906695157}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "TouchTunes", "the Jaguar", "the Gateway Mall", "Friday", "Sabino Canyon", "Orlando Bloom", "Babe Ruth", "the 1980s", "Arkansas", "Mike Tyson", "Iustitia", "contemporary and modern art", "Coyote", "bucolic", "Tito Puente", "Hydrogen", "Johnny Cash", "lymphoma", "Margaret", "Las Vegas", "San Francisco", "the 1940s", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "the Wright Brothers", "Badminton", "John Deere", "depth and height", "Chrysler", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "the Assyrian Empire", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "a bank", "a spirit-lifting jingle", "bobby brown,", "bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "Veracruz", "Monday night.", "23", "minister and biographer"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7067708333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_newsqa-validation-979", "mrqa_hotpotqa-validation-4539"], "SR": 0.59375, "CSR": 0.5378736413043479, "EFR": 1.0, "Overall": 0.7199966032608696}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico, Virginia", "the East", "William Shakespeare", "Ende", "the vermilion", "Alaska", "Sputnik", "Richmond, Virginia", "the early predecessors of program music", "Java", "(Haydn) Haydn", "Marius Petipa", "inseparable", "Room-temperature vulcanization", "Wuthering Heights", "Ali", "September 20, 1934", "Dead Man\\'s Chest", "Frederick Forsyth", "Chesterfield, Virginia", "a chipmunk", "Josephine", "salt", "a warrant", "Rossini", "Oman", "Spmi", "Tom Canty", "Andrzej Wajda", "Joan Didion", "a frigate", "Baltimore", "the Bay of Bengal", "Button Gwinnett", "Hillary Clinton", "Terrific", "geology", "six", "Olympia", "Ship of Fools", "ghost town", "tendang", "Color Splash", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "manic", "the Hudson Bay", "lighter", "after a scuffle with the Beast Folk", "Tanner", "Germany", "porthmadog (complete with a substantial semaphore signalling installation)", "Nairobi, Kenya", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6110882675438596}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5263157894736842, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15084", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-6867"], "SR": 0.515625, "CSR": 0.5376344086021505, "EFR": 1.0, "Overall": 0.7199487567204301}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Tony Orlando", "David Ogden Stiers", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners, Former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "At the north end, a portion of the early route through Pacific Grove begins at the intersection of Del Monte Blvd and Esplanade Street", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Frieza's body in red fur", "Audrey II", "January 2017", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "The Province", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3 of the United States Constitution", "Bill Irwin", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Jupiter", "excessive growth", "1939", "Richard Masur", "Sanaa Lathan", "Spanish", "Sauron", "Dan Heath", "statistical advantage for the casino that is built into the game", "159", "The Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "makes Maria a dress to wear to the neighborhood dance", "activates a relay which will handle the higher current load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood\\'s A Holy Grail", "a nide", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "\"The Da Vinci Code,\"", "\"She will stand next to Mark emotionally, but she cannot stand in the glare of others,\"", "Khrushchev", "(Julie) Andrews", "Ichabod Crane", "Leo Frank,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6359765982341413}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6206896551724138, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 0.7499999999999999, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.13333333333333333, 0.0, 0.4615384615384615, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-2989", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-105"], "SR": 0.515625, "CSR": 0.5374002659574468, "EFR": 0.9354838709677419, "Overall": 0.7069987023850377}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "Thon Marial Maker", "Battle of Chester", "youngest TV director ever", "19 February 1927, Halifax", "on the shore,", "film playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural areas", "8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "Pantone Matching System (PMS)", "Las Vegas Boulevard", "intelligent design", "Barbara Herrera", "William Scott Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevrolet Corvette Stingrays", "Little Big League", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "the \"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians,", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "\"Holinshed's Chronicles\"", "August 9, 2017", "Bangalore University", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "the third-most - massive planet", "alveolar process", "Dortmund - Ems Canal", "Hugh Quarshie", "china", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria", "Easter Island", "( Eli) Whitney", "Today", "25"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7083953373015873}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.47619047619047616, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-1656", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.609375, "CSR": 0.5381578947368422, "EFR": 1.0, "Overall": 0.7200534539473684}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies worldwide", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1950", "Roy Spencer", "1964", "Union Hill section of Kansas City, Missouri", "VH1", "London Review of Books", "Russian", "Jack Ryan", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "Northern Lights", "coca wine", "Mach number", "Jordan Ridgeway", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "Deputy Vice-Chancellor", "Song Il-gon", "Teen Titans Go!", "Mickey Mouser", "\"The Lark\"", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "seal hunting", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S,", "My Backyard", "Sun Woong", "boxer", "Aloe Vera of America", "creeks", "1992", "the United States of America", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "\"The Da Vinci Code,\"", "Dogpatch Labs", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.625, "QA-F1": 0.7020833333333334}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_hotpotqa-validation-2388", "mrqa_naturalquestions-validation-360", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503"], "SR": 0.625, "CSR": 0.5390625, "EFR": 1.0, "Overall": 0.720234375}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "The Highwaymen", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Mariann Karlsson", "American rapper Eminem,", "\"Love Streams\"", "In a Better World", "the Shropshire Union Canal", "\"deadpool 2\"", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "John Francis Kelly", "early Romantic period", "approximately $700 million", "the Sun", "Bhushan Patel", "1692", "interstate commerce", "The Wu-Tang Clan", "the 1995 teen drama \"Kids\"", "Mortal Kombat X", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "isosceles", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "bread pudding", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.703125, "QA-F1": 0.8406001984126984}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-2482", "mrqa_hotpotqa-validation-4514", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789"], "SR": 0.703125, "CSR": 0.5407538659793815, "EFR": 0.9473684210526315, "Overall": 0.7100463324064026}, {"timecode": 97, "before_eval_results": {"predictions": ["The Theory of Everything", "the Caucasus range", "David Bowie", "john Spencer", "Granada", "Treaty of Brest-Litovsk", "Karl Marx", "Paramounts", "Marilyn Monroe", "Sheichthys cyanoguttatus", "1957", "1876", "transsexual", "Sheena Dunaway", "greece", "Scotland Yard", "Inverness-shire", "full of woe", "winnie Mae", "Rudyard Kipling", "1921", "Full Monty", "Emilia", "avocado", "Frans Hals", "New Democracy", "Ford", "garbanzo", "Frank Sinatra", "1826", "w WymarkJacobs", "Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "an elephant", "Tigran Petrosyan", "i, o, or u", "Westminster Abbey", "Canada", "Sheidi Klum", "Edward VII", "Tombstone", "Santo Ant\u00e3o", "Mr. Men and Little Miss", "worcestercathedral.co.uk", "Mercury", "December 7, 1941", "endocrine gland", "Nadia Comaneci", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Electronic Attack Squadron 135", "95 AD", "170", "\"Californication\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5296875}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7127", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-4459", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-3536", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.46875, "CSR": 0.5400191326530612, "EFR": 1.0, "Overall": 0.7204257015306121}, {"timecode": 98, "before_eval_results": {"predictions": ["He hit the Sunday talk show circuit circuit this weekend and tried out the attack dog role, criticizing Republican John McCain for his stance on Georgia, Iraq and national security.", "Afghanistan", "hunt for Nazi gold", "suspects allegedly involved in forged credit cards and identity theft led authorities to a $13 million global crime ring,", "his health and about a comeback.", "poems", "then-Sen. Obama", "woman", "581", "The Everglades,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives,", "Mobile County Circuit Judge", "celebrities", "Iraqi economy.", "Phillip A. Myers.", "In 1959, Bobby Darin, left, was Larry's first major guest on his WKAT radio program.", "share personal information.", "Argentinean and 255 British", "Sheik Mohammed Ali", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "Muhammad Ali on a nine-day visit to Europe that included a stopover to his ancestral home in Ireland.", "Jennifer Arnold and husband Bill Klein,", "WBO welterweight title from Miguel Cotto", "Austin, Texas,", "17-month", "a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party", "death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "American Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983.", "health ailment or beauty concern.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Derek Mears", "\"we take this issue seriously.\"", "fastest circumnavigation of the globe in a powerboat", "$106.5 million", "18th", "Haeftling,", "on the table", "Asuka", "MercyMe", "n Nissan", "stone arch", "Jane Austen", "the Marx Brothers film", "Indian", "early 20th-century Europe", "a hostage", "the 70th Academy Awards", "W. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6264820748930919}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, true, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.23728813559322035, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.4, 0.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-2182", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-900", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-7963", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.484375, "CSR": 0.5394570707070707, "EFR": 0.9696969696969697, "Overall": 0.7142526830808081}, {"timecode": 99, "UKR": 0.736328125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.83984375, "KG": 0.5203125, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "most performed song of all time", "Oregon Ducks", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "Sick Jacken", "Broadcasting House in London", "smith for eddie smith", "Barney Miller", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "What's Up", "Saturday Night Live", "strongly associated with Gaia and Cybele", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle Cities", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Krusty the Clown", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "Fred \"Sonic\" Smith", "James City County", "North African Arab", "Linda Ronstadt", "the United Kingdom", "August 2013", "the Americas and the entire South American temperate zone", "Sister, Sister", "five", "Steve Coogan", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "based on the idea of laying out a tournament ladder by arranging slips of paper with the names of players on them", "Frank Zappa", "1991 model year Ninety and the One Ten", "applea", "fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Mario Balotelli", "Friday,", "Lifeboat", "a kilobyte", "stockbroker", "Benazir Bhutto"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6998798076923076}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.8, 1.0, 0.4, 0.25, 0.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.6923076923076923, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.578125, "CSR": 0.53984375, "EFR": 1.0, "Overall": 0.727265625}]}