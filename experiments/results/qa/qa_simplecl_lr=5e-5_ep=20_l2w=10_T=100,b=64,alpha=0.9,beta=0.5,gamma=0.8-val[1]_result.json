{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8320, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "P", "Daniel Burke", "the highest terrace", "major national and international patient information projects", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "variable", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Studs Terkel, American writer, essayist, filmmaker, teacher, and political activist Susan Sontag", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.75, "QA-F1": 0.8083926184110007}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-1692", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.75, "CSR": 0.7578125, "EFR": 0.9375, "Overall": 0.84765625}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "the Swiss canton of Graub\u00fcnden", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "physicians, lawyers, engineers", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "sequential proteolytic activation of complement molecules", "the head of Lituya Bay in Alaska", "120 m ( 390 ft )", "eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "Spain"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7420318153645136}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.8, 0.888888888888889, 0.4444444444444445, 1.0, 0.4, 1.0, 0.5853658536585366, 0.38095238095238093, 0.0, 0.5, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.640625, "CSR": 0.71875, "EFR": 0.9130434782608695, "Overall": 0.8158967391304348}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie saved something from the disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac,", "Egypt", "algae", "4,404.5", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "Forney Hull ( James Frain )", "In December 1971, the `` Smithsonian Agreement '' was reached. In this agreement, the dollar was devalued from $35 per troy ounce of gold to $38", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7667478354978354}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-8763", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.703125, "CSR": 0.71484375, "EFR": 1.0, "Overall": 0.857421875}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "sponges, both ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "evading it", "the kettle and the Cricket", "Gandhiji", "Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money, but Horace and Alexandra are repulsed by the suggestion", "Betamax", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4 x 365 = 730 days", "The Story of Tiger Woods' 1996 U.S. Amateur Win", "It was Arizona's territorial capital from 1867 to 1877, and a university was founded there in 1885", "Marshall Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali: Legian Resort on Seminyak Beach", "The new nightspot Teddy's made this presidential Hollywood hotel a happening # Quiz # Question. 0:29", "Pulsed Laser", "Incomprehensible", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "the fear of meat", "American", "The Mexican military"], "metric_results": {"EM": 0.5, "QA-F1": 0.6135593560525625}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14814814814814814, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 0.7499999999999999, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.17391304347826084, 1.0, 0.3076923076923077, 0.0, 0.4, 0.0, 0.0, 0.0, 0.19999999999999998, 0.14285714285714285, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-4424", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2804", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.5, "CSR": 0.671875, "EFR": 1.0, "Overall": 0.8359375}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "League of the Three Emperors", "science", "143,007", "Bill Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawn the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24", "Dover Beach"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8100077771493213}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-4517", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616"], "SR": 0.734375, "CSR": 0.6822916666666667, "EFR": 0.9411764705882353, "Overall": 0.811734068627451}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth", "Spanish", "Structural geologists", "president and CEO", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp", "Henry Gwyn Jeffreys Moseley", "racing", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "It is based in Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "Liverpool and England", "Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Obuasi", "79", "Algeria", "romantic", "Biafra", "Polar Cub", "Atlantic City, New Jersey"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7980392156862746}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-226", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.6875, "CSR": 0.6830357142857143, "EFR": 1.0, "Overall": 0.8415178571428572}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "solution", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "a modern canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "entire length", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "a deterministic Turing machine", "Bart Starr", "allotrope", "Karluk Kara-Khanid", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "Hanoi", "Sevens", "fennec", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African", "Teotihuacan", "Sleeping Beauty", "PeopleMover", "8 December 1985", "Noddy", "Ali Bongo", "Honey Nut Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7520833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, true, false, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-3091", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-1042", "mrqa_hotpotqa-validation-3885", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.6875, "CSR": 0.68359375, "EFR": 1.0, "Overall": 0.841796875}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "lower heat addition temperature", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Han Chinese and Khitans", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "Money trees", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Ai-Ling Lee", "Miss Universe 2010", "Adam Amin", "boxer", "Boston University", "Fulham", "A55", "Hugh de Kevelioc", "\u00c6thelstan", "Madras Export Processing Zone", "44", "I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "diastema", "Shirley Horn", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7055871212121212}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.3636363636363636, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-1501", "mrqa_squad-validation-9859", "mrqa_squad-validation-8356", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-524", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-3170"], "SR": 0.640625, "CSR": 0.6788194444444444, "EFR": 1.0, "Overall": 0.8394097222222222}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "French", "Museum of the Moving Image in London", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "Black's Law Dictionary", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "a pivotal event", "transgender teenage girl", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "4145 ft above mean sea level", "Central Park", "Robert John Day", "Tugurt", "James Tinling", "Italy", "2015 Masters Tournament", "Ulver and the Troms\u00f8 Chamber Orchestra", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "kuskusi", "more than 22 million", "morphine sulfate oral solution 20 mg/ml", "The Ferguson Library", "a species of freshwater airbreathing catfish"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6486222938588926}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.88, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.5625, "CSR": 0.6671875, "EFR": 0.9642857142857143, "Overall": 0.8157366071428571}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "not covered in any newspapers", "arrows, swords, and leather shields", "Cybermen", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "Rhine-Ruhr region", "course of study", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "Battle of the Philippines", "NCAA Division I", "The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "the RATE project", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Repertoire of Pl\u00e1cido Domingo", "Germany", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens and the Buckaroos", "World Health Organization", "Emmanuel Ofosu Yeboah", "California", "Panic! at the Disco", "the Royal Firework Music", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "Dustbin"], "metric_results": {"EM": 0.625, "QA-F1": 0.7200217599745216}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6927", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-5743", "mrqa_naturalquestions-validation-3837", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644"], "SR": 0.625, "CSR": 0.6633522727272727, "EFR": 0.9166666666666666, "Overall": 0.7900094696969697}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "Only 100\u2013150", "Philo of Byzantium", "cooler", "in marine waters worldwide", "$60,000", "his mother", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "It's helping consumers move beyond these hard times and has reignited a whole industry", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "on the Ohio River near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "the deal, which promises cabinet positions to the splinter group of the Movement for Democratic Change, does not involve MDC head Morgan Tsvangirai", "a homicide", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong from other parts of Asia", "opposition party members", "Missouri", "President Obama's race in 2008", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "the Employee Free Choice act", "Obama", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "Japanese", "Dan Parris, 25, and Rob Lehr", "Fayetteville", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "Andrew Morris", "the Ark of the Covenant", "Jean F Kernel", "Thomas Hardy", "Richmond", "1994", "The Conjuring", "The Gallipoli Campaign", "Lake Michigan", "Nowhere Boy"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6382810115231989}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.5, 0.4, 1.0, 0.0, 0.0625, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-4611", "mrqa_squad-validation-4524", "mrqa_squad-validation-1313", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.53125, "CSR": 0.65234375, "EFR": 1.0, "Overall": 0.826171875}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "God's grace (which cannot be earned) alone can make them just.", "Napoleon", "new technology and machinery", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation,", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Mark Ronson", "the Catechism", "beneath the university's Stagg Field", "Ian Botham", "Pyotr Ilich Tchaikovsky", "Vincent Motorcycle Company", "Simon \"Sam\" Marx", "Salvador Allende", "Marie Antoinette", "Hawaii", "Erik Thorvaldson", "Apollon", "Pal Joey", "Mary Seacole", "green", "Indonesia", "supreme religious leader of the Israelites", "Antonio", "European Economic Community", "Christine Keeler", "Jesus", "Nicholson", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott", "Sean", "John Denver", "Stage 1", "Travis", "Blue Peter", "Robert Kennedy", "Q", "Paris merchant Jean Marius", "a French author and philosopher", "barber", "Fred Stolle", "Murrah Federal Office Building", "Evita", "a litter of pipes on the mantelpiece", "fortified complex", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "\"It is very easy for comments to be taken out of context and create unnecessary drama -- especially between us women,\"", "a delegation of American Muslim and Christian leaders", "Anne of Cleves", "USC Columbia", "Juan Martin Del Potro."], "metric_results": {"EM": 0.53125, "QA-F1": 0.5837735615079365}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, false, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.12500000000000003, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.05555555555555556, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_squad-validation-670", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-5929"], "SR": 0.53125, "CSR": 0.6430288461538461, "EFR": 0.9, "Overall": 0.7715144230769231}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "in Medieval Latin, 9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "dernell", "moles", "Democritus", "Kwajalein Atoll", "Catherine of Aragon", "julius k Roosevelt", "Steve McQueen", "Portugal", "jazz piano", "two", "kopassus", "in the northwest of England", "dry Ice", "zanesville and Zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "aniridia", "t.S. Eliot", "River Forth", "woe", "NOW Magazine", "Burmese", "Italy", "Canada", "typhoid fever", "juliano Pavarotti", "action figure", "Walt Kowalski-Gran Torino", "2010", "volume of a given mass of a gas", "Venezuela", "al Laurel and Hardy", "temperature", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Christopher James \" Chris\" Weidman", "Drillers Stadium", "one", "Virgin America", "Nate O'Reily", "al Jazeera English", "Iran's parliament speaker", "English Premier League Fulham produced a superb performance in Switzerland on Wednesday to eliminate opponents Basel from the Europa League with a 3-2 victory."], "metric_results": {"EM": 0.5, "QA-F1": 0.5567031926406926}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0909090909090909]}}, "before_error_ids": ["mrqa_squad-validation-1002", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.5, "CSR": 0.6328125, "EFR": 0.96875, "Overall": 0.80078125}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "the University of Aberdeen", "public official", "the most cost efficient bidder", "acorn tree", "gaius", "thighbone", "alpine", "Ukrainian Soviet republic", "kungo", "Clark Kent", "fire", "amber", "high school football", "The executioner's Song", "right angle", "an A-Z of Central Asia", "anamosa", "grouchy", "Ephesus", "asylum", "film", "knife", "glare", "Cologne", "gaius caesar augusta", "crucible", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "cowboys", "a natural-born citizen", "white-tailed deer", "scholastic.com", "burt Reynolds", "kung fu", "boys", "windjammer", "stanley joe", "germanicus", "Augusta", "counter clockwise", "2013", "Nick Hornby", "Coldplay", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "memories of his mother", "Israel"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4427083333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.390625, "CSR": 0.6166666666666667, "EFR": 0.9487179487179487, "Overall": 0.7826923076923077}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "German", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "crossword", "Cuba Gooding Jr.", "Strongsville, Ohio", "Flemish", "Mastercard", "Robert C. Stempel", "Nashville", "olfactory nerve", "Ivan the Terrible", "Nancy Astor", "liver spot", "Kurt Russell", "Toronto Maple Leaf", "Zsa Zsa Gabor", "performance process", "Delaware", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "joey", "pro bono", "Bologna", "The Fun Factory", "a brown", "Manfred von Richthofen", "Nacho Libre", "copper", "black magic or of dealings with the devil", "hemlock", "Dr. Wigand", "National Poetry Month", "a sesame seed bun", "meager", "Casablanca", "blimps", "( Gustav Kirchhoff)", "a geisha", "Bigfoot", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "dark", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6227430555555555}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6463", "mrqa_squad-validation-9248", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.53125, "CSR": 0.611328125, "EFR": 0.9666666666666667, "Overall": 0.7889973958333334}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser", "an open casket on the dining room table", "(Ho) Minh", "a penis", "the Inuit's dwelling", "Detroit Rock City", "the Toronto Blue Jays", "President Lincoln", "Ray Bradbury", "crimes committed out of hatred for someone's race", "Madagascar", "Nicolas Sarkozy", "Rubicon", "(Conello)", "17", "(Louisa) May Alcott", "Play-Doh", "Aphrodite", "the nails", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "Bellerophon", "Balaam", "the Wharton School", "the Caine Mutiny", "the Rolling Stone", "(founded 1932)", "(John) Coltrane", "the peace sign", "oxygen", "Sphinx", "Jan Hus", "USA Network", "the Mavericks", "Onegin", "J.L. Hudson's Department Store", "a spinning jenny", "(Santa) Claus", "(Benicio) Snchez", "a doctor", "judges", "attached to another chromosome", "the City of Preston", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "( Brad Blauser)", "salary", "punishment"], "metric_results": {"EM": 0.46875, "QA-F1": 0.606908195970696}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.5, 0.8, 0.5, 1.0, 0.2, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.5, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-1759"], "SR": 0.46875, "CSR": 0.6029411764705883, "EFR": 0.9117647058823529, "Overall": 0.7573529411764706}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Tesla", "ring", "Party of National Unity", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "The Crystal Method", "Puerto Rico", "The Mausoleum", "The World Through More Than One lens", "Switzerland", "Sabena", "The Old Man", "French", "(Bob Fitzsimmons)", "the Nemean lion", "d'Artagnan", "the Bayeux Tapestry", "a mirror", "China", "Shia", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "a Belgian-owned Canadian beer company", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "a positive +1 ion", "Bromley", "the Ruul", "Cartoon Network", "Caylee Anthony", "know what is important in life", "Rabbani, a former Afghan president who had been leading the Afghan peace council, was killed in an attack at his home.", "Iran's development of a nuclear weapon", "The drama of the action in-and-around the golf course has enraptured fans of the game through the generations and around the world."], "metric_results": {"EM": 0.65625, "QA-F1": 0.6821875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.16, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1920", "mrqa_searchqa-validation-2355", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-2709", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7140", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.65625, "CSR": 0.6059027777777778, "EFR": 0.9545454545454546, "Overall": 0.7802241161616161}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "computational", "same-gender marriages", "During the 2006 Israel-Lebanon conflict", "the mid-18th century", "orange", "A Raisin in the Sun", "Sistine Chapel", "bielaruski", "(one tight end and one", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "White Cliffs of Dover", "Genoa", "\"Who is John Galt?\"", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "roses", "The Hampton Inn", "a gold palm", "(John) Janetzko", "Copeina arnoldi", "Paul McCartney", "omega-3", "Raphael", "Bachman Turner Overdrive", "horror", "Caddy Shack", "Tokyo", "Panama", "Eppson Center", "Narnia", "Finnegans Wake", "(William) Wordsworth", "Norway", "bears", "nuclear bombs", "(Judas) Iscariot", "elephant", "mazurka", "Sweden", "covert", "Our Country", "May 2010", "in 2014 Blue Bell was the best - selling ice cream brand in the United States", "Guanabara bay", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5852557684973303}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3157894736842105, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_squad-validation-1696", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.46875, "CSR": 0.5986842105263157, "EFR": 0.9705882352941176, "Overall": 0.7846362229102166}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "the Earth", "more than 53,000", "one", "Israeli poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "ambiguous", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "Arousal regulation", "Charlene Holt", "Ted '' Levine", "1991", "electron shells", "Cornett family", "Acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Ric Flair", "Toledo, Bowling Green, and Mount Union", "a form of business network", "a cylinder of glass or plastic", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus and Ancy Lostoma duodenale", "February 29", "The Lykan", "issues of the American Civil War", "A proton motive force drives protons down the gradient ( across the membrane ) through the proton channel of ATP synthase", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units within the National Health Service in England", "Lou Rawls", "Hermia", "Jupiter", "Latin", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "the olfactory nerve", "eucalyptus", "a horse", "oxygen"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6841399485930736}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.625, 1.0, 0.2, 1.0, 0.5, 1.0, 0.6666666666666666, 0.7499999999999999, 0.09090909090909091, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_squad-validation-880", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.578125, "CSR": 0.59765625, "EFR": 0.9629629629629629, "Overall": 0.7803096064814814}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape of a 15-year-old girl", "illegal crossings into U.S. waters", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer in five vignettes", "well over 1,000 pounds", "political dead-end", "Mutassim", "from Texas and Oklahoma to points east", "Polo", "his mother", "Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Jobs", "12-hour-plus", "Brad Blauser", "childbirth", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Pakistan's combustible Swat Valley", "Friday", "1979", "the United States", "GospelToday", "chief executive officer", "no chance", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Gustav", "gun", "Henrik Stenson", "orphanage in Abeche", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter festivals", "Whitsunday", "Dee", "\"Dumb and Dumber\"", "the Sugar Bowl", "Earl Warren", "converging", "autu", "season five", "The Force uprising ( 2015 )"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6029254302897394}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.4, 1.0, 0.8750000000000001, 1.0, 0.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.052631578947368425, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-2301", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-3226", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.515625, "CSR": 0.59375, "EFR": 0.967741935483871, "Overall": 0.7807459677419355}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers.", "Combined Statistical Area", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "responsibility for the abductions", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Golden Girls\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "\"I'm certainly not nearly as good of a speaker as he is.\"", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad, Iran.", "Amanda Knox's aunt", "jazz", "$530 million in debt", "\"Doogie Howser, M.D.\"", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "a nurse who tried to treat Jackson's insomnia", "Sarah", "\"They left without me,'", "1981", "\"17 Again,\"", "Nigeria", "$80,000 a year", "Republicans", "EU naval force", "Kate Hudson", "Omar Bongo", "the Delta Queen steamboat", "Hyundai Steel", "skeletal dysplasia,", "London Heathrow's Terminal 5.", "canceled the swimming privileges of a nearby day care center", "February 12", "more than 30 Latin American and Caribbean nations", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military strike", "White House Executive Chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"Mortal Kombat X\"", "The Kingdom of Northumbria", "\"Get Thee To A Nunnery\"", "Romanian Communist Party", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold"], "metric_results": {"EM": 0.53125, "QA-F1": 0.625686435704818}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-251", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107"], "SR": 0.53125, "CSR": 0.5909090909090908, "EFR": 1.0, "Overall": 0.7954545454545454}, {"timecode": 22, "before_eval_results": {"predictions": ["several experimental setup to produce X-rays.", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia,", "two", "glowed even when turned off.", "five female pastors", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "Prague", "\"project work\"", "a federal judge in Mississippi", "the department has been severely affected by the earthquake,", "$22 million", "a few family treasures.", "a music video on his land.", "\"wildcat\" strikes", "\"Watchmen\"", "The Real Housewives of Atlanta", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Vrishti Bhowmik.", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "male veterans struggling with homelessness and addiction.", "it will be the longest domestic relay in Olympic history,", "Zimbabwe's dire economic situation.", "No. 1", "nine", "Four bodies", "Friday", "Kingdom City", "Rima Fakih", "two contestants.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning -- the FDA's strongest -- to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Rima Fakih", "Isthmus of Corinth", "Nalini Negi", "( 2017 - 12 - 10 )", "Runcorn", "collarbone", "geographic horizon", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Viva Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5565307878307398}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.8235294117647058, 1.0, 0.5, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.421875, "CSR": 0.5835597826086957, "EFR": 0.972972972972973, "Overall": 0.7782663777908343}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "six Iraqis and wounded 10 others", "the two bodies", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over", "threatening messages", "Noriko Savoie", "drafting a new constitution", "he was bleeding profusely", "Abrahamson", "martial arts", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "an account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "the government in Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.", "Zuma", "haute, bandeau-style little numbers", "nine", "Iraq", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed", "Desmond Tutu", "$17,000", "Jobs", "$81,880", "to provide school districts with federal funds", "a spiritual conversion", "Jason Lee", "REM sleep", "substantive", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "The U.S. Founders and Cyrus the Great of Persia", "an retired captain in the United States Navy", "Florida"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6447709050140342}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.15789473684210525, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.59375, "CSR": 0.583984375, "EFR": 0.9230769230769231, "Overall": 0.7535306490384616}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Kathrin Hoelzl of Germany", "one of the shocks of the year", "him to step down as majority leader.", "United Nations World Food Program vessels carrying food and relief supplies to war-torn Somalia,", "gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "continuously trying to best your own fuel economy achievements,\"", "1979", "one of its diplomats in northwest Pakistan", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh", "technology experts Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "12 million", "President Sheikh Sharif Sheikh Ahmed", "a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "behind the counter.", "11", "one Iraqi soldier,", "A man who was raised at Camp Lejeune", "her fianc\u00e9", "racial intolerance.", "animal products.", "El Viceroy", "Symbionese Liberation Army", "8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "would compromise the public broadcaster's appearance of impartiality.", "black is beautiful", "$104,327,006 paid for \"L'Homme Qui Marche I, bronze\" (Walking Man 1), 1960, by Alberto Giacometti.", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade after a new survey showed how the drug dominates Afghanistan's economy.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of disaster assistance for parts of the Midwest that have been hit by record floods.", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance\" rated highly for Oxygen,", "famous faces like NHL hockey star Alexander Ovechkin, Russian Vogue editor in chief Aliona Vodianova, acclaimed conductor Valery Gergiev, the \"Russian Madonna\" singer Valeriya, and London-", "\"Steamboat Bill, Jr.", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Treaty of Paris between France and the Sixth Coalition, and the Treaty of Kiel", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "prime minister", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.390625, "QA-F1": 0.506870318552062}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.18181818181818182, 1.0, 0.4, 0.10526315789473685, 1.0, 0.0, 1.0, 0.8, 1.0, 0.25, 0.5714285714285715, 0.33333333333333337, 0.0, 1.0, 0.0, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.125, 1.0, 0.08, 0.0, 1.0, 0.0, 0.0, 0.4, 0.5, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.390625, "CSR": 0.5762499999999999, "EFR": 0.9743589743589743, "Overall": 0.7753044871794872}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "large scale", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "35", "a market where members join together as syndicates to insure risks.", "beetle", "arthropods", "Ub Iwerks", "Westminster Abbey", "holography,", "Pelias", "Sarah Collins", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "Noun", "copper and zinc", "Tigris", "Cordelia", "there were many kinds of publications that told both news and rumours.", "seborrheic dermatitis", "33", "a varietal", "Joseph Smith,", "Chicago", "palladium", "the moon", "13.", "a petticoat", "The Virgin Spring,", "Canada", "Clement Attlee", "Stockholm", "Peter Parker", "Golda Meir", "Lesa Ukman", "bullfight", "Sparks", "Ginger Rogers", "the Rock of Gibraltar", "Comedy Playhouse", "citric", "Charles Darwin", "John Denver,", "Mr. Boddy", "Marie Van Brittan Brown", "southern California", "1995", "Bourbon", "Taylor Swift.", "Rihanna", "had his personal.40-caliber pistol,", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop,", "cactus", "the Louvre", "Seaver College"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5705639367816092}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.16666666666666666, 0.4827586206896552, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.515625, "CSR": 0.5739182692307692, "EFR": 0.9354838709677419, "Overall": 0.7547010700992556}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "Pontiac Silverdome", "elephants", "to cook in front of a large party of guests.", "Frank McCourt", "jules verne", "jonathan k Kinnock", "margo leadbetter", "Schengen", "\u201cA\u201d", "city of the United Kingdom", "Famous Players Corporation", "the Monkees", "Gerald Durrell", "Jezebel", "County Cork", "jason", "can eat and drink anything, has good,  strong feet and is happy being in a new place every day.", "Halifax", "Noises Off", "jason stansbury", "Frank Wilson", "Carlos the Jackal", "edwina currie", "Gillis Grafstr\u00f6m", "jonathan stanssell", "1917", "For Gallantry", "\"full of woe\"", "tbilisi", "Cahaba", "Ever Increasingasing Circles", "Tahrir", "plutonium", "a father figure to the other musketeers.", "27", "Jack Ruby", "Jacopo tintoretto", "Eric Coates", "Dubai", "Lester", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "a heart rate that exceeds the normal resting rate", "672", "\"Linda McCartney's Life in Photography\"", "Robert Frost's former home in Franconia, New Hampshire,", "Twitter", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5470643939393939}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-208", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4916", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-4910", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.484375, "CSR": 0.5706018518518519, "EFR": 1.0, "Overall": 0.7853009259259259}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "70", "forced Tesla out leaving him penniless.", "Benazir Bhutto", "Iran's nuclear program.", "at least 27", "Former Beatles Paul McCartney and Ringo Starr", "FBI Special Agent Daniel Cain,", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Pakistan", "Florida Everglades", "dilshan scored his sixth Test century of a remarkable year to give Sri Lanka a fine start to the third match of their series against India in Mumbai on Wednesday.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos", "about $163 million (180 million Swiss francs)", "unwanted baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions.", "7 miles north of Steamboat Springs", "Orbiting Carbon Observatory", "Switzerland", "louis armstrong", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "burned over 65 percent of his body after being set on fire,", "al-Shabaab", "posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "opryland", "Number Ones", "attempting illegal crossings into U.S. waters.", "he was diagnosed with skin cancer.", "al Qaeda", "Barack Obama", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "The oceans", "baraceli Valencia, was mopping the kitchen in their family home on a typical warm spring morning in Phoenix, Arizona,", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "between 1923 and 1925", "gilda", "jonathan dryden", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "malawi flag"], "metric_results": {"EM": 0.453125, "QA-F1": 0.594734154626763}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.4, 0.8, 0.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.35294117647058826, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.11764705882352941, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 1.0, 0.0, 1.0, 0.6, 0.0, 1.0, 0.0, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.453125, "CSR": 0.56640625, "EFR": 0.9714285714285714, "Overall": 0.7689174107142858}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai Steel", "Monday night", "Florida", "kidnapping and concealing their identities.", "40", "the Illuminati", "in a public housing project,", "toxic smoke", "one of South Africa's most famous musicians,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "nuclear weapon", "in Japan", "Arizona", "Southeast Asia and India.", "Tetris", "outside influences", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "immediate release", "the area was sealed off,", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers", "\"project work\"", "Oprah: A Biography", "80 percent", "London's", "to try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "more than 300", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events", "\"State of Play\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "to help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "West Side Story", "The Fifth Amendment", "Nepal's", "Merck & Co.", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.583232821637427}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.31578947368421056, 1.0, 1.0, 1.0, 0.5, 0.4444444444444445, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1527", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.46875, "CSR": 0.5630387931034483, "EFR": 0.9705882352941176, "Overall": 0.766813514198783}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "domestic and imported ( Brazil )", "sex organs", "August von Mackensen", "galaxy", "August 6 and 9, 1945", "Doug Diemoz", "Jamestown settlement in the Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "in ancient Mesopotamia", "maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going '", "John Ridgely", "by captains of sailing ships to cross the world's oceans for centuries", "October 12, 1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "singer and a co-worker", "Ethel `` Edy '' Proctor", "ranking used in combat sports,", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "the Rashidun Caliphs", "Lake Powell", "ornament", "September 6, 2019", "its population", "substitute goods", "Marries Veronica", "over 74", "1987", "to signify cunnilingus and the gesture is often off - colour", "October 2000", "New York City", "Mamata Banerjee", "the United States economy first went into an economic recession", "closing of the atrioventricular valves and semilunar valves", "Hermann Ebbinghaus", "The Miracles", "used their knowledge of Native American languages as a basis to transmit coded messages", "Donny Osmond", "Carthaginian Empire and the expanding Roman Republic.", "George Herbert Walker Bush", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "helicopters and boats, as well as vessels from other agencies,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "adventure park"], "metric_results": {"EM": 0.359375, "QA-F1": 0.49480334081627186}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.2857142857142857, 0.4, 1.0, 0.0, 1.0, 0.0, 0.19999999999999998, 1.0, 0.7142857142857143, 1.0, 0.14285714285714285, 0.4, 0.0, 0.0, 0.0, 1.0, 0.3846153846153846, 1.0, 0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.13333333333333336, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.0, 0.4, 0.9333333333333333, 1.0, 1.0, 0.20689655172413793, 1.0, 0.2222222222222222, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.359375, "CSR": 0.55625, "EFR": 0.8780487804878049, "Overall": 0.7171493902439025}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "Louisiana", "the Delaware Chingachgook,", "shoes.", "nine", "r Rashid Akmaev,", "acetylene", "food", "fiber", "shrew", "What's", "Winston Rodney,", "sand", "nanjing", "Custer National Forest", "ry Python and the Holy Grail", "the Sun", "GILBERT & SullIVAN", "walker", "the Belgae", "walker", "the Boston Marathon.", "fibreboard", "iron", "walker", "a map of the Earth", "his father had boycotted Thomas Jefferson's", "\"Y\" 2 \"K\":", "Fat Man", "Hair", "William Randolph Hearst", "pumice", "ale", "primate", "telephone", "a song performed by English pop punk band Busted.", "Luther", "The New Colossus", "yelped", "Richard Wagner", "Sarah Fergie of York", "getting married tomorrow", "the middleweight champion", "bronchodilators", "Forty", "a glass tube containing a mixture of neon (99.5%) and argon gas.", "ryans", "a Chenard", "an American politician and the...", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "three", "Alberto juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan", "in Atlanta in 1996.", "an African-American woman"], "metric_results": {"EM": 0.328125, "QA-F1": 0.3614583333333333}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-16116", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-7231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_searchqa-validation-8480", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.328125, "CSR": 0.548891129032258, "EFR": 0.9767441860465116, "Overall": 0.7628176575393848}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the laser", "the volume", "a crossword puzzle clue", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "August Wilson", "Juliet", "Notre Dame", "Table Mountain", "Jamie", "Captain William Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad,", "Mike Huckabee", "Queen", "monosodium glutamate,", "the Chance", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Prince William and Kate Middleton", "America Ferrera", "an R (registered trademark)", "Zechariah", "New Jersey", "Lake Ontario", "Matthew Perry", "Marissa Jaret Winokur", "John Ford", "kismet", "Willy Wonka", "artillery", "aluminum", "General McClellan", "Ned Kelly", "nuclear reactor", "gravitational force", "Isis", "a quiver", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Max Planck", "Rocky Marciano", "Stevie Wonder,", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years,", "Arsene Wenger", "Tuesday on CNN's \"Larry King Live.\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6859375}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_newsqa-validation-2123"], "SR": 0.609375, "CSR": 0.55078125, "EFR": 0.96, "Overall": 0.755390625}, {"timecode": 32, "before_eval_results": {"predictions": ["the weight and that increase was the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Emperor Norton", "the CIA", "pianissimo", "Rickey Henderson", "Indira Gandhi", "the wild", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "the neutron", "Dust jacket", "Rudy Giuliani,", "the First Amendment", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel", "the Olympic Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Aidan Quinn", "Lindsay Davenport", "Los Angeles", "the East Wind", "King Edward", "the Labour Party", "the pen", "Mexico", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "Russia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Alice", "Harry Potter and the Deathly Hallows", "Roy Eberhardt moves to Florida and into the town of Coconut Cove, where his classmate Dana Matherson starts bullying him", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "My Backyard", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6816907051282052}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true], "QA-F1": [0.923076923076923, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5384615384615384, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-5449", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-8063", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160"], "SR": 0.609375, "CSR": 0.5525568181818181, "EFR": 1.0, "Overall": 0.7762784090909091}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"aware of what she's done and she's very sorry for it.\"", "the annual White House Correspondents' Association dinner", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license", "Arkansas", "fuel economy", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in", "a missile", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Brooklyn, New York, for Miami Beach, Florida,", "over 1000 square meters", "CNN", "There's no chance", "St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "a portrait", "the self-styled revolutionary Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "in-cabin lighting system", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "NATO", "some free milk.", "Kgalema Motlanthe", "the Ming dynasty", "George II", "2014 -- 15", "2013", "Javier Bardem", "Scotland", "Erika Girardi", "Terry the Tomboy", "Harriet Tubman", "Mrs. Potts", "Spokescandy", "the Star-Spangled Banner"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7049005681818182}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.5, 1.0, 1.0, 1.0, 0.6, 0.0, 1.0, 0.8, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-1622", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.59375, "CSR": 0.5537683823529411, "EFR": 1.0, "Overall": 0.7768841911764706}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "weren't taking it well.", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcies", "nearly $2 billion", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Fernando Verdasco", "Bahrain", "the children of street cleaners and firefighters.", "Joan Rivers", "$3 billion", "hardship for terminally ill patients and their caregivers,", "Honduran", "Brazil", "environmental", "strife in Somalia,", "Roy", "WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Alicia Keys", "to work together to stabilize Somalia and cooperate in security and military operations.", "Friday,", "a cancerous tumor.", "20", "Gary Brooker", "$1.5 million", "Matt Kuchar and Bubba Watson", "40", "sustainability.", "glamour and hedonism", "J. Crew.", "American Legion National Commander David Rehbein", "543", "anonymous,", "Robert Gates", "Israel", "about 30 miles southwest of Nashville,", "confirmed that Coleman, 42, was being treated there after being admitted on Wednesday.", "in Seoul,", "Nicole", "Holding the Olympic medal she and her mom always wanted,", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Indian monks", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "the Kingdom of Norway", "Beer", "Revengers Tragedy", "1972", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5808566693722944}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.5, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.16, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2418", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.484375, "CSR": 0.5517857142857143, "EFR": 0.9393939393939394, "Overall": 0.7455898268398269}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826,", "rum", "Nantucket", "an Islamic leadership position.", "leaves", "Malibu", "Sisyphus", "sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "horseshoe", "Caliban", "Purple", "the Aegean Sea", "the Battle of the Little Bighorn", "The Shakers", "a bellwether", "The Information Philosopher", "potato chips", "Boxer", "Arthur", "Mabel Harding", "Las Vegas", "The Cast of \"Don't Think Twice\"", "the Rose Bowl.", "Norman Rockwell", "the beehive", "light tunais", "Napa", "Eurail France", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "a sundae", "Mary Shelley", "50 million", "Volitan Lionfish", "Charlie Sheen", "feodor m Mikhailovich", "Bonnie Aarons", "2 September to Wednesday, 5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "a small hole or tear in a piece of material,", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6254261363636364}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-13067", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_naturalquestions-validation-590", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.515625, "CSR": 0.55078125, "EFR": 0.967741935483871, "Overall": 0.7592615927419355}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "the Mojave Desert", "bullion", "Supernanny", "the Atlantic", "Cincinnati", "mosque", "Henry Hudson", "the Peashooter", "dry ice", "Elihu Root", "Entourage", "eel", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "John C. Frmont\\'s campaign slogan", "Russia", "BYBRA STREISAND", "Hermann Hesse", "the Taj Mittal", "Johnson", "The opera Carmen", "Margaret Mitchell", "Claude Frollo", "Sultans of Swing", "Pandarus", "(bumrushed)", "Burt Reynolds", "the Sphinx", "Louis Satchmo Armstrong", "Saudi Arabia", "American rock band", "Arby\\'s", "coffee", "second lieutenant", "Robert Burns", "The Incredible Hulk", "Winnipeg", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "Cattalo", "Sunday", "Edith Piaf", "Ivan I", "a prologue", "clay", "an investor couple", "Jack Gleeson", "Phil Hurtt,", "animals", "Massachusetts", "City of Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.625, "QA-F1": 0.6854910714285714}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-14520", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_newsqa-validation-3951"], "SR": 0.625, "CSR": 0.5527871621621622, "EFR": 1.0, "Overall": 0.7763935810810811}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "Sanders", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "1927", "Egypt", "pi", "tin", "Lake Pontchartrain", "Cousin Eddie", "w", "Marriott", "the Principality of Monaco", "Canada", "The Secret", "the gold rush", "collagen", "China", "a compound", "the warblers", "a claw", "Alzheimer", "the Gulf of Mexico", "Stephen F. Austin", "Euclid", "Eva Peron", "Cain", "Edward Asner", "X-Men", "the Louvre", "the chinook", "Prison Break", "Voyager", "Maine", "sheep or goat's milk", "Meg", "the Sonnets", "deuce", "Hans", "Peter Bogdanovich", "the Ramone", "Jerusalem", "boat propulsion", "the Quaternary Period", "nolo contendere", "Junior Walker", "Czech Republic", "seewhat", "cut - throat competition", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"Sausage Party\"", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again,\"", "Nelson County"], "metric_results": {"EM": 0.625, "QA-F1": 0.6859375}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-6998", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8068", "mrqa_naturalquestions-validation-2918", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.625, "CSR": 0.5546875, "EFR": 1.0, "Overall": 0.77734375}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "yellow fever", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "brushes", "ferry", "forgetting Sarah Marshall", "Witness", "Jack the Ripper", "4500", "Shirley Schmidt", "phylum", "Spain", "the brain", "William McMaster Murdoch", "Macbeth", "comedy", "Mary Poppins", "a no-hitter", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "a second marriage", "Livin' On A Prayer", "Sherlock Holmes", "licorice", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "congruent", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "The Queen of Spades", "rhodonite", "glaciers", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Out of Africa", "Scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "organizational motivation", "one", "Norfolk Island", "The Wright brothers", "jurisdiction", "Canada Goose", "Sandro Bondi refused to attend Cannes,", "voluntary manslaughter", "the need for reconciliation", "Pygmalion"], "metric_results": {"EM": 0.625, "QA-F1": 0.6827380952380953}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.09523809523809522, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-2005", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.625, "CSR": 0.5564903846153846, "EFR": 1.0, "Overall": 0.7782451923076923}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "Wikis", "the Byzantine Empire", "Independence", "Jefferson", "Ezra Pound", "Guarauno", "a ready-to-use cotton swab", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking through research and analysis", "Warren Harding", "engrave", "William", "Francis Crick", "Bluntman and Chronic", "L. S. Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "alex", "Ratatouille", "circadian fluctuations", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "the marathon", "life", "a herb", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Danish", "Anna Murphy", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.484375, "QA-F1": 0.53125}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.484375, "CSR": 0.5546875, "EFR": 1.0, "Overall": 0.77734375}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "FAI Junior Cup", "Flaw", "alt-right", "the Drudge Report", "15,000 people", "Yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133,", "We Need a Little Christmas", "Tsavo East National Park", "the New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "Whitney Houston (August 9, 1963 \u2013 February 11, 2012) was an American singer, actress, producer, and model.", "Manchester United", "Daphnis et Chlo\u00e9", "1", "26,000", "Kristin Scott Thomas, Anne Bancroft, James Fox, Derek Jacobi, and Sean Penn.", "Ed Lee", "1958", "1993", "American burlesque", "Afro-Russian", "Loretta Lynn", "Lancashire, England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leon Uris", "Erika Mitchell Leonard", "Mason Alan Dinehart III", "Golde", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood", "by military personnel to hazardous materials", "two", "he checked himself into a Los Angeles mental institution in an effort to kick the habit.", "a riddle", "a man of Character", "Quizlet", "a narcissistic ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7143192693744165}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.35294117647058826, 0.8571428571428571, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.761904761904762, 0.0, 0.3333333333333333, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_searchqa-validation-13997", "mrqa_naturalquestions-validation-6326"], "SR": 0.609375, "CSR": 0.5560213414634146, "EFR": 1.0, "Overall": 0.7780106707317074}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "was \"in bad condition at the scene,\"", "Les Bleus", "2005", "more than 4,000", "Sen. Arlen Specter", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "a \"prostitute\"", "Zed", "tax", "Brazil", "acute stress", "Russia and China", "Facebook and Google,", "through a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "Pakistan", "for these last 23 years.", "a head injury.", "Bahrain", "an open window", "Leo Frank", "Paul McCartney and Ringo Starr", "Washington", "President Robert Mugabe", "don't have to visit laundromats", "three", "United Kingdom Dance Championships.", "on-loan David Beckham claimed his first goal in Italian football.", "He is more American than German", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Fayetteville, North Carolina,", "The plane had a crew of 14 people and was carrying an additional 98 passengers,", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "angular rotation", "the right side of the heart to the lungs", "54 Mbit / s", "County of Gloucestershire", "the B-24 Bomber Crash Landings", "cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "U.S. Department of Transportation"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7514645204672777}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.11764705882352942, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 0.21428571428571427, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.609375, "CSR": 0.5572916666666667, "EFR": 1.0, "Overall": 0.7786458333333334}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona", "Zimbabwe,", "Italian Serie A", "Darrel Mohler", "her dancing against a stripper's pole.", "Michoacan Family,", "WTA Tour titles", "MDC head Morgan Tsvangirai.", "42", "taking on the swords of the Taliban.", "some great travel spots to be altered or ruined by global climate change.", "80 percent of a woman's face", "1979", "Ben Hogan biopic \"Follow the Sun,\"", "Elena Kagan", "Rod Blagojevich", "an auxiliary lock", "1-1", "Umar Farouk AbdulMutallab", "Myanmar", "Collier County sheriff's department", "Marcus Schrenker,", "Bienvenido Latag", "poems telling of the pain and suffering of children", "the program was made with the parents' full consent.", "Sen. Barack Obama", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators who will decide whether to remove him from office", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "its nude beaches.", "how preachy and awkward cancer movies can get.", "Misty Croslin,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill.", "would not do it because they understand that Israel does have a nuclear arsenal.", "1940's", "March 22,", "ireport form", "Mediterranean Sea.", "\"Antichrist.\"", "a major fall in stock prices", "Thomas Jefferson's", "Alexander Salkind", "Orion", "brown", "Selfie", "2002", "England", "Manhattan Project", "the Rat", "rain", "Crawford", "the Pyrenees"], "metric_results": {"EM": 0.515625, "QA-F1": 0.658278886656644}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.8, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.3076923076923077, 1.0, 0.4, 0.4, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.12500000000000003, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-800", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-5989", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834"], "SR": 0.515625, "CSR": 0.5563226744186047, "EFR": 1.0, "Overall": 0.7781613372093024}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "cast doubt on Woodward's assertion Tuesday in a conversation with \"American Morning\" host John Roberts.", "hardship for terminally ill patients and their caregivers,", "Araceli Valencia,", "Zac Efron", "finance", "nearly $2 billion", "pesos", "1941,", "The station", "Krishna Rajaram,", "a man's lifeless, naked body", "Robert Mugabe", "Jenny Sanford,", "Afghanistan's restive provinces", "Wednesday", "$1.5 million", "a violent government crackdown seeped out.", "Iran could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Hyundai", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "Rima Fakih", "South Africa", "Barack Obama", "helicopters and unmanned aerial vehicles", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "A receptionist", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Aston Villa Football Club", "small-holder farmer", "cue ball", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "The Wizard of Oz", "the frontal lobe"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6367897727272728}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.08333333333333333, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1835", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.546875, "CSR": 0.5561079545454546, "EFR": 1.0, "Overall": 0.7780539772727273}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf.", "Los Angeles", "Chris Eubank Jr.", "Duval County", "Benj Pasek and Justin Paul,", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Thomas Staubach", "1944,", "Johns Creek", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley", "What Are Little Boys Made Of", "Berea College", "Omaha Nighthawks", "Timoth\u00e9e Chalamet", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "nationality law", "Radcliffe College", "Edward Anthony Spitzka", "Ford", "heavier than a feather", "Tamil Nadu", "Lutheranism", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men United", "Rain Man", "Interscope Records", "British East India Company", "3,672", "Henry Luce's", "I'm Shipping Up to Boston", "American", "Irish rock band U2", "China", "sixth - largest country by total area", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "know what's important in life,", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "suspicion", "healthy"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5515997023809524}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3340", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.46875, "CSR": 0.5541666666666667, "EFR": 0.9411764705882353, "Overall": 0.747671568627451}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "Indian Ocean waters", "30", "crocodile eggs", "Colorado prosecutor", "Jared Polis", "on Saturday.", "on the family's blog", "in July for A Country Christmas,", "sniff out cell phones.", "half a nautical mile from the shoreline of the city of Quebradillas.", "Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "dieting,", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "Jaime Andrade", "Joe Lieberman,", "a crocodile", "a bronze medal", "more than 200.", "Congress", "Susan Boyle", "\"Common Access Cards,\"", "Phillip A. Myers.", "Obama's", "Gyanendra,", "homicide.", "Casey Anthony, 22,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers,", "two weeks ago", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Donald Trump and Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "Latin liberalia studia", "one", "Johnny Mathis", "48 Hours", "Champion Jockey", "Luca Guadagnino", "Freddie Jackson", "unknown", "how timing shapes and supports brain function", "a jigger", "unarmed"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6001678876678875}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.7499999999999999, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1582", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.484375, "CSR": 0.5526494565217391, "EFR": 0.8787878787878788, "Overall": 0.715718667654809}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\"He's a shy guy, and he's doing a crazy, unique and different thing in his life that he wants to share with the world.\"", "without bail and will be arraigned June 25,", "12.3 million", "Mexico", "Real Madrid", "Michael Arrington,", "Brett Cummins,", "Indian army", "Saturday", "Nicole", "legitimacy of that race.", "\"France, Germany, England] or the emerging markets... especially Russia,\"", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "promise to improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "[Middle East and North Africa]", "twice", "October 19,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "ALS6", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback Forestry", "the children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "blacks, Hispanics and whites", "two", "the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "a turtle", "Japan", "fox hunting", "New York", "travel", "16,116", "a sophomore jinx", "sukkar", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7094187496531247}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.8, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_triviaqa-validation-1729", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.640625, "CSR": 0.5545212765957447, "EFR": 0.9565217391304348, "Overall": 0.7555215078630897}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "Parachutes", "5", "Chicago", "The Wind's Twelve Quarters", "teenage", "Dennis Kux", "drawing the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "Badfinger", "Lady Frederick Windsor", "point-coloration pattern", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930s and 1940s", "5,112", "1979", "retail, office and residential", "14,673", "6'5\" and 190 pounds", "Mickey Gilley's", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport.", "the Salzburg Festival", "Mississippi", "India", "1991\u201392", "Imelda Marcos", "Randall Boggs", "Part II", "Charlestown, Massachusetts", "lion", "the Royal Navy", "World War II", "Knoxville, Tennessee", "Three's Company", "Doomtree", "Labour", "Linda McCartney's Life in Photography", "Australian", "September 14, 2008", "79", "Frank Theodore `` Ted '' Levine", "Romania", "Farlake", "Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "halls", "Bank of England"], "metric_results": {"EM": 0.5, "QA-F1": 0.5968998015873015}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, true, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 0.5, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5349", "mrqa_hotpotqa-validation-3162", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-2757", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-4043", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.5, "CSR": 0.5533854166666667, "EFR": 0.96875, "Overall": 0.7610677083333334}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "gari", "offensive", "Augustus", "the Pilgrims", "Fawn Hall", "waived", "Citation", "Barnum", "Johnny Weissmuller", "negative electrode", "a torque screw", "gold", "Marlon Brando", "Citation", "\"rainbow\" palette", "UK", "Citation", "Brussels", "Macbeth", "General Lee", "$18.2 billion", "Fyodor Dostoevsky", "Martin Luther", "Clue", "Edgar Allan Poe", "Germany", "Andrew Johnson", "Debts", "Mike Connors", "Jungle Jim", "Jim Inhofe", "sancire", "Corpus Christi", "Equatorial Guinea", "ostrich", "a new government", "Obsolete", "mug", "Desperate Housewives", "Galileo Galilei", "Canada's", "Anne Hathaway", "Split", "the Grail", "West Virginia", "Thomas Jefferson", "home theater", "Citation", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidevous", "chariots", "Humberside Airport", "more than 265 million", "100 million", "financing to help poor families buy more energy-efficient electrical appliances.", "a head injury.", "Pope Benedict XVI refused Wednesday to soften the Vatican's ban on condom use", "Charles"], "metric_results": {"EM": 0.375, "QA-F1": 0.44114583333333335}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-10470", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663", "mrqa_triviaqa-validation-1959"], "SR": 0.375, "CSR": 0.5497448979591837, "EFR": 0.975, "Overall": 0.7623724489795918}, {"timecode": 49, "before_eval_results": {"predictions": ["National Security Agency", "the Heisman", "Brandi Chastain", "Colorado", "Pamela Anderson", "Colombo", "Treasure Island", "Pocahontas", "improvisation", "(Whizzer) White", "an ukulele", "an aerosol", "Great American Novel", "Ferris B Mueller", "Joseph Campbell", "Margaret Mitchell", "(Charles) Busch", "draft", "Ernest Lawrence", "a rodeo", "fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "the small intestine", "the mouthpiece", "the Keys", "the Fellowship of the Ring", "\" Please Mr. Please\"", "DEET", "Manhattan", "February 2", "Leontyne Price", "compost", "BUNNY", "Christopher Columbus", "Phil Mickelson", "Carrie Bradshaw", "the Castalian Spring", "Trinidad and Tobago", "the burnoose", "Philadelphia", "peanut butter", "Invisible Man", "cherry", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "terrybank thistle", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The incident Sunday evening", "three", "poems", "Nebo Zovyot"], "metric_results": {"EM": 0.546875, "QA-F1": 0.60625}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.13333333333333333, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.546875, "CSR": 0.5496875, "EFR": 0.9310344827586207, "Overall": 0.7403609913793103}, {"timecode": 50, "UKR": 0.763671875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.7890625, "KG": 0.50625, "before_eval_results": {"predictions": ["Fatih Ozmen", "an 850 saloon", "Skyscraper", "Cadillac Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Robert Downey, Jr.", "Continental AG", "band director", "Visigoths", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Umeadi Ejiofor", "president", "19th", "Hillary Scott", "Stratfor", "43rd President of the United States", "Tottenham Hotspur", "1958", "Vixen", "Forbidden Quest", "Rymill Park", "Balloon Street, Manchester", "May 1, 2011", "Santa Fe", "political", "Adelaide Lightning", "Landing Barge", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "Ferrara", "created the American Land-Grant universities and colleges", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "Indian", "hamburgers", "Liverpool", "Capellini", "Luigi Segre", "the United States Congress", "February 9, 2018", "R2E Micral", "Nacio Herb Brown", "Geoff Hurst", "Precambrian", "Mull", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "accused her of having a relationship with another person.", "neurological disease", "Paul Newman", "Puccini", "Uncle Buck", "milk and honey"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5067708333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.8, 1.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-3352", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-13015"], "SR": 0.390625, "CSR": 0.5465686274509804, "EFR": 1.0, "Overall": 0.7211106004901962}, {"timecode": 51, "before_eval_results": {"predictions": ["1898", "a Native American", "What You Will", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui Pratt", "St Vincents Hall", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "Original Knights of Louisiana", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Films", "2001", "dementia", "two", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Dame Eunice Mary Kennedy Shriver", "35", "Mark Neary Donohue Jr.", "a Peach or a nectarine", "Switzerland", "Richard Price", "Archie Andrews", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Utah", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "devonian", "a sentence", "near the Somali coast", "a Daytime Emmy Lifetime Achievement Award", "last week", "Jean Lafitte", "hunter sauce", "The Tolkien's", "carbon"], "metric_results": {"EM": 0.578125, "QA-F1": 0.652276672979798}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, false, true, false, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.3333333333333333, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-4744", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-2803", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.578125, "CSR": 0.5471754807692308, "EFR": 1.0, "Overall": 0.7212319711538462}, {"timecode": 52, "before_eval_results": {"predictions": ["My Antonia", "King Henry VIII", "lead", "the Rose Bowl", "VC-25", "amber", "Denmark", "Westies, Scotties, schnauzers", "Katrina & the Waves", "Jerusalem", "freestyle", "celtic", "pornography", "Jack O'Neill", "Lou Reed", "General Stonewall Jackson", "Fennoscandia", "Emmapeeler", "canvas", "celtic Fern", "The X-Files", "Frankie Muniz", "Ocean Life", "St. Lawrence River", "Coupvray", "kinetic", "Santera", "Starsky and Hutch", "a torch", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "cornucopia", "Chicago", "Ankara", "condensation", "eight", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Como agua para chocolate", "NigerCongo", "TGI Fridays", "President John Tyler", "Daniel Craig", "humility", "programming", "Isle of Sheppey in England", "footling breech", "if the concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bristol", "Gregory v. Helvering", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "along the equator between South America and Africa.", "It doesn't really matter all that much what hot, nubile French maverick has set the fashion world on fire.", "fake his own death by crashing his private plane into a Florida swamp.", "Stockton & Darlington"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6280428685897436}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8750000000000001, 0.08, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-4668", "mrqa_searchqa-validation-13812", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-1679", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.546875, "CSR": 0.5471698113207547, "EFR": 0.9655172413793104, "Overall": 0.7143342855400131}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Neil Young", "After Shawn's kidnapping", "to manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "birch", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Dimitar Berbatov and Carlos Tevez", "season two", "DNA", "global crowdfunding platform focused on creativity and merchandising", "warm and is considered to be the most comfortable climatic conditions of the year", "David Motl", "The Portuguese", "Madison, Wisconsin", "September 1972", "2017", "Gustav Bauer", "bacteria", "the theory of plate tectonics", "126", "Brooke Wexler", "Don Black", "1961", "111", "Brazil, Turkey and Uzbekistan", "a dromedary", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "a complex sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "Coriolis force", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "74", "`` speed limit '' omitted and an additional panel stating the type of hazard ahead", "various submucosal membrane sites", "noble gas", "Immigration and Naturalization Service's Fore Forensic Document Laboratory", "four", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Paul Gauguin", "CAIR", "creeks,", "Martin Scorsese", "Ian Fleming", "over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "off the coast", "Northwest Territories", "Chekhov", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6210731687294186}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.7692307692307692, 0.8, 0.08333333333333334, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.09090909090909091, 0.29629629629629634, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.5, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.484375, "CSR": 0.5460069444444444, "EFR": 0.9090909090909091, "Overall": 0.7028164457070707}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "cumin", "Paul McCartney", "Kanawha Rivers", "1803", "heads of federal executive departments who form the Cabinet of the United States", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "Ellen is restored to life and is married to Bobby", "California, Utah and Arizona", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "1773", "John J. Flanagan", "1988", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "John F. Kelly", "cylinder of glass or plastic that runs along the fiber's length", "embryo", "741 weeks from 1973 to 1988", "Zimbabwe", "London", "Sarah Palin", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison", "the ship", "a city of romance, of incredible architecture and history.", "Tater Tots", "Yemen", "QED", "Dalton Gang"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6320654407923043}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.4827586206896552, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.8, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2751", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-8575"], "SR": 0.515625, "CSR": 0.5454545454545454, "EFR": 0.9032258064516129, "Overall": 0.7015329453812317}, {"timecode": 55, "before_eval_results": {"predictions": ["Barbara Stanwyck", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "Oregon and Washington", "the Northeast Monsoon", "2005", "Nitty Gritty Dirt Band", "land, fresh water, air, rare earth metals and heavy metals", "an annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "`` Product / market fit", "London", "Marty J. Walsh", "Azizul Haque", "Ernest Rutherford", "depolarization of the cardiac muscle begins at the sinus node", "a strong, weight transferral synovial plane joint", "HTTP / 1.1", "Brooklyn, New York", "1 mile ( 1.6 km )", "pop ballad", "1985", "during meiosis", "2005", "Arnold Schoenberg", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "dead stratified squamous, keratinized", "2007", "Vanessa received an SMS which reveals that Dan was `` G gossip Girl ''", "10,605", "Steve Bacic", "Sebastian Vettel", "Alamodome", "Sun Harvester", "biological taxonomy", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Wayne Allwine", "Celebrity Big Brother", "John Devoy", "James Garner", "Boston, Massachusetts", "Colonel Patrick John Mercer,", "Robert Matthew Hurley", "improve the military's suicide-prevention programs.", "five", "\"a fantastic five episodes.\"", "(Charles)", "Madonna", "Eiffel Tower", "Teddy Riley"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5676309444232238}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.25, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.0, 1.0, 0.7878787878787877, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-4388", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2296", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136"], "SR": 0.46875, "CSR": 0.5440848214285714, "EFR": 0.9411764705882353, "Overall": 0.7088491334033613}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "World War II", "Raghuwanshi dynasty", "16", "1787", "1999", "Old Trafford", "Tami Lynn", "logical argument and mathematical proof", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Lucius Verus", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "the Dutch", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "noon of April 1st", "DJ Lance Rock", "24 hours later", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "1989", "Liam Cunningham", "Dennis C. Stewart", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "the septum", "Daoism", "the foreign exchange market", "`` Singing the Blues '' by Guy Mitchell", "Henry Moseley", "Nigel Lythgoe", "late - night programming block Adult Swim", "gastrocnemius", "Al Pacino", "introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan", "March 26, 1973", "1986", "a great deal on location", "President Lyndon Johnson", "prenatal development of the human heart", "a Christmas Tree", "1840", "2007", "Branson", "first baseman", "Tumi Holdings, Inc.", "River Shiel", "Ozzy Osbourne", "Polo because \"it was the sport of kings.", "Terra Firma", "ego", "Nova Scotia", "Sir Isaac Newton", "\"Love Letter\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.7105380639097745}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473682, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.5263157894736842, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-7452", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5700", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.59375, "CSR": 0.5449561403508771, "EFR": 0.9615384615384616, "Overall": 0.7130957953778678}, {"timecode": 57, "before_eval_results": {"predictions": ["Old French tailleur ( `` cutter '' )", "Massachusetts", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "an advantage without deviating from basic strategy", "Pearl Harbor", "the coffee shop Monk's", "Fred E. Ahlert", "January 2017", "Ozzie Smith", "Mark Jackson", "2017", "Resident Commissioner", "January 2018", "in all land - living organisms, both alive and dead", "September 30", "avian", "Gerald Ford", "September 8, 2017", "1998", "a political ideology", "Spektor", "an object", "the nucleus", "1973", "May 17, 2018", "Cristeta Comerford", "transposition from the key of C major to D major raises all pitches of the scale of C minor equally by a whole tone", "`` Phone a Friend ''", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root mlk `` king ''", "P.V. Sindhu", "Carpenter", "Asuka", "Wilt Chamberlain", "Herman Rarebell", "Uzbekistan", "UNESCO / ILO Recommendation concerning the Status of Teachers", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "in skeletal muscle and the brain", "Don Cook", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "Long Island", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Irish Chekhov", "Gust Avrakotos", "Mark Sanford.", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5671661931818182}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.7499999999999999, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.125, 0.14285714285714288, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.9142857142857143, 0.0, 0.9600000000000001, 1.0, 1.0, 0.888888888888889, 0.0, 0.4, 1.0, 1.0, 0.3, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.421875, "CSR": 0.5428340517241379, "EFR": 0.8918918918918919, "Overall": 0.698742063723206}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "North Dakota", "July 18, 2013", "Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979", "son of Edward '", "iron", "Detective Eddie Thawne", "Los Angeles, California", "thirteen American colonies", "biscuit - sized cakes", "king's Chamber", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "1898", "on the slopes of Mt. Hood in Oregon", "Ewan McGregor", "LED illuminated", "turkey", "1917", "2004", "Christy Plunkett ( Anna Faris )", "smen", "Mount Sinai", "Macon Blair", "genome", "by each state's DMV, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "13 February", "276", "the early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zoe Zebra", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles", "militant group", "peppermint oil", "the FBI", "a leech", "Leland Stanford", "Mexico", "Nepal"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6151365290054149}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.92, 0.5, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 1.0, 0.8750000000000001, 0.0, 0.19999999999999998, 0.5, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.9565217391304348, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-10561", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-2204"], "SR": 0.453125, "CSR": 0.541313559322034, "EFR": 0.8857142857142857, "Overall": 0.6972024440072639}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Abiotic", "9", "a useless, time - wasting activity", "head coach of the Philadelphia Eagles", "July 2012", "flower", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "January 2018", "American country music singer George Strait", "climate on the Earth", "Herman Hollerith", "94 by 50 feet", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson", "Long Island", "1988", "Egypt", "Rococo - era France", "Michael Crawford", "the Devastator", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 9, 1945", "1950s", "Napoleon Bonaparte", "XXXX", "December 25", "to turn our will and our lives over to the care of God as we understood Him", "De pictura", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Pink Floyd", "Chicago", "duchy", "Lucas Stephen Grabeel", "15,024", "actress and model", "the test results by the medical examiner's office, Garavaglia said.", "teenage", "Thursday,", "Vietnam", "bass", "Richard", "\u201cSon of Sam\u201d"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6839903150146319}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.6415094339622641, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.27586206896551724, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-4764", "mrqa_hotpotqa-validation-3979", "mrqa_hotpotqa-validation-4797", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.578125, "CSR": 0.5419270833333334, "EFR": 0.9629629629629629, "Overall": 0.7127748842592593}, {"timecode": 60, "before_eval_results": {"predictions": ["people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1996", "used their knowledge of Native American languages as a basis to transmit coded messages", "the Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "petition for a writ of certiorari", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "food and clothing", "six ahead of Jack Nicklaus with 73 wins", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T )", "US $5 billion", "Jason Lee", "the Nationalists", "Lorenzo Lamas", "Mahatma Gandhi", "the people of the United States", "the eighth season", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "August 2, 1990", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Brazil", "Parashara ( c. 400 -- c. 500 AD )", "Domhnall Gleeson", "Spanish botanist and physician Petrus Jacobus Stevus ( Pedro Jaime Esteve 1500 -- 1556 ), a professor of botany at the University of Valencia", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "Brooklyn Heights", "1966", "the alluvial plain", "analogue FM radio turn-off in the news again,", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway ( Arkansas)", "Kurt Cobain's", "\"Empire of the Sun,\"", "Stephen Dedalus", "The Killing Fields", "the Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6359722610961835}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.48275862068965514, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.53125, "CSR": 0.5417520491803278, "EFR": 0.8333333333333334, "Overall": 0.6868139515027323}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "Dimitar Berbatov and Carlos Tevez", "Jason Marsden", "New Mexico", "In 1889, following the Local Government Act 1888, using those same boundaries, Sussex was divided into two administrative counties, East Sussex and West Sussex together with three self - governing county boroughs, Brighton, Eastbourne and Hastings", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "William the Conqueror", "March 2, 2016", "July 20, 2017", "five", "September 1972", "James Rodr\u00edguez", "the mainland of the Australian continent, the island of Tasmania and numerous smaller islands", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Dan Stevens", "Acts passed by the Congress of the United States and its predecessor, the Continental Congress", "In 2018, the Women's Olympic Hockey Team won the gold medal in a 3 - 2 shootout, ending their 20 - year drought", "the first bull running is on 7 July, followed by one on each of the following mornings of the festival, beginning every day at 8 am", "the 2009 model year", "no more than 4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "18th century", "Thomas Jefferson", "Elijah Wood", "cat in the hat", "Brad Dourif", "counter clockwise direction", "the winning contestant Joanne Wheatley", "vice president", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the lower motor neurons, the efferent nerves that directly innervate muscles", "1773", "The Union's forces", "American country music duo Brooks & Dunn", "\"Pohjanmaan kautta\"", "termerized version of the Greek compound word \u1f00\u03bd\u03c4\u03b1\u03c1\u03ba\u03c4\u03b9\u03ba\u03cc\u03c2 (antarktikos)", "The Pilgrim's Progress", "Bourbon County", "Venancio Flores", "Bohemia", "Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "(Arthur) C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6402657427741577}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715, 0.9302325581395349, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.10526315789473684, 0.07692307692307691, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-8215", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-1887", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.53125, "CSR": 0.5415826612903225, "EFR": 0.9, "Overall": 0.7001134072580645}, {"timecode": 62, "before_eval_results": {"predictions": ["1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Javier Fern\u00e1ndez", "Tim Russert", "Byzantine Greek culture and Eastern Christianity", "short - circuit - proof extra-low voltage transformers for toys or doorbell installations", "tropomyosin", "in the pancreas by protein biosynthesis as a precursor called chymotrypsinogen", "the center of the Northern Hemisphere", "CeCe Drake", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud or L\u00e9oArnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "12 : 00 CET", "Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "Canada's parent country the United Kingdom", "1912", "Eric Clapton", "Djokovic", "Abraham Gottlob Werner ( 1749 -- 1817 )", "1922", "2017", "a scythe", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "Pyotr Tchaikovsky's Swan Lake", "Toronto and locations in Canada and the United States", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Kadokawa Shoten's Comp Ace", "the final scene of the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "the colonization of the Americas began", "10.5 %", "U.S. Interior Highlands region", "White House Executive chef", "Bangladesh -- India border", "Bart Millard", "a woman named Sarah Whitehead, who, after her brother's execution for forgery, went to the Bank of England every day to ask to see him", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal", "Selden", "Muslim Eid-ul-Adha", "the day before.", "said the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "the Entente Council", "Oshkosh Wisconsin", "River Welland"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5488338484432235}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.125, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.23076923076923078, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.9714285714285714, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2892", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3521", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-342", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_newsqa-validation-1285", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.453125, "CSR": 0.5401785714285714, "EFR": 1.0, "Overall": 0.7198325892857143}, {"timecode": 63, "before_eval_results": {"predictions": ["Robyn", "2006", "the closing of the atrioventricular valves and semilunar valves", "the Coppolas", "sacroiliac joint", "Identification of alternative plans / policies", "Cuernavaca, Durango", "the development of electronic computers", "the Internal Revenue Service", "the angel of the Lord", "Bhupendranath Dutt", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "March 23, 2018", "the napkin", "Andrew McCarthy", "Jakkur", "in a thousand years", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "data services ( Flex Data Services )", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "members", "Alicia Vikander as Lara Croft", "282,846", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "Czech word, robota", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser", "Austin and Pflugerville", "beginning in 1933", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "Trinidadian Calypso", "Jiles Perry Richardson", "The Pentagon", "Pisgah National Forest", "Johnnie Ray", "Robert Mugabe", "Capitol Hill.", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionist", "the Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5144973516067266}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.6153846153846153, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 0.5, 1.0, 1.0, 0.125, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3339", "mrqa_hotpotqa-validation-4240", "mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-8333"], "SR": 0.390625, "CSR": 0.537841796875, "EFR": 0.8717948717948718, "Overall": 0.6937242087339743}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League group stage", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan", "\"\"", "St. Louis Cardinals", "Foxborough", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "Michael Stipe", "January 30, 1930", "Doctor of Philosophy", "The Government of Ireland (Irish: \"Rialtas na h\u00c9ireann\"", "James Weldon Johnson", "coastal southeastern North Carolina, United States", "1979", "Taylor Swift", "the third", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "Ionolyce", "\"For Love Alone\" (1986)", "October 4, 1970", "King of France", "Sam Waterston", "Transporter 3 (French: Le Transporteur 3)", "March 14, 2000", "Gauteng", "the Vietnam War", "William Theodore Walton III", "the Darling River", "The Boz", "140 million", "English", "Teri Garr", "the employer", "1965 -- 66 season", "Wyoming", "Wee Jimmy Krankie and his father,", "people or society", "announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "black, red or white,", "intelligence official said North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Rome", "a sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6233878968253967}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 0.8, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 0.5, 0.14285714285714285, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.28571428571428575, 1.0, 0.5, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1263", "mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-4198", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-5297", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1066", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-3275", "mrqa_hotpotqa-validation-4810", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071"], "SR": 0.46875, "CSR": 0.5367788461538461, "EFR": 0.9117647058823529, "Overall": 0.7015055854072398}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "\"Archer\"", "Albert", "September 30, 2017", "322,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "1946 Winecoff Hotel fire", "Odense Boldklub", "Blois", "Jared Leto", "Gweilo", "Tufts College", "Amedeo", "1942", "The Wu-Tang Clan", "For Love Alone", "midtempo hip hop", "Hard rock", "G\u00e9rard Depardieu", "rural", "Summerlin", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse", "Kings Point, New York", "Robbie Gould", "It's Always Sunny in Philadelphia", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "Armidale, New South Wales", "Faith", "turns out to be a terrible date", "the Celtics", "Supernatural", "acid", "eight", "1867", "Sippin' on Some Syrup", "Jim Harrison", "James II", "Arabella Churchill", "Benny", "two Grammy awards", "S7", "2017", "Qutab Ud - Din - Aibak", "14 November 2001", "Thomas Jefferson", "Luxembourg", "Golda Meir", "The Muffin Man", "President George Bush", "250,000", "Vernon Forrest", "Coretta Scott", "blown", "folkloric", "Jamie Lee Curtis"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6236864697802197}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8571428571428571, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.8, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2978", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.484375, "CSR": 0.5359848484848485, "EFR": 0.9696969696969697, "Overall": 0.7129332386363637}, {"timecode": 66, "before_eval_results": {"predictions": ["a commoner", "Hillsborough", "Uruguay", "steam locomotives", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "George Gamow", "strata", "an international award given each year to a living architect who, in the opinion of select Pritzker Prize jury, has made profound achievements in the world of architecture", "Guy the Gorilla", "a man holding up a lighted match", "Port Moresby", "orange", "kursk", "pyrotechnics", "South Korea", "Eurythmics", "a goose", "super heroes", "Echidna", "Syria", "Wyoming", "Professor Brian Cox", "Benjamin Franklin", "Albert Finney", "Scotland", "24", "Martin Van Buren", "Ellice Islands", "Meta", "the Oil Capital of Europe", "about a mile north of the village of Dunvegan", "a narrow-bored wooden instrument", "The Spice Girls", "\"Mr Loophole\"", "Istanbul", "drinking song", "Republic of Texas", "Pablo Picasso", "Yalta", "Rajasthan", "African violet", "bali", "Glee", "Cardigan", "notorious Welsh pirate Edward Kenway, grandfather and father of Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway", "Djokovic", "In 1936", "Fennec fox or fennec (\"Vulpes zerda\")", "1927", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest", "Linda Hogan", "development of two courses on the Black Sea coast in Bulgaria.", "Andrew Wyeth", "parasites", "Stephen Alan \" Steve\" Wynn", "substitute good"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5616666666666668}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, false, false, true, false, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.07999999999999999, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2799", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-2232", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-6737", "mrqa_triviaqa-validation-4036", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-6970", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-9098", "mrqa_searchqa-validation-7189"], "SR": 0.484375, "CSR": 0.535214552238806, "EFR": 0.9393939393939394, "Overall": 0.7067185733265491}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less", "Thailand", "France", "tranquil beaches", "flooding was so fast that the thing flipped over,\"", "Werder Bremen", "Secretary of State", "Iran's President-elect Barack Obama", "Nearly eight in 10", "Fernando Caceres", "six Africans dead.", "no evidence", "America's Cup", "the 11th century Preah Vihear temple", "Uzbekistan.", "voluntary manslaughter", "Jenny Sanford", "Isabella", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones", "two contestants.", "Fiona MacKeown", "larry flynt.", "Graeme Smith", "former U.S. secretary of state.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old", "Manchester, England", "helicopters and boats, as well as vessels from other agencies", "terrorize is a crime,", "two tickets to Italy on Expedia.", "Oxbow,", "FAA received no reports from pilots in the air of any sightings", "21-year-old", "Jacob Zuma", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call", "Pew Research Center", "can also taste a hamburger and pizza, and drink coffee from a cup,", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "The Nitty Gritty Dirt Band", "a central place in Christian eschatology", "Phil Mickelson", "Dumbo", "skiffle quartet", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "Julie Taymor", "stephen franklin", "Who's Who - American Radio History", "men use violence within relationships to exercise power and control"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6168526785714286}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.75, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.8, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.24999999999999994, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_searchqa-validation-4134", "mrqa_naturalquestions-validation-9387"], "SR": 0.53125, "CSR": 0.53515625, "EFR": 1.0, "Overall": 0.718828125}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura", "their homes in Bhola", "off Somalia's coast.", "General Motors", "AS Roma beat Lecce 3-2", "people who wear the uniform of the United States even when it is not politically convenient.", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally from China", "2000", "at least 300", "Thursday", "volatile and dangerous.", "Israeli", "the same drama that pulls in the crowds", "2008.", "act against those who used Pakistani soil to perpetrate attacks.", "25", "a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "a remote part of northwestern Montana", "a genocide that left more than 800,000 dead.", "identity theft", "Bailey, Colorado,", "John Demjanjuk", "Venus Williams", "two weeks", "How I Met Your Mother", "British", "at least one", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds).", "stand down.", "his past and his future", "Mombasa, Kenya,", "related to the Common Germanic word guma", "Taron Egerton", "Vienna", "Hard Times", "Echinacea purpurea", "Nellie Melba", "Clark Gable", "1979", "the backside", "Sweden", "garcinia cambogia", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.5, "QA-F1": 0.5576522435897436}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.4, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-1168", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-917", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4367", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.5, "CSR": 0.5346467391304348, "EFR": 0.96875, "Overall": 0.7124762228260869}, {"timecode": 69, "before_eval_results": {"predictions": ["line the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "karma", "Kevin Sumlin", "Paradise, Nevada", "Detective Eddie Thawne", "Hathi Jr", "LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "Luke Luke 18 : 1 - 8", "by October 1986", "an address bar", "solids", "1996", "Carol Worthington", "September 6, 2019", "1972", "1902", "uprooted", "down to the ground", "Battle of Antietam", "an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "P wave", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive chef", "Mansa Musa", "25 years after the release of their first record", "the bank", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "Mallee", "inflation", "Peter Scudamore", "John M. Dowd", "December 17, 1974", "Northrop F-15 Reporter", "26", "The patient,", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6884424603174604}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.9523809523809523, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.8, 0.3333333333333333, 1.0, 0.2857142857142857, 1.0, 0.0, 0.5714285714285715, 0.888888888888889, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.9523809523809523, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993", "mrqa_newsqa-validation-1092"], "SR": 0.546875, "CSR": 0.5348214285714286, "EFR": 0.9310344827586207, "Overall": 0.7049680572660099}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "instructions", "January 2, 1971", "minced meat", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "Longliners", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Peru", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "Friedman Billings Ramsey", "the NFL", "14.69278 \u00b0 N", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "a premedication for medical or dental procedures", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "John De Vito", "Malware", "ex", "Beorn", "South Dakota", "John F. Kennedy", "100,000", "1967", "Rajasthan", "Sodor", "eye", "44,300", "the 2008 presidential election", "Frisian", "Long Island", "likening one American diplomat to a \"prostitute\" and threatening to oust another from his country.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6089242623377854}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.07692307692307691, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-4442", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-5392", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.546875, "CSR": 0.5349911971830985, "EFR": 0.9310344827586207, "Overall": 0.7050020109883438}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "north-south ridge", "photographer", "clown", "the Titanic", "Campania", "Hadrian", "Indonesia", "the Barbizon school", "Renzo Piano", "Manet", "Rodney", "Columbia", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "Honda", "Greenock", "ABBA", "Sonja Henie", "12", "Lord Snooty", "snuffles", "Rudolf Hess", "Institute of Chartered Surveyors", "Stieg Larsson", "Facebook Music Stories", "1957", "a giant menhir", "steel", "Rotherham United", "Joseph Priestley", "Persian greyhound, gazelle hound or tazi", "tennis", "Periodic Table", "bikutsi", "region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Spanish", "curre", "Patience", "Chubby Checker", "Eric Eisenberg", "to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 16th hole", "in San Francisco", "90s", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "monthly", "Jonathan Breeze, the CEO of Jet Republic,", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lashings", "the American Civil War", "in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past.", "the Peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6163500816993464}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 0.5, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6465", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-10030", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.546875, "CSR": 0.53515625, "EFR": 1.0, "Overall": 0.718828125}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby darin", "Thames", "Altamont Speedway", "The Jetsons", "26 miles", "jE. talus ankle joint", "ocellaris", "Samson", "Connecticut", "Daedalus", "girolamo", "british empire", "a goad", "Peter Parker", "14", "radars", "Queen Elizabeth II", "tonto", "sea horse", "Frank Miller", "tennis", "Orwell", "Atlantic Ocean", "New Zealand history", "Chatsworth House", "dirk bikembergs", "british", "in your dog's eyelid", "chainsaws", "augusta baker street", "aug. 24", "bos primigenius indicus", "Augustus", "South America", "Southwest Airlines", "bOULEVARD", "benny gary", "Derwent", "sesame", "Laos", "Louis van Gaal", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley", "spIRALI", "1768", "Joan Rivers", "Athens", "William Refrigerator Perry", "Ghana", "Near East", "observing the magnetic stripe `` anomalies '' on the ocean floor", "2001", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett", "Diego Milito", "Rembrandt Harmenszoon van Rijn", "Dumbo the Flying elephant", "February 27, 2016", "pythons"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5139022435897436}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.4, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-9987", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.390625, "CSR": 0.5331763698630136, "EFR": 0.9487179487179487, "Overall": 0.7081757387161924}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "The Bears", "\"Time\"", "Babylon", "1449", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "racehorse breeder and owner", "Nazi Party", "ali Gray", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "7", "model, actress and television host", "1957", "mathematician, physicist, and spectroscopist", "king Duncan", "The St Andrews Agreement", "Royal College of Music", "4145 ft", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "mpire Falls", "2013", "Michael Phelps", "a suburb", "schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "Torah", "paramitas", "1881", "writing", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Jobs", "meditation, yoga", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6755894566441442}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.6, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-3692"], "SR": 0.609375, "CSR": 0.5342060810810811, "EFR": 0.96, "Overall": 0.7106380912162162}, {"timecode": 74, "before_eval_results": {"predictions": ["the Jesuits", "ribonucleic acid", "ketchup", "a house", "a house fly", "construction boots", "Former Texas governor", "Burma", "Latvia", "the spleen", "auf wiedersehen", "rely", "Ramesses II", "wine", "the esophagus", "Super Bowl VI", "the Bible", "twist", "Marie Tussaud", "Biscay", "the Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "a brothel", "a potato", "The Aviator", "Gioachino Rossini", "Veracruz", "a tail", "Nashville", "c.150 BC", "the Starfighter", "Billy Crystal", "skin cancer", "(Henry) Ford", "kbec", "pontificio", "Kathy Kinney", "Fiji Islands", "Moonlighting", "Corpus Christi", "Homer", "Ruth Bader Ginsburg", "Edward R. Murrow", "the Bay of Bengal", "in vitro fertilisation", "Diogenes of Sinope", "pastries", "Whatchamacallit", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "Helen Reddy", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Don Johnson", "giving birth to baby daughter Jada,", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5826522435897435}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.923076923076923, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-6585", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_hotpotqa-validation-4363", "mrqa_newsqa-validation-801"], "SR": 0.46875, "CSR": 0.5333333333333333, "EFR": 1.0, "Overall": 0.7184635416666667}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2008 -- 2009", "1963", "The Satavahanas", "Central Board of Artisans", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK and Olivia", "28 July 1914 to 11 November 1918", "St. Pauli Girl Special Dark", "908 mbar ( hPa ; 26.81 inHg )", "North Atlantic Ocean", "February 7, 2018", "October 2000", "Lutheran Church of Sweden", "commemorating fealty and filial piety", "Burbank, California", "Richardson", "American singer - songwriter - actress Debbie Gibson", "James Zeebo", "31 January 1934", "at the mayor's home", "southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "function like an endocrine organ", "Kyla Coleman", "Bill Patriots", "December 19, 1971", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Partridge", "On April 3, 1973, Martin Cooper, a Motorola researcher and executive, made the first mobile telephone call from handheld subscriber equipment, placing a call to Dr. Joel S. Engel of Bell Labs, his rival", "Saint Etienne", "`` 200 lakh rupees ''", "Chuck Noland", "many forested parts", "arithmetic", "Shooting Glove", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "President Felipe Calderon", "low-calorie meals that he could prepare.", "0-0 draw", "Hapsburg", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6592302946819754}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.9795918367346939, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9428571428571428, 1.0, 0.5, 1.0, 0.5714285714285715, 0.6, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.888888888888889, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.4, 0.17647058823529413, 0.0, 0.5, 1.0, 0.6, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-1646"], "SR": 0.484375, "CSR": 0.532689144736842, "EFR": 0.9696969696969697, "Overall": 0.7122740978867623}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "victim blaming", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "sovereign states", "Authority", "Jughead Jones", "Los Lonely Boys", "ecological regions", "cakes", "Kiss", "England", "Julie Adams", "During World War II", "Anthony Quinn as Craig Belden", "January 2004", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "Oscar", "Tennessee Titan", "Judy Collins", "southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Chasty Ballesteros", "an anembryonic gestation", "It acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "champagne", "IV", "Virginia", "Saphira hatches from the stone, which was really an egg", "September 2017", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "Ace", "Spike", "regulatory site", "After divulging this truth, Slayer gives up on singing and dances so frenetically that she begins to smoke -- on the verge of combusting as Sweet's other victims have been shown to do --", "Aegisthus", "InterContinental Hotels Group", "the Balkan peninsula", "Jason Flemyng", "a mountainous, peninsular mainland jutting out into the Mediterranean Sea at the southernmost tip of the Balkans, and two smaller peninsulas projecting from it", "Norman Mailer", "vickers Vimy", "EMI", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million", "San Diego,", "CNN.com", "jazz", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7040324642462801}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 0.8181818181818181, 0.08333333333333334, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.33333333333333337, 0.0, 0.5, 0.4, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.72, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.4444444444444445, 0.6153846153846153, 1.0, 1.0, 1.0, 0.05714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 0.09523809523809523, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-4571", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-14736"], "SR": 0.578125, "CSR": 0.5332792207792207, "EFR": 0.9259259259259259, "Overall": 0.7036379043410294}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 8", "Live and Let Die", "Alessandro di Mariano Filipepi", "metal", "pulsar", "Seth", "Honda", "\"Erroneous\"", "Ozzy Van Halen", "It's True", "the 2010 FIFA World Cup", "Elizabeth I", "June", "Italy", "1960's", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "rum", "apple", "Arbroath", "Roddy Doyle", "discus thrower", "Separate Tables", "the sound of the human voice could be reproduced,", "Beatrix Potter", "Magpie", "the comets", "skating", "Kansas City", "Ra\u00fal Castro", "Space Oddity", "Scotland", "UK Butterflies", "Illinois", "red", "Splash", "South Africa", "menorah", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "native to Asia", "Liam Cunningham", "Foofa", "Fuenlabrada", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "Saint Bernard", "France", "Barnard College", "the equator,"], "metric_results": {"EM": 0.625, "QA-F1": 0.6677083333333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.625, "CSR": 0.5344551282051282, "EFR": 1.0, "Overall": 0.7186879006410256}, {"timecode": 78, "before_eval_results": {"predictions": ["Japan", "Granada", "Verdi", "April", "Al Pacino", "Mohanda Karamchand", "hard", "William Golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "Director General of the Security Service", "Hell Upside Down", "Funchal", "hobbit", "pasta joke", "Northern Ireland", "passport", "Marcel Duchamp", "The Quatermass Experiment", "Mumbai", "a statue", "1875", "raven", "hound", "Sue", "Estimate", "non-negative", "Narendra Modi", "Richard Wagner", "quentin tarantino", "Argentina", "woman", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "steppes steppe", "Romania", "brindisi", "Muriel Bing", "Emeril Lagasse", "Casino Square", "Darrin Stephens", "springtime for Hitler", "Holocaust memorial", "Eva Herzigov\u00e1", "j.B.Priestley", "Ireland", "numbit", "Carrie", "Colombia", "rolling hillsides", "the anterolateral corner of the spinal cord", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "English folk-song", "Martin O'Malley", "1992", "sculptures", "Sunday's", "Kenyan forces who have entered Somalia,", "The Old Man and the Sea", "Edward I", "the Cranberries", "Air traffic delays began to clear up Tuesday evening after computer problems left travelers across the United States waiting in airports,"], "metric_results": {"EM": 0.5, "QA-F1": 0.579547443977591}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.35294117647058826, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25000000000000006, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1306", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5155", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-35", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-2327", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.5, "CSR": 0.5340189873417722, "EFR": 1.0, "Overall": 0.7186006724683545}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "frisian", "amethyst", "Libya", "tomato", "Kyoto Protocol", "Fancy Dress Shop", "Bull Moose Party", "examination", "Jake La Motta", "resistance", "hanie McDaniel", "South Africa", "indigestion", "discretion", "charlie croker", "Apprentice", "George Washington", "Corinth", "human rights lawyer", "Iceland", "ascot", "pearls", "kris Jenner", "mafia", "doe", "Duncan", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby", "Rambo", "Julian WikiLeaks", "IT Crowd", "nastase", "local police officer Rip Nix", "bobby croker", "Richard Curtis", "terms of endearment", "ireland", "lothbrok", "1790", "bay", "chamomile", "driving miss daisy", "orchid", "Hilary Swank", "aberdeen", "latitude 90 \u00b0 North", "the end of the 18th century", "eight hours", "18 minutes", "England", "Nationalism", "\"GoldenEye\"", "Afghanistan's restive provinces", "Rodong Sinmun", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6739004629629629}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29629629629629634, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6562", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5872", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-5333", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.578125, "CSR": 0.5345703125, "EFR": 1.0, "Overall": 0.7187109375}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2", "dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "Canadian Rockies continental divide east to central Saskatchewan", "H CO ( equivalently OC (OH ) )", "Miami Heat", "began on March 29, 2018, and is scheduled to end on September 30", "four", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas, or tolled ( quota ) highways", "0.05 ( 5 % )", "Tom Burlinson, Red Symons and Dannii Minogue", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Corey Taylor", "Bonanza Creek Ranch", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "Director of National Intelligence", "Michael Crawford", "onoma tou Patros kai tou Huiou kai Tou Hagiou Pneumatos", "Kida", "September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market ( FX )", "Coppolas and, technically, the Farrow / Previn / Allens", "The Sunday Post", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Ringo Starr", "to be free, and to get there, he launches his house into the sky thanks to thousands of balloons.", "boyhood experience in a World War II internment camp", "off east  Africa", "modify", "olly ringwald", "petticoats", "skull and crossbones"], "metric_results": {"EM": 0.625, "QA-F1": 0.7184321691325086}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.631578947368421, 0.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.12903225806451615, 1.0, 0.3333333333333333, 1.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8711", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-5915", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.625, "CSR": 0.5356867283950617, "EFR": 0.9166666666666666, "Overall": 0.7022675540123456}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "CAI", "Cleopatra", "nuclear tests", "capitals", "pizza roll", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "in Las Vegas", "Jenny", "gestation", "ravens", "J.R. R. Tolkien", "James Franco", "the Blue Ridge Mountain range", "British Guiana", "magnet", "buddha", "Apple", "Thomas R. Gray", "a catfish", "A Chorus Line", "Frommer", "Atonement", "regret not speaking", "de Havilland", "Virginia", "College of William and. Mary", "a dog recently recognized by AKC", "Louisiana", "Vassar", "Japan", "silver", "The Police", "Air France", "Scarlatti", "kills his three sons", "trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "yodeling", "Indian Ocean", "a painkiller", "Jean-Paul Marat", "nanosecond", "bats", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "on location", "2010", "drum kit", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Allerdale", "Mugabe's opponents", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.617485119047619}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-6250", "mrqa_naturalquestions-validation-2110", "mrqa_triviaqa-validation-7122", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868"], "SR": 0.546875, "CSR": 0.5358231707317074, "EFR": 0.9655172413793104, "Overall": 0.7120649574222035}, {"timecode": 82, "before_eval_results": {"predictions": ["a submarine", "American", "China", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "a therapist", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "an acre", "Galapagos", "(Frans) Hals", "the Black Sox scandal", "a small cat", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "art nouveau", "autobahn", "Anglo-Saxon", "the California quail", "curtsy", "lacrosse", "Toronto", "diaeresis", "King David", "riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "point plat de Bruxelles", "(Lee) Marvin", "New Brunswick", "Westminster Abbey", "Superbad", "New Hampshire", "1885", "$2.187 billion", "On the west", "belgian", "maqui berry", "The Benedictine Order", "Pansexuality", "co-authorship", "getaway driver", "David Russ", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6925347222222222}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.22222222222222224, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_searchqa-validation-4122", "mrqa_searchqa-validation-4406", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-943"], "SR": 0.59375, "CSR": 0.5365210843373494, "EFR": 1.0, "Overall": 0.7191010918674698}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "the Office", "Jesus", "a penguin", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "Trinity", "Algeria", "Haydn", "Richard Cheney", "the black market", "a number", "Saturday Night Fever", "Japan", "Pizza Napoletana", "a turtle", "the Empire State Building", "White", "a picayune", "dogwood", "Quebec", "Larry McMurtry", "Kellogg", "Helen", "a sweatshirt", "a kilogram", "Napoleon", "wood", "the Arctic area of Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Henkel & Cie", "Pancho Gonzales", "the Aleutians", "the Latter-day Saints", "Jane Grey", "Tommy Tutone", "the crescent moon", "Iraq", "an old grasshopper", "Nicolaus Copernicus", "poblano chiles", "William Safire", "Giovanni Donato da", "the shrine of Saint Thomas Becket at Canterbury Cathedral", "Cecil B. DeMille", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "Theodore Roosevelt Mason", "Parlophone", "9:20 p.m. ET Wednesday.", "DBG", "1995", "four"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6385416666666666}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-11293", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-11669", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-6397", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-502", "mrqa_hotpotqa-validation-3182"], "SR": 0.53125, "CSR": 0.5364583333333333, "EFR": 1.0, "Overall": 0.7190885416666666}, {"timecode": 84, "before_eval_results": {"predictions": ["Georgia", "Henry VIII", "Judas Iscariot", "Windsor, Ontario", "Douglas", "Comrade", "the Great Gatsby", "a foxes", "Sexuality", "Salaries", "Solomon", "John McEnroe", "a bicycle", "Johnson County", "La Fea", "push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "Quezon City", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "a pirate", "engrave", "Daisy Miller", "the Nivernais", "Y", "a ship", "Kamehameha I", "a fox", "Pocahontas", "Jerry Maguire", "the north magnetic pole", "oysters", "an Italian-American", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "season two", "A complex sentence", "40", "Venus", "Nowhere Boy", "August 1973", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Carrefour", "financial gain,", "a Nazi concentration camp,", "\"transgressions\" that had let his family down,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6546875}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-109", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-6178", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-10285", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-11433", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-10841", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_triviaqa-validation-2049", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.578125, "CSR": 0.5369485294117646, "EFR": 1.0, "Overall": 0.719186580882353}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Winnie The Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "The Fountainhead", "Saraswati", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "Strawberry Fields", "The Hague", "Geena Davis", "pharmacy", "( Kit) Carson", "The Guernsey Football Association", "Doolittle", "air", "Martin Clunes", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "money changers", "The X-Files", "Babar the elephant", "Mensa International", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a toddler", "the Church of Jesus Christ of Latter-day Saints", "Veneto", "a watermelon", "the North Atlantic Treaty Organization", "Sparta", "The New York Times", "anode", "boldly go", "The National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "the epidermis", "the Texas Rangers", "Prozac", "H CO ( equivalently OC (OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "pizza,", "her landlord defaulted on the mortgage and the house fell into foreclosure.", "Why he's more American than a German,", "Charles Sherrington"], "metric_results": {"EM": 0.53125, "QA-F1": 0.578125}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-10138", "mrqa_searchqa-validation-4035", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-6063", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-15693", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-610", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-11773", "mrqa_searchqa-validation-10056", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2692"], "SR": 0.53125, "CSR": 0.5368822674418605, "EFR": 1.0, "Overall": 0.7191733284883721}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a horse", "a real animal", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "the Palatine hill", "California", "the Mississippi", "Alpha", "Quebec City", "nacre", "the Texas Chainsaw Massacre", "the rotunda", "a Medal of Honor", "Manet", "Plutarch", "Milan", "Celia", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "Millard", "chino", "Finnegans Wake", "alamu", "the black market", "professor", "seismic waves", "Maastricht", "Delilah", "synapses", "a croissant", "Mexico", "the lungs", "fuchsia", "metacarpal", "a pool", "Warsaw", "a trowel", "Mercury", "China", "Gettysburg", "Ibtihaj Muhammad", "trout", "a farce", "1959", "season two", "$75,000", "Zimbabwe", "15", "stonemason's Yard", "Agent Carter", "Orson Welles", "Manhattan", "56", "Secretary of State", "Bright Automotive", "James Hogg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6510416666666666}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-16661", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.609375, "CSR": 0.5377155172413793, "EFR": 0.96, "Overall": 0.7113399784482759}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "$72", "Walmart", "Scott Schwartz", "Milan", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Harry Kane", "Francis Ford Coppola", "$66.5 million", "helps digestion by breaking the bonds linking amino acids", "slavery", "The Osmonds", "a political pamphlet", "Federated States of Micronesia", "Anakin Skywalker", "Jeff East", "one", "Thomas Lennon", "Ed Roland", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "Washington", "the 6th century AD", "Triple threat", "in his first year at the Hogwarts School of Witchcraft and Wizardry", "shared", "foreign investors", "Louis XVIII", "the inverted - drop - shaped icon that marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool", "Robber baron", "December 20, 1951", "Crick", "Mount Aconcagua", "Bake Off", "1924", "Eugene Levy", "Aldosterone", "Nicole Kidman", "last summer.", "inspiring", "Longo-Ciprelli", "banker", "an eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6123014498673865}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5925925925925926, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2524", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.515625, "CSR": 0.5374644886363636, "EFR": 0.9032258064516129, "Overall": 0.6999349340175953}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff", "a bag", "Federer", "Veracruz, Mexico,", "Diego Milito's", "\"The harder they squeeze and squish that breast, the less tissue the X-rays have to go through and the more likely they are to find something.\"", "\"The three were seized early Monday after police raided a bus station in Sargodha, a city located about 120 miles (190 km) south of Islamabad in Pakistan's Punjab province.", "Salt Lake City, Utah,", "normal maritime traffic", "Drottningtorget", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "arrested three men with suicide vests who were plotting to carry out the attacks,", "\"It is big and red and I hope that Russia and the United States, and other countries will never press on another button which used to be associated with a destructive war,\"", "club managers", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "At least 14", "\"It hurts my heart to see him in pain, but it enlightenedens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Dr. Albert Reiter,", "the Defense of Marriage Act", "Europe", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Greeley, Colorado,", "a grocery store", "flying glass and rocks.", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million", "Krishna Rajaram,", "North Korea", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "Turkey can play an important role in Afghanistan and Pakistan -- not the kind of society the Taliban has been providing.", "the Yemeni port city of Aden", "federal officers", "\"Beverly Hills Chihuahua\"", "central business district of Bangkok", "journalists and the flight crew will be freed,", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England", "chicken livers", "Sleyman", "woodland", "Ramadan"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6048757273687547}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.058823529411764705, 1.0, 0.8, 1.0, 0.13333333333333333, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.9655172413793104, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.0, 0.07692307692307693, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.27586206896551724, 0.0, 0.8, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-3441", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763", "mrqa_searchqa-validation-6846"], "SR": 0.484375, "CSR": 0.5368679775280899, "EFR": 0.9696969696969697, "Overall": 0.713109864445012}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Kim So-hyun", "president", "\"talking Dead\"", "9\u201310 March 1945,", "2011", "John D Rockefeller", "during the early 1970s", "Asiana Town", "American R&B", "Rockland County", "Manitowoc County, Wisconsin", "21 kilometres south-east of Adelaide, in the Adelaide Hills.", "20 June 1967", "alcoholic drinks for consumption on the premises", "Fiat Chrysler Automobil NV", "Chrysler", "South Australia", "gorillas", "\"Traumnovelle\" (\"Dream Story\")", "The Royal Navy", "Robert Digges Wimberly Connor", "Yitzhak Edward Asner", "the Beatles and the Rolling Stones", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "\"Rated R\" (2009)", "95 AD", "1614", "French", "\"The Manhunter from Mars\"", "Mondays", "Michael Jordan", "Snowball II is killed off,", "Bank of China Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "1822", "\"Smile, Mom\" (2010)", "Suspiria", "\"The Independent\"", "Kansas\u2013Nebraska Act", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "elbow", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "Piers Morgan Tonight", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "for housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6282986111111111}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444444, 0.8, 0.8, 0.0, 1.0, 1.0, 0.2222222222222222, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-1573", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-3752", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-3198", "mrqa_hotpotqa-validation-5440", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-7701", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.53125, "CSR": 0.5368055555555555, "EFR": 0.9666666666666667, "Overall": 0.7124913194444444}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2002", "singer", "Pakistan", "1754", "\"Confessions of a Teenage Drama Queen\"", "VfB Stuttgart", "d\u00edsabl\u00f3t", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia,", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "London Heathrow", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama,", "Scandinavian design", "Mike Pence", "Barack Obama's", "bi-fuel", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian Church", "138,535", "Ry\u016bky\u016ban", "1972", "Stern-Plaza in Potsdam", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "Mexico", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "kite surfers", "Robert", "Valentina Tereshkova", "Hombre", "CO2", "Toilet Duck"], "metric_results": {"EM": 0.546875, "QA-F1": 0.626730595039019}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 0.30434782608695654, 0.0, 1.0, 1.0, 0.2564102564102564, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-3261", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_triviaqa-validation-4655", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.546875, "CSR": 0.5369162087912087, "EFR": 0.9655172413793104, "Overall": 0.7122835650341038}, {"timecode": 91, "before_eval_results": {"predictions": ["Wings of Desire", "the iTunes Store", "sedans", "the Gateway Arch", "Friday", "Sabino Canyon", "Johnny Depp", "Babe Ruth", "\"The Home and Family\"", "Arkansas", "Cus D'Amato", "Virgo", "contemporary and modern art", "the Prairie Wolf", "bcolicus", "Michael Jackson", "Hydrogen", "Johnny Cash", "Hodgkin\\'s", "Margaret, Countess of Snowdon", "Las Vegas", "San Francisco", "the Razor's Edge", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "the Wright Brothers", "Taekwondo", "John Deere", "Elizabeth Barrett Browning", "Pontiac", "Reptiles", "Georgia Bulldogs", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "hardwood", "Alice Walker", "F Troop", "Russia", "he's wrong.", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Iraq", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a spirit-lifting jingle", "Pat Houston", "bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "Texas A&M Offshore Sailing Team", "Monday", "23", "a English Wesleyan minister and biographer"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5424479166666666}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false], "QA-F1": [0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-1820", "mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-13521", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-3331", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-10866", "mrqa_searchqa-validation-7246", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_triviaqa-validation-1585", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-979", "mrqa_hotpotqa-validation-4539"], "SR": 0.421875, "CSR": 0.5356657608695652, "EFR": 0.972972972972973, "Overall": 0.7135246217685076}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Constantin Brancusi", "Quantico Virginia", "the East", "Shakespeare", "Shakespeare", "alb ale ali", "Chelmsford", "Sputnik I", "Richmond", "the early predecessors of program music", "Java", "baritone", "Reginald", "Indivisible", "Room-temperature", "Wuthering Heights", "Muhammad", "September 20, 1934", "Pirates of the Caribbean: Dead Man's Chest", "Charles de Gaulle", "Chesterfield", "a chipmunk", "Josephine", "chocolate", "Spousal privilege", "Rossini", "Oman", "Lapland", "Tom Canty", "Roman Polanski", "Joan Didion", "the frigate Alliance", "Baltimore", "the Bay of Bengal", "button", "Democrats", "Terrific", "geology of Mars", "six", "Olympia", "the Ship of Fools", "Haunted Zone", "tendang", "bodily fluid", "Margaret Mitchell", "Frances", "Vin Diesel", "Cremation", "the French & Indian War", "a manic episode", "central Saskatchewan", "lighter", "a scuffle with the Beast Folk", "Judi Dench", "Germany", "Caernarfon", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy\" (2010)", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5576073232323232}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-6225", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-12499", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-459"], "SR": 0.453125, "CSR": 0.5347782258064516, "EFR": 0.9428571428571428, "Overall": 0.707323948732719}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Telma Hopkins", "Mel Gibson", "1947, 1956, 1975, 2015 and 2017", "drivers who were 2016 Pole Award winners, former Clash race winners, Former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "at the intersection of Del Monte Blvd and Esplanade Street", "Goku's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form", "Audrey II", "the January 2017 patch", "NIRA", "1922", "Julie Deborah Kavner", "Justin Timberlake", "American production duo The Chainsmokers", "13 May 1787", "New York ( from James's English title )", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3", "McFerrin", "Napoleon", "Azizul Haque", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Jupiter", "hyperinflation", "1939", "Richard Masur", "Glenndon Chatman", "Tagalog", "Sauron", "Lana Del Rey", "if the player busts, the player loses, regardless of whether the dealer subsequently busts", "159", "Sino - Indian War of 1962 exposed weaknesses in the economy and shifted the focus towards the defence industry and the Indian Army", "Chemistry professor E.H.S. Bailey and his colleagues were returning by train to Lawrence after a conference", "works in a bridal shop", "increases the life of the pump, allows a smaller and lighter device to be used, and reduces electrical load", "a limited period of time", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood\\'s A Holy Grail", "nest", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "The Da Vinci Code", "\"She will stand next to Mark emotionally, but she cannot stand in the glare of others,\"", "Khrushchev", "( Julie) Andrews", "Ichabod Crane", "Leo Frank,"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6863806030925597}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.8571428571428572, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7272727272727273, 0.17391304347826086, 0.30769230769230765, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-105"], "SR": 0.609375, "CSR": 0.5355718085106382, "EFR": 0.92, "Overall": 0.7029112367021277}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "ThonMaker", "Battle of Chester", "youngest TV director ever", "28 January 1864", "Utnapishtim, the far-away", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "the Netherlands", "rural areas", "number 8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "CMYKOG", "Las Vegas Boulevard", "intelligent design", "Barbara Ryan Coleman", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park.", "Uzumaki", "Kansas", "nearly 80 years", "Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "\"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "disco fox", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "shorthand writing", "June 26, 2018", "Commonwealth Universities", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "giant planet", "alveolar bone", "Dortmund - Ems Canal", "Hugh Quarshie", "king johnny ii", "Tokyo", "Utah Valley Regional Medical Center", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7366154100529101}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.47619047619047616, 1.0, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.609375, "CSR": 0.5363486842105263, "EFR": 0.96, "Overall": 0.7110666118421053}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies worldwide", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1951", "Roy Spencer", "1964", "Kansas City, Missouri", "World of Wonder", "January", "Russian", "James Coburn", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "Northern Lights", "coca wine", "Mach number", "Days of our Lives", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "The Gang", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor at some institutions in the United Kingdom and Ireland, or a Deputy Vice-Chancellor (Academic) at most Australian universities", "Song Il-gon", "Teen Titans Go!", "Mickey Mouse Cup", "Grammy Award", "left-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "seal hunting", "Houston Rockets", "DI Humphrey Goodman", "The Rite of Spring", "Nebraska Cornhuskers women's basketball", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrus", "Compiegne", "La traviata", "April.", "The Da Vinci Code", "Dogpatch Labs", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6480902777777777}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-1059", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-181", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-2388", "mrqa_triviaqa-validation-1490", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503"], "SR": 0.578125, "CSR": 0.5367838541666667, "EFR": 1.0, "Overall": 0.7191536458333334}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "Willie Nelson and Kris Kristofferson", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "the Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "the Games of the Olympiad", "Oldham County", "1896", "Oracle Corporation", "143,007", "severe acute respiratory syndrome (SARS)", "5.3 million", "chocolate-colored Labrador Retriever", "Graham Hill", "1952", "Neneh Mariann Karlsson", "Eminem", "Love Streams", "In a Better World", "the Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "imp My Ride", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "a wooden Indian", "John Francis Kelly", "early Romantic period", "approximately $700 million", "the Sun", "Bhushan Patel", "1692", "interstate commerce", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "isosceles", "put a lid on the marking of Ashura", "Pakistan", "homicide", "bread stuffing", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.671875, "QA-F1": 0.815588924963925}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.5, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-13280"], "SR": 0.671875, "CSR": 0.5381765463917525, "EFR": 0.9523809523809523, "Overall": 0.7099083747545409}, {"timecode": 97, "before_eval_results": {"predictions": ["The Theory of Everything", "the Caucasus range", "David Bowie", "John Spencer", "Granada", "Treaty of Brest-Litovsk", "(Karl) Marx", "Procol Harum", "Wallis Warfield Simpson", "cyanoguttatus", "1957", "1912", "transsexual", "Fred Astaire", "south of England", "Scotland Yard", "Inverness-shire", "Friday\\'s child", "a airplane", "Rudyard Kipling", "1921", "Hamish Macbeth", "Desdemona", "avocat", "Frans Hals", "New Democracy", "Ford", "garbanzo", "Frank Sinatra", "1826", "w WJacobs", "the Parthenon", "Paddy Doherty", "Thomas Aquinas", "ap\u00e9ritif", "an elephant", "Tigran Petrosyan", "right sheik", "Westminster Abbey", "Canada", "Sheidi Klum", "Edward VII", "Tombstone", "S\u00e3o Miguel Island", "Mr. Tickle", "worcester Cathedral", "Mercury", "December 7, 1941", "the stapes", "Nadia Comaneci", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "VAQ-135", "95 AD", "170", "\"Californiaornication\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.421875, "QA-F1": 0.48385416666666664}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7127", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-3538", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-3536", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.421875, "CSR": 0.5369897959183674, "EFR": 0.972972972972973, "Overall": 0.7137894287782681}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan", "geologists have found evidence that soldiers from Hitler's Wehrmacht -- the German armed forces -- had been there: machine guns, parts of uniforms and explosives that are on display at the town's museum.", "The two-year probe, dubbed Operation Swiper, involved physical surveillance, intelligence gathering and court-authorized electronic eavesdropping on dozens of telephones in which thousands of conversations were intercepted,", "his health and about a comeback.", "poems", "then-Sen. Obama", "two women", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Former Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.", "Phillip A. Myers.", "I couldn't speak.", "to share personal information.", "Argentinean and 255 British", "a Yemeni cleric and his personal assistant,", "Iraqi Prime Minister Nouri al-Maliki", "France", "did not speak to those who had gathered but shadow-boxed to spectators and cameras before meeting his distant relatives.", "Because both Klein and Arnold carry a single gene for their type of skeletal dysplasia,", "Pacquiao returned home to a hero's welcome in his native Philippines on Friday after wresting the WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.'", "Austin, Texas,", "17-month", "to pay him a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party centered around Rush Limbaugh.", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "American Bill Haas", "used cars", "28", "step up.\"", "42 years old", "since 1983", "health ailment or beauty concern.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "I heard they were doing a new \"Friday the 13th,\"", "\"We take this issue seriously,\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "18th", "Haeftling", "Armenia", "Asuka", "Bart Millard", "nismo", "stone arch", "jMW turner", "the Marx Brothers film", "Indian", "early 20th-century Europe", "a (department manager)", "Shakespeare in Love", "W. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5740896412585716}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.15151515151515152, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.8333333333333333, 0.0, 1.0, 1.0, 0.8, 1.0, 0.4, 0.5, 1.0, 0.0, 0.1904761904761905, 0.2857142857142857, 0.19354838709677416, 1.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9090909090909091, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2182", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-2610", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-3208", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191"], "SR": 0.4375, "CSR": 0.5359848484848485, "EFR": 0.9166666666666666, "Overall": 0.7023271780303031}, {"timecode": 99, "UKR": 0.73046875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.76171875, "KG": 0.5046875, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "North Dakota", "most performed song of all time", "Oregon Ducks", "Arkansas", "2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "Pain Language", "Broadcasting House in London", "London Tipton", "sitcom", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle cities", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Kang and Kodos", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "\"Sonic\" Smith", "Naval Weapons Station Yorktown", "North African Arab", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Americas and the entire South American temperate zone", "Sister, Sister", "five-time", "Steve Coogan", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Zappa", "1991 model year", "apples", "Fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Mario Balotelli", "Friday,", "Lifeboat", "a megabytes", "a stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7416866987179487}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 0.3333333333333333, 0.25, 0.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.6666666666666666, 0.05128205128205128, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-2863", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.578125, "CSR": 0.53640625, "EFR": 1.0, "Overall": 0.70665625}]}