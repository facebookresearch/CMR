{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4470, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "the Grand Annual Steeplechase at Warrnambool", "the Paleoproterozoic eon", "the end", "1894", "French Rhin", "the Pacific", "the highest quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "teaching", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "from \u00a315\u2013100,000", "the Purus Arch", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "in series 1", "the chief electrician position", "lower incomes", "Luther states that everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "outrage from child protection and parental rights groups", "the Masovian Primeval Forest", "the days, weeks and months after it happened", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "the problem of squaring an integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "his granddaughter Susan Foreman", "Killer T cells", "Mr Ratti's solvent and varnish business", "More than 1 million", "2011", "inequality is driven by this price", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Buddhism", "Matthew 16:18", "the U.S. ship that was hijacked off Somalia's coast", "Wwanda", "the three-day festival has been canceled", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7017754814629815}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.6666666666666666, 0.1904761904761905, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-7566", "mrqa_squad-validation-9243", "mrqa_squad-validation-9530", "mrqa_squad-validation-2052", "mrqa_squad-validation-7763", "mrqa_squad-validation-2732", "mrqa_squad-validation-4276", "mrqa_squad-validation-7728", "mrqa_squad-validation-1285", "mrqa_squad-validation-2520", "mrqa_squad-validation-2035", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-7717", "mrqa_squad-validation-4274", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_squad-validation-8014", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-1908", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.578125, "CSR": 0.703125, "EFR": 0.9629629629629629, "Overall": 0.8330439814814814}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50% of the population to die", "mountainous areas", "the coast of Denmark", "quantum mechanics", "On Tesla's 75th birthday in 1931", "Distinguished Service Medal", "30", "Virgin Media", "the destruction of Israel and the establishment of an Islamic state in Palestine", "its main method of locomotion", "each six months", "Japanese", "the Electorate of Saxony", "Mark Twain", "the European Parliament and the Council of the European Union", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "a multi-party system", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "its compilation of a vast institutional compendium named Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two-page", "the Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "in the coming decades, pharmacists are expected to become more integral within the health care system", "declare martial law and sent the state militia to maintain order", "a customs union, and the principle of non-discrimination", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Ricky Martin \u2013 \"Livin' la Vida Loca / The Cup of Life / Mar\u00eda\"  * Spice Girls", "the ten stages of corporate life cycle, starting with Courtship and Infancy and ending in Bureaucracy and Death?", "the company's factory in Waterford City, Ireland", "nitrogen", "Nolan, WB Reteam for Sci-Fi Actioner Inception, and a Producers Guild of America Award, with Thomas and Charles Roven.", "Haraboard", "six Oscars, including Best Picture, Best Actor in a Leading Role (Hanks) and Best Director (Robert Zemeckis)", "It always begins with the music, of course. The tune sticks with you long after the song is over; the sort of tune that makes it almost impossible to sit still", "Natural Opera  Rigoletto  TV Series performer", "Illinois", "Rafael Palmeiro Corrales", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.6875, "QA-F1": 0.7561076423576423}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.09999999999999999, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5067", "mrqa_squad-validation-1637", "mrqa_squad-validation-9600", "mrqa_squad-validation-4437", "mrqa_squad-validation-4546", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-8316", "mrqa_squad-validation-8159", "mrqa_squad-validation-7949", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936"], "SR": 0.6875, "CSR": 0.6979166666666667, "EFR": 1.0, "Overall": 0.8489583333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "christopher saints", "Britain", "23", "a shortage of male teachers", "charleston", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President", "2000", "oxygen", "increase local producer prices by 20\u201325%", "the Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "the 50 fund", "integer factorization problem", "necessity", "Isel", "adapted quickly and often married outside their immediate French communities", "travis", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "charlasts", "the late 19th century", "the Channel Islands", "in no way", "Alberich", "charleston", "travis", "Churchill Downs", "charleston", "charleston", "1951", "Colombia", "study insects and their relationship to humans", "travis", "travis", "George Fox", "Washington, DC", "charleston", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.65625, "QA-F1": 0.6750868055555556}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-2032", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-1581", "mrqa_hotpotqa-validation-3821"], "SR": 0.65625, "CSR": 0.6875, "EFR": 0.9545454545454546, "Overall": 0.8210227272727273}, {"timecode": 4, "before_eval_results": {"predictions": ["in plants that contain them", "Parliament of Victoria", "Zaha Hadid", "Fort Edward", "Science and Discovery", "Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "Battle of Olustee", "at the port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "Roman Catholic", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "In 1700 several hundred French Huguenots migrated from England to the colony of Virginia", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "freely available on the web", "the Song dynasty", "2010", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "guzzanti", "22", "terror groups", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "new model is simply out of their reach", "Muslim", "will auction off one of the earliest versions of the Magna Carta later this year", "a unit of Time Warner", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "FBI Special Agent Daniel Cain", "mike atherton", "one", "celebrity-inspired", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "mike atherton"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6979040138782786}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.15999999999999998, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-7094", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3195", "mrqa_squad-validation-3733", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.671875, "CSR": 0.684375, "EFR": 1.0, "Overall": 0.8421875}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a data network based on this voice-phone network", "roughly 500,000", "Ofcom", "Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches", "2011", "algae", "a way of reminding their countrymen of injustice", "June 1978", "Milton Latham", "1914", "Philippines", "Denver's Executive Vice President of Football Operations and General Manager", "the 1970s", "the political and economic advantage over a land and the indigenous populations they control,", "German Te Deum", "1795", "Bermuda 419", "air could be liquefied, and its components isolated, by compressing and cooling it", "Infinity Broadcasting Corporation", "\"semi-legal\"", "1972", "rudimentary immune system, in the form of enzymes that protect against bacteriophage infections", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "It is mainly for the purpose of changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "an Ohio newspaper on 8 February 1925", "Herbert Hoover", "cannonball", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey", "the un security council get troops for military actions", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "three", "9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "the present ( 2016 -- 2018, contemporaneous with airing ) and a storyline taking place at a set time in the past ; but some episodes are set in one time period or use multiple flashback time periods", "Morgan Freeman", "David Gahan", "The Stanley Hotel", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "Jonas", "Jaipur", "Jonas Olsson", "a small and fast naval ship designed to carry torpedoes into battle", "garland"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6879869599354894}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.56, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 0.45454545454545453, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5833333333333334, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-376", "mrqa_squad-validation-9908", "mrqa_squad-validation-3473", "mrqa_squad-validation-6450", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.578125, "CSR": 0.6666666666666667, "EFR": 0.9259259259259259, "Overall": 0.7962962962962963}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "always more expensive than their public counterparts", "an antigen from a pathogen", "their disastrous financial situation", "making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "\"social and political action,\" declared that \"To perform its mission in the society, a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures.\"", "1936", "New Birth", "gold", "a deficit", "178 Vivienne Westwood", "reduction", "disease", "GIIF", "Confucian propriety and ancestor veneration", "rediscovery of \"Christ and His salvation\"", "five", "the European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live and 5 Live Sports Extra", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members, conducting hearings into allegations of professional misconduct and taking appropriate disciplinary action and accrediting teacher education programs", "end of the season", "10", "Jonas", "African-Americans", "will not support the Stop Online Piracy Act", "Chuck Bass", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer, can put users in a dazed stupor for about two hours, doctors said.", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea", "the first five Potter films have been held in a trust fund which he has not been able to touch.", "their cars have chosen their rides based on what their cars say about them", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "a \"stressed and tired force\" made vulnerable by multiple deployments", "James Whitehouse, has been quoted as saying she has terminal brain cancer, according to a blog called Manson Family Today.", "instability in the Maersk Alabama is being held by pirates on a lifeboat off Somalia.", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Jody Rosen of Rolling Stone", "Mike Gatting", "a private liberal arts college", "Church of Christ, Scientist", "a fat or fatty acid in which there is at least one double bond within the fatty acid chain", "New Testament"], "metric_results": {"EM": 0.53125, "QA-F1": 0.619559685965694}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.4444444444444445, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.25, 0.2, 0.5, 1.0, 0.5, 0.25, 0.3636363636363636, 0.13333333333333333, 1.0, 0.16666666666666669, 0.0, 0.16, 0.0, 0.3636363636363636, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.45454545454545453, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7114", "mrqa_squad-validation-1255", "mrqa_squad-validation-7950", "mrqa_squad-validation-5441", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-769", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_naturalquestions-validation-7683", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.53125, "CSR": 0.6473214285714286, "EFR": 1.0, "Overall": 0.8236607142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["the 1970s", "his friendship", "increased", "187 feet", "pH or available iron", "90\u00b0", "materials", "$100,000", "Stanford Stadium", "baptism", "Jim Gray", "PSPACE", "July 1969", "hiding a Jew in their house", "prolamellar body", "spontaneous", "the courts of member states", "gold", "Time Lord", "Buckland Valley", "Scottish rivers", "ricks for Warsaw", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "their \"Freshman Year\" experience", "United States", "Benazir Bhutto,", "Lindsey oil refinery", "April 24", "Krishna Rajaram,", "early detection and helping other women cope with the disease.", "as many as 250,000", "Timothy Masters,", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "William S. Cohen", "\"Dancing With The Stars\"", "some Guant Bay detainees", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "seeking help", "Japanese officials", "patrolling the pavement", "\"Empire of the Sun\"", "the Norman given name Robert", "the Olympics", "Matthew Ward Winer", "lenardo", "the Baltic Sea", "Mustique", "green"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6304533140470641}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.45454545454545453, 0.0, 1.0, 0.5333333333333333, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.5714285714285715, 1.0, 0.3636363636363636, 0.4, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.05555555555555555, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-4067", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-8883", "mrqa_squad-validation-3938", "mrqa_squad-validation-7587", "mrqa_squad-validation-872", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_searchqa-validation-7977"], "SR": 0.53125, "CSR": 0.6328125, "EFR": 0.9666666666666667, "Overall": 0.7997395833333334}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "that any French residents who chose to remain in the colony would be given freedom to continue worshiping in their Roman Catholic tradition, continued ownership of their property, and the right to remain undisturbed in their homes", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday afternoon", "\"Journey's End\"", "immediate", "Levi's Stadium", "decidedly Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "in variety of ways in different languages", "Aristotle and Archimedes", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th most-populous", "random access machines", "ensure that the prescription is valid", "the Stockton and Darlington Railway", "autonomy", "it is \"the largest center for breeding and exporting terrorism.\"", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "it was to be reunited with his American father.", "Animal Planet", "fake his own death by crashing his private plane into a Florida swamp.", "there were no radar outages and said it had not lost contact with any planes during the computer glitches.", "54 bodies", "early detection", "Diversity", "$250,000", "break up ice jams.", "Nazi Germany", "March 27 at 4:30 p.m. ET", "The Kirchners", "involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "as soon as 2050", "Alfredo Astiz,", "Abdullah Gul,", "Briton Carl Froch", "Everglades,", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans", "Henrik van Oosting's", "\"The perfect is the enemy of the good\"", "that you were married to a very brilliant man?", "give away T.J. Oshie, a former first-round"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6575881736727325}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.6538461538461539, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-9903", "mrqa_squad-validation-6300", "mrqa_squad-validation-10341", "mrqa_squad-validation-5586", "mrqa_squad-validation-1083", "mrqa_newsqa-validation-1219", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-3111", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.578125, "CSR": 0.6267361111111112, "EFR": 0.9629629629629629, "Overall": 0.794849537037037}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"hoos\"", "50%", "\"All I can say is that the Natives of these localities are very badly disposed towards the French, and are entirely devoted to the English.", "San Diego", "CRISPR", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement", "the Edict of Fontainebleau", "15", "\"The U.S. program to assassinate terrorists in Iraq.", "Ronaldinho", "\"global security, prosperity and freedom.\"", "25", "a treadmill", "the couple's surrogate lost the pregnancy.", "environmental and political events", "\"he was preparing the country for war and death, and to hand power to Kim Jong Un,\"", "at least two and a half hours", "Elin Nordegren", "New York City", "6,000", "a drug test after a Serie A game at Roma which returned a positive result.", "President Clinton", "\"two sides to every story -- sometimes three\" and he was confident the legal system would work in Harris' favor.", "MDC head Morgan Tsvangirai.", "\" policing the world and Africa in particular?\"", "future relations with Washington", "a canyon in the path of the blaze", "Zuma", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail,", "school, their books burned,", "strife in Somalia", "Ayelet Zurer and Ewan McGregor", "Columbia Police Department.", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "that a UH-60 Blackhawk helicopters crashed in northeastern Baghdad as a result of clashes between U.S.-backed Iraqi forces and gunmen.", "London", "after Shawn's kidnapping", "a people", "William Tell", "OutKast", "Groundhog Day", "Cleopatra", "a fairground"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6147721723824664}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.1081081081081081, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-10185", "mrqa_squad-validation-2429", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-11812"], "SR": 0.546875, "CSR": 0.61875, "EFR": 0.9655172413793104, "Overall": 0.7921336206896552}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan's", "heating water to provide steam that drives a turbine connected to an electrical generator", "internal strife", "yellow fever outbreaks", "DC traction", "The Prince of P\u0142ock,", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital.", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "broken pelvis", "issued his first military orders as leader of North Korea", "heavy snow and ice", "Gainsbourg", "\"Maude\"", "Phillip A. Myers", "Korea", "two weeks after Black History Month", "58", "two Metro transit trains", "last summer.", "Noriko Savoie", "Spc. Megan Lynn Touma", "Hyundai Steel", "Sharp-witted. Direct. In control. Loyal.", "Chinese President Hu Jintao", "Christian", "injuries,", "October 3,", "is back at his Premier League club side Wigan Athletic in northern England.", "Larry Zeiger", "shock", "President Bush", "\"green-card warriors\"", "2,800", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "is is the German Food Guide", "is a 2016 American-Indian-Irish computer-animated comedy-adventure film directed by Trevor Wall", "James Lofton", "is a glossary of spirituality terms", "whip-like"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5776405885780885}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-3418", "mrqa_squad-validation-1299", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-13", "mrqa_newsqa-validation-4180", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-1551", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.515625, "CSR": 0.609375, "EFR": 1.0, "Overall": 0.8046875}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "The combination of hermaphroditism and early reproduction", "Victoria Department of Education", "the FBI ordered the Alien Property Custodian to seize", "Manned Spacecraft Center", "higher economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks,", "Elway", "Philo", "36", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "the number 1 lacks", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "Agnes Wickfield", "the Clangers", "antelope", "nipples", "the Triassic", "Pio-  neers' Society, Ltd.", "Anastasia Dobromyslova", "gagapedia", "324", "Space Jam 2", "Radish", "Robert Ludlum", "giant grubs", "fltoff", "the largest showcase of Grand Prix racing cars in the world", "the film \u2018 Waynes World\u2019", "Hebrew", "The London Underground Piccadilly Line", "United States", "orangutan", "Manet", "The Magic Finger", "the US Constitution", "2005", "1971", "the \"Dodge Brothers\"", "dolt", "Venice", "a peplos", "Enrico Caruso", "florence Nightingale Graham", "collapsible support assembly", "Hardy Amies", "the Marshall Islands", "Wales", "Can't Get You Out of My Head", "Blake Pieroni", "Bloomingdale Firehouse", "the site of one of World War II's most notorious death camps.", "the Golden Gate Yacht Club of San Francisco", "Roger Vivier", "\"No woman, no cry\"", "Buddhism"], "metric_results": {"EM": 0.5, "QA-F1": 0.5570670215201465}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6153846153846153, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-1018", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983", "mrqa_searchqa-validation-13120"], "SR": 0.5, "CSR": 0.6002604166666667, "EFR": 0.96875, "Overall": 0.7845052083333334}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "70-50's", "Panini", "Bills", "anti-colonial movements", "Seeztal valley", "bacteria generate surface proteins that bind to antibodies", "suspicious of even the greatest thinkers and to test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor- patient relationship", "the case of an express wish of the people to withdraw from the EU", "1788", "Saturday", "a Roman Catholic archdiocese", "the Edict of Nantes", "John Wesley", "the Italian nationalisation law conflicted with the Treaty of Rome", "the Eternal Heaven", "Suffolk County Council and Waveney District Council", "Jessica Simpson", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "iceland", "saturday", "Vladivostok", "Sheryl Crow", "farthingale", "Camellia", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "astronomy", "iceland", "George Clooney", "alfred hawthorne", "James Chadwick", "\"Father McKenzie writing the dirt off his hands as he walks from the grave\"", "Monopoly", "champagne", "an extended period of abundant rainfall lasting many thousands of years", "the United States", "Brigit Forsyth", "iceland", "sino-Japanese", "hawthorne", "david hawthorne", "Kent", "alfred hawthorne", "saturday", "white", "Switzerland", "gin", "the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Jason Voorhees", "state and municipal budgets", "David", "\"The Screening Room\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5426034902597403}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 0.75, 0.0909090909090909, 1.0, 0.0, 0.8, 0.3333333333333333, 1.0, 0.3, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9126", "mrqa_squad-validation-6655", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_squad-validation-5827", "mrqa_squad-validation-917", "mrqa_squad-validation-3161", "mrqa_squad-validation-4590", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-2501", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_newsqa-validation-3207", "mrqa_searchqa-validation-8450", "mrqa_newsqa-validation-3860"], "SR": 0.484375, "CSR": 0.5913461538461539, "EFR": 0.9696969696969697, "Overall": 0.7805215617715617}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "it would appear to be some form of the ordinary Eastern or bubonic plague", "Huguenots had their own militia", "after the end of the Mexican War", "61", "quality of a country's institutions and high levels of education", "cilia", "gravity", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "thomas", "thomas", "albinism", "Straits of Tiran", "Brigit Forsyth", "call My Bluff", "March 10, 1997", "cuddly new pet", "the Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "lizard", "strong cold southwest wind", "table tennis", "edward Smith papyrus", "thomas penhaligon", "thomas goveve", "thomas gove", "Jinnah International", "Monday", "Caracas", "The Loop", "Pears soap", "c Cocktail", "avro", "Genesis", "Charlie Brooker", "herbal tea", "Harrods", "2007", "cher", "scarface", "pale yellow", "thomas edward moult", "bubba", "June 12", "Filipino American", "London", "Lambic", "Kindle Fire", "Steven Green", "commas", "fortune", "principality", "Synchronicity"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6151041666666666}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-6547", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-372", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-6864", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.5625, "CSR": 0.5892857142857143, "EFR": 1.0, "Overall": 0.7946428571428572}, {"timecode": 14, "before_eval_results": {"predictions": ["seven months old", "woodblocks", "New Orleans's Mercedes-Benz Superdome, Miami's Sun Life Stadium", "Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "slept after it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1936", "Authority", "junior enlisted sailor", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "World Trade Center", "Kevin Spacey", "1 November", "2.5", "white blood cell in a vertebrate's immune system", "Bangladesh", "President", "minor key", "Hustons", "Chandan Shetty", "sedimentary rock", "October 1, 2014", "United States", "Claims adjuster", "head, neck, a midpiece and a tail", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "10 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "foreheads of participants", "vertebral column", "three", "flowers", "sausages", "kew Gardens", "Nikita Khrushchev", "$500,000", "Alexandros Grigoropoulos,", "Cyrus McCormick", "NYPD Shield", "BBC's central London offices", "a kidney transplant"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6446795203588682}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.608695652173913, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_squad-validation-7670", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_newsqa-validation-121", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.53125, "CSR": 0.5854166666666667, "EFR": 0.9666666666666667, "Overall": 0.7760416666666667}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "a special episode of The Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "ESPN Deportes", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "60", "Seattle, Washington", "Battle of Antietam", "Andy Cole and Shearer", "In Time", "6th century AD", "Glenn Close", "four", "Agostino Bassi", "five", "a beach in Malibu, California", "Paul", "Dutch navy captain Jurriaen Aernoutsz", "September 2017", "Professor Kantorek", "1546", "Sam Waterston", "Bhupendranath Dutt", "Darkspawn", "Dr. Lexie Grey ( Chyler Leigh )", "Matt Jones", "September 1972", "Uruguay", "Alex Skuby", "Thomas Mttyitch", "National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "wool for trading", "1970s", "Director of National Intelligence", "students", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson", "Thespis", "Portugal", "John Coffey", "Rachel Kelly Tucker", "Czech Republic", "a garage beetle", "Myst3ry", "game designer", "opposition group, also known as the \"red shirts,\"", "the abduction of minors.", "Nevada", "Chile", "a department store company specializing in retailing brand name apparel, accessories, cosmetics, footwear, and housewares", "1881"], "metric_results": {"EM": 0.546875, "QA-F1": 0.652130941974692}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.42857142857142855, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 0.5, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-7736", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_hotpotqa-validation-1852"], "SR": 0.546875, "CSR": 0.5830078125, "EFR": 0.9310344827586207, "Overall": 0.7570211476293103}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "the New England Patriots", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "the US", "six", "11", "hydrogen and helium", "the Jin", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Microsoft Office", "SAVE", "Scandinavian Airlines", "1993 to 2001", "February 23, 1898", "the NCAA Division I Football Bowl Subdivision", "Martin Lee Truex", "Easter Rising", "45% male", "more than two decades", "BAFTA TV Award", "a rash", "the Battle of Culloden", "Burny Mattinson", "Sir William McMahon", "the North Sea coast", "The 7.63\u00d725mm Mauser (.30 Mauser Automatic) round", "the Academy Award for Best Animated Feature", "the Pakistan Aeronautical Complex (PAC)", "Delacorte Press", "Neighbourhood", "Secretariat", "Wake Island", "hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "Thomas Harold Amer", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Amway", "Capitol Records", "South Africa", "Surrey", "The Girl in the romantic comedy \"My Sassy Girl\"", "Charles Russell", "Boyd Gaming", "shared Anthony Davis of the New Orleans Pelicans", "1989", "Glenn Close", "Florence Welch", "Neighbours", "Ewan McGregor", "2011", "pippa passes", "the leader of the late insurrection in Southampton, Virginia", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6469640602453102}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.7499999999999999, 0.0, 0.25, 0.2857142857142857, 0.4, 0.8, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.2, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-76", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-3189", "mrqa_hotpotqa-validation-955", "mrqa_hotpotqa-validation-1869", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-3025", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2409", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-2314", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.484375, "CSR": 0.5772058823529411, "EFR": 1.0, "Overall": 0.7886029411764706}, {"timecode": 17, "before_eval_results": {"predictions": ["force of gravity acting on the object balanced by a force applied by the \"spring reaction force\"", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese imports became mass-market leaders with unibody construction and front-wheel drive,", "charter status", "1830", "nonfunctional pseudogenes", "the inner mitochondria membrane", "Charlie welch", "Stevie Wonder", "beaver", "\u201cThe Passage of the Red Sea.\u201d", "formic acid", "Toledo", "Zimbabwe", "\"Pressure of Speech\"", "Ted Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "MUDs", "Mercury", "gazelle", "Xenophon", "London Pride", "the Plimsoll line", "Nick Hornby", "\"The Comedy of Errors\"", "Charles V", "England", "welch", "Olympic Barbell", "\"big house\"", "Hadrian", "California", "typhus", "Birmingham Humphries", "Hamburg", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Prokofiev", "Jessica Simpson", "Culture Club", "Finland", "3000m race", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "Confederate", "New Jewel Movement", "Africa", "north-south highway at the crash scene in White Hills, Arizona, was shut in both directions.", "Anjuna beach in Goa", "Marius Petipa", "Oshkosh", "\"Papa's\"", "\"The World\"", "\"The Sunday Thing\""], "metric_results": {"EM": 0.546875, "QA-F1": 0.6211397058823529}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false], "QA-F1": [0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10351", "mrqa_squad-validation-3711", "mrqa_squad-validation-7089", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-3031", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.546875, "CSR": 0.5755208333333333, "EFR": 0.9655172413793104, "Overall": 0.7705190373563218}, {"timecode": 18, "before_eval_results": {"predictions": ["Jacksonville's low latitude", "1622", "high", "Manakintown", "northwest", "10 employees", "Middle Miocene", "new magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2018", "The Hustons", "Allison Janney", "the Isthmus of Corinth", "ability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Alison", "1993", "19 state rooms", "Solange Knowles", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Elms", "grades 1", "The Vamps", "2018", "the problems", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "the aorta", "July 21, 1861", "Dr. Addison Montgomery", "state or other organizational body", "png HTTP / 1.1", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "Rising Sun Blues", "Part 2", "Dumbo", "the \u201cBloody Assizes\u201d of 1685", "Christian", "Robert L. Stone", "2008", "Jeddah", "Mentor", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.5, "QA-F1": 0.6029241134859741}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true], "QA-F1": [0.8, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.19999999999999998, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7213", "mrqa_squad-validation-3193", "mrqa_squad-validation-6937", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_newsqa-validation-1493", "mrqa_hotpotqa-validation-4735"], "SR": 0.5, "CSR": 0.571546052631579, "EFR": 0.96875, "Overall": 0.7701480263157895}, {"timecode": 19, "before_eval_results": {"predictions": ["everything that is used to work sorrow over sin is called the law, even if it is Christ's life, Christ's death for sin, or God's goodness experienced in creation", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "1965", "270,000 tonnes", "Long troop deployments", "Joe Pantoliano", "the girl's stepmother, a key witness in the case, his attorneys told HLN's \"Nancy Grace.\"", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "eight in 10", "sovereignty over them.", "Tuesday in Los Angeles. Cole's search for a new kidney ended this week when someone with a compatible organ died and their family asked that it be given to the singer, according to the organ procurement group that handled the donation.", "forgery and flying without a valid license", "Anil Kapoor", "55-year-old Hogan's three-decade career, during which he held multiple championship titles and, during his heyday in the 1980s, was easily the most popular wrestler in the world.", "President Obama's surge plan to head to Afghanistan's restive provinces to support Marines and soldiers fighting a dug-in Taliban force.", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "Ferraris, a Lamborghini and an Acura NSX", "a lizard-like creature from New Zealand -- is now a dad.", "Mutassim", "her \"Nothing But Love\" comeback tour, her publicist said Wednesday.\" Doctors visited Whitney late last night in Paris and confirmed that she was suffering from an upper respiratory infection,\" a statement issued Wednesday said.", "\"Steamboat Bill, Jr.\"", "Russia's Tupolev TU-160, pictured here in 2003, is a long-range strategic bomber.", "alcohol", "Atlantic Ocean", "Ahmed,", "cortisone.", "fortune", "U.S. 93 in White Hills, Arizona, near Hoover Dam.", "Al Gore", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead, said military spokesman Gen. Athar Abbas.", "Roger Federer", "credit card information", "Louisiana", "the Southeast", "wife,Misty Cummings, then known asMisty Croslin,", "physicist Steven Chu as secretary of energy, and former EPA administrator Carol Browner to a new post in the White House to coordinate energy and climate policy.", "\"A Mother For All Seasons.\"", "the infant who became the center of an international end-of-life debate, died peacefully in his sleep at his Windsor, Ontario, home, a spokesperson for the family said Wednesday.", "back at work", "the initial necropsy or animal autopsy.", "27", "Amber Riley and her partner Derek Hough", "Thomas Jefferson", "Borsht (Borsch)", "Zager and Evans", "Bobby Hurley", "fourth term", "Adult Theatre", "the Ironsides", "Lapland", "1937", "Emad Hashim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5170170703887809}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true], "QA-F1": [0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.05405405405405406, 1.0, 1.0, 0.0, 0.1904761904761905, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.631578947368421, 0.6666666666666666, 0.30769230769230765, 0.0, 1.0, 0.0, 0.14814814814814814, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_squad-validation-3028", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_triviaqa-validation-3831", "mrqa_hotpotqa-validation-4760", "mrqa_searchqa-validation-328", "mrqa_searchqa-validation-8011", "mrqa_hotpotqa-validation-2922"], "SR": 0.421875, "CSR": 0.5640625, "EFR": 0.972972972972973, "Overall": 0.7685177364864866}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rhenus", "1331", "Death Wish Coffee", "L", "Cameroon,", "1994", "ballots", "a new fabric technique", "three empty vodka bottles,", "Eikenberry sent private cables to Obama last week,", "1959", "Di Montezemolo", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "\"Mandi is not a dangerous weapon.\"", "the composer of \"Phantom of the Opera\" and \"Cats\" and one of Britain's richest men,", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony,", "Amanda Knox's", "over 1,000 pounds", "Iran's development of a nuclear weapon", "a welcoming, bright blue-purple", "using recreational drugs", "ceo Herbert Hainer", "his client, Brett Cummins", "a nearby day care center whose children are predominantly African-American.", "inmates", "Cameron-Ritchie", "back on the set at \"E! News\" on Tuesday", "103 children", "jobs", "one of his strongest statements to date on the sex abuse scandal sweeping the Roman Catholic Church, saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "a vigilante group whose goal is the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "Republicans", "a businessman, team owner, radio-show host and author.", "An undated photo of Alexandros Grigoropoulos,", "a power-sharing deal with the opposition party's breakaway faction,", "a Prius", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Gary Brooker", "the creation of an Islamic emirate in Gaza,", "boogeyman Jason Voorhees", "determining which Guant detainees should be tried by a U.S. military commision,", "San Antonio,", "a guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "50", "Ku Klux Klan", "1939", "Branford College", "Wigan", "husbands", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "mice", "Hodel", "access to US courts", "British rock group Coldplay"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4763163261546882}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.14285714285714288, 0.23076923076923078, 1.0, 0.8, 0.8571428571428571, 0.28571428571428575, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.4, 0.0, 0.0, 0.41379310344827586, 0.0, 0.0, 1.0, 0.9333333333333333, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.19047619047619047, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.22222222222222224, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987"], "SR": 0.359375, "CSR": 0.5543154761904762, "EFR": 0.975609756097561, "Overall": 0.7649626161440186}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "the Treaties establishing the European Union", "\u201c Splash\u201d", "Nicola Adams", "copper and zinc", "eagle with extended wings", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "shoulders", "Madonna's", "Glasgow", "GPS receivers", "Australia", "glaze", "Pearson PLC.", "roch", "American Civil War,", "Loch Ness", "rochner", "roch", "a gentle cat with a somewhat shy nature around strangers.", "China", "Harrisburg", "roch", "glockenspiel", "Dr Sentamu", "women", "roch", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "charlemagne", "the A's west to Oakland,", "roch Crowe", "roch", "roch", "rochon", "roch Butler", "chamomile tea", "Ireland", "tarn", "Michel", "Albert Square", "Newbury", "the Old Testament", "70 million people", "Target Corporation", "\"The Omega Man\"", "Michelle Rounds", "Jackson told her that doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "(INGO)", "John Jackson Dickison", "prisoners' rights and better conditions for inmates,", "Oprah Winfrey.", "his mother"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5376420454545454}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-4045", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-4675", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-975", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-3569", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_newsqa-validation-2971", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.453125, "CSR": 0.5497159090909092, "EFR": 0.9428571428571428, "Overall": 0.746286525974026}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials, and because they are a matter of having sufficient funds at a specific time, can arise even when the overall total is enough.", "Vicodin,", "london", "rusy", "pearl", "Utah Territory", "Carrie Underwood", "liqueur", "he made his horse a consul, his palace a brothel, and his...", "Google", "Langston Hughes", "pain tolerance", "samuel kramm", "puck", "riata", "it means to be 'waxing philosophical'?", "london", "rhodesian ridgebacks", "David Beckham", "arturo Toscanini", "economics", "Miracle in the Andes: 72 Days on the Mountain and my...", "proscenium arch", "Montenegro", "discus", "puck", "basidiomycota", "james", "puck", "Idi Amin", "deere", "a body, body part, or personal object", "hard clay", "plutarch", "Rudy Giuliani", "masa", "40 seconds", "the Vikings", "And to Think That I Saw It on Mulberry Street", "london", "typhoid fever", "river valley", "london", "Williamsburg", "\"OO\" 7- LETTER", "tualatin", "hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off", "jen Knox", "the internal reproductive anatomy", "more than $1 billion worldwide", "risk factors for disease and targets for preventive healthcare", "jape", "Tesco", "london and North Eastern Railway", "russell hill", "the Battelle Energy Alliance", "IT products and services,", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "$10 billion", "Trenton, Florida"], "metric_results": {"EM": 0.3125, "QA-F1": 0.42867133266350016}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 0.5652173913043478, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.28571428571428575, 0.14285714285714285, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_squad-validation-6887", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_searchqa-validation-16854", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-1118", "mrqa_hotpotqa-validation-4804", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-1997"], "SR": 0.3125, "CSR": 0.5394021739130435, "EFR": 0.9772727272727273, "Overall": 0.7583374505928854}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Doritos", "Atlantic Ocean", "domestic cat", "the daughter of Tony Richardson", "Switzerland", "Argonauts", "prometheus", "the Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a MUDs", "Italy", "Khaki", "a magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "Mendip", "John McCain", "the Earth", "Nafea Faa Ipoipo", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "New Netherland", "Justin Trudeau", "radar", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "a typhone", "Rangers", "business", "Adidas", "Snarked", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "the unoccupied square", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "Tennis Channel", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7383272058823529}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-749", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-458"], "SR": 0.703125, "CSR": 0.5462239583333333, "EFR": 1.0, "Overall": 0.7731119791666666}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "20th Century Fox", "1997", "a suite of network protocols", "Christopher Savoie", "11 to 12 year old", "the first home series defeat on Australia in almost 16 years", "the Pacific Ocean territory of Guam", "the gun in Christofi's hand, and even jumped in his pool,", "11", "change course", "Alwin Landry's supply vessel", "the 3rd District of Utah", "money or other discreet aid for the effort if it could be made available,", "Sarah Brown", "boatlift", "environmental", "Brazil", "the Taliban", "Saturday", "38", "70,000 or so", "the Single European Sky initiative", "\"E! News\"", "former Boca Juniors teammate and national coach Diego Maradona", "Steve Williams", "new restaurant", "crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned, as the hard-core Islamic militants spread their reign of terror across parts of Pakistan", "theory", "2008", "Diego Maradona", "Dog patch Labs Europe", "club-themed movies", "two", "Mississippi", "the former Massachusetts governor", "the EU naval force", "Plymouth Rock", "Liza Murphy,", "the nomination of Sonia Sotomayor", "police", "former U.S. secretary of state", "At least 33 people", "Samir Kuntar", "get better skin, burn fat and boost her energy.", "contraband", "how sociopathic brains develop", "Alwin Landry's", "Krishna Rajaram", "Sunday", "death and destruction,", "an Irish feminine name", "southwestern Colorado and northwestern New Mexico", "2018", "northern irish", "a(nd) r(anging)", "art", "the point guard position", "23", "Brazil", "freestyle", "the nightingale", "Belief"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4589968191530691}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.6153846153846153, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.5555555555555556, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.4, 0.0, 0.15384615384615383, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-610", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-2954", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_hotpotqa-validation-2170", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.34375, "CSR": 0.538125, "EFR": 1.0, "Overall": 0.7690625}, {"timecode": 25, "before_eval_results": {"predictions": ["50th anniversary special", "Thomas Savery", "Vicodin,", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago onward", "a violent separatist campaign", "36", "269,000", "The Swiss art heist follows the recent theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg,", "38 feet", "Eintracht Frankfurt", "150", "a man had been stoned to death by an angry mob.", "Russian bombers", "41,", "Irvine,", "super-yacht designers", "137", "Kurdish militant group in Turkey", "3-2", "autonomy", "the shoreline of the city of Quebradillas.", "the Russian air force", "16", "the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "The mysterious disappearance of Flight AF 447 over the Atlantic Ocean has fueled speculation among aviation experts about what caused the state-of-the-art airliner to come down.", "ensure there is no shortage of the drug while patients wait for an approved product to take its place.", "Many nutritionists actually caution against using injectable vitamin supplements because the quantities are not regulated.", "Tom Baer", "militants", "say these planning processes are urgently needed and have been a long time in coming.", "aikini", "Brian Mabry", "completely changed the business of music,", "Sunday", "60 euros -- $89 --", "Former detainees", "\"His treatment met the legal definition of torture.", "Some truly mind-blowing structures", "Crista", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego,", "Emily Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "\"#JustSayin\"", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "\"bad guys\"", "spine", "Hyderabad", "between the Mediterranean Sea to the north", "to stay, abide", "Las Vegas", "Jackson Pollock", "wye", "McComb, Mississippi", "Janis Lyn Joplin", "King Duncan", "plutons", "a car, flatiron, racecar, shoe", "\"absorb\" (to choose, select) c.1200;"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4792868493091016}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.8, 0.0, 0.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.29411764705882354, 1.0, 1.0, 0.0588235294117647, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9432", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-947", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-114", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_newsqa-validation-2550", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832", "mrqa_searchqa-validation-9476"], "SR": 0.390625, "CSR": 0.5324519230769231, "EFR": 1.0, "Overall": 0.7662259615384616}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "\"It all started when the military arrested one man,", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot.", "Hong Kong's Victoria Harbor", "2002", "six prostitutes and a runaway involved in the drug trade.", "legitimacy of that race.", "think are the best.", "three", "Monday", "Scarlett Keeling", "two years,", "84-year-old", "regulators in the agency's Colorado office received improper gifts from energy industry representatives and engaged in illegal drug use and inappropriate sexual relations with them.", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "in July", "Akshay Kumar", "Rihanna,", "Marxist guerrillas admit they recently killed eight Indians whom the rebels accused of collaborating with the Colombian government,", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "James Newell Osterberg", "strangulation and asphyxiation and had two broken bones in his neck,", "Phil Spector", "Kim Il Sung", "1994", "suicide attacks,", "Friday,", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri,", "older than the industry average,", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "a Yemeni cleric and his personal assistant,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "by 9 a.m. three hours before Obama took his oath of office.", "same-sex civil unions,", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "two", "Matt Monro", "Jack Frost", "the innermost digit of the forelimb; thumb", "1985", "over 20 million", "Peoria, Illinois", "Hawaii", "KID-FRIendly 4-LETTER", "\"On such sacrifices, my Cordelia,", "Ottoman Empire"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6233760683760684}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.5333333333333333, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.72, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.2222222222222222, 0.5, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-1329", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.515625, "CSR": 0.5318287037037037, "EFR": 1.0, "Overall": 0.7659143518518519}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Alwin Landry's supply vessel Damon Bankston", "bank robber John Dillinger", "The search for the second missing person", "Seasons of My Heart", "his wife,", "Whitney Houston", "Kris Allen", "a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Lashkar-e-Tayyiba", "$1.5 million", "2006", "Rev. Alberto Cutie", "Los Angeles Angels", "Indian army", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "BADBUL,\"", "98 people,", "2008", "on extreme caution because of the recent pirate attacks.", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Pakistan's combustible Swat Valley,", "South Dakota State Penitentiary", "Iran", "November 26,", "people have chosen their rides based on what their", "July", "neither Sudanese nor orphans,", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death", "the Form Design Center", "fractured pelvis and sacrum", "Wednesday", "abduction of minors.", "a gun conviction,", "Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "1954", "11 p.m. to 3 a.m.,", "Charlotte Corday", "Thailand", "wheat", "Norwood, Massachusetts", "Manchester, New Zealand", "American", "bimatoprost", "Vermont", "beta blockers"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6932810245310245}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.057142857142857134, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.3636363636363636, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2208", "mrqa_newsqa-validation-4138", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3770", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-436", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-3389", "mrqa_hotpotqa-validation-4117", "mrqa_hotpotqa-validation-1144", "mrqa_searchqa-validation-9840"], "SR": 0.5625, "CSR": 0.5329241071428572, "EFR": 1.0, "Overall": 0.7664620535714286}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "technological superiority", "1981,", "forgery and flying without a valid license,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "the Genocide Prevention Task Force.", "the North Korea's announcement has triggered international consternation. U.S. Security Council resolution in 2006 banned North Korea from conducting ballistic missile activity.", "the European Commission", "Whitney Houston", "the lead plaintiff in perhaps the most controversial case involving Judge Sonia Sotomayor,", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "27", "the bomber arrived at the house at the same time a meeting was due to take place between Rabbani and a delegation representing the Taliban insurgency.", "misdemeanor assault charges", "the shipping industry", "Anil Kapoor.", "eradication of the Zetas cartel", "\"The Rosie Show,\"", "the city center,", "collaborating with the Colombian government,", "hippies, 20-somethings and celebrities like actor Richard Gere.", "the Dalai Lama's", "Russia", "8 p.m. local time Thursday", "Passers-by", "The first thing I see is this man's head peeking around the corner into my house,\"", "executive director of the Americas Division of Human Rights Watch,", "750", "300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators", "inconclusive", "5:20 p.m. at Terminal C", "The 9/11 attacks and Afghanistan's role in sheltering al Qaeda should have given us reason to re-examine other regions where the Cold War ended and the United States cut off support.", "$250,000", "100% of its byproducts", "School-age girls", "5,600 people", "million", "the club's board", "St. Petersburg,", "on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "bragging about his sex life on television", "a vertebral column ( spine )", "December 11, 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "the Sidgwick Avenue", "Douglas Richard Hofstadter", "\"The Dark Tower\"", "American", "Little Women", "Castle Rock", "Neapolitan sailors, from whom pizza marinara got"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6614390404067314}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.14814814814814814, 0.0, 1.0, 0.0, 0.9565217391304348, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 0.125, 0.18181818181818182, 0.5, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8823529411764706, 1.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-3692", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-229", "mrqa_newsqa-validation-1068", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-9830"], "SR": 0.5625, "CSR": 0.5339439655172413, "EFR": 1.0, "Overall": 0.7669719827586207}, {"timecode": 29, "before_eval_results": {"predictions": ["relatively stagnant wages for the working class", "El Tem\u00fcr", "16,000.", "Marty Ingels", "coaxial cables", "Pakistani", "Ever Bank Field", "7 members", "German Campaign of 1813", "John Churchill,", "1965", "Charles de Gaulle Airport", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Syracuse", "1963", "coca wine", "puzzle video game", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos", "Tom Kartsotis,", "2017", "Wayman Lawrence Tisdale", "Mexico,", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "23 March 1991", "Gregory Livingston Harper", "Adventures of Huckleberry Finn", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Archie A. Peck", "Ais native population", "Kentucky", "Slam Dunk Contest", "$10\u201320 million", "March 17, 1941", "Kennedy Road", "Somerset County, Pennsylvania,", "Drowning Pool", "Colin George Blakely", "two Nobel Peace Prizes", "IB Diploma Program", "Richard Parker", "off the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "King George VI and Queen Elizabeth,", "3,000 kilometers (1,900 miles),", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia,", "shrimp", "Australia"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5873502365689866}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.28571428571428575, 0.5, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 1.0, 0.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_squad-validation-4347", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-4048", "mrqa_hotpotqa-validation-1936", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-1213", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-4935", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3895", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-4840", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-1944", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585"], "SR": 0.4375, "CSR": 0.5307291666666667, "EFR": 1.0, "Overall": 0.7653645833333333}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "France.", "London", "Dave Thomas", "a cooperative where farmers pool their resources in certain areas of activity", "Danish", "1903", "From Here to Eternity", "other individuals, teams, or entire organizations", "ten years of probation", "John Joseph \" Jay\" Joyce", "Bolton", "How to Irritate People", "Kansas City Crime Family", "Dirk Werner Nowitzki", "the best in film and American television of 2013,", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200 Indians", "Theme Park World", "Formula E.", "New Jersey", "Hl\u00edn", "86,112", "Celtic", "Ouse and Foss", "Springfield, Massachusetts", "British comedian", "\"Apatosaurus\"", "1885", "American", "Frank Thomas' Big Hurt", "\"Stranger in Paradise\"", "Margarine Unie", "Winecoff", "New York City", "The Seduction of Hillary Rodham", "2005", "Lambic", "Tom Clancy's The Division", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "veto power", "Joseph E. Grosberg", "\"Chelsea Does\"", "276,170 inhabitants", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "Seattle", "Discus Thrower", "Villa Park", "2005", "228", "\"We're opening new chapters. And in fact, because some of this information is so new and it's so different from the way we use to think about the moon,\"", "Post Traumatic Stress disorder", "Copenhagen", "Chief Joseph"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6742883158508158}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.06060606060606061, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-3375", "mrqa_hotpotqa-validation-670", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-3926", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905"], "SR": 0.59375, "CSR": 0.5327620967741935, "EFR": 1.0, "Overall": 0.7663810483870968}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno native", "79", "Iceland", "georgia state", "Silent Snow", "Free fall ride", "georgia state", "a Van Morrison song", "Nassau", "a pearl oyster", "HIV", "Martin Van Buren", "a network of rail lines", "La Donna E Mobile", "aardwolf", "georgia state", "georgia state", "Inuk", "Death Valley", "Yves Saint Laurent", "reindeer", "Fortinbras", "the fleet", "Anna Mary Robertson Moses", "Sailor Moon", "a red chile-citrus", "georgia state", "georgia bear", "a tornado", "Gilson Lavis", "elderberries", "georgia cherries", "Milton Berle", "georgia state", "Congolese", "lunar module", "georgia", "Dan Marino Jr.", "Mars", "a clownfish", "E/c^2", "Guru Pitka", "georgia city", "millet", "Butterflies", "a Connecticut Yankee", "orangutan", "Sonora", "Soothsayer", "Yitzhak Rabin", "Saul", "Gettysburg", "Jack Gleeson", "Plank", "Buddhism", "Carl Johan Bernadotte", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic bogs", "20 March to 1 May 2003", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States.", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4642361111111111}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4444444444444445, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4708", "mrqa_searchqa-validation-8630", "mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-11913", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-7406", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-11690", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-7151", "mrqa_triviaqa-validation-3265", "mrqa_triviaqa-validation-4765", "mrqa_hotpotqa-validation-187", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587"], "SR": 0.390625, "CSR": 0.5283203125, "EFR": 0.9743589743589743, "Overall": 0.7513396434294872}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War,", "62 acres", "charlton Addington", "40", "Chad", "shania Twain", "Sheffield Wednesday", "glucagon", "The New York Yankees", "phase of sleep", "green", "charlia", "the Ba'ath Party", "French", "charles pizarro", "Ohio", "Francis Matthews", "photography", "iron", "Noah", "London", "New", "The Duke and Duchess of York", "Mercury", "watt", "Jennifer Sims", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Rio de Janeiro", "his long-suffering wife, Emma,", "aged 75 or older", "Jennifer Lopez", "1664", "Annie Lennox", "Fred Perry", "Downton Abbey", "Martina Hingis", "Pizarro", "Cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "a cheery optimist", "p Pomona", "Italy", "The Streets", "Appalachian Mountains", "a black Ferrari", "a branch of mathematics", "bears", "Michael Moriarty", "June 1992", "24", "1952", "Campbell Soup Company", "Kirkcudbright", "the soldiers", "cortisone.", "the United States can learn much from Turkey's expertise on Afghanistan and Pakistan", "Jennifer Cody", "connected to the sea", "a lung"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6076121794871795}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.33333333333333337, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-5228", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.546875, "CSR": 0.5288825757575757, "EFR": 1.0, "Overall": 0.7644412878787878}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "clare", "insulin", "charlesan", "Hudson Bay", "florida", "Allergic", "stanley", "stanley", "clare", "Belfast", "storm", "fire", "cock", "yankees", "Andy Warhol", "london", "jim branley", "stanley", "the solar system", "potatoes", "Moldova", "Mitsubishi", "stanley", "rusedski", "Estimate", "clare", "clare", "clare", "Madness", "branley", "discretion", "Yves Saint Laurent,", "Rudyard Kipling", "Leeds", "Manila", "rodents", "stanley", "stanley", "Moffitt", "stanley", "stanley", "5000", "racing", "stanley", "Newfoundland", "crow", "Yellowstone", "stanley", "Manila", "thomas branley", "Buddhism", "Guy Berryman", "Ohio", "Melbourne", "\u00c6thelred I of Northumbria", "Scarface", "forgery and flying without a valid license,", "claudio Pizarro, Naldo and Markus Rosenberg", "Liza Murphy, 42,", "Spock", "Turkmenistan", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.375, "QA-F1": 0.41874999999999996}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4823", "mrqa_triviaqa-validation-3524", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-786", "mrqa_triviaqa-validation-7129", "mrqa_triviaqa-validation-2126", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-4289", "mrqa_triviaqa-validation-1407", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_triviaqa-validation-2642", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-525", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.375, "CSR": 0.5243566176470589, "EFR": 1.0, "Overall": 0.7621783088235294}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "spain", "bologna, Italy", "george Santayana", "opossum", "Alice Cooper", "angiotensin II", "trumpet", "spain", "The Scream", "shildon", "Appalachian", "spain", "ballet", "george i", "black Eyed Peas", "lizards", "Blackburn Lancashire", "george laine", "The Mystery of Edwin Drood", "pommel horse", "scarlet", "Dick Van Dyke", "Egremont", "Numb3rs", "george dali", "phrixus", "spain", "george ababa", "venomous", "soap", "Some Like It Hot", "iona", "ireland", "Mike Meyers", "sea horse", "wool", "igneous rocks", "jules verne", "Thank you", "spain", "spain", "george i", "26", "Cleveland Brown", "spain", "One Direction", "spain", "Saturn", "george stanley", "george buis", "after the collapse of Ansett Australia in September 2001", "Baaghi", "sulfuric acid", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "ballet", "Howard Carter"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4984375}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-3837", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-535", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6449", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5537", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4530", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_naturalquestions-validation-8994", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.4375, "CSR": 0.521875, "EFR": 1.0, "Overall": 0.7609375}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "John Forster", "Matlock", "American Civil War", "Ethiopia", "beetles", "Arafura Sea", "tallos", "Tigris", "Bavarian", "to make wrinkles in one's face", "Spain", "Carousel", "bullfight", "jean jean smith", "canada", "Whiskas", "fidelio", "can form the basis of a Broadway musical", "jean feldman", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "Ghana", "armageddon", "G. Ramon", "canada", "goya", "Finland", "can be among the strangest \u2013 and most commonly misunderstood \u2013 objects in our universe", "Mille Miglia", "amphibian", "Bill heston", "50p", "Muriel Spark", "happy birthday", "seven", "mammals", "pickwick", "a machine that cuts the bread finely while efficiently and securely wrapped it in wax paper", "can console themselves that The Bridge will be back on BBC4 with Martin Rohde ( Kim Bodnia)", "bird", "jean", "bPA", "Nelson's Column", "Etruscan army", "Ken Burns", "Hyde Park Corner", "heston dorney", "Pyotr Ilich Tchaikovsky", "Mujib", "isle of canada", "Donna", "season four", "the sinoatrial node", "Sunmi", "tomato", "November 5, 2002", "\"It has never been, and never will be, the policy of Total to discriminate against British companies or British workers.", "the L'Aquila earthquake", "March 24,", "The Duke of Edinburgh", "equinox Day", "Pocahontas"], "metric_results": {"EM": 0.40625, "QA-F1": 0.47037259615384613}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.4, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.15384615384615385, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5537", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-3566", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-3021", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3182", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.40625, "CSR": 0.5186631944444444, "EFR": 1.0, "Overall": 0.7593315972222222}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "julian", "city of acacias", "branson", "Gordon Ramsay", "louis law", "julian ravel", "sulfur dioxide", "Margot Betti Frank", "ringway", "Portuguese", "travelocity", "Avengers", "Richmond", "comets", "comets", "maurice", "canola", "maurice ravel", "comets", "ravel", "Bolivia", "juliandonne", "comets", "Rio Grande", "comets", "ravel man", "30th anniversary", "Ginger Rogers", "julian ravel", "one Foot in the Grave", "julian ravel", "comets", "julian stanford", "glove", "Borrowdale", "Krankies", "comets", "julian ravel", "Canada", "rum", "Seattle", "ghee", "george III", "julian raveli", "hyperbole", "oldpatrick", "90th birthday", "julian ravel", "Ceylon", "screwdrivers", "Denver Broncos", "G minor", "A Christmas Story", "1974", "Nightmares", "Amberley", "found last week in woods about a half-mile from Anthony's house", "President Obama", "Elisabeth", "Pearl Buck", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4473958333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3858", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-4817", "mrqa_triviaqa-validation-4155", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-5196", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-2834", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-4535", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_naturalquestions-validation-4108", "mrqa_hotpotqa-validation-5545", "mrqa_hotpotqa-validation-4454", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908"], "SR": 0.390625, "CSR": 0.5152027027027026, "EFR": 0.9743589743589743, "Overall": 0.7447808385308385}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "pH ( / pi\u02d0\u02c8 ( h ) is a numeric scale used to specify the acidity or basicity of an aqueous solution", "aisles", "baby Charlotte", "Sakshi Malik", "U.S. states of Oregon and Washington", "a physiological reaction that occurs in response to a perceived harmful event, attack, or threat to survival", "49 cents", "1883", "geologist Charles Lyell", "14 \u00b0 41 \u2032 34", "joy of living", "420", "George Strait", "the slogan used to describe the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "January to May 2014", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "1770 BC", "Chandan Shetty", "two", "Sarah Silverman", "eukaryotic cells", "Anakin Kenobi", "Travis Tritt and Marty Stuart", "1976", "Barry and Robin Gibb", "Emily VanCamp", "Pradyumna", "at least as far back as 1853", "On the west", "Psychomachia, '' an epic poem written in the fifth century", "Seton Hall University", "two", "0.30 in", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "an important aspect of epidemiology", "Gloria", "Canadian Rockies continental divide east to central Saskatchewan", "Maginot Line", "pussia", "dumbo", "purple rain", "James A. Garfield", "The Gettysburg Address", "9 September 2014", "eight years", "India", "Gulf of Aden", "Desperate Housewives", "Cannonball Run", "Chiapas", "Tuesday"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5192223084886128}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 0.1111111111111111, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.42857142857142855, 1.0, 0.5, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-9191", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-5119", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-2554", "mrqa_searchqa-validation-2335"], "SR": 0.421875, "CSR": 0.5127467105263157, "EFR": 0.972972972972973, "Overall": 0.7428598417496444}, {"timecode": 38, "before_eval_results": {"predictions": ["Godfrey Sykes", "25 years after the release of their first record", "the Taft -- Katsura Agreement", "Kim Basinger", "August 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Rama", "in the pancreas", "Charles Crozat Converse", "Lady Gaga", "Chicago metropolitan area", "the president of the United States", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "West Bromwich Albion", "either as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "Stephen A. Douglas", "1984", "related to the Common Germanic word guma", "Pakistan", "23 February", "Tagalog or English", "Bryan Cranston", "thylakoid membrane", "at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Franklin and Wake counties", "By late 1922", "18 Divisional Round", "602", "energy of 687 keV", "between $10,000 and $30,000", "R2E Micral CCMC", "1931", "University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "John M. Coski", "a new character Randy", "the Infamy Speech of US President Franklin D. Roosevelt", "Joseph Stalin", "mitochondria, which produce ATP from products of the citric acid cycle, fatty acid oxidation, and amino acid oxidation", "tectonic", "North Dakota", "Sara Gilbert", "6", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Sir John Major", "Roddy doddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "his foreign policy approach, particularly as it relates to human rights around the globe.", "10 below zero", "General Motors'", "David McCullough", "a science fiction novel", "CERN", "london"], "metric_results": {"EM": 0.46875, "QA-F1": 0.588206087312974}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [0.0, 0.09523809523809525, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.975609756097561, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8666666666666666, 1.0, 0.11764705882352941, 0.0, 0.4, 1.0, 0.0, 0.32, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5569", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7039", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2512", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1076", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.46875, "CSR": 0.5116185897435898, "EFR": 0.9705882352941176, "Overall": 0.7411034125188537}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "the process", "Philippe Petit", "R2E Micral CCMC", "January 2004", "along the Yangtze River and in provinces in the south", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "alternative rock", "Set six months after Kratos killed his wife and child, he has been imprisoned by the three Furies", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "A 30 - something man ( XXXX )", "experimental psychology", "83", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Michael Johnston", "John Porter", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "generally composed of roughly 70 % hydrogen by mass, with most of the remaining gas consisting of helium", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Charles Sherrington", "1890", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "As of September, 2016", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "a defense against rain rather than sun", "Since 1940", "Ariel Winter as Sara Lavrof", "Mark Jackson", "Michael Palin ( born November 2, 1944 )", "a body", "on location", "the federal government received only those powers which the colonies had recognized as belonging to king and parliament", "1958", "Cody Fern", "the nature of Abraham Lincoln's war goals", "prophets and beloved religious leaders", "about 0.04 mg / L several times during a day", "Juan Manuel de Ayala", "Joseph Smith, Jr.", "doyle", "1909", "John Duigan", "460", "Dodi Fayed, and their driver, Henri Paul.", "Mikkel Kessler", "curfew", "Pearl", "shark", "Fast Food Nation", "Hep Stars"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5920606958061001}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.07407407407407407, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.47058823529411764, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.25, 0.125, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-4219", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-302", "mrqa_triviaqa-validation-3500"], "SR": 0.484375, "CSR": 0.5109375, "EFR": 1.0, "Overall": 0.75546875}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "the Indian army and separatist militants", "Joan Rivers", "\"You're The One That I Want\"", "glamour and hedonism", "2-0", "more than 15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "\"Z Zimbabwe cannot be British, it cannot be American. Yes, it is African,\"", "two weeks ago", "NATO", "Switzerland", "Monday", "500 soldiers", "Nazi Party members, shovels in hand, digging up graves of American soldiers", "\"To improve America's education, infrastructure, energy and health care systems.", "T.I.", "Baja California Language College", "Robert Barnett", "$627,", "41,", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "Nieb\u00fcll", "about 30 miles southwest of Nashville,", "Tuesday", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "to show that a visitor had been to the grave.", "Ali Bongo", "the Transportation Security Administration", "\"The report was an unclassified assessment sent to law enforcement agencies.", "Two pages", "A Brazilian supreme court judge", "Friday the 13th", "Operation Crank Call", "to help rebuild the nation's highways, bridges and other public-use facilities.", "East Java", "a children's hospital in St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls", "in 2007", "P.V. Sindhu", "March 1, 1960", "snickers", "monoceros", "capone", "Lake Buena Vista, Florida", "his uncle Juan Nepomuceno Guerra", "Bergen", "embalming ritual", "portugal", "a graphical interface", "the American Kennel Club"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6130343250898207}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, false, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.375, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.13793103448275862, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.29629629629629634, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.888888888888889, 1.0, 0.5333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.33333333333333337, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.453125, "CSR": 0.5095274390243902, "EFR": 1.0, "Overall": 0.7547637195121951}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1997", "displacement", "the Peace of Westphalia of 1648", "Megan Park", "the currency used by the majority of European Union's member states", "Kate Walsh", "September 14, 2008", "Kent Robbins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "the pour point of a liquid", "pulse - width modulation of the pump voltage", "a foreign worker to an individual in his or her home country", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million customer accounts", "estimated in 2009 to be less than $10,000 per year", "mining", "Mustafa Ali", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "1902", "Kris Kringle", "Yuzuru Hanyu", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "to collect menstrual flow", "Swine influenza virus ( SIV ) or swine - origin influenza virus", "General George Washington", "Spanish", "Virgil Tibbs", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the atrioventricular node, along the Bundle of His and through bundle branches", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements ) episodes", "to direct black or non-white youth to the unskilled labour market", "the Intertropical Convergence Zone ( ITCZ )", "Missouri River", "the right to vote", "frontal lobe", "10 June 1940", "Tandi, in Lahaul", "alberich", "ear canal", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "on September 21.", "Denver", "the Sadr City residents.", "CTU", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6470979681161133}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6451612903225806, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-744", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-2387", "mrqa_naturalquestions-validation-3494", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.53125, "CSR": 0.5100446428571428, "EFR": 0.9333333333333333, "Overall": 0.7216889880952381}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization", "Middlesex County, Province of Massachusetts Bay", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "composition and powers of the Senate", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "victory", "Gustav Bauer", "ceramics", "the Soviet Union's 1976 achievement of thirteen gold medals", "Covington, Kentucky", "Columbia Pictures and Warner Bros.", "inland processing and power plants", "December 15, 2017", "Paradise, Nevada", "L.K. Advani", "differential erosion", "Jeff Daniels", "the long form in the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "1985", "electricity generation, power distribution, and power transmission on the island", "fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English p Larson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "a circular arc centered at the vertex of the angle is drawn, e.g. with a pair of compasses", "Charlotte Thornton", "the Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "Joan Baez", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Disha Vakani", "2,140 kilometres ( 1,330 mi )", "asexually", "1926", "in Durban, South Africa", "starting in 1560s", "Frankie Muniz", "Leon Huff", "between 1765 and 1783", "normals", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall", "There show went on without the self-proclaimed \"King of the South,\" whose car and home in the Atlanta suburb of College Park were searched after his arrest.", "prostate cancer,", "wyvern", "Lord Fauntleroy", "till a waistcoat", "yellow"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5566757561610503}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.4799999999999999, 0.2222222222222222, 1.0, 1.0, 0.1818181818181818, 1.0, 0.7272727272727272, 1.0, 0.9, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 0.7058823529411765, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-7564", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-5566", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-2644", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.4375, "CSR": 0.5083575581395349, "EFR": 0.9166666666666666, "Overall": 0.7125121124031008}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "September 6, 2007", "asgard Studios in Stockholm, Sweden Perry co-wrote the song with Bonnie McKee and its producers Dr. Luke, Max Martin, and Cirkut", "to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "the arms of the king of Ireland", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Brutus", "de la Gandara", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier,", "Edward Kenway", "Haliaeetus", "the rootlets", "Alex Ryan", "a habitat", "2018", "Windows Media Video", "100", "Toledo", "no embryo", "During the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "in Paradise, Nevada", "Alicia Vikander", "in late January or early February", "Kalinga Ashoka", "Relieving Chambers", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority", "a destroyer's railgun", "the Christian biblical canon", "New England", "a heavy tank", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "2018", "Florida", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "Puerto Rico", "to be unfair", "wintertime", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bon auto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"pressing the reset button\"", "America's infrastructure.", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6043244839128159}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.3333333333333333, 0.15789473684210525, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.5714285714285715, 0.4705882352941177, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9189189189189189, 1.0, 0.25, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.09523809523809525, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352"], "SR": 0.4375, "CSR": 0.5067471590909092, "EFR": 0.9722222222222222, "Overall": 0.7394846906565657}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Laurel, Mississippi", "about the outdoors, especially mountain-climbing", "Sunflower County, Mississippi, United States", "Escorts Limited, an engineering company that manufacture agricultural machinery, machine construction and material handling equipment and railway equipment", "Jean Baptiste Point du Sable", "1992", "a male-dominated industry", "northeastern Alabama", "Jim Harrison", "Toronto", "the Tomorrowland section of the Magic Kingdom theme park at Walt Disney World Resort", "fennec", "United States Army", "American", "Jean Acker", "Bracebridge Heath", "Leucippus", "Caesars Entertainment Corporation", "Richard Avedon", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop F-15 Reporter", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford F.C.", "United States ambassador to Ghana", "Emmy, Grammy, Oscar", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "Andr\u00e9 3000", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints (FLDS Church)", "Pakistan", "Shohola Falls", "American chef, author and television personality", "South America", "2007", "perjury", "Operation Neptune", "Mary Elizabeth Hartman", "over 9,000 employees", "James Bolam", "potential of hydrogen", "Alamodome in San Antonio, Texas", "The Village Vomit", "a watch", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Chapter 5", "the Archies"], "metric_results": {"EM": 0.421875, "QA-F1": 0.54183836996337}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 0.4, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.15384615384615385, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.8, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-4762", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590"], "SR": 0.421875, "CSR": 0.5048611111111111, "EFR": 0.972972972972973, "Overall": 0.7389170420420421}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "\"is a law passed by the United States Congress in April 1824, which authorized the president to have surveys made of routes for transport roads and canals", "Naomi Wallace", "McLaren-Honda", "Tufts University", "Macau", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "203", "Scotland", "brothers Malcolm and Angus Young", "GmbH", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans", "Tampa Bay Lightning", "Steven Selling", "Chesley Burnett \"Sully\"", "Manhattan Project", "The Pacific War", "Romantic", "Air Officer Commanding RAF Fighter Command", "AMC Entertainment Holdings, Inc.,", "New York Islanders", "Fennec fox", "1978", "the Surtees Racing Organisation team that competed as a constructor in Formula One, Formula 2 and Formula 5000", "Canadian", "Pacific Place", "The Australian women's national soccer team", "\"Bad Blood\"", "\"SexyBack\"", "about 5320 km", "Giuseppe Verdi", "Chief Minister of Tamil Nadu", "Sacramento Kings", "Walldorf", "Fife", "Fyvie", "Faysal Qureshi", "the British Army", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "Boletus edulis", "Schleiden and Schawnn", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "is an American singer-songwriter, multi-instrumentalist, and actor", "Bahrain", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6188683712121212}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 0.09090909090909091, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-614", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-3678", "mrqa_naturalquestions-validation-4995", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-8327"], "SR": 0.53125, "CSR": 0.5054347826086957, "EFR": 1.0, "Overall": 0.7527173913043479}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "getting to Know You", "Republican National Committee's website address is GOP.com", "1996", "5", "Greenland shark", "The Word", "President Abraham Lincoln's", "St Jude Thaddeus", "Tasman", "the Death Penalty", "xerophyte", "Jack Roosevelt Robinson", "Staten Island", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "onions", "chicken", "curling", "Victoria Coren Mitchell", "carrie", "Chile\u2019s best wine producing regions", "Majorca (Mallorca)", "Great Expectations (1840-98)", "Laputa", "Lee Harvey Oswald", "Clara Wieck Schumann", "Jupiter", "Venus", "President Obama", "Canada's Conservative Revolution", "mortadella", "Cuba", "David Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "France", "Mary Poppins", "glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Sun", "13", "\"permissible\"", "2016", "the courts", "2017 season", "Chief of Protocol", "Diamond White", "1944", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia,", "death of a pregnant soldier", "Beatrix Potter", "George W. Bush", "How to Keep Young Mentally", "Most king said, \"Divide the living child in two, and give half to the other\""], "metric_results": {"EM": 0.453125, "QA-F1": 0.5356770833333333}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4740", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-3458", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6789", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-1581", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-1987", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.453125, "CSR": 0.5043218085106382, "EFR": 0.9714285714285714, "Overall": 0.7378751899696048}, {"timecode": 47, "before_eval_results": {"predictions": ["horse", "allergic reaction", "joe joe roddy", "auster", "Runic", "hong kong", "tennis", "alex kirchhoff", "republicans", "heating", "misery", "Styal", "stately", "blind beggar", "banksy", "joe", "parlophone", "Wild Atlantic Way", "hong hong", "an Unseen University football team", "noddy", "Lackawanna Six", "canada", "flister", "muezzin", "window", "a ship", "madame bovary", "Apollo 1", "flit", "alex florida", "hong", "oscar", "whale", "roddy", "east fife", "hampers", "social environment", "pre sliced bread", "Dilbert", "a man whose impulses are at war with one another, and when his wife and daughter, now a young woman, appear in casterbridge", "Nunc dimittis", "francophone", "medea", "Burgundy", "cribbage", "Beatles", "hong kong", "France", "muffin man", "hongam county", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Salvatore Avellino", "1754", "drugs", "from Galveston, Texas, to Veracruz, Mexico,", "airline", "Robert Frost", "King Henry VIII", "hong kong", "Mitsubishi Lancer OZ Rally"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4526909722222222}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.888888888888889]}}, "before_error_ids": ["mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5914", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-4571", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-1258", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-555", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-1431", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.40625, "CSR": 0.5022786458333333, "EFR": 1.0, "Overall": 0.7511393229166666}, {"timecode": 48, "before_eval_results": {"predictions": ["Route 66", "sesame street", "marcella Hazan", "cabbage", "australian", "jimmy magoo", "fleece", "Ash trees", "mrupials", "new Zealand", "maurice ravel", "60", "eagle", "1984", "frog", "mongols", "1875", "tax collector", "penny", "Rod Stewart", "mrmy of anjou", "bagram Collection Point", "jimmy Lee Jones", "Chrysler", "eagle", "mrigg", "Sacred Theology", "united States", "spain", "johannes korea", "biathlon", "eagle", "Charlie Chan", "Vienna", "white", "jaws", "paul murphy", "rabbit", "spain", "jimmy Leadbetter", "charles Foster Kane", "Hinduness", "menorah", "Dutch", "spain", "Super Bowl Sunday", "quant pole", "Ding Dong Bell Pussy", "marmole", "Rhododendron", "Ireland", "Chuck Noland", "English", "in Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park, Kenya", "2010", "Greece, the birthplace of the Olympics,", "10 below", "Nearly all", "coins", "the American Kennel Club", "Omaha", "George Glenn Jones"], "metric_results": {"EM": 0.375, "QA-F1": 0.48456370772946855}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.9565217391304348, 1.0, 0.888888888888889, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-3932", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2352", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.375, "CSR": 0.49968112244897955, "EFR": 0.975, "Overall": 0.7373405612244898}, {"timecode": 49, "before_eval_results": {"predictions": ["Percy sledge", "Iran", "tobacco", "clangers", "dharm", "daniel boone", "Thames Street", "Theodore Roosevelt", "satyrs", "crabs", "dharm", "bicapitalized Micro Soft", "wishbone", "Garrick Club", "Lackawanna 6", "barnaby roddy", "Susan Bullock", "the American Civil War", "\"black\"", "Cybill Shepherd", "jimmy Robertson", "Florence", "saint basil", "veruca salt", "severn", "australian", "south Africa", "droughts", "Nicaragua", "Clement attlee", "war of roses", "chemnitz", "dharm", "char family", "jennifer dubonnet", "Ken Norton", "dharm", "folklore", "dharm", "derny", "jennifer darlings", "robin hood", "Chris Martin", "dharm Flintstone", "a London police detective", "rugby", "dharm", "a Scottish pop band", "of dizzy Gillespie", "tobacco", "dharm", "of the economy", "Tom Selleck", "Chicago", "a pinball machine", "Texas Tech University", "Loughborough, Leicestershire, in the East Midlands of England", "Sharon Bialek", "the government of Said Barre", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "George Babbitt", "Oklahoma", "vodka", "four"], "metric_results": {"EM": 0.390625, "QA-F1": 0.45671044685990336}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.22222222222222224, 0.0, 0.0, 0.17391304347826086, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-3257", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6840", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-3615"], "SR": 0.390625, "CSR": 0.49750000000000005, "EFR": 0.9743589743589743, "Overall": 0.7359294871794873}, {"timecode": 50, "UKR": 0.66796875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.806640625, "KG": 0.44453125, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo", "Lipshitz", "Spanish", "\"Ted\"", "1945", "69.7 million", "Neneh Cherry", "Fiapre", "pronghorn antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport", "Scotty Grainger Jr.", "9", "Prelude", "8,648", "Alfonso Cuar\u00f3n", "1858", "September 30, 2017", "1946", "Nicolas Winding Refn", "devotional", "Giovanni Polese", "modern dance", "Cecily Strong", "J. Robert Oppenheimer", "invoice, bill or tab", "seasonal television specials, particularly its work in stop motion animation", "nearly 8 km", "1853", "Love", "Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "singer", "1901", "Pope John X", "Best Production Design", "Electronic Attack Squadron 135", "Alex Skuby", "The Nitty Gritty Dirt Band", "Prince James, Duke of York and of Albany", "jennifer", "FBI", "a large jug or pitcher", "Abbey Road music studios made famous by the Beatles are not for sale, the music label that owns them said Sunday,", "UNICEF", "9 a.m.,", "George Gordon", "Van Helsing", "Tigrinya", "a long-range missile"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5764632936507936}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-3163", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4792", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-3499", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-495", "mrqa_triviaqa-validation-217", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.46875, "CSR": 0.49693627450980393, "EFR": 1.0, "Overall": 0.6832153799019608}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field", "comedy", "Mickey's Christmas Carol", "143,007", "Atat\u00fcrk Museum Mansion", "\"Realty Bites\"", "24 NCAA sports", "Razor Ramon", "Morita therapy", "Forbes", "St. George", "Kramer Guitars", "Lithuanian", "International Boxing Hall of Fame (IBHOF)", "three", "Conservatorio Verdi", "Binion", "Smoothie King Center", "World Outgames", "beer", "Umberto II", "Presbyterian Church (USA),", "neuro-orthopaedic Irish veterinary surgeon", "Disintegration", "North Sea", "17 October 2006", "67,575", "Oxford", "\"OS DATA\"", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "Italian", "Eric Whitacre", "Mission Inn Hotel & Spa", "180 flights daily", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "McKenna's Fort", "Scunthorpe", "Canadian comedian", "Seventeen Seventy, Gladstone Region, Queensland", "Summer Olympic Games", "1862", "1945", "The Kennedy Center", "Budget", "Ch\u014dfu, Tokyo, Japan", "lion", "1959", "Donna Mills", "the song deals with heartbreak", "735 feet ( 224 m )", "bacall", "bacall", "maxilla", "Intel", "4.6 million", "Iranian efforts to stem the flow of information", "tea rose", "Commander-in-Chief", "coffee liqueur", "Rear Window"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5810335497835497}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.9090909090909091, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.8, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 1.0, 0.3333333333333333, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 0.4285714285714285, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1260", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-673", "mrqa_hotpotqa-validation-5556", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653", "mrqa_searchqa-validation-3934"], "SR": 0.453125, "CSR": 0.49609375, "EFR": 1.0, "Overall": 0.6830468749999999}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "citizens", "3", "100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "Camping World Stadium in Orlando", "Windows Media Video ( WMV ), Windows Media Audio ( WMA ) and Advanced Systems Format ( ASF )", "the American punk rock band the Ramones", "The Godfather Part II as Michael Corleone", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the Gospel of Matthew", "30 years after Return of the Kenobi", "standard form contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1963", "Battle of Sainte - Foy west of Quebec", "The 1972 Dolphins made its first Super Bowl appearance in Super Bowl VI, but lost to the Dallas Cowboys, 24 -- 3", "Columbia River Gorge in the U.S. states of Oregon and Washington", "Magnetically soft ( low coercivity ) iron is used for the cores in electromagnets", "2013", "malicious software", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "carnivore", "Terry Kath", "roofing material", "one person", "The Parlement de Bretagne", "Microsoft Windows", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "The overlaid attraction is then open to guests from late - September through early January", "currency option", "1603", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "the medulla oblongata", "2018", "Gibraltar", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "crawford", "Paul Maskey", "teenage actor or teen actor", "Saoirse Ronan", "Revolution Studios", "the Kirchners", "Croatia", "Gordon Brown", "veterans", "yellow fever", "winter solstice", "Netflix"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6467699657362652}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5714285714285715, 1.0, 0.47058823529411764, 0.33333333333333337, 0.0, 1.0, 1.0, 0.8333333333333334, 0.046511627906976744, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.4615384615384615, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.967741935483871, 0.0, 0.5555555555555556, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-10706", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3162", "mrqa_searchqa-validation-4527"], "SR": 0.546875, "CSR": 0.4970518867924528, "EFR": 0.9310344827586207, "Overall": 0.6694453989102147}, {"timecode": 53, "before_eval_results": {"predictions": ["Alston", "a classical theory", "Beethoven", "Green Acres", "a monthly gourmet lifestyle", "a blend of coconut, fruits, nuts and chocolate", "an archive of City Lights stories", "lobster", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "Calvin Coolidge", "the Institute of Cybernetics", "fish", "Pudd'nhead Wilson", "Sydney", "the tapir", "France", "Spam", "Stephen Dedalus", "early", "Banon", "Sunday", "the Dragon", "a centaur", "Mentor", "Lebanon", "Manifest Destiny", "Al Gore", "the Deaf President Now protest", "Singapore", "Bruce Springsteen", "Cyprus", "glucosamine", "Madagascar", "Google Groups (usenet groups), Google scholar", "a celebration", "a bag", "The Undeclared War Against American Women", "Dr. Dre", "St. Petersburg", "Fidel Castro", "fudge", "a story of the Transcontinental Railroad", "Laborers' International Union", "Black Moor Goldfish", "hormone", "a dive in which the body is first bent at the waist and then straightened", "yellowtail", "watermelon", "between the Mediterranean Sea to the north and the Red Sea in the south", "Beijing", "Zeus", "van Morrison", "antelope", "syrups in the world", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube", "three thousand", "insurgent small arms fire.", "about 3,000 kilometers (1,900 miles),", "Lambic"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5899305555555555}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.888888888888889, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-2596", "mrqa_searchqa-validation-1108", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-9470", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-904", "mrqa_searchqa-validation-6093", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-1000", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-3349"], "SR": 0.515625, "CSR": 0.49739583333333337, "EFR": 0.967741935483871, "Overall": 0.6768556787634409}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "Jay Berry Lee,", "the stems and roots of certain vascular plants", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew )", "1987", "John F. Kennedy", "at least 1926", "on the Isle of FERNANDO 'S!, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "an embryo", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "10 Stigwood Avenue", "Haji Sahib of Turangzai", "11 %", "Dr. Joel S. Engel of Bell Labs", "33 \u2032 47.0 '' north of the Equator", "1998", "Chris Martin", "the Ming dynasty", "its watershed", "Thomas Jefferson", "The Intolerable Acts", "National Industrial Recovery Act ( NIRA )", "semi-autonomous organisational units within the National Health Service in England", "Scott Schwartz", "Cyanea capillata", "1996", "Hyderabad", "the hand mould", "1881", "the speech was not given at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "the Finch family's African - American housekeeper, whom the children love and Atticus deeply respects ( he remarks in her defense that she `` never indulged ( the children ) like most colored nurses '' )", "( such as the muscles of the limbs, abdominal, and intercostal muscles )", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "miss Daisy", "Revenge", "Kaneohe Bay", "PlayStation 4", "2015 Orange Bowl", "Seminole Tribe", "Defense of Marriage Act", "Alinghi", "Eiffel Tower", "barnacles", "a bistro", "trainspotting"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5814468356505895}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5882352941176471, 1.0, 0.4615384615384615, 0.6666666666666666, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-8386", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-2067", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.4375, "CSR": 0.4963068181818182, "EFR": 0.9722222222222222, "Overall": 0.677533933080808}, {"timecode": 55, "before_eval_results": {"predictions": ["king eddie i", "mulligan", "purple", "aeoline", "ascot", "Lithuanian Litas", "Loretta Lynn", "WrestleMania", "steppenwolf", "chop suey", "roddy mcManus", "victoria mavrakis", "david mavrakis", "mavrakis", "Saddam", "New Zealand", "Tyrrhenian", "bobby Sands", "mauritania", "han lepperhey", "b Bolivia", "Martin Scorsese", "madagasikara", "ash", "king eddie VII", "komas Cranmer", "testicles", "Guatemala", "bacall", "Caroline Aherne", "Byron", "Bleu c\u00e9leste", "Mau Mau", "kipps:", "guggul", "Serena Williams", "Lome", "Pegida", "nibelung", "Utrecht", "1709", "Mitford", "Kansas", "david mavrakis", "parthenogenetic reproduction", "Skylab", "ostrich", "h Hugh Quarshie", "a stern tube", "david mavrakis", "korea", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack Ridley", "Linux Format", "Stage Stores", "26", "ordered the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guantanamo Bay, Cuba.", "Beijing", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5513257575757575}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.48484848484848486, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1825", "mrqa_triviaqa-validation-5972", "mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-1051", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5554", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-6312", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-6624", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2137", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-2488", "mrqa_searchqa-validation-4261"], "SR": 0.484375, "CSR": 0.49609375, "EFR": 0.9696969696969697, "Overall": 0.676986268939394}, {"timecode": 56, "before_eval_results": {"predictions": ["France", "bolivia", "The Telegraph", "liver", "portugal", "Welcome to the crossword dictionary at Crossword Nexus", "inishmore", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "george elphy", "tokelau", "meatball", "benazir butto", "cricket", "Sam Mendes", "john steed", "way back Attack", "season 9", "business", "lady Godiva", "sammy mcManus", "Mexico", "river Towy", "monaco", "1984", "monaco", "three", "shinto", "Sussex", "king george vii", "Mickey Mouse", "oxygen", "kingdom of monaco", "Toledo", "do I have to use earplugs", "dharm", "The Bends", "WATSON", "Loch lomond", "pyrenees", "bolivia", "gelatine", "Papua", "gulf of Aden", "monaco", "monaco", "sankt Moritz", "the French Revolution", "the Old Kent Road", "mediterranean", "An acetate / \u02c8\u00e6s\u026ate\u026at / is a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base", "iron", "creation of the office in 1789", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Tottenham ( )", "Unseeded", "off Somalia's coast.", "Shanghai", "Katheryn Maloney", "Pershing", "governess", "a large portion of rural Maine"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5138888888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224]}}, "before_error_ids": ["mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-4984", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-2943", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-1010", "mrqa_triviaqa-validation-1012", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.453125, "CSR": 0.49533991228070173, "EFR": 1.0, "Overall": 0.6828961074561403}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "jennifer smith", "rennet", "river lee", "de Cuevas", "Jessica", "placebo", "weather", "wellington", "papal state", "braille", "wilson boyd", "saint Cecilia", "Caroline Garcia", "morecambe & wiseman", "tommy lee jones", "butcher", "cowpox", "foxhunting", "Stockholm", "France", "Brothers In Arms", "anosmia", "george moemaker", "karl Marx", "rue", "yellow", "marinus sea raven", "Caracas", "ennio morricone", "British", "spain", "time team", "Turandot", "mzizima", "mzizima karakoram Mountains", "Dan Dare", "Howard Keel", "marriage", "Boutros Ghali", "Germany", "mcgregor lincoln", "El Paso", "garden of gethsemane", "Decision tree", "3", "The Mail On Sunday", "France", "karald III", "keirin", "selenium", "vehicles designed for off - road use are known as `` four - wheel drives ''", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number two", "natural gas", "Michael Jackson was in good health, contrary to media reports he was diagnosed with skin cancer.", "shiza Shahid", "Perseid meteor shower", "accordions", "bones", "Marky Mark"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6213541666666667}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.4, 1.0, 0.5, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-2165", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-5579", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-7431", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-1810", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-4074", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_hotpotqa-validation-836", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-16209"], "SR": 0.546875, "CSR": 0.4962284482758621, "EFR": 1.0, "Overall": 0.6830738146551724}, {"timecode": 58, "before_eval_results": {"predictions": ["rub", "Jonah", "The Color Purple", "Nicosia", "Jacqueline Susann", "Amazon", "Hudson", "a cell", "Boxing Day", "Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "cavaedium", "Valley Forge", "pomegranate", "oliver", "Siberia", "William Pitt", "5", "Friday the 13th", "Manchester", "The Godfather", "melanoma", "Henry II", "jahada", "harpoons", "Mandy", "finance", "Conrad", "Robert Rauschenberg", "plutonium", "cyanotype", "Zimbabwe", "Battle of Trafalgar", "a bald eagle", "menudo", "a dramma tragico", "hurricanes", "Home Improvement", "Kashmir", "Airport", "gethse", "Bourbon French Parfums", "20 million", "Ariel", "the Chicago Bulls", "fatal", "Margaret Spellings", "emerald", "a dome", "19 July 1990", "Incudomalleolar joint", "Louis XV", "Zimbabwe", "Mansion House", "chemo", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "money"], "metric_results": {"EM": 0.4375, "QA-F1": 0.48541666666666666}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-13207", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-9816", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-14893", "mrqa_searchqa-validation-4453", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-8965", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-5458", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-12017", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-1938", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225"], "SR": 0.4375, "CSR": 0.4952330508474576, "EFR": 0.9722222222222222, "Overall": 0.677319179613936}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "the 1&1 website", "barrel aging", "Leonard Bernstein", "magnesium", "Venice", "Danube", "the albatross", "Costanza", "The Smashing Pumpkins", "Syntax", "Ohio State", "William Tecumseh Sherman", "Pakistan", "Theology", "Ireland", "Sally Field", "Barbara Cartland", "Rum", "Pringles can", "Paul Hamm", "profundo", "East Siberia", "Nimble", "Tom Hanks", "Clue", "a theatrical cartoon series", "New Orleans", "an", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "We Are Marshall", "General Motors Co.", "the trade winds", "(1902)", "silk", "w", "a Unicorn", "Scrabble", "the humerus", "Saturday Night Fever", "Petruchio", "the Philippines", "mushrooms", "Che Guevara", "Yale", "Oscar Wilde", "Helen", "Dian Fossey", "an antique print", "an iron -- nickel alloy and some other elements", "ABC", "a minority report", "Pear", "Melbourne", "big bopper", "Ringo Starr", "Do Kyung-soo", "Hanna, Alberta", "acid", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "\"all the world\\'s largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "sinon"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6807291666666667}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-8167", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-5632", "mrqa_searchqa-validation-6415", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745", "mrqa_triviaqa-validation-6487"], "SR": 0.609375, "CSR": 0.4971354166666667, "EFR": 1.0, "Overall": 0.6832552083333333}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji", "Lu\u00eds Nani", "four", "Sippin'", "Sergeant Purley Stebbins", "The Maersk Mc- Kinney M\u00f8ller Centre for Continuing Education", "New Orleans", "Karl-Anthony Towns", "five", "Charlie Wilson", "Sim Theme Park", "the 850", "from its riverside location", "1859", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "James Fox", "Erinsborough", "2015", "Moscow Does Not Believe in Tears", "The Birds", "Derry", "York County", "the National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "25 August 1949", "the Savannah River Site", "\u00c6thelred I", "God and the just cause", "New York City", "Tiberius", "World War I", "January 19, 1943", "Marktown", "five", "Rodney Crowell", "Mendel", "New York", "a pentatonic scale", "Frankfurt", "Apollon", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5998511904761905}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-986", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3746", "mrqa_hotpotqa-validation-5741", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-399", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-4752", "mrqa_hotpotqa-validation-5216", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-6034", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.46875, "CSR": 0.4966700819672131, "EFR": 0.9705882352941176, "Overall": 0.6772797884522661}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Cartoon Network", "1983", "Leeds United", "264,152", "2,664 rooms", "841", "the first and second segment", "ABC1 and ABC2", "MG Cars", "Walt Disney", "1979", "15 mi", "January 23, 1898", "John W. Henry", "Bolton", "Argentino Americanos", "Them", "private liberal arts college", "John Snow", "Battle of White Plains", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "Dzyha Vertov", "Friday", "University of Oklahoma", "1982", "Mondays at 7pm", "1866", "Gaahl", "the Lega Serie B", "1887", "Isabella", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf", "The Fate of the Furious", "the seventeenth edition of the IAAF World Championships", "Julia Kathleen McKenzie", "Mercer University", "1951", "35,124", "154 days", "September 30", "Jimmy Flynn", "the Soviet Union", "his finger", "Ronald Wilson Reagan", "Bacofoil", "Long troop deployments", "from dealers to assembly workers", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during the removal process.", "James Watt", "T.S. Eliot", "Anastasia Romanov", "number of times a pitcher pitches in a season"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5381000905797101}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.5, 1.0, 0.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16666666666666666, 0.8, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5217391304347826, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4282", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-4408", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3061", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1687", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-3443", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-6998", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129", "mrqa_searchqa-validation-4629", "mrqa_naturalquestions-validation-715"], "SR": 0.359375, "CSR": 0.49445564516129037, "EFR": 1.0, "Overall": 0.6827192540322581}, {"timecode": 62, "before_eval_results": {"predictions": ["the academic neoclassical architectural style", "13 October 1958", "Walt Disney and Ub Iwerks", "a barcode", "Babylon", "a card", "lyric fairy tale", "Sean Yseult", "court systems in several common law jurisdictions", "October 5, 1937", "Hillsborough County", "Charles Eug\u00e8ne Jules Marie Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "the Lost Boys Foundation", "globetrotters", "Francis August Schaeffer", "San Francisco International Airport", "John Nicholas Galleher", "German", "Gareth Jones", "consulting", "April", "1978", "actor", "Connie", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "jewelry designer", "Axl Rose", "the Nebula Award, the Philip K. Dick Award", "\"The Big Bang Theory\"", "the German princely Battenberg family", "dice", "Kal Ho Naa Ho", "Dungeness", "Pendlebury, Lancashire", "25 October 1921", "Ray Cameron", "Martin O'Leary", "HTS", "Reginald Engelbach", "American", "the fourth Thursday", "Golden Valley, Minnesota", "Jean Erdman", "5.7 million", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard Seddon", "the right atrium", "Sitka", "take the Rio Group to a new level by creating the organization.", "\" \"It was incredible. We've had so much rain held off wherever Muhammad Ali went,\"", "Bob Bogle", "circumference", "Austin", "a station wagon", "2001"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6257351579986061}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.11764705882352941, 0.5, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 0.9473684210526316, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-5811", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-5231", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-434", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-2535", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-1714", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-7093"], "SR": 0.484375, "CSR": 0.4942956349206349, "EFR": 0.9696969696969697, "Overall": 0.6766266459235208}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "The homophonic pun", "\"The pound of flesh\"", "carrots", "Beluga whale", "Nicholas II", "tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "Argentina", "Thor", "Orange", "astride", "Borneo", "Paris", "the breakfast competition", "located just outside of Dallas", "whipped cream", "The Atlantic bluefin tuna", "Macbeth", "Jean Michel Basquiat", "Led Zeppelin", "War and Peace", "Dutchman", "Moonlighting", "The Grass Harp", "Peter Falk", "John Tyler", "Milwaukee", "sin", "Wall Street", "sake", "Notre Dame", "Portland", "Lafayette", "The Indianapolis 500", "Toy Story", "Improv", "Carrie Bradshaw", "The Boys' Club of New York", "Nikolai Gogol", "Oscar Wilde", "Fletcher Christian", "weaving", "Karol Wojtyla", "Greenland", "John", "The Marx Brothers", "watermelon", "Phillip Schofield and Christine Bleakley", "enterocytes", "Reverend J. Long", "violin", "a provocative and idiosyncratic feminist\u02bcs companion", "Mount Godwin Austen", "Garrett Morris", "third concert tour of America", "75 mi southeast of Lake Tahoe", "Susan Atkins", "9 million Americans", "almost one-third", "al-Maliki"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6880580357142857}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.5, 1.0, 0.6666666666666666, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-3671"], "SR": 0.609375, "CSR": 0.49609375, "EFR": 1.0, "Overall": 0.6830468749999999}, {"timecode": 64, "before_eval_results": {"predictions": ["Half Moon Bay", "Seminole", "billions of dollars", "\"green-card warriors\"", "228", "Jero", "2005", "in stimulus funds", "consumer confidence is key to getting the auto industry back on track.", "Second seed Fernando Gonzalez", "in the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "Dan Parris, 25, and Rob Lehr, 26,", "Jason Chaffetz", "not a safety issue", "the Somali coast.", "Barack Obama", "Sunday", "Bienvenido Latag", "France", "380,000", "be silent.", "Apple co-founder Steve Jobs took exception to Rose's characterization of him as \"a guy who founds high-tech companies and tries to make another billion.\"", "the Kenyan and Somali governments issued a joint communique declaring Al-Shabaab \"a common enemy to both countries.\"", "\"gotten the balance right\"", "a dozen", "10", "\"Quiet Nights,\"", "his death cast a shadow over festivities", "in places like Iran and Egypt.", "123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "not testify", "pelvis", "at least nine", "to step up.", "first-degree murder", "Russian supermodel and philanthropist described by designer Tom Ford as \"the most beautiful woman in the world.\"", "Mashhad", "O2", "only one", "Purvis", "Jeanne Tripplehorn", "al Qaeda,", "Garth Brooks", "in Oxbow, a town of about 238", "Bahrami", "different women coping with breast cancer", "Michael Schumacher", "Lula da Silva", "release of the four men", "2006", "12.9 - kilometre", "Jim Ruggiere", "Theodosius I", "prime Minister Ted Heath", "Estonia", "is our children learning", "Queen Elizabeth II and Prince Philip, Duke of Edinburgh", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Bistro.com", "Woodrow Wilson", "the shredded"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5102689428734319}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false], "QA-F1": [0.0, 1.0, 0.5454545454545454, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.6666666666666666, 0.5263157894736842, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8571428571428571, 1.0, 0.09523809523809522, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-1314", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-2455", "mrqa_newsqa-validation-1367", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-446", "mrqa_newsqa-validation-1745", "mrqa_newsqa-validation-3255", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-10515", "mrqa_searchqa-validation-709"], "SR": 0.359375, "CSR": 0.4939903846153846, "EFR": 1.0, "Overall": 0.6826262019230769}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "\"I always kind of admired him,", "North Korean Taepodong-2", "February 12", "Lubbock International Airport,", "South African Judge Richard Goldstone", "\"falling space debris,\"", "a Little Rock military recruiting center", "voluntary manslaughter", "Rainbow Babies and Children's Hospital", "Chris Robinson and girlfriend Allison Bridges", "Sandy Olssen", "Cipro", "34", "E. coli bacteria", "15,000", "not required to go to any specific type of organization by covering themselves in fake blood and lying in human-sized meat packages.", "\"The Sopranos,\"", "government", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "collapse on Tuesday afternoon.", "Cardinal Spellman", "against using injectable vitamin supplements", "it may have to drill deeper to find greater quantities of oil and gas.", "around 1610,", "Gulf of Aden,", "George W. Bush", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee,", "the immorality of these deviant young men", "launch in five days.", "managing his time.", "to ensure that government treats all its citizens equally, to fight injustice and intolerance in all its forms and to bring about that more perfect union,\"", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.\"", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "15, and Jesus Mendez,", "drug cartels", "state", "Trevor Rees,", "at least 28", "the leader of a drug cartel", "Johnny Carson", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "the Genocide Prevention Task Force,", "224.7", "Kirstjen Nielsen", "1937", "20", "Madison, Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "Lake Huron", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5764068309401369}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.923076923076923, 0.4, 1.0, 0.0, 0.7692307692307693, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.5, 0.06250000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.14814814814814817, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 0.18181818181818182, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-388", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-2911", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-3127", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-2527", "mrqa_newsqa-validation-3885", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-431", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-3469", "mrqa_triviaqa-validation-1217", "mrqa_triviaqa-validation-122", "mrqa_hotpotqa-validation-4692"], "SR": 0.453125, "CSR": 0.49337121212121215, "EFR": 1.0, "Overall": 0.6825023674242423}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Castile", "about a mile north of the village of Dunvegan", "arcelorMittal Orbit", "\"lodges\")", "Joseph Stillwell", "Tallinn,", "solar system", "coelacanth", "Belgium", "Philip E. Marlow", "calcium", "Eric Coates", "george armstrong", "mel Brooks", "The California condor", "wisconsin", "wind turbines", "Sid James", "bill", "Leonardo DiCaprio", "Hamlet", "Johannesburg", "crackerjack", "lebrecht Music and Arts Photo Library / Alamy", "carousel", "spain", "minder", "vinegar", "lum Dennis", "kansas city", "Gradgrind", "Toscana (Tuscany) Region,", "tallest building in the world", "Singapore", "wisconsin", "Pakistan International Airlines", "gold", "France", "Tomorrow Never Dies", "john Fitzgerald Kennedy", "California", "Chuck Yeager", "Melanie Bush,", "northern France", "horse racing", "ishmael", "the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective which developed around the middle of the twentieth century and that continues to be influential in some areas of the discipline", "21 July 2015", "Bern", "28 June 1945", "not change the threat level,", "25", "Pakistan's", "Yves Saint Laurent", "Eric Clapton", "Yogi Berra", "his business dealings"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6034970238095237}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.09523809523809525, 1.0, 0.09523809523809523, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1709", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-4077", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-6641", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-7476", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_triviaqa-validation-7014", "mrqa_triviaqa-validation-1771", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330"], "SR": 0.53125, "CSR": 0.4939365671641791, "EFR": 1.0, "Overall": 0.6826154384328358}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Alaska", "Robert Duncan McNeill", "August 9, 1945", "after obtaining the consent of the United Kingdom", "biscuit", "Olivia Olson", "Los Angeles", "Pyeongchang County, South Korea", "928", "April 7, 2016", "5.7 million customer accounts", "Wembley Stadium", "President", "David Joseph Madden", "The Fixx", "during the first week of April", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "the Royal Air Force ( RAF )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET", "1836", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Tamara Drasin", "October 14, 2017", "Kryptonite", "November 25, 2002", "IBM", "Chernobyl Nuclear Power Plant", "435", "sport utility vehicles", "Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand", "Frank Oz", "Flag Day in 1954", "2010", "Missouri River", "malmesbury", "lute", "spain", "John Churchill,", "Gregg Popovich", "Asiana Town", "Araceli Valencia,", "Eleven", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "emphasis or heightened effect"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6576613764524949}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, false], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 0.8421052631578948, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025", "mrqa_triviaqa-validation-4040"], "SR": 0.546875, "CSR": 0.4947150735294118, "EFR": 0.9655172413793104, "Overall": 0.6758745879817444}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "edward heathaway", "sesame seeds", "Infante(noun)", "Sunday", "barnaby rudge", "Gotama", "bulgaric", "1963", "discus", "the red top tabloid", "the Sidgwick Avenue arts faculty buildings", "racecourse", "ohio", "Jews of skye", "skye", "saint Basil's", "Peru", "the keel", "Evander Holyfield", "\"The Creator's Game.\"", "Buddhism", "new Orleans", "sprite Zero", "fat like oil or lard", "Steve Hansen", "brash", "Ken Burns", "Paddy Doherty", "Yvonne", "phi", "Hungary", "So Solid Crew", "bluesbreakers", "Pennsylvania", "the Balkars", "king of england", "\" Morningtown Ride\"", "Jupiter", "'Watch with mother',", "mf", "one", "Queens Park Rangers", "wake", "bulphemus", "flannel", "b\u00e9la Bart\u00f3k", "Hugh Dowding's", "Montpelier", "February", "Arthur, Prince of Wales", "every year", "318", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 30, 2025", "Amanda Knox's aunt Janet Huff", "Gulf of Aden,", "a rabbit hole,", "deep-rooted", "the United States", "Crackle", "Rok 1976 nie bdzie Rokiem Politykw tak jak byo do tej pory"], "metric_results": {"EM": 0.375, "QA-F1": 0.43432539682539684}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-3986", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-2822", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-3417", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-638", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.375, "CSR": 0.49298007246376807, "EFR": 1.0, "Overall": 0.6824241394927536}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "graham kane", "Chicago", "filly", "dar es Salaam", "Cecil Parkinson Trade and Industry Secretary", "miss marple", "Elkie Brooks", "UPS", "roberta Nadal", "Chopin", "Cambridge", "germaniana", "spice girls", "glycerol", "addams family", "Doubting Castle", "beetle", "germany", "Geoff Hurst", "Harry Shearer", "9-13", "pirate day", "caucasingian penny", "Spice Girls", "The Golden Child", "AFC Wimbledon", "germany", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "Bagram Collection Point", "Pygmalion", "gyrating", "cassis", "Dieppe Raid", "Dengue fever", "left-wing", "triathlon", "verbal kint", "the dividing of cells into additional cell bodies", "strictly Come Dancing", "\"sound and light\"), or a sound and light show,", "what", "jack Russell Terrier", "germany", "graham", "grahamjaro", "magic circle", "The Potsdam Conference, 1945", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Cordelia", "London Luton Airport", "Sarah Winnemucca", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Mauritius, Mayotte, R\u00e9union, Seychelles, fallow and roe deer", "saying Chaudhary's death was warning to management.", "\"the evidence and investigatory effort has minimized the likelihood that Haleigh's disappearance would mean for the search for Haleigh,", "\"The deceased appeared to have been there for some time.\"", "Vanilla Ice", "William Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5131993006993008}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5454545454545454, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.8, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.07692307692307691, 0.0, 0.07692307692307693, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-6664", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-546", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-2018", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-1346", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627"], "SR": 0.421875, "CSR": 0.49196428571428574, "EFR": 1.0, "Overall": 0.6822209821428571}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew", "simple", "Australian colonies became profitable exporters of wool and gold", "Ashrita Furman", "the American girl group No Secrets", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Vincent Price", "1911", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "state", "1999", "Mayor Hudnut", "its geographical location near the Equator", "no baby at 7 weeks", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Eddie Van Halen", "$10", "the referee", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W \ufeff / \ufffders 26.617 \u00b0 N 81.617", "At the end of the episode, she is seen smacking a fly on her mirror and removes its corpse", "around 2011", "Seton Hall Pirates men's basketball team", "ulnar", "2018", "British Indian Association", "many forested parts of the world", "the majority coming from Western Australia", "Carol Worthington", "1830", "biological agents, stress, or chemicals", "to meet others, play and laugh, forget and forgive, and repair broken relationships", "6", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "Nehru", "Anthony Hopkins", "Jesus Christ", "1996", "holography", "spain", "FAR WITH THE M ADDING CROWD", "Gillian Leigh Anderson", "direct scattering and inverse scattering", "45th Infantry Division", "\"one of the most magnificent expressions of freedom and free enterprise in history\"", "2009", "an open window that fits neatly around him.", "Dutchman", "Coleridge", "Pygmalion", "yen"], "metric_results": {"EM": 0.5, "QA-F1": 0.6357723709638894}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, false, false, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, false, true, true], "QA-F1": [0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.823529411764706, 0.0, 1.0, 0.5882352941176471, 0.6666666666666666, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 0.5714285714285715, 0.6046511627906976, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.8333333333333333, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-2623", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-9814", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-706", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-3858", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.5, "CSR": 0.4920774647887324, "EFR": 0.875, "Overall": 0.6572436179577464}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "harvested from the inner core and growing bud of certain palm trees ( notably the coconut ( Cocos nucifera )", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama World Tour", "Turkey", "zinc silicate primer and vinyl topcoats", "The rez", "either in front or on top of the brainstem", "On March 14, 1942", "Agamemnon", "Epithelial tissues", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Jones'then - wife, Peggy Lipton, who knew Vincent Price, suggested Price for the vocal part, which Price agreed to do", "India", "Tessa Peake - Jones", "a set of connected behaviors, rights, obligations, beliefs, and norms as conceptualized by people in a social situation", "United Nations Peacekeeping Operations", "in the bloodstream or surrounding tissue following surgery, disease, or trauma", "the Noahic Covenant", "Shirley Mae Jones", "reduces heat conduction or convection", "Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16, and Acts 1 : 13 )", "on August 19, 2016", "protects it from infections coming from other organs ( such as lungs )", "scrolls", "Terrell Suggs", "Sam", "August 22, 1980", "the optic disc", "letter series", "The New Day would continue to successfully retain their championship against Gallows and Anderson in the following months, such as SummerSlam on August 21, Clash of Champions on September 25 and the following night on Raw, ending their feud", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal, and the southern terminus is at an interchange with US 250 near Interstate 64 ( I - 64 ) in Rockfish Gap", "the Confederacy", "1955", "via redox ( both reduction and oxidation occurring simultaneously ) reactions, and couples this electron transfer with the transfer of protons ( H ions ) across a membrane", "out of 2 total", "Most wins", "2004 and 2008", "on 3 September", "three", "minimum viable product that addresses and solves a problem or need that exists", "Wyatt `` Dusty '' Chandler ( George Strait )", "accepted into the Christian biblical canon, and to the present day some `` Nestorian '' churches such as the Church of the East reject it", "In the 1920s", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "camellia sinensis", "EU", "dharm", "Frank Fertitta, Jr.", "\"Coronation Street\"", "Michael A. Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry.", "complicated", "Crandon, Wisconsin,", "(Skippers)", "Lyme disease", "10 years", "Afghanistan's main funding source.\""], "metric_results": {"EM": 0.3125, "QA-F1": 0.4337059401621812}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 0.35294117647058826, 0.75, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.15384615384615385, 0.5, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.6341463414634146, 1.0, 1.0, 0.08333333333333334, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-7459", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-7012", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-5738", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4202", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.3125, "CSR": 0.48958333333333337, "EFR": 1.0, "Overall": 0.6817447916666667}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day", "Afghanistan", "a sauce", "suffrage", "(Aragorn)", "Marcia Clark", "a gourmet", "a cloudy day", "Philip Berrigan", "wheat", "Carole King", "Spain", "the Pro-Jig Clamp Set", "Christo", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "Richard Blumenthal (born February 13, 1946)", "the Channel Islands", "Krackel", "Penelope", "I", "a bonobo", "Harry's Harbor Bizarre(2)", "Veep", "an NAF, Japan", "lullaby", "a rubies", "Pan's Labyrinth", "(sp) Barrie", "John Irving", "a Demonstrative Pronouns", "the Who", "Europe and Asia", "Xerox", "virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "World War II", "Beijing", "Lee Harvey Oswald", "George Armstrong Custer", "Newton's Second Law", "a vocalist", "Stockholm", "Alaska's Glacier Bay", "a puff", "Mausoleum", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004", "Matthew 2:11", "Pentateuch", "saint Cecilia", "Germany", "1989", "Suzuki 600", "nose, cheeks, upper jaw and facial tissue", "Donald Trump and Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6321914017131243}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7804878048780487, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 0.4, 0.8750000000000001, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-3101", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-13000", "mrqa_searchqa-validation-9881", "mrqa_naturalquestions-validation-6720", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1587"], "SR": 0.53125, "CSR": 0.49015410958904104, "EFR": 1.0, "Overall": 0.6818589469178081}, {"timecode": 73, "before_eval_results": {"predictions": ["a symphony", "Happy Days", "Rita Mae Brown", "Bolivia", "Kansas", "a grasshopper", "the executive officer", "a commercial", "1876", "a broody hen", "a spectator", "The Big Sleep", "Maryland", "Munich Bavaria", "pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Bruce Rauner", "Goofy", "the Chicago Bears", "Mount Everest", "Winston Rodney", "a poem", "the Teal", "the Tom Thumb", "Prince Edward Island", "the Mad Hatter", "a turkey", "Cincinnati", "to absorb sweat in an effort to aid the athlete's performance", "a Steinway piano", "a mushroom", "peanut butter", "basketball", "Tom Petty", "Tuscany", "Tunisia", "Rosa Parks", "an inch", "Paris", "William Henry Harrison", "Corinthian", "a gram", "Bern", "Prada", "the Chicago Civic Center", "the umbilical cord", "a ship", "the motto of the U.S. state of Ohio", "October 22, 2017", "Terrell Owens", "as the second single from the duo's debut studio album, Skrillex and Diplo Present Jack \u00dc ( 2015 )", "tipping point", "scotland", "epeiric", "James Harden", "subgenre of dark wave music", "Ron Goldman", "\"Mad Men\"", "\"fusion teams,\"", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6418402777777777}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.8, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-10697", "mrqa_searchqa-validation-11051", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-16213", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-403", "mrqa_searchqa-validation-11341", "mrqa_searchqa-validation-2988", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15975", "mrqa_searchqa-validation-12320", "mrqa_searchqa-validation-15724", "mrqa_searchqa-validation-2797", "mrqa_searchqa-validation-7654", "mrqa_naturalquestions-validation-7366", "mrqa_triviaqa-validation-4662", "mrqa_hotpotqa-validation-5148"], "SR": 0.609375, "CSR": 0.49176520270270274, "EFR": 1.0, "Overall": 0.6821811655405405}, {"timecode": 74, "before_eval_results": {"predictions": ["Urban Outfitters", "the Tyger", "\"The River\"", "The Last Supper", "Baccarat", "a bishop", "Harlem", "(Jheronimus) Bosch", "hulls", "Unity Recovery Center", "a cricket", "India", "Children of Men", "Skagway", "a petition", "Hippolyta", "a species", "John Galt", "spinach", "milk", "1,000 watts", "a toadstool", "World War I", "a student loan", "St. Louis", "Kobi Malkin", "Wolfgang Puck", "dachshund", "John Ericsson", "Cyprus", "Milwaukee", "coffee", "Kevin Costner", "\"Hot Lips\"", "Isadora Duncan", "Pig Latin", "Little Debbie", "Gerald Ford", "Speed Racer", "(John) Mellencamp", "Aristotle", "Code Black", "the Eagles", "An American Tail", "(Los Angeles)", "argyle", "Honda", "Setonix brachyurus", "a leather feather", "Mark Twain", "Greg Montgomery", "1918", "Mel Tillis", "Michael Moriarty", "(James Christopher) Bolam", "pawns", "brazil", "House of Habsburg-Lorraine", "SS", "Kansas\u2013Nebraska Act of 1854", "Orbiting Carbon Observatory", "South Africa", "Tuesday.", "two"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6270833333333334}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-11529", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-2238", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-1126", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-774", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-6329", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3779", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.578125, "CSR": 0.49291666666666667, "EFR": 1.0, "Overall": 0.6824114583333334}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "state", "1900", "at the origin", "Yuzuru Hanyu", "Michael Crawford", "Ceiba speciosa", "Hold On", "the Allies", "November 2016", "Empiricism", "Identification of alternative plans / policies", "17 - year - old Augustus Waters", "Greenland ( / \u02c8\u0261ri\u02d0nl\u0259nd / ; Greenlandic : Kalaallit Nunaat, pronounced ( kala\u02d0\u026cit nuna\u02d0t )", "Johnson", "Song of Songs", "Taron Egerton", "it failed to enforce its rule", "acronym", "Sheev Palpatine", "tokyanka Tripathi", "September 24, 2012", "Lex Luger", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "American indie pop band Foster the People", "Marshall Crenshaw", "Daniel A. Dailey", "Mickey Mantle", "addition", "February 3, 2017", "Kid Creole and the Coconuts", "before the start of the era", "2010", "a microfilament", "1983", "John Roberts", "President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Mahinda Rajapaksa", "1773", "Buddhism", "introverted Thinking ( Te ), Extroverted Intuition ( Ne ) )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "dogger", "t.S. Eliot", "RATE", "Hickam Air Force Base", "Rihanna", "his comments had been taken out of context.", "fractured pelvis and sacrum", "in 2001", "a debt", "Blackbird", "Meredith Grey", "September 25, 2017"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5644652496626181}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.10526315789473684, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7142857142857143, 0.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.4444444444444445, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-10448", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-5781", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.515625, "CSR": 0.4932154605263158, "EFR": 0.967741935483871, "Overall": 0.6760196042020373}, {"timecode": 76, "before_eval_results": {"predictions": ["makes Maria a dress to wear to the neighborhood dance", "Walter Mondale", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "in 1942", "awarded to the team that lost the pre-game coin toss", "16 May 2007", "15", "Ronald Reagan, who was 73 years, 274 days old at the time of his election to a second term", "once every 23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "Mockingocytes -- Part 2 ( 2015 )", "the President of India", "the fingers on either side of the mouth ( usually with the knuckles facing the observer ) and to stick the tongue out", "28 %", "American singer Elvis Presley", "Native American nation from the Great Plains", "Jack Scanlon", "during the 2013 -- 14 television season", "Elijah Wood", "head - up", "Doug Pruzan", "1984", "Donna Reed", "inside the cell nucleus", "pathology", "the age of about 14", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Jourdan Miller from Bend, Oregon", "Panzerkampfwagen VIII Maus", "exclusive rights granted by a sovereign state or intergovernmental organization", "toasted wheat bun", "Pittsburgh Steelers ( 6 -- 2 )", "40 %", "Janie Crawford", "the east coast of Queensland", "2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "Montreal Canadiens", "around 1872", "Bill Colman", "starch", "carbon", "the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Phelan Beale", "one", "Government Accountability Office report", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "double-breasted", "Heroes", "the book of the Dead", "since 1983."], "metric_results": {"EM": 0.46875, "QA-F1": 0.6174988753936121}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, true, true, false], "QA-F1": [0.13333333333333333, 0.0, 0.2222222222222222, 0.6666666666666666, 1.0, 0.0, 0.15384615384615385, 0.21052631578947367, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.16666666666666666, 0.5714285714285715, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.4, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-6137", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-377"], "SR": 0.46875, "CSR": 0.4928977272727273, "EFR": 0.9705882352941176, "Overall": 0.676525317513369}, {"timecode": 77, "before_eval_results": {"predictions": ["zoster", "zork", "roddy dogger", "jaggers", "prussia", "edward kipling", "phoebus", "phyllis hyman", "exclaves", "seattle", "Brian Close", "a cabbage worm", "london", "edward", "meter maid", "cricket", "pho\u00eet", "phoibain", "Vimto", "phobia", "leicestershire", "carry On", "phoatic region", "taste", "drums", "phogeography", "sesame seed", "ezeplechase", "The Centaurs", "tallest building", "football", "phonies", "doppelg\u00e4nger", "Giglio", "dutch", "stanyan Street and Golden Gate Park", "phoebus", "Harry patch", "funny Folks", "Sight & Sound", "st. peter", "ra(dio) d(etecting a(nd) r(anging)", "nelson", "day newspaper", "trousseau", "oregon", "stisa connan", "dragon", "supercontinent", "salyut 1", "phoibbean", "Whiskey Shivers as Saddle Up, a country - bluegrass - based band competing against the Bellas", "62", "Matthew Gregory Wise", "1861", "Bur\u016b Doragon", "Limbo", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.375, "QA-F1": 0.4695684523809524}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-4651", "mrqa_triviaqa-validation-7531", "mrqa_triviaqa-validation-333", "mrqa_triviaqa-validation-2", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-5989", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-7709", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7059", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-4321", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-57", "mrqa_triviaqa-validation-3613", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.375, "CSR": 0.49138621794871795, "EFR": 1.0, "Overall": 0.6821053685897436}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he believed he was about to be attacked himself.", "1960", "\"he was there before Tiger Woods,", "\"momentous discovery\"", "Al-Aqsa mosque", "the first wicket with Tharanga Paranavitana, who made 53.before becoming Harbhajan's first victim just before lunch.", "as soon as 2050,", "Sylt", "media", "at least four of them.", "Barack Obama", "Arnoldo Rueda Medina.", "left his indelible fingerprints on the entertainment industry.", "ketamine.", "Brian David Mitchell,", "Defense of Marriage", "Jacob,", "Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "new equipment, and neuroethicists focus on whether a new device fits ethical guidelines.", "1957", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda,", "Manmohan Singh's Congress party", "find calmness in a prison culture fertile with violence and chaos.", "outfit from designer Britt Lintner", "one day,", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's Japan.", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "people", "not feel Misty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$8.8 million", "Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Hungary", "4", "return of a fallen U.S. service member", "model", "Mike Quinn as Craig Belden", "Easter eggs", "16 seasons", "pluribus unum", "well", "China", "The Five Boroughs of the Danelaw", "\"I Should Have Known Better\"", "pornographicstar", "the burning bush", "lake", "Fannie Merritt Farmer", "freedom of choice, other social freedoms, and \"laissez-faire\" capitalism, while also being critical of authority."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5877884816207184}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 0.6666666666666666, 0.22222222222222224, 0.7499999999999999, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.8, 1.0, 1.0, 0.75, 0.0, 0.0, 1.0, 0.0, 0.8, 0.2105263157894737]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-337", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-1390", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-7235", "mrqa_triviaqa-validation-7665", "mrqa_hotpotqa-validation-5750", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-7153", "mrqa_hotpotqa-validation-3140"], "SR": 0.46875, "CSR": 0.4910996835443038, "EFR": 1.0, "Overall": 0.6820480617088608}, {"timecode": 79, "before_eval_results": {"predictions": ["1866", "Grant", "Yangtze River", "Genesis", "Anne", "The New York Times", "Australia", "Oklahoma", "Communist Party", "the 1950s", "Humphry Davy", "region of Asia", "(scheduled length)", "smallpox", "Dead Sea", "the fairway", "\"Hill Street Blues\"", "to help control swelling as well as immobilize and support your injury", "Mao Zedong", "Harriet the Spy", "Mickey Mouse", "Xerox", "a blitz", "Jamaica", "gossip", "an exothermic reaction", "canibalism", "Morocco", "Surf's Up", "Yao Ming", "U.S. government agency", "Clothes Off Our Back", "Marvell", "a vegetable", "Bollywood", "\"titanic\"", "\"Born To The Ballgame\"", "parapet", "joe", "a diary", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Surinam", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal Virgins", "The Lord of the Rings: The Return of the King", "Fidel Castro", "H CO ( equivalently OC ( OH ) )", "During his epic battle with Frieza", "W. Edwards Deming", "clara", "Doug Trendle", "Extras", "Ricky Marco i Vives", "edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "Demjanjuk", "2,579"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6842013888888889}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.8, 0.4, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14620", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-3519", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-2149", "mrqa_searchqa-validation-5810", "mrqa_triviaqa-validation-7308", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118"], "SR": 0.578125, "CSR": 0.4921875, "EFR": 0.9629629629629629, "Overall": 0.6748582175925926}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "James Maitland \" Jimmy\" Stewart", "Waimea Bay", "the Virgin label", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "the October Revolution", "7pm", "Francis Schaeffer", "26,788", "(nine)", "ancient Troad region of western Anatolia", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "the Royal Albert Hall", "The More", "England", "Workers' Party", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "his exploration and settlement of what is now Kentucky", "six-time Silver Slugger Award winner", "Mauthausen-Gusen", "Adrian Peter McLaren", "Distillery", "Theodore Anthony Nugent", "New York", "Viscount Cranborne", "The 49th Disney animated feature film", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "Boulder, Colorado", "Dutch", "September 14, 2002", "Boston", "\"8 Simple Rules\"", "Brendan O'Brien", "Delphine Software International", "Sullivan", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "power of the purse to control and direct the activities of state government and the strong constitutional connections between it and the Lieutenant Governor of Texas", "September 15, 2012", "Virginia Wade", "Vienna", "Malaysia", "Akio Toyoda", "Iran's nuclear program.", "The Chevy Equinox", "the78rpmrecordspins", "Seoul", "(Henry) Tudor", "soybeans"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6036458333333333}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.19999999999999998, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-1121", "mrqa_hotpotqa-validation-5694", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-1305", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-5476", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-5371", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-10352"], "SR": 0.484375, "CSR": 0.4920910493827161, "EFR": 1.0, "Overall": 0.6822463348765432}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four members", "1853", "Allies of World War I", "Acid house", "Esteban Ocon", "Lady Frederick Winkleman", "Perfume: The Story of a Murderer", "Barbara Feldon", "Razor Ramon", "Birmingham, Alabama", "Nobel Prize in Physics", "Adam Karpel", "American R&B singer, guitarist, songwriter and music producer", "14 November 1968", "Windermere, Cumbria", "Frank Lowy", "Hermione Baddeley", "MediaCityUK tram stop", "Accolade Wines", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "McLaren-Honda", "Ambroise Thomas's", "The Books", "\"The New York Times\"", "Annales de chimie et de physique", "Nairobi, Kenya", "English Electric Canberra", "March, 1904", "Washington, D.C.", "Russian rock group", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoons", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1938", "British Columbia, Canada", "F. Scott Fitzgerald\\'s 1925 novel", "willow", "Cliff Thorburn", "Kim Clijsters", "Mombasa, Kenya,", "Bhutto's husband of 20 years, Asif Ali Zardari, two daughters and a son.", "basic", "New York City Ballet", "volts", "Willa Cather"], "metric_results": {"EM": 0.4375, "QA-F1": 0.533247655122655}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-555", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-232", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-3696", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_naturalquestions-validation-2624", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-873", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.4375, "CSR": 0.4914253048780488, "EFR": 1.0, "Overall": 0.6821131859756097}, {"timecode": 82, "before_eval_results": {"predictions": ["in 1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "four", "October 23, 1971", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian language", "\"The Late Late Show\"", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "R.E.M.", "Parlophone", "January 15, 2016", "(IATA: VNO, ICAO: EYVI) (Lithuanian: \"Vilniaus oro uostas\"", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rk Anders, and Paolo Bonacelli", "\"The Worm\"", "Herman's Hermits", "Ustad Vilayat Khan", "810", "German mathematician", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Daniel Espinosa", "novel", "Fluffy", "3,384,569", "in East Mamprusi district, of the Northern Region of Ghana", "2 March 1972", "Great Smoky Mountains National Park", "La Scala, Milan", "public and private life", "Gary Ross", "Columbia River", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "born 2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium", "Amybeth McNulty", "the Super Bowl", "Wichita", "ringo Starr", "1882", "off the coast of Dubai", "Sunday evening", "granting some benefits", "the AT bus", "the Polio Vaccine", "the treble clef", "gun"], "metric_results": {"EM": 0.5625, "QA-F1": 0.671131148440931}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false], "QA-F1": [0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8695652173913043, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2240", "mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-2244", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2885", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-2483", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-904", "mrqa_hotpotqa-validation-1559", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-571", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_newsqa-validation-1245"], "SR": 0.5625, "CSR": 0.49228162650602414, "EFR": 1.0, "Overall": 0.6822844503012048}, {"timecode": 83, "before_eval_results": {"predictions": ["John F. Kennedy", "Metacom", "Chicago", "Leon Trotsky", "a loaf", "a family tree", "NY Times", "Martin Van Buren", "My Girls", "Winnie-the-Pooh", "Graeme Kay", "Alexander Graham Bell", "(Vijay) Singh", "clouds", "a modem", "Canada", "the Boston Red Sox", "Jon Stewart", "Mussolini", "the human breast", "Oliver Sacks", "Christo", "Kirstie Alley", "Ichiro Suzuki", "Frank Sinatra", "Horn of Africa", "the banjo", "Grant", "Belle Watling", "Mozart", "American alternative rock band", "Nellie Bly", "Byron", "meningitis", "Douglas MacArthur", "3M", "The Rolling Stones", "Edie Falco", "U.S.A.", "Oneonta College", "1936", "the CN Tower", "(Andrew) Paquin", "inheritance", "Maryland", "the cardinal", "Japan", "cattle", "Prince Edward Island", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "Cliff Thorburn", "730,000", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul Krugman", "1959.", "The son of Gabon's former president", "the United States", "late November or early December"], "metric_results": {"EM": 0.609375, "QA-F1": 0.678422619047619}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-889", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3923"], "SR": 0.609375, "CSR": 0.49367559523809523, "EFR": 1.0, "Overall": 0.682563244047619}, {"timecode": 84, "before_eval_results": {"predictions": ["Buddhist", "Peter Pan", "Jabez Stone", "the Stony Creek Granite", "olives", "the buffalo", "Chloe Lattanzi", "Oahu", "Joseph Smith", "arthropoda", "Harry Truman", "Capricorn", "Diane Arbus", "chiles", "Thomas Jefferson", "Parliament", "soy miso", "Old School", "the Distant Early Warning Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "the Art Journal", "Robert Bruce", "Zinc", "oxygen", "gargantua", "Elke Sommer", "the horn", "Robin Williams", "Philadelphia", "Ivory soap", "Faust", "The Five People You Meet in Heaven", "the Anglerfish", "the Big Cat", "Thomas Jefferson", "Gandhi", "Brazil", "Jim Thorpe", "Ed Helms", "Jack Crabb", "Lear", "the Super Jump", "the Bicentennial Symphony", "the Haunted Mansion", "Rembrandt", "Gilligan\\'s Island", "Nevada", "the Denver Rep11blican", "Manhattan", "Tom Robinson", "Andy Serkis", "Africa", "horizontal desire", "charlie darin", "Esp\u00edrito Santo Financial Group", "Herman\\'s Hermits", "Punjabi/Pashtun descent", "Asashoryu", "\"political and religious\"", "U.S. secretary of state.", "Newcastle Falcons"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5008680555555556}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.888888888888889, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-16755", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-16336", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_triviaqa-validation-5201", "mrqa_triviaqa-validation-4084", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-2724"], "SR": 0.421875, "CSR": 0.49283088235294115, "EFR": 0.972972972972973, "Overall": 0.6769888960651829}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "\"The Meryl Streep\"", "birds", "Virginia", "hot chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "Hamlet", "\"Green Acres\"", "a panic", "Gertrude Stein", "Pope John Paul II", "happiness", "Inigo Jones", "Charles Ponzi", "Amelia Earhart", "Tippi Hedren", "a programming language", "Nova Scotia", "chocolate", "tuna", "Absinthe", "the Lord of Macragge", "a kangaroo", "quid", "Lincoln", "Sammy Davis", "swimmer\\'s ear", "Uncle Henry", "the 2.4 GHz", "Greek", "Jeff Probst", "high school", "Gamal Abdel Nasser", "\"The Moment of Truth\"", "Laura", "a constellation", "Lynette", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "FDR", "Hellespont", "Katharine Hepburn", "a penny", "Young Frankenstein", "Walgreens", "to form a higher alkane", "comprehend and formulate language", "Hellenic polytheism", "south america", "The Shootist", "Sega Saturn", "the National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300", "it has not", "At least 88", "1981 drowning death,", "\"I wish we had this level of cooperation in every homicide that occurred.\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6529153138528139}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4, 1.0, 0.5, 0.5, 0.0, 0.18181818181818185]}}, "before_error_ids": ["mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-7459", "mrqa_searchqa-validation-9357", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-10463", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-2819", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_searchqa-validation-10146", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.5625, "CSR": 0.493640988372093, "EFR": 1.0, "Overall": 0.6825563226744186}, {"timecode": 86, "before_eval_results": {"predictions": ["Ann Doran", "at a given temperature", "season ten", "October 28, 2007", "seven", "absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "the northern terminus of Port Said", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the First Epistle of John", "between the stomach and the large intestine", "Gupta", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the pulmonary arteries", "St. Pauli Girl Special Dark", "Justin Timberlake", "Destiny's Child", "statistical", "Earle Hyman", "Husrev Pasha", "Anna Maria Demara", "The Osmonds", "The Drew Las Vegas", "converting glucose to glycogen", "chili con carne, nachos, hard Tac and fajitas", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Egypt", "nasal septum", "SIP ( Session Initiation Protocol )", "January 1, 1976", "parthenogenesis", "Implementation of plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "in the eye", "Donna Mills", "Donna", "annette Crosbie", "martin lewrey", "minder", "The leopard", "Tim Burton", "University Grants Commission", "Symbionese Liberation Army", "half the jobs involved in one of the latest subcontracts connected to the construction project", "two", "\"Like a Rock\"", "Rabbica", "King George III", "Norwegian"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6740846187803424}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.9166666666666666, 0.14285714285714285, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_triviaqa-validation-4028", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-3582", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-4175"], "SR": 0.5625, "CSR": 0.49443247126436785, "EFR": 0.9285714285714286, "Overall": 0.6684289049671592}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "The Franco-Prussian War", "the Hirsch index rating of all living chemists in the world", "Cody Miller", "1951", "Tara Strong", "The Ramna Stacks", "Book of Judges", "new, small and fast vessels such as torpedo boats and later submarines", "9 February 1971", "San Francisco", "\"Three\\'s Company\"", "9,984", "Kenan Thompson", "Marktown", "the Rose Theatre", "over 1 million", "Trey Parker and Matt Stone", "the Teatro Carlo Felice", "Fidenza", "237", "Shakespeare\\'s reputation", "balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel", "Michael Rispoli", "U2 360\u00b0 Tour", "Danny Green", "Scarface", "the Austro-Hungarian Army", "St. George, Maine", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "he abdicated in favour of his son Louis", "Vancouver", "Urijah Faber", "four", "1958", "The Thomas Crown Affair", "Bharat Ratna", "October 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings of the National Basketball Association", "Sam Kinison", "Ferdinand Magellan", "Franklin Roosevelt", "the 1920s", "Sundays", "jenny", "Puff the Magic Dragon", "dungarees", "Samoa", "flooding was so fast that the thing flipped over,\"", "\"Phantom of the Opera\" and \"Cats\"", "the fulsome", "Bath", "Winnipeg", "`` Merry Christmas ''"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5760416666666667}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.16666666666666666, 0.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-929", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2856", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-1302", "mrqa_hotpotqa-validation-2792", "mrqa_hotpotqa-validation-681", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-5932", "mrqa_triviaqa-validation-3809", "mrqa_triviaqa-validation-3147", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-2094", "mrqa_searchqa-validation-2044", "mrqa_searchqa-validation-15272", "mrqa_naturalquestions-validation-9361"], "SR": 0.4375, "CSR": 0.49378551136363635, "EFR": 1.0, "Overall": 0.6825852272727272}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as", "Ameneh Bahrami", "40", "state senators", "2005", "by text messaging,", "Alaska or Hawaii.", "Tuesday evening", "Brazil's", "her most important work is her charity, the Happy Hearts Fund.", "ability to scan military ID cards, known as \"Common Access Cards,\"", "Her husband and attorney,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "\"inappropriate,\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "because that would place it in clear violation of the Nuclear Non-Proliferation Treaty.", "Carnival", "Jared Polis", "summer", "southern port city of Karachi,", "allegedly involved in forged credit cards and identity theft", "said that anything could have stopped Robert Hawkins from going on a murderous rampage at an Omaha, Nebraska, shopping mall on Wednesday.", "Ricardo Valles de la Rosa,", "Islamabad", "Toffelmakaren.", "3 p.m. Wednesday", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra clan", "Nigeria,", "201-262-2800.", "South Africa", "measured about 60 feet wide by a few feet deep.", "France,", "Lisa Polyak,", "late Tuesday night,", "to reach car owners who haven't complied fully with recalls.", "Mashhad", "Australia", "Alina Cho", "Roger Federer", "last week,", "a Fitness equipment", "Nancy Edmunds", "10", "This will be the second", "Saxony, Thuringia and Saxony - Anhalt", "Rust", "gastrocnemius muscle", "Granada", "axe", "south of the famous Douro Valley", "June 17, 2007", "England", "Black Elk Speaks", "hollandaise", "Kwanzaa", "a frog", "leopard"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6092243141275648}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.10526315789473685, 0.08, 0.8, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-706", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2641", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-474", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-2642", "mrqa_naturalquestions-validation-8625", "mrqa_triviaqa-validation-6987", "mrqa_triviaqa-validation-4976", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749", "mrqa_hotpotqa-validation-855"], "SR": 0.515625, "CSR": 0.4940308988764045, "EFR": 1.0, "Overall": 0.6826343047752809}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "Reporters Without Borders", "killing rampage.", "Eintracht Frankfurt", "it was brought in the Eastern District of New York because al-Moayad allegedly collected terrorist funds at the al-Farooq mosque in Brooklyn.", "The federal officers' bodies", "Bill Haas", "Larry Ellison,", "cannot to pass significant restrictions on war funding because Republicans, for the most part, have stuck with Bush on the war.", "rising disposable income and an increasing interest in leisure pursuits, a growing number of courses, more television coverage and availability of EU funds,", "Joan Rivers", "just over", "Jaime Andrade", "KBR's", "Charles, the capital of Coptic Christianity.", "Aniston, Demi Moore and Alicia Keys", "two years,", "the body of the aircraft", "United States, Japan, Russia, South Korea and China,", "unclear until now.", "\" patterns matching.\"", "\"Gandhi,\"", "almost 9 million", "some U.S. senators", "Turkey,", "London and Buenos Aires", "she returned to Pakistan in October after President Pervez Musharraf signed an amnesty lifting corruption charges.", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "a bank", "two", "it was found in a canyon in the path of the blaze Thursday.", "At least 38", "Sri Lanka", "The BBC", "to avoid an area in the Sea of Japan", "after they ambushed a convoy carrying supplies for NATO forces in southern Afghanistan,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris late Sunday night in the area where the single-engine Cessna 206 went down,", "Aniston, Demi Moore and Alicia Keys", "ALS6,", "The EU naval force", "well over 1,000 pounds).", "Iran's Green Movement of protesters", "more effectively restore the vehicles to their pre-accident condition.", "1980 Nobel Peace Prize.", "provides nearly $162 billion in war funding", "Lindsey Vonn", "three", "the optic chiasm", "Hugo Weaving", "aragonite", "fire to someone else's car", "Tacoma", "Bruce R. Cook", "Los Angeles, California", "86,112", "Tweedledee", "a soap opera", "the CPI", "penrhyn castle"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5659076642443578}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.19354838709677416, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.8, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.923076923076923, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-816", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-213", "mrqa_newsqa-validation-3267", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-515", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_hotpotqa-validation-2460", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.453125, "CSR": 0.4935763888888889, "EFR": 1.0, "Overall": 0.6825434027777778}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Pluto", "larynx", "the Surgeon General", "Ebony", "Cook County", "Sartre", "Wordsworth", "St. Louis", "Polk", "Harpy", "lacrosse", "Naples", "The Hatter", "the Jews", "a cow pie", "Paradise Lost", "beautiful", "the White Sea", "Doctor Dolittle", "Memphis", "Mitch Albom", "Oregon", "earthquakes", "Donovan", "musicals", "Bionic Woman", "the multitude", "a tan", "Narnia", "a comet", "cedar park", "Kamehameha", "(Elbert) Gary", "corporality", "crowded", "'Duke'", "Orleans", "\"Another Brick in the Wall\"", "Pulp Fiction", "Hester Prynne", "pajamas", "China Airlines", "bagpipes", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "Chile", "Sydney", "central Saskatchewan", "the original timeline is eventually restored", "recessive", "Islands of the Blessed", "Another Day in Paradise", "The Danelaw", "Donald Wayne Johnson", "Robert Allen Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "North Korea", "financial gain,"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7182291666666667}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-16561", "mrqa_searchqa-validation-4704", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-15409", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-15887", "mrqa_searchqa-validation-10975", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-10583", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072"], "SR": 0.671875, "CSR": 0.4955357142857143, "EFR": 1.0, "Overall": 0.6829352678571429}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff", "keirin", "welterweight", "christopher nolan", "Schopenhauer", "highball", "arthur conan doyle", "lady Godiva", "a heart", "six", "Bashir", "dog sport", "\"the Double\"", "aluminium", "calcium", "a cat that had the original name of dippy dog", "can be 108 or 126 gallons", "the Welcome Stranger", "the recorder", "Oman", "Genesis", "Ladysmith", "californium", "robert robert gaul", "york Yankees", "george Orwell", "kibbutznik", "canada", "an appetizer", "william shrew", "1960s", "some like it hot", "portugal", "opium", "christopher roddy fothergill", "Sarajevo", "king edward ii", "st. thomas", "bullfighting", "leicestershire", "pelvis", "Crimea", "pea", "seattle", "seattle", "Twelfth night", "robert lowest", "a spotter", "france", "australia", "france", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1898", "January 1923", "South Asian Games", "Ramanaidu Daggubati", "four", "1,500", "15-year-old", "18 feet", "the Marquis de Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5133928571428572}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-600", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-1651", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-7550", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-3153", "mrqa_triviaqa-validation-4508", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3375", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-5466", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-369", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-3840", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134"], "SR": 0.46875, "CSR": 0.49524456521739135, "EFR": 0.9705882352941176, "Overall": 0.6769946851023018}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Staubach", "1979", "second", "2001", "Meghan Markle", "2006", "alcoholic drinks", "Seoul, South Korea", "Dutch", "vice president", "political correctness", "robert henke", "Wisconsin", "November 23, 2011", "more than 40 million", "Mazda", "Jack Kilby", "\"My Father\"", "water", "more than 70", "blood pudding", "Animorphs", "Francis", "two", "Emperor of Japan", "dinosaurs", "TD Banknorth Garden", "the controversial and explicit nature of many of their songs", "Sam Kinison", "Melbourne Storm", "Hawaiian", "2007", "Texas", "Prudence Jane Goward", "Vince Guaraldi", "\"What's My Line?", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Lauren Lane", "Joseph I", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "2018 Unibet Premier League Darts", "first freshman", "Canada", "a defense against rain rather than sun", "euro", "Jane Seymour", "willie nelson", "1984", "Argentine", "3.5 percent", "Ali Bongo", "Antietam", "your premium", "Princeton", "Cotto"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6972947191697192}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.15384615384615385, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1662", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-372", "mrqa_hotpotqa-validation-1849", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-5319", "mrqa_hotpotqa-validation-294", "mrqa_naturalquestions-validation-7425", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038", "mrqa_newsqa-validation-3511"], "SR": 0.546875, "CSR": 0.49579973118279574, "EFR": 1.0, "Overall": 0.6829880712365591}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "American stand-up comedian", "Edward R. Murrow", "Liesl", "Stage Stores", "\" Training Day\" (2014)", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "High Knob", "Dayton's department store", "1 September 1864", "its eclectic mix of musical styles incorporating elements of disco, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the engineering group of the Provisional Irish Republican Army", "Tel Aviv", "Chevy Motor Car Company", "sexual disorders and dysfunctions", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America", "\"Love Letter\"", "1977 to 2013", "Jericho Union Free School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Scottish novelist and poet", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "the district of Sierre", "Buffalo", "Gatwick Airport (also known as London Gatwick)", "George Martin", "Timo Hildebrand", "Adam Dawes", "Maasai", "Rockland, Maine", "2010", "the Vietnam War", "Toto", "9 February 2018", "Cheap Trick", "Gabriel Byrne, Kevin Spacey, Benicio Del Toro, Kevin Pollak, and Stephen Baldwin", "Funchal", "British", "Scudetto", "it would", "because a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7297356442577031}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.22222222222222224, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-4194", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-5279", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-2849", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694"], "SR": 0.59375, "CSR": 0.496841755319149, "EFR": 1.0, "Overall": 0.6831964760638297}, {"timecode": 94, "before_eval_results": {"predictions": ["a drummer", "Hitler", "a Greer Garson film", "Simon Cowell", "The Eagles", "a neon sign", "lifejackets", "Ian Fleming", "the Taming of the Shrew", "Anne Frank", "Bora", "The Chinese Orphan", "Nassau", "a geisha", "France", "the Barbary pirates", "the Iran branch", "yeast", "the Pearl", "forty days", "Phonetics", "Stills", "Frasier", "paper tickets", "a projectile", "the Constitutional Council", "Chiapas", "\"Jeopardy\"", "Afghanistan", "Australia", "a mozzarella", "Seoul", "Surgeons", "pitch", "Pete Rose", "Esther", "South Africa", "Bacall", "the GoldenEye", "art of cultivating soil", "Dumbo", "Wharton", "Aretha Franklin", "marsupials", "Spanish", "The Crow", "Ripken", "Orson Welles", "a mongoose", "( Russell Crowe)", "Ecuador", "Koine Greek : apokalypsis", "four", "to keep the peace", "Friends", "frankincense", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "Karolina Dean", "Pieter van Musschenbroek", "Seoul", "everyone welcomed me back with open arms and it was a wonderful homecoming,\"", "the Klan had become so powerful and intimidating that police were hesitant to build a case against them.", "Krankies"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6900094696969696}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.7272727272727273, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-11593", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-11108", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-307", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.609375, "CSR": 0.49802631578947365, "EFR": 1.0, "Overall": 0.6834333881578947}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin", "Kokomo", "Profiles in Courage", "the College of California", "the summer session", "Lady Godiva", "Beat The Clock", "the Sadler", "Dag Hammarskjld", "Latin", "Charles I", "San Francisco", "\"The Secrets of a Fire King\"", "Neptune", "Harry Potter", "Brutus", "Mickey", "(Franz) Joseph Haydn", "Willa Cather", "the Dow Jones Industrial Average", "Aunt Jemima", "the fowls", "\"New Kingdom\"", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "middle-aged", "B.B. King", "JFK", "Donovan", "cephalopod", "Candlestick Park", "a jointer plane", "just compensation", "Tvoe zdorovie", "Pastrami", "the charm", "heresy", "Ivy Dickens", "the faint", "Siegfried", "(Andrew) Japheth", "Calamine", "Sicily", "Admiral Horatio Nelson", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Caleb", "31 December 1960", "Wu Sangui", "order of the Friars of st. Francis of Wycombe", "\"Little arrows\"", "Rotary", "Craig William Macneill", "Matilda of Anjou", "twenty", "Newark, New Jersey", "4,000", "Teresa Hairston", "paul"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6380208333333334}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14077", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-9089", "mrqa_searchqa-validation-11613", "mrqa_searchqa-validation-11669", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-10119", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-12753", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-15970", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-417", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-2278", "mrqa_triviaqa-validation-833"], "SR": 0.578125, "CSR": 0.49886067708333337, "EFR": 0.9629629629629629, "Overall": 0.6761928530092592}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "del Sarto", "Unbreakable", "Holy Week", "Tijuana", "a Wizard", "the yottabytes", "Planned Parenthood Federation of America", "Jamie Lee Curtis", "King of the Hill", "Abduction", "Alexander Graham Bell", "north-east", "baffle plate", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "giant slalom", "Medusa", "zoology", "\"Lucia di Lammermoor.\"", "a telescope", "cricket", "Stephen Hawking", "St. Francis of Assisi", "light", "The Scarlet Letter", "1997", "rehab facility", "pastries", "the Hundred Years War", "The Metropolitan Museum of Art", "milk and honey", "Three Is A Magic Number", "a lung liver", "The Beatles", "Bronx cheer", "saccharides", "King Kong", "Cubism", "Umbria", "cottage cheese", "M. C. Escher", "Oahu", "Kidney Anatomy", "Scott Fitzgerald", "an aria", "lively Weaver", "Marquette University", "the monk", "Fall 1998", "irritation", "Bart Howard", "portugal", "marillion", "Usain Bolt", "Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"To the Muslim world, we seek a new way forward, based on mutual interest and mutual respect.\"", "in early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7584077380952381}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-9540", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-12798", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-14498", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-7573", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_triviaqa-validation-3952", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.640625, "CSR": 0.5003221649484536, "EFR": 1.0, "Overall": 0.6838925579896907}, {"timecode": 97, "before_eval_results": {"predictions": ["three", "three", "Gaston Leroux", "the Concorde", "gold", "the EEC", "netherlands", "Vietnam", "netherlands", "Wanderers", "emilia fox", "Amnesty", "San Marino", "Shaft", "gal", "Ramadan", "bizet", "the Count Basie Orchestra", "Pegida", "osmium", "kevin strong", "edward hopper", "Einstein", "Faversham", "Justin Trudeau", "kevin kline", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "netherlands", "christian wulff", "brandy", "usk", "spider", "Malcolm Turnbull", "daily herald", "nairobi", "Alan Turing", "sternum", "the heart", "Puck", "netherlands", "dubonnet", "Lady Susan", "Rocky Graziano", "a sternum", "Today newspaper", "netherlands", "Gene Vincent", "midgard", "its enzymatic activation", "the Chesapeake", "Ben Faulks", "as an infinite sum of terms that are calculated from the values of the function's derivatives", "Dwarka", "Art of Dying", "John Auer,", "Apple", "Christopher Savoie", "Poseidon", "Ingenue", "the First World War", "Joseph"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6167279411764706}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.47058823529411764, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-2947", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-4006", "mrqa_triviaqa-validation-4806", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-2039", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-2098", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947", "mrqa_searchqa-validation-1427"], "SR": 0.578125, "CSR": 0.5011160714285714, "EFR": 1.0, "Overall": 0.6840513392857142}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "auld reekie", "hippopotamus", "cirrus uncinus", "Procol Harum", "the Alt", "belfast", "bude", "Uganda", "st pancras", "lactic acid", "marne", "robinson Crusoe", "once a week", "my Favorite Martian", "bridge", "claustrophobia", "china", "Wyatt Earp", "May", "one Direction", "Diary of a Tuber", "Prince Harry", "1994", "titanium", "country park", "Pegasus", "alaskan", "robin williams", "brazil", "mustard", "swimming pools", "eyes", "belfast", "Bowie knife", "caspian seas", "a rat", "Independence Day", "Tinie Tempah", "portugal", "georgia", "baby buggy", "beard", "Little Dorrit", "robin williams", "The Sunday Post", "bobby darin", "uae", "robin williams", "mansfield park", "south africa", "Cam Clarke", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican War on Drugs", "one child, Lisa Brennan-Jobs", "opium", "Basilan", "Tutsi and Hutu", "The Tempest", "Naples", "Solomon", "heavier than a feather"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5029017857142857}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2636", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2107", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-5613", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.453125, "CSR": 0.5006313131313131, "EFR": 0.9428571428571428, "Overall": 0.6725258161976913}, {"timecode": 99, "UKR": 0.693359375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.818359375, "KG": 0.47265625, "before_eval_results": {"predictions": ["angry mob.", "third", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Somalia", "prostate cancer,", "Philip Markoff", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her;", "\"Red Lines,\"", "Kirchners", "an African-American woman for the job.", "Arsene Wenger", "Gary Coleman", "in the Louvre", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke", "missing", "June 25.", "\"El Viceroy\" and \"El General,\"", "Kerstin and her family", "Amnesty International", "Spiderman", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "intervene openly in its neighbors' internal affairs,", "lump in Henry's nether regions", "late Thursday to form a government of national reconciliation.", "record flood levels on several rivers.", "\"Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "five days a week.", "Oprah Winfrey", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "performance of a 15-year-old boy", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "Three thousand", "Palestinian Islamic Army,", "cause of the child's death will be listed as homicide by undetermined means,", "separately on multiple corruption charges.", "2,000", "near his Seattle home.", "Cirque du Soleil", "43", "10 percent.", "hydrogen", "Bobby Darin", "foreign investors", "neck", "Mondel\u0113z", "CBS", "in round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.53125, "QA-F1": 0.58515625}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.888888888888889, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2925", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3457", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1992", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-3835", "mrqa_newsqa-validation-3450", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_triviaqa-validation-3949", "mrqa_hotpotqa-validation-2793"], "SR": 0.53125, "CSR": 0.5009375, "EFR": 1.0, "Overall": 0.6970625}]}