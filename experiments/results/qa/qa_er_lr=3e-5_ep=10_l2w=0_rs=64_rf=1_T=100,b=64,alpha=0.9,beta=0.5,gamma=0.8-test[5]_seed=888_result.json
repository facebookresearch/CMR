{"method_class": "er", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_er_lr=3e-5_ep=10_l2w=0_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-test[5]_seed=888', diff_loss_weight=0.0, gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=10, kr_eval_mode='metric', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='experiments/ckpt_dirs/qa/er/qa_er_lr=3e-5_ep=10_l2w=0_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-test[5]_seed=888/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, replay_candidate_size=8, replay_frequency=1, replay_size=64, save_ckpt_freq=25, skip_instant_eval=False, total_steps=10000, upstream_sample_ratio=0.5, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=16, result_file='experiments/results/qa/qa_er_lr=3e-5_ep=10_l2w=0_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-test[5]_seed=888_result.json', stream_id=5, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-test.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 11730, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["a plug valve", "1550", "French Louisiana west of the Mississippi River", "2012", "carbon dioxide", "the Lisbon Treaty", "all colors", "in the chloroplasts of C4 plants", "An attorney", "democracy", "The Greens", "third", "Enthusiastic teachers", "expositions", "no French regular army troops were stationed in North America", "estates of the Holy Roman Empire", "Stromatoveris", "2011", "Louis Pasteur", "the owner", "Time Lord", "mosaic floors", "economic", "1893", "environmental factors like light color and intensity", "Gandhi", "deforestation", "Middle Rhine Valley", "pump this into the mesoglea", "low-light conditions", "No Child Left Behind", "one way streets", "\u20ac25,000 per year", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "unbalanced torque", "Ulaanbaatar", "power", "very weak", "Judith Merril", "Gender pay gap", "the Ilkhanate", "it is open to all irrespective of age, literacy level and has materials relevant to people of all walks of life", "University of Chicago campus", "3D printing technology", "1957", "2000", "a certain number of teacher's salaries are paid by the State", "the Dutch Republic", "San Jose Marriott", "April 20", "the Commission", "evacuate the cylinder", "the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "Hurricane Beryl", "temperature and light", "terra nullius", "growth", "human", "the \u2018combs\u2019", "1978", "non-Catholics", "Sanders", "vice president", "700 employees"], "metric_results": {"EM": 0.828125, "QA-F1": 0.8576388888888888}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10143", "mrqa_squad-validation-8841", "mrqa_squad-validation-2145", "mrqa_squad-validation-739", "mrqa_squad-validation-4452", "mrqa_squad-validation-3019", "mrqa_squad-validation-7449", "mrqa_squad-validation-9173", "mrqa_squad-validation-7364", "mrqa_squad-validation-9764", "mrqa_squad-validation-7051"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["1986", "carotenoid pigment", "standardized", "50% to 60%", "Stromatoveris", "lower incomes", "Fort Duquesne", "Katharina von Bora", "Miller", "women", "Three's Company", "Frank Marx", "the architect or engineer", "greater than $2 million", "superintendent of New York City schools", "San Francisco Bay Area at Santa Clara, California", "Kingdom of Prussia", "the same league as the Asian Economic Tigers", "Palestine", "Aristotle and Archimedes", "in the chloroplasts of C4 plants", "Outlaws", "increased blood flow into tissue", "Edgar Scherick", "the 14th to the 19th century", "Gibraltar and the \u00c5land islands", "the Evangelical Lutheran Church", "oxygen", "the BBC National Orchestra of Wales", "Thanksgiving", "the founding of new Protestant churches", "it is impossible to determine what the acceleration of the rope will be", "Venus", "those who proceed to secondary school or vocational training", "zoning and building code requirements", "the Ikh Zasag", "Central Bridge", "the Holy Roman Empire, the Duchy of Prussia, the Channel Islands, and Ireland", "King James Bible", "1935", "seven", "Grumman", "1191", "Maciot de Bethencourt", "Euclid", "case law by the Court of Justice", "long, slender tentacles", "mesoglea", "1970s", "white", "misguided", "2014", "Reconstruction and the Gilded Age", "European Parliament and the Council of the European Union", "members in good standing with the college", "Manakin Episcopal Church", "Nicholas Stone", "due to ongoing tectonic subsidence", "the release of her eponymous debut album the following year", "a form of business network", "the Capitol held its first session of the United States Congress with both chambers in session on November 17, 1800", "It is the currency used by the institutions of the European Union", "Djokovic went on to win his fifth Australian Open title", "the \"colorful\" mercenary group fought for Padua, Florence & other Italian city-states"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7848011363636364}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 0.2857142857142857, 0.0, 0.18181818181818182, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8661", "mrqa_squad-validation-7332", "mrqa_squad-validation-27", "mrqa_squad-validation-8459", "mrqa_squad-validation-10339", "mrqa_squad-validation-10321", "mrqa_squad-validation-3021", "mrqa_squad-validation-2328", "mrqa_squad-validation-3946", "mrqa_squad-validation-1906", "mrqa_squad-validation-5588", "mrqa_squad-validation-9166", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-7062", "mrqa_searchqa-validation-2579"], "SR": 0.734375, "CSR": 0.78125, "retrieved_ids": ["mrqa_squad-train-45685", "mrqa_squad-train-2304", "mrqa_squad-train-32026", "mrqa_squad-train-46774", "mrqa_squad-train-21677", "mrqa_squad-train-31111", "mrqa_squad-train-68166", "mrqa_squad-train-12205", "mrqa_squad-train-28250", "mrqa_squad-train-79108", "mrqa_squad-train-66641", "mrqa_squad-train-63566", "mrqa_squad-train-36675", "mrqa_squad-train-47626", "mrqa_squad-train-7043", "mrqa_squad-train-22369", "mrqa_squad-train-18953", "mrqa_squad-train-57001", "mrqa_squad-train-45771", "mrqa_squad-train-42041", "mrqa_squad-train-57175", "mrqa_squad-train-57437", "mrqa_squad-train-66579", "mrqa_squad-train-58085", "mrqa_squad-train-42004", "mrqa_squad-train-24077", "mrqa_squad-train-82363", "mrqa_squad-train-9268", "mrqa_squad-train-19408", "mrqa_squad-train-25757", "mrqa_squad-train-72525", "mrqa_squad-train-58737", "mrqa_squad-validation-9764", "mrqa_squad-validation-10143", "mrqa_squad-validation-739", "mrqa_squad-validation-8841", "mrqa_squad-validation-7364", "mrqa_squad-validation-9173", "mrqa_squad-validation-7449", "mrqa_squad-validation-4452", "mrqa_squad-validation-3019", "mrqa_squad-validation-7051", "mrqa_squad-validation-2145"], "EFR": 0.9411764705882353, "Overall": 0.8612132352941176}, {"timecode": 2, "before_eval_results": {"predictions": ["Lek", "prohibited emigration", "Private Education Student Financial Assistance", "highly-paid", "Labor", "time and storage", "special efforts", "rhetoric", "British", "a year", "Genghis Khan's", "a supervisory church body", "77", "a cubic interpolation formula", "King Sigismund III Vasa", "1835", "the exploitation of the valuable assets and supplies of the nation that was conquered", "poor management, internal divisions, and effective Canadian scouts", "five", "liquid oxygen", "Gosforth Park", "Metropolitan Police Authority", "18 February 1546", "2005", "1.7 billion years ago", "Mike Carey", "coal", "18 February", "Stanford University", "1976", "LOVE Radio", "ambiguity", "Tem\u00fcjin and his brother Khasar", "Sky Digital", "99.4", "about a third", "the issue of laity having a voice and vote in the administration of the church", "1995", "Endosymbiotic gene transfer", "rocketry and manned spaceflight", "linebacker", "feed water", "Sir Edward Poynter", "oxygen", "August 1967", "Velamen parallelum", "terrorist organisation", "three", "Lowry Digital", "T(n)", "2010", "33", "Buffalo Lookout", "Missouri", "The User State Migration Tool", "1773", "Onsan illness", "October 6, 2017", "11 p.m. to 3 a.m", "Haliaeetus", "Cetshwayo", "James Zeebo", "through the weekend", "Tom Hanks"], "metric_results": {"EM": 0.875, "QA-F1": 0.8924278846153846}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7357", "mrqa_squad-validation-1672", "mrqa_squad-validation-7612", "mrqa_squad-validation-3812", "mrqa_squad-validation-1708", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-9453"], "SR": 0.875, "CSR": 0.8125, "retrieved_ids": ["mrqa_squad-train-80207", "mrqa_squad-train-19588", "mrqa_squad-train-35284", "mrqa_squad-train-47106", "mrqa_squad-train-22181", "mrqa_squad-train-4247", "mrqa_squad-train-26794", "mrqa_squad-train-5958", "mrqa_squad-train-65509", "mrqa_squad-train-70609", "mrqa_squad-train-19487", "mrqa_squad-train-75378", "mrqa_squad-train-66000", "mrqa_squad-train-84587", "mrqa_squad-train-76960", "mrqa_squad-train-6751", "mrqa_squad-train-39456", "mrqa_squad-train-2959", "mrqa_squad-train-67284", "mrqa_squad-train-42346", "mrqa_squad-train-70678", "mrqa_squad-train-12213", "mrqa_squad-train-6635", "mrqa_squad-train-71369", "mrqa_squad-train-34153", "mrqa_squad-train-7181", "mrqa_squad-train-33928", "mrqa_squad-train-25047", "mrqa_squad-train-39710", "mrqa_squad-train-55566", "mrqa_squad-train-20708", "mrqa_squad-train-33636", "mrqa_squad-validation-1906", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-8841", "mrqa_squad-validation-27", "mrqa_squad-validation-9764", "mrqa_squad-validation-7449", "mrqa_squad-validation-3021", "mrqa_squad-validation-7051", "mrqa_squad-validation-4452", "mrqa_squad-validation-10321", "mrqa_squad-validation-7364", "mrqa_squad-validation-2328", "mrqa_squad-validation-10339", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-5588", "mrqa_squad-validation-3946", "mrqa_squad-validation-7332", "mrqa_squad-validation-10143", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-9166", "mrqa_squad-validation-2145", "mrqa_squad-validation-739", "mrqa_squad-validation-3019", "mrqa_naturalquestions-validation-7062", "mrqa_squad-validation-8661", "mrqa_squad-validation-9173", "mrqa_squad-validation-8459"], "EFR": 1.0, "Overall": 0.90625}, {"timecode": 3, "before_eval_results": {"predictions": ["female", "1884", "Sayyid Abul Ala Maududi", "a family member", "James E. Webb", "Lutheran and Reformed", "phycoerytherin", "their business is perpetually understaffed", "swimming-plates", "10 July 1856", "130 million cubic foot", "teleforce", "Heinrich Himmler", "34\u201319", "Baptism", "Decision problems", "customs of his tribe", "1953", "The Day of the Doctor", "Muhammad Khan", "Sun Life Stadium", "the Council", "February 9, 1953", "March", "sea gooseberry", "1961", "Trio Tribe", "Dai Setsen", "Late Medieval Catholic Church", "January 1979", "phagocytic", "Rankine cycle", "$2.2 billion", "Seine", "Newton's Law of Gravitation", "15 February 1546", "Marquis de la Jonqui\u00e8re", "BBC Dead Ringers", "Kenyans for Kenya", "Fresno", "Saudi", "Presiding Officer", "an intuitive understanding", "default emission factors", "Inherited wealth", "Michael P. Millardi", "Goldman Sachs", "Microfluidics", "aproveitando espaos, cama suspensa, armario", "South Dakota", "praying to an", "the children were nestled all snug in their beds", "the Great Temple at Abu Simbel", "the Leyden jar", "a list of the subjects that candidates", "Libretto By Gaetano Rossi", "the borders of Germany, and a part of French Flanders", "70%", "Macy's employees dressed as clowns, cowboys and sword-wielding knights", "the risk of a fire or a flood in my house", "the British", "early 1960s", "April 1917", "poor hygiene"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6961681547619047}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.0, 0.4, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-7525", "mrqa_squad-validation-2595", "mrqa_squad-validation-6072", "mrqa_squad-validation-5860", "mrqa_squad-validation-5262", "mrqa_squad-validation-10369", "mrqa_squad-validation-3863", "mrqa_squad-validation-7457", "mrqa_searchqa-validation-123", "mrqa_searchqa-validation-8711", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-3451", "mrqa_searchqa-validation-14194", "mrqa_searchqa-validation-9536", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-4367", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-1156", "mrqa_searchqa-validation-11367", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-10156"], "SR": 0.640625, "CSR": 0.76953125, "retrieved_ids": ["mrqa_squad-train-86229", "mrqa_squad-train-5259", "mrqa_squad-train-9359", "mrqa_squad-train-73916", "mrqa_squad-train-61240", "mrqa_squad-train-71629", "mrqa_squad-train-10470", "mrqa_squad-train-56764", "mrqa_squad-train-12814", "mrqa_squad-train-44977", "mrqa_squad-train-81426", "mrqa_squad-train-53881", "mrqa_squad-train-45027", "mrqa_squad-train-28360", "mrqa_squad-train-65760", "mrqa_squad-train-81125", "mrqa_squad-train-72754", "mrqa_squad-train-75159", "mrqa_squad-train-72785", "mrqa_squad-train-43342", "mrqa_squad-train-50740", "mrqa_squad-train-75929", "mrqa_squad-train-56402", "mrqa_squad-train-81081", "mrqa_squad-train-34868", "mrqa_squad-train-70457", "mrqa_squad-train-64775", "mrqa_squad-train-25210", "mrqa_squad-train-15789", "mrqa_squad-train-78481", "mrqa_squad-train-57824", "mrqa_squad-train-34948", "mrqa_squad-validation-9173", "mrqa_squad-validation-7449", "mrqa_squad-validation-3812", "mrqa_squad-validation-8841", "mrqa_squad-validation-1906", "mrqa_naturalquestions-validation-7062", "mrqa_squad-validation-10143", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-191", "mrqa_squad-validation-10339", "mrqa_naturalquestions-validation-5780", "mrqa_squad-validation-5588", "mrqa_squad-validation-8459", "mrqa_squad-validation-3946", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-8661", "mrqa_squad-validation-27", "mrqa_squad-validation-7357", "mrqa_squad-validation-739", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-10321", "mrqa_squad-validation-3019", "mrqa_squad-validation-3021", "mrqa_squad-validation-7612", "mrqa_naturalquestions-validation-9453", "mrqa_squad-validation-7364", "mrqa_squad-validation-7051", "mrqa_squad-validation-1672", "mrqa_squad-validation-9764", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-7332", "mrqa_squad-validation-2145"], "EFR": 1.0, "Overall": 0.884765625}, {"timecode": 4, "before_eval_results": {"predictions": ["boom-and-bust cycles", "The Prince of P\u0142ock", "hormones", "1840", "occupational stress", "in the parts of the internal canal network under the comb rows", "separate spheres of knowledge that each applies to", "Tesla Electric Company", "African-American", "Thomson cruise lines", "1905", "\"Nun komm, der Heiland\"", "John Fox", "in all health care settings", "cut in half", "the study of rocks", "colonies", "lower wages", "geophysical surveys", "Fontainebleau", "social power and wealth", "2,900 kilometres (1,802 mi)", "Elie Metchnikoff", "an algorithm", "Immediately after Decision Time", "Confucian propriety and ancestor veneration", "between 25-minute episodes", "eight", "elude host immune responses", "Pusey Library", "inequality", "designs into reality", "cytokines", "requiring his arrest", "wide sidewalks", "other members", "Air Force", "an occupancy permit", "reactive allotrope of oxygen", "Nederrijn", "multi-cultural", "pump water out of the mesoglea", "Tim Johnson", "Australia", "elected or appointed by means of a commission ( letters patent )", "Computer simulation", "Henry Purcell", "Ram Nath Kovind", "embryo", "Todd Griffin", "Sandy Knox and Billy Stritch", "Hudson Bay", "Etienne de Mestre", "a bow bridge with 16 arches shielded by ice guards", "from 1922 to 1991", "Nicole Gale Anderson", "1", "sedimentary rock", "Mrs. Wolowitz", "plate tectonics", "Columbia", "Isabella II of Jerusalem", "Kris Allen", "the Colombian telenovela"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7235637626262627}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2463", "mrqa_squad-validation-2456", "mrqa_squad-validation-6319", "mrqa_squad-validation-7338", "mrqa_squad-validation-2943", "mrqa_squad-validation-8093", "mrqa_squad-validation-7708", "mrqa_squad-validation-3497", "mrqa_squad-validation-9176", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-4002", "mrqa_triviaqa-validation-5855", "mrqa_hotpotqa-validation-4815", "mrqa_searchqa-validation-172"], "SR": 0.65625, "CSR": 0.746875, "retrieved_ids": ["mrqa_squad-train-50621", "mrqa_squad-train-25765", "mrqa_squad-train-73793", "mrqa_squad-train-44598", "mrqa_squad-train-47795", "mrqa_squad-train-7809", "mrqa_squad-train-84495", "mrqa_squad-train-20184", "mrqa_squad-train-15198", "mrqa_squad-train-42195", "mrqa_squad-train-44480", "mrqa_squad-train-71444", "mrqa_squad-train-9296", "mrqa_squad-train-62682", "mrqa_squad-train-37126", "mrqa_squad-train-54010", "mrqa_squad-train-72673", "mrqa_squad-train-63226", "mrqa_squad-train-52689", "mrqa_squad-train-58714", "mrqa_squad-train-66479", "mrqa_squad-train-17504", "mrqa_squad-train-80630", "mrqa_squad-train-54977", "mrqa_squad-train-75948", "mrqa_squad-train-40340", "mrqa_squad-train-78645", "mrqa_squad-train-78336", "mrqa_squad-train-8766", "mrqa_squad-train-11584", "mrqa_squad-train-15606", "mrqa_squad-train-50052", "mrqa_squad-validation-10143", "mrqa_naturalquestions-validation-5780", "mrqa_searchqa-validation-3451", "mrqa_searchqa-validation-8711", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-1708", "mrqa_searchqa-validation-13232", "mrqa_squad-validation-5860", "mrqa_searchqa-validation-11367", "mrqa_naturalquestions-validation-10156", "mrqa_squad-validation-7457", "mrqa_naturalquestions-validation-844", "mrqa_squad-validation-9173", "mrqa_squad-validation-8841", "mrqa_squad-validation-8595", "mrqa_squad-validation-3812", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-2145", "mrqa_squad-validation-739", "mrqa_squad-validation-8661", "mrqa_squad-validation-1906", "mrqa_naturalquestions-validation-7062", "mrqa_searchqa-validation-1156", "mrqa_searchqa-validation-123", "mrqa_squad-validation-7051", "mrqa_searchqa-validation-2568", "mrqa_squad-validation-8459", "mrqa_squad-validation-10339", "mrqa_squad-validation-7525", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-9166", "mrqa_squad-validation-5588"], "EFR": 1.0, "Overall": 0.8734375}, {"timecode": 5, "before_eval_results": {"predictions": ["former flooded terraces", "beginning of the 20th century", "1974", "ABC", "dictatorial", "Ben Johnston", "quantum mechanics", "Exodus", "Synthetic aperture radar", "Battlestar Galactica and Bionic Woman", "patients' prescriptions and patient safety issues", "No, that's no good", "1697", "3 January 1521", "magma", "a \"principal hostile country\"", "Jan Hus", "Newton", "Croatia", "2011", "Swynnerton Plan", "machine gun", "Theatre Museum", "August 10, 1948", "they are distinct or equal classes", "the 2004 Treaty establishing a Constitution for Europe", "Serge Chermayeff", "Thomas Edison", "Mnemiopsis", "the flail of God", "Woodward Park", "The Melbourne Cricket Ground", "Wednesdays", "most common", "concentration gradient", "tears and urine", "six years", "plants and algae", "Constitution of India", "1913", "Yuzuru Hanyu", "Konakuppakatil Gopinathan Balakrishnan", "1942", "March 2016", "Texas, Oklahoma, and the surrounding Great Plains", "a balance sheet", "Mayor Hudnut", "1995", "William the Conqueror", "1922", "an anembryonic gestation", "Bemis Heights", "9pm ET ( UTC - 5 )", "twice", "Joe Pizzulo and Leeza Miller", "Lituya Bay", "Sarah", "routing protocols", "The euro", "beyond violet", "March 14, 2000", "Rodong Sinmun", "R&B", "Rodgers & Hammerstein"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6866195851250199}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.5, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.3076923076923077, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5818", "mrqa_squad-validation-1827", "mrqa_squad-validation-1566", "mrqa_squad-validation-10388", "mrqa_squad-validation-7613", "mrqa_squad-validation-3770", "mrqa_squad-validation-1780", "mrqa_squad-validation-3985", "mrqa_squad-validation-4572", "mrqa_squad-validation-8904", "mrqa_squad-validation-6439", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-9597", "mrqa_triviaqa-validation-2749", "mrqa_hotpotqa-validation-21", "mrqa_searchqa-validation-14371"], "SR": 0.578125, "CSR": 0.71875, "retrieved_ids": ["mrqa_squad-train-53627", "mrqa_squad-train-499", "mrqa_squad-train-71554", "mrqa_squad-train-64812", "mrqa_squad-train-12765", "mrqa_squad-train-34001", "mrqa_squad-train-50906", "mrqa_squad-train-43874", "mrqa_squad-train-46407", "mrqa_squad-train-52174", "mrqa_squad-train-67166", "mrqa_squad-train-16767", "mrqa_squad-train-61846", "mrqa_squad-train-83342", "mrqa_squad-train-748", "mrqa_squad-train-53858", "mrqa_squad-train-45435", "mrqa_squad-train-42507", "mrqa_squad-train-14514", "mrqa_squad-train-52897", "mrqa_squad-train-61271", "mrqa_squad-train-62661", "mrqa_squad-train-60347", "mrqa_squad-train-78638", "mrqa_squad-train-83707", "mrqa_squad-train-63727", "mrqa_squad-train-60780", "mrqa_squad-train-1566", "mrqa_squad-train-26665", "mrqa_squad-train-10779", "mrqa_squad-train-47870", "mrqa_squad-train-49595", "mrqa_naturalquestions-validation-191", "mrqa_squad-validation-3019", "mrqa_squad-validation-7525", "mrqa_searchqa-validation-172", "mrqa_searchqa-validation-2579", "mrqa_naturalquestions-validation-9712", "mrqa_squad-validation-2943", "mrqa_squad-validation-8595", "mrqa_squad-validation-27", "mrqa_squad-validation-7612", "mrqa_squad-validation-9764", "mrqa_squad-validation-8841", "mrqa_squad-validation-2456", "mrqa_searchqa-validation-2568", "mrqa_triviaqa-validation-5855", "mrqa_searchqa-validation-11367", "mrqa_squad-validation-7332", "mrqa_squad-validation-7364", "mrqa_squad-validation-5262", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-15194", "mrqa_squad-validation-7357", "mrqa_squad-validation-7708", "mrqa_squad-validation-10369", "mrqa_squad-validation-6319", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-4002", "mrqa_squad-validation-10143", "mrqa_naturalquestions-validation-10156", "mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-1187"], "EFR": 0.9629629629629629, "Overall": 0.8408564814814814}, {"timecode": 6, "before_eval_results": {"predictions": ["four", "2 million", "Gender pay gap in favor of males in the labor market", "Pliocene", "relationship between teachers and children", "LeGrande", "After the sixth sermon", "Jason Bourne", "11.1%", "nearly 60,000", "University of Chicago College Bowl Team", "organized labor", "Santa Clara Marriott", "oxygen chambers", "two", "two catechisms", "Cologne", "1991", "Silk Road", "Surveyor 3 unmanned lunar probe", "145", "growth and investment", "the centers were computer service bureaus, offering batch processing services", "Vampire bats", "antiforms", "U. S. flags left on the Moon during the Apollo missions were found to still be standing", "weight", "Genghis Khan's Mongolia", "oil was priced in dollars", "Beyonc\u00e9 and Bruno Mars", "a university or college", "More than 1 million", "pseudorandom number generators", "Japan", "Coriolis force", "Mickey Rourke", "May 2016", "Nicklaus", "Superstition Mountains", "Panama Canal Authority", "silk, hair / fur ( including wool ) and feathers", "Convention", "two", "Sebastian Vettel", "April 10, 2018", "Gorakhpur", "How I Met Your Mother", "elected", "December 15, 2016", "Abraham Gottlob Werner", "Jourdan Miller", "1991", "Samantha Jo", "Denmark", "Broken Hill and Sydney", "159", "United Nations Security Council ( also known as the Permanent Five, Big Five, or P5 )", "Judiththia Aline Keppel", "medellin", "Crown Holdings Incorporated", "Expedia", "Hubble Space Telescope", "Zed", "us to step up"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7012505723443223}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.6666666666666666, 0.09523809523809523, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.25, 0.25, 0.25, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.07142857142857144, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7445", "mrqa_squad-validation-6965", "mrqa_squad-validation-5435", "mrqa_squad-validation-7422", "mrqa_squad-validation-4000", "mrqa_squad-validation-4838", "mrqa_squad-validation-3998", "mrqa_squad-validation-6228", "mrqa_squad-validation-3718", "mrqa_squad-validation-9161", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-6106"], "SR": 0.609375, "CSR": 0.703125, "retrieved_ids": ["mrqa_squad-train-14158", "mrqa_squad-train-54371", "mrqa_squad-train-17568", "mrqa_squad-train-81381", "mrqa_squad-train-41084", "mrqa_squad-train-34772", "mrqa_squad-train-77317", "mrqa_squad-train-3152", "mrqa_squad-train-33785", "mrqa_squad-train-23804", "mrqa_squad-train-25923", "mrqa_squad-train-38846", "mrqa_squad-train-39052", "mrqa_squad-train-58037", "mrqa_squad-train-62185", "mrqa_squad-train-13940", "mrqa_squad-train-47669", "mrqa_squad-train-67608", "mrqa_squad-train-29185", "mrqa_squad-train-62974", "mrqa_squad-train-63272", "mrqa_squad-train-76536", "mrqa_squad-train-19045", "mrqa_squad-train-26395", "mrqa_squad-train-27578", "mrqa_squad-train-54782", "mrqa_squad-train-13686", "mrqa_squad-train-71246", "mrqa_squad-train-56160", "mrqa_squad-train-43256", "mrqa_squad-train-48759", "mrqa_squad-train-84041", "mrqa_squad-validation-8904", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-9240", "mrqa_squad-validation-9166", "mrqa_squad-validation-6439", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-7332", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-3672", "mrqa_searchqa-validation-172", "mrqa_squad-validation-2595", "mrqa_squad-validation-3812", "mrqa_squad-validation-7525", "mrqa_naturalquestions-validation-469", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-3497", "mrqa_naturalquestions-validation-1187", "mrqa_triviaqa-validation-5855", "mrqa_squad-validation-7612", "mrqa_squad-validation-4452", "mrqa_squad-validation-7708", "mrqa_triviaqa-validation-2749", "mrqa_squad-validation-10321", "mrqa_naturalquestions-validation-3558", "mrqa_squad-validation-2463", "mrqa_squad-validation-8841", "mrqa_squad-validation-5262", "mrqa_squad-validation-6072", "mrqa_squad-validation-9176"], "EFR": 0.96, "Overall": 0.8315625}, {"timecode": 7, "before_eval_results": {"predictions": ["Director", "travel literature, cartography, geography, and scientific education", "oxygen chambers", "Graham Gano", "Two", "1066", "2008", "Mojave Desert", "Operating System Principles", "St. Lawrence and Mississippi watersheds", "27%", "4000", "Rhine Gorge", "helical thylakoid model", "highest", "impact process effects", "individual countries", "Warner Bros. Presents", "pharmacists", "high-frequency", "4:51", "Kabaty Forest", "the seal of the Federal Communications Commission", "strong sedimentation", "The European Commission", "SAP Center", "respiration", "352", "eliminate the accusing law", "October 6, 2004", "The Day of the Doctor", "Pakistan", "November 1999", "September 6, 2019", "Greek", "the fourth season", "three", "Nick Kroll", "the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "Billy Gibbons", "an apprentice of the fictional Wars Order in the Star Wars franchise", "in the brain", "31", "in the 1970s", "the Vital Records Office of the states, capital district, territories and former territories", "Art Carney", "accomplish the objectives of the organization", "in the female's body in the absence of mating", "December 1922", "Category 4", "September 2017", "3 September", "southern USA", "Terrell Owens", "since 3, 1, and 4", "five", "Kevin Corrigan", "Hampton Court Palace", "Sela Ward", "her decades-long portrayal of Alice Horton", "the Universal Licensing System", "Benjamin Britten", "an isosceles triangle", "NOW Magazine"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6644416781135531}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.625, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4629", "mrqa_squad-validation-8819", "mrqa_squad-validation-1938", "mrqa_squad-validation-6409", "mrqa_squad-validation-1195", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-2016", "mrqa_naturalquestions-validation-801", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2112", "mrqa_searchqa-validation-16130", "mrqa_triviaqa-validation-6548"], "SR": 0.609375, "CSR": 0.69140625, "retrieved_ids": ["mrqa_squad-train-78456", "mrqa_squad-train-74699", "mrqa_squad-train-36835", "mrqa_squad-train-60006", "mrqa_squad-train-58284", "mrqa_squad-train-523", "mrqa_squad-train-25889", "mrqa_squad-train-10823", "mrqa_squad-train-65590", "mrqa_squad-train-81673", "mrqa_squad-train-173", "mrqa_squad-train-22172", "mrqa_squad-train-23765", "mrqa_squad-train-64816", "mrqa_squad-train-68645", "mrqa_squad-train-8230", "mrqa_squad-train-32965", "mrqa_squad-train-35961", "mrqa_squad-train-52685", "mrqa_squad-train-52631", "mrqa_squad-train-340", "mrqa_squad-train-53459", "mrqa_squad-train-74112", "mrqa_squad-train-69655", "mrqa_squad-train-37285", "mrqa_squad-train-45416", "mrqa_squad-train-73634", "mrqa_squad-train-35353", "mrqa_squad-train-76364", "mrqa_squad-train-2688", "mrqa_squad-train-64162", "mrqa_squad-train-40147", "mrqa_squad-validation-27", "mrqa_hotpotqa-validation-21", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-9597", "mrqa_naturalquestions-validation-10039", "mrqa_squad-validation-2463", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-6461", "mrqa_squad-validation-8661", "mrqa_squad-validation-1566", "mrqa_squad-validation-2328", "mrqa_searchqa-validation-172", "mrqa_squad-validation-7364", "mrqa_squad-validation-3863", "mrqa_naturalquestions-validation-3686", "mrqa_squad-validation-8093", "mrqa_squad-validation-10339", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-844", "mrqa_squad-validation-739", "mrqa_searchqa-validation-14371", "mrqa_squad-validation-7422", "mrqa_squad-validation-10143", "mrqa_naturalquestions-validation-191", "mrqa_searchqa-validation-123", "mrqa_squad-validation-6072", "mrqa_searchqa-validation-9536", "mrqa_squad-validation-1708", "mrqa_squad-validation-4838", "mrqa_squad-validation-9173"], "EFR": 1.0, "Overall": 0.845703125}, {"timecode": 8, "before_eval_results": {"predictions": ["cytokines", "William Pitt", "North Carolina and New Mexico", "p-adic norm", "Maududi", "Gottfried Fritschel", "1973\u201380", "ular plastoglobulus", "pound-force", "Ming dynasty", "Dorothy and Michael Hintze", "The Small Catechism", "36", "Giuliano da Sangallo", "April 20", "biomass", "their belief in the validity of the social contract", "K MJ-TV", "Foreign Protestants Naturalization Act", "southern and central parts", "1.1 \u00d7 1011 metric tonnes", "Not designed to fly through the Earth's atmosphere or return to Earth", "Metro Trains Melbourne", "BBC 1", "$2 million", "Vince Lombardi Trophy", "Galileo", "in linked groups or chains", "meaning", "Tiber", "1885", "James Madison", "Ryan Pinkston", "federal republic", "lacteal", "2007", "foreign investors", "N\u0289m\u0289n\u0289\u0289", "8ft", "Bartolomeu Dias", "William Wyler", "1961", "March 1930", "Julie Adams", "Thomas Jefferson", "February 2017 in Japan and in March 2018 in North America and Europe", "October 29, 2015", "customary", "Millerlite", "Sunday night", "Billy Hill", "Mara Jade", "Malina Weissman", "September 6, 2019", "1773", "lacteal", "April 26, 2005", "Graham Nash", "Albert", "he remains in a coma in a grave condition", "Croatia", "Drew Kesse", "18", "they were part of a group of 20 similar cars making an annual road trip"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6345052083333333}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.375]}}, "before_error_ids": ["mrqa_squad-validation-8958", "mrqa_squad-validation-9615", "mrqa_squad-validation-7876", "mrqa_squad-validation-8786", "mrqa_squad-validation-6706", "mrqa_squad-validation-4715", "mrqa_squad-validation-2975", "mrqa_squad-validation-4181", "mrqa_squad-validation-8769", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5739", "mrqa_triviaqa-validation-4881", "mrqa_hotpotqa-validation-2800", "mrqa_newsqa-validation-3043", "mrqa_searchqa-validation-2141", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-3476"], "SR": 0.578125, "CSR": 0.6788194444444444, "retrieved_ids": ["mrqa_squad-train-43927", "mrqa_squad-train-85677", "mrqa_squad-train-71941", "mrqa_squad-train-7248", "mrqa_squad-train-81504", "mrqa_squad-train-77391", "mrqa_squad-train-15404", "mrqa_squad-train-44397", "mrqa_squad-train-68872", "mrqa_squad-train-42376", "mrqa_squad-train-58483", "mrqa_squad-train-79462", "mrqa_squad-train-75036", "mrqa_squad-train-30254", "mrqa_squad-train-35651", "mrqa_squad-train-41667", "mrqa_squad-train-26744", "mrqa_squad-train-17594", "mrqa_squad-train-72043", "mrqa_squad-train-78544", "mrqa_squad-train-17003", "mrqa_squad-train-5502", "mrqa_squad-train-44540", "mrqa_squad-train-17984", "mrqa_squad-train-43137", "mrqa_squad-train-62400", "mrqa_squad-train-63982", "mrqa_squad-train-18522", "mrqa_squad-train-691", "mrqa_squad-train-74094", "mrqa_squad-train-66193", "mrqa_squad-train-36279", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-4348", "mrqa_searchqa-validation-11367", "mrqa_naturalquestions-validation-473", "mrqa_searchqa-validation-13232", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-3442", "mrqa_squad-validation-1708", "mrqa_squad-validation-10369", "mrqa_naturalquestions-validation-10156", "mrqa_searchqa-validation-16130", "mrqa_naturalquestions-validation-2016", "mrqa_squad-validation-3021", "mrqa_squad-validation-1195", "mrqa_squad-validation-3770", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-7357", "mrqa_squad-validation-6409", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-7242", "mrqa_squad-validation-3812", "mrqa_squad-validation-8471", "mrqa_squad-validation-7332", "mrqa_hotpotqa-validation-62", "mrqa_squad-validation-27", "mrqa_naturalquestions-validation-7062", "mrqa_squad-validation-9764", "mrqa_naturalquestions-validation-10039", "mrqa_searchqa-validation-2579"], "EFR": 0.9629629629629629, "Overall": 0.8208912037037037}, {"timecode": 9, "before_eval_results": {"predictions": ["in an attempt to emphasize academics over athletics", "3,600", "nine", "individual states and territories", "30%\u201350% O2", "one of his wife's ladies-in-waiting", "liquid phase", "their greatest common divisor is one", "Europe", "the cell membrane", "Professor Moriarty to the Doctor's Sherlock Holmes", "Laverne & Shirley", "carbohydrates", "his butchery", "Jean Ribault", "March 2011", "Continental Edison Company", "2010", "more equality in the income distribution", "X reduces to Y", "38", "1887", "1469", "\"world classic of epoch-making oratory.\"", "up to half", "lowest", "WD-40 L lubricant", "a barbie doll type", "Georgie Porgie", "ethanol", "William Shaksper", "The Fray", "Venus", "Helen Hayes MacArthur", "Canberra", "jenn anacondas", "Alexander Graham Bell", "Anna Pavlova", "jOB Insurance", "Al Campanis", "Beanies, Beanie and Cartoon", "Billy Goat Tavern", "crayola", "a goat", "child molestation", "Resentment over someone's good fortune without wanting it", "a skydiving accident", "How romantic", "a dual role", "the chimney flue", "Andrew Jackson", "jenn Sean Penn", "fauves", "a sailfish", "black", "Laurie", "Egypt", "James Hutton", "Armenia", "Shepherd Neame", "Total Nonstop Action Wrestling", "jirsch index rating of all living chemists", "China and Japan", "NATO"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5956730769230769}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false], "QA-F1": [0.923076923076923, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7943", "mrqa_squad-validation-3687", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-1507", "mrqa_searchqa-validation-4169", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-10856", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-1053", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-11532", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-13600", "mrqa_searchqa-validation-3613", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-15202", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-686", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-15770", "mrqa_naturalquestions-validation-1378", "mrqa_triviaqa-validation-7463", "mrqa_hotpotqa-validation-929", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-2179"], "SR": 0.515625, "CSR": 0.6625, "retrieved_ids": ["mrqa_squad-train-14023", "mrqa_squad-train-25826", "mrqa_squad-train-32472", "mrqa_squad-train-50999", "mrqa_squad-train-19213", "mrqa_squad-train-58189", "mrqa_squad-train-24506", "mrqa_squad-train-83889", "mrqa_squad-train-81304", "mrqa_squad-train-52791", "mrqa_squad-train-47461", "mrqa_squad-train-8685", "mrqa_squad-train-65016", "mrqa_squad-train-7891", "mrqa_squad-train-7663", "mrqa_squad-train-60807", "mrqa_squad-train-49504", "mrqa_squad-train-55175", "mrqa_squad-train-82860", "mrqa_squad-train-256", "mrqa_squad-train-78753", "mrqa_squad-train-29234", "mrqa_squad-train-16472", "mrqa_squad-train-40033", "mrqa_squad-train-85489", "mrqa_squad-train-78987", "mrqa_squad-train-15524", "mrqa_squad-train-73885", "mrqa_squad-train-60501", "mrqa_squad-train-25834", "mrqa_squad-train-26230", "mrqa_squad-train-22939", "mrqa_squad-validation-1708", "mrqa_newsqa-validation-2112", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-8958", "mrqa_searchqa-validation-172", "mrqa_squad-validation-7612", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-8277", "mrqa_squad-validation-3985", "mrqa_naturalquestions-validation-8356", "mrqa_searchqa-validation-9536", "mrqa_squad-validation-3998", "mrqa_squad-validation-9173", "mrqa_squad-validation-3021", "mrqa_squad-validation-2463", "mrqa_squad-validation-10369", "mrqa_squad-validation-5818", "mrqa_squad-validation-3497", "mrqa_squad-validation-4715", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-7357", "mrqa_naturalquestions-validation-6461", "mrqa_newsqa-validation-3043", "mrqa_squad-validation-5262", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5739", "mrqa_squad-validation-6439", "mrqa_squad-validation-9615", "mrqa_squad-validation-27"], "EFR": 0.967741935483871, "Overall": 0.8151209677419355}, {"timecode": 10, "UKR": 0.806640625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10156", "mrqa_naturalquestions-validation-10298", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10670", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-1309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-1385", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2368", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-3898", "mrqa_naturalquestions-validation-3935", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4505", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4823", "mrqa_naturalquestions-validation-4880", "mrqa_naturalquestions-validation-4906", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-5087", "mrqa_naturalquestions-validation-5160", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5477", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5709", "mrqa_naturalquestions-validation-5709", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-6088", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-6276", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-6347", "mrqa_naturalquestions-validation-6358", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-8103", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-837", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-8454", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-8792", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-955", "mrqa_naturalquestions-validation-9597", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9818", "mrqa_newsqa-validation-1080", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-825", "mrqa_searchqa-validation-1053", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-11367", "mrqa_searchqa-validation-11532", "mrqa_searchqa-validation-1156", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13600", "mrqa_searchqa-validation-14371", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15169", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-15202", "mrqa_searchqa-validation-15770", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16439", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-172", "mrqa_searchqa-validation-2141", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-2579", "mrqa_searchqa-validation-3245", "mrqa_searchqa-validation-3613", "mrqa_searchqa-validation-393", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-4258", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-4367", "mrqa_searchqa-validation-5035", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-9284", "mrqa_searchqa-validation-9536", "mrqa_squad-validation-10000", "mrqa_squad-validation-10115", "mrqa_squad-validation-10136", "mrqa_squad-validation-1017", "mrqa_squad-validation-10181", "mrqa_squad-validation-10184", "mrqa_squad-validation-10217", "mrqa_squad-validation-10263", "mrqa_squad-validation-10281", "mrqa_squad-validation-10290", "mrqa_squad-validation-10321", "mrqa_squad-validation-10339", "mrqa_squad-validation-10361", "mrqa_squad-validation-10369", "mrqa_squad-validation-1038", "mrqa_squad-validation-10410", "mrqa_squad-validation-10454", "mrqa_squad-validation-10496", "mrqa_squad-validation-1095", "mrqa_squad-validation-1125", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-1177", "mrqa_squad-validation-1181", "mrqa_squad-validation-1195", "mrqa_squad-validation-120", "mrqa_squad-validation-1226", "mrqa_squad-validation-1240", "mrqa_squad-validation-1254", "mrqa_squad-validation-1269", "mrqa_squad-validation-1371", "mrqa_squad-validation-1499", "mrqa_squad-validation-1521", "mrqa_squad-validation-1533", "mrqa_squad-validation-1566", "mrqa_squad-validation-1651", "mrqa_squad-validation-166", "mrqa_squad-validation-1672", "mrqa_squad-validation-1708", "mrqa_squad-validation-1748", "mrqa_squad-validation-1780", "mrqa_squad-validation-1787", "mrqa_squad-validation-1848", "mrqa_squad-validation-1863", "mrqa_squad-validation-1892", "mrqa_squad-validation-1924", "mrqa_squad-validation-1938", "mrqa_squad-validation-195", "mrqa_squad-validation-1953", "mrqa_squad-validation-1998", "mrqa_squad-validation-2019", "mrqa_squad-validation-2041", "mrqa_squad-validation-2050", "mrqa_squad-validation-2059", "mrqa_squad-validation-2108", "mrqa_squad-validation-2145", "mrqa_squad-validation-2209", "mrqa_squad-validation-2233", "mrqa_squad-validation-2241", "mrqa_squad-validation-2243", "mrqa_squad-validation-2248", "mrqa_squad-validation-2352", "mrqa_squad-validation-2365", "mrqa_squad-validation-2411", "mrqa_squad-validation-2438", "mrqa_squad-validation-2456", "mrqa_squad-validation-2463", "mrqa_squad-validation-2467", "mrqa_squad-validation-247", "mrqa_squad-validation-2521", "mrqa_squad-validation-2545", "mrqa_squad-validation-2589", "mrqa_squad-validation-2595", "mrqa_squad-validation-2642", "mrqa_squad-validation-27", "mrqa_squad-validation-2751", "mrqa_squad-validation-2820", "mrqa_squad-validation-2885", "mrqa_squad-validation-2886", "mrqa_squad-validation-2897", "mrqa_squad-validation-2943", "mrqa_squad-validation-2959", "mrqa_squad-validation-3019", "mrqa_squad-validation-3039", "mrqa_squad-validation-305", "mrqa_squad-validation-3076", "mrqa_squad-validation-3144", "mrqa_squad-validation-3164", "mrqa_squad-validation-317", "mrqa_squad-validation-3184", "mrqa_squad-validation-322", "mrqa_squad-validation-3230", "mrqa_squad-validation-3270", "mrqa_squad-validation-334", "mrqa_squad-validation-335", "mrqa_squad-validation-3358", "mrqa_squad-validation-3364", "mrqa_squad-validation-3376", "mrqa_squad-validation-3380", "mrqa_squad-validation-3392", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3435", "mrqa_squad-validation-3497", "mrqa_squad-validation-358", "mrqa_squad-validation-3605", "mrqa_squad-validation-3605", "mrqa_squad-validation-3626", "mrqa_squad-validation-3687", "mrqa_squad-validation-3703", "mrqa_squad-validation-3718", "mrqa_squad-validation-374", "mrqa_squad-validation-3769", "mrqa_squad-validation-3770", "mrqa_squad-validation-381", "mrqa_squad-validation-3824", "mrqa_squad-validation-3829", "mrqa_squad-validation-3842", "mrqa_squad-validation-3848", "mrqa_squad-validation-3852", "mrqa_squad-validation-3863", "mrqa_squad-validation-3909", "mrqa_squad-validation-3917", "mrqa_squad-validation-3946", "mrqa_squad-validation-3955", "mrqa_squad-validation-3985", "mrqa_squad-validation-3986", "mrqa_squad-validation-3998", "mrqa_squad-validation-4000", "mrqa_squad-validation-4009", "mrqa_squad-validation-402", "mrqa_squad-validation-4031", "mrqa_squad-validation-4066", "mrqa_squad-validation-4175", "mrqa_squad-validation-4181", "mrqa_squad-validation-4187", "mrqa_squad-validation-4213", "mrqa_squad-validation-4291", "mrqa_squad-validation-4312", "mrqa_squad-validation-4348", "mrqa_squad-validation-4446", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4452", "mrqa_squad-validation-4467", "mrqa_squad-validation-4468", "mrqa_squad-validation-4509", "mrqa_squad-validation-451", "mrqa_squad-validation-4530", "mrqa_squad-validation-4538", "mrqa_squad-validation-4539", "mrqa_squad-validation-4557", "mrqa_squad-validation-4557", "mrqa_squad-validation-4572", "mrqa_squad-validation-4583", "mrqa_squad-validation-4629", "mrqa_squad-validation-4715", "mrqa_squad-validation-4838", "mrqa_squad-validation-491", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5004", "mrqa_squad-validation-5014", "mrqa_squad-validation-5019", "mrqa_squad-validation-5064", "mrqa_squad-validation-5110", "mrqa_squad-validation-5140", "mrqa_squad-validation-516", "mrqa_squad-validation-5262", "mrqa_squad-validation-5396", "mrqa_squad-validation-5436", "mrqa_squad-validation-5448", "mrqa_squad-validation-5453", "mrqa_squad-validation-5479", "mrqa_squad-validation-5493", "mrqa_squad-validation-5527", "mrqa_squad-validation-5546", "mrqa_squad-validation-5572", "mrqa_squad-validation-5588", "mrqa_squad-validation-5602", "mrqa_squad-validation-5631", "mrqa_squad-validation-5664", "mrqa_squad-validation-5677", "mrqa_squad-validation-57", "mrqa_squad-validation-5726", "mrqa_squad-validation-5750", "mrqa_squad-validation-5763", "mrqa_squad-validation-5781", "mrqa_squad-validation-5806", "mrqa_squad-validation-5818", "mrqa_squad-validation-5852", "mrqa_squad-validation-5860", "mrqa_squad-validation-5865", "mrqa_squad-validation-5960", "mrqa_squad-validation-6030", "mrqa_squad-validation-6031", "mrqa_squad-validation-6066", "mrqa_squad-validation-6069", "mrqa_squad-validation-6171", "mrqa_squad-validation-6176", "mrqa_squad-validation-6206", "mrqa_squad-validation-6222", "mrqa_squad-validation-6229", "mrqa_squad-validation-6240", "mrqa_squad-validation-6243", "mrqa_squad-validation-6319", "mrqa_squad-validation-6330", "mrqa_squad-validation-6347", "mrqa_squad-validation-6353", "mrqa_squad-validation-6355", "mrqa_squad-validation-6409", "mrqa_squad-validation-6439", "mrqa_squad-validation-6502", "mrqa_squad-validation-6517", "mrqa_squad-validation-6543", "mrqa_squad-validation-6551", "mrqa_squad-validation-6611", "mrqa_squad-validation-6649", "mrqa_squad-validation-6664", "mrqa_squad-validation-6694", "mrqa_squad-validation-6790", "mrqa_squad-validation-6815", "mrqa_squad-validation-6838", "mrqa_squad-validation-6875", "mrqa_squad-validation-6876", "mrqa_squad-validation-6879", "mrqa_squad-validation-6898", "mrqa_squad-validation-6951", "mrqa_squad-validation-6957", "mrqa_squad-validation-6965", "mrqa_squad-validation-6999", "mrqa_squad-validation-7036", "mrqa_squad-validation-7039", "mrqa_squad-validation-7064", "mrqa_squad-validation-7192", "mrqa_squad-validation-7205", "mrqa_squad-validation-7228", "mrqa_squad-validation-7260", "mrqa_squad-validation-7261", "mrqa_squad-validation-7297", "mrqa_squad-validation-7332", "mrqa_squad-validation-7338", "mrqa_squad-validation-7357", "mrqa_squad-validation-7364", "mrqa_squad-validation-7368", "mrqa_squad-validation-7380", "mrqa_squad-validation-739", "mrqa_squad-validation-7390", "mrqa_squad-validation-7422", "mrqa_squad-validation-7445", "mrqa_squad-validation-7457", "mrqa_squad-validation-7470", "mrqa_squad-validation-7492", "mrqa_squad-validation-7503", "mrqa_squad-validation-7525", "mrqa_squad-validation-7608", "mrqa_squad-validation-7612", "mrqa_squad-validation-7613", "mrqa_squad-validation-7618", "mrqa_squad-validation-762", "mrqa_squad-validation-7693", "mrqa_squad-validation-7700", "mrqa_squad-validation-7708", "mrqa_squad-validation-7717", "mrqa_squad-validation-7775", "mrqa_squad-validation-7781", "mrqa_squad-validation-7785", "mrqa_squad-validation-779", "mrqa_squad-validation-7863", "mrqa_squad-validation-7871", "mrqa_squad-validation-7917", "mrqa_squad-validation-7943", "mrqa_squad-validation-7954", "mrqa_squad-validation-7982", "mrqa_squad-validation-7984", "mrqa_squad-validation-7993", "mrqa_squad-validation-8016", "mrqa_squad-validation-8043", "mrqa_squad-validation-8093", "mrqa_squad-validation-8125", "mrqa_squad-validation-8154", "mrqa_squad-validation-8177", "mrqa_squad-validation-8184", "mrqa_squad-validation-8192", "mrqa_squad-validation-8232", "mrqa_squad-validation-8282", "mrqa_squad-validation-829", "mrqa_squad-validation-8309", "mrqa_squad-validation-8365", "mrqa_squad-validation-8414", "mrqa_squad-validation-8449", "mrqa_squad-validation-8459", "mrqa_squad-validation-8471", "mrqa_squad-validation-8484", "mrqa_squad-validation-8500", "mrqa_squad-validation-852", "mrqa_squad-validation-8568", "mrqa_squad-validation-8585", "mrqa_squad-validation-8661", "mrqa_squad-validation-8670", "mrqa_squad-validation-8670", "mrqa_squad-validation-8754", "mrqa_squad-validation-8769", "mrqa_squad-validation-8809", "mrqa_squad-validation-8841", "mrqa_squad-validation-888", "mrqa_squad-validation-8904", "mrqa_squad-validation-8925", "mrqa_squad-validation-893", "mrqa_squad-validation-8933", "mrqa_squad-validation-8958", "mrqa_squad-validation-8985", "mrqa_squad-validation-908", "mrqa_squad-validation-9095", "mrqa_squad-validation-9161", "mrqa_squad-validation-9166", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9193", "mrqa_squad-validation-9234", "mrqa_squad-validation-9403", "mrqa_squad-validation-9405", "mrqa_squad-validation-9446", "mrqa_squad-validation-9464", "mrqa_squad-validation-9556", "mrqa_squad-validation-957", "mrqa_squad-validation-9594", "mrqa_squad-validation-9615", "mrqa_squad-validation-9669", "mrqa_squad-validation-9716", "mrqa_squad-validation-9717", "mrqa_squad-validation-9764", "mrqa_squad-validation-9814", "mrqa_squad-validation-9816", "mrqa_squad-validation-9876", "mrqa_squad-validation-9907", "mrqa_squad-validation-9928", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4444", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-6421", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-7463"], "OKR": 0.9453125, "KG": 0.44140625, "before_eval_results": {"predictions": ["Northern Europe and the Mid-Atlantic", "$2 million", "fish stocks to collapse", "Chris Keates", "its many castles and vineyards", "Cinerama Productions/Palomar theatrical library", "Antigone", "3.5 million", "Denver Broncos", "1997", "A \u2192 G deamination gradients", "since 2001", "Streptococcus", "1784", "Narrow alleys", "another problem", "economic growth", "John and Benjamin Green", "1530", "installed electrical arc light based illumination systems", "two", "the poor", "Irish Hospitals' Sweepstakes", "Pearl Jam", "Grey's Anatomy", "(Bally and Isler, 1904", "Bruce Springsteen", "Wounded Knee", "Maria Callas", "Henry Moore", "the Red Sox", "Charlotte, North Carolina", "(Prince) of the Merion Golf Club", "Narcissus", "Fred Williamson", "the Orange River", "milliners, sharps and tapestry", "the Holy Grail", "the Smashing Pumpkins", "Fran", "Ludwig Van Beethoven", "Lake Victoria", "often", "Dr Pepper", "(oil filter)", "Sarah Orne Jewett", "Velvet Revolver", "(EGO) MANIAC", "polar-front", "You Bet Your Life", "China", "(adjective) Canadian", "Kenny G", "(19501956)", "Franklin Pierce", "Pearl Harbor", "Michael Schumacher", "a four - page pamphlet", "(William) billiards", "Queen Margaret College", "Sam Neill", "Hugh Dowding", "NATO fighters", "Congress"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6683159722222222}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.888888888888889, 1.0, 0.7499999999999999, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4326", "mrqa_squad-validation-8990", "mrqa_squad-validation-5887", "mrqa_squad-validation-6655", "mrqa_squad-validation-7353", "mrqa_searchqa-validation-12363", "mrqa_searchqa-validation-3530", "mrqa_searchqa-validation-12864", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-8760", "mrqa_searchqa-validation-7086", "mrqa_searchqa-validation-2761", "mrqa_searchqa-validation-7269", "mrqa_searchqa-validation-4393", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-4394", "mrqa_searchqa-validation-9148", "mrqa_searchqa-validation-6909", "mrqa_searchqa-validation-14569", "mrqa_searchqa-validation-7517", "mrqa_searchqa-validation-2866", "mrqa_searchqa-validation-6181", "mrqa_naturalquestions-validation-5702", "mrqa_triviaqa-validation-4307", "mrqa_triviaqa-validation-6896", "mrqa_hotpotqa-validation-1843"], "SR": 0.578125, "CSR": 0.6548295454545454, "retrieved_ids": ["mrqa_squad-train-23544", "mrqa_squad-train-37948", "mrqa_squad-train-75105", "mrqa_squad-train-29474", "mrqa_squad-train-36054", "mrqa_squad-train-17279", "mrqa_squad-train-2947", "mrqa_squad-train-47492", "mrqa_squad-train-34359", "mrqa_squad-train-65283", "mrqa_squad-train-41546", "mrqa_squad-train-39254", "mrqa_squad-train-7483", "mrqa_squad-train-23370", "mrqa_squad-train-5157", "mrqa_squad-train-31235", "mrqa_squad-train-18512", "mrqa_squad-train-11137", "mrqa_squad-train-408", "mrqa_squad-train-78236", "mrqa_squad-train-4988", "mrqa_squad-train-8099", "mrqa_squad-train-32333", "mrqa_squad-train-28147", "mrqa_squad-train-56500", "mrqa_squad-train-48639", "mrqa_squad-train-16798", "mrqa_squad-train-12340", "mrqa_squad-train-36554", "mrqa_squad-train-57886", "mrqa_squad-train-47942", "mrqa_squad-train-24351", "mrqa_naturalquestions-validation-8189", "mrqa_squad-validation-6072", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-8401", "mrqa_hotpotqa-validation-21", "mrqa_searchqa-validation-792", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-7554", "mrqa_searchqa-validation-3451", "mrqa_searchqa-validation-6234", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-7080", "mrqa_searchqa-validation-3960", "mrqa_naturalquestions-validation-9453", "mrqa_squad-validation-6706", "mrqa_naturalquestions-validation-10156", "mrqa_squad-validation-4572", "mrqa_searchqa-validation-123", "mrqa_squad-validation-1566", "mrqa_naturalquestions-validation-5531", "mrqa_squad-validation-1672", "mrqa_squad-validation-7943", "mrqa_naturalquestions-validation-7390", "mrqa_squad-validation-3718", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-7422", "mrqa_searchqa-validation-7514", "mrqa_newsqa-validation-1007", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-8277"], "EFR": 1.0, "Overall": 0.7696377840909091}, {"timecode": 11, "before_eval_results": {"predictions": ["the Horn of Africa", "Grumman", "to civil disobedients", "1700", "St. Johns River", "canceled", "The President of the Council and a Commissioner can sit in on ECB meetings, but don't have voting rights", "Ismailiyah, Egypt", "phycobilisomes", "lupus erythematosus", "December 1878", "bars, caf\u00e9s and clubs", "PNU and ODM camps", "T(n) = O(n2)", "Bill Clinton", "qu", "International Crops Research Institute for the Semi-Arid Tropics", "straight line", "Scandinavia", "autoimmune", "David Leslie", "intelligent design", "Seoul", "2005", "December 24, 1973", "May 21, 2000", "the 100 metres", "January 2016", "seven", "Samuel Beckett", "Eilean Donan", "Sonic Mania", "Homeland", "Carson City", "League of the Three Emperors", "Barack Obama", "Brian A. Miller", "Washington, D.C.", "December 13, 2015", "Front Row", "before 1638", "Vixen", "Revolution Studios", "the Mach number", "1990", "Michael A. Cremo", "Gangsta's Paradise", "The A41", "Mary Astor", "five", "Indiana", "Esteban Ocon", "ABC", "the British military", "National Lottery", "2018", "Tim Rice", "Milton Friedman", "Billy Wilder", "1-0", "forward deck space", "Chad", "a pillar", "Yahya Khan"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7014880952380953}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-9912", "mrqa_squad-validation-6759", "mrqa_squad-validation-4150", "mrqa_hotpotqa-validation-558", "mrqa_hotpotqa-validation-5328", "mrqa_hotpotqa-validation-5154", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-16", "mrqa_hotpotqa-validation-3944", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-1747", "mrqa_hotpotqa-validation-957", "mrqa_hotpotqa-validation-5604", "mrqa_naturalquestions-validation-10161", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1700", "mrqa_searchqa-validation-11991", "mrqa_searchqa-validation-971", "mrqa_naturalquestions-validation-3485"], "SR": 0.65625, "CSR": 0.6549479166666667, "retrieved_ids": ["mrqa_squad-train-33779", "mrqa_squad-train-1479", "mrqa_squad-train-60248", "mrqa_squad-train-32769", "mrqa_squad-train-42364", "mrqa_squad-train-50927", "mrqa_squad-train-11120", "mrqa_squad-train-47393", "mrqa_squad-train-73287", "mrqa_squad-train-48187", "mrqa_squad-train-22884", "mrqa_squad-train-17927", "mrqa_squad-train-68540", "mrqa_squad-train-2463", "mrqa_squad-train-24411", "mrqa_squad-train-63000", "mrqa_squad-train-30811", "mrqa_squad-train-8800", "mrqa_squad-train-31031", "mrqa_squad-train-47148", "mrqa_squad-train-686", "mrqa_squad-train-24921", "mrqa_squad-train-82647", "mrqa_squad-train-50042", "mrqa_squad-train-15757", "mrqa_squad-train-68956", "mrqa_squad-train-27569", "mrqa_squad-train-85900", "mrqa_squad-train-4032", "mrqa_squad-train-20783", "mrqa_squad-train-62674", "mrqa_squad-train-54427", "mrqa_squad-validation-9764", "mrqa_squad-validation-7364", "mrqa_naturalquestions-validation-4002", "mrqa_searchqa-validation-7517", "mrqa_naturalquestions-validation-3558", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-6106", "mrqa_newsqa-validation-3476", "mrqa_squad-validation-27", "mrqa_squad-validation-10388", "mrqa_searchqa-validation-16546", "mrqa_naturalquestions-validation-8189", "mrqa_triviaqa-validation-4881", "mrqa_squad-validation-1780", "mrqa_searchqa-validation-12864", "mrqa_squad-validation-5262", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-801", "mrqa_searchqa-validation-1053", "mrqa_squad-validation-8958", "mrqa_squad-validation-1938", "mrqa_searchqa-validation-14569", "mrqa_naturalquestions-validation-7062", "mrqa_squad-validation-2328", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-2749", "mrqa_naturalquestions-validation-1378", "mrqa_squad-validation-8819", "mrqa_naturalquestions-validation-10156", "mrqa_triviaqa-validation-7463", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-4000"], "EFR": 1.0, "Overall": 0.7696614583333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a Wi-Fi or Power-line connection rather than receive their own satellite feeds", "water pump", "Tesla coil", "1946", "21 to 11", "Convening the Parliamentary Bureau", "Japan and Latin America", "sent missionaries", "Arizona Cardinals", "842 pounds", "1540s", "John Fox", "American Indians in the colony of Georgia", "orbit the Moon", "poison", "quickly", "pathogens", "March 1896", "Percy Jackson", "James `` Jamie '' Dornan", "W. Edwards Deming", "usually in May", "biochemistry", "$657.4 million", "current day", "Accounting Standards Board ( ASB )", "Ole Einar Bj\u00f8rndalen", "General George Washington", "postgraduate training", "Djokovic", "Longliners", "1952", "dome", "1997", "Procol Harum", "Sheev Palpatine", "jennifer", "punk rock", "septum", "The White House Executive chef", "vaskania", "the church at Philippi", "10 May 1940", "Brenda", "bohrium", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "nasal septum", "the Iraq War", "Spanish American wars of independence", "Colin Atkinson", "Owen Vaccaro", "Walter Brennan", "1872", "Mike Alstott", "1992", "King Richard II", "Austria and Switzerland", "Chuck vs. First Class", "Dana Scully", "French Open", "18", "to carry me home", "blinking his left eye", "Puget Sound"], "metric_results": {"EM": 0.5, "QA-F1": 0.5835069444444444}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.20000000000000004, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2932", "mrqa_squad-validation-978", "mrqa_squad-validation-9458", "mrqa_squad-validation-3130", "mrqa_squad-validation-3811", "mrqa_squad-validation-9863", "mrqa_squad-validation-8164", "mrqa_squad-validation-6494", "mrqa_naturalquestions-validation-4135", "mrqa_naturalquestions-validation-9088", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-5583", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-2813", "mrqa_triviaqa-validation-4886", "mrqa_hotpotqa-validation-2009", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-1360", "mrqa_newsqa-validation-765", "mrqa_searchqa-validation-13332", "mrqa_searchqa-validation-9822"], "SR": 0.5, "CSR": 0.6430288461538461, "retrieved_ids": ["mrqa_squad-train-86475", "mrqa_squad-train-56091", "mrqa_squad-train-17292", "mrqa_squad-train-37544", "mrqa_squad-train-41170", "mrqa_squad-train-65527", "mrqa_squad-train-83071", "mrqa_squad-train-45531", "mrqa_squad-train-2046", "mrqa_squad-train-67176", "mrqa_squad-train-24961", "mrqa_squad-train-42923", "mrqa_squad-train-21738", "mrqa_squad-train-74344", "mrqa_squad-train-35282", "mrqa_squad-train-33485", "mrqa_squad-train-648", "mrqa_squad-train-61905", "mrqa_squad-train-14250", "mrqa_squad-train-39981", "mrqa_squad-train-77095", "mrqa_squad-train-14549", "mrqa_squad-train-33474", "mrqa_squad-train-53823", "mrqa_squad-train-43335", "mrqa_squad-train-69253", "mrqa_squad-train-39460", "mrqa_squad-train-35183", "mrqa_squad-train-14772", "mrqa_squad-train-59221", "mrqa_squad-train-25165", "mrqa_squad-train-31389", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-1863", "mrqa_searchqa-validation-8343", "mrqa_squad-validation-7445", "mrqa_squad-validation-7353", "mrqa_searchqa-validation-8760", "mrqa_hotpotqa-validation-2800", "mrqa_naturalquestions-validation-469", "mrqa_squad-validation-7943", "mrqa_squad-validation-8904", "mrqa_hotpotqa-validation-3304", "mrqa_squad-validation-2943", "mrqa_naturalquestions-validation-7062", "mrqa_hotpotqa-validation-1843", "mrqa_naturalquestions-validation-3332", "mrqa_squad-validation-1195", "mrqa_squad-validation-8958", "mrqa_naturalquestions-validation-4002", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-6909", "mrqa_searchqa-validation-15770", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-2934", "mrqa_squad-validation-7613", "mrqa_newsqa-validation-1538", "mrqa_hotpotqa-validation-3020", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10156", "mrqa_squad-validation-5887", "mrqa_squad-validation-7449"], "EFR": 0.96875, "Overall": 0.7610276442307693}, {"timecode": 13, "before_eval_results": {"predictions": ["Protestantism", "Extension", "Riverside", "conservation of momentum", "Hamburg merchants and traders", "Department of Justice", "water flow through the body cavity", "67.9", "Fort Duquesne", "Sports Programs, Inc.", "quality rental units", "Pittsburgh Steelers", "Edward Teller", "the geographical area it covers as well as the frequency of meeting", "to stay, so long as there was at least an \"indirect quid pro quo\" for the work he did", "Andrew Lortie", "bilaterally symmetrical ( Bilateria )", "Thirty years after the Galactic Civil War", "a series of structural rearrangements in the RTK that lead to its enzymatic activation", "two years", "1968", "Longline fishing", "the film was shot at various locations in Redford's adopted home state of Utah", "Stephen A. Douglas", "April 2011", "around 1940", "Las Vegas Stadium", "Herman Hollerith", "Dr. Sachchidananda Sinha", "Ron Harper", "hairpin turn", "July 2011", "the International Baccalaureate ( IB )", "when the cell is undergoing the metaphase of cell division", "it activates a relay which will handle the higher current load", "Donald Trump", "Liam Cunningham", "the spectroscopic notation for the associated atomic orbitals", "Veronica", "moral", "a revolution or orbital revolution", "Sauron", "Gustav Bauer", "2002", "Mohammad Reza Pahlavi", "the southeastern coast of the Commonwealth of Virginia in the United States", "a convergent plate boundary", "Jourdan Miller", "10,605", "the most common double - double combination is points - rebounds, followed by points - assists", "1773", "Jesse McCartney", "73", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1920", "Catherine Zeta-Jones", "Michael Crawford", "247,597", "10,000", "those missing", "the Mormon Tabernacle Choir", "carbon dioxide", "Pickwick", "Sunshine State"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6317650094788253}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.15384615384615383, 0.5, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.8, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.8, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9473684210526316, 1.0, 1.0, 1.0, 0.3, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-3066", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-9979", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2196", "mrqa_naturalquestions-validation-5912", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-6046", "mrqa_triviaqa-validation-4844", "mrqa_triviaqa-validation-5500", "mrqa_hotpotqa-validation-511", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2765", "mrqa_searchqa-validation-12611", "mrqa_triviaqa-validation-1166"], "SR": 0.53125, "CSR": 0.6350446428571428, "retrieved_ids": ["mrqa_squad-train-84410", "mrqa_squad-train-45431", "mrqa_squad-train-22062", "mrqa_squad-train-41521", "mrqa_squad-train-45577", "mrqa_squad-train-79601", "mrqa_squad-train-71391", "mrqa_squad-train-15314", "mrqa_squad-train-37504", "mrqa_squad-train-61984", "mrqa_squad-train-60138", "mrqa_squad-train-74248", "mrqa_squad-train-10469", "mrqa_squad-train-40026", "mrqa_squad-train-62904", "mrqa_squad-train-37873", "mrqa_squad-train-32173", "mrqa_squad-train-43116", "mrqa_squad-train-17738", "mrqa_squad-train-7548", "mrqa_squad-train-7043", "mrqa_squad-train-38920", "mrqa_squad-train-3948", "mrqa_squad-train-37147", "mrqa_squad-train-71", "mrqa_squad-train-16809", "mrqa_squad-train-59359", "mrqa_squad-train-65635", "mrqa_squad-train-58944", "mrqa_squad-train-63589", "mrqa_squad-train-8795", "mrqa_squad-train-49319", "mrqa_naturalquestions-validation-1187", "mrqa_searchqa-validation-1156", "mrqa_squad-validation-3497", "mrqa_searchqa-validation-14194", "mrqa_newsqa-validation-3331", "mrqa_squad-validation-10339", "mrqa_searchqa-validation-9536", "mrqa_naturalquestions-validation-2016", "mrqa_squad-validation-8819", "mrqa_squad-validation-8164", "mrqa_squad-validation-1672", "mrqa_squad-validation-7943", "mrqa_naturalquestions-validation-8934", "mrqa_searchqa-validation-14371", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-8983", "mrqa_squad-validation-3770", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-4619", "mrqa_searchqa-validation-15770", "mrqa_squad-validation-7612", "mrqa_squad-validation-4838", "mrqa_squad-validation-9615", "mrqa_squad-validation-2595", "mrqa_hotpotqa-validation-2800", "mrqa_searchqa-validation-10856", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-5583", "mrqa_squad-validation-6759", "mrqa_squad-validation-1566", "mrqa_squad-validation-7422"], "EFR": 1.0, "Overall": 0.7656808035714285}, {"timecode": 14, "before_eval_results": {"predictions": ["Tulku", "Quaternary", "King George's War", "Brad Nortman", "Museum of the Moving Image", "BBC Dead Ringers", "1206", "Louis Pasteur", "The Brain of Morbius", "the depths of the oceans and seas", "two fumbles,", "a mainline Protestant Methodist denomination", "Albert Einstein", "Vince Lombardi Trophy", "death in body and soul, if only as highwaymen and murderers", "Candice Susan Swanepoel", "AT&T", "Australian", "German", "Chris Anderson", "on the northwest tip of Canisteo Peninsula in Amundsen Sea", "1949", "Red", "Australian", "DI Humphrey Goodman", "Jena Malone", "John M. Dowd", "fainaru Fantaj\u012b Tuerubu", "Republican", "New York", "Southern Rock Allstars", "a tragedy", "Cricket fighting", "14th Street", "bass", "Brad Wilk", "2012", "New Orleans Pelicans", "Robert &quot", "May 4, 1924", "Australian", "1966", "2012", "1926", "27th", "jennifer ciaramello", "Greek mythology", "VAQ-135", "1892", "Ludwig van Beethoven", "Hustle & Flow", "Manchester United", "Saudi Arabian", "1942", "October 6, 2017", "at a given temperature", "wolf", "Ganges", "January 24, 2006", "in some of the poorest parts of South Africa", "a pager", "Baltimore", "1917", "in the Blue Ridge Mountains of Virginia"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6313403603566626}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9411764705882353, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.10526315789473684]}}, "before_error_ids": ["mrqa_squad-validation-7674", "mrqa_squad-validation-8229", "mrqa_squad-validation-218", "mrqa_squad-validation-2383", "mrqa_hotpotqa-validation-2205", "mrqa_hotpotqa-validation-3395", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-2887", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-1011", "mrqa_hotpotqa-validation-5808", "mrqa_hotpotqa-validation-4712", "mrqa_hotpotqa-validation-2585", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-4418", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1951", "mrqa_hotpotqa-validation-5627", "mrqa_hotpotqa-validation-2058", "mrqa_hotpotqa-validation-2582", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-5889", "mrqa_naturalquestions-validation-10613", "mrqa_newsqa-validation-1879", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-1813"], "SR": 0.5625, "CSR": 0.6302083333333333, "retrieved_ids": ["mrqa_squad-train-52588", "mrqa_squad-train-23273", "mrqa_squad-train-45170", "mrqa_squad-train-43030", "mrqa_squad-train-84282", "mrqa_squad-train-31878", "mrqa_squad-train-75015", "mrqa_squad-train-9573", "mrqa_squad-train-64831", "mrqa_squad-train-57726", "mrqa_squad-train-63628", "mrqa_squad-train-58901", "mrqa_squad-train-18521", "mrqa_squad-train-81026", "mrqa_squad-train-32718", "mrqa_squad-train-6182", "mrqa_squad-train-24300", "mrqa_squad-train-86561", "mrqa_squad-train-59258", "mrqa_squad-train-81549", "mrqa_squad-train-44333", "mrqa_squad-train-63088", "mrqa_squad-train-6659", "mrqa_squad-train-79740", "mrqa_squad-train-86511", "mrqa_squad-train-19832", "mrqa_squad-train-38664", "mrqa_squad-train-72247", "mrqa_squad-train-29822", "mrqa_squad-train-80603", "mrqa_squad-train-82898", "mrqa_squad-train-27722", "mrqa_naturalquestions-validation-3485", "mrqa_searchqa-validation-6463", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-10321", "mrqa_naturalquestions-validation-3066", "mrqa_squad-validation-8164", "mrqa_squad-validation-1708", "mrqa_searchqa-validation-4393", "mrqa_squad-validation-8459", "mrqa_hotpotqa-validation-929", "mrqa_squad-validation-2943", "mrqa_newsqa-validation-2765", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-7067", "mrqa_squad-validation-259", "mrqa_searchqa-validation-15202", "mrqa_naturalquestions-validation-4135", "mrqa_squad-validation-1195", "mrqa_naturalquestions-validation-4348", "mrqa_searchqa-validation-11137", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-6500", "mrqa_squad-validation-9615", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-4071", "mrqa_squad-validation-7708", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-191", "mrqa_triviaqa-validation-4844", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-4193"], "EFR": 1.0, "Overall": 0.7647135416666666}, {"timecode": 15, "before_eval_results": {"predictions": ["1937", "Educational Institute of Scotland and the Scottish Secondary Teachers' Association", "2014", "Journey's End", "stronger, tech-oriented", "John Houghton", "heterokontophyte", "NP-complete", "Chinggis", "128,843", "a simple majority vote", "56.2%", "20\u201318", "Archdeacon", "KlingStubbins", "Edward Albert", "1st Earl Mountbatten of Burma", "Alcorn State", "The Guest", "The Light in the Piazza", "Philadelphia, Pennsylvania", "12", "The A41", "Royce da 5'9\" (Bad) and Eminem (Evil)", "Pimp My Ride", "1998", "casting, job opportunities, and career advice", "Mary Harron", "Flashback: The Quest for Identity", "Eenasul Fateh", "Chicago", "Australia", "2014", "Battle of Singapore", "Lismore", "rural", "teenage actor or teen actor", "Summerlin, Clark County, Nevada", "Lester Ben \"Benny\" Binion", "YG Entertainment", "water sprite", "Noel Gallagher", "\"Pour le M\u00e9rite\"", "Trey Parker and Matt Stone", "Epic Records", "Aqua", "American Longhair", "four operas", "Christy Walton", "Lt. Gen. Ulysses S. Grant", "Hechingen", "Black Sabbath", "manager", "8,211", "Tim Allen", "the cell nucleus", "Bristol Box Kite", "1961", "a powerful anesthetic and sedative", "South Dakota State Penitentiary", "Douglas Fir", "drink wine or kiss a fool", "a striking blow to due process and the rule of law", "Philip Markoff"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6771005036630037}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.6153846153846153, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 0.8, 0.0, 1.0, 0.4, 0.8, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2094", "mrqa_squad-validation-2835", "mrqa_hotpotqa-validation-989", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-5644", "mrqa_hotpotqa-validation-1239", "mrqa_hotpotqa-validation-5014", "mrqa_hotpotqa-validation-5667", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-2198", "mrqa_hotpotqa-validation-3162", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-1742", "mrqa_hotpotqa-validation-3721", "mrqa_hotpotqa-validation-2378", "mrqa_hotpotqa-validation-2178", "mrqa_hotpotqa-validation-230", "mrqa_naturalquestions-validation-289", "mrqa_naturalquestions-validation-2558", "mrqa_triviaqa-validation-7461", "mrqa_newsqa-validation-3615", "mrqa_newsqa-validation-1144", "mrqa_searchqa-validation-13595", "mrqa_searchqa-validation-1757"], "SR": 0.546875, "CSR": 0.625, "retrieved_ids": ["mrqa_squad-train-63101", "mrqa_squad-train-44259", "mrqa_squad-train-48455", "mrqa_squad-train-7095", "mrqa_squad-train-17664", "mrqa_squad-train-31071", "mrqa_squad-train-40416", "mrqa_squad-train-22430", "mrqa_squad-train-49528", "mrqa_squad-train-85991", "mrqa_squad-train-76272", "mrqa_squad-train-29556", "mrqa_squad-train-81248", "mrqa_squad-train-84936", "mrqa_squad-train-9577", "mrqa_squad-train-70112", "mrqa_squad-train-66940", "mrqa_squad-train-77843", "mrqa_squad-train-19793", "mrqa_squad-train-25368", "mrqa_squad-train-84769", "mrqa_squad-train-75676", "mrqa_squad-train-53661", "mrqa_squad-train-21330", "mrqa_squad-train-6057", "mrqa_squad-train-54571", "mrqa_squad-train-83249", "mrqa_squad-train-74298", "mrqa_squad-train-48030", "mrqa_squad-train-84882", "mrqa_squad-train-15668", "mrqa_squad-train-6346", "mrqa_squad-validation-5588", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-6106", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-9453", "mrqa_squad-validation-27", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5579", "mrqa_searchqa-validation-3451", "mrqa_triviaqa-validation-1166", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-259", "mrqa_squad-validation-8229", "mrqa_hotpotqa-validation-21", "mrqa_squad-validation-978", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5721", "mrqa_hotpotqa-validation-16", "mrqa_squad-validation-2943", "mrqa_naturalquestions-validation-5531", "mrqa_squad-validation-7449", "mrqa_searchqa-validation-16130", "mrqa_searchqa-validation-6234", "mrqa_squad-validation-4629", "mrqa_squad-validation-4150", "mrqa_squad-validation-3863", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1912", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-2887", "mrqa_hotpotqa-validation-5328"], "EFR": 1.0, "Overall": 0.763671875}, {"timecode": 16, "before_eval_results": {"predictions": ["civil, military, and censorial offices", "Puritan", "James Wolfe", "March 1974", "2003", "Frederick II the Great", "Lower taxes, increased economic development, unification of the community, better public spending and effective administration by a more central authority", "Armenians", "redistributive taxation", "Seattle Seahawks", "paid professionals", "a polynomial-time reduction", "revelry", "Krishna Rajaram", "Padre Alberto", "Mark Thompson", "Alan Kardec scored a spectacular second-half winner", "Choi", "second-degree aggravated battery", "Romney", "a UPS delivery box", "Charman Sinkfield, 30; Demario Ware, 20; and Jquante Crews, 25", "be silent", "200", "28", "several weeks", "auction off one of the earliest versions of the Magna Carta later this year", "it pulls the scab and it cracks, and it starts to bleed", "Prince", "Caylee Anthony", "10 below in Chicago, Illlinois", "women", "Manmohan Singh", "jazz", "1983", "cancer", "Al-Shabaab", "Casalesi Camorra", "videtaping", "Appathurai", "Eintracht Frankfurt", "opium poppies", "Lillo Brancato Jr.", "1,073", "Arthur E. Morgan III", "Arturo Gonzalez Rodriguez", "Las Vegas", "Afghanistan", "FBI negotiators", "Akio Toyoda", "18", "\"Draquila -- Italy Trembles.\"", "India", "Mumbai", "Miami Heat", "a combination of genetics and the male hormone dihydrotestosterone", "Senegal", "Windermere", "Field of Dreams", "Bill Paxton", "a star", "jedoublen/jeopardy", "Sex Pistols", "a portrait of an ambitious Jewish boy growing up in a poor neighborhood in Montreal"], "metric_results": {"EM": 0.5, "QA-F1": 0.5820661109723609}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.5454545454545454, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7296", "mrqa_squad-validation-1136", "mrqa_squad-validation-1765", "mrqa_newsqa-validation-3982", "mrqa_newsqa-validation-216", "mrqa_newsqa-validation-340", "mrqa_newsqa-validation-81", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-25", "mrqa_newsqa-validation-245", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-445", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-2184", "mrqa_newsqa-validation-2837", "mrqa_newsqa-validation-872", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-250", "mrqa_newsqa-validation-631", "mrqa_newsqa-validation-2900", "mrqa_triviaqa-validation-4966", "mrqa_hotpotqa-validation-5742", "mrqa_searchqa-validation-11406", "mrqa_searchqa-validation-11395", "mrqa_searchqa-validation-4356"], "SR": 0.5, "CSR": 0.6176470588235294, "retrieved_ids": ["mrqa_squad-train-39070", "mrqa_squad-train-53903", "mrqa_squad-train-56431", "mrqa_squad-train-11594", "mrqa_squad-train-5447", "mrqa_squad-train-80047", "mrqa_squad-train-44035", "mrqa_squad-train-16010", "mrqa_squad-train-12757", "mrqa_squad-train-43556", "mrqa_squad-train-14552", "mrqa_squad-train-75814", "mrqa_squad-train-60588", "mrqa_squad-train-57354", "mrqa_squad-train-53482", "mrqa_squad-train-53254", "mrqa_squad-train-11181", "mrqa_squad-train-13999", "mrqa_squad-train-13838", "mrqa_squad-train-80346", "mrqa_squad-train-69168", "mrqa_squad-train-44528", "mrqa_squad-train-67275", "mrqa_squad-train-10610", "mrqa_squad-train-11734", "mrqa_squad-train-35622", "mrqa_squad-train-39570", "mrqa_squad-train-19403", "mrqa_squad-train-45646", "mrqa_squad-train-81347", "mrqa_squad-train-27171", "mrqa_squad-train-26423", "mrqa_squad-validation-8595", "mrqa_naturalquestions-validation-4071", "mrqa_hotpotqa-validation-1951", "mrqa_squad-validation-7051", "mrqa_squad-validation-9161", "mrqa_hotpotqa-validation-5386", "mrqa_squad-validation-7876", "mrqa_naturalquestions-validation-6500", "mrqa_squad-validation-4452", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-1912", "mrqa_hotpotqa-validation-5604", "mrqa_squad-validation-7674", "mrqa_searchqa-validation-13151", "mrqa_hotpotqa-validation-1123", "mrqa_naturalquestions-validation-2813", "mrqa_searchqa-validation-6909", "mrqa_searchqa-validation-4393", "mrqa_searchqa-validation-16627", "mrqa_naturalquestions-validation-9715", "mrqa_hotpotqa-validation-4418", "mrqa_naturalquestions-validation-123", "mrqa_searchqa-validation-15202", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6759", "mrqa_hotpotqa-validation-1437", "mrqa_searchqa-validation-16908", "mrqa_squad-validation-3985", "mrqa_hotpotqa-validation-3395", "mrqa_naturalquestions-validation-4865", "mrqa_hotpotqa-validation-5154"], "EFR": 1.0, "Overall": 0.7622012867647059}, {"timecode": 17, "before_eval_results": {"predictions": ["economic inequality", "private individuals, private organizations or religious groups", "high schools", "a glass case suspended from the lid", "phagocytic cells", "2000", "five", "weight", "Leukocytes", "3D printing technology", "Ong Khan", "colonel", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "\"The oceans are kind of the last frontier for use and development,\"", "Wigan Athletic", "Russian air company Vertikal-T,", "Graeme Smith", "228", "the commissions as a legitimate forum for prosecution,", "a Florida girl who disappeared in February", "St. Francis De Sales Catholic Church", "The Tinkler", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East", "air support", "power lines downed by Saturday's winds,", "African National Congress", "Somali", "The oldest documented bikinis -- haute, bandeau-style little numbers", "\"Swingin' Down the Lane\"", "Adam Yahiye Gadahn,", "Gov. Mark Sanford", "150", "all buses, subways and trolleys in Philadelphia and on the Frontier line in Bucks and Montgomery counties stopped running at 3 a.m.", "the equator", "Chinese President Hu Jintao", "183", "alert patients of possible tendon ruptures and tendonitis", "Too many glass shards left by beer drinkers in the city center,", "(l-r) Paul McCartney,", "\"Goldstone Report\"", "11th year in a row", "stolen", "the fastest circumnavigation of the globe in a powerboat", "Guinea, Myanmar, Sudan and Venezuela", "Austin Wuennenberg,", "United Kingdom Dance Championships", "forcibly drugging deportees", "Oaxaca,", "buckling under pressure from the ruling party.", "a polo match", "more than 100", "bribing other wrestlers to lose bouts", "Alfredo Astiz,", "MacFarlane", "convert single - stranded genomic RNA into double - stranded cDNA", "Harrison Ford", "Andes", "Peter Robert Auty", "2009", "\"The Jack Paar Show\"", "Marilyn Monroe", "The Who", "Mary Poppins", "cancun Family Mexican Restaurant"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5529510537323037}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false], "QA-F1": [0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4864864864864865, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7320", "mrqa_squad-validation-7136", "mrqa_squad-validation-2000", "mrqa_squad-validation-7845", "mrqa_squad-validation-6477", "mrqa_newsqa-validation-412", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-3986", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-1634", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-3978", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-4030", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2491", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-140", "mrqa_newsqa-validation-3785", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1123", "mrqa_naturalquestions-validation-1974", "mrqa_hotpotqa-validation-1968", "mrqa_searchqa-validation-13710", "mrqa_searchqa-validation-1649"], "SR": 0.484375, "CSR": 0.6102430555555556, "retrieved_ids": ["mrqa_squad-train-10817", "mrqa_squad-train-38249", "mrqa_squad-train-3338", "mrqa_squad-train-73041", "mrqa_squad-train-20173", "mrqa_squad-train-50234", "mrqa_squad-train-42551", "mrqa_squad-train-21083", "mrqa_squad-train-395", "mrqa_squad-train-32422", "mrqa_squad-train-68341", "mrqa_squad-train-30446", "mrqa_squad-train-65592", "mrqa_squad-train-33285", "mrqa_squad-train-24875", "mrqa_squad-train-35655", "mrqa_squad-train-79783", "mrqa_squad-train-56784", "mrqa_squad-train-21386", "mrqa_squad-train-4660", "mrqa_squad-train-36623", "mrqa_squad-train-48371", "mrqa_squad-train-26586", "mrqa_squad-train-84772", "mrqa_squad-train-56750", "mrqa_squad-train-52605", "mrqa_squad-train-40477", "mrqa_squad-train-56781", "mrqa_squad-train-84212", "mrqa_squad-train-58584", "mrqa_squad-train-70607", "mrqa_squad-train-80398", "mrqa_squad-validation-8819", "mrqa_naturalquestions-validation-4619", "mrqa_squad-validation-2943", "mrqa_newsqa-validation-3982", "mrqa_squad-validation-9458", "mrqa_naturalquestions-validation-9436", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-2205", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-191", "mrqa_searchqa-validation-2579", "mrqa_searchqa-validation-11991", "mrqa_squad-validation-2595", "mrqa_squad-validation-9764", "mrqa_squad-validation-7353", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-1757", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-2102", "mrqa_squad-validation-8459", "mrqa_squad-validation-739", "mrqa_naturalquestions-validation-2452", "mrqa_searchqa-validation-3613", "mrqa_hotpotqa-validation-788", "mrqa_newsqa-validation-2900", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-3686", "mrqa_hotpotqa-validation-4712", "mrqa_squad-validation-5887", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-1747", "mrqa_hotpotqa-validation-1011"], "EFR": 0.9696969696969697, "Overall": 0.754659880050505}, {"timecode": 18, "before_eval_results": {"predictions": ["10 Cloverfield Lane", "in the condenser", "1999", "mesoglea", "a body of treaties and legislation", "liquid", "socially", "Mark Twain's", "in amylopectin starch granules that are located in their cytoplasm", "Tower District", "did not change the threat level", "pro-democracy activists clashed Friday with Egyptian security forces", "a construction site in the heart of Los Angeles.", "to overthrow the socialist government of Salvador Allende in Chile,", "became the world's first \"micro-yachtsman,\"", "a rally", "2,000", "Michael Schumacher", "Ventures", "seven", "Black History Month", "resigned", "\"I'm just getting started.\"", "14", "to release the women without feeling that its legal system has been slighted", "hand-painted Swedish wooden clogs", "Daniel Radcliffe", "Muslim", "five", "her mother", "$10 billion", "Six members of Zoe's Ark", "Galveston, Texas", "9-week-old", "stop selling unapproved pain-relief drugs.", "Lucky Dube", "a Lion Among Men", "James Newell Osterberg", "40", "NATO", "Lindsey Vonn", "acknowledged the procedures should be changed", "a hunting party of three men", "International Polo Club Palm Beach in Florida.", "Nevaeh (heaven spelled backward)", "HPV (human papillomavirus)", "working aid, family finances, competitiveness, infrastructure, and actions toward public spending", "28 of them seriously enough to go to a hospital,", "creation of an Islamic emirate in Gaza", "an \"unnamed international terror group\"", "Nicole", "Stoke City", "al-Maqdessi", "the sixth series", "January 2017", "30", "cuffs", "Waylon Albright \"Shooter\" Jennings", "people working in film and the performing arts", "Coppertone", "Your messes", "Marlborough, New Hampshire", "1968", "The Krypto Report"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5714823160446975}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 0.0, 0.4444444444444445, 0.9411764705882353, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.32258064516129037, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-606", "mrqa_squad-validation-1235", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-472", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-1456", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-3088", "mrqa_newsqa-validation-1064", "mrqa_newsqa-validation-859", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-3679", "mrqa_newsqa-validation-4122", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3446", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2733", "mrqa_naturalquestions-validation-2503", "mrqa_naturalquestions-validation-1770", "mrqa_triviaqa-validation-5209", "mrqa_hotpotqa-validation-2986", "mrqa_searchqa-validation-2463", "mrqa_searchqa-validation-4044", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-3428"], "SR": 0.46875, "CSR": 0.602796052631579, "retrieved_ids": ["mrqa_squad-train-85992", "mrqa_squad-train-11182", "mrqa_squad-train-40854", "mrqa_squad-train-49530", "mrqa_squad-train-77336", "mrqa_squad-train-19904", "mrqa_squad-train-3540", "mrqa_squad-train-13592", "mrqa_squad-train-70842", "mrqa_squad-train-3840", "mrqa_squad-train-46889", "mrqa_squad-train-80143", "mrqa_squad-train-70579", "mrqa_squad-train-380", "mrqa_squad-train-52679", "mrqa_squad-train-32443", "mrqa_squad-train-172", "mrqa_squad-train-70300", "mrqa_squad-train-59820", "mrqa_squad-train-52104", "mrqa_squad-train-21641", "mrqa_squad-train-43055", "mrqa_squad-train-9900", "mrqa_squad-train-70133", "mrqa_squad-train-18337", "mrqa_squad-train-73843", "mrqa_squad-train-67929", "mrqa_squad-train-68879", "mrqa_squad-train-78866", "mrqa_squad-train-75214", "mrqa_squad-train-40624", "mrqa_squad-train-74644", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-4071", "mrqa_searchqa-validation-1649", "mrqa_searchqa-validation-2866", "mrqa_triviaqa-validation-4881", "mrqa_squad-validation-5818", "mrqa_hotpotqa-validation-5742", "mrqa_searchqa-validation-1507", "mrqa_squad-validation-4181", "mrqa_searchqa-validation-13332", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-8934", "mrqa_squad-validation-2000", "mrqa_hotpotqa-validation-2378", "mrqa_newsqa-validation-3785", "mrqa_squad-validation-27", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-1912", "mrqa_searchqa-validation-7514", "mrqa_squad-validation-6655", "mrqa_naturalquestions-validation-469", "mrqa_hotpotqa-validation-5808", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-8356", "mrqa_newsqa-validation-3502", "mrqa_hotpotqa-validation-4815", "mrqa_squad-validation-4838", "mrqa_naturalquestions-validation-2934", "mrqa_squad-validation-3021"], "EFR": 1.0, "Overall": 0.7592310855263158}, {"timecode": 19, "before_eval_results": {"predictions": ["the blood\u2013brain barrier, blood\u2013cerebrospinal fluid barrier, and similar fluid\u2013brain barriers", "an Executive Committee,", "San Francisco Bay Area's", "the death of Elisabeth Sladen", "NFL Experience", "English and Swahili", "61% of GDP", "plastoglobulus", "three", "Lycia", "wombat", "KENNY", "gestation", "Peyton Place", "the Hope Diamond", "gin", "Pilate", "enamel", "bone", "Tagline", "the Norman-French army of William, the Duke of Normandy, and an English army under the Anglo-Saxon King Harold Godwinson", "the Caspian Sea", "a work journal", "\"The 1,001 Nights\"", "Gannett Company", "the boss", "\"Don Juan De Marco\"", "Morocco", "the 1998 FIFA World Cup Final", "Interlaken", "Mystic Pizza", "Princeton University", "Mandy", "the Russian Collection at the Library of Congress", "Malay Peninsula", "Herman Wouk", "Frederick IV,", "\"The heart of a fool\"", "poetry", "Buxhowden", "carontosaurus", "the fifth inning of the fifth game of the 1920 World Series", "thermodynamics", "Derek Smalls", "Dalits", "Robert-Houdini", "\"Randy\" Danson", "Double Vision", "dollop", "Lust for Life", "Camembert", "James Ross Clemens", "a hole-in-one", "1991", "to universalize the topic of the song into something everyone could relate to and ascribe personal meaning to in their own way", "Hoyo de Monterrey Epicure Especial", "\"Thrilla in Manila\"", "North America, Australia, and India", "841", "Ike,", "\"It was terrible, it was gut-wrenching just to hear them say it,\"", "East River", "the Peace of Westphalia of 1648", "near the city of Cairo, Illinois"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5409383494412564}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 0.13953488372093023, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9090909090909091, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-127", "mrqa_squad-validation-8415", "mrqa_searchqa-validation-2143", "mrqa_searchqa-validation-5172", "mrqa_searchqa-validation-12267", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-16076", "mrqa_searchqa-validation-14301", "mrqa_searchqa-validation-13900", "mrqa_searchqa-validation-5928", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-10806", "mrqa_searchqa-validation-12962", "mrqa_searchqa-validation-16378", "mrqa_searchqa-validation-13585", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-11886", "mrqa_searchqa-validation-8705", "mrqa_searchqa-validation-7059", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-5755", "mrqa_searchqa-validation-12440", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-16453", "mrqa_searchqa-validation-13003", "mrqa_searchqa-validation-2714", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-13554", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-5938", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-7401", "mrqa_hotpotqa-validation-2769", "mrqa_newsqa-validation-3214", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-3559"], "SR": 0.4375, "CSR": 0.59453125, "retrieved_ids": ["mrqa_squad-train-34294", "mrqa_squad-train-78941", "mrqa_squad-train-55461", "mrqa_squad-train-64620", "mrqa_squad-train-7116", "mrqa_squad-train-53116", "mrqa_squad-train-75250", "mrqa_squad-train-84150", "mrqa_squad-train-47017", "mrqa_squad-train-83078", "mrqa_squad-train-76578", "mrqa_squad-train-29928", "mrqa_squad-train-58180", "mrqa_squad-train-34251", "mrqa_squad-train-56765", "mrqa_squad-train-69935", "mrqa_squad-train-20454", "mrqa_squad-train-62401", "mrqa_squad-train-34927", "mrqa_squad-train-43748", "mrqa_squad-train-68072", "mrqa_squad-train-8226", "mrqa_squad-train-15539", "mrqa_squad-train-17149", "mrqa_squad-train-63228", "mrqa_squad-train-56125", "mrqa_squad-train-27292", "mrqa_squad-train-48542", "mrqa_squad-train-30202", "mrqa_squad-train-45322", "mrqa_squad-train-62539", "mrqa_squad-train-50448", "mrqa_naturalquestions-validation-9753", "mrqa_newsqa-validation-1032", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-1863", "mrqa_hotpotqa-validation-2198", "mrqa_hotpotqa-validation-2582", "mrqa_squad-validation-4000", "mrqa_squad-validation-6072", "mrqa_searchqa-validation-2866", "mrqa_naturalquestions-validation-3564", "mrqa_squad-validation-6439", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-8239", "mrqa_squad-validation-4629", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-2124", "mrqa_squad-validation-2328", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-8356", "mrqa_newsqa-validation-2886", "mrqa_searchqa-validation-11137", "mrqa_newsqa-validation-3679", "mrqa_squad-validation-8786", "mrqa_hotpotqa-validation-2009", "mrqa_searchqa-validation-2568", "mrqa_newsqa-validation-895", "mrqa_naturalquestions-validation-10311", "mrqa_searchqa-validation-123", "mrqa_naturalquestions-validation-7464", "mrqa_hotpotqa-validation-3162", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-8765"], "EFR": 0.9722222222222222, "Overall": 0.7520225694444445}, {"timecode": 20, "UKR": 0.794921875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-1173", "mrqa_hotpotqa-validation-1252", "mrqa_hotpotqa-validation-1317", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1739", "mrqa_hotpotqa-validation-1742", "mrqa_hotpotqa-validation-1747", "mrqa_hotpotqa-validation-1890", "mrqa_hotpotqa-validation-1967", "mrqa_hotpotqa-validation-2009", "mrqa_hotpotqa-validation-2058", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-2198", "mrqa_hotpotqa-validation-2205", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2232", "mrqa_hotpotqa-validation-230", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2582", "mrqa_hotpotqa-validation-2605", "mrqa_hotpotqa-validation-261", "mrqa_hotpotqa-validation-2705", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3015", "mrqa_hotpotqa-validation-3347", "mrqa_hotpotqa-validation-3519", "mrqa_hotpotqa-validation-3635", "mrqa_hotpotqa-validation-3662", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-4", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4344", "mrqa_hotpotqa-validation-4712", "mrqa_hotpotqa-validation-4815", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5014", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5328", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5644", "mrqa_hotpotqa-validation-5742", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-929", "mrqa_hotpotqa-validation-975", "mrqa_hotpotqa-validation-99", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2503", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2813", "mrqa_naturalquestions-validation-2855", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3898", "mrqa_naturalquestions-validation-4135", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4454", "mrqa_naturalquestions-validation-4906", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5160", "mrqa_naturalquestions-validation-5477", "mrqa_naturalquestions-validation-5583", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5912", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6276", "mrqa_naturalquestions-validation-6279", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-6358", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-837", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9088", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-955", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9818", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-1080", "mrqa_newsqa-validation-1191", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1360", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1456", "mrqa_newsqa-validation-1468", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-1700", "mrqa_newsqa-validation-1738", "mrqa_newsqa-validation-1774", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1811", "mrqa_newsqa-validation-1815", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2184", "mrqa_newsqa-validation-2313", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2491", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2837", "mrqa_newsqa-validation-2900", "mrqa_newsqa-validation-2920", "mrqa_newsqa-validation-3214", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-3333", "mrqa_newsqa-validation-343", "mrqa_newsqa-validation-3446", "mrqa_newsqa-validation-3615", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3679", "mrqa_newsqa-validation-3765", "mrqa_newsqa-validation-3785", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3978", "mrqa_newsqa-validation-4054", "mrqa_newsqa-validation-4122", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-631", "mrqa_newsqa-validation-671", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-766", "mrqa_newsqa-validation-782", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-859", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-920", "mrqa_searchqa-validation-10098", "mrqa_searchqa-validation-1053", "mrqa_searchqa-validation-10856", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-11270", "mrqa_searchqa-validation-11395", "mrqa_searchqa-validation-12646", "mrqa_searchqa-validation-13003", "mrqa_searchqa-validation-1357", "mrqa_searchqa-validation-13585", "mrqa_searchqa-validation-13883", "mrqa_searchqa-validation-13900", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14301", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14371", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-14569", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-16076", "mrqa_searchqa-validation-16130", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-172", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-2100", "mrqa_searchqa-validation-217", "mrqa_searchqa-validation-2303", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-2607", "mrqa_searchqa-validation-2714", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-393", "mrqa_searchqa-validation-4169", "mrqa_searchqa-validation-4258", "mrqa_searchqa-validation-4269", "mrqa_searchqa-validation-4393", "mrqa_searchqa-validation-4469", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5172", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-5755", "mrqa_searchqa-validation-5928", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-686", "mrqa_searchqa-validation-7059", "mrqa_searchqa-validation-7086", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-7998", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-8693", "mrqa_searchqa-validation-8705", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-971", "mrqa_squad-validation-10097", "mrqa_squad-validation-10135", "mrqa_squad-validation-10136", "mrqa_squad-validation-10143", "mrqa_squad-validation-10168", "mrqa_squad-validation-10241", "mrqa_squad-validation-10266", "mrqa_squad-validation-10370", "mrqa_squad-validation-10388", "mrqa_squad-validation-10477", "mrqa_squad-validation-1095", "mrqa_squad-validation-1125", "mrqa_squad-validation-1141", "mrqa_squad-validation-115", "mrqa_squad-validation-1177", "mrqa_squad-validation-1195", "mrqa_squad-validation-120", "mrqa_squad-validation-1254", "mrqa_squad-validation-127", "mrqa_squad-validation-1288", "mrqa_squad-validation-1408", "mrqa_squad-validation-1453", "mrqa_squad-validation-1499", "mrqa_squad-validation-1533", "mrqa_squad-validation-1566", "mrqa_squad-validation-1672", "mrqa_squad-validation-1747", "mrqa_squad-validation-1765", "mrqa_squad-validation-1827", "mrqa_squad-validation-1892", "mrqa_squad-validation-195", "mrqa_squad-validation-1953", "mrqa_squad-validation-2033", "mrqa_squad-validation-2041", "mrqa_squad-validation-2050", "mrqa_squad-validation-2059", "mrqa_squad-validation-218", "mrqa_squad-validation-22", "mrqa_squad-validation-2243", "mrqa_squad-validation-2248", "mrqa_squad-validation-2328", "mrqa_squad-validation-2352", "mrqa_squad-validation-2365", "mrqa_squad-validation-2379", "mrqa_squad-validation-2383", "mrqa_squad-validation-2411", "mrqa_squad-validation-2438", "mrqa_squad-validation-2456", "mrqa_squad-validation-2463", "mrqa_squad-validation-2467", "mrqa_squad-validation-2538", "mrqa_squad-validation-2545", "mrqa_squad-validation-257", "mrqa_squad-validation-2589", "mrqa_squad-validation-2595", "mrqa_squad-validation-2683", "mrqa_squad-validation-27", "mrqa_squad-validation-2886", "mrqa_squad-validation-2943", "mrqa_squad-validation-2953", "mrqa_squad-validation-2959", "mrqa_squad-validation-3019", "mrqa_squad-validation-305", "mrqa_squad-validation-3052", "mrqa_squad-validation-3130", "mrqa_squad-validation-3144", "mrqa_squad-validation-3184", "mrqa_squad-validation-3241", "mrqa_squad-validation-327", "mrqa_squad-validation-3335", "mrqa_squad-validation-335", "mrqa_squad-validation-3358", "mrqa_squad-validation-3364", "mrqa_squad-validation-3406", "mrqa_squad-validation-3435", "mrqa_squad-validation-3501", "mrqa_squad-validation-3567", "mrqa_squad-validation-358", "mrqa_squad-validation-3605", "mrqa_squad-validation-3605", "mrqa_squad-validation-3626", "mrqa_squad-validation-3680", "mrqa_squad-validation-3687", "mrqa_squad-validation-3796", "mrqa_squad-validation-381", "mrqa_squad-validation-3812", "mrqa_squad-validation-3863", "mrqa_squad-validation-3864", "mrqa_squad-validation-3917", "mrqa_squad-validation-3919", "mrqa_squad-validation-3946", "mrqa_squad-validation-3975", "mrqa_squad-validation-3986", "mrqa_squad-validation-3994", "mrqa_squad-validation-4000", "mrqa_squad-validation-402", "mrqa_squad-validation-402", "mrqa_squad-validation-4047", "mrqa_squad-validation-4066", "mrqa_squad-validation-4175", "mrqa_squad-validation-4187", "mrqa_squad-validation-4265", "mrqa_squad-validation-4302", "mrqa_squad-validation-4312", "mrqa_squad-validation-4326", "mrqa_squad-validation-4446", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4468", "mrqa_squad-validation-4509", "mrqa_squad-validation-4530", "mrqa_squad-validation-4538", "mrqa_squad-validation-4546", "mrqa_squad-validation-4572", "mrqa_squad-validation-4583", "mrqa_squad-validation-4629", "mrqa_squad-validation-4715", "mrqa_squad-validation-4883", "mrqa_squad-validation-5004", "mrqa_squad-validation-5014", "mrqa_squad-validation-5097", "mrqa_squad-validation-5110", "mrqa_squad-validation-5140", "mrqa_squad-validation-5237", "mrqa_squad-validation-5320", "mrqa_squad-validation-5396", "mrqa_squad-validation-5435", "mrqa_squad-validation-5448", "mrqa_squad-validation-5453", "mrqa_squad-validation-5479", "mrqa_squad-validation-5572", "mrqa_squad-validation-5588", "mrqa_squad-validation-5604", "mrqa_squad-validation-5677", "mrqa_squad-validation-5692", "mrqa_squad-validation-5737", "mrqa_squad-validation-5781", "mrqa_squad-validation-5859", "mrqa_squad-validation-5860", "mrqa_squad-validation-5887", "mrqa_squad-validation-5960", "mrqa_squad-validation-6030", "mrqa_squad-validation-6069", "mrqa_squad-validation-6171", "mrqa_squad-validation-6206", "mrqa_squad-validation-6228", "mrqa_squad-validation-6240", "mrqa_squad-validation-6243", "mrqa_squad-validation-6279", "mrqa_squad-validation-6347", "mrqa_squad-validation-6439", "mrqa_squad-validation-6490", "mrqa_squad-validation-6517", "mrqa_squad-validation-6535", "mrqa_squad-validation-6543", "mrqa_squad-validation-6551", "mrqa_squad-validation-6594", "mrqa_squad-validation-6611", "mrqa_squad-validation-6694", "mrqa_squad-validation-6729", "mrqa_squad-validation-6790", "mrqa_squad-validation-6838", "mrqa_squad-validation-6951", "mrqa_squad-validation-6957", "mrqa_squad-validation-6965", "mrqa_squad-validation-6999", "mrqa_squad-validation-7034", "mrqa_squad-validation-7039", "mrqa_squad-validation-7051", "mrqa_squad-validation-71", "mrqa_squad-validation-7125", "mrqa_squad-validation-7136", "mrqa_squad-validation-7192", "mrqa_squad-validation-7390", "mrqa_squad-validation-7422", "mrqa_squad-validation-7449", "mrqa_squad-validation-7521", "mrqa_squad-validation-7576", "mrqa_squad-validation-7608", "mrqa_squad-validation-7612", "mrqa_squad-validation-7613", "mrqa_squad-validation-7618", "mrqa_squad-validation-7674", "mrqa_squad-validation-7693", "mrqa_squad-validation-7708", "mrqa_squad-validation-7751", "mrqa_squad-validation-7814", "mrqa_squad-validation-7863", "mrqa_squad-validation-7872", "mrqa_squad-validation-7876", "mrqa_squad-validation-7881", "mrqa_squad-validation-7943", "mrqa_squad-validation-7952", "mrqa_squad-validation-7954", "mrqa_squad-validation-7982", "mrqa_squad-validation-7984", "mrqa_squad-validation-7993", "mrqa_squad-validation-8043", "mrqa_squad-validation-8229", "mrqa_squad-validation-8282", "mrqa_squad-validation-829", "mrqa_squad-validation-8309", "mrqa_squad-validation-8415", "mrqa_squad-validation-8417", "mrqa_squad-validation-8471", "mrqa_squad-validation-8500", "mrqa_squad-validation-852", "mrqa_squad-validation-8561", "mrqa_squad-validation-8585", "mrqa_squad-validation-8594", "mrqa_squad-validation-8670", "mrqa_squad-validation-8710", "mrqa_squad-validation-8754", "mrqa_squad-validation-8769", "mrqa_squad-validation-8809", "mrqa_squad-validation-893", "mrqa_squad-validation-8933", "mrqa_squad-validation-8969", "mrqa_squad-validation-8985", "mrqa_squad-validation-9095", "mrqa_squad-validation-9102", "mrqa_squad-validation-9166", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9367", "mrqa_squad-validation-9405", "mrqa_squad-validation-942", "mrqa_squad-validation-9594", "mrqa_squad-validation-9614", "mrqa_squad-validation-9669", "mrqa_squad-validation-985", "mrqa_squad-validation-9866", "mrqa_squad-validation-9876", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-2441", "mrqa_triviaqa-validation-2623", "mrqa_triviaqa-validation-4881", "mrqa_triviaqa-validation-4886", "mrqa_triviaqa-validation-6421", "mrqa_triviaqa-validation-6665", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-7496"], "OKR": 0.92578125, "KG": 0.48203125, "before_eval_results": {"predictions": ["the main contractor", "widespread education", "300", "an attack on New France's capital, Quebec", "two-thirds", "Decompression sickness", "1979", "Parliament Square, High Street and George IV Bridge", "1959", "the Lincoln Laboratory", "grizzly bear", "Dracula", "Sid Vicious", "nitrous oxide", "an", "Frederic Remington", "a mangrove swamps", "Arkansas", "an object oriented programming", "2010", "the Uniform Code of Military Justice", "William Henry Harrison", "ER", "a man", "a knife", "The Princess Diaries", "Arkansas", "Mao Zedong", "a multilingual person", "a genie", "Lehman Brothers", "Sundance", "a man", "amber", "Holly", "Umbria", "a Roth IRA", "Quentin Tarantino", "the Palatine", "Kentucky", "a statement that is taken to be true, to serve as a premise or starting point for further reasoning and arguments", "Daylight Saving Time", "a miniskirt", "a juliehagerty", "Libby", "an overwhelm", "an ill-fated, forbidden romance", "Equatorial Guinea", "a man", "a thumb", "Walter Reed", "Aerobic exercise", "Anaheim", "Steve Hale", "the distribution and determinants of health and disease conditions in defined populations", "Belgium", "Jack Frost", "137th", "Merck and Schering-Plough", "semiconductors", "St Petersburg and Moscow", "Great Britain", "Hagrid", "Phil Mickelson"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5680989583333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.625, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4918", "mrqa_searchqa-validation-4028", "mrqa_searchqa-validation-9185", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-15995", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-16826", "mrqa_searchqa-validation-1770", "mrqa_searchqa-validation-14446", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-12996", "mrqa_searchqa-validation-2038", "mrqa_searchqa-validation-4032", "mrqa_searchqa-validation-3926", "mrqa_searchqa-validation-3811", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-12477", "mrqa_searchqa-validation-10536", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-3479", "mrqa_searchqa-validation-12188", "mrqa_searchqa-validation-11227", "mrqa_searchqa-validation-3525", "mrqa_searchqa-validation-2743", "mrqa_searchqa-validation-9183", "mrqa_searchqa-validation-9853", "mrqa_searchqa-validation-4768", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-4992", "mrqa_hotpotqa-validation-3157", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-4118", "mrqa_triviaqa-validation-2527", "mrqa_triviaqa-validation-436"], "SR": 0.453125, "CSR": 0.5877976190476191, "retrieved_ids": ["mrqa_squad-train-36121", "mrqa_squad-train-8332", "mrqa_squad-train-70162", "mrqa_squad-train-50555", "mrqa_squad-train-39990", "mrqa_squad-train-63711", "mrqa_squad-train-82204", "mrqa_squad-train-16262", "mrqa_squad-train-11253", "mrqa_squad-train-59008", "mrqa_squad-train-30397", "mrqa_squad-train-29242", "mrqa_squad-train-41657", "mrqa_squad-train-57854", "mrqa_squad-train-15930", "mrqa_squad-train-69972", "mrqa_squad-train-37318", "mrqa_squad-train-76871", "mrqa_squad-train-78314", "mrqa_squad-train-47295", "mrqa_squad-train-987", "mrqa_squad-train-83957", "mrqa_squad-train-58638", "mrqa_squad-train-55293", "mrqa_squad-train-9897", "mrqa_squad-train-44177", "mrqa_squad-train-58791", "mrqa_squad-train-4723", "mrqa_squad-train-65215", "mrqa_squad-train-42242", "mrqa_squad-train-86112", "mrqa_squad-train-48535", "mrqa_searchqa-validation-14569", "mrqa_hotpotqa-validation-5790", "mrqa_searchqa-validation-3960", "mrqa_newsqa-validation-2112", "mrqa_naturalquestions-validation-2466", "mrqa_squad-validation-10321", "mrqa_hotpotqa-validation-2452", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2866", "mrqa_naturalquestions-validation-7390", "mrqa_squad-validation-6409", "mrqa_searchqa-validation-9390", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-2969", "mrqa_squad-validation-7422", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-3811", "mrqa_squad-validation-5435", "mrqa_newsqa-validation-340", "mrqa_squad-validation-7051", "mrqa_newsqa-validation-3869", "mrqa_squad-validation-3497", "mrqa_searchqa-validation-14655", "mrqa_hotpotqa-validation-5644", "mrqa_squad-validation-4838", "mrqa_newsqa-validation-2541", "mrqa_searchqa-validation-4044", "mrqa_searchqa-validation-15770", "mrqa_naturalquestions-validation-10156", "mrqa_squad-validation-8093", "mrqa_triviaqa-validation-5500"], "EFR": 1.0, "Overall": 0.7581063988095238}, {"timecode": 21, "before_eval_results": {"predictions": ["a lesson plan", "laws of physics", "(1893)", "Welsh", "pastors and teachers", "criminal", "a monthly subscription", "10,000 BC", "novella", "President of the United States", "above the light source and under the sample in an upright microscope", "November 3, 2007", "1939", "April 1917", "1959", "the orphanage where he was raised", "September 19 - 22, 2017", "bypasses", "can affect the perception of a decision, action, idea, business, person, group, entity, or other whenever concrete data is generalized or influences ambiguous information", "Bobby Eli, John Freeman and Vinnie Barrett", "Nagaland", "Dick Rutan and Jeana Yeager", "Paracelsus", "January 2004", "members of the gay ( LGBT ) community", "annually", "it violated their rights as Englishmen to `` No taxation without representation ''", "LSD", "push the food down the esophagus", "Splodgenessabounds", "drive", "Edd Kimber", "a white one", "diastema", "Saul", "video game", "high officials", "flour and water", "the National Football League ( NFL )", "Gupta Empire", "card verification value", "T - Bone Walker", "Ray Charles", "Francis Hutcheson", "1937", "Cairo, Illinois", "Barbara Windsor", "British", "Gladys Knight & the Pips", "Executive Residence of the White House Complex", "2013", "judges", "Kanawha River", "athletics", "isosceles", "1898", "Sir Matthew Arundell", "WFTV", "tennis", "The O.J. Simpson trial", "Austria", "women coping with breast cancer", "Harry Nicolaides", "dropped the bat"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5987646621148459}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6428571428571429, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.10714285714285714, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.4583333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.35294117647058826, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5882352941176471, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-10037", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-8228", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-9691", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-4544", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-6087", "mrqa_hotpotqa-validation-5403", "mrqa_newsqa-validation-469", "mrqa_searchqa-validation-4715", "mrqa_newsqa-validation-442", "mrqa_newsqa-validation-1985"], "SR": 0.546875, "CSR": 0.5859375, "retrieved_ids": ["mrqa_squad-train-83416", "mrqa_squad-train-36525", "mrqa_squad-train-18664", "mrqa_squad-train-75630", "mrqa_squad-train-42405", "mrqa_squad-train-62749", "mrqa_squad-train-81213", "mrqa_squad-train-43841", "mrqa_squad-train-76315", "mrqa_squad-train-2059", "mrqa_squad-train-59327", "mrqa_squad-train-33407", "mrqa_squad-train-19991", "mrqa_squad-train-25027", "mrqa_squad-train-14381", "mrqa_squad-train-9358", "mrqa_squad-train-71218", "mrqa_squad-train-28330", "mrqa_squad-train-8685", "mrqa_squad-train-64372", "mrqa_squad-train-77785", "mrqa_squad-train-12332", "mrqa_squad-train-16428", "mrqa_squad-train-43607", "mrqa_squad-train-32189", "mrqa_squad-train-46859", "mrqa_squad-train-68492", "mrqa_squad-train-73621", "mrqa_squad-train-40850", "mrqa_squad-train-19720", "mrqa_squad-train-80295", "mrqa_squad-train-48419", "mrqa_squad-validation-9863", "mrqa_searchqa-validation-6181", "mrqa_searchqa-validation-11406", "mrqa_searchqa-validation-2038", "mrqa_hotpotqa-validation-4815", "mrqa_searchqa-validation-13554", "mrqa_squad-validation-5435", "mrqa_searchqa-validation-3530", "mrqa_squad-validation-4918", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-2969", "mrqa_searchqa-validation-4044", "mrqa_squad-validation-8471", "mrqa_hotpotqa-validation-3395", "mrqa_newsqa-validation-1412", "mrqa_naturalquestions-validation-7554", "mrqa_newsqa-validation-2735", "mrqa_squad-validation-7612", "mrqa_naturalquestions-validation-291", "mrqa_squad-validation-1780", "mrqa_hotpotqa-validation-132", "mrqa_newsqa-validation-4122", "mrqa_hotpotqa-validation-929", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-12267", "mrqa_squad-validation-2145", "mrqa_squad-validation-7296", "mrqa_squad-validation-8769", "mrqa_newsqa-validation-2591", "mrqa_naturalquestions-validation-5721", "mrqa_searchqa-validation-7086"], "EFR": 0.8620689655172413, "Overall": 0.7301481681034482}, {"timecode": 22, "before_eval_results": {"predictions": ["literacy and numeracy, craftsmanship or vocational training, the arts, religion, civics, community roles, or life skills", "mulberry trees", "drama series", "1806", "\"distributive efficiency\"", "on issues related to the substance of the statement", "Tokyo", "Continental drift", "Frank Oz", "1975", "775", "Kimberlin Brown", "AD 95 -- 110", "status line", "the disk, about 26,000 light - years from the Galactic Center, on the inner edge of the Nebula Arm, one of the spiral - shaped concentrations of gas and dust", "absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "handheld subscriber equipment", "a number of English country estates", "a type II endoprotease, cleaves the C peptide - A chain bond", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "Yuzuru Hanyu", "Aibak", "a negro, whose ancestors were imported into ( the U.S. ), and sold as slaves '', whether enslaved or free, could not be an American citizen and therefore had no standing to sue in federal court", "Coton in the Elms", "an ascender", "Wakanda and the Savage Land", "1992", "a root respiration", "shortwave radio", "Mansa Musa passed out gold to all the poor along the way", "Edward Kenway", "Robert Hooke", "dense regions within molecular clouds in interstellar space", "Alicia Vikander", "a male bandmates ( Tavish Crowe )", "the name announcement of Kylie Jenner's first child", "5 liters", "somatic cell nuclear transfer ( SCNT )", "Betty", "rapid destruction of the donor red blood cells by host antibodies ( IgG, IgM )", "June 8, 2009", "head - up display", "presidential representative democratic republic", "Ferm\u00edn Francisco de Lasu\u00e9n", "a moral tale", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "1994", "Spanish / Basque origin", "Laura Jane Haddock", "Atlanta", "2002", "nasal septum", "a coffee house", "Chief Inspector of Prisons", "Cheshire", "#364", "24800 mi", "liberal revolutions of 1848", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan", "Matamoros, Mexico", "airport was grounded until the process was completed.", "X-Files", "biometric authentication", "the Great Seal"], "metric_results": {"EM": 0.53125, "QA-F1": 0.7010099287358382}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.23529411764705882, 0.6666666666666666, 1.0, 1.0, 1.0, 0.923076923076923, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6842105263157895, 0.9166666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.7407407407407407, 1.0, 0.0, 0.2, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 0.5714285714285715, 0.0, 0.7999999999999999, 0.2857142857142857, 0.888888888888889, 0.14285714285714288, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23076923076923078, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1802", "mrqa_squad-validation-8195", "mrqa_squad-validation-9484", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-4190", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-10128", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-2210", "mrqa_naturalquestions-validation-9141", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-3484", "mrqa_searchqa-validation-3633", "mrqa_searchqa-validation-7662"], "SR": 0.53125, "CSR": 0.5835597826086957, "retrieved_ids": ["mrqa_squad-train-25114", "mrqa_squad-train-71114", "mrqa_squad-train-44198", "mrqa_squad-train-22516", "mrqa_squad-train-47360", "mrqa_squad-train-60748", "mrqa_squad-train-22295", "mrqa_squad-train-6915", "mrqa_squad-train-39485", "mrqa_squad-train-16922", "mrqa_squad-train-5906", "mrqa_squad-train-74090", "mrqa_squad-train-75943", "mrqa_squad-train-49699", "mrqa_squad-train-33459", "mrqa_squad-train-54732", "mrqa_squad-train-71743", "mrqa_squad-train-6384", "mrqa_squad-train-7803", "mrqa_squad-train-64208", "mrqa_squad-train-53460", "mrqa_squad-train-82609", "mrqa_squad-train-8569", "mrqa_squad-train-59550", "mrqa_squad-train-53063", "mrqa_squad-train-3235", "mrqa_squad-train-18283", "mrqa_squad-train-74805", "mrqa_squad-train-6041", "mrqa_squad-train-23140", "mrqa_squad-train-59125", "mrqa_squad-train-587", "mrqa_squad-validation-6409", "mrqa_squad-validation-10143", "mrqa_hotpotqa-validation-5292", "mrqa_searchqa-validation-2463", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-1757", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4712", "mrqa_naturalquestions-validation-3559", "mrqa_newsqa-validation-2491", "mrqa_naturalquestions-validation-10613", "mrqa_searchqa-validation-11886", "mrqa_naturalquestions-validation-7694", "mrqa_searchqa-validation-14655", "mrqa_triviaqa-validation-4881", "mrqa_newsqa-validation-4122", "mrqa_naturalquestions-validation-10554", "mrqa_newsqa-validation-340", "mrqa_hotpotqa-validation-3162", "mrqa_newsqa-validation-631", "mrqa_searchqa-validation-13595", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8983", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-1879", "mrqa_naturalquestions-validation-2503", "mrqa_squad-validation-7457", "mrqa_newsqa-validation-250", "mrqa_searchqa-validation-7059", "mrqa_naturalquestions-validation-5938", "mrqa_naturalquestions-validation-3686", "mrqa_hotpotqa-validation-3395"], "EFR": 0.9333333333333333, "Overall": 0.7439254981884058}, {"timecode": 23, "before_eval_results": {"predictions": ["100,000", "Tyneside Classical", "ring theory", "his birthtown, Smiljan", "Persia", "ABC-DuMont", "bathtub curve", "First World War", "John Constable", "Charlie Harper", "salutations", "Duncan", "Everton", "October", "cogito ergo sum", "Bull Moose Party", "the final round of the 2013 The Masters", "Demi Moore", "the College of Cardinals", "Cornell", "Robert Stroud", "Alice in Alice", "caffeine", "The Blind Side", "11", "17", "Achille Lauro", "Quentin Tarantino", "Bert Jones", "New York", "Wyatt", "Chuck Hagel", "Hispaniola", "Bangladesh", "argument form", "Claire Goose", "one king, one queen, two bishops, two knights, and eight pawns", "Bath, Bristol, Coventry, Moseley, Nottingham, Orrell, Sale, Wasps", "tinctures", "Andy Murray", "Independence Day", "a phantom eight-ender", "Hanseatic League", "Crusades", "King Henry I", "ThunderCats", "comic", "The European Council", "Volkswagen", "Prince William", "kalvinka", "China", "Edward Seton", "Thomas Jefferson", "central plains", "William Adelin", "Barbary pirates", "Sir William Collins", "to hold onto his land", "was found Sunday on an island stronghold of the Islamic militant group Abu Sayyaf,", "if they focused their subversive energy on neural devices, such as the deep-brain stimulators used to treat Parkinson's and depression, or electrode systems for controlling prosthetic limbs", "Port In A Storm", "the Lone Star", "Bahadur Shah Zafar II"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6376984126984127}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.1904761904761905, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9136", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-2486", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3864", "mrqa_triviaqa-validation-5816", "mrqa_triviaqa-validation-6584", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-7212", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-1802", "mrqa_triviaqa-validation-7056", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-1683", "mrqa_naturalquestions-validation-1782", "mrqa_hotpotqa-validation-4451", "mrqa_newsqa-validation-3404", "mrqa_newsqa-validation-2371", "mrqa_searchqa-validation-4179", "mrqa_searchqa-validation-13686"], "SR": 0.5625, "CSR": 0.5826822916666667, "retrieved_ids": ["mrqa_squad-train-5943", "mrqa_squad-train-14768", "mrqa_squad-train-48024", "mrqa_squad-train-15656", "mrqa_squad-train-31198", "mrqa_squad-train-84801", "mrqa_squad-train-23194", "mrqa_squad-train-33058", "mrqa_squad-train-47326", "mrqa_squad-train-31836", "mrqa_squad-train-78339", "mrqa_squad-train-53837", "mrqa_squad-train-67548", "mrqa_squad-train-29851", "mrqa_squad-train-16092", "mrqa_squad-train-30066", "mrqa_squad-train-58763", "mrqa_squad-train-40761", "mrqa_squad-train-54712", "mrqa_squad-train-18317", "mrqa_squad-train-82216", "mrqa_squad-train-15989", "mrqa_squad-train-11933", "mrqa_squad-train-1009", "mrqa_squad-train-73664", "mrqa_squad-train-65365", "mrqa_squad-train-18920", "mrqa_squad-train-41472", "mrqa_squad-train-46648", "mrqa_squad-train-3813", "mrqa_squad-train-38038", "mrqa_squad-train-54531", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-291", "mrqa_newsqa-validation-1412", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-923", "mrqa_searchqa-validation-2038", "mrqa_hotpotqa-validation-3944", "mrqa_naturalquestions-validation-10614", "mrqa_searchqa-validation-16130", "mrqa_searchqa-validation-14446", "mrqa_squad-validation-3770", "mrqa_naturalquestions-validation-8189", "mrqa_triviaqa-validation-5500", "mrqa_naturalquestions-validation-5780", "mrqa_searchqa-validation-8711", "mrqa_searchqa-validation-11137", "mrqa_newsqa-validation-2541", "mrqa_squad-validation-7296", "mrqa_searchqa-validation-11395", "mrqa_naturalquestions-validation-7694", "mrqa_hotpotqa-validation-3090", "mrqa_newsqa-validation-3476", "mrqa_squad-validation-7708", "mrqa_newsqa-validation-1855", "mrqa_searchqa-validation-16826", "mrqa_hotpotqa-validation-1239", "mrqa_hotpotqa-validation-2887", "mrqa_squad-validation-3718", "mrqa_hotpotqa-validation-5627", "mrqa_squad-validation-2595", "mrqa_searchqa-validation-12363"], "EFR": 0.9642857142857143, "Overall": 0.7499404761904762}, {"timecode": 24, "before_eval_results": {"predictions": ["Napoleon", "The Victorian Alps in the northeast", "skin damage", "three", "European Parliament and the Council of the European Union", "Steve McQueen", "\u00c9dith Piaf", "guitar", "Midtown", "bogge", "shoes", "boxer", "Geneva", "The Circus", "Woodrow Wilson", "the east coast of the island of Menorca", "Wales", "amphit was decided they should change their name", "bulldog Drummond", "distance selling", "Edward VI", "linseed", "Mercury", "piano", "architecture", "james bond villain", "Iain Banks", "Spain", "gluten", "Jan Van Eyck", "george iv", "red-green", "george iv", "charlie", "World War II", "the Battle of Thermopylae", "george iv", "Yosemite", "maelor", "king duncan", "8 minutes", "uranium", "Old Betsy", "a bra made by Playtex", "West Point", "Saint Cecilia", "algebra", "george ivy", "Whittle", "charlie", "Loose ends", "Chester", "Brazil, Bolivia, Paraguay and Argentina", "a for - profit business, nonprofit organization, or a government agency", "2005", "Wes Craven", "1698", "Bill Clinton", "\"AS IS/where IS\" at a salvage yard in Kearny, New Jersey", "the triangular bone within the pelvis", "246", "Hurricane", "The Treasure of the Sierra Madre", "smallpox"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5759399801587302}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.08000000000000002, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2911", "mrqa_triviaqa-validation-2544", "mrqa_triviaqa-validation-601", "mrqa_triviaqa-validation-3769", "mrqa_triviaqa-validation-2199", "mrqa_triviaqa-validation-5261", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-2669", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-5387", "mrqa_triviaqa-validation-4073", "mrqa_triviaqa-validation-1156", "mrqa_triviaqa-validation-7439", "mrqa_triviaqa-validation-4210", "mrqa_triviaqa-validation-4317", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-2495", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-2361", "mrqa_triviaqa-validation-189", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-4843", "mrqa_triviaqa-validation-2151", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-2426", "mrqa_newsqa-validation-2086", "mrqa_newsqa-validation-1496", "mrqa_searchqa-validation-8665", "mrqa_searchqa-validation-1857"], "SR": 0.53125, "CSR": 0.580625, "retrieved_ids": ["mrqa_squad-train-9458", "mrqa_squad-train-8813", "mrqa_squad-train-46839", "mrqa_squad-train-52011", "mrqa_squad-train-58478", "mrqa_squad-train-51317", "mrqa_squad-train-29677", "mrqa_squad-train-56775", "mrqa_squad-train-74888", "mrqa_squad-train-38454", "mrqa_squad-train-63001", "mrqa_squad-train-75902", "mrqa_squad-train-46451", "mrqa_squad-train-44957", "mrqa_squad-train-71454", "mrqa_squad-train-56409", "mrqa_squad-train-46348", "mrqa_squad-train-43162", "mrqa_squad-train-83932", "mrqa_squad-train-71212", "mrqa_squad-train-15150", "mrqa_squad-train-39991", "mrqa_squad-train-9706", "mrqa_squad-train-36358", "mrqa_squad-train-32266", "mrqa_squad-train-9869", "mrqa_squad-train-6870", "mrqa_squad-train-82170", "mrqa_squad-train-82429", "mrqa_squad-train-39470", "mrqa_squad-train-28718", "mrqa_squad-train-16161", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-2969", "mrqa_searchqa-validation-6445", "mrqa_squad-validation-7525", "mrqa_hotpotqa-validation-511", "mrqa_searchqa-validation-8705", "mrqa_squad-validation-9615", "mrqa_squad-validation-606", "mrqa_searchqa-validation-13554", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1747", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-2213", "mrqa_searchqa-validation-7724", "mrqa_squad-validation-10388", "mrqa_naturalquestions-validation-6046", "mrqa_searchqa-validation-8760", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-6524", "mrqa_newsqa-validation-2476", "mrqa_squad-validation-3811", "mrqa_squad-validation-3718", "mrqa_newsqa-validation-1893", "mrqa_hotpotqa-validation-3721", "mrqa_naturalquestions-validation-4132", "mrqa_squad-validation-2145", "mrqa_hotpotqa-validation-16", "mrqa_searchqa-validation-10806", "mrqa_squad-validation-1906", "mrqa_searchqa-validation-9183", "mrqa_squad-validation-8990"], "EFR": 1.0, "Overall": 0.756671875}, {"timecode": 25, "before_eval_results": {"predictions": ["only individuals can act unjustly", "Thomas Piketty", "1,548", "zoning and building code requirements", "Science and Discovery", "upstate New York village of Lake Placid", "the Central line", "Vietnam", "a non-speaking character", "bluebird", "a boat", "300", "1939", "mansoleum", "jennifer carmen cans", "jodie Foster as Pugsley", "Billie Holiday", "The National Council for the Unmarried Mother and her Child", "thomas mackelson", "Jean-Paul Sartre", "Len Deighton", "the Highland Garb Act", "Alex Garland", "L. Pasteur", "Dionysus", "prime minister Benjamin Disraeli", "Johannesburg", "Martin Luther King", "Chicago", "Aidensfield", "a point in the first set", "blue tang", "David Cameron", "Newfoundland", "Eddie Cochran", "brenda carmen cans", "Outkast", "Wanderers", "sunny afternoon", "Biafra secession", "Tina Turner", "brenda", "Cuba", "a dove", "Heston Blumenthal", "Harold Godwinson", "Tommy Burns", "Ritchie Valens", "bristol", "Honda", "Bristol", "j.M. Cohen", "Krypton", "Cyanea capillata", "if the concentration of a compound exceeds its solubility", "Morning Edition", "Franz Ferdinand", "Paul John Manafort Jr.", "underprivileged", "Jennifer Aniston, Demi Moore and Alicia Keys", "80", "Maldives", "Matt Leinart", "Stephen Hawking"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6048010149572649}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.923076923076923, 1.0, 0.0, 0.25, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6973", "mrqa_triviaqa-validation-5294", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-3418", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-341", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-205", "mrqa_triviaqa-validation-102", "mrqa_triviaqa-validation-423", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-1303", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-2655", "mrqa_triviaqa-validation-4458", "mrqa_triviaqa-validation-6828", "mrqa_triviaqa-validation-1402", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-1387", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2965", "mrqa_hotpotqa-validation-4832", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-439"], "SR": 0.515625, "CSR": 0.578125, "retrieved_ids": ["mrqa_squad-train-32561", "mrqa_squad-train-70713", "mrqa_squad-train-6500", "mrqa_squad-train-61844", "mrqa_squad-train-37605", "mrqa_squad-train-78077", "mrqa_squad-train-43147", "mrqa_squad-train-34220", "mrqa_squad-train-13066", "mrqa_squad-train-52177", "mrqa_squad-train-78257", "mrqa_squad-train-50397", "mrqa_squad-train-726", "mrqa_squad-train-48683", "mrqa_squad-train-69860", "mrqa_squad-train-63002", "mrqa_squad-train-26606", "mrqa_squad-train-73035", "mrqa_squad-train-15531", "mrqa_squad-train-79467", "mrqa_squad-train-39481", "mrqa_squad-train-52656", "mrqa_squad-train-29404", "mrqa_squad-train-44120", "mrqa_squad-train-75587", "mrqa_squad-train-9048", "mrqa_squad-train-77682", "mrqa_squad-train-82806", "mrqa_squad-train-49758", "mrqa_squad-train-65261", "mrqa_squad-train-7496", "mrqa_squad-train-67358", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-1987", "mrqa_searchqa-validation-12962", "mrqa_squad-validation-7457", "mrqa_naturalquestions-validation-4667", "mrqa_squad-validation-4000", "mrqa_hotpotqa-validation-996", "mrqa_newsqa-validation-3446", "mrqa_triviaqa-validation-2669", "mrqa_naturalquestions-validation-10128", "mrqa_naturalquestions-validation-6759", "mrqa_squad-validation-7449", "mrqa_squad-validation-3021", "mrqa_searchqa-validation-4032", "mrqa_naturalquestions-validation-2813", "mrqa_newsqa-validation-1700", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-6524", "mrqa_searchqa-validation-9789", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-4054", "mrqa_squad-validation-5818", "mrqa_triviaqa-validation-4966", "mrqa_newsqa-validation-765", "mrqa_squad-validation-3946", "mrqa_naturalquestions-validation-9272", "mrqa_triviaqa-validation-4457", "mrqa_hotpotqa-validation-132", "mrqa_searchqa-validation-5928", "mrqa_newsqa-validation-2086", "mrqa_searchqa-validation-11271", "mrqa_squad-validation-9136"], "EFR": 1.0, "Overall": 0.7561718749999999}, {"timecode": 26, "before_eval_results": {"predictions": ["paid professionals", "Basel", "we want to practice Christian love toward them and pray that they convert", "Informal rule", "anxiety disorders", "a raven", "helium", "John Logie Baird", "london", "Pickwick", "Titanic", "brenda", "taekwondo", "Gibraltar", "Rome", "florida", "the skull", "Len Hutton", "bury", "oxygen", "morris", "japp Stam", "Venus", "wigan Athletic", "florida", "Jupiter", "stanzas", "morris", "john florida", "Urania", "Australia", "meninges", "Charlie Chaplin", "Cambridge", "the Netherlands", "Vladivostok", "simmering", "beetles", "phoenician civilization", "Norwegian", "the Gulf of Suez", "beard", "Lichfield Cathedral", "lithium", "salema", "America", "the gloomy description of a foggy and dark afternoon in Chancery", "tempera", "Rio", "peacock", "Mandarin", "sauvignon", "6ft 1in", "Judith Cynthia Aline Keppel", "94 by 50 feet", "Eli Manning", "photographs, film and television", "March 17, 2015", "AbdulMutallab", "an eye for an eye", "three", "captain florida", "Dennis Miller", "May"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6048177083333334}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.375, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2368", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-2459", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-5478", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-2693", "mrqa_triviaqa-validation-6380", "mrqa_triviaqa-validation-7030", "mrqa_triviaqa-validation-5278", "mrqa_triviaqa-validation-7033", "mrqa_triviaqa-validation-24", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-285", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-2945", "mrqa_triviaqa-validation-3563", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-5476", "mrqa_triviaqa-validation-1605", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-3782", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-6046", "mrqa_searchqa-validation-8872"], "SR": 0.578125, "CSR": 0.578125, "retrieved_ids": ["mrqa_squad-train-58686", "mrqa_squad-train-57664", "mrqa_squad-train-66158", "mrqa_squad-train-78858", "mrqa_squad-train-75002", "mrqa_squad-train-30930", "mrqa_squad-train-56048", "mrqa_squad-train-25886", "mrqa_squad-train-19531", "mrqa_squad-train-23500", "mrqa_squad-train-29522", "mrqa_squad-train-54368", "mrqa_squad-train-71053", "mrqa_squad-train-17565", "mrqa_squad-train-79762", "mrqa_squad-train-24453", "mrqa_squad-train-54151", "mrqa_squad-train-34121", "mrqa_squad-train-51732", "mrqa_squad-train-64527", "mrqa_squad-train-64163", "mrqa_squad-train-5052", "mrqa_squad-train-23047", "mrqa_squad-train-8748", "mrqa_squad-train-66491", "mrqa_squad-train-23980", "mrqa_squad-train-10535", "mrqa_squad-train-40037", "mrqa_squad-train-23813", "mrqa_squad-train-82195", "mrqa_squad-train-22804", "mrqa_squad-train-67521", "mrqa_searchqa-validation-7514", "mrqa_squad-validation-1195", "mrqa_searchqa-validation-14480", "mrqa_newsqa-validation-4017", "mrqa_triviaqa-validation-4886", "mrqa_naturalquestions-validation-9088", "mrqa_hotpotqa-validation-2378", "mrqa_naturalquestions-validation-923", "mrqa_triviaqa-validation-2202", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-1415", "mrqa_squad-validation-6706", "mrqa_naturalquestions-validation-7554", "mrqa_newsqa-validation-1879", "mrqa_squad-validation-6965", "mrqa_naturalquestions-validation-9737", "mrqa_newsqa-validation-1700", "mrqa_naturalquestions-validation-5781", "mrqa_searchqa-validation-9536", "mrqa_searchqa-validation-4768", "mrqa_squad-validation-4629", "mrqa_squad-validation-218", "mrqa_searchqa-validation-2463", "mrqa_naturalquestions-validation-5721", "mrqa_hotpotqa-validation-5644", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-3564", "mrqa_triviaqa-validation-3208", "mrqa_naturalquestions-validation-6500", "mrqa_triviaqa-validation-6392", "mrqa_searchqa-validation-10536"], "EFR": 0.9629629629629629, "Overall": 0.7487644675925925}, {"timecode": 27, "before_eval_results": {"predictions": ["on the sidelines", "15th", "60%", "Xbox One", "three", "it will be the golfer's first public appearance since his November 27 car crash outside his home near Orlando, Florida.", "the National Restaurant Association", "to \"wipe out\" the United States", "blew himself up", "generally from an older generation", "broadband television network", "four Impressionist paintings worth about $163 million", "\"Americans always believe things are better in their own lives than in the rest of the country", "Elena Kagan", "Mandi Hamlin", "750", "fire a missile", "Lana Clarkson", "the front door", "\u4e2d\u570b", "severe", "jobs", "in the Swat Valley", "Rawalpindi", "Santaquin City, Utah", "Sunday", "four", "a residential area in East Java", "Johannesburg", "$2 billion", "three French journalists, a seven-member Spanish flight crew and one Belgian", "2002", "\"It all started when the military arrested one man, and then an hour later he emerged from building barely able to walk from the beating,\"", "\"It has never been the policy of this president or this administration to torture.", "Former Mobile County Circuit Judge Herman Thomas", "in Egypt", "Lee Myung-Bak", "her mother", "\"They can't go out to dinner, can't even go to the convenience store to get a drink", "out of either heavy flannel or wool", "Melbourne", "into the Southeast", "Sunday,", "$273 million", "through a facility in Salt Lake City, Utah", "that veterans returning from Iraq and Afghanistan have a higher unemployment rate than the rest of America", "an animal tranquilizer,", "in Arlington National Cemetery's", "NATO's International Security Assistance Force", "Jaime Andrade", "1994", "dance show", "Santiago Ram\u00f3n y Cajal", "Los Angeles", "a fortified complex at the heart of Moscow", "the Magic Circle", "london", "the Sutherland Brothers", "Lin-Manuel Miranda", "15,024", "novelist and poet", "mantle", "beaker", "marshmallows"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5565193619031934}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7272727272727272, 1.0, 0.0, 0.0, 0.22222222222222224, 0.1739130434782609, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 0.0, 0.8, 0.0, 0.2857142857142857, 1.0, 1.0, 0.6, 0.6666666666666666, 0.0, 0.0, 0.125, 0.7272727272727273, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7272727272727273, 0.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.2, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-589", "mrqa_newsqa-validation-3761", "mrqa_newsqa-validation-2582", "mrqa_newsqa-validation-213", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4032", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-2384", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-593", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-1078", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-1547", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-3559", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-4905", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-4411", "mrqa_hotpotqa-validation-3979", "mrqa_hotpotqa-validation-1864"], "SR": 0.390625, "CSR": 0.5714285714285714, "retrieved_ids": ["mrqa_squad-train-1236", "mrqa_squad-train-62023", "mrqa_squad-train-21842", "mrqa_squad-train-76315", "mrqa_squad-train-46230", "mrqa_squad-train-10926", "mrqa_squad-train-12570", "mrqa_squad-train-27471", "mrqa_squad-train-12285", "mrqa_squad-train-64186", "mrqa_squad-train-36677", "mrqa_squad-train-17031", "mrqa_squad-train-78291", "mrqa_squad-train-71233", "mrqa_squad-train-23821", "mrqa_squad-train-65651", "mrqa_squad-train-16380", "mrqa_squad-train-60638", "mrqa_squad-train-20889", "mrqa_squad-train-41537", "mrqa_squad-train-79083", "mrqa_squad-train-35882", "mrqa_squad-train-58639", "mrqa_squad-train-45", "mrqa_squad-train-12204", "mrqa_squad-train-64597", "mrqa_squad-train-5207", "mrqa_squad-train-22670", "mrqa_squad-train-51855", "mrqa_squad-train-46575", "mrqa_squad-train-2522", "mrqa_squad-train-33792", "mrqa_newsqa-validation-1076", "mrqa_naturalquestions-validation-3686", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-6015", "mrqa_newsqa-validation-469", "mrqa_newsqa-validation-445", "mrqa_searchqa-validation-9730", "mrqa_triviaqa-validation-7056", "mrqa_squad-validation-1566", "mrqa_hotpotqa-validation-2769", "mrqa_searchqa-validation-4393", "mrqa_squad-validation-4181", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-6328", "mrqa_squad-validation-7612", "mrqa_searchqa-validation-7662", "mrqa_hotpotqa-validation-3157", "mrqa_hotpotqa-validation-2205", "mrqa_hotpotqa-validation-4069", "mrqa_triviaqa-validation-4458", "mrqa_naturalquestions-validation-7351", "mrqa_searchqa-validation-3479", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-7464", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-8415", "mrqa_triviaqa-validation-2735", "mrqa_naturalquestions-validation-8239", "mrqa_newsqa-validation-340", "mrqa_squad-validation-1195", "mrqa_squad-validation-3687", "mrqa_naturalquestions-validation-6610"], "EFR": 0.9743589743589743, "Overall": 0.7497043841575091}, {"timecode": 28, "before_eval_results": {"predictions": ["Denver's Executive Vice President of Football Operations and General Manager", "illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "Pittsburgh", "Cress", "molecular clouds in interstellar space", "Stefanie Scott", "the predominantly black city of Detroit and Wayne County and the predominantly White Oakland County and Macomb County suburbs", "Ram Nath Kovind", "Joseph Nye Welch", "100", "members of the gay ( LGBT ) community", "copper ( Cu ), silver ( Ag ), and gold ( Au )", "Wembley Stadium", "195,000", "1776", "Continental drift", "Julie Adams", "genetics and the male hormone dihydrotestosterone", "Jonathan Cheban", "Norman Greenbaum", "De Wayne Warren", "Thirty years after the Galactic Civil War", "restoring someone's faith in love and family relationships", "Obi - Wan Kenobi", "April 15, 2018", "April 17, 1982", "the Speaker of the House of Representatives", "London, United Kingdom", "a legal case in certain legal systems", "the Near East", "the population", "Isle of FERNANDO 'S!", "pre-Columbian times", "central plains", "China ( formerly the Republic of China ), Russia (formerly the Soviet Union ), France, the United Kingdom, and the United States", "costumes", "directly into the bloodstream", "Kenny Anderson", "beneath the liver", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "Nathan Hale", "Jesse Frederick James Conaway", "naos", "defense against rain rather than sun", "port of Nueva Espa\u00f1a to the Spanish coast", "September 19, 2017", "West Egg on prosperous Long Island", "it was first published on November 12, 1976 by Ballantine Books", "Butter Island off North Haven, Maine in the Penobscot Bay", "winter", "Tony Rydinger", "Moira Kelly", "Flanagan", "east of the Mississippi River", "Mediterranean", "Manor of More", "Craig William Macneill", "Democratic Unionist Party (DUP)", "military personnel", "1960", "\"The Orchid Thief\"", "without", "Balfour Declaration", "Edgar Allan Poe"], "metric_results": {"EM": 0.5, "QA-F1": 0.5988664215686275}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.2222222222222222, 0.6666666666666666, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 0.4, 1.0, 0.823529411764706, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-386", "mrqa_squad-validation-6848", "mrqa_naturalquestions-validation-2605", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-243", "mrqa_naturalquestions-validation-104", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-186", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8359", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-1135", "mrqa_triviaqa-validation-7330", "mrqa_triviaqa-validation-1463", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-2150", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1570", "mrqa_searchqa-validation-4495", "mrqa_searchqa-validation-12829"], "SR": 0.5, "CSR": 0.5689655172413793, "retrieved_ids": ["mrqa_squad-train-1209", "mrqa_squad-train-15709", "mrqa_squad-train-43825", "mrqa_squad-train-51004", "mrqa_squad-train-84589", "mrqa_squad-train-79716", "mrqa_squad-train-20844", "mrqa_squad-train-62084", "mrqa_squad-train-39723", "mrqa_squad-train-55062", "mrqa_squad-train-35988", "mrqa_squad-train-77303", "mrqa_squad-train-69044", "mrqa_squad-train-39467", "mrqa_squad-train-84810", "mrqa_squad-train-70528", "mrqa_squad-train-8670", "mrqa_squad-train-38652", "mrqa_squad-train-46903", "mrqa_squad-train-6946", "mrqa_squad-train-42109", "mrqa_squad-train-14274", "mrqa_squad-train-4665", "mrqa_squad-train-57484", "mrqa_squad-train-48442", "mrqa_squad-train-29776", "mrqa_squad-train-54508", "mrqa_squad-train-12489", "mrqa_squad-train-5834", "mrqa_squad-train-22468", "mrqa_squad-train-55489", "mrqa_squad-train-34414", "mrqa_searchqa-validation-11367", "mrqa_hotpotqa-validation-957", "mrqa_searchqa-validation-12864", "mrqa_searchqa-validation-16130", "mrqa_naturalquestions-validation-3922", "mrqa_triviaqa-validation-4715", "mrqa_squad-validation-7612", "mrqa_squad-validation-2835", "mrqa_squad-validation-589", "mrqa_triviaqa-validation-2693", "mrqa_searchqa-validation-4028", "mrqa_newsqa-validation-3594", "mrqa_squad-validation-27", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3359", "mrqa_newsqa-validation-765", "mrqa_hotpotqa-validation-4712", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-4002", "mrqa_hotpotqa-validation-5644", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-9436", "mrqa_triviaqa-validation-102", "mrqa_searchqa-validation-6150", "mrqa_triviaqa-validation-5278", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-11991", "mrqa_newsqa-validation-872", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7967", "mrqa_squad-validation-1235", "mrqa_searchqa-validation-12996"], "EFR": 0.90625, "Overall": 0.7355899784482759}, {"timecode": 29, "before_eval_results": {"predictions": ["Sophocles' play Antigone", "Meuse", "In 1806", "New Delhi", "MacFarlane", "Jacksonville", "Hon July Moyo", "many forested parts of the world", "Narendra Modi", "forests and animals", "Andrew Michael Harrison", "The White House Executive Chef", "Michael Crawford", "Pyeongchang Olympic Stadium", "the red bone marrow of large bones", "Emily Blunt", "Pangaea", "Jonathan Breck", "dermis", "S\u00e9rgio Mendes", "Ming", "201", "Chuck Noland", "Detroit Red Wings", "Britney Spears", "Waylon Jennings", "Nancy Jean Cartwright", "Beyonc\u00e9", "Philadelphia", "New York Yankees", "1996", "red chlorophyll pigments", "United States customary units", "Joe Spano", "Michael Moriarty", "Rock Island, Illinois", "2002", "September 1959", "Neil Patrick Harris", "Bonnie Lipton", "the Whig Party's colorful Log Cabin Campaign", "the probability of rejecting the null hypothesis", "the title `` The Chariot ''", "Elijah, Rebekah, Klaus and Davina", "the kitchen", "Tagalog or English", "Ernest Rutherford", "Napoleon", "the 12th century", "Yosemite National Park", "Norman Pritchard", "2014", "polecat", "the Big Bang", "king florida", "October 13, 1980", "motorsport world championship", "Polihale State Park", "Defense of Marriage Act", "Bronx.", "9 million", "\"Tennessee Waltz\"", "an abacus", "Cyrus"], "metric_results": {"EM": 0.5, "QA-F1": 0.6214820463441786}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, true, true, true], "QA-F1": [0.5, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.11764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.8, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6638", "mrqa_squad-validation-1037", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-588", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-4279", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-4280", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-1462", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-4309", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3760", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-834", "mrqa_triviaqa-validation-5106", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3606"], "SR": 0.5, "CSR": 0.5666666666666667, "retrieved_ids": ["mrqa_squad-train-77464", "mrqa_squad-train-30620", "mrqa_squad-train-1453", "mrqa_squad-train-43771", "mrqa_squad-train-61332", "mrqa_squad-train-56634", "mrqa_squad-train-39261", "mrqa_squad-train-84837", "mrqa_squad-train-24637", "mrqa_squad-train-2228", "mrqa_squad-train-26579", "mrqa_squad-train-74658", "mrqa_squad-train-27468", "mrqa_squad-train-61199", "mrqa_squad-train-54230", "mrqa_squad-train-41231", "mrqa_squad-train-5695", "mrqa_squad-train-40872", "mrqa_squad-train-11989", "mrqa_squad-train-37437", "mrqa_squad-train-4254", "mrqa_squad-train-61475", "mrqa_squad-train-77557", "mrqa_squad-train-50848", "mrqa_squad-train-38893", "mrqa_squad-train-73120", "mrqa_squad-train-40971", "mrqa_squad-train-52908", "mrqa_squad-train-23894", "mrqa_squad-train-663", "mrqa_squad-train-62385", "mrqa_squad-train-71612", "mrqa_searchqa-validation-8665", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-3442", "mrqa_triviaqa-validation-1094", "mrqa_naturalquestions-validation-5986", "mrqa_triviaqa-validation-1802", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-9615", "mrqa_triviaqa-validation-2361", "mrqa_searchqa-validation-3811", "mrqa_squad-validation-1765", "mrqa_naturalquestions-validation-6166", "mrqa_hotpotqa-validation-4832", "mrqa_triviaqa-validation-6746", "mrqa_hotpotqa-validation-2452", "mrqa_triviaqa-validation-7439", "mrqa_naturalquestions-validation-9737", "mrqa_hotpotqa-validation-929", "mrqa_hotpotqa-validation-3162", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-3848", "mrqa_squad-validation-6409", "mrqa_triviaqa-validation-24", "mrqa_naturalquestions-validation-8116", "mrqa_newsqa-validation-216", "mrqa_squad-validation-2368", "mrqa_squad-validation-3497", "mrqa_searchqa-validation-971", "mrqa_triviaqa-validation-2527"], "EFR": 0.96875, "Overall": 0.7476302083333333}, {"timecode": 30, "UKR": 0.80859375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1317", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-16", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1747", "mrqa_hotpotqa-validation-1951", "mrqa_hotpotqa-validation-2058", "mrqa_hotpotqa-validation-2150", "mrqa_hotpotqa-validation-2169", "mrqa_hotpotqa-validation-2198", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-230", "mrqa_hotpotqa-validation-2769", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-3015", "mrqa_hotpotqa-validation-3635", "mrqa_hotpotqa-validation-3662", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-392", "mrqa_hotpotqa-validation-409", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4418", "mrqa_hotpotqa-validation-4451", "mrqa_hotpotqa-validation-4712", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-511", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5742", "mrqa_hotpotqa-validation-99", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-104", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-1309", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-1502", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-243", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2855", "mrqa_naturalquestions-validation-2930", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-3145", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4190", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-4309", "mrqa_naturalquestions-validation-4454", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-4917", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-5087", "mrqa_naturalquestions-validation-5113", "mrqa_naturalquestions-validation-5160", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5477", "mrqa_naturalquestions-validation-5583", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5932", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6276", "mrqa_naturalquestions-validation-6279", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-6349", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-720", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-779", "mrqa_naturalquestions-validation-7889", "mrqa_naturalquestions-validation-7976", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-8052", "mrqa_naturalquestions-validation-8103", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8228", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-837", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9291", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-9691", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-974", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-9876", "mrqa_naturalquestions-validation-9887", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1078", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1200", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-1366", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1456", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-1547", "mrqa_newsqa-validation-1700", "mrqa_newsqa-validation-1738", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-1774", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2404", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-288", "mrqa_newsqa-validation-2900", "mrqa_newsqa-validation-2920", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-3214", "mrqa_newsqa-validation-3218", "mrqa_newsqa-validation-3333", "mrqa_newsqa-validation-343", "mrqa_newsqa-validation-3446", "mrqa_newsqa-validation-3476", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-3721", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-3785", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3978", "mrqa_newsqa-validation-4030", "mrqa_newsqa-validation-4032", "mrqa_newsqa-validation-4054", "mrqa_newsqa-validation-4122", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-469", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-671", "mrqa_newsqa-validation-755", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-859", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-9", "mrqa_searchqa-validation-10098", "mrqa_searchqa-validation-10536", "mrqa_searchqa-validation-10856", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-11836", "mrqa_searchqa-validation-11886", "mrqa_searchqa-validation-13251", "mrqa_searchqa-validation-13520", "mrqa_searchqa-validation-1357", "mrqa_searchqa-validation-13710", "mrqa_searchqa-validation-13874", "mrqa_searchqa-validation-13883", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-15740", "mrqa_searchqa-validation-15995", "mrqa_searchqa-validation-16076", "mrqa_searchqa-validation-1649", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-172", "mrqa_searchqa-validation-1770", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-2242", "mrqa_searchqa-validation-2303", "mrqa_searchqa-validation-2323", "mrqa_searchqa-validation-2463", "mrqa_searchqa-validation-2714", "mrqa_searchqa-validation-2743", "mrqa_searchqa-validation-2835", "mrqa_searchqa-validation-2866", "mrqa_searchqa-validation-3514", "mrqa_searchqa-validation-3597", "mrqa_searchqa-validation-3633", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-3926", "mrqa_searchqa-validation-393", "mrqa_searchqa-validation-4032", "mrqa_searchqa-validation-4258", "mrqa_searchqa-validation-4393", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-515", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-5928", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-6170", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-686", "mrqa_searchqa-validation-6876", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-7527", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-7774", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-7998", "mrqa_searchqa-validation-8693", "mrqa_searchqa-validation-8872", "mrqa_searchqa-validation-9185", "mrqa_searchqa-validation-9269", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-971", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-9853", "mrqa_squad-validation-10135", "mrqa_squad-validation-10136", "mrqa_squad-validation-10181", "mrqa_squad-validation-10268", "mrqa_squad-validation-10326", "mrqa_squad-validation-10339", "mrqa_squad-validation-10388", "mrqa_squad-validation-10477", "mrqa_squad-validation-1095", "mrqa_squad-validation-1125", "mrqa_squad-validation-1177", "mrqa_squad-validation-1195", "mrqa_squad-validation-1408", "mrqa_squad-validation-1453", "mrqa_squad-validation-1499", "mrqa_squad-validation-1533", "mrqa_squad-validation-1566", "mrqa_squad-validation-1672", "mrqa_squad-validation-1765", "mrqa_squad-validation-1791", "mrqa_squad-validation-1848", "mrqa_squad-validation-1890", "mrqa_squad-validation-1892", "mrqa_squad-validation-195", "mrqa_squad-validation-2019", "mrqa_squad-validation-2033", "mrqa_squad-validation-2041", "mrqa_squad-validation-2243", "mrqa_squad-validation-2411", "mrqa_squad-validation-2456", "mrqa_squad-validation-247", "mrqa_squad-validation-2545", "mrqa_squad-validation-2683", "mrqa_squad-validation-27", "mrqa_squad-validation-2742", "mrqa_squad-validation-305", "mrqa_squad-validation-3130", "mrqa_squad-validation-3144", "mrqa_squad-validation-3184", "mrqa_squad-validation-3241", "mrqa_squad-validation-327", "mrqa_squad-validation-3335", "mrqa_squad-validation-335", "mrqa_squad-validation-3364", "mrqa_squad-validation-3406", "mrqa_squad-validation-3435", "mrqa_squad-validation-3501", "mrqa_squad-validation-3507", "mrqa_squad-validation-358", "mrqa_squad-validation-3605", "mrqa_squad-validation-3626", "mrqa_squad-validation-3718", "mrqa_squad-validation-3770", "mrqa_squad-validation-3796", "mrqa_squad-validation-381", "mrqa_squad-validation-386", "mrqa_squad-validation-3863", "mrqa_squad-validation-3919", "mrqa_squad-validation-3946", "mrqa_squad-validation-3986", "mrqa_squad-validation-4000", "mrqa_squad-validation-402", "mrqa_squad-validation-4046", "mrqa_squad-validation-4054", "mrqa_squad-validation-4175", "mrqa_squad-validation-4213", "mrqa_squad-validation-4265", "mrqa_squad-validation-4302", "mrqa_squad-validation-4312", "mrqa_squad-validation-4326", "mrqa_squad-validation-4446", "mrqa_squad-validation-4452", "mrqa_squad-validation-4468", "mrqa_squad-validation-4538", "mrqa_squad-validation-4546", "mrqa_squad-validation-4572", "mrqa_squad-validation-4629", "mrqa_squad-validation-4883", "mrqa_squad-validation-4986", "mrqa_squad-validation-5004", "mrqa_squad-validation-5097", "mrqa_squad-validation-5320", "mrqa_squad-validation-5396", "mrqa_squad-validation-5435", "mrqa_squad-validation-5448", "mrqa_squad-validation-5588", "mrqa_squad-validation-5692", "mrqa_squad-validation-5724", "mrqa_squad-validation-5781", "mrqa_squad-validation-5818", "mrqa_squad-validation-5860", "mrqa_squad-validation-5887", "mrqa_squad-validation-6019", "mrqa_squad-validation-6030", "mrqa_squad-validation-6069", "mrqa_squad-validation-6171", "mrqa_squad-validation-6206", "mrqa_squad-validation-6228", "mrqa_squad-validation-6240", "mrqa_squad-validation-6243", "mrqa_squad-validation-6279", "mrqa_squad-validation-6353", "mrqa_squad-validation-6439", "mrqa_squad-validation-6490", "mrqa_squad-validation-6517", "mrqa_squad-validation-6535", "mrqa_squad-validation-6543", "mrqa_squad-validation-6543", "mrqa_squad-validation-6611", "mrqa_squad-validation-6694", "mrqa_squad-validation-6729", "mrqa_squad-validation-6790", "mrqa_squad-validation-6838", "mrqa_squad-validation-6965", "mrqa_squad-validation-6973", "mrqa_squad-validation-6999", "mrqa_squad-validation-7039", "mrqa_squad-validation-71", "mrqa_squad-validation-7192", "mrqa_squad-validation-7368", "mrqa_squad-validation-7426", "mrqa_squad-validation-7521", "mrqa_squad-validation-7612", "mrqa_squad-validation-7674", "mrqa_squad-validation-7693", "mrqa_squad-validation-7814", "mrqa_squad-validation-7872", "mrqa_squad-validation-7876", "mrqa_squad-validation-7943", "mrqa_squad-validation-7952", "mrqa_squad-validation-7954", "mrqa_squad-validation-7984", "mrqa_squad-validation-7993", "mrqa_squad-validation-8043", "mrqa_squad-validation-8229", "mrqa_squad-validation-829", "mrqa_squad-validation-8415", "mrqa_squad-validation-8417", "mrqa_squad-validation-8500", "mrqa_squad-validation-852", "mrqa_squad-validation-8561", "mrqa_squad-validation-8585", "mrqa_squad-validation-8594", "mrqa_squad-validation-8754", "mrqa_squad-validation-8769", "mrqa_squad-validation-8969", "mrqa_squad-validation-8985", "mrqa_squad-validation-9102", "mrqa_squad-validation-9166", "mrqa_squad-validation-9170", "mrqa_squad-validation-9176", "mrqa_squad-validation-9196", "mrqa_squad-validation-942", "mrqa_squad-validation-9445", "mrqa_squad-validation-957", "mrqa_squad-validation-9614", "mrqa_squad-validation-9764", "mrqa_squad-validation-985", "mrqa_squad-validation-9866", "mrqa_squad-validation-9876", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1156", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-1303", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-1378", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-177", "mrqa_triviaqa-validation-1785", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1802", "mrqa_triviaqa-validation-2361", "mrqa_triviaqa-validation-254", "mrqa_triviaqa-validation-2623", "mrqa_triviaqa-validation-2693", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3747", "mrqa_triviaqa-validation-3782", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-4328", "mrqa_triviaqa-validation-4465", "mrqa_triviaqa-validation-4496", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-483", "mrqa_triviaqa-validation-4843", "mrqa_triviaqa-validation-4886", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-5044", "mrqa_triviaqa-validation-5106", "mrqa_triviaqa-validation-5141", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-5387", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-578", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-6046", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6257", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6665", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-6828", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-7033", "mrqa_triviaqa-validation-7220", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7374", "mrqa_triviaqa-validation-7461"], "OKR": 0.91015625, "KG": 0.48046875, "before_eval_results": {"predictions": ["space suit materials", "1992", "four", "Genesis", "real estate investment trusts", "Louisiana's Bayou", "the carat", "Mission: Impossible.", "dikonos", "Edinburgh", "Paul Gauguin", "the Bahia de Darwinthe cruise-ship/cradle of all mankind", "Bill Murray", "Battle of Chancellorsville", "Kinetoscope", "Wii", "Suez Canal", "Dave Matthews Band", "nightingale", "less than other", "\"Friday the 13th'", "Kinko's", "a platypus", "a photon", "a long tongue", "Cherokee Nation", "nekropolis", "Eleanor Roosevelt", "oyster", "fortune", "Johnny Cash", "bamboos", "Isaac Newton", "the Unabomber", "Narnia", "Freud", "Burma Ruby stone", "librettos", "john Swift", "Who's Afraid of Virginia Woolf", "medium's Allison Dubois", "beefalo", "high school", "Botswana's", "Susan B. Anthony dollar", "Mattel", "Little Red Riding Hood", "Splint", "milky", "Serbian", "spinal cord", "jelly doughnuts", "infection, irritation, or allergies", "Castleford", "annually ( usually in May ) at the Palais des Festivals et des Congr\u00e8s", "henry", "Sahara", "henry", "You're Next", "Headless Body in Topless Bar", "political correctness", "Hanin Zoabi,", "Princess Diana", "homicide"], "metric_results": {"EM": 0.515625, "QA-F1": 0.609672619047619}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.42857142857142855, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3969", "mrqa_searchqa-validation-2971", "mrqa_searchqa-validation-5180", "mrqa_searchqa-validation-4724", "mrqa_searchqa-validation-5038", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3542", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-4836", "mrqa_searchqa-validation-9196", "mrqa_searchqa-validation-838", "mrqa_searchqa-validation-7004", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-2773", "mrqa_searchqa-validation-8582", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-3203", "mrqa_searchqa-validation-11006", "mrqa_searchqa-validation-16659", "mrqa_searchqa-validation-16839", "mrqa_searchqa-validation-2495", "mrqa_searchqa-validation-5586", "mrqa_searchqa-validation-13247", "mrqa_searchqa-validation-4851", "mrqa_searchqa-validation-382", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2855", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2519", "mrqa_triviaqa-validation-6237"], "SR": 0.515625, "CSR": 0.5650201612903225, "retrieved_ids": ["mrqa_squad-train-63893", "mrqa_squad-train-13344", "mrqa_squad-train-75445", "mrqa_squad-train-58417", "mrqa_squad-train-42585", "mrqa_squad-train-23", "mrqa_squad-train-73884", "mrqa_squad-train-17576", "mrqa_squad-train-40893", "mrqa_squad-train-12825", "mrqa_squad-train-55348", "mrqa_squad-train-73394", "mrqa_squad-train-66080", "mrqa_squad-train-21778", "mrqa_squad-train-46447", "mrqa_squad-train-37494", "mrqa_squad-train-67065", "mrqa_squad-train-22308", "mrqa_squad-train-43420", "mrqa_squad-train-63973", "mrqa_squad-train-9136", "mrqa_squad-train-2100", "mrqa_squad-train-75280", "mrqa_squad-train-32672", "mrqa_squad-train-39497", "mrqa_squad-train-39651", "mrqa_squad-train-38047", "mrqa_squad-train-7878", "mrqa_squad-train-51388", "mrqa_squad-train-80913", "mrqa_squad-train-45015", "mrqa_squad-train-4914", "mrqa_newsqa-validation-3446", "mrqa_naturalquestions-validation-7967", "mrqa_squad-validation-4181", "mrqa_hotpotqa-validation-16", "mrqa_newsqa-validation-2735", "mrqa_searchqa-validation-12363", "mrqa_newsqa-validation-1700", "mrqa_searchqa-validation-11406", "mrqa_triviaqa-validation-4073", "mrqa_searchqa-validation-6234", "mrqa_naturalquestions-validation-1705", "mrqa_squad-validation-8819", "mrqa_squad-validation-8471", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-2491", "mrqa_squad-validation-8904", "mrqa_searchqa-validation-13332", "mrqa_newsqa-validation-2591", "mrqa_hotpotqa-validation-3428", "mrqa_searchqa-validation-7517", "mrqa_searchqa-validation-4394", "mrqa_searchqa-validation-16453", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-250", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4411", "mrqa_newsqa-validation-3035", "mrqa_naturalquestions-validation-9887", "mrqa_newsqa-validation-1412", "mrqa_hotpotqa-validation-2769", "mrqa_naturalquestions-validation-5348"], "EFR": 1.0, "Overall": 0.7528477822580645}, {"timecode": 31, "before_eval_results": {"predictions": ["West", "Khasar", "2007", "Sheev Palpatine, ( colloquial : Darth Sidious and The Emperor )", "the University of Oxford", "July 1, 1923", "a pH indicator, a color marker", "winter", "South Africa", "mainly part of Assam and Meghalaya", "either in front or on top of the brainstem", "Janie Crawford", "Jim Capaldi, Paul Carrack, and Peter Vale", "from a point A to a point B", "786", "Department of Health and Human Services", "The primary and secondary recipients can not see the tertiary recipients", "round, bottom round, and top round", "1957", "Martin Lawrence", "An error does not count as a hit", "Andreas Vesalius", "Moscazzano", "Kristy Swanson", "bacteria", "Asuka", "Jay Baruchel", "Oceania", "a revolution or orbital revolution", "Houston Astros", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "The optic nerve carries the ganglion cell axons to the brain", "in the fascia surrounding skeletal muscle", "Pangaea", "2017", "near the inner rim of the Orion Arm, within the Local Fluff of the Local bubble, and in the Gould Belt", "Ricky Nelson", "they mark it off with a special marker called a `` dabber '' or `` dauber ''", "Debbie Gibson", "Death Eaters", "the Mishnah ( Hebrew : \u05de\u05e9\u05e0\u05d4, c. 200 CE )", "a column - like or oval ( egg - shaped ) symbol of Shiva", "the first week of April", "Algeria", "the King James Bible", "Harlem River", "1998", "R.E.M.", "332", "above the light source and under the sample in an upright microscope, and above the stage and below the light sources in an inverted microscope", "Georgia Bulldogs football team", "Illinois", "Northumberland", "Northern Ireland", "Travis and Williamson counties", "Boston, Massachusetts", "Adam Dawes", "Republicans", "\"Zed,\" a Columbian mammoth whose nearly intact skeleton is part of what is being described as a key find by paleontologists at Los Angeles' George C. Page Museum.", "in a tenement in the Mumbai suburb of Chembur,", "a dummy", "Aristotle", "a risk"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6816230456840715}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.11764705882352941, 0.5, 0.6666666666666666, 1.0, 1.0, 0.21739130434782608, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.05128205128205128, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6956521739130436, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.15384615384615383, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9473684210526315, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 0.20689655172413793, 0.923076923076923, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6169", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-8036", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-809", "mrqa_naturalquestions-validation-8896", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-4073", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-4593", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-5599", "mrqa_triviaqa-validation-3940", "mrqa_hotpotqa-validation-2777", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-3518", "mrqa_searchqa-validation-6752"], "SR": 0.546875, "CSR": 0.564453125, "retrieved_ids": ["mrqa_squad-train-23604", "mrqa_squad-train-27592", "mrqa_squad-train-72664", "mrqa_squad-train-32123", "mrqa_squad-train-31373", "mrqa_squad-train-9339", "mrqa_squad-train-15596", "mrqa_squad-train-38203", "mrqa_squad-train-42162", "mrqa_squad-train-7071", "mrqa_squad-train-57479", "mrqa_squad-train-17352", "mrqa_squad-train-32606", "mrqa_squad-train-78629", "mrqa_squad-train-46782", "mrqa_squad-train-33870", "mrqa_squad-train-36364", "mrqa_squad-train-69994", "mrqa_squad-train-2044", "mrqa_squad-train-51047", "mrqa_squad-train-63457", "mrqa_squad-train-40614", "mrqa_squad-train-60135", "mrqa_squad-train-20200", "mrqa_squad-train-17764", "mrqa_squad-train-29756", "mrqa_squad-train-951", "mrqa_squad-train-81319", "mrqa_squad-train-41187", "mrqa_squad-train-62000", "mrqa_squad-train-2620", "mrqa_squad-train-18395", "mrqa_hotpotqa-validation-2582", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-3418", "mrqa_newsqa-validation-3227", "mrqa_naturalquestions-validation-7967", "mrqa_triviaqa-validation-2655", "mrqa_squad-validation-3812", "mrqa_searchqa-validation-14569", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4100", "mrqa_searchqa-validation-3613", "mrqa_searchqa-validation-2052", "mrqa_hotpotqa-validation-2769", "mrqa_searchqa-validation-1507", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-8665", "mrqa_triviaqa-validation-4457", "mrqa_newsqa-validation-216", "mrqa_triviaqa-validation-1683", "mrqa_squad-validation-10143", "mrqa_triviaqa-validation-77", "mrqa_naturalquestions-validation-6106", "mrqa_squad-validation-9615", "mrqa_squad-validation-8471", "mrqa_newsqa-validation-3615", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-5418", "mrqa_hotpotqa-validation-3979", "mrqa_squad-validation-4572", "mrqa_squad-validation-5588", "mrqa_naturalquestions-validation-8765", "mrqa_squad-validation-1906"], "EFR": 0.8275862068965517, "Overall": 0.7182516163793103}, {"timecode": 32, "before_eval_results": {"predictions": ["magnitude and direction", "2003", "1982", "National Aviation Hall of Fame", "Giotto", "1985", "more than 26,000", "Lakshmibai", "Championship", "French", "2009", "a series of individual adventures", "Bonobo", "singer", "Greg Gorman and Helmut Newton", "Shameless", "stolperstein", "1901", "Carl Zeiss AG", "Premier League club Arsenal", "Bambi, a Life in the Woods", "Robert \"Bobby\" Germaine", "2004", "DTM", "one season", "\"Twice in a Lifetime\"", "the Sun", "Polson", "Kolkata", "The Walking Dead", "Ted Nugent", "jewelry designer", "Gust Avrakotos", "Maleficent", "Coll\u00e8ge de France", "Hard Rock Stadium", "Martin Ingerman", "1945", "Edward R. Murrow", "Conservatorio Verdi", "Mindy Kaling", "June 10, 1982", "beer and soft drinks", "Liga MX", "Donald Duck", "The School Boys", "Lord Chancellor of England", "Taoiseach", "The English Electric Canberra", "Richa Sharma", "48,982", "The Sound of Music", "53", "Stanford Cardinal", "Frank Langella", "an elephant", "an apple core", "carbonic acid", "the British capital's other two airports, Stansted and Gatwick,", "homicide", "maintain an \"aesthetic environment\" and ensure public safety", "Marshal Petain", "tank", "Hannah Montana"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7487580128205128}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1664", "mrqa_hotpotqa-validation-4950", "mrqa_hotpotqa-validation-5305", "mrqa_hotpotqa-validation-2781", "mrqa_hotpotqa-validation-3059", "mrqa_hotpotqa-validation-2792", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-5594", "mrqa_hotpotqa-validation-5296", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-1030", "mrqa_hotpotqa-validation-4655", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-6532", "mrqa_triviaqa-validation-1534", "mrqa_newsqa-validation-1483", "mrqa_newsqa-validation-3726"], "SR": 0.703125, "CSR": 0.568655303030303, "retrieved_ids": ["mrqa_squad-train-4337", "mrqa_squad-train-78715", "mrqa_squad-train-49315", "mrqa_squad-train-65457", "mrqa_squad-train-68319", "mrqa_squad-train-25917", "mrqa_squad-train-12517", "mrqa_squad-train-7007", "mrqa_squad-train-51741", "mrqa_squad-train-46762", "mrqa_squad-train-69646", "mrqa_squad-train-18973", "mrqa_squad-train-72201", "mrqa_squad-train-65155", "mrqa_squad-train-39641", "mrqa_squad-train-56119", "mrqa_squad-train-80058", "mrqa_squad-train-55728", "mrqa_squad-train-31622", "mrqa_squad-train-68205", "mrqa_squad-train-37630", "mrqa_squad-train-49760", "mrqa_squad-train-39684", "mrqa_squad-train-62353", "mrqa_squad-train-2476", "mrqa_squad-train-55613", "mrqa_squad-train-27748", "mrqa_squad-train-38203", "mrqa_squad-train-81091", "mrqa_squad-train-50897", "mrqa_squad-train-38287", "mrqa_squad-train-58514", "mrqa_squad-validation-259", "mrqa_searchqa-validation-3633", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-7694", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-4367", "mrqa_triviaqa-validation-4843", "mrqa_triviaqa-validation-423", "mrqa_triviaqa-validation-2459", "mrqa_searchqa-validation-9183", "mrqa_squad-validation-3969", "mrqa_squad-validation-10369", "mrqa_newsqa-validation-3437", "mrqa_naturalquestions-validation-10684", "mrqa_searchqa-validation-5038", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-11532", "mrqa_naturalquestions-validation-3598", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-4170", "mrqa_naturalquestions-validation-7301", "mrqa_hotpotqa-validation-1437", "mrqa_squad-validation-5887", "mrqa_naturalquestions-validation-8896", "mrqa_naturalquestions-validation-4924", "mrqa_searchqa-validation-4179", "mrqa_naturalquestions-validation-3112", "mrqa_squad-validation-3998", "mrqa_searchqa-validation-12864", "mrqa_triviaqa-validation-243", "mrqa_naturalquestions-validation-7127"], "EFR": 1.0, "Overall": 0.7535748106060606}, {"timecode": 33, "before_eval_results": {"predictions": ["CEPR", "special university classes, called Lehramtstudien (Teaching Education Studies)", "CTV", "13\u20133", "American", "July 25 to August 4", "1958", "Norway", "twenty-three", "Crips", "The Crowned Prince of the Philadelphia Mob", "Kentucky Derby", "Charles Edward Stuart", "historic buildings, arts, and published works", "August 9, 2017", "Movie Masters", "eastern Tennessee, United States", "G\u00e9rard Depardieu, Daniel Auteuil,", "books, films and other media", "King Duncan", "Europop", "13 March 1918", "Ed Lee", "Ghana", "Norwegian", "Dutch", "1976", "January 23, 1898", "Motorised quadricycle", "Nazareth", "Charlyn Marie \" Chan\" Marshall", "1968", "76,416", "Father Dougal McGuire", "June 17, 2007", "Karl Haushofer", "The United States of America (USA)", "the indigenous peoples of the Ryukyu Islands between the islands of Kyushu and Taiwan", "coaxial", "November 15, 1903", "international producers", "1961", "1951", "Indian", "one child, Lisa Brennan-Jobs.", "Pablo Escobar", "ZZ Top", "Steve and Rudy", "Russian", "Hydrogen vehicle", "Blue Ridge Parkway", "\"King of Cool\"", "subduction zone", "Barry Bonds", "Owen Vaccaro", "Machu Picchu", "Exile", "a downtown diner late at night.", "normal maritime traffic", "Ma Khin Khin Leh,", "$1.45 billion", "onomatopoeia", "Singapore", "the femur"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6958491161616162}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2043", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-3290", "mrqa_hotpotqa-validation-4515", "mrqa_hotpotqa-validation-2395", "mrqa_hotpotqa-validation-3063", "mrqa_hotpotqa-validation-3431", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-4322", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2567", "mrqa_hotpotqa-validation-722", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3136", "mrqa_hotpotqa-validation-4274", "mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1070", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-3703", "mrqa_triviaqa-validation-4306", "mrqa_newsqa-validation-1673", "mrqa_searchqa-validation-15477"], "SR": 0.59375, "CSR": 0.5693933823529411, "retrieved_ids": ["mrqa_squad-train-81446", "mrqa_squad-train-42050", "mrqa_squad-train-29888", "mrqa_squad-train-20637", "mrqa_squad-train-67583", "mrqa_squad-train-40029", "mrqa_squad-train-21049", "mrqa_squad-train-57261", "mrqa_squad-train-79539", "mrqa_squad-train-80362", "mrqa_squad-train-16639", "mrqa_squad-train-84232", "mrqa_squad-train-54677", "mrqa_squad-train-24881", "mrqa_squad-train-59129", "mrqa_squad-train-46791", "mrqa_squad-train-65993", "mrqa_squad-train-4766", "mrqa_squad-train-85347", "mrqa_squad-train-70934", "mrqa_squad-train-25269", "mrqa_squad-train-1138", "mrqa_squad-train-76420", "mrqa_squad-train-76033", "mrqa_squad-train-48889", "mrqa_squad-train-62285", "mrqa_squad-train-11603", "mrqa_squad-train-44124", "mrqa_squad-train-83351", "mrqa_squad-train-6550", "mrqa_squad-train-51082", "mrqa_squad-train-19376", "mrqa_searchqa-validation-7106", "mrqa_squad-validation-5860", "mrqa_squad-validation-7422", "mrqa_hotpotqa-validation-1951", "mrqa_squad-validation-7708", "mrqa_naturalquestions-validation-4924", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-4100", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-291", "mrqa_newsqa-validation-4059", "mrqa_triviaqa-validation-5855", "mrqa_searchqa-validation-11227", "mrqa_triviaqa-validation-3864", "mrqa_naturalquestions-validation-3558", "mrqa_squad-validation-1566", "mrqa_naturalquestions-validation-7301", "mrqa_triviaqa-validation-24", "mrqa_searchqa-validation-7662", "mrqa_newsqa-validation-4027", "mrqa_squad-validation-9484", "mrqa_hotpotqa-validation-5594", "mrqa_naturalquestions-validation-3672", "mrqa_searchqa-validation-2141", "mrqa_naturalquestions-validation-2965", "mrqa_newsqa-validation-2541", "mrqa_searchqa-validation-1156", "mrqa_newsqa-validation-2074", "mrqa_hotpotqa-validation-5448", "mrqa_squad-validation-9136", "mrqa_searchqa-validation-686", "mrqa_newsqa-validation-1175"], "EFR": 1.0, "Overall": 0.7537224264705882}, {"timecode": 34, "before_eval_results": {"predictions": ["Peyton Manning", "The static friction increases or decreases in response to the applied force", "25 million", "A simple iron boar crest", "Vienna", "that Fama and K. G. French's research is period dependent", "the Harpe brothers", "Bill Clinton", "Dirk Werner Nowitzki", "Detroit, Michigan", "Bury St Edmunds, Suffolk, England", "novelty songs, comedy, and strange or unusual recordings", "Mahoning County", "16 November 1973", "Hillary Rodham's advisor", "Hungary", "New York", "The Washington Post", "400 MW", "Mauritian", "Household Words", "Gatwick Airport", "Kagoshima Airport", "Minette Walters", "CTV", "Firestorm", "2013", "Les Miles", "40 Days and 40 Nights", "James Tinling", "2014", "Louis King", "gull-wing doors", "Terry Malloy", "Operation Neptune", "Attack the Block", "House of Commons", "Hessian", "Battle of Chester", "Wayne County, Michigan", "Western Samoa", "mistress of the Robes", "Duchess Eleanor of Aquitaine", "Barack Obama", "August 17, 2017", "Guardians of the Galaxy Vol.  2", "Director of Central Intelligence", "1963", "Bologna Process", "Pittsburgh", "Nebraska Cornhuskers", "Salman Rushdie", "the Internal Revenue Service", "the Hongwu Emperor of the Ming Dynasty", "commemorating fealty and filial piety", "Chihuahua", "Arkansas", "throtu", "1979", "his father", "$8.8 million", "Red Heat", "Miriam Makeba", "a tooth's quadrant"], "metric_results": {"EM": 0.625, "QA-F1": 0.6916666666666667}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-384", "mrqa_squad-validation-10316", "mrqa_hotpotqa-validation-741", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-4177", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-1182", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-503", "mrqa_hotpotqa-validation-1681", "mrqa_hotpotqa-validation-176", "mrqa_hotpotqa-validation-5228", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-3773", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-4143", "mrqa_triviaqa-validation-2316", "mrqa_newsqa-validation-501", "mrqa_searchqa-validation-9394"], "SR": 0.625, "CSR": 0.5709821428571429, "retrieved_ids": ["mrqa_squad-train-14054", "mrqa_squad-train-80511", "mrqa_squad-train-59089", "mrqa_squad-train-20904", "mrqa_squad-train-66169", "mrqa_squad-train-58345", "mrqa_squad-train-41960", "mrqa_squad-train-75945", "mrqa_squad-train-12342", "mrqa_squad-train-2490", "mrqa_squad-train-83326", "mrqa_squad-train-83369", "mrqa_squad-train-72768", "mrqa_squad-train-7914", "mrqa_squad-train-5454", "mrqa_squad-train-42029", "mrqa_squad-train-34377", "mrqa_squad-train-85305", "mrqa_squad-train-14463", "mrqa_squad-train-76153", "mrqa_squad-train-60712", "mrqa_squad-train-77200", "mrqa_squad-train-15722", "mrqa_squad-train-51538", "mrqa_squad-train-76042", "mrqa_squad-train-20632", "mrqa_squad-train-21580", "mrqa_squad-train-37068", "mrqa_squad-train-54634", "mrqa_squad-train-29226", "mrqa_squad-train-67085", "mrqa_squad-train-5214", "mrqa_newsqa-validation-1879", "mrqa_squad-validation-9173", "mrqa_newsqa-validation-1570", "mrqa_triviaqa-validation-1387", "mrqa_searchqa-validation-4724", "mrqa_squad-validation-10143", "mrqa_searchqa-validation-11886", "mrqa_searchqa-validation-14371", "mrqa_naturalquestions-validation-10460", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5403", "mrqa_squad-validation-8786", "mrqa_naturalquestions-validation-2832", "mrqa_squad-validation-606", "mrqa_searchqa-validation-14194", "mrqa_naturalquestions-validation-3319", "mrqa_hotpotqa-validation-3944", "mrqa_newsqa-validation-2606", "mrqa_triviaqa-validation-2361", "mrqa_hotpotqa-validation-5035", "mrqa_newsqa-validation-3446", "mrqa_squad-validation-9863", "mrqa_newsqa-validation-439", "mrqa_searchqa-validation-13151", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-3437", "mrqa_triviaqa-validation-4798", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-7351", "mrqa_hotpotqa-validation-5627", "mrqa_naturalquestions-validation-10684", "mrqa_searchqa-validation-1279"], "EFR": 1.0, "Overall": 0.7540401785714286}, {"timecode": 35, "before_eval_results": {"predictions": ["DuMont Television Network", "Mount Kenya", "Albany", "1908", "1958", "1986 to 2013", "Ronald Wilson Reagan", "Chiltern Hills", "Ted 2", "Bay of Fundy", "CD Castell\u00f3n", "2001", "Sean Yseult", "country music", "The Hawai\u02bbi State Senate is the upper chamber of the Hawaii State Legislature", "Operation Watchtower", "Paul W. S. Anderson", "15 February 1970", "Talib Kweli", "Shooter Jennings", "downtown", "\"Bad Moon Rising\"", "Kristoffer Kristofferson", "382.6 days", "Atomic Kitten", "Trey Parker and Matt Stone", "Matt Gonzalez", "The Gold Coast", "1979", "\u00c6thelred the Unready", "PlayStation 4", "Republic of Malta", "1966", "Key West", "Europe", "Black Mountain College", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "Fabio Cannavaro", "Comedy Central", "Prince George's County", "EQT Plaza in Pittsburgh, Pennsylvania.", "1891", "L\u00edneas A\u00e9reas", "Gainsborough Trinity F.C.", "Los Angeles", "October 13, 1980", "a water sprite", "India", "Syracuse University", "FIFA Women's World Cup", "Orange County", "76,416", "various submucosal membrane sites", "mathematical modeling and statistical estimation", "Brian Steele", "Deep Blue", "albert reynolds", "George Washington", "U.S. senators", "California-based Current TV", "two", "baht", "The Lost Boys", "succotash"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6907497594997596}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.5, 0.8571428571428571, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.45454545454545453, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.26666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2923", "mrqa_hotpotqa-validation-1302", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-5588", "mrqa_hotpotqa-validation-3018", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-3216", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-347", "mrqa_hotpotqa-validation-3928", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-1041", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-2848", "mrqa_hotpotqa-validation-5114", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-257", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6592", "mrqa_triviaqa-validation-1348", "mrqa_newsqa-validation-2595"], "SR": 0.5625, "CSR": 0.5707465277777778, "retrieved_ids": ["mrqa_squad-train-45752", "mrqa_squad-train-42449", "mrqa_squad-train-31632", "mrqa_squad-train-48100", "mrqa_squad-train-58731", "mrqa_squad-train-3992", "mrqa_squad-train-24536", "mrqa_squad-train-3105", "mrqa_squad-train-27008", "mrqa_squad-train-22364", "mrqa_squad-train-70602", "mrqa_squad-train-13165", "mrqa_squad-train-42419", "mrqa_squad-train-13916", "mrqa_squad-train-22884", "mrqa_squad-train-58222", "mrqa_squad-train-43901", "mrqa_squad-train-42376", "mrqa_squad-train-47169", "mrqa_squad-train-6778", "mrqa_squad-train-52861", "mrqa_squad-train-23447", "mrqa_squad-train-80195", "mrqa_squad-train-66565", "mrqa_squad-train-11240", "mrqa_squad-train-71388", "mrqa_squad-train-71593", "mrqa_squad-train-68738", "mrqa_squad-train-62633", "mrqa_squad-train-15589", "mrqa_squad-train-24614", "mrqa_squad-train-66391", "mrqa_searchqa-validation-13600", "mrqa_triviaqa-validation-7401", "mrqa_searchqa-validation-7269", "mrqa_searchqa-validation-13554", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2124", "mrqa_newsqa-validation-831", "mrqa_triviaqa-validation-4306", "mrqa_naturalquestions-validation-7484", "mrqa_searchqa-validation-6181", "mrqa_squad-validation-739", "mrqa_hotpotqa-validation-3162", "mrqa_searchqa-validation-3203", "mrqa_newsqa-validation-3446", "mrqa_naturalquestions-validation-3288", "mrqa_triviaqa-validation-2486", "mrqa_hotpotqa-validation-234", "mrqa_searchqa-validation-4169", "mrqa_naturalquestions-validation-6555", "mrqa_triviaqa-validation-1802", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-4458", "mrqa_searchqa-validation-2773", "mrqa_searchqa-validation-4701", "mrqa_naturalquestions-validation-9330", "mrqa_triviaqa-validation-2459", "mrqa_triviaqa-validation-5294", "mrqa_naturalquestions-validation-7062", "mrqa_searchqa-validation-9536", "mrqa_hotpotqa-validation-3773", "mrqa_naturalquestions-validation-5912", "mrqa_searchqa-validation-16378"], "EFR": 0.9642857142857143, "Overall": 0.7468501984126984}, {"timecode": 36, "before_eval_results": {"predictions": ["between June and September", "emergency plans", "music video", "a bank", "in July", "Casalesi Camorra clan", "Tulsa,", "41,280", "Old Trafford", "\"release\" civilians", "Number Ones", "Zac Efron", "the Indian embassy", "director of the Division of Adult Institutions", "37", "Annie Duke", "for an arms embargo on Israel", "that the legislation will foster racial profiling,", "producing rock music with a country influence", "Kirchners", "a place for another non-European Union player", "root out terrorists within its borders.", "separatist campaign", "at the ancient Greek site of Olympia", "3,000", "closing these racial gaps", "Behar", "22", "3-0", "150", "helicopters and boats", "U.N. agencies", "30", "the man was dead", "one", "23 million square meters", "south of Kabul in the eastern Afghan province of Logar", "Virgin America", "fuel economy and safety while boosting", "the American Civil Liberties Union", "summer", "that 75 percent of utilities had taken steps to mitigate the Aurora vulnerability,", "Jason", "mental health and recovery", "56", "The people kill him with the blocks,", "Frank Ricci", "the Ku Klux Klan", "90", "Cash for Clunkers", "Argentina", "1997", "103", "Carolyn Sue Jones", "vanilla", "Hercules", "the World Into Six Major Climate Classifications", "Gian Carlo Menotti", "50th anniversary of the founding of the National Basketball Association", "Gararish", "mother", "Daisy Miller", "Detaiils", "Apollo"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6678727164291023}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.5, 0.4, 0.0, 0.0, 0.26666666666666666, 1.0, 1.0, 1.0, 1.0, 0.9565217391304348, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.375, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-978", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3714", "mrqa_newsqa-validation-152", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-950", "mrqa_newsqa-validation-169", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-2222", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-1746", "mrqa_newsqa-validation-748", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-3605", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-533", "mrqa_triviaqa-validation-575", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-4389", "mrqa_searchqa-validation-1261", "mrqa_searchqa-validation-2623"], "SR": 0.5625, "CSR": 0.5705236486486487, "retrieved_ids": ["mrqa_squad-train-33864", "mrqa_squad-train-85472", "mrqa_squad-train-70127", "mrqa_squad-train-17388", "mrqa_squad-train-31713", "mrqa_squad-train-80680", "mrqa_squad-train-20561", "mrqa_squad-train-16660", "mrqa_squad-train-26679", "mrqa_squad-train-85484", "mrqa_squad-train-60659", "mrqa_squad-train-1118", "mrqa_squad-train-85861", "mrqa_squad-train-74161", "mrqa_squad-train-21687", "mrqa_squad-train-44788", "mrqa_squad-train-28518", "mrqa_squad-train-16530", "mrqa_squad-train-2790", "mrqa_squad-train-7867", "mrqa_squad-train-74480", "mrqa_squad-train-23567", "mrqa_squad-train-24937", "mrqa_squad-train-86280", "mrqa_squad-train-40378", "mrqa_squad-train-46892", "mrqa_squad-train-11008", "mrqa_squad-train-21317", "mrqa_squad-train-61588", "mrqa_squad-train-65266", "mrqa_squad-train-65345", "mrqa_squad-train-5426", "mrqa_searchqa-validation-4367", "mrqa_squad-validation-5588", "mrqa_squad-validation-9161", "mrqa_naturalquestions-validation-3329", "mrqa_triviaqa-validation-2749", "mrqa_naturalquestions-validation-2605", "mrqa_squad-validation-7708", "mrqa_squad-validation-6169", "mrqa_hotpotqa-validation-1906", "mrqa_naturalquestions-validation-3598", "mrqa_squad-validation-9176", "mrqa_squad-validation-7943", "mrqa_searchqa-validation-13600", "mrqa_newsqa-validation-3518", "mrqa_hotpotqa-validation-62", "mrqa_searchqa-validation-8582", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-123", "mrqa_newsqa-validation-3214", "mrqa_triviaqa-validation-5500", "mrqa_hotpotqa-validation-3919", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-3331", "mrqa_searchqa-validation-9536", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10613", "mrqa_triviaqa-validation-6746", "mrqa_naturalquestions-validation-81", "mrqa_hotpotqa-validation-2986", "mrqa_naturalquestions-validation-10128", "mrqa_squad-validation-2943", "mrqa_hotpotqa-validation-257"], "EFR": 1.0, "Overall": 0.7539484797297298}, {"timecode": 37, "before_eval_results": {"predictions": ["five", "the state's attorney", "Abdullah Gul", "Ed McMahon", "they are co-chair of the Genocide Prevention Task Force.", "off Somalia's coast.", "clogs", "upper respiratory infection", "two", "tells stories of different women coping with breast cancer in five vignettes.", "Larry King", "Dr. Jennifer Arnold and husband Bill Klein", "Facebook and Google", "Alwin Landry", "Venus Williams", "Won Sei Hoon, who heads South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "Robert Mugabe", "a female soldier", "brother, Julio Cesar Godoy Rangel", "J. Crew", "$17,000", "Barack Obama", "Al-Aqsa mosque", "\"momentous discovery\"", "a three-story residential building in downtown Nairobi.", "Robert Barnett", "Asian qualifying Group 2", "Matthew Fisher", "Zimbabwean", "Ben Roethlisberger", "two", "Pew Research Center", "Sgt. Jason Bendett", "Egypt and the United Arab Emirates", "on websites on the 24th.", "$14.1 million", "a jury", "Salt Lake City, Utah,", "Sunday.", "Robert Mugabe", "13", "One of Osama bin Laden's sons", "of the six imprisoned leaders of the religious minority were held for security reasons and not because of their faith.", "\"We tortured (Mohammed al.) Qahtani,\"", "autonomy", "the Arctic north of Murmansk down to the southern climes of Sochi", "Long Island", "Ma Khin Khin Leh", "several months", "The 19-year-old woman", "Washington State's decommissioned Hanford nuclear site", "the breast or lower chest of beef or veal", "wintertime", "to relieve families who had difficulty finding jobs", "jubilee c. Taylor", "bullfight", "the waltz", "1887", "Atlantic Coast Conference", "uncle", "Virginia", "\"Rabbit\"", "Brunswick", "Labrador retrievevers"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6240248466810967}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 0.0, 0.7272727272727273, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-2723", "mrqa_newsqa-validation-1022", "mrqa_newsqa-validation-1693", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-3781", "mrqa_newsqa-validation-1837", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-903", "mrqa_newsqa-validation-650", "mrqa_newsqa-validation-3741", "mrqa_newsqa-validation-4100", "mrqa_newsqa-validation-2905", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-9856", "mrqa_triviaqa-validation-55", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-3660", "mrqa_hotpotqa-validation-5703", "mrqa_searchqa-validation-15103", "mrqa_searchqa-validation-12609", "mrqa_triviaqa-validation-3505"], "SR": 0.53125, "CSR": 0.5694901315789473, "retrieved_ids": ["mrqa_squad-train-28710", "mrqa_squad-train-55836", "mrqa_squad-train-3016", "mrqa_squad-train-59450", "mrqa_squad-train-28714", "mrqa_squad-train-11098", "mrqa_squad-train-71100", "mrqa_squad-train-27263", "mrqa_squad-train-3673", "mrqa_squad-train-51298", "mrqa_squad-train-58420", "mrqa_squad-train-64722", "mrqa_squad-train-69667", "mrqa_squad-train-32851", "mrqa_squad-train-13230", "mrqa_squad-train-62394", "mrqa_squad-train-21025", "mrqa_squad-train-44115", "mrqa_squad-train-27169", "mrqa_squad-train-11152", "mrqa_squad-train-84386", "mrqa_squad-train-38258", "mrqa_squad-train-69219", "mrqa_squad-train-80960", "mrqa_squad-train-75176", "mrqa_squad-train-29626", "mrqa_squad-train-58954", "mrqa_squad-train-28326", "mrqa_squad-train-47165", "mrqa_squad-train-23732", "mrqa_squad-train-58690", "mrqa_squad-train-1696", "mrqa_searchqa-validation-2463", "mrqa_hotpotqa-validation-4322", "mrqa_squad-validation-9176", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-2368", "mrqa_triviaqa-validation-3940", "mrqa_naturalquestions-validation-3672", "mrqa_newsqa-validation-2595", "mrqa_squad-validation-218", "mrqa_triviaqa-validation-899", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-4030", "mrqa_hotpotqa-validation-4864", "mrqa_triviaqa-validation-423", "mrqa_hotpotqa-validation-3090", "mrqa_naturalquestions-validation-3553", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-3584", "mrqa_hotpotqa-validation-3304", "mrqa_naturalquestions-validation-10039", "mrqa_triviaqa-validation-4210", "mrqa_hotpotqa-validation-3216", "mrqa_searchqa-validation-15477", "mrqa_triviaqa-validation-2151", "mrqa_searchqa-validation-9148", "mrqa_newsqa-validation-3541", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-2463", "mrqa_naturalquestions-validation-7390", "mrqa_newsqa-validation-3697"], "EFR": 1.0, "Overall": 0.7537417763157894}, {"timecode": 38, "before_eval_results": {"predictions": ["vector quantities", "Transport Workers Union leaders", "March 24,", "Eleven people", "Mexican military", "Pakistani officials,", "$7.8 million", "Stratfor", "Madeleine K. Albright", "Hillary Clinton", "Marco Polo", "German Foreign Ministry,", "10,000 refugees,", "IV cafe.", "Red Lines", "body bags on the roadway near the bus,", "40 militants and six Pakistan soldiers dead,", "intricate Flemish tapestries in an east-facing sitting room called the Morning Room.", "Islamic militants", "in the heart of Los Angeles.", "last week", "Sunni Arab and Shiite tribal leaders", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "an antihistamine and an epinephrine auto-injector", "North Korea", "Hong Kong from other parts of Asia,", "from his plane over Lebanon in October 1986.", "the release of the four men -- Jesus Ortiz, 19; Stalin Felipe, 19); Kevin Taveras, 20; and Rondell Bedward, 21;", "Polo", "President Sheikh Sharif Sheikh Ahmed", "Saturday's Hungarian Grand Prix.", "power-sharing talks", "that the matron swore and scream at the girls and assaulted them,", "a hospital in Amstetten,", "9-1 on aggregate.", "Africa", "fear of losing their licenses to fly.", "President Robert Mugabe", "FBI.", "first grand Slam,", "\"it should stay that way.\"", "CNN", "Obama and McCain", "strength of its brand name and the diversity of its product portfolio,", "U.S. State Department and British Foreign Office", "Monday's", "Fiona Mac Keown", "sculptures", "Pakistan's High Commission in India", "Bryant Purvis,", "pain-relief drugs.", "1871", "President of Zambia", "experimental psychology", "animals", "Treaty of Utrecht", "Massachusetts", "Jim Harrison", "Ford Island", "Tomorrowland", "Tiger Woods", "greed", "Martin Luther King Jr.", "Sesame Street"], "metric_results": {"EM": 0.5, "QA-F1": 0.6762825715950717}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.923076923076923, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.8333333333333333, 0.4, 1.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.33333333333333337, 0.5714285714285715, 0.3636363636363636, 0.0, 0.5, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2830", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-3327", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2635", "mrqa_newsqa-validation-1219", "mrqa_newsqa-validation-1517", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-3720", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-1403", "mrqa_newsqa-validation-3806", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-3803", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2991", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-1136", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-1060", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-10040", "mrqa_triviaqa-validation-6409", "mrqa_hotpotqa-validation-1614"], "SR": 0.5, "CSR": 0.5677083333333333, "retrieved_ids": ["mrqa_squad-train-44430", "mrqa_squad-train-73117", "mrqa_squad-train-15211", "mrqa_squad-train-43555", "mrqa_squad-train-84823", "mrqa_squad-train-610", "mrqa_squad-train-84292", "mrqa_squad-train-81412", "mrqa_squad-train-31728", "mrqa_squad-train-72645", "mrqa_squad-train-6575", "mrqa_squad-train-81816", "mrqa_squad-train-25061", "mrqa_squad-train-75623", "mrqa_squad-train-5775", "mrqa_squad-train-54735", "mrqa_squad-train-36342", "mrqa_squad-train-30848", "mrqa_squad-train-85407", "mrqa_squad-train-10797", "mrqa_squad-train-7868", "mrqa_squad-train-19718", "mrqa_squad-train-45490", "mrqa_squad-train-201", "mrqa_squad-train-55157", "mrqa_squad-train-73133", "mrqa_squad-train-79522", "mrqa_squad-train-28092", "mrqa_squad-train-68495", "mrqa_squad-train-24093", "mrqa_squad-train-65229", "mrqa_squad-train-23768", "mrqa_naturalquestions-validation-6148", "mrqa_newsqa-validation-1746", "mrqa_searchqa-validation-9148", "mrqa_naturalquestions-validation-3186", "mrqa_triviaqa-validation-1576", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-9979", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2986", "mrqa_triviaqa-validation-3782", "mrqa_searchqa-validation-8760", "mrqa_hotpotqa-validation-1706", "mrqa_searchqa-validation-15033", "mrqa_newsqa-validation-1483", "mrqa_searchqa-validation-12829", "mrqa_hotpotqa-validation-21", "mrqa_triviaqa-validation-5294", "mrqa_newsqa-validation-3043", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-1813", "mrqa_triviaqa-validation-6746", "mrqa_hotpotqa-validation-996", "mrqa_searchqa-validation-14569", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-950", "mrqa_hotpotqa-validation-2378", "mrqa_newsqa-validation-712", "mrqa_squad-validation-1136", "mrqa_squad-validation-4715", "mrqa_triviaqa-validation-1046", "mrqa_newsqa-validation-169"], "EFR": 1.0, "Overall": 0.7533854166666666}, {"timecode": 39, "before_eval_results": {"predictions": ["Andrew Lortie", "worse", "vert", "high cooking", "Silver Hatch", "peripheral nerves", "Ethiopia", "carmen cans", "Puerto Rico.", "Harrier", "reserved for military-trained professionals", "Macau", "alastair Cook", "Enterprise", "The Three Little Pigs", "Australia", "shoulder", "Frank Sinatra", "meninges", "English", "Charles Brandon", "Munich", "Henry Mancini", "Fred Astaire", "a swamp", "woe", "Sudan", "Low Countries", "Dramatic Hour", "The Bible", "stand-up", "Jamaica", "peppercorn", "drama", "s\u00e3o Jorge", "pancreas", "peter", "football", "Antoine Lavoisier", "Leon", "geologist Dr. Paul Hoffman,", "interference with commerce and trade", "Pet Shop Boys", "Chris Salmon", "algiers", "Marks & Co", "Anabaptists", "albert carmen cans be invoked against particular aspects of life", "Hebrew", "John Virgo", "herpes virus", "reduce trade and adversely affect consumers in general ( by raising the cost of imported goods ), and harm the producers and workers in export sectors, both in the country implementing protectionist policies, and in the countries protected against", "Garfield Sobers", "In the mountains outside City 17", "Dan Castellaneta", "Johannes Vermeer", "O.T. Genasis", "Climate Care,", "there are several thousand drugs, mostly older products, marketed illegally without FDA approval in this country.", "Kevin Kuranyi", "Lost in America", "autumnal", "Soviet Union", "Republicans"], "metric_results": {"EM": 0.4375, "QA-F1": 0.47980781408308}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.2553191489361702, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2262", "mrqa_triviaqa-validation-4864", "mrqa_triviaqa-validation-2456", "mrqa_triviaqa-validation-6748", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-7508", "mrqa_triviaqa-validation-2508", "mrqa_triviaqa-validation-2357", "mrqa_triviaqa-validation-5179", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-4924", "mrqa_triviaqa-validation-7690", "mrqa_triviaqa-validation-4436", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-7376", "mrqa_triviaqa-validation-4750", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-3447", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-3809", "mrqa_triviaqa-validation-2926", "mrqa_triviaqa-validation-970", "mrqa_triviaqa-validation-3735", "mrqa_triviaqa-validation-1403", "mrqa_triviaqa-validation-4687", "mrqa_triviaqa-validation-2936", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-4784", "mrqa_triviaqa-validation-2781", "mrqa_naturalquestions-validation-86", "mrqa_hotpotqa-validation-264", "mrqa_newsqa-validation-2509", "mrqa_searchqa-validation-6304"], "SR": 0.4375, "CSR": 0.564453125, "retrieved_ids": ["mrqa_squad-train-27316", "mrqa_squad-train-76577", "mrqa_squad-train-51258", "mrqa_squad-train-7164", "mrqa_squad-train-46592", "mrqa_squad-train-67577", "mrqa_squad-train-60539", "mrqa_squad-train-70555", "mrqa_squad-train-7434", "mrqa_squad-train-62050", "mrqa_squad-train-2963", "mrqa_squad-train-77202", "mrqa_squad-train-81042", "mrqa_squad-train-8056", "mrqa_squad-train-60814", "mrqa_squad-train-23385", "mrqa_squad-train-46652", "mrqa_squad-train-47152", "mrqa_squad-train-71189", "mrqa_squad-train-32759", "mrqa_squad-train-41822", "mrqa_squad-train-81973", "mrqa_squad-train-74788", "mrqa_squad-train-62723", "mrqa_squad-train-30663", "mrqa_squad-train-56412", "mrqa_squad-train-77314", "mrqa_squad-train-51987", "mrqa_squad-train-51170", "mrqa_squad-train-77656", "mrqa_squad-train-80638", "mrqa_squad-train-1530", "mrqa_triviaqa-validation-6380", "mrqa_naturalquestions-validation-3329", "mrqa_searchqa-validation-13595", "mrqa_newsqa-validation-4170", "mrqa_naturalquestions-validation-1462", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-9691", "mrqa_squad-validation-386", "mrqa_naturalquestions-validation-9272", "mrqa_newsqa-validation-1759", "mrqa_triviaqa-validation-5478", "mrqa_squad-validation-4326", "mrqa_hotpotqa-validation-5014", "mrqa_triviaqa-validation-3864", "mrqa_triviaqa-validation-6548", "mrqa_newsqa-validation-908", "mrqa_squad-validation-4838", "mrqa_squad-validation-2975", "mrqa_newsqa-validation-2086", "mrqa_searchqa-validation-4851", "mrqa_hotpotqa-validation-2582", "mrqa_hotpotqa-validation-5792", "mrqa_searchqa-validation-13554", "mrqa_searchqa-validation-14194", "mrqa_naturalquestions-validation-8239", "mrqa_triviaqa-validation-5476", "mrqa_squad-validation-2094", "mrqa_triviaqa-validation-7401"], "EFR": 1.0, "Overall": 0.752734375}, {"timecode": 40, "UKR": 0.77734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1041", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1216", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-1368", "mrqa_hotpotqa-validation-1389", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1495", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1681", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1853", "mrqa_hotpotqa-validation-1919", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2273", "mrqa_hotpotqa-validation-2392", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2402", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-261", "mrqa_hotpotqa-validation-2705", "mrqa_hotpotqa-validation-2735", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2769", "mrqa_hotpotqa-validation-2792", "mrqa_hotpotqa-validation-2841", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-2986", "mrqa_hotpotqa-validation-3018", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-3136", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3355", "mrqa_hotpotqa-validation-347", "mrqa_hotpotqa-validation-3714", "mrqa_hotpotqa-validation-3721", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-3928", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-423", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-4295", "mrqa_hotpotqa-validation-4418", "mrqa_hotpotqa-validation-4459", "mrqa_hotpotqa-validation-4526", "mrqa_hotpotqa-validation-4575", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-503", "mrqa_hotpotqa-validation-5131", "mrqa_hotpotqa-validation-5339", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5483", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5578", "mrqa_hotpotqa-validation-558", "mrqa_hotpotqa-validation-5869", "mrqa_hotpotqa-validation-594", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-646", "mrqa_hotpotqa-validation-929", "mrqa_hotpotqa-validation-975", "mrqa_hotpotqa-validation-99", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10156", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-10298", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10411", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-10513", "mrqa_naturalquestions-validation-10606", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-10670", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-1519", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2855", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-3935", "mrqa_naturalquestions-validation-4036", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4135", "mrqa_naturalquestions-validation-435", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-4917", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5767", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6592", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6778", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-757", "mrqa_naturalquestions-validation-7976", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-8052", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-837", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9291", "mrqa_naturalquestions-validation-9299", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-94", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-9870", "mrqa_naturalquestions-validation-9887", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-1132", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1200", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1232", "mrqa_newsqa-validation-139", "mrqa_newsqa-validation-1403", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-1693", "mrqa_newsqa-validation-1746", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-1776", "mrqa_newsqa-validation-1851", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1908", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-1985", "mrqa_newsqa-validation-1995", "mrqa_newsqa-validation-2010", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2026", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-231", "mrqa_newsqa-validation-2313", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2384", "mrqa_newsqa-validation-2404", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-245", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2582", "mrqa_newsqa-validation-2635", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2905", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-3698", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3728", "mrqa_newsqa-validation-3741", "mrqa_newsqa-validation-3816", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-3847", "mrqa_newsqa-validation-389", "mrqa_newsqa-validation-3917", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3986", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-4054", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-641", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-720", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-825", "mrqa_searchqa-validation-1030", "mrqa_searchqa-validation-10806", "mrqa_searchqa-validation-10918", "mrqa_searchqa-validation-11406", "mrqa_searchqa-validation-11836", "mrqa_searchqa-validation-1227", "mrqa_searchqa-validation-12440", "mrqa_searchqa-validation-12493", "mrqa_searchqa-validation-1261", "mrqa_searchqa-validation-1264", "mrqa_searchqa-validation-12829", "mrqa_searchqa-validation-12864", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-13251", "mrqa_searchqa-validation-13257", "mrqa_searchqa-validation-13456", "mrqa_searchqa-validation-1357", "mrqa_searchqa-validation-13907", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15075", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-15568", "mrqa_searchqa-validation-15671", "mrqa_searchqa-validation-15770", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-16453", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-16839", "mrqa_searchqa-validation-1770", "mrqa_searchqa-validation-1898", "mrqa_searchqa-validation-1999", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-2141", "mrqa_searchqa-validation-2143", "mrqa_searchqa-validation-217", "mrqa_searchqa-validation-2866", "mrqa_searchqa-validation-3018", "mrqa_searchqa-validation-3479", "mrqa_searchqa-validation-3597", "mrqa_searchqa-validation-4044", "mrqa_searchqa-validation-4269", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-4724", "mrqa_searchqa-validation-515", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-5725", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-6181", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-686", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-9185", "mrqa_searchqa-validation-9394", "mrqa_searchqa-validation-9596", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9846", "mrqa_squad-validation-10000", "mrqa_squad-validation-10097", "mrqa_squad-validation-10135", "mrqa_squad-validation-10184", "mrqa_squad-validation-10263", "mrqa_squad-validation-10317", "mrqa_squad-validation-10326", "mrqa_squad-validation-10339", "mrqa_squad-validation-10369", "mrqa_squad-validation-10496", "mrqa_squad-validation-1240", "mrqa_squad-validation-1269", "mrqa_squad-validation-127", "mrqa_squad-validation-1408", "mrqa_squad-validation-1430", "mrqa_squad-validation-1453", "mrqa_squad-validation-1708", "mrqa_squad-validation-1713", "mrqa_squad-validation-1765", "mrqa_squad-validation-1890", "mrqa_squad-validation-2019", "mrqa_squad-validation-2094", "mrqa_squad-validation-2328", "mrqa_squad-validation-2352", "mrqa_squad-validation-2365", "mrqa_squad-validation-2438", "mrqa_squad-validation-2456", "mrqa_squad-validation-2595", "mrqa_squad-validation-2751", "mrqa_squad-validation-280", "mrqa_squad-validation-2886", "mrqa_squad-validation-2897", "mrqa_squad-validation-2943", "mrqa_squad-validation-2953", "mrqa_squad-validation-2959", "mrqa_squad-validation-3021", "mrqa_squad-validation-305", "mrqa_squad-validation-3124", "mrqa_squad-validation-3184", "mrqa_squad-validation-3364", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3435", "mrqa_squad-validation-3444", "mrqa_squad-validation-3497", "mrqa_squad-validation-3551", "mrqa_squad-validation-3608", "mrqa_squad-validation-3703", "mrqa_squad-validation-3796", "mrqa_squad-validation-3812", "mrqa_squad-validation-3863", "mrqa_squad-validation-3909", "mrqa_squad-validation-3946", "mrqa_squad-validation-402", "mrqa_squad-validation-4047", "mrqa_squad-validation-4265", "mrqa_squad-validation-4298", "mrqa_squad-validation-4326", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4528", "mrqa_squad-validation-4583", "mrqa_squad-validation-4630", "mrqa_squad-validation-4715", "mrqa_squad-validation-491", "mrqa_squad-validation-4918", "mrqa_squad-validation-5004", "mrqa_squad-validation-5128", "mrqa_squad-validation-5134", "mrqa_squad-validation-5180", "mrqa_squad-validation-5479", "mrqa_squad-validation-5644", "mrqa_squad-validation-5664", "mrqa_squad-validation-5692", "mrqa_squad-validation-5737", "mrqa_squad-validation-5763", "mrqa_squad-validation-5781", "mrqa_squad-validation-5836", "mrqa_squad-validation-5852", "mrqa_squad-validation-6089", "mrqa_squad-validation-6228", "mrqa_squad-validation-6353", "mrqa_squad-validation-6494", "mrqa_squad-validation-6517", "mrqa_squad-validation-6543", "mrqa_squad-validation-6706", "mrqa_squad-validation-6875", "mrqa_squad-validation-71", "mrqa_squad-validation-7147", "mrqa_squad-validation-7192", "mrqa_squad-validation-7205", "mrqa_squad-validation-7296", "mrqa_squad-validation-7297", "mrqa_squad-validation-7338", "mrqa_squad-validation-7434", "mrqa_squad-validation-7492", "mrqa_squad-validation-7613", "mrqa_squad-validation-7751", "mrqa_squad-validation-7781", "mrqa_squad-validation-7993", "mrqa_squad-validation-8134", "mrqa_squad-validation-8154", "mrqa_squad-validation-8232", "mrqa_squad-validation-8282", "mrqa_squad-validation-8841", "mrqa_squad-validation-893", "mrqa_squad-validation-8933", "mrqa_squad-validation-908", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9193", "mrqa_squad-validation-9234", "mrqa_squad-validation-9367", "mrqa_squad-validation-9376", "mrqa_squad-validation-9461", "mrqa_squad-validation-9581", "mrqa_squad-validation-959", "mrqa_squad-validation-9614", "mrqa_squad-validation-9666", "mrqa_squad-validation-9771", "mrqa_squad-validation-9900", "mrqa_squad-validation-9959", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1239", "mrqa_triviaqa-validation-1282", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1534", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-1619", "mrqa_triviaqa-validation-1683", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-2024", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-2262", "mrqa_triviaqa-validation-2361", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-2456", "mrqa_triviaqa-validation-2459", "mrqa_triviaqa-validation-2519", "mrqa_triviaqa-validation-260", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-2712", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-2926", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2936", "mrqa_triviaqa-validation-3301", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3447", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-358", "mrqa_triviaqa-validation-3735", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-3805", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-4338", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4886", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-5179", "mrqa_triviaqa-validation-5261", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-5294", "mrqa_triviaqa-validation-5381", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-55", "mrqa_triviaqa-validation-5500", "mrqa_triviaqa-validation-568", "mrqa_triviaqa-validation-5749", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-611", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6358", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6665", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-6748", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-6927", "mrqa_triviaqa-validation-7038", "mrqa_triviaqa-validation-7374", "mrqa_triviaqa-validation-7560", "mrqa_triviaqa-validation-7619", "mrqa_triviaqa-validation-7690", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-899"], "OKR": 0.884765625, "KG": 0.471875, "before_eval_results": {"predictions": ["chameleon circuit", "Jake LaMotta", "belgian", "Joshua", "pangram", "Let Die", "lassie", "smith", "brazil", "Robert Hooke", "Hadrian", "Napier", "Sony Interactive Entertainment", "king smith", "green", "1215", "delphiniums", "Robinson Crusoe", "Charles Dickens", "belgian", "Egypt", "a neutron star", "earache", "New York Yankees", "Four Tops", "hudson", "July 20, 1969", "about a quarter (fourth) of a full barrel", "bali", "Lilac", "Hilary Swank", "scarlet tanager", "a dove", "a mole", "John McCarthy", "springtime for Hitler", "six", "georgia dorOTheA", "Shaft", "the heel", "daily Mirror", "smith", "horse", "Pakistan", "belgian", "Vitcos", "Paul McCartney", "Madness", "squeee", "Kansas", "belgian", "A marriage officiant, solemniser, or `` vow master ''", "Ricky Nelson", "Wabanaki Confederacy members Abenaki and Mi'kmaq, and Algonquin, Lenape, Ojibwa, Ottawa, Shawnee, and Wyandot", "Port Moresby, Papua New Guinea", "Bass", "Security Management", "eight", "Russia", "like a class to help women \" learn how to dance and feel sexy,\"", "Malacca", "Hank Aaron", "livin' on a prayer", "Robber Barons"], "metric_results": {"EM": 0.5, "QA-F1": 0.5833881578947369}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3522", "mrqa_triviaqa-validation-571", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-2063", "mrqa_triviaqa-validation-3079", "mrqa_triviaqa-validation-1606", "mrqa_triviaqa-validation-6324", "mrqa_triviaqa-validation-1746", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-56", "mrqa_triviaqa-validation-2632", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-1978", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-705", "mrqa_triviaqa-validation-6915", "mrqa_triviaqa-validation-5726", "mrqa_triviaqa-validation-5919", "mrqa_triviaqa-validation-6396", "mrqa_triviaqa-validation-7619", "mrqa_triviaqa-validation-2045", "mrqa_triviaqa-validation-774", "mrqa_naturalquestions-validation-3491", "mrqa_hotpotqa-validation-650", "mrqa_hotpotqa-validation-3526", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1413", "mrqa_searchqa-validation-11621"], "SR": 0.5, "CSR": 0.5628810975609756, "retrieved_ids": ["mrqa_squad-train-71525", "mrqa_squad-train-11644", "mrqa_squad-train-48663", "mrqa_squad-train-63228", "mrqa_squad-train-38026", "mrqa_squad-train-11789", "mrqa_squad-train-45351", "mrqa_squad-train-59233", "mrqa_squad-train-65177", "mrqa_squad-train-73423", "mrqa_squad-train-48713", "mrqa_squad-train-70856", "mrqa_squad-train-1533", "mrqa_squad-train-56551", "mrqa_squad-train-29988", "mrqa_squad-train-20358", "mrqa_squad-train-35826", "mrqa_squad-train-83867", "mrqa_squad-train-18532", "mrqa_squad-train-81172", "mrqa_squad-train-11730", "mrqa_squad-train-64277", "mrqa_squad-train-26224", "mrqa_squad-train-71337", "mrqa_squad-train-43972", "mrqa_squad-train-64952", "mrqa_squad-train-80827", "mrqa_squad-train-12428", "mrqa_squad-train-28041", "mrqa_squad-train-68428", "mrqa_squad-train-58217", "mrqa_squad-train-42891", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-2036", "mrqa_naturalquestions-validation-7095", "mrqa_squad-validation-218", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-6592", "mrqa_newsqa-validation-3986", "mrqa_hotpotqa-validation-3773", "mrqa_squad-validation-8958", "mrqa_triviaqa-validation-4411", "mrqa_newsqa-validation-1008", "mrqa_searchqa-validation-12440", "mrqa_newsqa-validation-1893", "mrqa_hotpotqa-validation-5154", "mrqa_searchqa-validation-4032", "mrqa_naturalquestions-validation-1987", "mrqa_searchqa-validation-13554", "mrqa_naturalquestions-validation-3686", "mrqa_triviaqa-validation-3223", "mrqa_naturalquestions-validation-5485", "mrqa_newsqa-validation-2903", "mrqa_searchqa-validation-1507", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-10161", "mrqa_hotpotqa-validation-4950", "mrqa_squad-validation-4715", "mrqa_searchqa-validation-5172", "mrqa_triviaqa-validation-6409", "mrqa_naturalquestions-validation-276", "mrqa_hotpotqa-validation-3136"], "EFR": 0.96875, "Overall": 0.7331230945121952}, {"timecode": 41, "before_eval_results": {"predictions": ["Edward Teller", "food, music, culture and language of Latin America", "Los Angeles", "her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Tim Clark, Matt Kuchar and Bubba Watson", "Philip Markoff", "Haeftling", "forgery and flying without a valid license,", "Sea World in San Antonio", "Mafia", "someone with a compatible organ died", "45th anniversary.", "convicts caught with phones", "16", "cancer", "$40", "McDonald's' plans seem to have caused more media attention abroad than in France,", "she's in love,", "France", "President Obama and Britain's Prince Charles", "eight", "South Africa's", "Madeleine K. Albright", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "back at work", "president and CEO of Ripken Baseball,", "unknown,", "five", "hiring of hundreds of foreign workers", "Ronald Cummings", "Elisabeth's father,", "his club", "they", "$60 billion", "twice the storage space and a longer advertised battery life", "J.G. Ballard", "Republicans", "he discussed foreplay, sexual conquests and how he picks up women,", "Airbus A330-200", "United States, NATO member states, Russia and India", "fatally shooting a limo driver", "ties", "walk on ice in Alaska.", "not", "China", "Steve Wozniak", "\"Rin Tin Tin: The Life and the Legend\"", "Sri Lanka's", "The station", "the state's attorney", "First Lieutenant Israel Greene", "126 by Wilt Chamberlain from October 19, 1961 -- January 19, 1963", "Robert E. Lee", "The Telegraph", "prime minister", "\"Chant de guerre de lisle\"", "Kristy Lee Cook", "John Samuel Waters Jr.", "Norman Mark Reedus", "Damned Women", "Douglas MacArthur", "rice", "no license or advanced training beyond just firearm familiarization"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5979938162682727}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.26666666666666666, 1.0, 1.0, 1.0, 0.17391304347826086, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.08333333333333334, 1.0, 0.8571428571428571, 1.0, 0.0, 0.33333333333333337, 0.4, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.16666666666666669, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.1818181818181818]}}, "before_error_ids": ["mrqa_squad-validation-7880", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-2244", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2951", "mrqa_newsqa-validation-551", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-1442", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2078", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-371", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-2421", "mrqa_triviaqa-validation-4759", "mrqa_triviaqa-validation-2819", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-2138", "mrqa_searchqa-validation-1621", "mrqa_searchqa-validation-149", "mrqa_naturalquestions-validation-8617"], "SR": 0.484375, "CSR": 0.5610119047619048, "retrieved_ids": ["mrqa_squad-train-16681", "mrqa_squad-train-82595", "mrqa_squad-train-33877", "mrqa_squad-train-83745", "mrqa_squad-train-23056", "mrqa_squad-train-85275", "mrqa_squad-train-76171", "mrqa_squad-train-69282", "mrqa_squad-train-5936", "mrqa_squad-train-82085", "mrqa_squad-train-60776", "mrqa_squad-train-10391", "mrqa_squad-train-76683", "mrqa_squad-train-35836", "mrqa_squad-train-43162", "mrqa_squad-train-31209", "mrqa_squad-train-74690", "mrqa_squad-train-61416", "mrqa_squad-train-18826", "mrqa_squad-train-37694", "mrqa_squad-train-56545", "mrqa_squad-train-77204", "mrqa_squad-train-50545", "mrqa_squad-train-35259", "mrqa_squad-train-16120", "mrqa_squad-train-384", "mrqa_squad-train-32973", "mrqa_squad-train-58524", "mrqa_squad-train-32781", "mrqa_squad-train-245", "mrqa_squad-train-19317", "mrqa_squad-train-56032", "mrqa_squad-validation-1938", "mrqa_newsqa-validation-3772", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-2462", "mrqa_triviaqa-validation-899", "mrqa_hotpotqa-validation-5386", "mrqa_squad-validation-7457", "mrqa_searchqa-validation-4724", "mrqa_naturalquestions-validation-5583", "mrqa_hotpotqa-validation-2923", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-186", "mrqa_searchqa-validation-7059", "mrqa_searchqa-validation-10806", "mrqa_hotpotqa-validation-5154", "mrqa_newsqa-validation-3915", "mrqa_naturalquestions-validation-2452", "mrqa_newsqa-validation-4032", "mrqa_newsqa-validation-2429", "mrqa_naturalquestions-validation-2813", "mrqa_naturalquestions-validation-9979", "mrqa_newsqa-validation-1855", "mrqa_squad-validation-3812", "mrqa_squad-validation-259", "mrqa_squad-validation-3718", "mrqa_squad-validation-6319", "mrqa_searchqa-validation-1649", "mrqa_triviaqa-validation-7585", "mrqa_searchqa-validation-9148", "mrqa_triviaqa-validation-2495", "mrqa_newsqa-validation-2991", "mrqa_naturalquestions-validation-588"], "EFR": 1.0, "Overall": 0.7389992559523809}, {"timecode": 42, "before_eval_results": {"predictions": ["ITT", "246", "beloved and admired", "The cause of the child's death will be listed as homicide by undetermined means,", "Britain's Prime Minister Gordon Brown, France's President Nicolas Sarkozy", "Dean Martin, Katharine Hepburn and Spencer Tracy", "Iran's parliament speaker has criticized U.S. President-elect Barack Obama for saying that Iran's development of a nuclear weapon is unacceptable.", "20", "\"Dance Your Ass Off\"", "the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "15", "AbdulMutallab,", "London", "Democratic", "Philippines", "Kitty Kelley, biographer of the rich and famous,", "France", "Democrats and Republicans", "Amanda Knox's aunt", "Michael Krane, president of Green Apple Barter Services in Pittsburgh, Pennsylvania.", "15,000", "about 12 million", "the Gulf", "May 4", "3-0", "Zimbabwean President Robert Mugabe", "The militants are suspected of launching attacks inside Pakistan and in neighboring Afghanistan from their haven in the mountainous tribal region along the northwestern border.", "kill then-Sen. Obama", "10", "165-room", "when times get tough, you see a 50 percent-plus increase in bartering as a way for people to be able to buy things or get things and do it economically.", "Ignazio La Russa", "Adriano", "$40 and a loaf of bread.", "rural Tennessee.", "Tulsa, Oklahoma.", "2-1", "nearly $2 billion", "Russian concerns that the defensive shield could be used for offensive aims.", "1981", "Knox's parents, Curt Knox and Edda Mellas,", "London's", "Prague", "more than 100", "Microsoft.", "Michael Partain,", "Mitt Romney", "Islamic", "prisoners", "part of the proceeds from sales go to organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "it does not grant full health-care coverage,", "season five episode `` Aqua ''", "1960s", "1940", "Afghanistan", "sheriff Martin Howe", "denmark", "\"Shake It Off\"", "Cheshire", "Selden is a hamlet (and census-designated place) in the Town of Brookhaven in Suffolk County, New York, United States", "Transamerica", "the concept of a novel that shows the culture of the United States at a specific time", "Pirates", "16"], "metric_results": {"EM": 0.5, "QA-F1": 0.5894003594156447}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.26666666666666666, 1.0, 0.34782608695652173, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 0.3076923076923077, 0.5, 0.7499999999999999, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.0, 0.15384615384615385, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-2503", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-1761", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-1229", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-716", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3394", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-715", "mrqa_newsqa-validation-3130", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-1429", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-143", "mrqa_triviaqa-validation-1380", "mrqa_triviaqa-validation-6580", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-5848", "mrqa_searchqa-validation-13919", "mrqa_searchqa-validation-398", "mrqa_searchqa-validation-709", "mrqa_naturalquestions-validation-1640"], "SR": 0.5, "CSR": 0.559593023255814, "retrieved_ids": ["mrqa_squad-train-65403", "mrqa_squad-train-58821", "mrqa_squad-train-46532", "mrqa_squad-train-83111", "mrqa_squad-train-76525", "mrqa_squad-train-3292", "mrqa_squad-train-7599", "mrqa_squad-train-1951", "mrqa_squad-train-80795", "mrqa_squad-train-59108", "mrqa_squad-train-18613", "mrqa_squad-train-27376", "mrqa_squad-train-3550", "mrqa_squad-train-80558", "mrqa_squad-train-18573", "mrqa_squad-train-78135", "mrqa_squad-train-16283", "mrqa_squad-train-25312", "mrqa_squad-train-39788", "mrqa_squad-train-61615", "mrqa_squad-train-71092", "mrqa_squad-train-70456", "mrqa_squad-train-5438", "mrqa_squad-train-24542", "mrqa_squad-train-78682", "mrqa_squad-train-62501", "mrqa_squad-train-43060", "mrqa_squad-train-42864", "mrqa_squad-train-74818", "mrqa_squad-train-82855", "mrqa_squad-train-65603", "mrqa_squad-train-58578", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-664", "mrqa_naturalquestions-validation-3390", "mrqa_hotpotqa-validation-5154", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6216", "mrqa_searchqa-validation-16627", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-895", "mrqa_hotpotqa-validation-2393", "mrqa_squad-validation-8786", "mrqa_triviaqa-validation-3004", "mrqa_searchqa-validation-2052", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-4100", "mrqa_hotpotqa-validation-5255", "mrqa_squad-validation-6169", "mrqa_naturalquestions-validation-9614", "mrqa_newsqa-validation-748", "mrqa_naturalquestions-validation-6500", "mrqa_squad-validation-6409", "mrqa_triviaqa-validation-5816", "mrqa_squad-validation-3811", "mrqa_searchqa-validation-10806", "mrqa_searchqa-validation-7269", "mrqa_searchqa-validation-9148", "mrqa_searchqa-validation-172", "mrqa_newsqa-validation-3280", "mrqa_triviaqa-validation-6882", "mrqa_searchqa-validation-13151", "mrqa_newsqa-validation-1712", "mrqa_squad-validation-4715"], "EFR": 1.0, "Overall": 0.7387154796511627}, {"timecode": 43, "before_eval_results": {"predictions": ["the top 400", "14", "3-0", "how health care can affect families.", "\"procedure on her heart,\"", "school in the Oaxacan countryside of southern", "the punishment for the player", "wings", "Vernon Forrest,", "Mandi Hamlin", "U.S. State Department and British Foreign Office", "Pastor Paula White", "Phoenix, Arizona, police", "\"We tortured (Mohammed al%) Qahtani,\"", "The elephant Sanctuary; it is currently home to 15 African and Asian elephants.", "Six", "Wednesday.", "Springfield, Virginia,", "NATO fighters", "Dr. Conrad Murray,", "Hamas forces", "a senior at Stetson University", "Michael Jackson", "1,500", "through the weekend,", "three", "\"The e-mails]", "Aniston, Demi Moore and Alicia Keys", "January", "to hold onto his land", "Miguel Cotto", "Two pages -- usually high school juniors who serve Congress as messengers", "U.S. soldier", "shark River Park", "as many as 50,000 members of the group United Front for Democracy Against Dictatorship", "shutting down buses, subways and trolleys that carry almost a million people daily.", "five", "Long troop deployments", "St. Louis, Missouri.", "it's not", "a number of calls,", "Clifford Harris,", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Republican Party,", "almost 9 million", "Asashoryu", "an upper respiratory infection", "Adriano", "\"Zed,\"", "prime minister's handling of the L'Aquila earthquake,", "the massacre of innocent civilians,", "1973", "Roanoke", "Scarlett Johansson", "the skull", "Red Sea", "Pacific Ocean", "Tyler \"Ty\" Mendoza", "Robert A. Iger", "Salgaocar", "Persuasion", "Abercrombie & Fitch", "soap opera", "Bobby Beathard, Robert Brazile, Brian Dawkins, Jerry Kramer, Ray Lewis, Randy Moss, Terrell Owens, and Brian Urlacher"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6653144278966647}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, false], "QA-F1": [0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.2857142857142857, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.5, 0.14285714285714288, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.21052631578947367]}}, "before_error_ids": ["mrqa_squad-validation-7454", "mrqa_newsqa-validation-2001", "mrqa_newsqa-validation-3933", "mrqa_newsqa-validation-2546", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1086", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-3970", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-3063", "mrqa_newsqa-validation-1989", "mrqa_naturalquestions-validation-375", "mrqa_triviaqa-validation-3275", "mrqa_hotpotqa-validation-802", "mrqa_searchqa-validation-6252", "mrqa_naturalquestions-validation-4915"], "SR": 0.5625, "CSR": 0.5596590909090908, "retrieved_ids": ["mrqa_squad-train-7908", "mrqa_squad-train-32662", "mrqa_squad-train-25419", "mrqa_squad-train-58755", "mrqa_squad-train-44388", "mrqa_squad-train-58943", "mrqa_squad-train-44189", "mrqa_squad-train-39407", "mrqa_squad-train-53188", "mrqa_squad-train-45681", "mrqa_squad-train-41768", "mrqa_squad-train-22640", "mrqa_squad-train-42236", "mrqa_squad-train-85397", "mrqa_squad-train-44531", "mrqa_squad-train-65622", "mrqa_squad-train-6051", "mrqa_squad-train-32656", "mrqa_squad-train-45155", "mrqa_squad-train-36657", "mrqa_squad-train-8137", "mrqa_squad-train-47805", "mrqa_squad-train-78893", "mrqa_squad-train-82427", "mrqa_squad-train-70215", "mrqa_squad-train-82468", "mrqa_squad-train-6075", "mrqa_squad-train-16429", "mrqa_squad-train-32128", "mrqa_squad-train-5284", "mrqa_squad-train-6700", "mrqa_squad-train-39719", "mrqa_triviaqa-validation-3076", "mrqa_hotpotqa-validation-1843", "mrqa_newsqa-validation-214", "mrqa_naturalquestions-validation-10554", "mrqa_newsqa-validation-1032", "mrqa_naturalquestions-validation-2562", "mrqa_squad-validation-7445", "mrqa_hotpotqa-validation-3930", "mrqa_newsqa-validation-631", "mrqa_newsqa-validation-1007", "mrqa_hotpotqa-validation-650", "mrqa_searchqa-validation-16546", "mrqa_newsqa-validation-2074", "mrqa_hotpotqa-validation-3703", "mrqa_newsqa-validation-1456", "mrqa_searchqa-validation-2568", "mrqa_triviaqa-validation-2819", "mrqa_hotpotqa-validation-3090", "mrqa_naturalquestions-validation-4279", "mrqa_newsqa-validation-4170", "mrqa_searchqa-validation-1757", "mrqa_squad-validation-8661", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-1863", "mrqa_squad-validation-6228", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-1529", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-8116", "mrqa_hotpotqa-validation-3136", "mrqa_searchqa-validation-172", "mrqa_naturalquestions-validation-10460"], "EFR": 1.0, "Overall": 0.7387286931818181}, {"timecode": 44, "before_eval_results": {"predictions": ["help transfer and dissipate excess energy", "at his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "Isthmus of Corinth", "Alex Ryan", "I", "2001", "August 2015", "Betty", "devised by Leonard Nimoy, who portrayed the half - Vulcan character Mr. Spock on the original Star Trek television series", "Rodney Crowell", "Jason Momoa", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "from a donor molecule to an acceptor molecule", "Jamie Foxx", "Iowa", "1996", "The uvea", "the Director of National Intelligence", "biological taxonomy", "Zeebo", "1977", "as of 2000", "France", "development of electronic computers", "The Archers is the world's longest - running radio soap opera", "1939", "Kristy Swanson", "Jyotirindra Basu", "25 years", "2018", "the first naturalization law for the United States, the Naturalization Act of 1790", "the Colony of Virginia", "Arkansas", "December 24, 1836", "at slightly different times when viewed from different points on Earth", "during the American Civil War", "the Executive Residence of the White House Complex", "420 mg", "Timothy B. Schmit", "March 2, 2016", "Thirty years", "Woody Paige", "Allison Janney", "$75,000", "four", "Blood is the New Black", "between the stomach and the large intestine", "USS Chesapeake", "18 - season", "to offer the hope that a happy day being marked would recur many more times", "President Lyndon Johnson", "Sarah Palin's", "al Pacino,", "Passion fruit", "Kinnairdy Castle", "Kevin Smith", "Kona coast of the island of Hawai\u02bb i", "his business dealings for possible securities violations", "40", "16", "John Deere", "alpine skiing", "dollop", "algiers"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6843351275917064}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.7368421052631579, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.20000000000000004, 0.5, 1.0, 1.0, 0.060606060606060615, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.20000000000000004, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-9445", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-779", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-824", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-1156", "mrqa_hotpotqa-validation-5117", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-880", "mrqa_searchqa-validation-2656"], "SR": 0.59375, "CSR": 0.5604166666666667, "retrieved_ids": ["mrqa_squad-train-27077", "mrqa_squad-train-62819", "mrqa_squad-train-8144", "mrqa_squad-train-10873", "mrqa_squad-train-68146", "mrqa_squad-train-27664", "mrqa_squad-train-47296", "mrqa_squad-train-51018", "mrqa_squad-train-41543", "mrqa_squad-train-1819", "mrqa_squad-train-66462", "mrqa_squad-train-11875", "mrqa_squad-train-13129", "mrqa_squad-train-43385", "mrqa_squad-train-44895", "mrqa_squad-train-35643", "mrqa_squad-train-84023", "mrqa_squad-train-47256", "mrqa_squad-train-32380", "mrqa_squad-train-18480", "mrqa_squad-train-1675", "mrqa_squad-train-16306", "mrqa_squad-train-47587", "mrqa_squad-train-20396", "mrqa_squad-train-60102", "mrqa_squad-train-45724", "mrqa_squad-train-11026", "mrqa_squad-train-38517", "mrqa_squad-train-11080", "mrqa_squad-train-79252", "mrqa_squad-train-10743", "mrqa_squad-train-23608", "mrqa_newsqa-validation-927", "mrqa_triviaqa-validation-5855", "mrqa_naturalquestions-validation-6453", "mrqa_newsqa-validation-3982", "mrqa_hotpotqa-validation-957", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-8175", "mrqa_triviaqa-validation-4798", "mrqa_hotpotqa-validation-2887", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-1782", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3557", "mrqa_hotpotqa-validation-2969", "mrqa_naturalquestions-validation-3", "mrqa_hotpotqa-validation-5403", "mrqa_hotpotqa-validation-1996", "mrqa_naturalquestions-validation-2210", "mrqa_newsqa-validation-3227", "mrqa_searchqa-validation-4495", "mrqa_naturalquestions-validation-9818", "mrqa_hotpotqa-validation-2117", "mrqa_newsqa-validation-2384", "mrqa_squad-validation-8164", "mrqa_newsqa-validation-1123", "mrqa_naturalquestions-validation-8907", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-4865", "mrqa_squad-validation-2145", "mrqa_naturalquestions-validation-1912", "mrqa_hotpotqa-validation-4879"], "EFR": 0.9615384615384616, "Overall": 0.7311879006410257}, {"timecode": 45, "before_eval_results": {"predictions": ["locomotion", "The genetic basis", "Cheryl Campbell", "the Satavahanas", "Michael Moriarty", "Canada", "111", "Virginia", "RAM", "1940", "Doug Diemoz", "Charlene Holt", "David Kaye", "Thomas Edison", "Hedwig", "O'Meara", "the Atlanta Hawks", "Missi Hale", "2001", "Eddie Murphy", "Portugal. The Man", "Theodore Roosevelt", "1940", "parthenogenic", "Lyle Waggoner", "in Paradise, Nevada", "Coconut Cove", "the season finale", "the biblical name of a Canaanite god associated with child sacrifice", "Mercedes - wagen", "10 June 1940", "Bill Pullman", "Great G minor symphony", "using a baby as bait", "April 2010", "786 -- 802", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Franklin and Wake counties in the U.S. state of North Carolina", "Justin Timberlake", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Bartemius Crouch Jr", "Martin Lawrence", "Naomi", "the priests and virgins", "Jurchen Aisin Gioro clan", "Muhammad", "Americans", "August 22, 1980", "Sergeant Himmelstoss", "Michael Rooker", "the next episode, `` Seeing Red ''", "luster", "bushfires", "adrian Edmondson", "Figaro", "Big 12 Conference", "Debbie Reynolds", "Gulf of Aden,", "the legitimacy of that race.", "Salt Lake City, Utah,", "Java", "OPEC", "Kansas City", "Current TV"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6431081878568292}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.5, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9600000000000001, 0.4347826086956522, 1.0, 0.9696969696969697, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-9675", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-9639", "mrqa_naturalquestions-validation-1327", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-138", "mrqa_triviaqa-validation-5296", "mrqa_newsqa-validation-637", "mrqa_newsqa-validation-903", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4457", "mrqa_newsqa-validation-2590"], "SR": 0.515625, "CSR": 0.5594429347826086, "retrieved_ids": ["mrqa_squad-train-47398", "mrqa_squad-train-8820", "mrqa_squad-train-27246", "mrqa_squad-train-73264", "mrqa_squad-train-29750", "mrqa_squad-train-15422", "mrqa_squad-train-13421", "mrqa_squad-train-65785", "mrqa_squad-train-69409", "mrqa_squad-train-66064", "mrqa_squad-train-80894", "mrqa_squad-train-18623", "mrqa_squad-train-39113", "mrqa_squad-train-14968", "mrqa_squad-train-53534", "mrqa_squad-train-52858", "mrqa_squad-train-62934", "mrqa_squad-train-71115", "mrqa_squad-train-20950", "mrqa_squad-train-62477", "mrqa_squad-train-79176", "mrqa_squad-train-10529", "mrqa_squad-train-15139", "mrqa_squad-train-42099", "mrqa_squad-train-83328", "mrqa_squad-train-54560", "mrqa_squad-train-69807", "mrqa_squad-train-12515", "mrqa_squad-train-68674", "mrqa_squad-train-43001", "mrqa_squad-train-81589", "mrqa_squad-train-43805", "mrqa_naturalquestions-validation-4132", "mrqa_searchqa-validation-5038", "mrqa_newsqa-validation-2606", "mrqa_searchqa-validation-12440", "mrqa_naturalquestions-validation-6524", "mrqa_hotpotqa-validation-3090", "mrqa_triviaqa-validation-5294", "mrqa_squad-validation-6477", "mrqa_squad-validation-2595", "mrqa_naturalquestions-validation-5912", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-6087", "mrqa_squad-validation-7708", "mrqa_triviaqa-validation-6846", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-3446", "mrqa_hotpotqa-validation-1864", "mrqa_searchqa-validation-398", "mrqa_searchqa-validation-3203", "mrqa_squad-validation-2094", "mrqa_newsqa-validation-1712", "mrqa_squad-validation-589", "mrqa_hotpotqa-validation-3944", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-371", "mrqa_triviaqa-validation-2926", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-4118", "mrqa_hotpotqa-validation-5296", "mrqa_squad-validation-2328", "mrqa_hotpotqa-validation-1843", "mrqa_naturalquestions-validation-2503"], "EFR": 0.9354838709677419, "Overall": 0.7257822361500701}, {"timecode": 46, "before_eval_results": {"predictions": ["the main porch", "Pastoral farming", "American country music group The Nitty Gritty Dirt Band", "right name tape", "Luther Ingram", "Taron Egerton", "Spencer Treat Clark", "Ishaan Anirudh Sinha", "Ray Harroun", "Shiji no yukikai", "Clarence Anglin", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane, resulting in an electrical potential or ion concentration difference across the membrane", "Copernicus, Galileo and Kepler", "a set of related data", "the President pro tempore", "capillary action", "electron donors", "T.J. Miller", "Ren\u00e9 Descartes", "2006 -- 04 season", "right", "1955", "the town of Acolman, just north of Mexico City", "23 September 1889", "indigenous to many forested parts of the world", "January 2018", "Colon Street", "The higher the vapor pressure of a liquid at a given temperature", "adenine ( A ), uracil ( U ), guanine ( G ), and cytosine ( C )", "1923", "Hugh S. Johnson", "Somatic motor neurons", "Lord Banquo", "harm - joy", "lead", "al - khimar", "291", "Anthony Hopkins", "the middle of the 15th century", "Ingrid Bergman", "political ideology", "c. 1000 AD", "Identification of alternative plans / policies", "Missouri River", "2,140 kilometres ( 1,330 mi )", "Anakin Luke", "private sector", "the head of the United States Department of Justice per 28 U.S.C. \u00a7503", "July 22, 2017", "C\u03bc and C\u03b4", "August 29, 2017", "Beaujolais Nouveau", "Edward Woodward", "\"Swan Lake\"", "Lake Wallace", "Paul W. S. Anderson", "1866", "43 percent", "the world's tallest building,", "due process rights for detainees held at the U.S. facility in Guant Bay, Cuba,", "victory", "the Vedas", "Gertrude Stein", "Ilkley"], "metric_results": {"EM": 0.515625, "QA-F1": 0.606089917027417}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5555555555555556, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-4868", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-2956", "mrqa_naturalquestions-validation-10631", "mrqa_naturalquestions-validation-5602", "mrqa_naturalquestions-validation-384", "mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-6519", "mrqa_naturalquestions-validation-1884", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-5903", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-4197", "mrqa_triviaqa-validation-4711", "mrqa_hotpotqa-validation-1605", "mrqa_newsqa-validation-3835", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-4201", "mrqa_searchqa-validation-3518"], "SR": 0.515625, "CSR": 0.5585106382978724, "retrieved_ids": ["mrqa_squad-train-45826", "mrqa_squad-train-3449", "mrqa_squad-train-62976", "mrqa_squad-train-35786", "mrqa_squad-train-50702", "mrqa_squad-train-52216", "mrqa_squad-train-50135", "mrqa_squad-train-59783", "mrqa_squad-train-67571", "mrqa_squad-train-10803", "mrqa_squad-train-65652", "mrqa_squad-train-54573", "mrqa_squad-train-64020", "mrqa_squad-train-55069", "mrqa_squad-train-7391", "mrqa_squad-train-19797", "mrqa_squad-train-9658", "mrqa_squad-train-40536", "mrqa_squad-train-23590", "mrqa_squad-train-48110", "mrqa_squad-train-74778", "mrqa_squad-train-8189", "mrqa_squad-train-85900", "mrqa_squad-train-71180", "mrqa_squad-train-6010", "mrqa_squad-train-52364", "mrqa_squad-train-55457", "mrqa_squad-train-78857", "mrqa_squad-train-39407", "mrqa_squad-train-13729", "mrqa_squad-train-20186", "mrqa_squad-train-49947", "mrqa_hotpotqa-validation-1011", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2884", "mrqa_naturalquestions-validation-3288", "mrqa_newsqa-validation-1547", "mrqa_naturalquestions-validation-359", "mrqa_newsqa-validation-2509", "mrqa_naturalquestions-validation-8239", "mrqa_searchqa-validation-12609", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-6592", "mrqa_naturalquestions-validation-2813", "mrqa_newsqa-validation-3915", "mrqa_triviaqa-validation-575", "mrqa_searchqa-validation-7086", "mrqa_triviaqa-validation-5209", "mrqa_newsqa-validation-4201", "mrqa_naturalquestions-validation-1378", "mrqa_newsqa-validation-551", "mrqa_triviaqa-validation-5919", "mrqa_triviaqa-validation-3940", "mrqa_newsqa-validation-1855", "mrqa_hotpotqa-validation-3395", "mrqa_newsqa-validation-859", "mrqa_newsqa-validation-2491", "mrqa_naturalquestions-validation-5825", "mrqa_triviaqa-validation-1125", "mrqa_naturalquestions-validation-801", "mrqa_newsqa-validation-1330", "mrqa_triviaqa-validation-6580", "mrqa_searchqa-validation-709"], "EFR": 0.9032258064516129, "Overall": 0.719144163949897}, {"timecode": 47, "before_eval_results": {"predictions": ["2014", "Tim Russert", "Sebastian Lund ( Rob Kerkovich )", "Celtic became the first British team to win the competition, coming back from 1 -- 0 down after a Sandro Mazzola penalty to beat Internazionale 2 -- 1 in the Est\u00e1dio Nacional in Lisbon", "1978", "two", "September 6, 2019", "Russell Huxtable", "September 19, 2017", "Wallace is a Scottish surname derived from the Anglo - Norman French waleis", "31 October 1972", "23 September 1889", "Speaker of the House of Representatives", "Pittsburgh", "frontal lobe", "the 1940s", "increased productivity, trade, and secular economic trends", "2 %", "approximately 5 liters, with females generally having less blood volume than males", "G -- Games", "the 17th episode in the third season", "the financial statement showing a firm's assets, liabilities and equity ( capital ) at a set point in time, usually the end of the fiscal year reported on the accompanying income statement", "the New York Yankees", "94 by 50 feet", "Sam Waterston", "the realm of the Valar in Aman", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak )", "bohrium", "Shastri", "the main road through the gated community of Pebble Beach", "a place of trade, entertainment, and education", "electron pairs", "November 2014", "Lewis Carroll", "Janis Joplin", "the South Pacific Ocean", "T'Pau", "Ethiopia ( Abyssinia ), the Dervish state ( a portion of present - day Somalia ) and Liberia still being independent", "Blue laws", "in South America", "Edgar Lungu", "The Paris Sisters", "An optional message body", "Yes", "an alien mechanoid being that Will first encounters on the planet that his family crash lands on", "the centre of Munich", "Gary Grimes as Hermie, Jerry Houser as his best friend Oscy, Oliver Conant as their Nerdy young friend Benjie", "1998", "Thomas Chisholm", "Tommy James", "nausea", "credit issues with government debt and not just credit problems  detonating in the financial systems", "\"The best is yet to come.\"", "Chattahoochee", "Patterns of Sexual Behavior", "france", "Argentina", "an ice jam", "Facebook and Google,", "decaffeinated", "One Flew Over the Cuckoo's Nest", "Stephen Hawking", "20%"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5510423199182335}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.0689655172413793, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.18181818181818182, 0.8, 1.0, 0.6666666666666666, 0.125, 1.0, 0.28571428571428575, 0.4, 0.08695652173913042, 0.33333333333333337, 0.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.1904761904761905, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-681", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-3602", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-3170", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-6466", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-7015", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-5928", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-10259", "mrqa_naturalquestions-validation-7228", "mrqa_naturalquestions-validation-2540", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-485", "mrqa_triviaqa-validation-4834", "mrqa_triviaqa-validation-2385", "mrqa_hotpotqa-validation-114", "mrqa_hotpotqa-validation-2819", "mrqa_newsqa-validation-3459", "mrqa_searchqa-validation-14104", "mrqa_newsqa-validation-2608"], "SR": 0.421875, "CSR": 0.5556640625, "retrieved_ids": ["mrqa_squad-train-49999", "mrqa_squad-train-10901", "mrqa_squad-train-44510", "mrqa_squad-train-34880", "mrqa_squad-train-69266", "mrqa_squad-train-63373", "mrqa_squad-train-56909", "mrqa_squad-train-714", "mrqa_squad-train-59592", "mrqa_squad-train-43761", "mrqa_squad-train-32822", "mrqa_squad-train-53782", "mrqa_squad-train-81200", "mrqa_squad-train-8859", "mrqa_squad-train-23938", "mrqa_squad-train-40376", "mrqa_squad-train-50093", "mrqa_squad-train-38048", "mrqa_squad-train-67068", "mrqa_squad-train-80328", "mrqa_squad-train-24408", "mrqa_squad-train-15574", "mrqa_squad-train-17305", "mrqa_squad-train-42615", "mrqa_squad-train-6507", "mrqa_squad-train-25748", "mrqa_squad-train-17389", "mrqa_squad-train-5262", "mrqa_squad-train-47328", "mrqa_squad-train-12974", "mrqa_squad-train-48774", "mrqa_squad-train-49279", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-3769", "mrqa_triviaqa-validation-6046", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-230", "mrqa_searchqa-validation-5755", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-8005", "mrqa_newsqa-validation-1008", "mrqa_squad-validation-4000", "mrqa_searchqa-validation-11621", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-779", "mrqa_triviaqa-validation-970", "mrqa_triviaqa-validation-7083", "mrqa_newsqa-validation-2205", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-3497", "mrqa_newsqa-validation-81", "mrqa_naturalquestions-validation-2143", "mrqa_triviaqa-validation-4458", "mrqa_naturalquestions-validation-1439", "mrqa_newsqa-validation-765", "mrqa_squad-validation-2943", "mrqa_triviaqa-validation-4668", "mrqa_squad-validation-7320", "mrqa_naturalquestions-validation-6201", "mrqa_newsqa-validation-2471", "mrqa_squad-validation-7136", "mrqa_hotpotqa-validation-5296", "mrqa_naturalquestions-validation-3485", "mrqa_triviaqa-validation-2669"], "EFR": 0.972972972972973, "Overall": 0.7325242820945945}, {"timecode": 48, "before_eval_results": {"predictions": ["Democratic VP candidate", "Stuttgart", "three", "Long troop deployments", "well over 1,000 pounds", "This is not a project for commercial gain.", "Dennis Davern,", "the shoreline of the city of Quebradillas.", "Eleven people", "a man", "The prosecutor sought 18 years imprisonment,", "anti-trust laws.", "Ferraris, a Lamborghini and an Acura NSX", "eight", "1831", "frees up a place", "Michael Krane,", "Russian bombers", "three gunmen outside the facility where aid distribution is coordinated.", "all day starting at 10 a.m.", "2-1", "more than 200.", "\"It's just going to become part of the fabric of the fashion imagery of pop culture,", "a one-shot victory in the Bob Hope Classic", "test scores and graduation rates", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "\"It was perfect work, ready to go for the stimulus package,\"", "US Airways Flight 1549", "the southern city of Naples", "racial intolerance", "Friday,", "\"Twilight\"", "Robert Kimmitt", "22-year-old", "the couple's", "in Nuevo Leon, one of two states in northeastern Mexico where drug cartel members blocked roads with hijacked vehicles Thursday and Friday to prevent military reinforcements from arriving.", "10", "Retailers", "Anil Kapoor.", "Samoa", "authorizing killings and kidnappings by paramilitary death squads.", "E. coli", "Ma Khin Khin Leh,", "lounge music", "\"The train ride up there is spectacular.", "1998", "\"Drug trafficking is a transnational threat, and therefore national initiatives have their limitations,\"", "London's O2 arena", "The EU naval force", "Cyprus in Parma.", "the group must recommend a national policy on the subject that's designed to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Membership is believed to cost between $10,000 and $30,000", "31 December 1600", "Number 4, Privet Drive, Little Whinging in Surrey, England", "fructose", "$1000", "a fishing hat", "five times", "E Street Band", "England", "the Ojibwe", "salt", "Everybody Have Fun Tonight", "the foreign exchange market (FX )"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6206524939521263}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.33333333333333337, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.8, 0.25, 0.11764705882352941, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.05714285714285715, 1.0, 0.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.4666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-333", "mrqa_newsqa-validation-828", "mrqa_newsqa-validation-2048", "mrqa_newsqa-validation-3918", "mrqa_newsqa-validation-3469", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-541", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-2858", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2346", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-1488", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-1649", "mrqa_newsqa-validation-4169", "mrqa_naturalquestions-validation-4768", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-2918", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-6597", "mrqa_searchqa-validation-12129"], "SR": 0.53125, "CSR": 0.5551658163265306, "retrieved_ids": ["mrqa_squad-train-29145", "mrqa_squad-train-9559", "mrqa_squad-train-27815", "mrqa_squad-train-21957", "mrqa_squad-train-48497", "mrqa_squad-train-84629", "mrqa_squad-train-7422", "mrqa_squad-train-25901", "mrqa_squad-train-46061", "mrqa_squad-train-43702", "mrqa_squad-train-11448", "mrqa_squad-train-55321", "mrqa_squad-train-57763", "mrqa_squad-train-63627", "mrqa_squad-train-59222", "mrqa_squad-train-42466", "mrqa_squad-train-25341", "mrqa_squad-train-85201", "mrqa_squad-train-5425", "mrqa_squad-train-29260", "mrqa_squad-train-14791", "mrqa_squad-train-21741", "mrqa_squad-train-54582", "mrqa_squad-train-45418", "mrqa_squad-train-50425", "mrqa_squad-train-14205", "mrqa_squad-train-29638", "mrqa_squad-train-58271", "mrqa_squad-train-7464", "mrqa_squad-train-68200", "mrqa_squad-train-22335", "mrqa_squad-train-66918", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-6821", "mrqa_newsqa-validation-1331", "mrqa_naturalquestions-validation-9092", "mrqa_squad-validation-2368", "mrqa_hotpotqa-validation-1528", "mrqa_squad-validation-9764", "mrqa_naturalquestions-validation-5469", "mrqa_squad-validation-9458", "mrqa_hotpotqa-validation-741", "mrqa_searchqa-validation-7106", "mrqa_squad-validation-3130", "mrqa_squad-validation-1195", "mrqa_newsqa-validation-1360", "mrqa_naturalquestions-validation-2476", "mrqa_newsqa-validation-1983", "mrqa_naturalquestions-validation-6166", "mrqa_triviaqa-validation-2199", "mrqa_squad-validation-978", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-9887", "mrqa_squad-validation-606", "mrqa_searchqa-validation-1770", "mrqa_naturalquestions-validation-10613", "mrqa_triviaqa-validation-102", "mrqa_naturalquestions-validation-3760", "mrqa_newsqa-validation-445", "mrqa_newsqa-validation-1413", "mrqa_hotpotqa-validation-4864", "mrqa_newsqa-validation-3035", "mrqa_triviaqa-validation-4711", "mrqa_searchqa-validation-11991"], "EFR": 0.9666666666666667, "Overall": 0.7311633715986394}, {"timecode": 49, "before_eval_results": {"predictions": ["Pierre Laval", "Beckett", "james johnson", "Michaela Tabb", "Alpha Orionis", "Edward VIII", "james zavoroni", "falcon", "Stephen Fry", "Benghazi", "Darshaan", "Robinson", "vinaya", "The Daily Mail", "William Shakespeare", "HP.52 Hampden", "death", "Rod Laver", "Texas", "slower", "the Strait of Messina", "hoy", "thematic and country-specific", "Brian Deane", "car", "Emilia Fox", "October", "PETER FRAMPTON LYRICS", "catherine zeta", "South Africa", "Jim Braddock", "Mediterranean", "1839", "bony fish", "Gibeon", "Hawaii", "vomiting", "Hugo von Hofmannsthal", "sperm", "Syria", "penguins", "golf", "purple coneflower", "Amnesty International", "Oliver Wendell \" Spearchucker\" Jones", "her skills", "the Kingdom of Lesotho", "Variations", "Mauricio Pochettino", "the Duke of Edinburgh", "myxoma", "the season - five premiere episode `` Second Opinion ''", "The U.S. state of Georgia", "Parker's pregnancy at the time of filming", "Dame Eileen June Atkins, DBE", "Battle of Chester", "James Gandolfini", "Bill Stanton", "Los Angeles Angels", "56,", "Twenty three", "the howitzer", "a circle", "Patty Duke"], "metric_results": {"EM": 0.5, "QA-F1": 0.5670138888888889}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 0.6666666666666667, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4624", "mrqa_triviaqa-validation-4974", "mrqa_triviaqa-validation-6271", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-50", "mrqa_triviaqa-validation-4875", "mrqa_triviaqa-validation-1076", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-5470", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-7128", "mrqa_triviaqa-validation-1948", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-5477", "mrqa_triviaqa-validation-3752", "mrqa_triviaqa-validation-1583", "mrqa_triviaqa-validation-5377", "mrqa_triviaqa-validation-4066", "mrqa_triviaqa-validation-52", "mrqa_triviaqa-validation-5691", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-3338", "mrqa_triviaqa-validation-7264", "mrqa_triviaqa-validation-2667", "mrqa_triviaqa-validation-4729", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-2853", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-7507", "mrqa_hotpotqa-validation-831", "mrqa_searchqa-validation-12134", "mrqa_searchqa-validation-6004"], "SR": 0.5, "CSR": 0.5540625, "retrieved_ids": ["mrqa_squad-train-7285", "mrqa_squad-train-10417", "mrqa_squad-train-44457", "mrqa_squad-train-3860", "mrqa_squad-train-49160", "mrqa_squad-train-72744", "mrqa_squad-train-2537", "mrqa_squad-train-16070", "mrqa_squad-train-84186", "mrqa_squad-train-32142", "mrqa_squad-train-27354", "mrqa_squad-train-74090", "mrqa_squad-train-60375", "mrqa_squad-train-77080", "mrqa_squad-train-13735", "mrqa_squad-train-85730", "mrqa_squad-train-69923", "mrqa_squad-train-36712", "mrqa_squad-train-56828", "mrqa_squad-train-84127", "mrqa_squad-train-80750", "mrqa_squad-train-85399", "mrqa_squad-train-75619", "mrqa_squad-train-36580", "mrqa_squad-train-21162", "mrqa_squad-train-54209", "mrqa_squad-train-63164", "mrqa_squad-train-8513", "mrqa_squad-train-6236", "mrqa_squad-train-48857", "mrqa_squad-train-17770", "mrqa_squad-train-836", "mrqa_triviaqa-validation-7033", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-1336", "mrqa_searchqa-validation-4179", "mrqa_newsqa-validation-3459", "mrqa_triviaqa-validation-285", "mrqa_squad-validation-8990", "mrqa_naturalquestions-validation-5928", "mrqa_newsqa-validation-3415", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-801", "mrqa_squad-validation-1195", "mrqa_naturalquestions-validation-10156", "mrqa_searchqa-validation-6150", "mrqa_naturalquestions-validation-7967", "mrqa_newsqa-validation-2723", "mrqa_newsqa-validation-2731", "mrqa_searchqa-validation-9183", "mrqa_newsqa-validation-1144", "mrqa_naturalquestions-validation-4354", "mrqa_newsqa-validation-2984", "mrqa_naturalquestions-validation-3491", "mrqa_searchqa-validation-13595", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-4197", "mrqa_triviaqa-validation-2486", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-4436", "mrqa_hotpotqa-validation-3141", "mrqa_naturalquestions-validation-3922", "mrqa_triviaqa-validation-2316", "mrqa_hotpotqa-validation-4389"], "EFR": 0.875, "Overall": 0.712609375}, {"timecode": 50, "UKR": 0.798828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1041", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1216", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-1368", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1681", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-176", "mrqa_hotpotqa-validation-1919", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2273", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2402", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-261", "mrqa_hotpotqa-validation-2705", "mrqa_hotpotqa-validation-2735", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2769", "mrqa_hotpotqa-validation-2792", "mrqa_hotpotqa-validation-2841", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-2848", "mrqa_hotpotqa-validation-2986", "mrqa_hotpotqa-validation-3018", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3136", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3355", "mrqa_hotpotqa-validation-347", "mrqa_hotpotqa-validation-3714", "mrqa_hotpotqa-validation-3721", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-423", "mrqa_hotpotqa-validation-4253", "mrqa_hotpotqa-validation-4269", "mrqa_hotpotqa-validation-4295", "mrqa_hotpotqa-validation-430", "mrqa_hotpotqa-validation-4418", "mrqa_hotpotqa-validation-4431", "mrqa_hotpotqa-validation-4459", "mrqa_hotpotqa-validation-4526", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-503", "mrqa_hotpotqa-validation-5339", "mrqa_hotpotqa-validation-5483", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5869", "mrqa_hotpotqa-validation-594", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10091", "mrqa_naturalquestions-validation-10298", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10411", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-10513", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-10631", "mrqa_naturalquestions-validation-10670", "mrqa_naturalquestions-validation-1190", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-1519", "mrqa_naturalquestions-validation-1539", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2670", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2855", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3170", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-3935", "mrqa_naturalquestions-validation-4036", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4135", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-435", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-4917", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5928", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6432", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6778", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-681", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7976", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-8207", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-86", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-8761", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9299", "mrqa_naturalquestions-validation-9607", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9870", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-9921", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-1064", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1136", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-1200", "mrqa_newsqa-validation-1232", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-139", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1550", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-1688", "mrqa_newsqa-validation-1693", "mrqa_newsqa-validation-1746", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1851", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1896", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1908", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1995", "mrqa_newsqa-validation-2010", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2026", "mrqa_newsqa-validation-2048", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2244", "mrqa_newsqa-validation-2250", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-231", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2384", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2477", "mrqa_newsqa-validation-2546", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2802", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-3016", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-3327", "mrqa_newsqa-validation-333", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3526", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3728", "mrqa_newsqa-validation-3785", "mrqa_newsqa-validation-3816", "mrqa_newsqa-validation-3822", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-3847", "mrqa_newsqa-validation-389", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3917", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3957", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-4054", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4169", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-483", "mrqa_newsqa-validation-623", "mrqa_newsqa-validation-641", "mrqa_newsqa-validation-641", "mrqa_newsqa-validation-643", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-693", "mrqa_newsqa-validation-715", "mrqa_newsqa-validation-720", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-783", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-962", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-1030", "mrqa_searchqa-validation-10918", "mrqa_searchqa-validation-11406", "mrqa_searchqa-validation-11621", "mrqa_searchqa-validation-11836", "mrqa_searchqa-validation-1227", "mrqa_searchqa-validation-12440", "mrqa_searchqa-validation-12493", "mrqa_searchqa-validation-1261", "mrqa_searchqa-validation-12864", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-13257", "mrqa_searchqa-validation-13456", "mrqa_searchqa-validation-1357", "mrqa_searchqa-validation-14104", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-15568", "mrqa_searchqa-validation-15671", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-1898", "mrqa_searchqa-validation-1999", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-2141", "mrqa_searchqa-validation-2143", "mrqa_searchqa-validation-217", "mrqa_searchqa-validation-3018", "mrqa_searchqa-validation-3479", "mrqa_searchqa-validation-3597", "mrqa_searchqa-validation-4044", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-515", "mrqa_searchqa-validation-5477", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-5725", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-6181", "mrqa_searchqa-validation-6304", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-709", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-9185", "mrqa_searchqa-validation-9394", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9846", "mrqa_squad-validation-10000", "mrqa_squad-validation-10097", "mrqa_squad-validation-10135", "mrqa_squad-validation-10184", "mrqa_squad-validation-10326", "mrqa_squad-validation-10339", "mrqa_squad-validation-10496", "mrqa_squad-validation-1240", "mrqa_squad-validation-1269", "mrqa_squad-validation-1408", "mrqa_squad-validation-1708", "mrqa_squad-validation-1713", "mrqa_squad-validation-1765", "mrqa_squad-validation-1890", "mrqa_squad-validation-2019", "mrqa_squad-validation-2328", "mrqa_squad-validation-2365", "mrqa_squad-validation-2456", "mrqa_squad-validation-2595", "mrqa_squad-validation-2751", "mrqa_squad-validation-280", "mrqa_squad-validation-2886", "mrqa_squad-validation-2897", "mrqa_squad-validation-2943", "mrqa_squad-validation-2953", "mrqa_squad-validation-2959", "mrqa_squad-validation-3021", "mrqa_squad-validation-305", "mrqa_squad-validation-3184", "mrqa_squad-validation-3364", "mrqa_squad-validation-3406", "mrqa_squad-validation-3444", "mrqa_squad-validation-3551", "mrqa_squad-validation-3608", "mrqa_squad-validation-3796", "mrqa_squad-validation-3812", "mrqa_squad-validation-3863", "mrqa_squad-validation-3909", "mrqa_squad-validation-402", "mrqa_squad-validation-4265", "mrqa_squad-validation-4298", "mrqa_squad-validation-4326", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4528", "mrqa_squad-validation-4583", "mrqa_squad-validation-4630", "mrqa_squad-validation-491", "mrqa_squad-validation-5004", "mrqa_squad-validation-5128", "mrqa_squad-validation-5134", "mrqa_squad-validation-5180", "mrqa_squad-validation-5479", "mrqa_squad-validation-5644", "mrqa_squad-validation-5692", "mrqa_squad-validation-5737", "mrqa_squad-validation-5781", "mrqa_squad-validation-5836", "mrqa_squad-validation-5852", "mrqa_squad-validation-6017", "mrqa_squad-validation-6089", "mrqa_squad-validation-6228", "mrqa_squad-validation-6353", "mrqa_squad-validation-6494", "mrqa_squad-validation-6875", "mrqa_squad-validation-71", "mrqa_squad-validation-7205", "mrqa_squad-validation-7297", "mrqa_squad-validation-7338", "mrqa_squad-validation-7434", "mrqa_squad-validation-7492", "mrqa_squad-validation-7613", "mrqa_squad-validation-7781", "mrqa_squad-validation-7993", "mrqa_squad-validation-8134", "mrqa_squad-validation-8232", "mrqa_squad-validation-8282", "mrqa_squad-validation-893", "mrqa_squad-validation-908", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9193", "mrqa_squad-validation-9234", "mrqa_squad-validation-9367", "mrqa_squad-validation-9376", "mrqa_squad-validation-9461", "mrqa_squad-validation-9581", "mrqa_squad-validation-959", "mrqa_squad-validation-9614", "mrqa_squad-validation-9666", "mrqa_squad-validation-9771", "mrqa_squad-validation-9900", "mrqa_squad-validation-9959", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1282", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1479", "mrqa_triviaqa-validation-1619", "mrqa_triviaqa-validation-1683", "mrqa_triviaqa-validation-1883", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-2024", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-2229", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-260", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-2712", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3187", "mrqa_triviaqa-validation-3301", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-358", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-3809", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-4178", "mrqa_triviaqa-validation-4664", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-4759", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4886", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-52", "mrqa_triviaqa-validation-5261", "mrqa_triviaqa-validation-5294", "mrqa_triviaqa-validation-5377", "mrqa_triviaqa-validation-5381", "mrqa_triviaqa-validation-55", "mrqa_triviaqa-validation-5500", "mrqa_triviaqa-validation-5500", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-5726", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-5943", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6665", "mrqa_triviaqa-validation-6748", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-7038", "mrqa_triviaqa-validation-7374", "mrqa_triviaqa-validation-7407", "mrqa_triviaqa-validation-7508", "mrqa_triviaqa-validation-7560", "mrqa_triviaqa-validation-7619", "mrqa_triviaqa-validation-899"], "OKR": 0.90234375, "KG": 0.4921875, "before_eval_results": {"predictions": ["A Christmas Carol", "july zaks", "Bangladesh", "Dan Dare", "fred fred", "Denmark", "f\u00fcr sexualwissenschaft", "The Rocky Horror Picture Show", "20th century", "Prince Albert", "bill", "Pakistan", "spider", "Popeye", "llangollen", "Bull Moose Party", "Genoa", "Shakespears Sister", "james boswell", "Jamaica", "Jessica Simpson", "fred stooge", "earthquake", "Campania", "Charlie Chan", "Chongqing", "colette", "Louis XVIII", "Anne Boleyn", "playoff basketball", "Philippines", "127 Hours", "Cannes Film Festival", "fred Perry", "london", "sarah armstrong", "god of helius", "widow", "virtual images", "Wolfgang Amadeus Mozart", "Anne-Marie Duff", "Joan Rivers", "milk or water", "fourth", "phobias", "soap", "guitar", "Toby", "sarmiento", "kenny Everett", "Fenn Street School", "In 1804", "spraying the whole atmosphere as if drawing letters in the air", "November 3, 2007", "John Bingham", "Marktown", "Bit Instant", "well over 1,000 pounds", "one of Europe's most experienced providers of carbon offsets,", "while admitting they learned of the death from TV news coverage,", "W.C. Handy", "Lamb of God", "feet", "1978"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5688244047619047}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, true, false, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6594", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-602", "mrqa_triviaqa-validation-5137", "mrqa_triviaqa-validation-1988", "mrqa_triviaqa-validation-4996", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-206", "mrqa_triviaqa-validation-4150", "mrqa_triviaqa-validation-23", "mrqa_triviaqa-validation-605", "mrqa_triviaqa-validation-7424", "mrqa_triviaqa-validation-2073", "mrqa_triviaqa-validation-5161", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-5690", "mrqa_triviaqa-validation-5182", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-94", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-5624", "mrqa_naturalquestions-validation-2960", "mrqa_naturalquestions-validation-3323", "mrqa_hotpotqa-validation-4319", "mrqa_hotpotqa-validation-5281", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-3244", "mrqa_searchqa-validation-10670"], "SR": 0.484375, "CSR": 0.5526960784313726, "retrieved_ids": ["mrqa_squad-train-36186", "mrqa_squad-train-28516", "mrqa_squad-train-73013", "mrqa_squad-train-21554", "mrqa_squad-train-84567", "mrqa_squad-train-67377", "mrqa_squad-train-62347", "mrqa_squad-train-57865", "mrqa_squad-train-25269", "mrqa_squad-train-21432", "mrqa_squad-train-16519", "mrqa_squad-train-4473", "mrqa_squad-train-54342", "mrqa_squad-train-58928", "mrqa_squad-train-62530", "mrqa_squad-train-65804", "mrqa_squad-train-38580", "mrqa_squad-train-11579", "mrqa_squad-train-1169", "mrqa_squad-train-77324", "mrqa_squad-train-21645", "mrqa_squad-train-76918", "mrqa_squad-train-46438", "mrqa_squad-train-18985", "mrqa_squad-train-70009", "mrqa_squad-train-18632", "mrqa_squad-train-28364", "mrqa_squad-train-11284", "mrqa_squad-train-16562", "mrqa_squad-train-61422", "mrqa_squad-train-3057", "mrqa_squad-train-15656", "mrqa_newsqa-validation-3280", "mrqa_squad-validation-8195", "mrqa_newsqa-validation-2509", "mrqa_squad-validation-1235", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-3447", "mrqa_hotpotqa-validation-2769", "mrqa_hotpotqa-validation-4177", "mrqa_hotpotqa-validation-1681", "mrqa_newsqa-validation-2816", "mrqa_searchqa-validation-4851", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-681", "mrqa_searchqa-validation-6463", "mrqa_naturalquestions-validation-10040", "mrqa_squad-validation-4326", "mrqa_naturalquestions-validation-8907", "mrqa_naturalquestions-validation-9856", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-4006", "mrqa_naturalquestions-validation-9419", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-1378", "mrqa_newsqa-validation-2265", "mrqa_triviaqa-validation-2486", "mrqa_searchqa-validation-271", "mrqa_hotpotqa-validation-1182", "mrqa_naturalquestions-validation-10161", "mrqa_newsqa-validation-4064", "mrqa_hotpotqa-validation-3395"], "EFR": 0.9696969696969697, "Overall": 0.7431504846256685}, {"timecode": 51, "before_eval_results": {"predictions": ["Carthage", "blue", "Robin Ellis", "mortadella", "albus", "helium", "the base of the foot", "the natural world and mysticism", "ballando con le stelle", "South Pacific", "Agatha Christie", "b Bosnia and Herzegovina", "laos", "Sparta", "\" Morningtown Ride\"", "squash", "Northwestern University", "Turkey", "barry stanley and yvonne", "China", "diffusion", "hoggle", "Robben Island", "bukwus", "myrrh", "medium", "Libyan", "Rocky Marciano", "zsa zsa Gabor", "paul chukwuemeka Okogwu", "Ruth Ellis", "Egypt", "sparrow", "Eton College", "margot", "Siamese", "Aug. 24", "a Boojum", "bacall", "Valentine Dyall", "lauren bacall", "laos", "Opus Dei", "Flying Pickets", "Dry Ice", "Kenya", "disraeli", "cowscart", "norman tebbit", "reanne Evans", "blood", "ummat al - Islamiyah", "Rachel Kelly Tucker", "Honor\u00e9 Mirabeau", "Big Bad Wolf", "Daniel Radcliffe", "Steve Trevor", "President Obama", "Croatia", "Tom Hanks, Ayelet Zurer", "Curly Lambeau", "Curly Wurly", "Rosa Parks", "Mite Bird Mite"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6033482142857143}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-3495", "mrqa_triviaqa-validation-1947", "mrqa_triviaqa-validation-3456", "mrqa_triviaqa-validation-1517", "mrqa_triviaqa-validation-549", "mrqa_triviaqa-validation-7582", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-7618", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-503", "mrqa_triviaqa-validation-2110", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-7115", "mrqa_triviaqa-validation-5154", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-2705", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-4976", "mrqa_triviaqa-validation-1953", "mrqa_triviaqa-validation-6925", "mrqa_naturalquestions-validation-1455", "mrqa_hotpotqa-validation-2075", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-2456", "mrqa_searchqa-validation-11960"], "SR": 0.53125, "CSR": 0.5522836538461539, "retrieved_ids": ["mrqa_squad-train-16355", "mrqa_squad-train-55378", "mrqa_squad-train-30068", "mrqa_squad-train-727", "mrqa_squad-train-35693", "mrqa_squad-train-79764", "mrqa_squad-train-51806", "mrqa_squad-train-1230", "mrqa_squad-train-83977", "mrqa_squad-train-25871", "mrqa_squad-train-27064", "mrqa_squad-train-80461", "mrqa_squad-train-74212", "mrqa_squad-train-76632", "mrqa_squad-train-9620", "mrqa_squad-train-59460", "mrqa_squad-train-32344", "mrqa_squad-train-49236", "mrqa_squad-train-17426", "mrqa_squad-train-127", "mrqa_squad-train-68317", "mrqa_squad-train-8690", "mrqa_squad-train-1821", "mrqa_squad-train-46469", "mrqa_squad-train-73543", "mrqa_squad-train-18688", "mrqa_squad-train-54112", "mrqa_squad-train-81495", "mrqa_squad-train-76617", "mrqa_squad-train-17730", "mrqa_squad-train-57862", "mrqa_squad-train-27934", "mrqa_triviaqa-validation-1606", "mrqa_newsqa-validation-2346", "mrqa_hotpotqa-validation-5792", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-8239", "mrqa_squad-validation-6973", "mrqa_hotpotqa-validation-3721", "mrqa_squad-validation-7422", "mrqa_triviaqa-validation-2316", "mrqa_naturalquestions-validation-473", "mrqa_hotpotqa-validation-4319", "mrqa_naturalquestions-validation-8277", "mrqa_squad-validation-3130", "mrqa_naturalquestions-validation-4905", "mrqa_triviaqa-validation-4668", "mrqa_newsqa-validation-3210", "mrqa_triviaqa-validation-3418", "mrqa_triviaqa-validation-2781", "mrqa_searchqa-validation-7004", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-4143", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1403", "mrqa_triviaqa-validation-6828", "mrqa_naturalquestions-validation-5312", "mrqa_searchqa-validation-13600", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-7767", "mrqa_searchqa-validation-2463", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-340"], "EFR": 0.9333333333333333, "Overall": 0.7357952724358975}, {"timecode": 52, "before_eval_results": {"predictions": ["Ringo Starr", "Apprendi v. New Jersey", "Minnesota's 8th congressional district", "Erreway", "North Queensland", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "Pamelyn Wanda Ferdin", "Christian Kern", "The Social Network", "$10.5 million", "2017", "Dutch", "2014", "rapper", "Missouri", "Rochdale", "\"50 best cities to live in.\"", "Virginia", "\"The Godfather Part II\"", "two", "Rigoletto", "Scunthorpe", "Talib Kweli", "motor", "third", "1 September 1864", "Eugene O'Neill", "\"Brotherly Leader\" of the Great Socialist People's Libyan Arab Jamahiriya from 1977 to 2011", "U2", "side friction roller coaster", "Sofia the First", "Sufism", "$700 million", "Carl Mears", "Magnate", "The Saturdays", "The New York and New Jersey campaign", "Alabama", "John Joseph Travolta", "ice hockey", "Hong Kong", "2006", "Pacific Place", "jazz homeland section of New Orleans and on that part of the South in particular", "sarod", "2009", "Northern Ireland", "1999", "Russian Ark", "Delacorte Press", "the voice of The Beast", "1624", "April 4, 2017", "the original Star Wars film in 1977", "an ancient optical illusion toy", "nickel", "Vickers-Armstrong", "art scene", "bishops", "school", "lip service", "a white pine", "Henry Clay", "Richard Crispin Armitage"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6994791666666667}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8181818181818181, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.1818181818181818, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5562", "mrqa_hotpotqa-validation-4311", "mrqa_hotpotqa-validation-1351", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-2325", "mrqa_hotpotqa-validation-1044", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-3442", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-1273", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-2802", "mrqa_naturalquestions-validation-2906", "mrqa_naturalquestions-validation-3422", "mrqa_triviaqa-validation-3348", "mrqa_triviaqa-validation-6834", "mrqa_triviaqa-validation-468", "mrqa_newsqa-validation-1688", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-11977"], "SR": 0.640625, "CSR": 0.5539504716981132, "retrieved_ids": ["mrqa_squad-train-14898", "mrqa_squad-train-69645", "mrqa_squad-train-68726", "mrqa_squad-train-52131", "mrqa_squad-train-29302", "mrqa_squad-train-76087", "mrqa_squad-train-71330", "mrqa_squad-train-43413", "mrqa_squad-train-13363", "mrqa_squad-train-50765", "mrqa_squad-train-55890", "mrqa_squad-train-46194", "mrqa_squad-train-5394", "mrqa_squad-train-9175", "mrqa_squad-train-23293", "mrqa_squad-train-50354", "mrqa_squad-train-2783", "mrqa_squad-train-73941", "mrqa_squad-train-19132", "mrqa_squad-train-54149", "mrqa_squad-train-32033", "mrqa_squad-train-17353", "mrqa_squad-train-66509", "mrqa_squad-train-66214", "mrqa_squad-train-35822", "mrqa_squad-train-21235", "mrqa_squad-train-85401", "mrqa_squad-train-2765", "mrqa_squad-train-80358", "mrqa_squad-train-52448", "mrqa_squad-train-27093", "mrqa_squad-train-50394", "mrqa_naturalquestions-validation-8896", "mrqa_newsqa-validation-1570", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-51", "mrqa_newsqa-validation-1318", "mrqa_naturalquestions-validation-5579", "mrqa_triviaqa-validation-7618", "mrqa_triviaqa-validation-5154", "mrqa_triviaqa-validation-2669", "mrqa_triviaqa-validation-6237", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-4307", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-8907", "mrqa_newsqa-validation-541", "mrqa_newsqa-validation-169", "mrqa_naturalquestions-validation-1135", "mrqa_newsqa-validation-3584", "mrqa_hotpotqa-validation-264", "mrqa_newsqa-validation-1836", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-2151", "mrqa_newsqa-validation-1413", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-1978", "mrqa_hotpotqa-validation-831", "mrqa_hotpotqa-validation-5742", "mrqa_squad-validation-8819", "mrqa_hotpotqa-validation-511", "mrqa_searchqa-validation-12996", "mrqa_triviaqa-validation-4834", "mrqa_hotpotqa-validation-3018"], "EFR": 1.0, "Overall": 0.7494619693396226}, {"timecode": 53, "before_eval_results": {"predictions": ["Mike Mills", "1998", "30.9%", "Kittie", "American", "People!", "South Australian", "The Vanguard Group", "American", "Ready to Die", "to steal the plans for the Death Star, the Galactic Empire's super weapon", "Danish", "York County", "Seventeen", "Wake Island", "Australian Defence Force", "1973", "Arthur William Bell III", "Boston", "Erreway", "Tampa Bay Lightning", "CBS", "Boston Bruins", "Elise Marie Stefanik", "Jennifer Taylor", "Correcaminos UAT", "9Lives brand cat food", "Black Ravens", "2005", "Las Vegas Strip in Paradise, Nevada.", "42,972", "over 9,000", "Michael Seater", "Drunken Master II", "more than 100 countries", "Bassline", "E22", "Allies of World War I", "Geraldine Page", "Kristina Ceyton and Kristian Moliere", "Life in Photography", "Philip Billard Municipal Airport", "1964 to 1974", "Big Fucking German", "law", "Hamlet", "Bow River and the Elbow River", "Gillian Anderson", "extensive use of segues", "united Ireland", "\"Queen In-hyun's Man\"", "American musical group founded by Marcus Bowens and Jermaine Fuller", "Virgil Ogletree", "# 4 School of Public Health in the country", "Topiary", "bowie", "1961", "Luca di Montezemolo", "near the Somali coast", "blind,", "Cassie", "automobile", "Mark Wahlberg", "cheese"], "metric_results": {"EM": 0.5, "QA-F1": 0.6378404581529582}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 0.0, 0.4, 1.0, 0.0, 0.9090909090909091, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.8571428571428571, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1754", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-573", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-5831", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3615", "mrqa_hotpotqa-validation-2025", "mrqa_hotpotqa-validation-2369", "mrqa_hotpotqa-validation-71", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-1199", "mrqa_hotpotqa-validation-2531", "mrqa_hotpotqa-validation-2826", "mrqa_hotpotqa-validation-2404", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2840", "mrqa_hotpotqa-validation-1891", "mrqa_hotpotqa-validation-1897", "mrqa_naturalquestions-validation-10249", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-115", "mrqa_newsqa-validation-2163", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1641", "mrqa_searchqa-validation-5501", "mrqa_searchqa-validation-3970"], "SR": 0.5, "CSR": 0.5529513888888888, "retrieved_ids": ["mrqa_squad-train-39915", "mrqa_squad-train-53020", "mrqa_squad-train-35820", "mrqa_squad-train-54723", "mrqa_squad-train-67747", "mrqa_squad-train-36971", "mrqa_squad-train-61199", "mrqa_squad-train-44695", "mrqa_squad-train-64902", "mrqa_squad-train-18775", "mrqa_squad-train-57464", "mrqa_squad-train-40662", "mrqa_squad-train-69423", "mrqa_squad-train-71458", "mrqa_squad-train-21375", "mrqa_squad-train-6583", "mrqa_squad-train-37600", "mrqa_squad-train-53771", "mrqa_squad-train-18162", "mrqa_squad-train-79069", "mrqa_squad-train-67284", "mrqa_squad-train-20747", "mrqa_squad-train-5675", "mrqa_squad-train-6744", "mrqa_squad-train-12709", "mrqa_squad-train-9612", "mrqa_squad-train-39933", "mrqa_squad-train-38240", "mrqa_squad-train-70290", "mrqa_squad-train-62061", "mrqa_squad-train-51140", "mrqa_squad-train-79596", "mrqa_squad-validation-4452", "mrqa_newsqa-validation-3404", "mrqa_squad-validation-589", "mrqa_naturalquestions-validation-4609", "mrqa_triviaqa-validation-51", "mrqa_searchqa-validation-14569", "mrqa_newsqa-validation-1879", "mrqa_triviaqa-validation-5726", "mrqa_naturalquestions-validation-1987", "mrqa_triviaqa-validation-3862", "mrqa_searchqa-validation-15194", "mrqa_triviaqa-validation-7690", "mrqa_naturalquestions-validation-7351", "mrqa_triviaqa-validation-7463", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-4103", "mrqa_newsqa-validation-472", "mrqa_newsqa-validation-2491", "mrqa_triviaqa-validation-5690", "mrqa_triviaqa-validation-6409", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2635", "mrqa_squad-validation-3021", "mrqa_triviaqa-validation-2819", "mrqa_triviaqa-validation-4844", "mrqa_newsqa-validation-181", "mrqa_squad-validation-7296", "mrqa_searchqa-validation-10856", "mrqa_newsqa-validation-2497", "mrqa_triviaqa-validation-6915", "mrqa_searchqa-validation-1507"], "EFR": 1.0, "Overall": 0.7492621527777777}, {"timecode": 54, "before_eval_results": {"predictions": ["her brother, Brian", "art", "Callability", "the angel Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "Waylon Jennings", "August 2, 1990", "Charlene Holt", "eight", "the courts", "English author Rudyard Kipling", "an official document permitting a specific individual to operate one or more types of motorized vehicles", "18", "Jewel Akens", "Division 1", "Irsay", "Abid Ali Neemuchwala", "winter", "Roxette", "Cadillac", "Vincent Price", "The First Battle of Bull Run ( the name used by Union forces )", "the chest, back, shoulders, torso and / or legs", "Authority ( derived from the Latin word auctoritas )", "drizzle, rain, sleet, snow, graupel and hail", "1967", "Virginia", "due to Parker's pregnancy at the time of filming", "lakes or reservoirs at high altitudes", "merengue and bachata music", "Times Square in New York City west to Lincoln Park in San Francisco", "the 1960s", "IBM", "American singer Elvis Presley", "late - 17th century New England", "1998", "Karen Gillan", "part of the present Indian constitutive state of Meghalaya ( formerly Assam ), which includes the present districts of East Jaintia Hills district, headquarter Khliehriat, West Jaintian Hills district", "A rear - view mirror ( or rearview mirror )", "April 15", "flawed democracy", "2026", "William Chatterton Dix", "Joan Garred", "Selena Gomez", "Steve Russell", "1881", "an armed conflict without the consent of the U.S. Congress", "Timothy B. Schmit", "Games played", "Sir Henry Bartle Frere", "Games", "Cambridge", "Oklahoma City", "choroid", "1982", "2015", "film", "22", "one", "economic opportunities.", "Ray Walston", "Ukrainian", "Napoleon", "\"Traumnovelle\" (\"Dream Story\")"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6984486794832531}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.5, 0.0, 0.0, 0.8387096774193548, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.2857142857142857, 0.25, 1.0, 1.0, 0.823529411764706, 0.42857142857142855, 0.4, 0.631578947368421, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.7384615384615384, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6086956521739131, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8933", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-158", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-767", "mrqa_naturalquestions-validation-6442", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-3419", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-8534", "mrqa_naturalquestions-validation-4925", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-8591", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-5785", "mrqa_naturalquestions-validation-10331", "mrqa_naturalquestions-validation-6211", "mrqa_triviaqa-validation-4940", "mrqa_triviaqa-validation-2996", "mrqa_searchqa-validation-354", "mrqa_searchqa-validation-7780"], "SR": 0.5625, "CSR": 0.553125, "retrieved_ids": ["mrqa_squad-train-78341", "mrqa_squad-train-73420", "mrqa_squad-train-58988", "mrqa_squad-train-83410", "mrqa_squad-train-50164", "mrqa_squad-train-66998", "mrqa_squad-train-59122", "mrqa_squad-train-72747", "mrqa_squad-train-51382", "mrqa_squad-train-26062", "mrqa_squad-train-4564", "mrqa_squad-train-38350", "mrqa_squad-train-9596", "mrqa_squad-train-31879", "mrqa_squad-train-84708", "mrqa_squad-train-74704", "mrqa_squad-train-39066", "mrqa_squad-train-19997", "mrqa_squad-train-19593", "mrqa_squad-train-77113", "mrqa_squad-train-57610", "mrqa_squad-train-52187", "mrqa_squad-train-46221", "mrqa_squad-train-17251", "mrqa_squad-train-81889", "mrqa_squad-train-2366", "mrqa_squad-train-2776", "mrqa_squad-train-48305", "mrqa_squad-train-85055", "mrqa_squad-train-46732", "mrqa_squad-train-6674", "mrqa_squad-train-11947", "mrqa_newsqa-validation-1413", "mrqa_naturalquestions-validation-7212", "mrqa_triviaqa-validation-3954", "mrqa_hotpotqa-validation-5792", "mrqa_triviaqa-validation-3814", "mrqa_searchqa-validation-13686", "mrqa_squad-validation-6228", "mrqa_triviaqa-validation-5476", "mrqa_naturalquestions-validation-10412", "mrqa_naturalquestions-validation-4924", "mrqa_searchqa-validation-9853", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-12829", "mrqa_searchqa-validation-12440", "mrqa_squad-validation-10143", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-7408", "mrqa_hotpotqa-validation-5644", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-9691", "mrqa_triviaqa-validation-94", "mrqa_triviaqa-validation-2516", "mrqa_searchqa-validation-686", "mrqa_hotpotqa-validation-2531", "mrqa_newsqa-validation-2905", "mrqa_searchqa-validation-2971", "mrqa_newsqa-validation-1641", "mrqa_squad-validation-4715", "mrqa_squad-validation-7708", "mrqa_naturalquestions-validation-1439"], "EFR": 0.8214285714285714, "Overall": 0.7135825892857143}, {"timecode": 55, "before_eval_results": {"predictions": ["the 1960s", "Charlton Heston", "an advantage without deviating from basic strategy", "Doreen Mantle", "Felicity Huffman", "March 18, 2005", "a solitary figure who is not understood by others, but is actually wise", "when the forward reaction proceeds at the same rate as the reverse reaction", "28 July 1914", "Terry Kath", "1922", "2017 season", "Sylvester Stallone", "2008", "Ethiopia and Liberia", "English law", "Abid Ali Neemuchwala", "Hodel", "instant messenger", "James Fleet", "from September 15, 2015, to November 17, 2015", "ulnar nerve", "Border Collie", "Massachusetts", "citizens", "commercial at", "The Sun", "60", "August 22, 1980", "Jack Nicklaus", "2020", "General George Washington", "7.6 % Per Annum'( compounded annually )", "9.0 -- 9.1 ( M )", "Part 2", "1966", "As of January 17, 2018, 201 episodes", "by 2026", "1926", "October 20, 1977", "Cetshwayo", "50 home run club", "Mamlakah al - \u02bbArab\u012byah", "Garbi\u00f1e Muguruza", "23 %", "Detroit Tigers", "Rockwell", "radioisotope thermoelectric generator", "Charlotte Hornets", "lumbar enlargement", "February 7, 2018", "muezzin", "Elizabeth Taylor", "Sweden", "fourth", "\"Queen In-hyun's Man\"", "James Franco", "step up attacks against innocent civilians.\"", "a delegation of American Muslim and Christian leaders", "iTunes,", "\"if a man does not keep pace with his companions, perhaps it is because he hears a different drummer", "the Manchus", "the World Series fix", "seven"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7288070436507936}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-6040", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-1950", "mrqa_naturalquestions-validation-6886", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-10163", "mrqa_naturalquestions-validation-5001", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-5034", "mrqa_hotpotqa-validation-4560", "mrqa_newsqa-validation-2622", "mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-12190", "mrqa_newsqa-validation-1458"], "SR": 0.65625, "CSR": 0.5549665178571428, "retrieved_ids": ["mrqa_squad-train-80079", "mrqa_squad-train-75328", "mrqa_squad-train-81577", "mrqa_squad-train-53726", "mrqa_squad-train-78203", "mrqa_squad-train-14934", "mrqa_squad-train-29782", "mrqa_squad-train-80392", "mrqa_squad-train-30191", "mrqa_squad-train-69350", "mrqa_squad-train-8688", "mrqa_squad-train-23304", "mrqa_squad-train-13404", "mrqa_squad-train-35848", "mrqa_squad-train-81867", "mrqa_squad-train-10210", "mrqa_squad-train-47580", "mrqa_squad-train-17154", "mrqa_squad-train-57910", "mrqa_squad-train-75015", "mrqa_squad-train-28848", "mrqa_squad-train-14870", "mrqa_squad-train-63728", "mrqa_squad-train-69317", "mrqa_squad-train-47542", "mrqa_squad-train-8546", "mrqa_squad-train-1505", "mrqa_squad-train-20762", "mrqa_squad-train-43540", "mrqa_squad-train-79328", "mrqa_squad-train-13767", "mrqa_squad-train-77945", "mrqa_searchqa-validation-2456", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-767", "mrqa_newsqa-validation-3446", "mrqa_triviaqa-validation-6392", "mrqa_newsqa-validation-2816", "mrqa_triviaqa-validation-1988", "mrqa_naturalquestions-validation-779", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-7212", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-2361", "mrqa_triviaqa-validation-6828", "mrqa_naturalquestions-validation-2069", "mrqa_searchqa-validation-15103", "mrqa_naturalquestions-validation-4280", "mrqa_triviaqa-validation-7212", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-9675", "mrqa_naturalquestions-validation-4007", "mrqa_newsqa-validation-3594", "mrqa_squad-validation-9136", "mrqa_squad-validation-8904", "mrqa_naturalquestions-validation-3442", "mrqa_hotpotqa-validation-5573", "mrqa_naturalquestions-validation-4351", "mrqa_newsqa-validation-1483", "mrqa_triviaqa-validation-3717", "mrqa_naturalquestions-validation-2426", "mrqa_triviaqa-validation-4875", "mrqa_newsqa-validation-712", "mrqa_naturalquestions-validation-86"], "EFR": 1.0, "Overall": 0.7496651785714286}, {"timecode": 56, "before_eval_results": {"predictions": ["Clifford, the gamekeeper", "Sweden", "White House drama", "Adam Smith", "Luxembourg", "el Hiero", "Carl Van", "stave", "tyne", "road race", "The Blues Brothers", "onion", "1984", "Frottage", "Penhaligon", "Kevin Painter", "beans", "Messenger orbiter", "goose bump", "duck-billed platypus", "Montr\u00e9al", "Jeffrey Archer", "Four Tops", "Velazquez", "Restless Leg Syndrome", "aviva plc", "Charlie Chan", "Apocalypse Now", "taekwondo", "Ishmael", "jubilee line", "Aramis", "delphiniums", "the head", "fogg", "Chuck Hagel", "haute", "zephyr", "300", "speedway", "France", "Rock Hudson", "marinated dried fruits", "Jay-Z", "bird", "paraphilias", "george iv", "Margaret Beckett", "Washington Post", "White Ferns", "United States", "the 18th century", "Austria - Hungary", "Sean O' Neal", "140 million", "The New Yorker", "In Pursuit", "Aung San Suu Kyi", "his brother to surrender.", "\" Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "Gene Wilder", "South Park", "Tucson", "\"The Simpsons Movie\""], "metric_results": {"EM": 0.671875, "QA-F1": 0.7340277777777778}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1824", "mrqa_triviaqa-validation-5613", "mrqa_triviaqa-validation-6424", "mrqa_triviaqa-validation-4599", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-7497", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-5342", "mrqa_triviaqa-validation-3690", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-7536", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-4482", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-7704", "mrqa_triviaqa-validation-6930", "mrqa_naturalquestions-validation-7549", "mrqa_hotpotqa-validation-4810", "mrqa_newsqa-validation-2308", "mrqa_searchqa-validation-13467"], "SR": 0.671875, "CSR": 0.5570175438596492, "retrieved_ids": ["mrqa_squad-train-65721", "mrqa_squad-train-9882", "mrqa_squad-train-60620", "mrqa_squad-train-57194", "mrqa_squad-train-79200", "mrqa_squad-train-37604", "mrqa_squad-train-23431", "mrqa_squad-train-44564", "mrqa_squad-train-7549", "mrqa_squad-train-68252", "mrqa_squad-train-77806", "mrqa_squad-train-8154", "mrqa_squad-train-84792", "mrqa_squad-train-7141", "mrqa_squad-train-31792", "mrqa_squad-train-65903", "mrqa_squad-train-35731", "mrqa_squad-train-21406", "mrqa_squad-train-73866", "mrqa_squad-train-26072", "mrqa_squad-train-12550", "mrqa_squad-train-11079", "mrqa_squad-train-44111", "mrqa_squad-train-45818", "mrqa_squad-train-56191", "mrqa_squad-train-35142", "mrqa_squad-train-34747", "mrqa_squad-train-20457", "mrqa_squad-train-29273", "mrqa_squad-train-14391", "mrqa_squad-train-82218", "mrqa_squad-train-35568", "mrqa_naturalquestions-validation-4824", "mrqa_searchqa-validation-13151", "mrqa_newsqa-validation-1893", "mrqa_naturalquestions-validation-6886", "mrqa_naturalquestions-validation-2385", "mrqa_triviaqa-validation-774", "mrqa_triviaqa-validation-1125", "mrqa_squad-validation-2932", "mrqa_triviaqa-validation-1606", "mrqa_searchqa-validation-16130", "mrqa_searchqa-validation-12363", "mrqa_searchqa-validation-3530", "mrqa_squad-validation-2595", "mrqa_squad-validation-10143", "mrqa_hotpotqa-validation-4418", "mrqa_triviaqa-validation-1094", "mrqa_naturalquestions-validation-1415", "mrqa_hotpotqa-validation-989", "mrqa_searchqa-validation-13232", "mrqa_newsqa-validation-3280", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-6396", "mrqa_squad-validation-4150", "mrqa_searchqa-validation-12477", "mrqa_hotpotqa-validation-5703", "mrqa_triviaqa-validation-6392", "mrqa_hotpotqa-validation-3428", "mrqa_naturalquestions-validation-5348", "mrqa_searchqa-validation-12190", "mrqa_newsqa-validation-2288", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-6787"], "EFR": 0.9523809523809523, "Overall": 0.7405515742481203}, {"timecode": 57, "before_eval_results": {"predictions": ["CBS", "robbie coltrane", "elles", "Utah", "black lights", "lacrosse", "Packers", "utrecht", "Operation Overlord", "salvador", "Virginia", "augusta", "yachts", "eggplant", "1215", "pullover", "diffusion", "wye", "jack London", "South Carolina", "ellesmere port", "Parsley", "Hindi", "Santiago", "japan", "Lynda Baron", "Oscar De La Hoya", "robbie coltrane", "90%", "Sven Goran Eriksson", "robbie colombo", "the 11th Century Church at St Devote", "A", "Jordan", "a written record", "Motown", "Sudan", "plainsies", "chatter", "colony", "ireland", "anschluss", "silk", "Irving Berlin", "medical", "Leo Tolstoy", "Austria", "oasis", "killer energy brew", "salvador", "biplane", "the university's science club", "2003", "Magnavox Odyssey", "Clark County", "created the American Land- Grant universities and colleges.", "fifth level", "whose area of influence includes the eastern state of Veracruz.", "Japan", "Dr. Maria Siemionow, the head of plastic surgery research at the Cleveland, Ohio, hospital,", "vertex", "Voldemort", "an apricot", "the Red Sea"], "metric_results": {"EM": 0.5, "QA-F1": 0.5411892361111111}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-284", "mrqa_triviaqa-validation-1194", "mrqa_triviaqa-validation-157", "mrqa_triviaqa-validation-1714", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-6018", "mrqa_triviaqa-validation-1395", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-6649", "mrqa_triviaqa-validation-2404", "mrqa_triviaqa-validation-6233", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7011", "mrqa_triviaqa-validation-2310", "mrqa_triviaqa-validation-2017", "mrqa_triviaqa-validation-4240", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-2532", "mrqa_triviaqa-validation-1062", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-5578", "mrqa_triviaqa-validation-5877", "mrqa_naturalquestions-validation-8707", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2021", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-1678", "mrqa_searchqa-validation-16366", "mrqa_searchqa-validation-5198"], "SR": 0.5, "CSR": 0.5560344827586207, "retrieved_ids": ["mrqa_squad-train-616", "mrqa_squad-train-33870", "mrqa_squad-train-64970", "mrqa_squad-train-55569", "mrqa_squad-train-43553", "mrqa_squad-train-27807", "mrqa_squad-train-48646", "mrqa_squad-train-9113", "mrqa_squad-train-66389", "mrqa_squad-train-10380", "mrqa_squad-train-39589", "mrqa_squad-train-7525", "mrqa_squad-train-54652", "mrqa_squad-train-19249", "mrqa_squad-train-27552", "mrqa_squad-train-64423", "mrqa_squad-train-85486", "mrqa_squad-train-68234", "mrqa_squad-train-49493", "mrqa_squad-train-46170", "mrqa_squad-train-76007", "mrqa_squad-train-56853", "mrqa_squad-train-1620", "mrqa_squad-train-4328", "mrqa_squad-train-71313", "mrqa_squad-train-26981", "mrqa_squad-train-85777", "mrqa_squad-train-64548", "mrqa_squad-train-4862", "mrqa_squad-train-44126", "mrqa_squad-train-39625", "mrqa_squad-train-66977", "mrqa_naturalquestions-validation-2558", "mrqa_naturalquestions-validation-8227", "mrqa_triviaqa-validation-3752", "mrqa_newsqa-validation-2205", "mrqa_naturalquestions-validation-10680", "mrqa_squad-validation-1195", "mrqa_hotpotqa-validation-3395", "mrqa_squad-validation-7422", "mrqa_naturalquestions-validation-9887", "mrqa_newsqa-validation-2900", "mrqa_triviaqa-validation-2073", "mrqa_newsqa-validation-333", "mrqa_hotpotqa-validation-2378", "mrqa_triviaqa-validation-2486", "mrqa_searchqa-validation-5038", "mrqa_naturalquestions-validation-5939", "mrqa_squad-validation-5818", "mrqa_hotpotqa-validation-1123", "mrqa_triviaqa-validation-206", "mrqa_triviaqa-validation-52", "mrqa_naturalquestions-validation-7507", "mrqa_hotpotqa-validation-114", "mrqa_hotpotqa-validation-1534", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-5161", "mrqa_squad-validation-6319", "mrqa_hotpotqa-validation-650", "mrqa_squad-validation-8786", "mrqa_hotpotqa-validation-4655", "mrqa_naturalquestions-validation-4354", "mrqa_searchqa-validation-1757", "mrqa_hotpotqa-validation-4810"], "EFR": 0.84375, "Overall": 0.7186287715517241}, {"timecode": 58, "before_eval_results": {"predictions": ["Christian Louboutin", "apple", "Galapagos Islands", "For Gallantry", "Tonight", "onions", "new york", "Mariah Carey", "blancmange", "the Daily Herald", "four", "Isaac", "dicks Francis", "larkin", "james Gutenberg", "opossum", "Soviets", "UK Independence Party.", "William Wallace", "charlie", "Monster M*A*S*H", "helene hanff", "lingua mortua", "California condor", "molybdenum", "France", "laos", "sports agent", "Puerto Rico", "John Huston", "peterborough united", "cat", "bajan", "aurochs", "wells", "michael duchess", "de Gaulle", "mercury", "The Cranberry Martini", "michael d Dalton", "bassoon", "Mary Poppins", "man of Character", "Queensland", "Blofeld", "George Eastman", "United Nations of Football", "Kenya", "george iv", "tuscany", "n Nissan", "Ptolemy", "Toto", "commemorating fealty and filial piety", "Heather Elizabeth Langenkamp", "Operation Iceberg", "quarterly", "Rambosk", "Revolutionary Armed Forces of Colombia,", "preliminary injunction", "the horror", "Pole vault", "Maine", "Coleridge"], "metric_results": {"EM": 0.59375, "QA-F1": 0.674599358974359}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-5177", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-4263", "mrqa_triviaqa-validation-5071", "mrqa_triviaqa-validation-5024", "mrqa_triviaqa-validation-1089", "mrqa_triviaqa-validation-1383", "mrqa_triviaqa-validation-4577", "mrqa_triviaqa-validation-6833", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-935", "mrqa_triviaqa-validation-1832", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-626", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-7727", "mrqa_triviaqa-validation-6368", "mrqa_triviaqa-validation-3102", "mrqa_triviaqa-validation-1708", "mrqa_triviaqa-validation-3341", "mrqa_triviaqa-validation-4635", "mrqa_hotpotqa-validation-2639", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-384", "mrqa_searchqa-validation-5746"], "SR": 0.59375, "CSR": 0.5566737288135593, "retrieved_ids": ["mrqa_squad-train-80910", "mrqa_squad-train-83120", "mrqa_squad-train-33450", "mrqa_squad-train-52382", "mrqa_squad-train-32203", "mrqa_squad-train-37925", "mrqa_squad-train-71734", "mrqa_squad-train-9209", "mrqa_squad-train-80918", "mrqa_squad-train-64600", "mrqa_squad-train-56998", "mrqa_squad-train-60816", "mrqa_squad-train-37617", "mrqa_squad-train-27201", "mrqa_squad-train-43453", "mrqa_squad-train-40073", "mrqa_squad-train-85129", "mrqa_squad-train-46686", "mrqa_squad-train-61599", "mrqa_squad-train-14936", "mrqa_squad-train-45052", "mrqa_squad-train-49661", "mrqa_squad-train-4169", "mrqa_squad-train-11007", "mrqa_squad-train-20043", "mrqa_squad-train-48534", "mrqa_squad-train-80835", "mrqa_squad-train-71166", "mrqa_squad-train-62004", "mrqa_squad-train-42257", "mrqa_squad-train-84984", "mrqa_squad-train-66051", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-5117", "mrqa_triviaqa-validation-4457", "mrqa_searchqa-validation-5180", "mrqa_hotpotqa-validation-503", "mrqa_newsqa-validation-715", "mrqa_triviaqa-validation-2459", "mrqa_naturalquestions-validation-3922", "mrqa_triviaqa-validation-2632", "mrqa_searchqa-validation-9196", "mrqa_hotpotqa-validation-2325", "mrqa_naturalquestions-validation-4135", "mrqa_searchqa-validation-3518", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-157", "mrqa_naturalquestions-validation-8534", "mrqa_searchqa-validation-5038", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-6233", "mrqa_naturalquestions-validation-5304", "mrqa_newsqa-validation-2506", "mrqa_hotpotqa-validation-3162", "mrqa_newsqa-validation-4006", "mrqa_naturalquestions-validation-3363", "mrqa_newsqa-validation-908", "mrqa_squad-validation-3863", "mrqa_naturalquestions-validation-8227", "mrqa_searchqa-validation-16378", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-9239", "mrqa_hotpotqa-validation-5140"], "EFR": 0.9615384615384616, "Overall": 0.7423143130704042}, {"timecode": 59, "before_eval_results": {"predictions": ["Victor Garber", "Strato of Lampsacus", "Eliot Cutler", "goalkeeper", "David Weissman", "\"The Suite Life of Cody\"", "comedy", "November 29, 1895", "Cher", "Sir Philip Anthony Hopkins", "near Philip Billard Municipal Airport", "football", "two years", "Walt Disney and Ub Iwerks at the Walt Disney Studios", "Martin \"Marty\" McCann", "WB Television Network", "gainsborough Trinity Football Club is a football club based in Gainsborough, Lincolnshire, England.", "Marge turns out to be a terrible date", "$7.3 billion", "shortest player ever to play in the National Basketball Association", "George I", "sixteen", "Rural Electrification Act of 1936", "2015", "Ron Swanson", "Golden Globe Award", "XXXTentacion", "Dire Straits", "American reality documentary television series", "MGM Grand Garden Special Events Center", "Best Alternative Music Album", "Pieter van Musschenbroek", "1979", "the 70 m and 90 m events", "Viscount Cranborne", "horror", "Bulgarian", "KXII", "James Bond films", "Eastern College Athletic Conference", "Indian", "William Corcoran Eustis", "World Outgames", "Adelaide", "Saturday", "Shooter Jennings", "Can't Be Tamed", "Bolton, England", "Stephen Hawking", "Beyonce Wallace", "Saoirse Ronan", "Judy Garland and Mickey Rooney", "Scheria ( / \u02c8sk\u025bri\u0259 / ; Ancient Greek : \u03a3\u03c7\u03b5\u03c1\u03af\u03b7 or \u03a3 \u03c7\u03b5\u03af\u03b1 )", "Todd Bridges", "lemon", "Hindi", "jaipur", "in the southern Gaza city of Rafah,", "the U.S. Consulate in Rio de Janeiro", "CNN", "\"Ende gut, Alles gut\"", "ice cream", "Rock Island Arsenal", "Captain James Cook"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7295127615440116}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.9090909090909091, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5714285714285715, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2372", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-1007", "mrqa_hotpotqa-validation-4120", "mrqa_hotpotqa-validation-4408", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-3405", "mrqa_hotpotqa-validation-1505", "mrqa_hotpotqa-validation-1491", "mrqa_hotpotqa-validation-4988", "mrqa_hotpotqa-validation-5682", "mrqa_hotpotqa-validation-2207", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-3263", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-1451", "mrqa_hotpotqa-validation-2429", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-3404", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-6145", "mrqa_searchqa-validation-2444", "mrqa_searchqa-validation-15613"], "SR": 0.5625, "CSR": 0.5567708333333333, "retrieved_ids": ["mrqa_squad-train-76619", "mrqa_squad-train-4381", "mrqa_squad-train-17508", "mrqa_squad-train-49442", "mrqa_squad-train-34198", "mrqa_squad-train-9529", "mrqa_squad-train-61946", "mrqa_squad-train-37557", "mrqa_squad-train-78302", "mrqa_squad-train-7849", "mrqa_squad-train-33817", "mrqa_squad-train-74013", "mrqa_squad-train-6398", "mrqa_squad-train-37988", "mrqa_squad-train-1136", "mrqa_squad-train-16389", "mrqa_squad-train-31458", "mrqa_squad-train-8892", "mrqa_squad-train-77311", "mrqa_squad-train-46793", "mrqa_squad-train-64441", "mrqa_squad-train-35584", "mrqa_squad-train-8443", "mrqa_squad-train-48396", "mrqa_squad-train-13743", "mrqa_squad-train-43123", "mrqa_squad-train-40367", "mrqa_squad-train-31182", "mrqa_squad-train-46605", "mrqa_squad-train-7520", "mrqa_squad-train-43588", "mrqa_squad-train-5201", "mrqa_triviaqa-validation-5476", "mrqa_naturalquestions-validation-9088", "mrqa_triviaqa-validation-3102", "mrqa_searchqa-validation-2579", "mrqa_newsqa-validation-2503", "mrqa_hotpotqa-validation-5117", "mrqa_naturalquestions-validation-4544", "mrqa_newsqa-validation-2923", "mrqa_hotpotqa-validation-2923", "mrqa_hotpotqa-validation-1351", "mrqa_triviaqa-validation-2316", "mrqa_hotpotqa-validation-2395", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-6148", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-8228", "mrqa_newsqa-validation-3871", "mrqa_hotpotqa-validation-3018", "mrqa_naturalquestions-validation-4865", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-859", "mrqa_newsqa-validation-3151", "mrqa_triviaqa-validation-2735", "mrqa_squad-validation-2328", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-10156", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-8326", "mrqa_newsqa-validation-1988", "mrqa_naturalquestions-validation-10037", "mrqa_searchqa-validation-13467", "mrqa_hotpotqa-validation-5562"], "EFR": 1.0, "Overall": 0.7500260416666666}, {"timecode": 60, "UKR": 0.791015625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1041", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-1368", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-1451", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-1496", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1919", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2256", "mrqa_hotpotqa-validation-2273", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2402", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-261", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-2705", "mrqa_hotpotqa-validation-2735", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2769", "mrqa_hotpotqa-validation-2792", "mrqa_hotpotqa-validation-2841", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-2986", "mrqa_hotpotqa-validation-3018", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3136", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-3205", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3355", "mrqa_hotpotqa-validation-347", "mrqa_hotpotqa-validation-3714", "mrqa_hotpotqa-validation-3721", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-423", "mrqa_hotpotqa-validation-4253", "mrqa_hotpotqa-validation-430", "mrqa_hotpotqa-validation-4408", "mrqa_hotpotqa-validation-4418", "mrqa_hotpotqa-validation-4459", "mrqa_hotpotqa-validation-4526", "mrqa_hotpotqa-validation-4536", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-4732", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-4828", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-503", "mrqa_hotpotqa-validation-5339", "mrqa_hotpotqa-validation-5483", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-5831", "mrqa_hotpotqa-validation-5869", "mrqa_hotpotqa-validation-594", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-10091", "mrqa_naturalquestions-validation-10259", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10411", "mrqa_naturalquestions-validation-1047", "mrqa_naturalquestions-validation-10513", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-10670", "mrqa_naturalquestions-validation-1190", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-1519", "mrqa_naturalquestions-validation-1539", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2670", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2855", "mrqa_naturalquestions-validation-3", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-3935", "mrqa_naturalquestions-validation-3970", "mrqa_naturalquestions-validation-4036", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4135", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-435", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-4917", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6166", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-6211", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6432", "mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-6778", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-6886", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7301", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7976", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8207", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-86", "mrqa_naturalquestions-validation-8761", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-9607", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-9870", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-9921", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-1064", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1136", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-1232", "mrqa_newsqa-validation-139", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-1550", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-1641", "mrqa_newsqa-validation-1688", "mrqa_newsqa-validation-1693", "mrqa_newsqa-validation-1746", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1851", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1896", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1908", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1995", "mrqa_newsqa-validation-2010", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2026", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2244", "mrqa_newsqa-validation-2250", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-231", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2477", "mrqa_newsqa-validation-2546", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2802", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-3016", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-3327", "mrqa_newsqa-validation-333", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-3526", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3785", "mrqa_newsqa-validation-3816", "mrqa_newsqa-validation-3822", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-3847", "mrqa_newsqa-validation-389", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-4054", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-623", "mrqa_newsqa-validation-641", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-693", "mrqa_newsqa-validation-715", "mrqa_newsqa-validation-720", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-828", "mrqa_newsqa-validation-903", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-1030", "mrqa_searchqa-validation-10918", "mrqa_searchqa-validation-11406", "mrqa_searchqa-validation-11621", "mrqa_searchqa-validation-12440", "mrqa_searchqa-validation-12493", "mrqa_searchqa-validation-1261", "mrqa_searchqa-validation-13257", "mrqa_searchqa-validation-13456", "mrqa_searchqa-validation-1357", "mrqa_searchqa-validation-14104", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15508", "mrqa_searchqa-validation-15568", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-1898", "mrqa_searchqa-validation-1999", "mrqa_searchqa-validation-2052", "mrqa_searchqa-validation-2143", "mrqa_searchqa-validation-217", "mrqa_searchqa-validation-3018", "mrqa_searchqa-validation-3597", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-4996", "mrqa_searchqa-validation-515", "mrqa_searchqa-validation-5477", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-5746", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-6181", "mrqa_searchqa-validation-6304", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-709", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-9185", "mrqa_searchqa-validation-9394", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9846", "mrqa_squad-validation-10000", "mrqa_squad-validation-10097", "mrqa_squad-validation-10135", "mrqa_squad-validation-10184", "mrqa_squad-validation-10326", "mrqa_squad-validation-10339", "mrqa_squad-validation-10496", "mrqa_squad-validation-1240", "mrqa_squad-validation-1269", "mrqa_squad-validation-1408", "mrqa_squad-validation-1708", "mrqa_squad-validation-1713", "mrqa_squad-validation-1765", "mrqa_squad-validation-1890", "mrqa_squad-validation-2019", "mrqa_squad-validation-2328", "mrqa_squad-validation-2456", "mrqa_squad-validation-2751", "mrqa_squad-validation-280", "mrqa_squad-validation-2886", "mrqa_squad-validation-2897", "mrqa_squad-validation-2943", "mrqa_squad-validation-2953", "mrqa_squad-validation-2959", "mrqa_squad-validation-3021", "mrqa_squad-validation-305", "mrqa_squad-validation-3184", "mrqa_squad-validation-3364", "mrqa_squad-validation-3406", "mrqa_squad-validation-3444", "mrqa_squad-validation-3551", "mrqa_squad-validation-3608", "mrqa_squad-validation-3796", "mrqa_squad-validation-3812", "mrqa_squad-validation-3909", "mrqa_squad-validation-402", "mrqa_squad-validation-4265", "mrqa_squad-validation-4298", "mrqa_squad-validation-4326", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4583", "mrqa_squad-validation-4630", "mrqa_squad-validation-491", "mrqa_squad-validation-5004", "mrqa_squad-validation-5134", "mrqa_squad-validation-5180", "mrqa_squad-validation-5479", "mrqa_squad-validation-5692", "mrqa_squad-validation-5737", "mrqa_squad-validation-5781", "mrqa_squad-validation-5836", "mrqa_squad-validation-5852", "mrqa_squad-validation-6017", "mrqa_squad-validation-6089", "mrqa_squad-validation-6353", "mrqa_squad-validation-6494", "mrqa_squad-validation-6875", "mrqa_squad-validation-71", "mrqa_squad-validation-7205", "mrqa_squad-validation-7338", "mrqa_squad-validation-7434", "mrqa_squad-validation-7613", "mrqa_squad-validation-7781", "mrqa_squad-validation-7993", "mrqa_squad-validation-8134", "mrqa_squad-validation-8282", "mrqa_squad-validation-908", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9193", "mrqa_squad-validation-9234", "mrqa_squad-validation-9367", "mrqa_squad-validation-9376", "mrqa_squad-validation-9461", "mrqa_squad-validation-9614", "mrqa_squad-validation-9666", "mrqa_squad-validation-9771", "mrqa_squad-validation-9900", "mrqa_squad-validation-9959", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1147", "mrqa_triviaqa-validation-1282", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1479", "mrqa_triviaqa-validation-1619", "mrqa_triviaqa-validation-1668", "mrqa_triviaqa-validation-1683", "mrqa_triviaqa-validation-1883", "mrqa_triviaqa-validation-1947", "mrqa_triviaqa-validation-1953", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-2017", "mrqa_triviaqa-validation-2023", "mrqa_triviaqa-validation-2024", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-2229", "mrqa_triviaqa-validation-2456", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-260", "mrqa_triviaqa-validation-2630", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-2712", "mrqa_triviaqa-validation-2843", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3177", "mrqa_triviaqa-validation-3187", "mrqa_triviaqa-validation-3211", "mrqa_triviaqa-validation-3301", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-3456", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-358", "mrqa_triviaqa-validation-3627", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4150", "mrqa_triviaqa-validation-4178", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4458", "mrqa_triviaqa-validation-4460", "mrqa_triviaqa-validation-4482", "mrqa_triviaqa-validation-4494", "mrqa_triviaqa-validation-4664", "mrqa_triviaqa-validation-468", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-4729", "mrqa_triviaqa-validation-4759", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5161", "mrqa_triviaqa-validation-5182", "mrqa_triviaqa-validation-5261", "mrqa_triviaqa-validation-5294", "mrqa_triviaqa-validation-5377", "mrqa_triviaqa-validation-5381", "mrqa_triviaqa-validation-55", "mrqa_triviaqa-validation-5622", "mrqa_triviaqa-validation-5690", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-5726", "mrqa_triviaqa-validation-5763", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-6012", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6475", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6665", "mrqa_triviaqa-validation-6748", "mrqa_triviaqa-validation-6755", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-7011", "mrqa_triviaqa-validation-7038", "mrqa_triviaqa-validation-7112", "mrqa_triviaqa-validation-7128", "mrqa_triviaqa-validation-7374", "mrqa_triviaqa-validation-7508", "mrqa_triviaqa-validation-7558", "mrqa_triviaqa-validation-7560", "mrqa_triviaqa-validation-7571", "mrqa_triviaqa-validation-758", "mrqa_triviaqa-validation-7618", "mrqa_triviaqa-validation-7619", "mrqa_triviaqa-validation-807", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-881", "mrqa_triviaqa-validation-899"], "OKR": 0.892578125, "KG": 0.490625, "before_eval_results": {"predictions": ["Batman", "under a Union List, a State List and a Concurrent List", "Frank Oz", "786 -- 802", "Patris et Filii et Spiritus Sancti", "19 July 1990", "John Ernest Crawford", "Andy Warhol", "September 1972", "about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "as a Norman occupational surname ( meaning tailor ) in France", "BC Jean and Toby Gad", "the BBC", "57 days", "961", "Jay Baruchel", "December 1886", "U.S. declared neutrality", "at the state and national governmental level", "The courts", "Lori Rom", "Justin Johnson", "2018", "Coroebus of Elis", "giant planet", "Crepuscular animals", "Clarence Williams", "due to not being profitable", "in a nearby river bottom", "questions about the name of the war, the tariff", "10 : 30am", "David Ben - Gurion", "RMS Titanic", "a warrior", "in San Francisco Bay", "Eight full seasons", "traditional dance", "Vasoepididymostomy", "the fourth quarter of the preceding year", "Rosalind Bailey", "an Irish feminine name", "Broken Hill and Sydney", "Reverse - Flash", "to Aramaic \u05d0\u05d5\u05e9\u05e2\u05e0\u05d0 ( \u02be\u014dsha\u02bfn\u0101 ) meaning `` save, rescue, savior", "sedimentary rock", "Sir Ronald Ross", "personnel directors", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "post translational modification", "the 135th meridian west of the Greenwich Observatory", "near Camarillo, California", "goneril", "tomato", "Guru Nanak", "footballer", "mixed martial arts", "James Tinling", "Rima Fakih", "165-room", "David Bowie,", "Dame Nellie Melba", "December to April", "Godiva", "Sri Lanka Freedom Party"], "metric_results": {"EM": 0.5625, "QA-F1": 0.672048611111111}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 0.0, 0.0, 0.2222222222222222, 0.8, 1.0, 1.0, 0.16666666666666669, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4870", "mrqa_naturalquestions-validation-6490", "mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1966", "mrqa_naturalquestions-validation-52", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-9848", "mrqa_naturalquestions-validation-1133", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-9007", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1068", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-8599", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-7489", "mrqa_triviaqa-validation-1154", "mrqa_hotpotqa-validation-4952", "mrqa_searchqa-validation-7226", "mrqa_searchqa-validation-12527"], "SR": 0.5625, "CSR": 0.5568647540983607, "retrieved_ids": ["mrqa_squad-train-61491", "mrqa_squad-train-36029", "mrqa_squad-train-75611", "mrqa_squad-train-62621", "mrqa_squad-train-60492", "mrqa_squad-train-33831", "mrqa_squad-train-10996", "mrqa_squad-train-50875", "mrqa_squad-train-37098", "mrqa_squad-train-65160", "mrqa_squad-train-72284", "mrqa_squad-train-82716", "mrqa_squad-train-73481", "mrqa_squad-train-65747", "mrqa_squad-train-85482", "mrqa_squad-train-71934", "mrqa_squad-train-76592", "mrqa_squad-train-35118", "mrqa_squad-train-59555", "mrqa_squad-train-16540", "mrqa_squad-train-64454", "mrqa_squad-train-36233", "mrqa_squad-train-56091", "mrqa_squad-train-62169", "mrqa_squad-train-13572", "mrqa_squad-train-51664", "mrqa_squad-train-42699", "mrqa_squad-train-31451", "mrqa_squad-train-1440", "mrqa_squad-train-71285", "mrqa_squad-train-84241", "mrqa_squad-train-80991", "mrqa_naturalquestions-validation-3485", "mrqa_newsqa-validation-3394", "mrqa_naturalquestions-validation-9508", "mrqa_newsqa-validation-748", "mrqa_newsqa-validation-3435", "mrqa_squad-validation-3130", "mrqa_hotpotqa-validation-66", "mrqa_triviaqa-validation-4577", "mrqa_hotpotqa-validation-4408", "mrqa_newsqa-validation-2020", "mrqa_triviaqa-validation-3505", "mrqa_newsqa-validation-4122", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-4197", "mrqa_hotpotqa-validation-5255", "mrqa_newsqa-validation-3732", "mrqa_searchqa-validation-9159", "mrqa_newsqa-validation-3982", "mrqa_triviaqa-validation-2669", "mrqa_triviaqa-validation-4992", "mrqa_naturalquestions-validation-6466", "mrqa_hotpotqa-validation-2150", "mrqa_naturalquestions-validation-8063", "mrqa_newsqa-validation-245", "mrqa_newsqa-validation-2503", "mrqa_triviaqa-validation-7083", "mrqa_searchqa-validation-5038", "mrqa_searchqa-validation-5198", "mrqa_hotpotqa-validation-2075", "mrqa_newsqa-validation-3978", "mrqa_squad-validation-4150", "mrqa_triviaqa-validation-6532"], "EFR": 1.0, "Overall": 0.7462167008196722}, {"timecode": 61, "before_eval_results": {"predictions": ["for the 1994 season", "Tenochtitlan", "Conrad Lewis", "Bart Millard", "Pangaea or Pangea", "111", "Kiss", "Justice Harlan", "full '' sexual intercourse", "Rose Stagg ( Valene Kane )", "georgia", "passing of the year", "November 28, 1973", "T.J. Miller", "condemns rural depopulation and the pursuit of excessive wealth", "Malina Weissman", "Pasek & Paul", "the economy", "937 total weeks", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "Pure water is neutral, at pH 7 ( 25 \u00b0 C )", "1957", "cat in the hat", "1999", "the first to develop lethal injection as a method of execution", "the concentration of a compound exceeds its solubility", "February 16, 2018", "carnivore", "Andrew Lloyd Webber", "Dollree Mapp", "the 15th century", "electron donors", "Rich Mullins", "in a cell", "Detroit", "Mickey Mantle", "Shawn", "Gillen Simone Vangsness", "dress shop", "the First Epistle of John", "1603", "September 25, 1987", "The development of renewable sources of energy in the 1970s and'80s", "1939", "Randy Newman", "1956", "Ravi", "prokaryotic", "# 4", "Sweden had been an active supporter of the League of Nations", "New York City", "shoes", "sepp Blatter", "horses", "Vanarama National League", "Polonius", "40 million", "Dr. Maria Siemionow", "Joe Harn", "gun charges,", "Ronald Reagan", "titanium", "Hastings", "lohot"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6305314066416039}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 0.8421052631578948, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-2351", "mrqa_naturalquestions-validation-4821", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-1433", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-8975", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-442", "mrqa_naturalquestions-validation-7356", "mrqa_triviaqa-validation-2177", "mrqa_hotpotqa-validation-631", "mrqa_hotpotqa-validation-5479", "mrqa_newsqa-validation-4098", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-13746", "mrqa_triviaqa-validation-3768"], "SR": 0.53125, "CSR": 0.5564516129032258, "retrieved_ids": ["mrqa_squad-train-49635", "mrqa_squad-train-61452", "mrqa_squad-train-81053", "mrqa_squad-train-84776", "mrqa_squad-train-47694", "mrqa_squad-train-16813", "mrqa_squad-train-48717", "mrqa_squad-train-70804", "mrqa_squad-train-74694", "mrqa_squad-train-66697", "mrqa_squad-train-61184", "mrqa_squad-train-21687", "mrqa_squad-train-73904", "mrqa_squad-train-16753", "mrqa_squad-train-5534", "mrqa_squad-train-31966", "mrqa_squad-train-85417", "mrqa_squad-train-48589", "mrqa_squad-train-74303", "mrqa_squad-train-19876", "mrqa_squad-train-23711", "mrqa_squad-train-53060", "mrqa_squad-train-30935", "mrqa_squad-train-814", "mrqa_squad-train-37988", "mrqa_squad-train-19593", "mrqa_squad-train-15751", "mrqa_squad-train-58836", "mrqa_squad-train-24483", "mrqa_squad-train-78258", "mrqa_squad-train-50526", "mrqa_squad-train-86094", "mrqa_hotpotqa-validation-3842", "mrqa_naturalquestions-validation-7549", "mrqa_hotpotqa-validation-5682", "mrqa_naturalquestions-validation-2540", "mrqa_newsqa-validation-47", "mrqa_naturalquestions-validation-8203", "mrqa_searchqa-validation-2656", "mrqa_naturalquestions-validation-6555", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-2426", "mrqa_triviaqa-validation-7115", "mrqa_hotpotqa-validation-4434", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-8294", "mrqa_triviaqa-validation-4996", "mrqa_newsqa-validation-3459", "mrqa_triviaqa-validation-6271", "mrqa_newsqa-validation-927", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-4676", "mrqa_searchqa-validation-9536", "mrqa_triviaqa-validation-206", "mrqa_triviaqa-validation-5063", "mrqa_naturalquestions-validation-1378", "mrqa_hotpotqa-validation-1491", "mrqa_newsqa-validation-3982", "mrqa_searchqa-validation-14655", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-2558", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-3522", "mrqa_hotpotqa-validation-16"], "EFR": 0.9666666666666667, "Overall": 0.7394674059139785}, {"timecode": 62, "before_eval_results": {"predictions": ["\"Gansbaai\"", "horseracing", "Italy", "bees", "adare", "rail tour steward", "63 to 144 inches", "patcham", "squash", "Jack London", "AFC Wimbledon", "Scotland", "Edward VIII", "Bugs Bunny", "Swaziland", "ambidextrous", "bear Grylls", "Japan", "wake", "mercury", "y Yahoo!", "Klaus Barbie", "honey", "Joanne Harris", "The Forbidden Club", "george", "Moldova", "Chatsworth House", "India and Pakistan", "Bull Moose Party", "Antarctica", "eagle", "Stockholm", "Ambroz Bajec-Lapajne", "Hercules", "Real Madrid", "Tennessee whiskey", "Matthew Pinsent", "Iran", "salsa", "Cuba", "John McEnroe", "kia", "Robert Stroud", "Cat Stevens", "epidermis", "tyne", "oxygen", "mulberry", "trumpet", "Cockermouth", "more rural in its character", "October 1941", "Bharata Muni", "Amber Laura Heard", "near Philip Billard Municipal Airport", "gull-wing doors", "July 8 at London's 20,000-capacity O2 Arena.", "sexual harassment", "5,600", "tuna", "banzai", "A Moon for the Misbegotten", "If These Dolls Could Talk"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7092013888888888}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3532", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-1920", "mrqa_triviaqa-validation-1144", "mrqa_triviaqa-validation-519", "mrqa_triviaqa-validation-1562", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-1408", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-3276", "mrqa_triviaqa-validation-5993", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-988", "mrqa_hotpotqa-validation-652", "mrqa_newsqa-validation-3652", "mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-9158"], "SR": 0.6875, "CSR": 0.558531746031746, "retrieved_ids": ["mrqa_squad-train-21035", "mrqa_squad-train-46021", "mrqa_squad-train-5593", "mrqa_squad-train-73242", "mrqa_squad-train-7928", "mrqa_squad-train-60180", "mrqa_squad-train-33315", "mrqa_squad-train-12828", "mrqa_squad-train-15017", "mrqa_squad-train-22336", "mrqa_squad-train-38712", "mrqa_squad-train-55766", "mrqa_squad-train-37471", "mrqa_squad-train-56657", "mrqa_squad-train-63652", "mrqa_squad-train-43051", "mrqa_squad-train-33674", "mrqa_squad-train-76005", "mrqa_squad-train-4951", "mrqa_squad-train-2329", "mrqa_squad-train-325", "mrqa_squad-train-57818", "mrqa_squad-train-30694", "mrqa_squad-train-12956", "mrqa_squad-train-12278", "mrqa_squad-train-49052", "mrqa_squad-train-38525", "mrqa_squad-train-33111", "mrqa_squad-train-82304", "mrqa_squad-train-17249", "mrqa_squad-train-84973", "mrqa_squad-train-11228", "mrqa_hotpotqa-validation-3141", "mrqa_naturalquestions-validation-8317", "mrqa_triviaqa-validation-189", "mrqa_naturalquestions-validation-8228", "mrqa_searchqa-validation-2456", "mrqa_naturalquestions-validation-3028", "mrqa_searchqa-validation-10856", "mrqa_triviaqa-validation-1156", "mrqa_hotpotqa-validation-5328", "mrqa_naturalquestions-validation-2143", "mrqa_newsqa-validation-1569", "mrqa_triviaqa-validation-1988", "mrqa_squad-validation-8164", "mrqa_triviaqa-validation-2017", "mrqa_naturalquestions-validation-2006", "mrqa_hotpotqa-validation-4545", "mrqa_newsqa-validation-1517", "mrqa_triviaqa-validation-6833", "mrqa_naturalquestions-validation-1911", "mrqa_hotpotqa-validation-2840", "mrqa_hotpotqa-validation-2452", "mrqa_squad-validation-6848", "mrqa_hotpotqa-validation-1706", "mrqa_squad-validation-3019", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-81", "mrqa_hotpotqa-validation-350", "mrqa_newsqa-validation-3584", "mrqa_triviaqa-validation-854", "mrqa_newsqa-validation-501", "mrqa_triviaqa-validation-7690", "mrqa_naturalquestions-validation-5631"], "EFR": 0.9, "Overall": 0.7265500992063492}, {"timecode": 63, "before_eval_results": {"predictions": ["his mother.", "southern city of Naples", "\"CNN Heroes: An All-Star Tribute\"", "for the rest of the year", "canceled the swimming privileges of a nearby day care center", "Bob Bogle,", "\"We say to the people of Gaza, give more resistance and we will be with you in the field,", "his business dealings", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "People Against Switching Sides", "Haiti,", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "Darrin Tuck,", "Amsterdam, in the Netherlands, to Ankara, Turkey,", "a review of state government practices completed in 100 days.", "prostate cancer,", "90", "a birdie four at the last hole", "Rima Fakih", "JBS Swift Beef Company,", "37", "slayings of actress Sharon Tate and four others.", "33-year-old", "Isaac, and daughter, Rebecca.", "12-hour", "Judge Herman Thomas", "Game Change", "oldest documented bikinis", "free laundry service.", "angry over the treatment of Muslims,", "twice.", "lessons are simple enough -- confidence-building exercises, critical-thinking lessons", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "Friday,", "Gavin de Becker", "400 years ago", "the U.S. Consulate in Rio de Janeiro", "Apple employees", "heavy turbulence", "$3 billion", "Nkepile M abuse", "resources", "mother's memories of his mother.", "Lance Cpl. Maria Lauterbach", "then-Sen. Obama", "Technological Institute of Higher Learning of Monterrey,", "a female soldier,", "\"It was incredible. We've had so much rain, and yet today it was beautiful.", "David Russ,", "wisecracking youngster Arnold Drummond", "Chinese", "a young husband and wife and how they deal with the challenge of buying secret Christmas gifts for each other with very little money", "The stability, security, and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade", "six", "Israel", "algebra", "Chuck Yeager", "Detroit, Michigan", "on the north bank of the North Esk", "singer", "turtles", "the atmosphere", "Thief knot", "Fort Kent, Maine, at the Canada -- US border, south to Key West, Florida"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7152987558644373}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 0.14634146341463414, 1.0, 0.13333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.34782608695652173, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.9600000000000001]}}, "before_error_ids": ["mrqa_newsqa-validation-3088", "mrqa_newsqa-validation-3789", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1319", "mrqa_newsqa-validation-2103", "mrqa_newsqa-validation-2860", "mrqa_newsqa-validation-1820", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3290", "mrqa_newsqa-validation-2241", "mrqa_newsqa-validation-616", "mrqa_newsqa-validation-3087", "mrqa_newsqa-validation-2518", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1827", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1540", "mrqa_searchqa-validation-9458", "mrqa_naturalquestions-validation-6670"], "SR": 0.609375, "CSR": 0.559326171875, "retrieved_ids": ["mrqa_squad-train-43763", "mrqa_squad-train-12055", "mrqa_squad-train-37065", "mrqa_squad-train-49243", "mrqa_squad-train-85434", "mrqa_squad-train-60214", "mrqa_squad-train-18363", "mrqa_squad-train-81406", "mrqa_squad-train-43435", "mrqa_squad-train-24757", "mrqa_squad-train-10632", "mrqa_squad-train-37530", "mrqa_squad-train-46397", "mrqa_squad-train-44985", "mrqa_squad-train-85291", "mrqa_squad-train-18839", "mrqa_squad-train-5256", "mrqa_squad-train-44784", "mrqa_squad-train-19086", "mrqa_squad-train-56504", "mrqa_squad-train-50111", "mrqa_squad-train-30110", "mrqa_squad-train-59536", "mrqa_squad-train-29067", "mrqa_squad-train-71766", "mrqa_squad-train-28237", "mrqa_squad-train-77596", "mrqa_squad-train-33288", "mrqa_squad-train-53924", "mrqa_squad-train-4675", "mrqa_squad-train-55206", "mrqa_squad-train-21631", "mrqa_naturalquestions-validation-10377", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-3526", "mrqa_naturalquestions-validation-2960", "mrqa_searchqa-validation-8711", "mrqa_triviaqa-validation-4996", "mrqa_searchqa-validation-2971", "mrqa_naturalquestions-validation-10122", "mrqa_newsqa-validation-4032", "mrqa_searchqa-validation-11532", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-6216", "mrqa_hotpotqa-validation-1754", "mrqa_squad-validation-3969", "mrqa_naturalquestions-validation-7967", "mrqa_newsqa-validation-2001", "mrqa_naturalquestions-validation-809", "mrqa_triviaqa-validation-2063", "mrqa_naturalquestions-validation-988", "mrqa_triviaqa-validation-5478", "mrqa_triviaqa-validation-5613", "mrqa_searchqa-validation-16130", "mrqa_searchqa-validation-2456", "mrqa_hotpotqa-validation-5228", "mrqa_newsqa-validation-3130", "mrqa_newsqa-validation-3869", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-94", "mrqa_triviaqa-validation-4073", "mrqa_triviaqa-validation-3768", "mrqa_newsqa-validation-1988"], "EFR": 0.92, "Overall": 0.730708984375}, {"timecode": 64, "before_eval_results": {"predictions": ["the Rurik dynasty", "Labatt Blue", "sweepstakes", "General McClellan", "Agnes", "Shiraz", "Toto", "a diamond", "Bologna", "potatoes", "Princeton", "China", "the Knight", "Evian", "unicorns", "heaven", "the Andes", "Jim Jarmusch", "Martin Luther", "Miles Davis", "Tennessee", "Audrey Hepburn", "Falafel", "Aladdin", "history of Lake County, Indiana, and the Calumet region", "Derek Jeter", "Arthur C. Clarke", "Washington Redskins", "Vietnam War", "Jodie Foster", "a dynamic, contemporary Australian university", "Christian Louboutin", "a monk seal", "beer", "communication", "milk with less than 1% fat", "Linda Keene", "Beijing", "plumeria", "Lafayette", "Marie Osmond", "Martin Chuzzlewit", "Bison", "a comet", "Chuck Yeager", "Newton", "sheep", "Eragon", "Georgia", "French toast", "the Fifth Amendment", "Elvis Presley", "the Louvre Museum in Paris", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "lauren bacall", "jaws", "denarius", "18 November [O.S. 6 November] 1860", "White Horse", "the 1824 Constitution of Mexico", "Kurt Cobain", "Glasgow, Scotland", "Christopher Savoie and 6-year-old Rebecca.", "London"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6813954274891775}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.25, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.7878787878787877, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9479", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-16176", "mrqa_searchqa-validation-7596", "mrqa_searchqa-validation-6953", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-6692", "mrqa_searchqa-validation-6961", "mrqa_searchqa-validation-1377", "mrqa_searchqa-validation-13142", "mrqa_searchqa-validation-16569", "mrqa_searchqa-validation-10160", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-16755", "mrqa_searchqa-validation-10015", "mrqa_searchqa-validation-10795", "mrqa_searchqa-validation-3875", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-5831", "mrqa_hotpotqa-validation-4263", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-1900"], "SR": 0.609375, "CSR": 0.5600961538461539, "retrieved_ids": ["mrqa_squad-train-51301", "mrqa_squad-train-78418", "mrqa_squad-train-59207", "mrqa_squad-train-70705", "mrqa_squad-train-3558", "mrqa_squad-train-369", "mrqa_squad-train-59214", "mrqa_squad-train-67234", "mrqa_squad-train-23012", "mrqa_squad-train-81218", "mrqa_squad-train-82235", "mrqa_squad-train-17630", "mrqa_squad-train-35260", "mrqa_squad-train-50179", "mrqa_squad-train-43414", "mrqa_squad-train-26873", "mrqa_squad-train-14902", "mrqa_squad-train-69248", "mrqa_squad-train-47921", "mrqa_squad-train-3390", "mrqa_squad-train-49678", "mrqa_squad-train-40704", "mrqa_squad-train-67695", "mrqa_squad-train-32685", "mrqa_squad-train-44642", "mrqa_squad-train-37710", "mrqa_squad-train-7652", "mrqa_squad-train-20452", "mrqa_squad-train-4879", "mrqa_squad-train-17436", "mrqa_squad-train-34903", "mrqa_squad-train-8114", "mrqa_hotpotqa-validation-5154", "mrqa_triviaqa-validation-6396", "mrqa_naturalquestions-validation-8909", "mrqa_newsqa-validation-2595", "mrqa_naturalquestions-validation-8903", "mrqa_newsqa-validation-421", "mrqa_triviaqa-validation-3525", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1154", "mrqa_naturalquestions-validation-2969", "mrqa_hotpotqa-validation-5296", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-1255", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-3785", "mrqa_searchqa-validation-172", "mrqa_squad-validation-1672", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-4545", "mrqa_naturalquestions-validation-2605", "mrqa_naturalquestions-validation-9306", "mrqa_searchqa-validation-16378", "mrqa_triviaqa-validation-1517", "mrqa_naturalquestions-validation-8027", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-1897", "mrqa_newsqa-validation-541", "mrqa_hotpotqa-validation-1968", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-5170", "mrqa_newsqa-validation-1218"], "EFR": 0.92, "Overall": 0.7308629807692308}, {"timecode": 65, "before_eval_results": {"predictions": ["Montana", "the McClatchy Company", "Spectre", "William Tell", "The Apprentice", "Aeschylus", "the College of William", "Intelligence Quotient", "Stranger in a Strange Land", "cracker barrel", "RBIs", "Cowpoke", "Monty Python and the Holy Grail", "Ludwig van Beethoven", "Stalin", "In God We Trust", "Portland", "China", "Abishalom", "Castle Rock", "Bollywood", "the Brady", "the Habsburg", "joy", "a Twinkie", "the altitude", "the Unbearable Lightness of Being", "Richard", "Henry VIII", "SUFFIXES", "Fred Rogers", "Liliuokalani", "the pituitary", "the South African Boer War", "the pulp", "Dana Carvey", "Aswan", "Billy Ray Cyrus", "a quiver", "The Body", "Impostor syndrome", "melting", "the Godfather", "Sagittarius", "a volcano", "zinc", "Dubliners", "the Trembling Mountain of the Arabs", "Cuba", "the Taliban", "the Kennedy", "Ali", "Otis Timson", "prenatal development", "Exile", "Maria do Carmo Miranda da Cunha", "joan crawford", "superhero Birdman", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "Erich Maria Remarque", "black civil rights leaders and prominent Democrats", "no shortage of the drug while patients wait for an approved product to take its place.", "15-year-old's", "Firoz Shah Tughlaq"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5365087365591399}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true, false, true, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 0.25, 0.4, 0.5, 0.0, 0.9032258064516129, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15873", "mrqa_searchqa-validation-11355", "mrqa_searchqa-validation-9446", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-3800", "mrqa_searchqa-validation-2194", "mrqa_searchqa-validation-5095", "mrqa_searchqa-validation-10927", "mrqa_searchqa-validation-10163", "mrqa_searchqa-validation-14179", "mrqa_searchqa-validation-9120", "mrqa_searchqa-validation-11135", "mrqa_searchqa-validation-2231", "mrqa_searchqa-validation-8465", "mrqa_searchqa-validation-9081", "mrqa_searchqa-validation-16276", "mrqa_searchqa-validation-3734", "mrqa_searchqa-validation-6444", "mrqa_searchqa-validation-11604", "mrqa_searchqa-validation-8710", "mrqa_searchqa-validation-1428", "mrqa_searchqa-validation-8840", "mrqa_searchqa-validation-6273", "mrqa_searchqa-validation-15851", "mrqa_searchqa-validation-1852", "mrqa_searchqa-validation-1045", "mrqa_searchqa-validation-14981", "mrqa_searchqa-validation-1683", "mrqa_searchqa-validation-8703", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1982", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-5531", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1062", "mrqa_naturalquestions-validation-10509"], "SR": 0.421875, "CSR": 0.5580018939393939, "retrieved_ids": ["mrqa_squad-train-79962", "mrqa_squad-train-9352", "mrqa_squad-train-25816", "mrqa_squad-train-10317", "mrqa_squad-train-31965", "mrqa_squad-train-1150", "mrqa_squad-train-46900", "mrqa_squad-train-40598", "mrqa_squad-train-30953", "mrqa_squad-train-11453", "mrqa_squad-train-40302", "mrqa_squad-train-47577", "mrqa_squad-train-17843", "mrqa_squad-train-78294", "mrqa_squad-train-80319", "mrqa_squad-train-39128", "mrqa_squad-train-46269", "mrqa_squad-train-26274", "mrqa_squad-train-70008", "mrqa_squad-train-15947", "mrqa_squad-train-67734", "mrqa_squad-train-44188", "mrqa_squad-train-52611", "mrqa_squad-train-78872", "mrqa_squad-train-67379", "mrqa_squad-train-24621", "mrqa_squad-train-45312", "mrqa_squad-train-69005", "mrqa_squad-train-41497", "mrqa_squad-train-37072", "mrqa_squad-train-51335", "mrqa_squad-train-61627", "mrqa_triviaqa-validation-284", "mrqa_hotpotqa-validation-4263", "mrqa_naturalquestions-validation-1782", "mrqa_squad-validation-7943", "mrqa_naturalquestions-validation-3319", "mrqa_hotpotqa-validation-347", "mrqa_naturalquestions-validation-7957", "mrqa_searchqa-validation-15103", "mrqa_hotpotqa-validation-21", "mrqa_searchqa-validation-5928", "mrqa_naturalquestions-validation-5348", "mrqa_newsqa-validation-3232", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-3505", "mrqa_newsqa-validation-1496", "mrqa_naturalquestions-validation-7144", "mrqa_triviaqa-validation-4966", "mrqa_naturalquestions-validation-6046", "mrqa_searchqa-validation-9479", "mrqa_squad-validation-3946", "mrqa_triviaqa-validation-594", "mrqa_hotpotqa-validation-3216", "mrqa_searchqa-validation-4768", "mrqa_triviaqa-validation-2819", "mrqa_newsqa-validation-1514", "mrqa_triviaqa-validation-5278", "mrqa_searchqa-validation-5149", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-1032", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-4436"], "EFR": 0.8378378378378378, "Overall": 0.7140116963554464}, {"timecode": 66, "before_eval_results": {"predictions": ["eight", "synthesizing vitamin B and vitamin K", "December 20, 1951", "the ninth w\u0101", "Terry Kath", "comprehend and formulate language", "hyperirritable spots in the fascia surrounding skeletal muscle", "when the Moon's ecliptic longitude and the Sun's Ecliptics longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "1546", "Lord Banquo", "January 1923", "The identity of the second `` A '', Red Coat, and the leader of the `` A- Team '' was revealed to be CeCe Drake", "a habitat", "minced meat", "geophysicists", "free floating", "the United States", "Help!", "30 October 1918", "Austria - Hungary", "Domhnall Gleeson", "13 to 22 June 2012", "T - Bone Walker", "Paul Baumer", "in Paradise, Nevada", "the Executive Residence of the White House Complex", "Article Two", "April 13, 2018", "Bush", "Yuzuru Hanyu", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "across the Strait of Magellan", "the five - year time jump", "336", "January 1, 2016", "Leonardo da Vinci", "the absolute temperature", "Thawne", "Philippe Petit", "Proposition 103", "2004", "inside the cell nucleus", "Julie Adams", "The palace has 775 rooms", "Pakistan", "Xiu Li Dai", "the Miracles", "Americans who served in the armed forces and as civilians during World War II", "eight years", "James Fleet", "the year AD 1 immediately follows the year 1 BC", "David Davis", "Dirty Dancing", "mumps", "Delphi Lawrence", "2 May 2015", "The International Boxing Federation (IBF) is one of four major organizations recognized by the International Boxing Hall of Fame (IBHOF)", "J.Crew,", "Pakistani officials,", "Almost all British", "Jamaica", "tuna", "Delphi", "they accepted the Liverpool captain's version that he acted in self defense in punching businessman Marcus McGhee."], "metric_results": {"EM": 0.65625, "QA-F1": 0.7303010062720741}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.8095238095238095, 1.0, 0.6666666666666666, 1.0, 0.23529411764705882, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 0.2, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4347826086956522, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-6519", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-8450", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-10015", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4419", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-47", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1259", "mrqa_searchqa-validation-5072", "mrqa_newsqa-validation-37"], "SR": 0.65625, "CSR": 0.5594682835820896, "retrieved_ids": ["mrqa_squad-train-6678", "mrqa_squad-train-27676", "mrqa_squad-train-16846", "mrqa_squad-train-6319", "mrqa_squad-train-44448", "mrqa_squad-train-30793", "mrqa_squad-train-67079", "mrqa_squad-train-3098", "mrqa_squad-train-3212", "mrqa_squad-train-85947", "mrqa_squad-train-12301", "mrqa_squad-train-27174", "mrqa_squad-train-86191", "mrqa_squad-train-59333", "mrqa_squad-train-51833", "mrqa_squad-train-1326", "mrqa_squad-train-36751", "mrqa_squad-train-17315", "mrqa_squad-train-20968", "mrqa_squad-train-25823", "mrqa_squad-train-61674", "mrqa_squad-train-56177", "mrqa_squad-train-36808", "mrqa_squad-train-60916", "mrqa_squad-train-52864", "mrqa_squad-train-73837", "mrqa_squad-train-2044", "mrqa_squad-train-21425", "mrqa_squad-train-73735", "mrqa_squad-train-56459", "mrqa_squad-train-72547", "mrqa_squad-train-6273", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-4940", "mrqa_triviaqa-validation-2073", "mrqa_squad-validation-6319", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-868", "mrqa_triviaqa-validation-5342", "mrqa_newsqa-validation-1733", "mrqa_squad-validation-1136", "mrqa_naturalquestions-validation-1426", "mrqa_triviaqa-validation-2544", "mrqa_triviaqa-validation-2199", "mrqa_newsqa-validation-1319", "mrqa_naturalquestions-validation-7067", "mrqa_newsqa-validation-1570", "mrqa_naturalquestions-validation-5611", "mrqa_searchqa-validation-7780", "mrqa_hotpotqa-validation-5644", "mrqa_triviaqa-validation-519", "mrqa_hotpotqa-validation-3919", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6424", "mrqa_hotpotqa-validation-5307", "mrqa_triviaqa-validation-4317", "mrqa_searchqa-validation-12440", "mrqa_searchqa-validation-12996", "mrqa_triviaqa-validation-3532", "mrqa_hotpotqa-validation-5464", "mrqa_newsqa-validation-4086", "mrqa_hotpotqa-validation-1664", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-1505"], "EFR": 0.9090909090909091, "Overall": 0.7285555885345997}, {"timecode": 67, "before_eval_results": {"predictions": ["Pyeongchang County, Gangwon Province, South Korea", "Padawan", "in a liquid solution", "April 1917", "London", "Utah", "1970", "by October 1986", "the referee", "English law", "parthenogenesis", "Carolinas Crandell", "Reproductive system", "Taiwan", "local authorities, specifically London Boroughs, Metropolitan boroughs, unitary authorities, and district councils, who took over this power from the Justices of the Peace", "terrier", "Gibraltar", "September 1947", "7 July", "in the bone marrow", "Sophia Akuffo", "of who the better fighters are relative to their weight", "the team", "Sarah Josepha Hale", "Ingrid Bergman", "Jessica Simpson", "on the microscope's stage", "the Old Testament", "Daren Maxwell Kagasoff", "Steveston Outdoor pool in Richmond, BC", "Thomas Lennon", "Michigan and surrounding states and provinces", "a recognized group of people who jointly oversee the activities of an organization", "Friedman Billings Ramsey", "Miami Heat of the National Basketball Association ( NBA )", "vasoconstriction of most blood vessels, including many of those in the skin, the digestive tract, and the kidneys", "Toronto Islands", "lighter", "the final episode of the series", "Roger Nichols and Paul Williams", "Konakuppakatil Gopinathan Balakrishnan", "Car Ryan Evancic", "a Border Collie", "Vesta", "1665 to 1666", "sugars and amino acids", "Menelaus", "on the continent of Antarctica", "California", "during Christmas season in the late 1970s", "December 1349", "Ipswich Town", "post-impressionist", "British Airways", "Genderqueer", "14,372", "YouTube", "five victims", "Joel \"Taz\" DiGregorio", "system of military trials", "the Death Valley", "1972", "Ichabod Crane", "Thomas Jefferson"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6869327984817115}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.17391304347826084, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.5, 1.0, 0.1739130434782609, 1.0, 1.0, 0.4444444444444445, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2972", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-2870", "mrqa_naturalquestions-validation-4454", "mrqa_naturalquestions-validation-836", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-10107", "mrqa_naturalquestions-validation-1269", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-4558", "mrqa_triviaqa-validation-263", "mrqa_hotpotqa-validation-621", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-4207"], "SR": 0.578125, "CSR": 0.5597426470588236, "retrieved_ids": ["mrqa_squad-train-67490", "mrqa_squad-train-81518", "mrqa_squad-train-39100", "mrqa_squad-train-25274", "mrqa_squad-train-23131", "mrqa_squad-train-35289", "mrqa_squad-train-21048", "mrqa_squad-train-30675", "mrqa_squad-train-5813", "mrqa_squad-train-26268", "mrqa_squad-train-51790", "mrqa_squad-train-56380", "mrqa_squad-train-29287", "mrqa_squad-train-62982", "mrqa_squad-train-12079", "mrqa_squad-train-69432", "mrqa_squad-train-47640", "mrqa_squad-train-26587", "mrqa_squad-train-13785", "mrqa_squad-train-46925", "mrqa_squad-train-12531", "mrqa_squad-train-41135", "mrqa_squad-train-11445", "mrqa_squad-train-13183", "mrqa_squad-train-16602", "mrqa_squad-train-84143", "mrqa_squad-train-27831", "mrqa_squad-train-69560", "mrqa_squad-train-86465", "mrqa_squad-train-38124", "mrqa_squad-train-10928", "mrqa_squad-train-57160", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-8534", "mrqa_newsqa-validation-3679", "mrqa_triviaqa-validation-51", "mrqa_newsqa-validation-1060", "mrqa_newsqa-validation-1547", "mrqa_searchqa-validation-15613", "mrqa_triviaqa-validation-3809", "mrqa_naturalquestions-validation-10039", "mrqa_hotpotqa-validation-2178", "mrqa_naturalquestions-validation-5719", "mrqa_newsqa-validation-1994", "mrqa_hotpotqa-validation-4274", "mrqa_hotpotqa-validation-3020", "mrqa_naturalquestions-validation-3828", "mrqa_newsqa-validation-3733", "mrqa_hotpotqa-validation-4069", "mrqa_naturalquestions-validation-767", "mrqa_naturalquestions-validation-4740", "mrqa_triviaqa-validation-3505", "mrqa_naturalquestions-validation-4547", "mrqa_newsqa-validation-1462", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-2632", "mrqa_newsqa-validation-3789", "mrqa_hotpotqa-validation-2198", "mrqa_squad-validation-2043", "mrqa_naturalquestions-validation-6670", "mrqa_triviaqa-validation-1395", "mrqa_hotpotqa-validation-4434", "mrqa_triviaqa-validation-3495"], "EFR": 0.9259259259259259, "Overall": 0.7319774645969499}, {"timecode": 68, "before_eval_results": {"predictions": ["Malaysia", "nomadic people", "5.4%", "Parkinson's Disease", "Patrick Henry", "Warsaw", "capital of this capital", "a carat diamond", "Botswana", "(Clay) Aiken", "Muhammad", "Oceania", "Namath", "high and dry", "a doll", "the inquisition of Peru", "Cleopatra VII", "the International Space Station", "Iran", "Gaius Cassius Longinus", "the Charleston", "South Africa", "John Deere", "Thames", "Oxford", "(William) Wordsworth", "\"Elphaba\"", "Tuscaloosa", "Germany", "Sabino Canyon", "Frasier Crane", "Bob Dylan", "Sicily", "Herbert Hoover", "Zhou Enlai", "pizza", "Lake Geneva", "bacall", "The Mole", "HIV/AIDS", "Today Show", "Golden", "liver cancer", "Bern", "bchamel", "Jackie Robinson", "Buzzbee", "Diane Arbus", "(Willa) Cather", "overrule", "the marathon", "Masha Skorobogatov", "Kyla Pratt", "Dumont d'Urville Station", "Union Gap", "michael d. kinghorn", "Cameroon", "Ding Sheng", "May 5, 2015", "Massapequa", "on a dangerous stretch of Highway 18 near Grand Ronde, Oregon.", "1937,", "transit bombings", "an acid phosphate"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6061698717948718}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3218", "mrqa_searchqa-validation-2956", "mrqa_searchqa-validation-14101", "mrqa_searchqa-validation-13698", "mrqa_searchqa-validation-10614", "mrqa_searchqa-validation-11096", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-6130", "mrqa_searchqa-validation-1918", "mrqa_searchqa-validation-13041", "mrqa_searchqa-validation-16229", "mrqa_searchqa-validation-2049", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13061", "mrqa_searchqa-validation-1415", "mrqa_searchqa-validation-12391", "mrqa_searchqa-validation-6816", "mrqa_searchqa-validation-14310", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-14259", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-9364", "mrqa_searchqa-validation-12621", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-3166", "mrqa_hotpotqa-validation-2112", "mrqa_hotpotqa-validation-3538", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-1457", "mrqa_triviaqa-validation-3820"], "SR": 0.515625, "CSR": 0.5591032608695652, "retrieved_ids": ["mrqa_squad-train-63119", "mrqa_squad-train-58646", "mrqa_squad-train-62535", "mrqa_squad-train-76700", "mrqa_squad-train-62980", "mrqa_squad-train-47384", "mrqa_squad-train-70596", "mrqa_squad-train-64351", "mrqa_squad-train-46441", "mrqa_squad-train-56106", "mrqa_squad-train-9588", "mrqa_squad-train-33916", "mrqa_squad-train-73122", "mrqa_squad-train-18368", "mrqa_squad-train-34333", "mrqa_squad-train-80852", "mrqa_squad-train-66387", "mrqa_squad-train-66222", "mrqa_squad-train-56528", "mrqa_squad-train-39574", "mrqa_squad-train-61343", "mrqa_squad-train-61004", "mrqa_squad-train-67391", "mrqa_squad-train-38797", "mrqa_squad-train-552", "mrqa_squad-train-13311", "mrqa_squad-train-27737", "mrqa_squad-train-25595", "mrqa_squad-train-7421", "mrqa_squad-train-69126", "mrqa_squad-train-24063", "mrqa_squad-train-6954", "mrqa_searchqa-validation-4356", "mrqa_naturalquestions-validation-8934", "mrqa_squad-validation-3985", "mrqa_squad-validation-7353", "mrqa_newsqa-validation-3130", "mrqa_newsqa-validation-2086", "mrqa_naturalquestions-validation-1813", "mrqa_hotpotqa-validation-4086", "mrqa_naturalquestions-validation-5912", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-2800", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-10331", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-3761", "mrqa_triviaqa-validation-7011", "mrqa_triviaqa-validation-2819", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2735", "mrqa_hotpotqa-validation-957", "mrqa_searchqa-validation-8374", "mrqa_squad-validation-6655", "mrqa_hotpotqa-validation-4047", "mrqa_triviaqa-validation-1988", "mrqa_naturalquestions-validation-10311", "mrqa_searchqa-validation-15973", "mrqa_triviaqa-validation-5377", "mrqa_searchqa-validation-14981", "mrqa_newsqa-validation-3918", "mrqa_naturalquestions-validation-5170", "mrqa_triviaqa-validation-1714"], "EFR": 1.0, "Overall": 0.746664402173913}, {"timecode": 69, "before_eval_results": {"predictions": ["aqueduct", "quark", "Christopher Reeve", "Romania", "Macbeth", "John Jacob Astor", "\"Don't Think Twice\"", "South Station", "The Sun Also Rises", "Cherokee", "Ferrari", "L'Appart", "Iberian", "Joe Hill", "Job", "Kentucky", "Supernatural", "jane Foucault", "Montana", "Deep brain stimulation", "kissanhnt", "the Amazon", "Oklahoma", "Anne Hathaway", "Model T", "Iraq", "Vietnam", "(William) Wordsworth", "Canuck", "Cecil Day-Lewis", "Sir Isaac Newton", "the Blue Ridge Mountain", "Frdric Chopin", "Susan B. Anthony", "julia stiles", "the opossum rat", "the Washington Bullets", "Starsky", "Batman", "Knocked Up", "the Space Chimps", "Chick Corea", "jazz", "South Carolina", "Han Solo", "george bredsdorff", "triumphal arch", "president Porfirio Diaz", "a veil", "Goldwater", "Guinness", "Portugal. The Man", "1983", "singers Laura Williams and Sally Dworsky provide the singing voices of young and adult Nala respectively", "pumas", "jane Seymour", "Greek", "Academy Award for Best Animated Feature", "1937", "Stephen James Ireland", "a group of college students of Pakistani background", "Copts", "\"an eye for an eye,\"", "Retina display"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5370098039215687}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, false, true, false, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16658", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-1986", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-13478", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-5269", "mrqa_searchqa-validation-119", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-244", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-9260", "mrqa_searchqa-validation-1816", "mrqa_searchqa-validation-10046", "mrqa_searchqa-validation-6956", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-909", "mrqa_searchqa-validation-12728", "mrqa_searchqa-validation-14736", "mrqa_searchqa-validation-10184", "mrqa_searchqa-validation-9078", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-2333", "mrqa_searchqa-validation-6185", "mrqa_searchqa-validation-2934", "mrqa_searchqa-validation-5427", "mrqa_naturalquestions-validation-6349", "mrqa_triviaqa-validation-3274", "mrqa_triviaqa-validation-1437", "mrqa_triviaqa-validation-7182", "mrqa_hotpotqa-validation-987", "mrqa_newsqa-validation-2238", "mrqa_newsqa-validation-2435"], "SR": 0.453125, "CSR": 0.5575892857142857, "retrieved_ids": ["mrqa_squad-train-37892", "mrqa_squad-train-64745", "mrqa_squad-train-2576", "mrqa_squad-train-41890", "mrqa_squad-train-36522", "mrqa_squad-train-82202", "mrqa_squad-train-12939", "mrqa_squad-train-80701", "mrqa_squad-train-46098", "mrqa_squad-train-74952", "mrqa_squad-train-81047", "mrqa_squad-train-83152", "mrqa_squad-train-20304", "mrqa_squad-train-36232", "mrqa_squad-train-40574", "mrqa_squad-train-65229", "mrqa_squad-train-10190", "mrqa_squad-train-23901", "mrqa_squad-train-25861", "mrqa_squad-train-71305", "mrqa_squad-train-40411", "mrqa_squad-train-74662", "mrqa_squad-train-6850", "mrqa_squad-train-83536", "mrqa_squad-train-13466", "mrqa_squad-train-41578", "mrqa_squad-train-74984", "mrqa_squad-train-20741", "mrqa_squad-train-29944", "mrqa_squad-train-37026", "mrqa_squad-train-23858", "mrqa_squad-train-47734", "mrqa_hotpotqa-validation-1614", "mrqa_searchqa-validation-1770", "mrqa_triviaqa-validation-2478", "mrqa_naturalquestions-validation-5719", "mrqa_searchqa-validation-3451", "mrqa_newsqa-validation-3491", "mrqa_naturalquestions-validation-5631", "mrqa_newsqa-validation-1076", "mrqa_naturalquestions-validation-3352", "mrqa_newsqa-validation-4030", "mrqa_naturalquestions-validation-7095", "mrqa_searchqa-validation-709", "mrqa_newsqa-validation-1761", "mrqa_triviaqa-validation-5624", "mrqa_newsqa-validation-3518", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-5702", "mrqa_triviaqa-validation-1683", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-8164", "mrqa_naturalquestions-validation-636", "mrqa_hotpotqa-validation-5549", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-6670", "mrqa_naturalquestions-validation-1133", "mrqa_hotpotqa-validation-957", "mrqa_triviaqa-validation-826", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-3605", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-707"], "EFR": 0.9714285714285714, "Overall": 0.7406473214285715}, {"timecode": 70, "UKR": 0.828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1172", "mrqa_hotpotqa-validation-1216", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-1866", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-1910", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2195", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2232", "mrqa_hotpotqa-validation-2369", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-2802", "mrqa_hotpotqa-validation-2819", "mrqa_hotpotqa-validation-2888", "mrqa_hotpotqa-validation-3034", "mrqa_hotpotqa-validation-3059", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3263", "mrqa_hotpotqa-validation-3355", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-3783", "mrqa_hotpotqa-validation-3790", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3878", "mrqa_hotpotqa-validation-39", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4590", "mrqa_hotpotqa-validation-4613", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-5124", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-5275", "mrqa_hotpotqa-validation-5279", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5578", "mrqa_hotpotqa-validation-5594", "mrqa_hotpotqa-validation-5595", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-722", "mrqa_hotpotqa-validation-789", "mrqa_hotpotqa-validation-84", "mrqa_hotpotqa-validation-978", "mrqa_naturalquestions-validation-10107", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-10549", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-1120", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-1763", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-2972", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3170", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-3805", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4029", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-4890", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5359", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6279", "mrqa_naturalquestions-validation-6349", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-793", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-8207", "mrqa_naturalquestions-validation-8290", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-8668", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-9857", "mrqa_naturalquestions-validation-9897", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-110", "mrqa_newsqa-validation-1196", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1254", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-1366", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1422", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-1488", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1517", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-1634", "mrqa_newsqa-validation-1640", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1935", "mrqa_newsqa-validation-2001", "mrqa_newsqa-validation-2102", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-230", "mrqa_newsqa-validation-2365", "mrqa_newsqa-validation-2384", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2951", "mrqa_newsqa-validation-3024", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-325", "mrqa_newsqa-validation-3251", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-3605", "mrqa_newsqa-validation-3721", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-376", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3917", "mrqa_newsqa-validation-395", "mrqa_newsqa-validation-3963", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-496", "mrqa_newsqa-validation-551", "mrqa_newsqa-validation-604", "mrqa_newsqa-validation-643", "mrqa_newsqa-validation-669", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-872", "mrqa_newsqa-validation-91", "mrqa_newsqa-validation-963", "mrqa_searchqa-validation-10015", "mrqa_searchqa-validation-10613", "mrqa_searchqa-validation-10670", "mrqa_searchqa-validation-10795", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-11965", "mrqa_searchqa-validation-12252", "mrqa_searchqa-validation-12391", "mrqa_searchqa-validation-12646", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-13041", "mrqa_searchqa-validation-13061", "mrqa_searchqa-validation-13120", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13384", "mrqa_searchqa-validation-13478", "mrqa_searchqa-validation-14310", "mrqa_searchqa-validation-14334", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-15580", "mrqa_searchqa-validation-15686", "mrqa_searchqa-validation-16021", "mrqa_searchqa-validation-16209", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16378", "mrqa_searchqa-validation-16569", "mrqa_searchqa-validation-1986", "mrqa_searchqa-validation-2038", "mrqa_searchqa-validation-2268", "mrqa_searchqa-validation-2304", "mrqa_searchqa-validation-3018", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3573", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-3809", "mrqa_searchqa-validation-4089", "mrqa_searchqa-validation-4169", "mrqa_searchqa-validation-4581", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-4836", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5746", "mrqa_searchqa-validation-5886", "mrqa_searchqa-validation-5911", "mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-6252", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-663", "mrqa_searchqa-validation-6876", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-7527", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-7871", "mrqa_searchqa-validation-8214", "mrqa_searchqa-validation-8276", "mrqa_searchqa-validation-8465", "mrqa_searchqa-validation-8623", "mrqa_searchqa-validation-8638", "mrqa_searchqa-validation-9490", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9853", "mrqa_squad-validation-10369", "mrqa_squad-validation-10477", "mrqa_squad-validation-1125", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-127", "mrqa_squad-validation-1371", "mrqa_squad-validation-2328", "mrqa_squad-validation-2467", "mrqa_squad-validation-259", "mrqa_squad-validation-2691", "mrqa_squad-validation-280", "mrqa_squad-validation-2943", "mrqa_squad-validation-2959", "mrqa_squad-validation-3052", "mrqa_squad-validation-3124", "mrqa_squad-validation-3144", "mrqa_squad-validation-3230", "mrqa_squad-validation-3241", "mrqa_squad-validation-335", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3608", "mrqa_squad-validation-3703", "mrqa_squad-validation-3832", "mrqa_squad-validation-3852", "mrqa_squad-validation-386", "mrqa_squad-validation-3919", "mrqa_squad-validation-3946", "mrqa_squad-validation-3955", "mrqa_squad-validation-3969", "mrqa_squad-validation-3994", "mrqa_squad-validation-4066", "mrqa_squad-validation-415", "mrqa_squad-validation-4312", "mrqa_squad-validation-4326", "mrqa_squad-validation-4467", "mrqa_squad-validation-4528", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5110", "mrqa_squad-validation-5320", "mrqa_squad-validation-5422", "mrqa_squad-validation-5493", "mrqa_squad-validation-5604", "mrqa_squad-validation-5726", "mrqa_squad-validation-5781", "mrqa_squad-validation-5960", "mrqa_squad-validation-6169", "mrqa_squad-validation-6229", "mrqa_squad-validation-6243", "mrqa_squad-validation-6502", "mrqa_squad-validation-6638", "mrqa_squad-validation-6875", "mrqa_squad-validation-6957", "mrqa_squad-validation-7064", "mrqa_squad-validation-739", "mrqa_squad-validation-7549", "mrqa_squad-validation-7688", "mrqa_squad-validation-7708", "mrqa_squad-validation-7717", "mrqa_squad-validation-7751", "mrqa_squad-validation-7917", "mrqa_squad-validation-8309", "mrqa_squad-validation-8754", "mrqa_squad-validation-8904", "mrqa_squad-validation-893", "mrqa_squad-validation-8958", "mrqa_squad-validation-9446", "mrqa_squad-validation-959", "mrqa_squad-validation-9716", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1147", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-12", "mrqa_triviaqa-validation-1239", "mrqa_triviaqa-validation-1290", "mrqa_triviaqa-validation-143", "mrqa_triviaqa-validation-1512", "mrqa_triviaqa-validation-1517", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-1802", "mrqa_triviaqa-validation-189", "mrqa_triviaqa-validation-1917", "mrqa_triviaqa-validation-2000", "mrqa_triviaqa-validation-2004", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-205", "mrqa_triviaqa-validation-2075", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-2404", "mrqa_triviaqa-validation-2420", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-2527", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2705", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2936", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-2940", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-3043", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3079", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-3348", "mrqa_triviaqa-validation-341", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-3495", "mrqa_triviaqa-validation-3522", "mrqa_triviaqa-validation-3534", "mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-3747", "mrqa_triviaqa-validation-3768", "mrqa_triviaqa-validation-3936", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-3967", "mrqa_triviaqa-validation-3999", "mrqa_triviaqa-validation-4006", "mrqa_triviaqa-validation-4306", "mrqa_triviaqa-validation-4328", "mrqa_triviaqa-validation-4447", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-4655", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-483", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4956", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5035", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-5141", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-5668", "mrqa_triviaqa-validation-5691", "mrqa_triviaqa-validation-5726", "mrqa_triviaqa-validation-5763", "mrqa_triviaqa-validation-5823", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5861", "mrqa_triviaqa-validation-5897", "mrqa_triviaqa-validation-595", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6475", "mrqa_triviaqa-validation-6522", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6549", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6571", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6833", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7140", "mrqa_triviaqa-validation-7190", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7417", "mrqa_triviaqa-validation-7439", "mrqa_triviaqa-validation-7497", "mrqa_triviaqa-validation-7727", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-839", "mrqa_triviaqa-validation-917"], "OKR": 0.896484375, "KG": 0.50390625, "before_eval_results": {"predictions": ["Kathy Najimy", "2006 -- 07", "The Divergent Series : Ascendant", "Mel Tillis", "2026", "Clare Torry", "Andrew Lloyd Webber", "Hollywood Masonic Temple ( now known as the El Capitan Entertainment Centre )", "hit points or health points", "Stephen Graham", "5 - 7", "1955", "Owen Hunt ( Kevin McKidd )", "Parthenogenesis", "fertilization", "Yente", "Judy Garland, Carole Landis, Dean Martin, and Ethel Merman", "stems and roots of certain vascular plants", "a Czech word, robota", "skeletal muscle and the brain", "Nazi Germany and Fascist Italy", "Gunpei Yokoi", "David Motl", "a simple majority vote", "September 9, 2010", "a tradeable entity used to avoid the inconvenienceiences of a pure barter system", "scrolls dating back to the 12th century", "Buddhism", "Kiss", "the eighth series of the UK version of The X Factor", "Trace Adkins", "the optic chiasm", "to manage the characteristics of the beer's head", "United States, the United Kingdom, and their respective allies", "Chrysler 300 `` letter series '' ; a large, high - performance luxury coupe sold in very limited numbers", "James Intveld", "15 February 1998", "Christopher Allen Lloyd", "100,000", "January 2004", "Bartolomeu Dias", "Isabela Moner", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "potential of hydrogen", "Fall 1998", "the Qianlong Emperor", "Guwahati", "languages diverse as Azerbaijani, Malayalam and Welsh as well as the dead languages Latin and Ancient Greek", "Khoisan language of the \u01c0Xam people", "Rufus and Chaka Khan", "eight", "Venado Tuerto, Argentina", "Jamaica", "mead", "Tomorrowland", "the Tallahassee City Commission", "John Kavanagh", "pesos", "Martin Buber, Emanuel Levinas, or Primo Levi also produced the Stern Gang, Meir Kahane and Baruch Goldstein.", "123 pounds of cocaine and 4.5 pounds of heroin,", "In Memoriam", "Mercury", "Oz", "UNICEF"], "metric_results": {"EM": 0.625, "QA-F1": 0.7226302516927517}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.22222222222222224, 0.18181818181818182, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 0.0, 0.9, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7692307692307692, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.07999999999999999, 1.0, 1.0, 1.0, 0.9600000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-1567", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-6968", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-7593", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-6378", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3358", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-9150", "mrqa_triviaqa-validation-4646", "mrqa_hotpotqa-validation-3032", "mrqa_newsqa-validation-1309"], "SR": 0.625, "CSR": 0.5585387323943662, "retrieved_ids": ["mrqa_squad-train-66119", "mrqa_squad-train-8667", "mrqa_squad-train-42029", "mrqa_squad-train-77186", "mrqa_squad-train-51357", "mrqa_squad-train-68060", "mrqa_squad-train-25699", "mrqa_squad-train-81634", "mrqa_squad-train-19799", "mrqa_squad-train-60065", "mrqa_squad-train-41244", "mrqa_squad-train-20102", "mrqa_squad-train-48233", "mrqa_squad-train-4293", "mrqa_squad-train-64865", "mrqa_squad-train-82750", "mrqa_squad-train-11485", "mrqa_squad-train-70468", "mrqa_squad-train-50238", "mrqa_squad-train-79846", "mrqa_squad-train-7110", "mrqa_squad-train-68377", "mrqa_squad-train-34351", "mrqa_squad-train-61467", "mrqa_squad-train-38720", "mrqa_squad-train-64386", "mrqa_squad-train-66638", "mrqa_squad-train-76087", "mrqa_squad-train-44788", "mrqa_squad-train-16345", "mrqa_squad-train-83918", "mrqa_squad-train-19737", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-3028", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-8159", "mrqa_newsqa-validation-2476", "mrqa_triviaqa-validation-4240", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-5470", "mrqa_newsqa-validation-3523", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-4832", "mrqa_naturalquestions-validation-2080", "mrqa_triviaqa-validation-3954", "mrqa_naturalquestions-validation-104", "mrqa_naturalquestions-validation-5538", "mrqa_searchqa-validation-2143", "mrqa_newsqa-validation-2905", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-3419", "mrqa_naturalquestions-validation-7172", "mrqa_newsqa-validation-686", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-3963", "mrqa_naturalquestions-validation-4348", "mrqa_triviaqa-validation-2385", "mrqa_searchqa-validation-12129", "mrqa_triviaqa-validation-4411", "mrqa_newsqa-validation-2723", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-3431", "mrqa_newsqa-validation-1403"], "EFR": 0.875, "Overall": 0.7324108714788732}, {"timecode": 71, "before_eval_results": {"predictions": ["Easter", "George Balanchine", "Jimi Hendrix", "the Mesozoic Era", "Austen", "Leonardo DiCaprio", "the Basque", "Cherry Jones", "Happy Feet", "a guardian angel", "the United States Naval Academy", "Trent", "Law & Order: Special Victims Unit", "the Caucasus", "(June) Carter Cash", "Cape Town", "the Great Barrier", "(David) Farragut", "1:24 a.m.", "salaried", "a Skull", "Marie Osmond", "Scrabble", "suckers", "the Catholic Church", "London", "Burgenland", "Halliburton", "the retina", "Boston", "anamosa", "the spelling bee", "poetry", "the Battle of Fort Donelson", "the 1950s", "the Rich and Famous", "sucrose", "Shropshire", "Cuba", "The Prince and the Pauper", "Thomas Paine", "Abraham Lincoln", "Lord North", "Charles I", "the Jemima", "Diane Arbus", "Gujarat", "(George) Bernard Shaw", "Utah", "Humulin", "Kublai Khan", "difficulties of the pulmonary circulation", "Kimberlin Brown", "Henry Selick", "Caviar", "July 20, 1969", "argentina", "the vicar of Wantage", "Mark Feld", "Jewish", "a collapsed apartment building in Cologne, Germany,", "Kurdish Gas City", "$40 and a loaf of bread.", "argentina"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5243427579365079}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4530", "mrqa_searchqa-validation-13583", "mrqa_searchqa-validation-8544", "mrqa_searchqa-validation-1158", "mrqa_searchqa-validation-13029", "mrqa_searchqa-validation-10353", "mrqa_searchqa-validation-1827", "mrqa_searchqa-validation-13396", "mrqa_searchqa-validation-9571", "mrqa_searchqa-validation-5919", "mrqa_searchqa-validation-4309", "mrqa_searchqa-validation-4000", "mrqa_searchqa-validation-12776", "mrqa_searchqa-validation-3932", "mrqa_searchqa-validation-14359", "mrqa_searchqa-validation-15548", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-15280", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-550", "mrqa_searchqa-validation-16607", "mrqa_searchqa-validation-9495", "mrqa_searchqa-validation-12497", "mrqa_searchqa-validation-6350", "mrqa_searchqa-validation-15590", "mrqa_naturalquestions-validation-1680", "mrqa_triviaqa-validation-2140", "mrqa_triviaqa-validation-3746", "mrqa_hotpotqa-validation-3593", "mrqa_hotpotqa-validation-3503", "mrqa_hotpotqa-validation-2493", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3002", "mrqa_triviaqa-validation-1782"], "SR": 0.453125, "CSR": 0.5570746527777778, "retrieved_ids": ["mrqa_squad-train-15955", "mrqa_squad-train-59008", "mrqa_squad-train-15679", "mrqa_squad-train-86167", "mrqa_squad-train-9646", "mrqa_squad-train-7622", "mrqa_squad-train-18115", "mrqa_squad-train-71165", "mrqa_squad-train-67112", "mrqa_squad-train-24479", "mrqa_squad-train-74937", "mrqa_squad-train-57359", "mrqa_squad-train-83905", "mrqa_squad-train-45584", "mrqa_squad-train-77936", "mrqa_squad-train-27639", "mrqa_squad-train-72720", "mrqa_squad-train-7723", "mrqa_squad-train-34123", "mrqa_squad-train-31941", "mrqa_squad-train-80087", "mrqa_squad-train-19745", "mrqa_squad-train-70594", "mrqa_squad-train-36659", "mrqa_squad-train-22888", "mrqa_squad-train-58832", "mrqa_squad-train-6720", "mrqa_squad-train-74406", "mrqa_squad-train-10826", "mrqa_squad-train-44503", "mrqa_squad-train-26605", "mrqa_squad-train-26857", "mrqa_triviaqa-validation-4482", "mrqa_naturalquestions-validation-7896", "mrqa_newsqa-validation-216", "mrqa_naturalquestions-validation-3332", "mrqa_triviaqa-validation-3275", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-8441", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-715", "mrqa_searchqa-validation-13746", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-2998", "mrqa_hotpotqa-validation-3157", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-7694", "mrqa_newsqa-validation-2984", "mrqa_hotpotqa-validation-1127", "mrqa_naturalquestions-validation-6149", "mrqa_squad-validation-3497", "mrqa_newsqa-validation-1693", "mrqa_hotpotqa-validation-3842", "mrqa_naturalquestions-validation-8228", "mrqa_newsqa-validation-3978", "mrqa_triviaqa-validation-4458", "mrqa_squad-validation-1765", "mrqa_naturalquestions-validation-4302", "mrqa_searchqa-validation-12267", "mrqa_newsqa-validation-3679", "mrqa_triviaqa-validation-6237", "mrqa_newsqa-validation-2509"], "EFR": 0.9142857142857143, "Overall": 0.7399751984126984}, {"timecode": 72, "before_eval_results": {"predictions": ["Vienna", "peninsulas", "western", "Brazil", "Applebee's", "North Carolina", "backgammon", "St sleepless Dan", "Artemis", "Hobart", "Colorado Springs", "Cheap Trick", "Spinach", "Islam", "Cerberus", "Robert E. Lee", "Trinidad", "Brigadoon", "Columbus", "Elijah Muhammad", "(Tom) Mayer", "Federico Fellini", "Fenway Park", "C.T. Eisler", "The Princess Diaries", "fluoridation", "Herman Melville", "Korea", "John Henry", "Babe Ruth", "Hillary Clinton", "Chicago", "Wallace & Gromit", "sesame", "Nike", "Jack Nicholson", "ammonia", "the Omaha", "dogs", "Gauguin", "Francis Scott Key", "Mexico", "the Peashooter", "Joe Pozzuoli", "money", "Massachusetts", "ACTIVE", "box office", "Alfred Hitchcock", "the Basques", "Ambrose Bierce", "The president", "2.45 billion years ago", "Jennifer Morrison", "stanley bacall", "comets", "Argentina", "Edinburgh", "Campbellsville", "French", "Hearst Castle", "\"At one point I thought, 15 years on, no one would really know who Kurt Cobain was outside of a group of diehard fans,\"", "Brian Smith,", "a Ballon d'Or"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7087780214424951}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.4210526315789474, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.07407407407407408, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4160", "mrqa_searchqa-validation-10654", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-1079", "mrqa_searchqa-validation-12763", "mrqa_searchqa-validation-14670", "mrqa_searchqa-validation-8407", "mrqa_searchqa-validation-15055", "mrqa_searchqa-validation-6649", "mrqa_searchqa-validation-483", "mrqa_searchqa-validation-12031", "mrqa_searchqa-validation-775", "mrqa_searchqa-validation-3000", "mrqa_searchqa-validation-10907", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-2889", "mrqa_triviaqa-validation-6507", "mrqa_triviaqa-validation-5187", "mrqa_hotpotqa-validation-662", "mrqa_hotpotqa-validation-4856", "mrqa_newsqa-validation-2630", "mrqa_newsqa-validation-1962"], "SR": 0.640625, "CSR": 0.5582191780821918, "retrieved_ids": ["mrqa_squad-train-44435", "mrqa_squad-train-76863", "mrqa_squad-train-48759", "mrqa_squad-train-21669", "mrqa_squad-train-9795", "mrqa_squad-train-19763", "mrqa_squad-train-33629", "mrqa_squad-train-41481", "mrqa_squad-train-33521", "mrqa_squad-train-68854", "mrqa_squad-train-37445", "mrqa_squad-train-70435", "mrqa_squad-train-74558", "mrqa_squad-train-4660", "mrqa_squad-train-82843", "mrqa_squad-train-59621", "mrqa_squad-train-31915", "mrqa_squad-train-58731", "mrqa_squad-train-81219", "mrqa_squad-train-67534", "mrqa_squad-train-61080", "mrqa_squad-train-9738", "mrqa_squad-train-13354", "mrqa_squad-train-33130", "mrqa_squad-train-72484", "mrqa_squad-train-29518", "mrqa_squad-train-35430", "mrqa_squad-train-44983", "mrqa_squad-train-66459", "mrqa_squad-train-86335", "mrqa_squad-train-34226", "mrqa_squad-train-43953", "mrqa_hotpotqa-validation-1011", "mrqa_searchqa-validation-2714", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-2991", "mrqa_searchqa-validation-1156", "mrqa_triviaqa-validation-3862", "mrqa_searchqa-validation-2143", "mrqa_newsqa-validation-263", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-6999", "mrqa_newsqa-validation-245", "mrqa_hotpotqa-validation-1614", "mrqa_newsqa-validation-2858", "mrqa_newsqa-validation-716", "mrqa_searchqa-validation-6252", "mrqa_naturalquestions-validation-4675", "mrqa_triviaqa-validation-3099", "mrqa_naturalquestions-validation-2124", "mrqa_searchqa-validation-398", "mrqa_naturalquestions-validation-5485", "mrqa_hotpotqa-validation-1182", "mrqa_searchqa-validation-2934", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-2855", "mrqa_triviaqa-validation-4458", "mrqa_squad-validation-7320", "mrqa_newsqa-validation-2163", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-6444", "mrqa_hotpotqa-validation-350", "mrqa_newsqa-validation-927", "mrqa_hotpotqa-validation-4102"], "EFR": 0.782608695652174, "Overall": 0.7138686997468732}, {"timecode": 73, "before_eval_results": {"predictions": ["barcaruolo", "Sinclair Lewis", "Hilary Swank", "sun lust Pictures", "sacred Wonders of Britain", "Israel", "Lundy", "Van Morrison", "Carbon", "stuart bingham", "Frank Darabont", "Neutrality", "Adam Smith", "espresso", "helps managers understand employees' needs in order to further employees' motivation", "Volkswagen", "birmingham", "henryson", "Netherland", "jabba the hutt", "Andy Murray", "Crystal Gayle", "Zachary Taylor", "baku", "Chechnya", "john Buchan", "green", "henry gee", "Hippety Hopper", "a smock or shift or chemise", "Mt Kenya", "a pumpkin", "lanka", "palermo", "Switzerland", "magic", "Julie Andrews Edwards", "Pancho Villa", "Nigeria", "leeds", "benjamin", "c Cologne", "Oliver!", "indenno", "Raul Castro", "indiopia", "Renzo Piano", "impossible objects", "Mexico", "n Carolina", "Friends", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "Tom Brady", "December 11, 2014", "Forrest Gump", "John Anderson", "Mel Blanc", "Arnold Drummond", "dining scene", "Abhisit Vejjajiva", "Jackie Moon", "Maria Callas", "Desperate Housewives", "his advocacy of young earth creationism and intelligent design"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5744318181818182}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3636363636363636]}}, "before_error_ids": ["mrqa_triviaqa-validation-6526", "mrqa_triviaqa-validation-7773", "mrqa_triviaqa-validation-3590", "mrqa_triviaqa-validation-2845", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-7052", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-957", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-5654", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-3750", "mrqa_triviaqa-validation-5756", "mrqa_triviaqa-validation-5032", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-4554", "mrqa_triviaqa-validation-2414", "mrqa_triviaqa-validation-6862", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-4028", "mrqa_hotpotqa-validation-1306", "mrqa_newsqa-validation-1828", "mrqa_searchqa-validation-16053", "mrqa_hotpotqa-validation-3469"], "SR": 0.515625, "CSR": 0.5576435810810811, "retrieved_ids": ["mrqa_squad-train-32692", "mrqa_squad-train-43653", "mrqa_squad-train-14408", "mrqa_squad-train-19223", "mrqa_squad-train-14557", "mrqa_squad-train-57395", "mrqa_squad-train-25473", "mrqa_squad-train-24976", "mrqa_squad-train-82749", "mrqa_squad-train-1250", "mrqa_squad-train-19008", "mrqa_squad-train-35007", "mrqa_squad-train-39246", "mrqa_squad-train-62686", "mrqa_squad-train-10185", "mrqa_squad-train-53489", "mrqa_squad-train-9693", "mrqa_squad-train-82337", "mrqa_squad-train-65143", "mrqa_squad-train-49722", "mrqa_squad-train-38643", "mrqa_squad-train-75782", "mrqa_squad-train-65945", "mrqa_squad-train-23014", "mrqa_squad-train-29762", "mrqa_squad-train-67511", "mrqa_squad-train-30764", "mrqa_squad-train-74477", "mrqa_squad-train-10412", "mrqa_squad-train-44008", "mrqa_squad-train-51200", "mrqa_squad-train-76692", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-5588", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-10279", "mrqa_hotpotqa-validation-1891", "mrqa_naturalquestions-validation-10209", "mrqa_newsqa-validation-3835", "mrqa_squad-validation-218", "mrqa_hotpotqa-validation-2769", "mrqa_newsqa-validation-1397", "mrqa_naturalquestions-validation-5986", "mrqa_hotpotqa-validation-4988", "mrqa_searchqa-validation-4715", "mrqa_naturalquestions-validation-7164", "mrqa_newsqa-validation-541", "mrqa_naturalquestions-validation-6519", "mrqa_triviaqa-validation-3447", "mrqa_triviaqa-validation-4240", "mrqa_triviaqa-validation-6392", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-2299", "mrqa_triviaqa-validation-51", "mrqa_newsqa-validation-2976", "mrqa_hotpotqa-validation-3059", "mrqa_hotpotqa-validation-5328", "mrqa_naturalquestions-validation-9877", "mrqa_triviaqa-validation-2853", "mrqa_naturalquestions-validation-4279", "mrqa_hotpotqa-validation-5464", "mrqa_naturalquestions-validation-9235", "mrqa_triviaqa-validation-1463", "mrqa_hotpotqa-validation-227"], "EFR": 0.7419354838709677, "Overall": 0.7056189379904098}, {"timecode": 74, "before_eval_results": {"predictions": ["james bardon", "james bond", "the navy", "a high-speed car crash", "apples", "yellow", "Dreamgirls", "s\u00e8vres", "the Antilles Current", "Viola", "hay fever", "gin", "Canada", "it means that the rent doesn't include additional costs such as insurance or business rates", "whooping cough", "peter stuyvesant", "apples", "India and Pakistan", "daedalus", "Chiricahua", "the sinus node", "blucher", "pius XII", "smell", "3", "george II", "Lincolnshire", "Zimbabwe", "rolling hillsides of Ireland", "schnittles", "nasser el-Sadat", "david bowie", "Silent Spring", "bath", "Glenn Close and Rade Serbedzija", "Frank Langella", "The Archers", "Northern line", "Montmorency", "the condor", "twelve", "staircase", "Pinocchio", "the cenozoic Era", "japan", "Jamie Oliver", "hub", "willy Russell", "petula Clark", "Radical Left", "The Blue Boy", "a Border Collie", "Kristy Swanson", "fourth season", "John", "Hermione Baddeley", "Floyd Casey Stadium", "David Bowie,", "Iraqi economy", "Robert Kimmitt.", "the Mammoth Cave", "recessive", "a novella", "Floyd Nathaniel \"Nate\" Hills"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6073660714285714}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-2589", "mrqa_triviaqa-validation-3926", "mrqa_triviaqa-validation-4228", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-3482", "mrqa_triviaqa-validation-2506", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-7086", "mrqa_triviaqa-validation-2441", "mrqa_triviaqa-validation-2699", "mrqa_triviaqa-validation-7353", "mrqa_triviaqa-validation-2180", "mrqa_triviaqa-validation-6797", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-4435", "mrqa_triviaqa-validation-4887", "mrqa_triviaqa-validation-4470", "mrqa_triviaqa-validation-1344", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-4927", "mrqa_triviaqa-validation-4727", "mrqa_triviaqa-validation-5738", "mrqa_naturalquestions-validation-8404", "mrqa_hotpotqa-validation-2801", "mrqa_searchqa-validation-4464", "mrqa_hotpotqa-validation-3787"], "SR": 0.546875, "CSR": 0.5575, "retrieved_ids": ["mrqa_squad-train-51317", "mrqa_squad-train-4626", "mrqa_squad-train-75826", "mrqa_squad-train-81188", "mrqa_squad-train-12398", "mrqa_squad-train-85498", "mrqa_squad-train-46597", "mrqa_squad-train-27599", "mrqa_squad-train-46158", "mrqa_squad-train-60558", "mrqa_squad-train-82490", "mrqa_squad-train-5975", "mrqa_squad-train-5928", "mrqa_squad-train-48819", "mrqa_squad-train-79511", "mrqa_squad-train-13217", "mrqa_squad-train-33869", "mrqa_squad-train-1866", "mrqa_squad-train-80502", "mrqa_squad-train-5864", "mrqa_squad-train-10977", "mrqa_squad-train-78481", "mrqa_squad-train-16206", "mrqa_squad-train-56407", "mrqa_squad-train-84175", "mrqa_squad-train-13401", "mrqa_squad-train-28503", "mrqa_squad-train-57993", "mrqa_squad-train-77497", "mrqa_squad-train-9359", "mrqa_squad-train-75621", "mrqa_squad-train-51883", "mrqa_searchqa-validation-1045", "mrqa_triviaqa-validation-1746", "mrqa_searchqa-validation-2231", "mrqa_hotpotqa-validation-3431", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-2923", "mrqa_newsqa-validation-1229", "mrqa_searchqa-validation-6350", "mrqa_naturalquestions-validation-5781", "mrqa_searchqa-validation-16366", "mrqa_naturalquestions-validation-2540", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-5228", "mrqa_naturalquestions-validation-10039", "mrqa_squad-validation-739", "mrqa_searchqa-validation-5928", "mrqa_triviaqa-validation-3341", "mrqa_naturalquestions-validation-9530", "mrqa_hotpotqa-validation-5328", "mrqa_triviaqa-validation-6380", "mrqa_newsqa-validation-3404", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-6865", "mrqa_newsqa-validation-2735", "mrqa_searchqa-validation-16076", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-1166", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-5602", "mrqa_newsqa-validation-340"], "EFR": 0.7586206896551724, "Overall": 0.7089272629310345}, {"timecode": 75, "before_eval_results": {"predictions": ["New Zealand", "1907", "saut\u00e9eing onions", "daleks", "duke orsino", "james iv", "mike de cervantes", "japan", "Gillette", "spain", "Tyrrhenian", "Bash Street", "Tahrir Square", "the forelimb", "two motorcycle enthusiasts, William Lyons and William Walmsley", "Chicago", "Brett Favre", "Netherlands", "Gryffindor", "hallmarks", "james garner", "Pyrenees", "17", "joshua", "argentina", "Elysium", "geometry", "jane brane", "Crete", "france", "Copenhagen", "vena cava", "joshua carmenfouz", "orca", "Christopher Nolan", "purple rain", "chess", "Ireland", "diana vickers", "February", "iain Duncan Smith", "argon", "bagel", "france", "South Dakota", "Alexander Dubcek", "Denver", "Chicago Cubs", "st. Louis", "bacall", "Rosetta Stone", "formal education", "the Saudi Arab kingdom", "the nucleus", "August 14, 1848", "1892", "Merck & Co.", "1,500", "Shenzhen in southern China.", "Iran", "bone", "Washington, D.C.", "sedimentary", "golf"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5817708333333333}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7442", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-5873", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4490", "mrqa_triviaqa-validation-5653", "mrqa_triviaqa-validation-4799", "mrqa_triviaqa-validation-2012", "mrqa_triviaqa-validation-399", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-7458", "mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-136", "mrqa_triviaqa-validation-156", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-317", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-4643", "mrqa_triviaqa-validation-2002", "mrqa_triviaqa-validation-4902", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-366", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4506", "mrqa_searchqa-validation-10770"], "SR": 0.5625, "CSR": 0.5575657894736843, "retrieved_ids": ["mrqa_squad-train-26634", "mrqa_squad-train-67578", "mrqa_squad-train-31567", "mrqa_squad-train-21453", "mrqa_squad-train-9409", "mrqa_squad-train-47854", "mrqa_squad-train-11689", "mrqa_squad-train-73772", "mrqa_squad-train-32113", "mrqa_squad-train-75389", "mrqa_squad-train-56824", "mrqa_squad-train-26616", "mrqa_squad-train-5698", "mrqa_squad-train-16991", "mrqa_squad-train-19204", "mrqa_squad-train-24490", "mrqa_squad-train-83010", "mrqa_squad-train-23508", "mrqa_squad-train-29832", "mrqa_squad-train-59871", "mrqa_squad-train-62946", "mrqa_squad-train-27704", "mrqa_squad-train-15781", "mrqa_squad-train-10196", "mrqa_squad-train-67856", "mrqa_squad-train-2768", "mrqa_squad-train-32304", "mrqa_squad-train-82922", "mrqa_squad-train-15200", "mrqa_squad-train-2076", "mrqa_squad-train-19192", "mrqa_squad-train-3326", "mrqa_triviaqa-validation-3348", "mrqa_newsqa-validation-81", "mrqa_squad-validation-7136", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-8903", "mrqa_triviaqa-validation-2693", "mrqa_naturalquestions-validation-9818", "mrqa_hotpotqa-validation-802", "mrqa_searchqa-validation-13003", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-1891", "mrqa_triviaqa-validation-2357", "mrqa_hotpotqa-validation-5594", "mrqa_searchqa-validation-9148", "mrqa_searchqa-validation-11835", "mrqa_hotpotqa-validation-5627", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1144", "mrqa_naturalquestions-validation-6998", "mrqa_triviaqa-validation-7054", "mrqa_newsqa-validation-2905", "mrqa_newsqa-validation-2068", "mrqa_triviaqa-validation-7439", "mrqa_squad-validation-8661", "mrqa_squad-validation-6759", "mrqa_searchqa-validation-7596", "mrqa_searchqa-validation-2866", "mrqa_hotpotqa-validation-5742", "mrqa_hotpotqa-validation-2493", "mrqa_squad-validation-8093", "mrqa_newsqa-validation-181"], "EFR": 0.8214285714285714, "Overall": 0.7215019971804512}, {"timecode": 76, "before_eval_results": {"predictions": ["English", "Andrew Garfield", "California, Utah and Arizona", "studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "William Chatterton Dix", "1924", "September 27, 2017", "Alabama", "Scheria", "Sanchez Navarro", "Thomas Jefferson", "August 2, 1990", "Joe Pizzulo and Leeza Miller", "Julie Adams", "Ian Hart", "Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "a Native American nation from the Great Plains", "in capillaries, alveoli, glomeruli, outer layer of skin", "the French CYCLADES project directed by Louis Pouzin", "April 1979", "Tbilisi", "a security feature for `` card not present '' payment card transactions instituted to reduce the incidence of credit card fraud", "Atticus Finch", "four", "Liam Cunningham", "2013", "ummat al - Islamiyah", "# 4", "1980", "2017 season", "W. Edwards Deming", "Saphira", "transmissions", "Industrial Workers of the World", "1972 -- 81", "Ajay Tyagi", "jules carri\u00e8re", "Paul Revere", "Julius Caesar", "Aristotle", "1956", "Zeus", "two degrees of freedom", "April 10, 2018", "Lee County, Florida, United States", "mid November", "Kevin Spacey", "Fa Ze YouTubers", "two installments", "the French", "excessive growth", "Lingerie", "Amy", "Octavian", "Karolina Dean", "four hundred", "Caesars Entertainment Corporation", "does not believe North Korea intends to launch a long-range missile in the near future,", "the sins of the members of the church", "Marcus Schrenker,", "horse-master", "the Amadeus Quartet", "ask for help", "Charice"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6355407519952714}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true], "QA-F1": [0.4, 1.0, 0.4, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5714285714285715, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.22222222222222224, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8, 1.0, 0.8695652173913044, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2060", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4139", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-2133", "mrqa_naturalquestions-validation-1171", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-8608", "mrqa_naturalquestions-validation-5942", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-214", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-8409", "mrqa_naturalquestions-validation-8884", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-5185", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-3036", "mrqa_hotpotqa-validation-4503", "mrqa_hotpotqa-validation-5761", "mrqa_newsqa-validation-212", "mrqa_searchqa-validation-4245", "mrqa_searchqa-validation-8474", "mrqa_searchqa-validation-1590"], "SR": 0.515625, "CSR": 0.5570211038961039, "retrieved_ids": ["mrqa_squad-train-56362", "mrqa_squad-train-60545", "mrqa_squad-train-72722", "mrqa_squad-train-68601", "mrqa_squad-train-12713", "mrqa_squad-train-542", "mrqa_squad-train-28398", "mrqa_squad-train-14623", "mrqa_squad-train-10083", "mrqa_squad-train-16459", "mrqa_squad-train-45445", "mrqa_squad-train-45273", "mrqa_squad-train-75158", "mrqa_squad-train-25983", "mrqa_squad-train-44173", "mrqa_squad-train-48935", "mrqa_squad-train-43404", "mrqa_squad-train-38326", "mrqa_squad-train-85958", "mrqa_squad-train-11122", "mrqa_squad-train-33786", "mrqa_squad-train-8055", "mrqa_squad-train-4930", "mrqa_squad-train-81505", "mrqa_squad-train-57162", "mrqa_squad-train-57342", "mrqa_squad-train-41724", "mrqa_squad-train-26485", "mrqa_squad-train-59576", "mrqa_squad-train-39163", "mrqa_squad-train-37013", "mrqa_squad-train-59266", "mrqa_searchqa-validation-13595", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-4832", "mrqa_naturalquestions-validation-553", "mrqa_triviaqa-validation-2918", "mrqa_newsqa-validation-1276", "mrqa_naturalquestions-validation-4190", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8534", "mrqa_searchqa-validation-2495", "mrqa_triviaqa-validation-977", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3063", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-4207", "mrqa_searchqa-validation-9081", "mrqa_newsqa-validation-2733", "mrqa_hotpotqa-validation-3431", "mrqa_triviaqa-validation-2936", "mrqa_newsqa-validation-1827", "mrqa_triviaqa-validation-5182", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-9897", "mrqa_searchqa-validation-5172", "mrqa_searchqa-validation-7086", "mrqa_naturalquestions-validation-7930", "mrqa_newsqa-validation-3469", "mrqa_naturalquestions-validation-5304", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-3944", "mrqa_triviaqa-validation-6146"], "EFR": 0.7096774193548387, "Overall": 0.6990428296501886}, {"timecode": 77, "before_eval_results": {"predictions": ["Lyndon Johnson", "Istanbul", "a wedding", "fetch", "The Marriage of Figaro", "Valerie Bertinelli", "Glitter", "Bayer", "the Randolph Caldecott Medal", "Karl Rove", "Russians", "Ireland", "Trinity College", "Portland", "Florida Keys", "Doctor John Dolittle", "fish", "transmission", "hot air balloons", "vacuum tubes", "The Bridges of Madison County", "Italy", "dates", "LOUIS XIV", "ice cream", "Louis XIV", "catfish", "Alien", "Kennedy assassination", "Indira Gandhi", "the pacarana", "Stephen Decatur", "Patti LaBelle", "the squire", "Miss Lois Cassatt", "sister cities", "hurricanes", "The Wall Street Journal", "grenades", "Tinactin", "Virgin Atlantic", "Perrier", "Eastwick", "Richard III", "trout", "India", "Minnesota", "San Francisco", "rabbit", "latte", "the M9", "Brazil", "Nicole DuPort", "species", "deep purple", "Piero da Vinci", "Surrealist", "July 25 to August 4", "1755", "Trey Parker and Matt Stone", "more than 1.2 million people.", "president Luca di Montezemolo", "Roger Federer", "an Italian portrait painter of the late Mannerist Florentine school"], "metric_results": {"EM": 0.625, "QA-F1": 0.6917410714285714}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-692", "mrqa_searchqa-validation-2938", "mrqa_searchqa-validation-1049", "mrqa_searchqa-validation-4400", "mrqa_searchqa-validation-15029", "mrqa_searchqa-validation-11570", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-2171", "mrqa_searchqa-validation-14009", "mrqa_searchqa-validation-13399", "mrqa_searchqa-validation-5989", "mrqa_searchqa-validation-15247", "mrqa_searchqa-validation-15164", "mrqa_searchqa-validation-14373", "mrqa_searchqa-validation-11403", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-14239", "mrqa_searchqa-validation-2858", "mrqa_triviaqa-validation-3041", "mrqa_triviaqa-validation-3098", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-1364", "mrqa_triviaqa-validation-5253"], "SR": 0.625, "CSR": 0.5578926282051282, "retrieved_ids": ["mrqa_squad-train-9455", "mrqa_squad-train-13886", "mrqa_squad-train-14434", "mrqa_squad-train-67905", "mrqa_squad-train-11504", "mrqa_squad-train-27608", "mrqa_squad-train-3540", "mrqa_squad-train-12896", "mrqa_squad-train-61095", "mrqa_squad-train-38789", "mrqa_squad-train-23313", "mrqa_squad-train-39831", "mrqa_squad-train-5290", "mrqa_squad-train-42120", "mrqa_squad-train-68224", "mrqa_squad-train-4660", "mrqa_squad-train-40305", "mrqa_squad-train-73624", "mrqa_squad-train-71101", "mrqa_squad-train-50494", "mrqa_squad-train-5374", "mrqa_squad-train-31054", "mrqa_squad-train-28109", "mrqa_squad-train-37579", "mrqa_squad-train-10095", "mrqa_squad-train-37601", "mrqa_squad-train-3369", "mrqa_squad-train-16752", "mrqa_squad-train-31053", "mrqa_squad-train-46588", "mrqa_squad-train-33059", "mrqa_squad-train-13347", "mrqa_naturalquestions-validation-8999", "mrqa_searchqa-validation-6252", "mrqa_searchqa-validation-8665", "mrqa_newsqa-validation-1032", "mrqa_searchqa-validation-13595", "mrqa_newsqa-validation-3741", "mrqa_newsqa-validation-664", "mrqa_searchqa-validation-14101", "mrqa_hotpotqa-validation-2205", "mrqa_searchqa-validation-13919", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-6260", "mrqa_newsqa-validation-1330", "mrqa_squad-validation-6973", "mrqa_newsqa-validation-3048", "mrqa_hotpotqa-validation-4322", "mrqa_naturalquestions-validation-809", "mrqa_newsqa-validation-3232", "mrqa_triviaqa-validation-4924", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-2133", "mrqa_triviaqa-validation-919", "mrqa_squad-validation-6706", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-3214", "mrqa_squad-validation-4918", "mrqa_newsqa-validation-1457", "mrqa_searchqa-validation-13232", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-5305", "mrqa_triviaqa-validation-6271", "mrqa_hotpotqa-validation-3063"], "EFR": 0.625, "Overall": 0.6822816506410256}, {"timecode": 78, "before_eval_results": {"predictions": ["Tycho Brahe", "Little Miss Sunshine", "Philadelphia", "Peter Rabbit", "Tommy Franks", "Ur", "Jonny Quest", "Burundi", "Fort Sumter", "Love Story", "Captains Courageous", "Bryan Adams", "Moses", "engineering", "Chaucer", "the Toronto Blue Jays", "second lieutenant", "Adam", "\"Sayonara\"", "Orient Express", "Dante", "Sir Walter Scott", "a face cord", "Louisiana", "1941", "Douglas MacArthur", "Cheshire Cheshvan", "breast", "PG-13", "occipital", "a spoon", "Little Red Riding Hood", "\"Year 3000\"", "Iceland", "the Popsicle", "San Francisco", "paladin", "\"Chelsea Morning\"", "a comb", "Venice", "Paraguay", "(E. T. A. Hoffmann", "debts", "(WimPY)", "El Supremo", "Foot Locker", "Princess Leia", "artichoke", "documents", "Hammurabi", "alkaline anlam", "the ninth w\u0101", "Matt Monro", "on the two tablets", "Mt Kenya", "Elvis Presley", "Boston Legal", "Whitney Houston", "Channel 4", "Mark Neary Donohue Jr.", "State Department", "a share in the royalties", "Arizona", "3D computer-animated comedy"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7244791666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4423", "mrqa_searchqa-validation-14441", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-7375", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-11438", "mrqa_searchqa-validation-6426", "mrqa_searchqa-validation-11646", "mrqa_searchqa-validation-12278", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-13377", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-1701", "mrqa_searchqa-validation-11821", "mrqa_searchqa-validation-16176", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-12891", "mrqa_naturalquestions-validation-10310", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-4688", "mrqa_hotpotqa-validation-5344", "mrqa_newsqa-validation-939"], "SR": 0.640625, "CSR": 0.5589398734177216, "retrieved_ids": ["mrqa_squad-train-20962", "mrqa_squad-train-63920", "mrqa_squad-train-19241", "mrqa_squad-train-46898", "mrqa_squad-train-32362", "mrqa_squad-train-69514", "mrqa_squad-train-51652", "mrqa_squad-train-5555", "mrqa_squad-train-50316", "mrqa_squad-train-69359", "mrqa_squad-train-6935", "mrqa_squad-train-12849", "mrqa_squad-train-71523", "mrqa_squad-train-80742", "mrqa_squad-train-28856", "mrqa_squad-train-44347", "mrqa_squad-train-3994", "mrqa_squad-train-84227", "mrqa_squad-train-40549", "mrqa_squad-train-84619", "mrqa_squad-train-25630", "mrqa_squad-train-73680", "mrqa_squad-train-504", "mrqa_squad-train-81633", "mrqa_squad-train-33952", "mrqa_squad-train-41830", "mrqa_squad-train-83947", "mrqa_squad-train-20952", "mrqa_squad-train-66268", "mrqa_squad-train-12833", "mrqa_squad-train-26257", "mrqa_squad-train-32596", "mrqa_naturalquestions-validation-7172", "mrqa_hotpotqa-validation-2021", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2207", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-2184", "mrqa_hotpotqa-validation-1127", "mrqa_triviaqa-validation-3495", "mrqa_hotpotqa-validation-2848", "mrqa_hotpotqa-validation-2582", "mrqa_naturalquestions-validation-10509", "mrqa_naturalquestions-validation-321", "mrqa_triviaqa-validation-6896", "mrqa_hotpotqa-validation-1030", "mrqa_naturalquestions-validation-9979", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-5297", "mrqa_searchqa-validation-13900", "mrqa_hotpotqa-validation-1239", "mrqa_newsqa-validation-1483", "mrqa_naturalquestions-validation-1649", "mrqa_newsqa-validation-3933", "mrqa_newsqa-validation-859", "mrqa_triviaqa-validation-1363", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-3332", "mrqa_triviaqa-validation-4646", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-6822"], "EFR": 0.6521739130434783, "Overall": 0.6879258822922399}, {"timecode": 79, "before_eval_results": {"predictions": ["to aid the athlete's performance", "Banquo", "Detroit Rock City", "a tree", "the 23rd letter", "Ford", "Joseph Campbell", "thesaurus", "Frank Edwin \"Tug\" McGraw Jr.", "Novel", "stick hoovers", "Edinburgh", "engineering", "Cyprus", "savanna", "the tandoori", "floatplane", "piano", "deodorant", "oyster", "What's eating Gilbert Grape", "Mrs. Barbara Bush", "the American Civil War", "The Jungle Book", "eggshells", "the Hornet", "(The Sadler) Wells", "Pakistan", "the FBI", "Aaron Burr", "Johns Hopkins University", "Jason", "Mississippi River", "Damascus", "Oahu", "Devo", "taxonomy", "stuffing", "Reading Railroad", "George Eliot", "the Cotton Bowl", "Shiloh", "Candice Bergen", "Takana", "apples", "a cedar", "Almond Joy", "The Children", "Sam Houston", "Caesar salad", "cable cars", "July 14, 1969", "on permanent display at the Louvre Museum in Paris", "1923", "sticky wicket", "Casualty", "The Boar", "Willie Nelson and Kris Kristofferson", "Sarajevo", "Annie Ida Jenny No\u00eb Haesendonck", "Mother's Day poems", "Italian Serie A title", "The son of Gabon's former president", "Wildcats"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6088541666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-197", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-15449", "mrqa_searchqa-validation-6324", "mrqa_searchqa-validation-5254", "mrqa_searchqa-validation-4534", "mrqa_searchqa-validation-12299", "mrqa_searchqa-validation-86", "mrqa_searchqa-validation-10697", "mrqa_searchqa-validation-15892", "mrqa_searchqa-validation-7340", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-15134", "mrqa_searchqa-validation-8338", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-872", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-13472", "mrqa_searchqa-validation-1853", "mrqa_triviaqa-validation-6366", "mrqa_triviaqa-validation-6870", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-3155", "mrqa_newsqa-validation-3085", "mrqa_newsqa-validation-3923"], "SR": 0.5625, "CSR": 0.558984375, "retrieved_ids": ["mrqa_squad-train-27309", "mrqa_squad-train-18053", "mrqa_squad-train-4245", "mrqa_squad-train-4497", "mrqa_squad-train-63125", "mrqa_squad-train-29319", "mrqa_squad-train-20926", "mrqa_squad-train-31884", "mrqa_squad-train-37081", "mrqa_squad-train-24972", "mrqa_squad-train-52606", "mrqa_squad-train-85591", "mrqa_squad-train-81935", "mrqa_squad-train-59040", "mrqa_squad-train-44287", "mrqa_squad-train-71163", "mrqa_squad-train-12448", "mrqa_squad-train-68303", "mrqa_squad-train-39019", "mrqa_squad-train-51147", "mrqa_squad-train-66692", "mrqa_squad-train-5989", "mrqa_squad-train-23077", "mrqa_squad-train-15217", "mrqa_squad-train-82188", "mrqa_squad-train-19778", "mrqa_squad-train-14923", "mrqa_squad-train-82342", "mrqa_squad-train-86494", "mrqa_squad-train-86499", "mrqa_squad-train-78029", "mrqa_squad-train-27717", "mrqa_triviaqa-validation-2262", "mrqa_newsqa-validation-3035", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-7767", "mrqa_hotpotqa-validation-650", "mrqa_searchqa-validation-16627", "mrqa_naturalquestions-validation-129", "mrqa_newsqa-validation-442", "mrqa_triviaqa-validation-5726", "mrqa_searchqa-validation-9120", "mrqa_hotpotqa-validation-1011", "mrqa_searchqa-validation-6304", "mrqa_newsqa-validation-2976", "mrqa_triviaqa-validation-7414", "mrqa_searchqa-validation-13600", "mrqa_hotpotqa-validation-5667", "mrqa_triviaqa-validation-3735", "mrqa_hotpotqa-validation-4434", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-16276", "mrqa_hotpotqa-validation-3886", "mrqa_newsqa-validation-3915", "mrqa_triviaqa-validation-4711", "mrqa_naturalquestions-validation-553", "mrqa_hotpotqa-validation-1044", "mrqa_triviaqa-validation-3275", "mrqa_naturalquestions-validation-1455", "mrqa_triviaqa-validation-503", "mrqa_searchqa-validation-3530", "mrqa_naturalquestions-validation-8983", "mrqa_triviaqa-validation-3495"], "EFR": 0.5714285714285714, "Overall": 0.6717857142857142}, {"timecode": 80, "UKR": 0.8203125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1216", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-1866", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2195", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2232", "mrqa_hotpotqa-validation-2369", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2819", "mrqa_hotpotqa-validation-3034", "mrqa_hotpotqa-validation-3059", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-3783", "mrqa_hotpotqa-validation-3790", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3878", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4120", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4474", "mrqa_hotpotqa-validation-4590", "mrqa_hotpotqa-validation-4613", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-5124", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-5275", "mrqa_hotpotqa-validation-5279", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-5578", "mrqa_hotpotqa-validation-5594", "mrqa_hotpotqa-validation-5595", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-789", "mrqa_hotpotqa-validation-84", "mrqa_naturalquestions-validation-10107", "mrqa_naturalquestions-validation-10122", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1315", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-1763", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-2220", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-2972", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3358", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-3805", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5359", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6349", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-793", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-8207", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-8668", "mrqa_naturalquestions-validation-8764", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9857", "mrqa_naturalquestions-validation-9897", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-110", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1254", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-1366", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1422", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-1488", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1517", "mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-1634", "mrqa_newsqa-validation-1640", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1828", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1935", "mrqa_newsqa-validation-2001", "mrqa_newsqa-validation-2102", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-230", "mrqa_newsqa-validation-2365", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2951", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3024", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-325", "mrqa_newsqa-validation-3251", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3432", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-3605", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-376", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-395", "mrqa_newsqa-validation-3963", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-496", "mrqa_newsqa-validation-551", "mrqa_newsqa-validation-643", "mrqa_newsqa-validation-669", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-872", "mrqa_newsqa-validation-91", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-1001", "mrqa_searchqa-validation-1049", "mrqa_searchqa-validation-10613", "mrqa_searchqa-validation-10670", "mrqa_searchqa-validation-10675", "mrqa_searchqa-validation-10795", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-11570", "mrqa_searchqa-validation-11965", "mrqa_searchqa-validation-12031", "mrqa_searchqa-validation-12252", "mrqa_searchqa-validation-12594", "mrqa_searchqa-validation-12646", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-12962", "mrqa_searchqa-validation-13041", "mrqa_searchqa-validation-13061", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-13120", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13273", "mrqa_searchqa-validation-13478", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-14310", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-15580", "mrqa_searchqa-validation-15686", "mrqa_searchqa-validation-1590", "mrqa_searchqa-validation-16021", "mrqa_searchqa-validation-16176", "mrqa_searchqa-validation-16209", "mrqa_searchqa-validation-16299", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16378", "mrqa_searchqa-validation-16569", "mrqa_searchqa-validation-1827", "mrqa_searchqa-validation-1986", "mrqa_searchqa-validation-2038", "mrqa_searchqa-validation-2268", "mrqa_searchqa-validation-2304", "mrqa_searchqa-validation-3000", "mrqa_searchqa-validation-3013", "mrqa_searchqa-validation-3018", "mrqa_searchqa-validation-3137", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3573", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-3758", "mrqa_searchqa-validation-398", "mrqa_searchqa-validation-4089", "mrqa_searchqa-validation-4169", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-4581", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-4836", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5177", "mrqa_searchqa-validation-5746", "mrqa_searchqa-validation-5812", "mrqa_searchqa-validation-5886", "mrqa_searchqa-validation-5911", "mrqa_searchqa-validation-5922", "mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-6252", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-663", "mrqa_searchqa-validation-6876", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-7154", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7375", "mrqa_searchqa-validation-7419", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-7871", "mrqa_searchqa-validation-8214", "mrqa_searchqa-validation-8276", "mrqa_searchqa-validation-8465", "mrqa_searchqa-validation-8623", "mrqa_searchqa-validation-8631", "mrqa_searchqa-validation-8638", "mrqa_searchqa-validation-872", "mrqa_searchqa-validation-8803", "mrqa_searchqa-validation-8888", "mrqa_searchqa-validation-8985", "mrqa_searchqa-validation-9372", "mrqa_searchqa-validation-9490", "mrqa_searchqa-validation-9696", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9853", "mrqa_searchqa-validation-9896", "mrqa_searchqa-validation-9910", "mrqa_squad-validation-10369", "mrqa_squad-validation-10477", "mrqa_squad-validation-1125", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-127", "mrqa_squad-validation-1371", "mrqa_squad-validation-2328", "mrqa_squad-validation-259", "mrqa_squad-validation-2691", "mrqa_squad-validation-280", "mrqa_squad-validation-2959", "mrqa_squad-validation-3052", "mrqa_squad-validation-3124", "mrqa_squad-validation-3144", "mrqa_squad-validation-3230", "mrqa_squad-validation-3241", "mrqa_squad-validation-335", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3608", "mrqa_squad-validation-3703", "mrqa_squad-validation-3919", "mrqa_squad-validation-3955", "mrqa_squad-validation-3969", "mrqa_squad-validation-4066", "mrqa_squad-validation-415", "mrqa_squad-validation-4312", "mrqa_squad-validation-4326", "mrqa_squad-validation-4528", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5110", "mrqa_squad-validation-5320", "mrqa_squad-validation-5422", "mrqa_squad-validation-5604", "mrqa_squad-validation-5726", "mrqa_squad-validation-5781", "mrqa_squad-validation-5960", "mrqa_squad-validation-6169", "mrqa_squad-validation-6229", "mrqa_squad-validation-6243", "mrqa_squad-validation-6502", "mrqa_squad-validation-6875", "mrqa_squad-validation-7064", "mrqa_squad-validation-7549", "mrqa_squad-validation-7708", "mrqa_squad-validation-7717", "mrqa_squad-validation-7751", "mrqa_squad-validation-8754", "mrqa_squad-validation-8904", "mrqa_squad-validation-8958", "mrqa_squad-validation-9446", "mrqa_squad-validation-959", "mrqa_squad-validation-9716", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1147", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-12", "mrqa_triviaqa-validation-1239", "mrqa_triviaqa-validation-1290", "mrqa_triviaqa-validation-1512", "mrqa_triviaqa-validation-1517", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-1806", "mrqa_triviaqa-validation-1879", "mrqa_triviaqa-validation-189", "mrqa_triviaqa-validation-1917", "mrqa_triviaqa-validation-2002", "mrqa_triviaqa-validation-2004", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-205", "mrqa_triviaqa-validation-2075", "mrqa_triviaqa-validation-2140", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-2404", "mrqa_triviaqa-validation-2441", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-2504", "mrqa_triviaqa-validation-2527", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2705", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3043", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-3348", "mrqa_triviaqa-validation-341", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-3495", "mrqa_triviaqa-validation-3522", "mrqa_triviaqa-validation-3534", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-3747", "mrqa_triviaqa-validation-3768", "mrqa_triviaqa-validation-3936", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-3967", "mrqa_triviaqa-validation-4006", "mrqa_triviaqa-validation-426", "mrqa_triviaqa-validation-4306", "mrqa_triviaqa-validation-4410", "mrqa_triviaqa-validation-4447", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4655", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-4727", "mrqa_triviaqa-validation-483", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4902", "mrqa_triviaqa-validation-4956", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5035", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-5141", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-5668", "mrqa_triviaqa-validation-5691", "mrqa_triviaqa-validation-5726", "mrqa_triviaqa-validation-5763", "mrqa_triviaqa-validation-5823", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5897", "mrqa_triviaqa-validation-5941", "mrqa_triviaqa-validation-5989", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6475", "mrqa_triviaqa-validation-6522", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6571", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6833", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-7052", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7140", "mrqa_triviaqa-validation-7190", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7439", "mrqa_triviaqa-validation-7497", "mrqa_triviaqa-validation-7727", "mrqa_triviaqa-validation-7773", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-839", "mrqa_triviaqa-validation-917", "mrqa_triviaqa-validation-971"], "OKR": 0.876953125, "KG": 0.50234375, "before_eval_results": {"predictions": ["paulas", "partridge", "depressant", "c Czech Republic", "George IV", "azerbaijani", "alphabets", "Sisyphus", "new state", "coffee house", "laos", "Moldova", "Taking of Pelham 1-2-3", "egypt", "Frank McCourt", "Furbys", "Arkansas", "Texas", "Norway", "archer", "will Blake", "Antarctica", "Roger Federer", "Charlie Chan", "Galileo Galilei", "Great British Bake Off", "World War I", "shekel", "George Sand", "michael caine", "Professor Brian Cox", "two Australians, driver Jack Brabham and designer Ron Tauranac", "Knutsford", "Coronation Street", "McDonnell Douglas", "tyne", "Missouri", "Emma Chambers", "Buckinghamshire", "Turkey", "cat", "michael miherley", "nine", "One Direction", "Groucho Marx", "Brazil", "Kate Winslet", "Pakistan", "1939", "Sweeney Todd", "Rio Grande", "If waivers are requested outside the playing season, or before November 1, then the player shall be transferred to the team with the lowest points in the preceding season", "8 January 1999", "David Joseph Madden", "The Braes o' Bowhether", "Mary Astor", "al-Qaeda", "natural gas", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \" Follow the Sun,\"", "Madonna", "Hawaii", "Monaco", "P. D. James", "MacFarlane"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6926609848484848}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-953", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-5654", "mrqa_triviaqa-validation-4997", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-3969", "mrqa_triviaqa-validation-1559", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-6352", "mrqa_triviaqa-validation-2921", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-4534", "mrqa_triviaqa-validation-2170", "mrqa_triviaqa-validation-2733", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-2718", "mrqa_newsqa-validation-4110", "mrqa_searchqa-validation-12999"], "SR": 0.65625, "CSR": 0.5601851851851851, "retrieved_ids": ["mrqa_squad-train-68441", "mrqa_squad-train-73278", "mrqa_squad-train-58536", "mrqa_squad-train-13563", "mrqa_squad-train-74222", "mrqa_squad-train-67572", "mrqa_squad-train-13014", "mrqa_squad-train-83730", "mrqa_squad-train-11898", "mrqa_squad-train-4580", "mrqa_squad-train-23890", "mrqa_squad-train-26699", "mrqa_squad-train-67267", "mrqa_squad-train-86511", "mrqa_squad-train-44420", "mrqa_squad-train-51125", "mrqa_squad-train-406", "mrqa_squad-train-42138", "mrqa_squad-train-19101", "mrqa_squad-train-7886", "mrqa_squad-train-69842", "mrqa_squad-train-39190", "mrqa_squad-train-69173", "mrqa_squad-train-27421", "mrqa_squad-train-4251", "mrqa_squad-train-13300", "mrqa_squad-train-73367", "mrqa_squad-train-85799", "mrqa_squad-train-8421", "mrqa_squad-train-40305", "mrqa_squad-train-40080", "mrqa_squad-train-80929", "mrqa_squad-validation-10321", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4280", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7525", "mrqa_searchqa-validation-4851", "mrqa_hotpotqa-validation-66", "mrqa_naturalquestions-validation-6851", "mrqa_searchqa-validation-1182", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-1068", "mrqa_naturalquestions-validation-3485", "mrqa_triviaqa-validation-3338", "mrqa_searchqa-validation-12763", "mrqa_naturalquestions-validation-7957", "mrqa_hotpotqa-validation-3090", "mrqa_naturalquestions-validation-1480", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-290", "mrqa_naturalquestions-validation-2482", "mrqa_newsqa-validation-1827", "mrqa_naturalquestions-validation-5726", "mrqa_triviaqa-validation-1714", "mrqa_searchqa-validation-4000", "mrqa_naturalquestions-validation-1813", "mrqa_searchqa-validation-5038", "mrqa_hotpotqa-validation-3721", "mrqa_searchqa-validation-14239", "mrqa_searchqa-validation-10415", "mrqa_newsqa-validation-1688", "mrqa_naturalquestions-validation-7224", "mrqa_naturalquestions-validation-8975"], "EFR": 0.4090909090909091, "Overall": 0.6337770938552189}, {"timecode": 81, "before_eval_results": {"predictions": ["the main highway entrance at California State Route 1,", "written before the first letter of an interrogative sentence or clause", "New York Knickerbockers", "John Dalton", "the Alamodome and city of San Antonio", "rear - view mirror", "The Golden Gate Bridge", "RAF, Fighter Command had achieved a great victory in successfully carrying out Sir Thomas Inskip's 1937 air policy of preventing the Germans from knocking Britain out of the war", "BC Jean and Toby Gad", "UNESCO / ILO Recommendation concerning the Status of Teachers", "September 2017", "Universal Pictures and Focus Features", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "September 29, 2017", "nine", "Tbilisi, Georgia", "April 1917", "From 1900 to 1946", "Bryan Cranston", "Geothermal gradient", "around 10 : 30am", "frontal lobe", "Napoleon's planned invasion of the United Kingdom", "potential of hydrogen", "volcanic activity", "held that `` a negro, whose ancestors were imported into ( the U.S. ), and sold as slaves '', whether enslaved or free, could not be an American citizen and therefore had no standing to sue in federal court", "the biblical Book of Exodus", "As of January 17, 2018, 201 episodes", "The pia mater", "members of the gay ( LGBT ) community", "Burbank, California", "April 20, 1983", "2018", "rapid destruction of the donor red blood cells by host antibodies", "1603", "English author Rudyard Kipling", "March 16, 2018", "Fusajiro Yamauchi", "off the rez", "2013", "the breast or lower chest", "David Lyons Neil Sterenberg", "Flash", "2018", "Saint Peter", "1963", "August 19, 2016", "Madison, Wisconsin, United States", "John Adams", "ABC", "Brevet Colonel Robert E. Lee", "glockenspiel", "alaskan", "Hercules", "Elbow", "County Louth", "NCAA Division II", "the Airbus A330-200", "the WSSRC had received about 50 formal applications for speed attempts during 2008.", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "Portugal", "gravity", "Lafayette C. Baker", "Yemen,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7447170829767393}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.07407407407407407, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.2666666666666667, 0.7692307692307692, 1.0, 1.0, 0.7710843373493976, 0.8571428571428571, 1.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3841", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-8700", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-5564", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-9477", "mrqa_naturalquestions-validation-2319", "mrqa_triviaqa-validation-4319", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-4136", "mrqa_searchqa-validation-2328"], "SR": 0.65625, "CSR": 0.5613567073170731, "retrieved_ids": ["mrqa_squad-train-27204", "mrqa_squad-train-9482", "mrqa_squad-train-8221", "mrqa_squad-train-36820", "mrqa_squad-train-14212", "mrqa_squad-train-41387", "mrqa_squad-train-1921", "mrqa_squad-train-12253", "mrqa_squad-train-61065", "mrqa_squad-train-33125", "mrqa_squad-train-83363", "mrqa_squad-train-15787", "mrqa_squad-train-59604", "mrqa_squad-train-6738", "mrqa_squad-train-9562", "mrqa_squad-train-79231", "mrqa_squad-train-58659", "mrqa_squad-train-73016", "mrqa_squad-train-61966", "mrqa_squad-train-48017", "mrqa_squad-train-53994", "mrqa_squad-train-3305", "mrqa_squad-train-62257", "mrqa_squad-train-84328", "mrqa_squad-train-76431", "mrqa_squad-train-65451", "mrqa_squad-train-3612", "mrqa_squad-train-55402", "mrqa_squad-train-4560", "mrqa_squad-train-67593", "mrqa_squad-train-36995", "mrqa_squad-train-16053", "mrqa_naturalquestions-validation-5599", "mrqa_newsqa-validation-3806", "mrqa_triviaqa-validation-6507", "mrqa_naturalquestions-validation-104", "mrqa_triviaqa-validation-3223", "mrqa_naturalquestions-validation-897", "mrqa_squad-validation-7445", "mrqa_triviaqa-validation-102", "mrqa_triviaqa-validation-575", "mrqa_naturalquestions-validation-4740", "mrqa_triviaqa-validation-6581", "mrqa_hotpotqa-validation-4655", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-10460", "mrqa_triviaqa-validation-51", "mrqa_searchqa-validation-3653", "mrqa_newsqa-validation-2048", "mrqa_triviaqa-validation-1303", "mrqa_searchqa-validation-15247", "mrqa_searchqa-validation-10415", "mrqa_triviaqa-validation-1832", "mrqa_searchqa-validation-11438", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1319", "mrqa_searchqa-validation-14670", "mrqa_searchqa-validation-11137", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-9508", "mrqa_triviaqa-validation-3969", "mrqa_squad-validation-2911", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-1273"], "EFR": 0.5454545454545454, "Overall": 0.6612841255543237}, {"timecode": 82, "before_eval_results": {"predictions": ["Jon Stewart", "henry i", "Ross Kemp", "jumanji", "Kirk Douglas", "William Shakespeare", "Christmas", "African violet", "Rod Stewart", "Gerald Ford", "clarinets", "pembrokeshire coast", "Imola", "South Africa", "sows", "The Persistence of Memory", "orangutan", "Time Machine", "Uranus", "Tacitus", "Lady Gaga", "Mecca", "cirrus uncinus", "kiev", "myxomatosis", "jennifer fforde", "Philippines", "xerophyte", "Blur", "The King and I", "The Last King of Scotland", "jaws", "Pearson PLC", "Steinbeck", "The Bulletin", "violin", "Ross Bagdasarian", "Mark Hamill", "pierce bacall", "Myanma", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "cryonics", "j\u00f8rn Utzon", "Another Day in Paradise", "embellish", "br\u00fcnderzeit", "Department of Justice", "South Africa", "rapid eye movement", "Antonio Vivaldi", "Corfu", "Walter Brennan", "a solitary figure who is not understood by others, but is actually wise", "Continental drift", "Charles White Whittlesey", "2015 Orange Bowl", "White Knights of the Ku Klux Klan", "6,000", "fill a million sandbags and place 700,000 around our city", "Judge Herman Thomas", "the clock", "Mazur", "@ Fontdeck", "1945 to 1951"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7054501488095238}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.125, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-6130", "mrqa_triviaqa-validation-5207", "mrqa_triviaqa-validation-4361", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-4346", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-11", "mrqa_triviaqa-validation-5716", "mrqa_triviaqa-validation-7545", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-7103", "mrqa_triviaqa-validation-3996", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-2050", "mrqa_hotpotqa-validation-3895", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4711", "mrqa_searchqa-validation-5320", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-2044"], "SR": 0.640625, "CSR": 0.5623117469879518, "retrieved_ids": ["mrqa_squad-train-57780", "mrqa_squad-train-31395", "mrqa_squad-train-69202", "mrqa_squad-train-76142", "mrqa_squad-train-35036", "mrqa_squad-train-85449", "mrqa_squad-train-63440", "mrqa_squad-train-44396", "mrqa_squad-train-376", "mrqa_squad-train-58680", "mrqa_squad-train-76056", "mrqa_squad-train-10435", "mrqa_squad-train-73159", "mrqa_squad-train-79887", "mrqa_squad-train-5684", "mrqa_squad-train-43862", "mrqa_squad-train-43638", "mrqa_squad-train-14114", "mrqa_squad-train-57767", "mrqa_squad-train-56018", "mrqa_squad-train-35580", "mrqa_squad-train-3362", "mrqa_squad-train-81343", "mrqa_squad-train-82355", "mrqa_squad-train-75444", "mrqa_squad-train-4473", "mrqa_squad-train-70589", "mrqa_squad-train-25825", "mrqa_squad-train-51294", "mrqa_squad-train-17624", "mrqa_squad-train-49547", "mrqa_squad-train-47064", "mrqa_searchqa-validation-3618", "mrqa_hotpotqa-validation-2075", "mrqa_searchqa-validation-1770", "mrqa_naturalquestions-validation-7301", "mrqa_triviaqa-validation-4599", "mrqa_hotpotqa-validation-1667", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5702", "mrqa_hotpotqa-validation-114", "mrqa_newsqa-validation-3970", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-919", "mrqa_newsqa-validation-1397", "mrqa_naturalquestions-validation-9614", "mrqa_hotpotqa-validation-2801", "mrqa_hotpotqa-validation-1302", "mrqa_searchqa-validation-12363", "mrqa_naturalquestions-validation-4874", "mrqa_triviaqa-validation-4784", "mrqa_newsqa-validation-1415", "mrqa_hotpotqa-validation-5448", "mrqa_searchqa-validation-10795", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8189", "mrqa_searchqa-validation-872", "mrqa_triviaqa-validation-1982", "mrqa_naturalquestions-validation-4134", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-3782", "mrqa_squad-validation-1708", "mrqa_naturalquestions-validation-10554", "mrqa_newsqa-validation-3232"], "EFR": 0.043478260869565216, "Overall": 0.5610798765715035}, {"timecode": 83, "before_eval_results": {"predictions": ["libya", "Syriza", "epaves", "wrigley", "PJ Harvey", "louis slaghoople", "eight", "Charles Taylor", "palm Sunday", "USD", "The Wicker Man", "sac", "endgame", "serpent", "Peter Nichols", "bear Grylls", "Count Basie Orchestra", "glenn", "Plato", "amundsen", "wine", "Pensacola, Florida", "Ireland", "michael hordern", "Gerald Durrell", "Ishmael", "Switzerland", "climate", "historic battle tanks", "fenella fielding", "Etruscan", "James Van Allen", "sheffield wednesday", "Bulls Eye", "Britain", "boots", "Helen Gurley Brown", "Thebes", "The Jungle Book", "joshua", "Massachusetts", "Josh Brolin", "Hamlet", "helen Glover", "The Penguin", "r34", "cue", "rock follies", "Australia", "Ann Darrow", "old country", "1996", "beans", "16 June", "Squam Lake", "3D computer-animated comedy", "1902", "part of a planned training exercise designed to help the prince learn to fly in combat situations.", "The Impeccable", "Justicialist Party, or PJ by its Spanish acronym,", "Ming dynasty", "Prince Albert", "a crossword clue", "al Qaeda."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6736995579481793}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9375, 1.0, 0.9411764705882353, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-465", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-3521", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-1983", "mrqa_triviaqa-validation-5103", "mrqa_triviaqa-validation-6393", "mrqa_triviaqa-validation-1765", "mrqa_triviaqa-validation-3922", "mrqa_triviaqa-validation-3264", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-101", "mrqa_triviaqa-validation-2214", "mrqa_triviaqa-validation-5883", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-942", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-7713", "mrqa_triviaqa-validation-1539", "mrqa_triviaqa-validation-4848", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-5596", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-3703", "mrqa_searchqa-validation-581", "mrqa_searchqa-validation-6285"], "SR": 0.578125, "CSR": 0.5625, "retrieved_ids": ["mrqa_squad-train-34672", "mrqa_squad-train-1543", "mrqa_squad-train-32773", "mrqa_squad-train-27607", "mrqa_squad-train-42842", "mrqa_squad-train-34040", "mrqa_squad-train-82191", "mrqa_squad-train-56514", "mrqa_squad-train-20040", "mrqa_squad-train-24517", "mrqa_squad-train-377", "mrqa_squad-train-9672", "mrqa_squad-train-57340", "mrqa_squad-train-74784", "mrqa_squad-train-12814", "mrqa_squad-train-52662", "mrqa_squad-train-84293", "mrqa_squad-train-83116", "mrqa_squad-train-31319", "mrqa_squad-train-36037", "mrqa_squad-train-30746", "mrqa_squad-train-8250", "mrqa_squad-train-37300", "mrqa_squad-train-81811", "mrqa_squad-train-79019", "mrqa_squad-train-83813", "mrqa_squad-train-29782", "mrqa_squad-train-45986", "mrqa_squad-train-62572", "mrqa_squad-train-14870", "mrqa_squad-train-32068", "mrqa_squad-train-76868", "mrqa_newsqa-validation-3978", "mrqa_newsqa-validation-712", "mrqa_hotpotqa-validation-631", "mrqa_naturalquestions-validation-10331", "mrqa_searchqa-validation-2648", "mrqa_naturalquestions-validation-2080", "mrqa_newsqa-validation-3043", "mrqa_naturalquestions-validation-8975", "mrqa_searchqa-validation-15500", "mrqa_squad-validation-9458", "mrqa_newsqa-validation-2429", "mrqa_hotpotqa-validation-264", "mrqa_searchqa-validation-14981", "mrqa_newsqa-validation-1879", "mrqa_searchqa-validation-2328", "mrqa_naturalquestions-validation-6999", "mrqa_searchqa-validation-5180", "mrqa_naturalquestions-validation-1171", "mrqa_naturalquestions-validation-1327", "mrqa_searchqa-validation-6304", "mrqa_squad-validation-3812", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-4974", "mrqa_naturalquestions-validation-1567", "mrqa_searchqa-validation-10927", "mrqa_triviaqa-validation-4263", "mrqa_triviaqa-validation-2699", "mrqa_searchqa-validation-1158", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-8990", "mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-571"], "EFR": 0.0, "Overall": 0.5524218750000001}, {"timecode": 84, "before_eval_results": {"predictions": ["ganga", "David Hilbert", "Halifax", "portugal", "Q", "Franklin Delano Roosevelt", "Buncefield Depot", "indium", "cappuccino", "turanga leela", "benjamin wales", "cimarron", "Brad Pitt", "florida", "Lord Melbourne", "Jupiter Mining Corporation", "phil Hartman", "Nouakchott", "lagertha", "verona", "weekly", "gail Webb", "Noah", "Jezebel", "budge", "Victoria and Prince Albert", "Quentin Tarantino", "Dick Whittington", "the Comitium", "rowing", "Mickey Mouse", "gin", "Supertramp", "leicestershire", "halogens", "Jackie Kennedy", "blue", "calcium carbonate", "toleware", "Cuba", "lorraine", "Nicola Adams", "new york", "Andes", "Essex Eagles", "carry On", "American History X", "endometriosis", "new collection at: the avenues, tel 22597642", "Brighton", "el Loco", "approximately 26,000 years", "Travis Tritt and Marty Stuart", "Norway", "Perdita", "Michael Ebenazer Kwadjo Omari Owuo, Jr.", "Tottenham Hotspur and the England national team", "a potential military strike against the Tehran regime", "one count of attempted murder in the second degree", "Ma Khin Khin Leh,", "Wii", "Germaine Greer", "Isaac and Esau", "Surrey"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6295138888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5664", "mrqa_triviaqa-validation-5212", "mrqa_triviaqa-validation-1389", "mrqa_triviaqa-validation-1500", "mrqa_triviaqa-validation-3438", "mrqa_triviaqa-validation-3183", "mrqa_triviaqa-validation-3894", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-413", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-3125", "mrqa_triviaqa-validation-7251", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-7379", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-7311", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-2381", "mrqa_triviaqa-validation-4587", "mrqa_hotpotqa-validation-3085", "mrqa_hotpotqa-validation-875", "mrqa_hotpotqa-validation-3265", "mrqa_newsqa-validation-729", "mrqa_newsqa-validation-2718", "mrqa_searchqa-validation-4541", "mrqa_searchqa-validation-14852"], "SR": 0.53125, "CSR": 0.5621323529411765, "retrieved_ids": ["mrqa_squad-train-46387", "mrqa_squad-train-862", "mrqa_squad-train-67190", "mrqa_squad-train-15970", "mrqa_squad-train-40390", "mrqa_squad-train-83544", "mrqa_squad-train-36368", "mrqa_squad-train-64219", "mrqa_squad-train-71752", "mrqa_squad-train-83201", "mrqa_squad-train-698", "mrqa_squad-train-19531", "mrqa_squad-train-14571", "mrqa_squad-train-17930", "mrqa_squad-train-56784", "mrqa_squad-train-54190", "mrqa_squad-train-56762", "mrqa_squad-train-3106", "mrqa_squad-train-53189", "mrqa_squad-train-3508", "mrqa_squad-train-3230", "mrqa_squad-train-47730", "mrqa_squad-train-16721", "mrqa_squad-train-29292", "mrqa_squad-train-73597", "mrqa_squad-train-28686", "mrqa_squad-train-14597", "mrqa_squad-train-20665", "mrqa_squad-train-45834", "mrqa_squad-train-20855", "mrqa_squad-train-35487", "mrqa_squad-train-21531", "mrqa_newsqa-validation-3961", "mrqa_naturalquestions-validation-7212", "mrqa_squad-validation-7445", "mrqa_newsqa-validation-2184", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-1606", "mrqa_searchqa-validation-9446", "mrqa_newsqa-validation-2792", "mrqa_searchqa-validation-7226", "mrqa_newsqa-validation-1458", "mrqa_triviaqa-validation-3482", "mrqa_hotpotqa-validation-4676", "mrqa_naturalquestions-validation-2666", "mrqa_triviaqa-validation-4599", "mrqa_squad-validation-7296", "mrqa_naturalquestions-validation-1950", "mrqa_triviaqa-validation-5294", "mrqa_squad-validation-7612", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-1987", "mrqa_squad-validation-2368", "mrqa_naturalquestions-validation-2743", "mrqa_newsqa-validation-421", "mrqa_searchqa-validation-14101", "mrqa_hotpotqa-validation-2802", "mrqa_triviaqa-validation-2963", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-551", "mrqa_naturalquestions-validation-6216", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1634", "mrqa_naturalquestions-validation-844"], "EFR": 0.03333333333333333, "Overall": 0.559015012254902}, {"timecode": 85, "before_eval_results": {"predictions": ["eagle", "teacher", "Shaft", "a semicubical parabola", "jets", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "chol", "a single arrow pointing to the left", "Rudyard Kipling", "eat porridge", "The Life and Opinions of Tristram Shandy", "David Arroyo", "240", "god of Earth", "\u00a31,250", "Department of Justice", "Nicosia (Lefkoe)", "sheep", "laos", "Toilet Lid Lock", "Andes Mountains of Chile", "George Sand", "18", "minder", "Shepherd Neame", "shoulder", "scrobbesbyrig", "legs", "bacall", "Saturday Night and Sunday Morning", "one of the Vikings nine realms", "around May 1", "1982", "beA", "Danish", "priesthood", "Pablo Escobar", "South Africa", "Microsoft", "Bolivia", "Napoleon Bonaparte", "secretary", "Apocalypse Now", "Judy Garland", "Amnesty International", "The Truth About Wilson", "the Land of the Long White Cloud", "east", "Renzo Piano", "50", "russia", "before the first year begins", "2,579 steps", "Hold On", "1919", "patosaurus", "La opera at the Teatro Metastasio", "Virgin America", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "Police", "Daredevil", "Dr. George Washington Carver", "panda", "California, Texas and Florida,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6247082166199813}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 0.888888888888889, 1.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2922", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-2383", "mrqa_triviaqa-validation-3394", "mrqa_triviaqa-validation-421", "mrqa_triviaqa-validation-630", "mrqa_triviaqa-validation-1761", "mrqa_triviaqa-validation-2005", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-4290", "mrqa_triviaqa-validation-193", "mrqa_triviaqa-validation-3547", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3109", "mrqa_triviaqa-validation-3828", "mrqa_triviaqa-validation-3040", "mrqa_triviaqa-validation-6628", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-5964", "mrqa_triviaqa-validation-672", "mrqa_naturalquestions-validation-5465", "mrqa_naturalquestions-validation-3561", "mrqa_hotpotqa-validation-372", "mrqa_hotpotqa-validation-4899", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-15855", "mrqa_searchqa-validation-237", "mrqa_newsqa-validation-2338"], "SR": 0.546875, "CSR": 0.5619549418604651, "retrieved_ids": ["mrqa_squad-train-57492", "mrqa_squad-train-57158", "mrqa_squad-train-43248", "mrqa_squad-train-48453", "mrqa_squad-train-77172", "mrqa_squad-train-24759", "mrqa_squad-train-70981", "mrqa_squad-train-67405", "mrqa_squad-train-26221", "mrqa_squad-train-43531", "mrqa_squad-train-255", "mrqa_squad-train-47232", "mrqa_squad-train-81100", "mrqa_squad-train-23891", "mrqa_squad-train-63476", "mrqa_squad-train-73378", "mrqa_squad-train-12476", "mrqa_squad-train-65710", "mrqa_squad-train-57967", "mrqa_squad-train-61101", "mrqa_squad-train-75336", "mrqa_squad-train-8103", "mrqa_squad-train-50803", "mrqa_squad-train-70964", "mrqa_squad-train-29671", "mrqa_squad-train-10997", "mrqa_squad-train-69946", "mrqa_squad-train-80746", "mrqa_squad-train-77612", "mrqa_squad-train-64333", "mrqa_squad-train-84612", "mrqa_squad-train-60904", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-3430", "mrqa_hotpotqa-validation-260", "mrqa_naturalquestions-validation-1310", "mrqa_newsqa-validation-1319", "mrqa_searchqa-validation-4495", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-4552", "mrqa_hotpotqa-validation-2801", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-3136", "mrqa_triviaqa-validation-3865", "mrqa_hotpotqa-validation-1742", "mrqa_hotpotqa-validation-4120", "mrqa_triviaqa-validation-7011", "mrqa_triviaqa-validation-7585", "mrqa_searchqa-validation-149", "mrqa_hotpotqa-validation-558", "mrqa_triviaqa-validation-5294", "mrqa_squad-validation-4000", "mrqa_naturalquestions-validation-4302", "mrqa_triviaqa-validation-4799", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-4057", "mrqa_hotpotqa-validation-4545", "mrqa_searchqa-validation-86", "mrqa_triviaqa-validation-23", "mrqa_searchqa-validation-13377", "mrqa_naturalquestions-validation-5596", "mrqa_newsqa-validation-3476", "mrqa_searchqa-validation-197", "mrqa_naturalquestions-validation-469"], "EFR": 0.0, "Overall": 0.5523128633720931}, {"timecode": 86, "before_eval_results": {"predictions": ["police car sits outside the Westroads Mall in Omaha, Nebraska,", "money or other discreet aid", "41,", "top designers", "in a fair and independent manner and ratify successful efforts.", "assassinated", "iCloud service", "Seasons of My Heart", "Johannesburg", "shot in the head", "a house party in Crandon, Wisconsin,", "Kenneth Cole", "$17,000", "137", "dental", "take a more active role in countering the spread of the", "School-age girls", "Theoneste Bagosora,", "\"The Lost Symbol,\" is by Brown himself.", "Haiti's", "2,000", "German authorities", "his brother to surrender.", "Roy Foster", "Mogadishu", "\"face of the peace initiative has been attacked.\"", "16 times.", "A rarely seen portrait of Michael Jackson", "fighting charges of Nazi war crimes", "oys And Girls alone", "London and Buenos Aires", "ALS6", "Den of Spies", "Dead Weather's \"Horehound\" at No. 6,", "\"Woz,\" as he is known by friends and fans alike, and partner Katarina Smirnoff", "his parents", "an empty water bottle down the touchline", "Samuel Herr, 26, and Juri Kibuishi, 23,", "forged credit cards and identity theft", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "\"Itsy Bitsy Teeny Weeny Yellow Polka Dot Bikini.\"", "five female pastors", "Facebook and Google,", "central Cairo,", "NATO's International Security Assistance Force", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "a U.S. military helicopter", "mental health", "\"The Cycle of Life,\"", "abusing its dominant position in the computer processing unit (CPU) market.", "Thomas Edison", "Donna", "Thomas Lennon", "1947", "new york", "mariette", "Boston Celtics", "Australian", "Oahu", "Florida", "toasted carmen cans", "the Seine", "The Mary Tyler Moore Show"], "metric_results": {"EM": 0.546875, "QA-F1": 0.664910427558914}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8421052631578948, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.14285714285714288, 1.0, 0.75, 0.0, 1.0, 0.0, 0.0, 0.23529411764705882, 1.0, 0.7499999999999999, 0.4444444444444445, 0.19512195121951217, 0.9166666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-982", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2324", "mrqa_newsqa-validation-227", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-3639", "mrqa_newsqa-validation-1907", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3788", "mrqa_newsqa-validation-522", "mrqa_newsqa-validation-2534", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2049", "mrqa_newsqa-validation-2702", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-940", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2019", "mrqa_newsqa-validation-3913", "mrqa_triviaqa-validation-884", "mrqa_hotpotqa-validation-4625", "mrqa_searchqa-validation-14248"], "SR": 0.546875, "CSR": 0.5617816091954023, "retrieved_ids": ["mrqa_squad-train-80752", "mrqa_squad-train-53307", "mrqa_squad-train-42835", "mrqa_squad-train-39541", "mrqa_squad-train-14709", "mrqa_squad-train-21212", "mrqa_squad-train-24985", "mrqa_squad-train-43180", "mrqa_squad-train-8599", "mrqa_squad-train-2006", "mrqa_squad-train-39839", "mrqa_squad-train-84048", "mrqa_squad-train-4762", "mrqa_squad-train-44520", "mrqa_squad-train-9621", "mrqa_squad-train-45091", "mrqa_squad-train-9342", "mrqa_squad-train-35122", "mrqa_squad-train-53852", "mrqa_squad-train-45559", "mrqa_squad-train-29884", "mrqa_squad-train-50008", "mrqa_squad-train-19929", "mrqa_squad-train-85711", "mrqa_squad-train-830", "mrqa_squad-train-53446", "mrqa_squad-train-53960", "mrqa_squad-train-4862", "mrqa_squad-train-76786", "mrqa_squad-train-81007", "mrqa_squad-train-18212", "mrqa_squad-train-65828", "mrqa_newsqa-validation-1218", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-1171", "mrqa_hotpotqa-validation-1127", "mrqa_squad-validation-9136", "mrqa_triviaqa-validation-1076", "mrqa_searchqa-validation-12278", "mrqa_triviaqa-validation-5309", "mrqa_hotpotqa-validation-2150", "mrqa_naturalquestions-validation-7694", "mrqa_triviaqa-validation-1363", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-4028", "mrqa_hotpotqa-validation-1614", "mrqa_triviaqa-validation-1983", "mrqa_triviaqa-validation-2414", "mrqa_triviaqa-validation-1389", "mrqa_triviaqa-validation-501", "mrqa_naturalquestions-validation-143", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-2558", "mrqa_searchqa-validation-15892", "mrqa_naturalquestions-validation-1446", "mrqa_searchqa-validation-2328", "mrqa_hotpotqa-validation-3162", "mrqa_squad-validation-1195", "mrqa_hotpotqa-validation-573", "mrqa_searchqa-validation-15851", "mrqa_hotpotqa-validation-5531", "mrqa_newsqa-validation-3605", "mrqa_triviaqa-validation-285", "mrqa_naturalquestions-validation-4193"], "EFR": 0.0, "Overall": 0.5522781968390805}, {"timecode": 87, "before_eval_results": {"predictions": ["four", "yellow", "whooping cough", "Kawasaki", "jeroen Krabb\u00e9", "reservoirs, an ancient stone circle and the modest moorland tops of cheetham Close and, more distantly, the Peak District", "the equator", "Wimbledon", "\"Sugar Baby Love\"", "1981", "Bernardo Bertolucci", "The Seven Year Itch", "dieppe", "Mediterranean", "tomato", "libretto", "Nicky Morgan", "midsomer Murders", "Muriel", "Abraham", "Aquaman", "American Civil War", "Christian Louboutin", "york", "chicken", "orange blossom", "herpes zoster", "The Queen Mother", "indonesian rupiah", "bannatt", "charles II", "Illinois", "danish", "The Landlord's Game", "diamantina", "Christine Keeler", "Silver Hatch", "magic", "Guatemalan", "clogs", "butch Cassidy and the Sundance Kid", "louis", "Edwina Currie", "Baton Rouge", "Warsaw", "2010", "carole king", "drizzle", "Casualty", "brimdon", "sleepless in seattle", "Telma Hopkins", "1624", "Milira", "Shaftesbury, Dorset", "Austrian Volksbanks", "1848 to 1852", "50,", "The United States has designated a Kurdish militant group in Turkey as a terrorist organization,", "Elena Kagan", "an abacus", "the Maine", "the Marquis de Lafayette", "The Osmonds"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5457618464052287}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4000000000000001, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2178", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-6826", "mrqa_triviaqa-validation-2704", "mrqa_triviaqa-validation-6808", "mrqa_triviaqa-validation-4726", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-7166", "mrqa_triviaqa-validation-3669", "mrqa_triviaqa-validation-5437", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-1688", "mrqa_triviaqa-validation-2756", "mrqa_triviaqa-validation-985", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-4060", "mrqa_triviaqa-validation-1255", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7175", "mrqa_triviaqa-validation-5775", "mrqa_naturalquestions-validation-2862", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5487", "mrqa_newsqa-validation-3922", "mrqa_newsqa-validation-1506"], "SR": 0.515625, "CSR": 0.5612571022727273, "retrieved_ids": ["mrqa_squad-train-33664", "mrqa_squad-train-83098", "mrqa_squad-train-64548", "mrqa_squad-train-69346", "mrqa_squad-train-53506", "mrqa_squad-train-82993", "mrqa_squad-train-22621", "mrqa_squad-train-5635", "mrqa_squad-train-63889", "mrqa_squad-train-56218", "mrqa_squad-train-54408", "mrqa_squad-train-37030", "mrqa_squad-train-46899", "mrqa_squad-train-12003", "mrqa_squad-train-86094", "mrqa_squad-train-7285", "mrqa_squad-train-71846", "mrqa_squad-train-71383", "mrqa_squad-train-2960", "mrqa_squad-train-46229", "mrqa_squad-train-5470", "mrqa_squad-train-56363", "mrqa_squad-train-6750", "mrqa_squad-train-6936", "mrqa_squad-train-19522", "mrqa_squad-train-82127", "mrqa_squad-train-1981", "mrqa_squad-train-43392", "mrqa_squad-train-25820", "mrqa_squad-train-74132", "mrqa_squad-train-1649", "mrqa_squad-train-39583", "mrqa_triviaqa-validation-2936", "mrqa_squad-validation-1195", "mrqa_naturalquestions-validation-7224", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-9979", "mrqa_triviaqa-validation-2921", "mrqa_newsqa-validation-3720", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-942", "mrqa_squad-validation-8415", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-10377", "mrqa_hotpotqa-validation-2372", "mrqa_naturalquestions-validation-10156", "mrqa_hotpotqa-validation-2802", "mrqa_searchqa-validation-2761", "mrqa_naturalquestions-validation-5564", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-8983", "mrqa_newsqa-validation-645", "mrqa_searchqa-validation-7375", "mrqa_hotpotqa-validation-1614", "mrqa_newsqa-validation-2068", "mrqa_searchqa-validation-5559", "mrqa_triviaqa-validation-1559", "mrqa_hotpotqa-validation-4001", "mrqa_triviaqa-validation-765", "mrqa_naturalquestions-validation-5780", "mrqa_searchqa-validation-1771", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-1439", "mrqa_newsqa-validation-1989"], "EFR": 0.0, "Overall": 0.5521732954545455}, {"timecode": 88, "before_eval_results": {"predictions": ["a fish", "luau", "Pat Paulsen", "paddington bear", "Antarctica", "a random number generator", "Mensheviks", "prada", "Euphoria Men Intense", "a hatchet", "Mel Gibson Hamlet", "baboon", "Chicken Little", "Bach", "Bangkok", "Eli Whitney", "John Smith", "James Buchanan Eads", "A Bug's Life", "NASCAR", "quiver", "the queen of hearts", "U.S. ambassador to South Vietnam", "Benito Mussolini", "a sheepshank", "Robert Burns", "Ebony", "Jack Nicklaus", "brass", "Las Vegas", "fiber", "poppy", "a portrait", "Lord of the Flies", "The Pursuit of Happyness", "Nickelback", "Succotash", "Jack London", "Falkland Islands", "acetone", "pecan", "adultery", "frankfurter", "Roanoke", "Blackbeard", "Lindsay Davenport", "Borden", "SO2", "Amish", "the dachshund", "Robert Frost", "Virginia Dare", "Ole Einar Bj\u00f8rndalen", "the first quarter of the 19th century", "George Washington", "Puerto Rico", "dav Graham", "1987", "1745 rebellion", "east", "a tenement in the Mumbai suburb of Chembur,", "Monday's", "Rod Blagojevich,", "Charles A. Carpenter"], "metric_results": {"EM": 0.625, "QA-F1": 0.6659226190476191}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.5, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16505", "mrqa_searchqa-validation-16628", "mrqa_searchqa-validation-5719", "mrqa_searchqa-validation-9291", "mrqa_searchqa-validation-14289", "mrqa_searchqa-validation-11143", "mrqa_searchqa-validation-5949", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-12850", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-14294", "mrqa_searchqa-validation-963", "mrqa_searchqa-validation-14824", "mrqa_searchqa-validation-11279", "mrqa_searchqa-validation-16576", "mrqa_searchqa-validation-2110", "mrqa_searchqa-validation-8484", "mrqa_searchqa-validation-5816", "mrqa_triviaqa-validation-3013", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-220", "mrqa_newsqa-validation-3631", "mrqa_triviaqa-validation-813"], "SR": 0.625, "CSR": 0.5619733146067416, "retrieved_ids": ["mrqa_squad-train-23573", "mrqa_squad-train-21641", "mrqa_squad-train-62760", "mrqa_squad-train-48367", "mrqa_squad-train-28565", "mrqa_squad-train-18367", "mrqa_squad-train-69096", "mrqa_squad-train-46529", "mrqa_squad-train-1770", "mrqa_squad-train-36002", "mrqa_squad-train-41124", "mrqa_squad-train-14572", "mrqa_squad-train-28833", "mrqa_squad-train-84663", "mrqa_squad-train-57045", "mrqa_squad-train-68649", "mrqa_squad-train-26226", "mrqa_squad-train-57068", "mrqa_squad-train-36443", "mrqa_squad-train-21853", "mrqa_squad-train-86223", "mrqa_squad-train-52345", "mrqa_squad-train-36919", "mrqa_squad-train-79327", "mrqa_squad-train-72608", "mrqa_squad-train-30527", "mrqa_squad-train-70097", "mrqa_squad-train-41040", "mrqa_squad-train-14001", "mrqa_squad-train-47488", "mrqa_squad-train-5143", "mrqa_squad-train-54759", "mrqa_newsqa-validation-2900", "mrqa_newsqa-validation-4122", "mrqa_triviaqa-validation-4836", "mrqa_squad-validation-8990", "mrqa_naturalquestions-validation-4768", "mrqa_triviaqa-validation-953", "mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-3769", "mrqa_newsqa-validation-3319", "mrqa_triviaqa-validation-7713", "mrqa_naturalquestions-validation-1443", "mrqa_newsqa-validation-1985", "mrqa_newsqa-validation-339", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-4393", "mrqa_triviaqa-validation-6424", "mrqa_naturalquestions-validation-4667", "mrqa_triviaqa-validation-3041", "mrqa_hotpotqa-validation-4322", "mrqa_triviaqa-validation-3820", "mrqa_squad-validation-27", "mrqa_newsqa-validation-2183", "mrqa_searchqa-validation-11532", "mrqa_newsqa-validation-2429", "mrqa_hotpotqa-validation-5328", "mrqa_searchqa-validation-1590", "mrqa_searchqa-validation-4851", "mrqa_searchqa-validation-1770", "mrqa_triviaqa-validation-3669", "mrqa_triviaqa-validation-465", "mrqa_squad-validation-3998"], "EFR": 0.0, "Overall": 0.5523165379213484}, {"timecode": 89, "before_eval_results": {"predictions": ["Bill Bryson", "pussycat", "Jordan", "vikings", "sartre", "u.S.A.", "jules bacall", "Mars", "riyadh", "margot fonteyn", "Diane Keaton", "plutocracy", "dominoes", "michael", "rebranded radio 4 Extra", "Steel Beads", "violinist", "u2", "bacall", "Australia", "auk", "cfs", "stanley", "soybean", "George Best", "time Bandits", "Jean-Paul Gaultier", "Red Rock West", "x", "zagreb", "handley page", "Marine One", "Zachary Taylor", "Hitler", "All Holies Day", "Shaft", "bacall", "le Vau", "Scotland", "Tripoli", "jubilee line", "Abbey Theatre", "Maine", "willow", "atlantic", "Denver", "1777", "michael blanc", "Lily Allen", "al-Qaeda", "oats", "Wisconsin", "season seven", "Whig candidates William Henry Harrison ( the `` hero of Tippecanoe '' ) and John Tyler", "230", "Serie B", "Mark O'Connor", "Colombia.", "a federal judge in Mississippi", "\"The workers should be dealt (with) with compassion and should not be pushed so hard that they resort to whatever that had happened in Nodia\"", "Wade E. Pickren", "the Untouchables", "expunge", "Tyne Daly"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6274217549923196}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06451612903225806, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1295", "mrqa_triviaqa-validation-5922", "mrqa_triviaqa-validation-3830", "mrqa_triviaqa-validation-3265", "mrqa_triviaqa-validation-6682", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-5952", "mrqa_triviaqa-validation-3144", "mrqa_triviaqa-validation-6620", "mrqa_triviaqa-validation-7104", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-3270", "mrqa_triviaqa-validation-7107", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-2780", "mrqa_triviaqa-validation-5138", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-1265", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-2307", "mrqa_naturalquestions-validation-7737", "mrqa_newsqa-validation-3566", "mrqa_searchqa-validation-7456", "mrqa_searchqa-validation-9329"], "SR": 0.59375, "CSR": 0.5623263888888889, "retrieved_ids": ["mrqa_squad-train-10518", "mrqa_squad-train-81929", "mrqa_squad-train-8665", "mrqa_squad-train-21187", "mrqa_squad-train-28202", "mrqa_squad-train-67215", "mrqa_squad-train-6723", "mrqa_squad-train-76687", "mrqa_squad-train-77931", "mrqa_squad-train-69552", "mrqa_squad-train-17105", "mrqa_squad-train-59235", "mrqa_squad-train-8332", "mrqa_squad-train-42522", "mrqa_squad-train-62193", "mrqa_squad-train-62807", "mrqa_squad-train-28474", "mrqa_squad-train-34385", "mrqa_squad-train-61253", "mrqa_squad-train-19836", "mrqa_squad-train-77009", "mrqa_squad-train-31284", "mrqa_squad-train-62525", "mrqa_squad-train-69239", "mrqa_squad-train-82500", "mrqa_squad-train-3036", "mrqa_squad-train-36468", "mrqa_squad-train-6463", "mrqa_squad-train-68900", "mrqa_squad-train-32329", "mrqa_squad-train-33190", "mrqa_squad-train-19934", "mrqa_triviaqa-validation-2733", "mrqa_newsqa-validation-442", "mrqa_newsqa-validation-2112", "mrqa_searchqa-validation-16607", "mrqa_squad-validation-3497", "mrqa_searchqa-validation-1827", "mrqa_naturalquestions-validation-6453", "mrqa_hotpotqa-validation-5154", "mrqa_searchqa-validation-12497", "mrqa_newsqa-validation-2991", "mrqa_naturalquestions-validation-5960", "mrqa_hotpotqa-validation-257", "mrqa_naturalquestions-validation-4326", "mrqa_newsqa-validation-3200", "mrqa_triviaqa-validation-4799", "mrqa_naturalquestions-validation-1171", "mrqa_hotpotqa-validation-1742", "mrqa_squad-validation-384", "mrqa_searchqa-validation-11886", "mrqa_triviaqa-validation-399", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-581", "mrqa_searchqa-validation-3218", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-1950", "mrqa_newsqa-validation-3772", "mrqa_triviaqa-validation-2214", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-227", "mrqa_triviaqa-validation-4411", "mrqa_hotpotqa-validation-831"], "EFR": 0.0, "Overall": 0.5523871527777777}, {"timecode": 90, "UKR": 0.814453125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1216", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-1866", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1996", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2232", "mrqa_hotpotqa-validation-2369", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2819", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-3034", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3214", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-3783", "mrqa_hotpotqa-validation-3790", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3878", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4120", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4474", "mrqa_hotpotqa-validation-4590", "mrqa_hotpotqa-validation-4625", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-5124", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-5275", "mrqa_hotpotqa-validation-5279", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-5578", "mrqa_hotpotqa-validation-5594", "mrqa_hotpotqa-validation-5595", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-789", "mrqa_hotpotqa-validation-84", "mrqa_naturalquestions-validation-10049", "mrqa_naturalquestions-validation-10107", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1315", "mrqa_naturalquestions-validation-1332", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-1763", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-2220", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3358", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-3805", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6349", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-793", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-7958", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-8764", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9897", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-110", "mrqa_newsqa-validation-1104", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1254", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-1366", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1422", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-1488", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1517", "mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-1634", "mrqa_newsqa-validation-1640", "mrqa_newsqa-validation-1828", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1907", "mrqa_newsqa-validation-1935", "mrqa_newsqa-validation-2001", "mrqa_newsqa-validation-2102", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-230", "mrqa_newsqa-validation-2365", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2951", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3024", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-325", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3432", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-3605", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3842", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-395", "mrqa_newsqa-validation-3963", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-551", "mrqa_newsqa-validation-643", "mrqa_newsqa-validation-669", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-777", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-872", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-1001", "mrqa_searchqa-validation-1049", "mrqa_searchqa-validation-10613", "mrqa_searchqa-validation-10670", "mrqa_searchqa-validation-10675", "mrqa_searchqa-validation-10795", "mrqa_searchqa-validation-10863", "mrqa_searchqa-validation-11143", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-11530", "mrqa_searchqa-validation-11570", "mrqa_searchqa-validation-11965", "mrqa_searchqa-validation-12031", "mrqa_searchqa-validation-12252", "mrqa_searchqa-validation-12594", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-12962", "mrqa_searchqa-validation-12999", "mrqa_searchqa-validation-13041", "mrqa_searchqa-validation-13061", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-13120", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13273", "mrqa_searchqa-validation-13478", "mrqa_searchqa-validation-14310", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-15686", "mrqa_searchqa-validation-15855", "mrqa_searchqa-validation-1590", "mrqa_searchqa-validation-16021", "mrqa_searchqa-validation-16176", "mrqa_searchqa-validation-16209", "mrqa_searchqa-validation-16299", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16378", "mrqa_searchqa-validation-16569", "mrqa_searchqa-validation-1827", "mrqa_searchqa-validation-1986", "mrqa_searchqa-validation-2038", "mrqa_searchqa-validation-2268", "mrqa_searchqa-validation-2304", "mrqa_searchqa-validation-2368", "mrqa_searchqa-validation-3013", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3573", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-3758", "mrqa_searchqa-validation-398", "mrqa_searchqa-validation-4089", "mrqa_searchqa-validation-4169", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-4581", "mrqa_searchqa-validation-4836", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5177", "mrqa_searchqa-validation-5746", "mrqa_searchqa-validation-5812", "mrqa_searchqa-validation-5911", "mrqa_searchqa-validation-5922", "mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-663", "mrqa_searchqa-validation-6876", "mrqa_searchqa-validation-7154", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7375", "mrqa_searchqa-validation-7419", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-7871", "mrqa_searchqa-validation-8214", "mrqa_searchqa-validation-8276", "mrqa_searchqa-validation-8465", "mrqa_searchqa-validation-8638", "mrqa_searchqa-validation-8888", "mrqa_searchqa-validation-8985", "mrqa_searchqa-validation-9249", "mrqa_searchqa-validation-935", "mrqa_searchqa-validation-9372", "mrqa_searchqa-validation-9696", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9853", "mrqa_searchqa-validation-9896", "mrqa_searchqa-validation-9902", "mrqa_searchqa-validation-9910", "mrqa_squad-validation-10369", "mrqa_squad-validation-10477", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-127", "mrqa_squad-validation-1371", "mrqa_squad-validation-2328", "mrqa_squad-validation-259", "mrqa_squad-validation-2691", "mrqa_squad-validation-280", "mrqa_squad-validation-2959", "mrqa_squad-validation-3052", "mrqa_squad-validation-3124", "mrqa_squad-validation-3144", "mrqa_squad-validation-3230", "mrqa_squad-validation-3241", "mrqa_squad-validation-335", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3608", "mrqa_squad-validation-3703", "mrqa_squad-validation-3919", "mrqa_squad-validation-3955", "mrqa_squad-validation-4066", "mrqa_squad-validation-415", "mrqa_squad-validation-4326", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5110", "mrqa_squad-validation-5422", "mrqa_squad-validation-5604", "mrqa_squad-validation-5726", "mrqa_squad-validation-5781", "mrqa_squad-validation-5960", "mrqa_squad-validation-6169", "mrqa_squad-validation-6502", "mrqa_squad-validation-6875", "mrqa_squad-validation-7064", "mrqa_squad-validation-7549", "mrqa_squad-validation-7708", "mrqa_squad-validation-7717", "mrqa_squad-validation-7751", "mrqa_squad-validation-8754", "mrqa_squad-validation-8904", "mrqa_squad-validation-8958", "mrqa_squad-validation-959", "mrqa_squad-validation-9716", "mrqa_triviaqa-validation-1019", "mrqa_triviaqa-validation-1038", "mrqa_triviaqa-validation-1147", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-12", "mrqa_triviaqa-validation-1206", "mrqa_triviaqa-validation-1239", "mrqa_triviaqa-validation-1290", "mrqa_triviaqa-validation-1512", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-1806", "mrqa_triviaqa-validation-1879", "mrqa_triviaqa-validation-189", "mrqa_triviaqa-validation-1917", "mrqa_triviaqa-validation-2002", "mrqa_triviaqa-validation-2004", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-205", "mrqa_triviaqa-validation-2075", "mrqa_triviaqa-validation-2140", "mrqa_triviaqa-validation-2170", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-2328", "mrqa_triviaqa-validation-2404", "mrqa_triviaqa-validation-2441", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-2504", "mrqa_triviaqa-validation-2527", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-2565", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2705", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-2762", "mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3043", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3115", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-341", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-3495", "mrqa_triviaqa-validation-3522", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3747", "mrqa_triviaqa-validation-3768", "mrqa_triviaqa-validation-384", "mrqa_triviaqa-validation-3936", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-3967", "mrqa_triviaqa-validation-4006", "mrqa_triviaqa-validation-426", "mrqa_triviaqa-validation-4306", "mrqa_triviaqa-validation-4346", "mrqa_triviaqa-validation-4410", "mrqa_triviaqa-validation-4447", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-447", "mrqa_triviaqa-validation-4655", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-4727", "mrqa_triviaqa-validation-4740", "mrqa_triviaqa-validation-4750", "mrqa_triviaqa-validation-483", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4902", "mrqa_triviaqa-validation-4902", "mrqa_triviaqa-validation-4956", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5032", "mrqa_triviaqa-validation-5035", "mrqa_triviaqa-validation-5141", "mrqa_triviaqa-validation-5180", "mrqa_triviaqa-validation-5212", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-5312", "mrqa_triviaqa-validation-5560", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5667", "mrqa_triviaqa-validation-5763", "mrqa_triviaqa-validation-5823", "mrqa_triviaqa-validation-5853", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5867", "mrqa_triviaqa-validation-5897", "mrqa_triviaqa-validation-5915", "mrqa_triviaqa-validation-5952", "mrqa_triviaqa-validation-5989", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-6255", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6388", "mrqa_triviaqa-validation-6475", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6571", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6808", "mrqa_triviaqa-validation-6833", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7103", "mrqa_triviaqa-validation-7190", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7380", "mrqa_triviaqa-validation-7405", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-7439", "mrqa_triviaqa-validation-7497", "mrqa_triviaqa-validation-7688", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-839", "mrqa_triviaqa-validation-917", "mrqa_triviaqa-validation-971"], "OKR": 0.86328125, "KG": 0.496875, "before_eval_results": {"predictions": ["a meteoroid", "colleen McCullough", "The Lion King", "Cyprus", "f. Lee Bailey and Barry Scheck", "Pokemon", "Turkmenistan", "a dove", "giraffe", "a meadow", "argentina", "Venus", "leiter", "tunisia", "colleen McCullough", "Egypt", "gioacchino Rossini", "drew Carey", "Three Mile Island", "sicily", "sunset boulevard", "Bombe", "brussels", "arrows", "The Quatermass Experiment", "pasta joke", "Frogmore Estate or Gardens", "Emmy Awards", "caucausus", "36", "cold Comfort Farm", "new year", "Iceland", "David Hilbert", "mediterranean", "Declaration of Independence", "Marlon Brando", "regal", "Cleopatra Selene", "greenham", "Robert Schumann", "Whisky Galore", "Grace Slick", "michael caine", "fonds de la Recherche Scientifique", "Robert Boyle", "1929", "The Lone Gunmen", "Sue", "daily Herald", "PJ Harvey", "Brian Steele", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "Cherokee River", "Benedict of Nursia", "Wichita", "Jewish", "Friday,", "put him in \"solitary confinement.\"", "a dove", "Konstantin Stanislavski", "Annie Proulx", "\"Nude, Green Leaves and Bust\""], "metric_results": {"EM": 0.6875, "QA-F1": 0.7402686403508771}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1595", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-5925", "mrqa_triviaqa-validation-5220", "mrqa_triviaqa-validation-406", "mrqa_triviaqa-validation-6609", "mrqa_triviaqa-validation-5526", "mrqa_triviaqa-validation-2054", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-5155", "mrqa_triviaqa-validation-4815", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-7391", "mrqa_triviaqa-validation-1261", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7098", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-10147", "mrqa_newsqa-validation-4026", "mrqa_searchqa-validation-508"], "SR": 0.6875, "CSR": 0.5637019230769231, "retrieved_ids": ["mrqa_squad-train-2970", "mrqa_squad-train-1133", "mrqa_squad-train-43789", "mrqa_squad-train-53257", "mrqa_squad-train-27394", "mrqa_squad-train-42753", "mrqa_squad-train-15740", "mrqa_squad-train-75506", "mrqa_squad-train-16170", "mrqa_squad-train-85099", "mrqa_squad-train-63891", "mrqa_squad-train-63536", "mrqa_squad-train-79631", "mrqa_squad-train-85807", "mrqa_squad-train-19082", "mrqa_squad-train-32455", "mrqa_squad-train-68667", "mrqa_squad-train-76751", "mrqa_squad-train-19706", "mrqa_squad-train-46155", "mrqa_squad-train-33098", "mrqa_squad-train-30029", "mrqa_squad-train-82007", "mrqa_squad-train-42892", "mrqa_squad-train-81394", "mrqa_squad-train-57593", "mrqa_squad-train-71082", "mrqa_squad-train-55404", "mrqa_squad-train-34808", "mrqa_squad-train-18273", "mrqa_squad-train-40392", "mrqa_squad-train-29930", "mrqa_searchqa-validation-9185", "mrqa_squad-validation-7051", "mrqa_triviaqa-validation-4457", "mrqa_squad-validation-6477", "mrqa_triviaqa-validation-6642", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-3344", "mrqa_triviaqa-validation-24", "mrqa_newsqa-validation-3714", "mrqa_naturalquestions-validation-10202", "mrqa_searchqa-validation-11279", "mrqa_searchqa-validation-3875", "mrqa_triviaqa-validation-3996", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-5738", "mrqa_newsqa-validation-2001", "mrqa_triviaqa-validation-7353", "mrqa_newsqa-validation-551", "mrqa_naturalquestions-validation-9477", "mrqa_hotpotqa-validation-3440", "mrqa_newsqa-validation-3290", "mrqa_searchqa-validation-9329", "mrqa_newsqa-validation-2491", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-5360", "mrqa_triviaqa-validation-4836", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-1165", "mrqa_searchqa-validation-6273", "mrqa_triviaqa-validation-7379", "mrqa_triviaqa-validation-7107", "mrqa_triviaqa-validation-465"], "EFR": 0.0, "Overall": 0.5476622596153847}, {"timecode": 91, "before_eval_results": {"predictions": ["evangelical Christian periodical", "2011", "John McClane", "Marika Green", "Princeton University", "conservative", "Lombardy", "writer", "Elton John", "Newcastle upon Tyne, England", "Lev Ivanovich Yashin", "Blackwood Partners Management Corporation", "1958", "2007", "Robots Overlords", "1776", "Ashland", "public house", "1944", "Austria", "Ron Cowen and Daniel Lipman", "The Soloist", "indoor", "Hannaford", "January 30, 1930", "Dr. Alberto Taquini", "John Gotti", "Chris Weidman", "north", "Harrison Ford", "C. H. Greenblatt", "Taoiseach of Ireland", "Dissection", "The Killer", "seacoast", "Javed Miandad", "Dorothy", "2017", "people working in film and the performing arts", "June 2, 2008", "The 8th Habit", "one", "London", "Australia", "Ready Player One", "1981 World Rowing Championships", "1911", "15,023", "North Atlantic Conference", "a variety of ancient herding dogs", "Phelan Beale", "March 2018", "New Zealand", "62", "fly", "Perry Mason", "Oliver Goldsmith", "Afghan lawmakers", "Her husband and attorney, James Whitehouse,", "al Qaeda,", "Ford", "Matt Damon", "a Kiwanis", "bartering"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7278645833333333}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.4, 0.5, 1.0, 0.25, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2023", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-4948", "mrqa_hotpotqa-validation-1257", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-4077", "mrqa_hotpotqa-validation-5740", "mrqa_hotpotqa-validation-5056", "mrqa_hotpotqa-validation-4208", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-3966", "mrqa_hotpotqa-validation-5852", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-2503", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-3250", "mrqa_triviaqa-validation-1178", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-14674", "mrqa_searchqa-validation-9994"], "SR": 0.65625, "CSR": 0.5647078804347826, "retrieved_ids": ["mrqa_squad-train-61633", "mrqa_squad-train-60898", "mrqa_squad-train-12497", "mrqa_squad-train-71004", "mrqa_squad-train-28803", "mrqa_squad-train-71464", "mrqa_squad-train-11026", "mrqa_squad-train-5560", "mrqa_squad-train-45282", "mrqa_squad-train-78640", "mrqa_squad-train-61764", "mrqa_squad-train-37046", "mrqa_squad-train-36153", "mrqa_squad-train-43351", "mrqa_squad-train-22688", "mrqa_squad-train-52954", "mrqa_squad-train-23049", "mrqa_squad-train-33872", "mrqa_squad-train-41818", "mrqa_squad-train-11833", "mrqa_squad-train-46337", "mrqa_squad-train-2429", "mrqa_squad-train-78697", "mrqa_squad-train-35552", "mrqa_squad-train-8171", "mrqa_squad-train-28472", "mrqa_squad-train-64481", "mrqa_squad-train-20224", "mrqa_squad-train-28924", "mrqa_squad-train-69587", "mrqa_squad-train-63849", "mrqa_squad-train-28489", "mrqa_squad-validation-6072", "mrqa_naturalquestions-validation-2006", "mrqa_newsqa-validation-3559", "mrqa_triviaqa-validation-7497", "mrqa_squad-validation-7612", "mrqa_newsqa-validation-2582", "mrqa_triviaqa-validation-5477", "mrqa_hotpotqa-validation-4712", "mrqa_newsqa-validation-3474", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-7461", "mrqa_squad-validation-2145", "mrqa_naturalquestions-validation-7164", "mrqa_searchqa-validation-686", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-3769", "mrqa_triviaqa-validation-7321", "mrqa_searchqa-validation-7456", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-10490", "mrqa_triviaqa-validation-2383", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-988", "mrqa_triviaqa-validation-3276", "mrqa_triviaqa-validation-7464", "mrqa_naturalquestions-validation-3288", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-9120", "mrqa_hotpotqa-validation-3886"], "EFR": 0.0, "Overall": 0.5478634510869566}, {"timecode": 92, "before_eval_results": {"predictions": ["Margery Williams", "Vi\u1ec7t B\u1eafc", "Richard Avedon", "one of the youngest publicly documented people to be identified as transgender", "Australian women's national soccer team", "Odense Boldklub", "SpongeBob SquarePants 4-D", "Oldham County", "Grammar, logic, and rhetoric", "Wright brothers", "a research university with high research activity", "O.T. Genasis", "science fiction drama", "Speedway World Championship", "Citric acid", "200", "moth", "Gerald Hatten Buss", "Delacorte Press", "close range combat", "twice", "Eli Roth", "Adelaide", "Lincoln Riley", "December 13, 1920", "Mark Sinclair", "John McClane", "rural areas", "Orchard Central", "Art of Dying", "Book of Judges", "Ant Timpson, Ted Geoghegan and Tim League", "Great Exuma", "John Ford", "classical", "Marvel", "between 7,500 and 40,000", "for crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "Earvin \"Magic\" Johnson Jr.", "Nevada", "Yasir Hussain", "Victoria", "Jennifer Aniston", "the Main Line of the Long Island Rail Road", "Universal's volcano Bay", "25 December 2009", "the Hanna-Barbera show \" Birdman and the Galaxy Trio.\"", "Jango Fett", "\"Der Rosenkavalier\", \"Elektra\", \"Die Frau ohne Schatten\" and \"Four Last Songs\"", "8th", "NBA 2K16", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth )", "Professor Eobard Thawne", "India", "36", "beetle", "Australia", "umpire Jake Garner", "Kearny, New Jersey.", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "noodles", "Tennessee Williams", "Oregon", "old country"], "metric_results": {"EM": 0.578125, "QA-F1": 0.697224386422756}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.33333333333333326, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.5217391304347826, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.4, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-4211", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-41", "mrqa_hotpotqa-validation-3807", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-1530", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-1185", "mrqa_hotpotqa-validation-2254", "mrqa_hotpotqa-validation-1857", "mrqa_hotpotqa-validation-4546", "mrqa_hotpotqa-validation-4979", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-4735", "mrqa_naturalquestions-validation-2472", "mrqa_triviaqa-validation-6079", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-909", "mrqa_searchqa-validation-8642", "mrqa_searchqa-validation-5853", "mrqa_triviaqa-validation-4848"], "SR": 0.578125, "CSR": 0.5648521505376345, "retrieved_ids": ["mrqa_squad-train-31925", "mrqa_squad-train-22860", "mrqa_squad-train-12964", "mrqa_squad-train-83529", "mrqa_squad-train-25125", "mrqa_squad-train-41180", "mrqa_squad-train-79336", "mrqa_squad-train-49433", "mrqa_squad-train-25829", "mrqa_squad-train-47668", "mrqa_squad-train-52362", "mrqa_squad-train-33785", "mrqa_squad-train-19179", "mrqa_squad-train-75548", "mrqa_squad-train-66411", "mrqa_squad-train-17872", "mrqa_squad-train-68175", "mrqa_squad-train-11192", "mrqa_squad-train-81278", "mrqa_squad-train-22936", "mrqa_squad-train-15007", "mrqa_squad-train-59805", "mrqa_squad-train-73433", "mrqa_squad-train-58765", "mrqa_squad-train-31790", "mrqa_squad-train-18088", "mrqa_squad-train-4498", "mrqa_squad-train-42622", "mrqa_squad-train-55809", "mrqa_squad-train-43924", "mrqa_squad-train-32704", "mrqa_squad-train-51194", "mrqa_hotpotqa-validation-2044", "mrqa_newsqa-validation-333", "mrqa_hotpotqa-validation-2117", "mrqa_newsqa-validation-3933", "mrqa_hotpotqa-validation-4864", "mrqa_newsqa-validation-1007", "mrqa_naturalquestions-validation-7967", "mrqa_hotpotqa-validation-2840", "mrqa_hotpotqa-validation-3886", "mrqa_searchqa-validation-6426", "mrqa_triviaqa-validation-1659", "mrqa_squad-validation-1566", "mrqa_hotpotqa-validation-3085", "mrqa_newsqa-validation-940", "mrqa_squad-validation-4326", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-3752", "mrqa_newsqa-validation-321", "mrqa_triviaqa-validation-3768", "mrqa_naturalquestions-validation-8599", "mrqa_triviaqa-validation-3525", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-16", "mrqa_naturalquestions-validation-10015", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-2630", "mrqa_newsqa-validation-3922", "mrqa_naturalquestions-validation-1135", "mrqa_triviaqa-validation-3419", "mrqa_squad-validation-4572"], "EFR": 0.0, "Overall": 0.547892305107527}, {"timecode": 93, "before_eval_results": {"predictions": ["YIVO", "Archbishop of Canterbury", "Samuel Beckett", "January 28, 2016", "The Catholic Church in Ireland", "close range combat", "Iran", "Kate Millett", "Timothy Matthew Howard", "\"Lucky\"", "Do Kyung-soo", "John Hunt", "Kongo", "William Finn", "Sam Raimi", "The final of 2011 AFC Asian Cup", "suburb", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "Marine Corps Air Station Kaneohe Bay", "August 17, 2017", "Montagues and Capulets", "Walter R\u00f6hrl", "left", "Vladimir Valentinovich Menshov", "film", "Denmark and Norway", "Love and Theft", "C. W. Grafton", "Jean-Claude Van Damme and Stephen Rea and Evey's mother", "\"My Love from the Star\"", "143,372", "Jack Kilby", "Cold Spring", "Afghanistan", "Operation Sculpin", "guitar feedback", "Flushed Away", "George Washington Bridge", "Reginald Engelbach", "Van Diemen's Land", "Tampa", "Sergeant First Class", "140 million", "SpongeBob SquarePants 4-D", "StubHub Center", "Argentinian", "Americas and the entire South American temperate zone", "a large portion of rural Maine,", "1998", "The More", "John F. Kennedy Jr.", "com TLD", "Andrew Lloyd Webber", "John Bull", "NASCAR", "The Avengers", "Rick Wakeman", "mental health", "Madhav Kumar Nepal of the Communist Party of Nepal (Unified Marxist-Leninist)", "hardship", "Berlin", "William Golding", "The Odd Couple", "Americans who served in the armed forces and as civilians during World War II"], "metric_results": {"EM": 0.75, "QA-F1": 0.8177307935120435}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.22222222222222224, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5676", "mrqa_hotpotqa-validation-3591", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-4455", "mrqa_hotpotqa-validation-4294", "mrqa_hotpotqa-validation-4015", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5647", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-4052", "mrqa_hotpotqa-validation-4235", "mrqa_naturalquestions-validation-4844", "mrqa_newsqa-validation-964", "mrqa_newsqa-validation-1063"], "SR": 0.75, "CSR": 0.5668218085106382, "retrieved_ids": ["mrqa_squad-train-6783", "mrqa_squad-train-73501", "mrqa_squad-train-74004", "mrqa_squad-train-61975", "mrqa_squad-train-57504", "mrqa_squad-train-13581", "mrqa_squad-train-54205", "mrqa_squad-train-52078", "mrqa_squad-train-39420", "mrqa_squad-train-63154", "mrqa_squad-train-9986", "mrqa_squad-train-70282", "mrqa_squad-train-47998", "mrqa_squad-train-7885", "mrqa_squad-train-33960", "mrqa_squad-train-41453", "mrqa_squad-train-3740", "mrqa_squad-train-58757", "mrqa_squad-train-10860", "mrqa_squad-train-71042", "mrqa_squad-train-1260", "mrqa_squad-train-74500", "mrqa_squad-train-73595", "mrqa_squad-train-58913", "mrqa_squad-train-68118", "mrqa_squad-train-49969", "mrqa_squad-train-9603", "mrqa_squad-train-55832", "mrqa_squad-train-27594", "mrqa_squad-train-25968", "mrqa_squad-train-69687", "mrqa_squad-train-2942", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-2927", "mrqa_hotpotqa-validation-3538", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-2308", "mrqa_naturalquestions-validation-2558", "mrqa_triviaqa-validation-156", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7464", "mrqa_squad-validation-6973", "mrqa_triviaqa-validation-1982", "mrqa_searchqa-validation-15770", "mrqa_naturalquestions-validation-34", "mrqa_searchqa-validation-3451", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-13585", "mrqa_naturalquestions-validation-10684", "mrqa_searchqa-validation-2367", "mrqa_naturalquestions-validation-9451", "mrqa_searchqa-validation-3875", "mrqa_searchqa-validation-8544", "mrqa_searchqa-validation-14674", "mrqa_searchqa-validation-1621", "mrqa_naturalquestions-validation-3419", "mrqa_searchqa-validation-6961", "mrqa_hotpotqa-validation-3917", "mrqa_naturalquestions-validation-9897", "mrqa_newsqa-validation-1700", "mrqa_triviaqa-validation-3800", "mrqa_hotpotqa-validation-4177", "mrqa_naturalquestions-validation-8159"], "EFR": 0.0, "Overall": 0.5482862367021276}, {"timecode": 94, "before_eval_results": {"predictions": ["Nutbush", "china", "6", "golf", "Einstein", "Manchester", "stanley", "Bleak House", "brunn", "Roosevelt", "new york", "to make wrinkles", "Amy Tan", "The Great Gatsby", "Charlie Chan", "1664", "A Beautiful Mind", "marquess of david", "Damian Green", "engraver", "george orwell o'brien", "Jim Peters", "nitrogen", "oldpatricktoe-end", "delilah", "infante", "cuckoo", "PPTH", "The Wicker Man", "yellow", "avonlea", "giacomo Meyerbeer", "Guardian", "John Huston", "Passenger Pigeon", "Anne Frank", "manchego", "Texas", "pi\u00f1a colada", "fauntleroy", "kachhi", "Petula Clark", "Dr Tamseel", "Flo Rida", "The Comedy of Errors", "mead", "chemical origins of life", "Finland", "saccharides", "dolma", "kempton", "Cress", "Vesta", "the pouring rain at a rest stop", "Tiffany & Company", "2010 to 2012", "Nathan Bedford Forrest", "Friday,", "Six", "\"Americans always believe things are better in their own lives than in the rest of the country,\"", "tanning", "Tulane", "Lauren Conrad", "the Bactrian"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5691236413043478}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.1739130434782609, 1.0, 1.0, 0.0, 0.25]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-870", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-4430", "mrqa_triviaqa-validation-1828", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-5695", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-7529", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-2801", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-4663", "mrqa_triviaqa-validation-5580", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-7655", "mrqa_triviaqa-validation-1304", "mrqa_triviaqa-validation-6995", "mrqa_triviaqa-validation-2276", "mrqa_triviaqa-validation-2843", "mrqa_triviaqa-validation-4091", "mrqa_naturalquestions-validation-9903", "mrqa_hotpotqa-validation-2141", "mrqa_newsqa-validation-2336", "mrqa_newsqa-validation-1300", "mrqa_searchqa-validation-5376", "mrqa_naturalquestions-validation-8046"], "SR": 0.53125, "CSR": 0.5664473684210527, "retrieved_ids": ["mrqa_squad-train-63019", "mrqa_squad-train-19109", "mrqa_squad-train-50458", "mrqa_squad-train-51868", "mrqa_squad-train-56364", "mrqa_squad-train-33444", "mrqa_squad-train-28467", "mrqa_squad-train-48981", "mrqa_squad-train-58792", "mrqa_squad-train-75671", "mrqa_squad-train-67931", "mrqa_squad-train-37078", "mrqa_squad-train-55655", "mrqa_squad-train-18651", "mrqa_squad-train-65416", "mrqa_squad-train-48379", "mrqa_squad-train-6816", "mrqa_squad-train-63625", "mrqa_squad-train-63422", "mrqa_squad-train-34764", "mrqa_squad-train-50432", "mrqa_squad-train-28257", "mrqa_squad-train-67641", "mrqa_squad-train-31624", "mrqa_squad-train-500", "mrqa_squad-train-63782", "mrqa_squad-train-30171", "mrqa_squad-train-16741", "mrqa_squad-train-68173", "mrqa_squad-train-46161", "mrqa_squad-train-80193", "mrqa_squad-train-27928", "mrqa_searchqa-validation-9159", "mrqa_newsqa-validation-2086", "mrqa_naturalquestions-validation-5538", "mrqa_searchqa-validation-483", "mrqa_naturalquestions-validation-10554", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-11", "mrqa_squad-validation-8819", "mrqa_naturalquestions-validation-4592", "mrqa_triviaqa-validation-957", "mrqa_naturalquestions-validation-849", "mrqa_squad-validation-2383", "mrqa_searchqa-validation-4000", "mrqa_triviaqa-validation-7107", "mrqa_naturalquestions-validation-3033", "mrqa_hotpotqa-validation-1070", "mrqa_searchqa-validation-3932", "mrqa_triviaqa-validation-6930", "mrqa_naturalquestions-validation-836", "mrqa_squad-validation-5588", "mrqa_triviaqa-validation-3505", "mrqa_naturalquestions-validation-10271", "mrqa_searchqa-validation-8374", "mrqa_triviaqa-validation-4534", "mrqa_squad-validation-2000", "mrqa_searchqa-validation-12864", "mrqa_naturalquestions-validation-824", "mrqa_triviaqa-validation-6233", "mrqa_hotpotqa-validation-3930"], "EFR": 0.0, "Overall": 0.5482113486842106}, {"timecode": 95, "before_eval_results": {"predictions": ["the Korean War", "$1.5 million", "Fernando Caceres", "37", "opposition parties", "green-card warriors", "people give the United States abysmal approval ratings.", "Secretary of State", "his wife's name", "A paper cape sits loosely around your shoulders, covering your naked chest.", "U.S. senators", "put a lid on the marking of Ashura", "Alexey Pajitnov,", "Spc. Megan Lynn Touma,", "regulators in the agency's Colorado office", "west African nation", "Leo Frank, a northern Jew who'd moved to Atlanta to supervise the National Pencil Company factory.", "Sri Lanka", "Johannesburg", "last year's", "The escalating conflict in Mogadishu is having a devastating impact on the city's population causing enormous suffering and massive displacement,\"", "heavy flannel or wool", "It is not something that has gotten lost,\"", "near Pakistan's border with Afghanistan", "walk", "an independent homeland since 1983.", "that would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "longest domestic relay in the games' history,", "Kim Jong Un", "Arthur E. Morgan III,", "billboards with an image of the burning World Trade Center", "top designers", "walk", "E! News", "Cologne, Germany,", "she had been lured from a club, forced into a men's bathroom at a university dormitory, bound and assaulted.", "70,000 or so", "The station", "in terms of the country's most-wanted list, Mejia Munera was one of Colombia's most sought-after criminals and ranked just below the leaders of Revolutionary Armed Forces of Colombia,", "one of his strongest statements to date on the sex abuse scandal sweeping the Roman Catholic Church,", "large accumulations of ice", "East Java", "part of a planned training exercise designed to help the prince learn to fly in combat situations.", "billions of dollars", "between June 20 and July 20", "Rod Blagojevich", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "Majid Movahedi,", "violating anti-trust laws.", "Jonas", "billions of dollars in Chinese products each year,", "Windows Media Video ( WMA )", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Joe Pizzulo and Leeza Miller", "alonzo Church", "paisley", "thumbelina", "three", "The Apple iPod+HP", "Lithuanian", "Jeopardy!", "Krakauer", "The Sun Also Rises", "Rob Reiner"], "metric_results": {"EM": 0.5, "QA-F1": 0.6202836680133941}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.09302325581395349, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.3, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 0.4, 0.9411764705882353, 0.0, 0.0, 1.0, 1.0, 0.35714285714285715, 0.5, 1.0, 0.07407407407407407, 0.0, 1.0, 1.0, 0.9375, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-359", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-3425", "mrqa_newsqa-validation-3852", "mrqa_newsqa-validation-1750", "mrqa_newsqa-validation-3164", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-3358", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-3808", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-876", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1646", "mrqa_naturalquestions-validation-3851", "mrqa_triviaqa-validation-3391", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-318", "mrqa_searchqa-validation-8089", "mrqa_searchqa-validation-4108", "mrqa_searchqa-validation-10142"], "SR": 0.5, "CSR": 0.5657552083333333, "retrieved_ids": ["mrqa_squad-train-25492", "mrqa_squad-train-12081", "mrqa_squad-train-27536", "mrqa_squad-train-17859", "mrqa_squad-train-40780", "mrqa_squad-train-31071", "mrqa_squad-train-72452", "mrqa_squad-train-14707", "mrqa_squad-train-46925", "mrqa_squad-train-27443", "mrqa_squad-train-25735", "mrqa_squad-train-2596", "mrqa_squad-train-61255", "mrqa_squad-train-68930", "mrqa_squad-train-76720", "mrqa_squad-train-59090", "mrqa_squad-train-19831", "mrqa_squad-train-77295", "mrqa_squad-train-48144", "mrqa_squad-train-59729", "mrqa_squad-train-13703", "mrqa_squad-train-79635", "mrqa_squad-train-44443", "mrqa_squad-train-81581", "mrqa_squad-train-43834", "mrqa_squad-train-71405", "mrqa_squad-train-39794", "mrqa_squad-train-60150", "mrqa_squad-train-4432", "mrqa_squad-train-28411", "mrqa_squad-train-11422", "mrqa_squad-train-63863", "mrqa_naturalquestions-validation-7507", "mrqa_searchqa-validation-6444", "mrqa_triviaqa-validation-6808", "mrqa_triviaqa-validation-5437", "mrqa_hotpotqa-validation-722", "mrqa_squad-validation-6072", "mrqa_newsqa-validation-3986", "mrqa_searchqa-validation-13583", "mrqa_triviaqa-validation-2486", "mrqa_triviaqa-validation-4643", "mrqa_triviaqa-validation-3036", "mrqa_hotpotqa-validation-3272", "mrqa_triviaqa-validation-2099", "mrqa_squad-validation-6965", "mrqa_searchqa-validation-7340", "mrqa_searchqa-validation-7633", "mrqa_newsqa-validation-4026", "mrqa_triviaqa-validation-7424", "mrqa_naturalquestions-validation-1705", "mrqa_newsqa-validation-2608", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-7226", "mrqa_triviaqa-validation-7773", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-602", "mrqa_naturalquestions-validation-809", "mrqa_squad-validation-8195", "mrqa_searchqa-validation-12996", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-10631", "mrqa_newsqa-validation-2261", "mrqa_hotpotqa-validation-1900"], "EFR": 0.0, "Overall": 0.5480729166666667}, {"timecode": 96, "before_eval_results": {"predictions": ["UNICEF", "poppy production", "security breach", "take a more active role in countering the spread of the", "public opinion", "Christopher Savoie", "prisoners at the South Dakota State Penitentiary", "Tuesday afternoon.", "Iowa,", "Dr. Jennifer Arnold and husband Bill Klein,", "Chinese", "Michael Bloomberg", "more than 1.2 million", "the estate with its 18th-century sights, sounds, and scents.", "The survey also says that three out of four Americans are angry about the way things are going in the country.", "$250,000 for Rivers' charity: God's Love We Deliver.", "Flint, Michigan.", "FARC rebels.", "Mexico", "Larry Zeiger", "Alberto Espinoza Barron,", "The tall 34-year-old, slouching exhausted in a Johannesburg church that has become a de facto transit camp,", "Four", "Math teacher Mawise Gumba", "burned over 65 percent of his body", "Brian Smith", "2-1", "a motor scooter that goes about 55 miles per hour -- on 12-inch wheels.", "Hank Moody", "April 2010.", "Nothing But Love", "Mandi Hamlin", "people look at the content of the speech, not just the delivery.", "Yemen,", "Dodi Fayed,", "an American who entered the country illegally from China on Christmas Eve.", "don't", "the company has not yet managed to sell the concept to a buyer", "Manny Pacquiao", "\"confronting and critiquing cultural constraints\" against notions of \"fatness\" and \"the fat body,\"", "did not identify any of the dead.", "President Thabo Mbeki", "Bright Automotive, a small carmaker from Anderson, Indiana, to showcase its IDEA, a new, 100-mpg plug-in hybrid electric vehicle that it hopes to market for government and commercial fleets.", "Jeffrey Jamaleldine", "did not get them to agree", "Haiti,", "at Atlanta's Hartsfield-Jackson International Airport", "his business dealings", "hardship", "nearly 28 years", "Hollywood", "A \u00d7 9", "ThonMaker", "parashah", "morocco", "the Benedictine Order", "Cecil", "sexy Star", "March 31, 1944", "Dutch", "a dragon", "Marcus Garvey", "the zodiac", "obsessive-compulsive disorder"], "metric_results": {"EM": 0.5, "QA-F1": 0.6050480283699714}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.8421052631578948, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.2222222222222222, 0.0909090909090909, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.16666666666666669, 0.0, 1.0, 0.1, 0.0, 0.2, 0.13793103448275862, 0.6666666666666666, 0.125, 1.0, 0.0, 1.0, 0.2222222222222222, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2648", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-3556", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2928", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-905", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-1138", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-2229", "mrqa_triviaqa-validation-6184", "mrqa_hotpotqa-validation-5312", "mrqa_searchqa-validation-2594"], "SR": 0.5, "CSR": 0.5650773195876289, "retrieved_ids": ["mrqa_squad-train-52368", "mrqa_squad-train-29520", "mrqa_squad-train-23271", "mrqa_squad-train-6368", "mrqa_squad-train-45103", "mrqa_squad-train-42805", "mrqa_squad-train-65035", "mrqa_squad-train-28431", "mrqa_squad-train-85833", "mrqa_squad-train-7937", "mrqa_squad-train-48472", "mrqa_squad-train-11006", "mrqa_squad-train-34439", "mrqa_squad-train-39000", "mrqa_squad-train-19161", "mrqa_squad-train-603", "mrqa_squad-train-36115", "mrqa_squad-train-32411", "mrqa_squad-train-34754", "mrqa_squad-train-30109", "mrqa_squad-train-49210", "mrqa_squad-train-8666", "mrqa_squad-train-43589", "mrqa_squad-train-25218", "mrqa_squad-train-13926", "mrqa_squad-train-45357", "mrqa_squad-train-51669", "mrqa_squad-train-40589", "mrqa_squad-train-4345", "mrqa_squad-train-73324", "mrqa_squad-train-20149", "mrqa_squad-train-46906", "mrqa_newsqa-validation-1458", "mrqa_hotpotqa-validation-5296", "mrqa_naturalquestions-validation-10461", "mrqa_squad-validation-1136", "mrqa_triviaqa-validation-1659", "mrqa_searchqa-validation-971", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-5469", "mrqa_newsqa-validation-533", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-5228", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3771", "mrqa_searchqa-validation-15029", "mrqa_hotpotqa-validation-2058", "mrqa_hotpotqa-validation-1754", "mrqa_newsqa-validation-4122", "mrqa_hotpotqa-validation-3141", "mrqa_naturalquestions-validation-5928", "mrqa_newsqa-validation-1483", "mrqa_naturalquestions-validation-4348", "mrqa_triviaqa-validation-1971", "mrqa_newsqa-validation-386", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-1076", "mrqa_searchqa-validation-11821", "mrqa_naturalquestions-validation-6194", "mrqa_searchqa-validation-4245", "mrqa_hotpotqa-validation-1156", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-1070"], "EFR": 0.0, "Overall": 0.5479373389175258}, {"timecode": 97, "before_eval_results": {"predictions": ["Johannes Gutenberg", "2018", "twice in the Hebrew Bible, in the books of Exodus and Deuteronomy", "Thomas Jefferson", "about the level of the third lumbar vertebra, or L3, at birth", "Rama", "Pakistan", "for the red - bed country of its watershed", "United States, its NATO allies and others", "Rashida Jones", "cut off close by the hip, and under the left shoulder, he carried a crutch", "sunny throughout the year", "Peter Andrew Beardsley MBE", "Season two", "Terry Reid", "1260 cubic centimeters ( cm ) for men and 1130 cm for women", "May 3, 2005", "As of September 18, 2012, the chain operates 639 stores in 43 states", "the Rashidun Caliphs", "British Columbia, Canada", "central place in Christian eschatology", "Pyeongchang County, Gangwon Province, South Korea", "diffuse interstellar medium ( ISM )", "made in desperation, with only a small chance of success and time running out on the clock", "1944 through 1946", "Tokyo for the 2020 Summer Olympics", "Lituya Bay in Alaska", "San Jose, California", "wagen VIII Maus", "July 2, 1776", "accomplish the objectives of the organization", "Domhnall Gleeson", "Simon Callow", "Florida", "Laura Jane Haddock", "May 2016", "Bacon", "1994", "Matthew Broderick", "senators", "origins of replication, in the genome", "the fourth quarter of the preceding year", "April 2016", "Michael Schumacher", "Massachusetts", "Latitude", "2015", "post translational modification", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "a writ of certiorari", "Jules Shear", "morocco", "island", "brain", "Romeo Montague (Italian: \"Romeo Montecchi\" )", "De La Soul", "Delilah Rene", "July as part of the State Department's Foreign Relations of the United States series.", "he was educated there, in Spain and at Harvard Law School.", "$81,1203", "Missouri River", "jade", "Frank Sinatra", "Long troop deployments"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6408193671136768}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 0.0, 0.18181818181818182, 1.0, 0.15384615384615383, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 0.8148148148148148, 1.0, 0.15384615384615385, 1.0, 1.0, 0.25, 1.0, 0.39999999999999997, 0.05970149253731343, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.14285714285714285, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-5039", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7458", "mrqa_naturalquestions-validation-6687", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-5819", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-878", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-473", "mrqa_triviaqa-validation-2425", "mrqa_triviaqa-validation-7592", "mrqa_hotpotqa-validation-212", "mrqa_hotpotqa-validation-1952", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1987", "mrqa_newsqa-validation-4199", "mrqa_searchqa-validation-4588", "mrqa_newsqa-validation-2892"], "SR": 0.5625, "CSR": 0.5650510204081632, "retrieved_ids": ["mrqa_squad-train-58145", "mrqa_squad-train-23256", "mrqa_squad-train-83955", "mrqa_squad-train-2618", "mrqa_squad-train-53994", "mrqa_squad-train-48335", "mrqa_squad-train-81512", "mrqa_squad-train-67694", "mrqa_squad-train-23655", "mrqa_squad-train-67863", "mrqa_squad-train-16247", "mrqa_squad-train-76799", "mrqa_squad-train-86503", "mrqa_squad-train-59916", "mrqa_squad-train-19899", "mrqa_squad-train-47555", "mrqa_squad-train-60861", "mrqa_squad-train-84030", "mrqa_squad-train-67878", "mrqa_squad-train-82478", "mrqa_squad-train-66613", "mrqa_squad-train-51121", "mrqa_squad-train-52772", "mrqa_squad-train-82054", "mrqa_squad-train-40316", "mrqa_squad-train-50141", "mrqa_squad-train-21172", "mrqa_squad-train-29008", "mrqa_squad-train-33332", "mrqa_squad-train-35376", "mrqa_squad-train-8200", "mrqa_squad-train-78235", "mrqa_triviaqa-validation-3102", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-181", "mrqa_hotpotqa-validation-2044", "mrqa_triviaqa-validation-4228", "mrqa_squad-validation-2456", "mrqa_hotpotqa-validation-3503", "mrqa_hotpotqa-validation-4451", "mrqa_hotpotqa-validation-1007", "mrqa_squad-validation-3812", "mrqa_hotpotqa-validation-3381", "mrqa_squad-validation-6706", "mrqa_hotpotqa-validation-4177", "mrqa_hotpotqa-validation-1605", "mrqa_searchqa-validation-13377", "mrqa_naturalquestions-validation-10454", "mrqa_triviaqa-validation-3590", "mrqa_hotpotqa-validation-5328", "mrqa_searchqa-validation-581", "mrqa_newsqa-validation-245", "mrqa_triviaqa-validation-3208", "mrqa_naturalquestions-validation-2945", "mrqa_newsqa-validation-2020", "mrqa_hotpotqa-validation-66", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-4519", "mrqa_searchqa-validation-7517", "mrqa_hotpotqa-validation-5647", "mrqa_triviaqa-validation-3270", "mrqa_naturalquestions-validation-1640", "mrqa_searchqa-validation-4836"], "EFR": 0.0, "Overall": 0.5479320790816327}, {"timecode": 98, "before_eval_results": {"predictions": ["hair", "Deimos", "Julia Jean Turner", "a Polaroid picture", "Germantown", "June Carter Cash", "\"The owl and the Pussycat\"", "St Lewis", "fat", "poison ivy", "Denny McLain", "bicycle", "Edith Wharton", "Liberia", "rockabilly", "Buckingham Palace", "AARP", "Arturo Toscanini", "Bangladesh", "Saturn", "Nancy Pelosi", "Unison", "root beer", "misery", "an anglerfish", "Coal mining", "Iowa", "kidnapping", "Pope John Paul II", "an photocopier", "Syria", "(William) Inge", "a plies", "the Bean Sidhe", "Japan", "Zephyr Teachout", "a ballistic missile submarine", "Ambrose Bierce", "Walt Whitman", "frequency", "Macbeth", "Colorado River", "vice presidential running mate", "Tommy Franks", "Botswana", "Mousehunt", "the Dow Jones Industrial Average", "Winston Churchill", "Vietnam", "a bell", "a Croque Madam", "Kyla Pratt", "Wisconsin", "March 11, 2018", "top cat", "goose bump", "Adrian Cronauer (Williams), an Air Force disc jockey who'sbeen flown in from another assignment to a post at the center of the escalating conflict in Vietnam.", "1 August 1971", "Australia", "Bronwyn Kathleen Bishop", "Jonas", "Madhav Kumar Nepal of the Communist Party of Nepal (Unified Marxist-Leninist)", "Joe Jackson", "200"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6922755912565696}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.08695652173913045, 1.0, 1.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-1844", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-14933", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15889", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-14445", "mrqa_searchqa-validation-10204", "mrqa_searchqa-validation-13577", "mrqa_searchqa-validation-13824", "mrqa_searchqa-validation-11733", "mrqa_searchqa-validation-7239", "mrqa_searchqa-validation-7781", "mrqa_searchqa-validation-8836", "mrqa_searchqa-validation-1625", "mrqa_searchqa-validation-6160", "mrqa_searchqa-validation-2884", "mrqa_triviaqa-validation-5342", "mrqa_triviaqa-validation-312", "mrqa_hotpotqa-validation-123", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-964", "mrqa_newsqa-validation-1955", "mrqa_hotpotqa-validation-5878"], "SR": 0.59375, "CSR": 0.5653409090909092, "retrieved_ids": ["mrqa_squad-train-86149", "mrqa_squad-train-65542", "mrqa_squad-train-27981", "mrqa_squad-train-4741", "mrqa_squad-train-72427", "mrqa_squad-train-38786", "mrqa_squad-train-26137", "mrqa_squad-train-9128", "mrqa_squad-train-78601", "mrqa_squad-train-10595", "mrqa_squad-train-57933", "mrqa_squad-train-48754", "mrqa_squad-train-1132", "mrqa_squad-train-18591", "mrqa_squad-train-66222", "mrqa_squad-train-25737", "mrqa_squad-train-65076", "mrqa_squad-train-21494", "mrqa_squad-train-84241", "mrqa_squad-train-81816", "mrqa_squad-train-76677", "mrqa_squad-train-64199", "mrqa_squad-train-27354", "mrqa_squad-train-6912", "mrqa_squad-train-46404", "mrqa_squad-train-25383", "mrqa_squad-train-73775", "mrqa_squad-train-18539", "mrqa_squad-train-52608", "mrqa_squad-train-67212", "mrqa_squad-train-86180", "mrqa_squad-train-51402", "mrqa_triviaqa-validation-156", "mrqa_searchqa-validation-7596", "mrqa_naturalquestions-validation-9013", "mrqa_triviaqa-validation-5873", "mrqa_searchqa-validation-8089", "mrqa_searchqa-validation-4530", "mrqa_hotpotqa-validation-3399", "mrqa_newsqa-validation-939", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-5780", "mrqa_searchqa-validation-11621", "mrqa_triviaqa-validation-7033", "mrqa_squad-validation-3946", "mrqa_triviaqa-validation-1559", "mrqa_searchqa-validation-7106", "mrqa_naturalquestions-validation-6328", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-5278", "mrqa_naturalquestions-validation-1423", "mrqa_newsqa-validation-2020", "mrqa_triviaqa-validation-2733", "mrqa_naturalquestions-validation-578", "mrqa_searchqa-validation-9479", "mrqa_newsqa-validation-421", "mrqa_triviaqa-validation-7379", "mrqa_naturalquestions-validation-801", "mrqa_newsqa-validation-3503", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-4298", "mrqa_searchqa-validation-8642", "mrqa_triviaqa-validation-1517"], "EFR": 0.0, "Overall": 0.5479900568181819}, {"timecode": 99, "UKR": 0.814453125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1078", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-1866", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-1935", "mrqa_hotpotqa-validation-2023", "mrqa_hotpotqa-validation-2067", "mrqa_hotpotqa-validation-2141", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2232", "mrqa_hotpotqa-validation-2254", "mrqa_hotpotqa-validation-2369", "mrqa_hotpotqa-validation-2393", "mrqa_hotpotqa-validation-2662", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-276", "mrqa_hotpotqa-validation-2819", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-3034", "mrqa_hotpotqa-validation-3141", "mrqa_hotpotqa-validation-3214", "mrqa_hotpotqa-validation-3329", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-3783", "mrqa_hotpotqa-validation-3790", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3878", "mrqa_hotpotqa-validation-3905", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-3979", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4120", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4474", "mrqa_hotpotqa-validation-4590", "mrqa_hotpotqa-validation-4625", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-4879", "mrqa_hotpotqa-validation-5124", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-5275", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-5578", "mrqa_hotpotqa-validation-5594", "mrqa_hotpotqa-validation-5595", "mrqa_hotpotqa-validation-5598", "mrqa_hotpotqa-validation-5620", "mrqa_hotpotqa-validation-5647", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-5724", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-789", "mrqa_hotpotqa-validation-84", "mrqa_naturalquestions-validation-10049", "mrqa_naturalquestions-validation-10107", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1315", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-1636", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-1763", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-2220", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-2970", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3358", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-3668", "mrqa_naturalquestions-validation-3805", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4190", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4553", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-4865", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5055", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5538", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-6349", "mrqa_naturalquestions-validation-636", "mrqa_naturalquestions-validation-6372", "mrqa_naturalquestions-validation-6378", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-7127", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-793", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-7958", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8120", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8637", "mrqa_naturalquestions-validation-8764", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-9239", "mrqa_naturalquestions-validation-926", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9419", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9897", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-110", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1217", "mrqa_newsqa-validation-1254", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-1276", "mrqa_newsqa-validation-1300", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-1366", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1422", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-1488", "mrqa_newsqa-validation-1517", "mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-1634", "mrqa_newsqa-validation-1640", "mrqa_newsqa-validation-1750", "mrqa_newsqa-validation-1828", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1907", "mrqa_newsqa-validation-1935", "mrqa_newsqa-validation-2001", "mrqa_newsqa-validation-2102", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-230", "mrqa_newsqa-validation-2365", "mrqa_newsqa-validation-2575", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2951", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3024", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3247", "mrqa_newsqa-validation-325", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-3432", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-3605", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-3842", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-395", "mrqa_newsqa-validation-3963", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-459", "mrqa_newsqa-validation-643", "mrqa_newsqa-validation-70", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-777", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-823", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-872", "mrqa_newsqa-validation-901", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-1001", "mrqa_searchqa-validation-1049", "mrqa_searchqa-validation-10670", "mrqa_searchqa-validation-10675", "mrqa_searchqa-validation-10795", "mrqa_searchqa-validation-10863", "mrqa_searchqa-validation-11271", "mrqa_searchqa-validation-11530", "mrqa_searchqa-validation-11570", "mrqa_searchqa-validation-11965", "mrqa_searchqa-validation-12252", "mrqa_searchqa-validation-12568", "mrqa_searchqa-validation-12594", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-12962", "mrqa_searchqa-validation-12999", "mrqa_searchqa-validation-13041", "mrqa_searchqa-validation-13061", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-13120", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13273", "mrqa_searchqa-validation-13478", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-14655", "mrqa_searchqa-validation-15686", "mrqa_searchqa-validation-15855", "mrqa_searchqa-validation-16021", "mrqa_searchqa-validation-16176", "mrqa_searchqa-validation-16209", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16378", "mrqa_searchqa-validation-16569", "mrqa_searchqa-validation-1827", "mrqa_searchqa-validation-1986", "mrqa_searchqa-validation-2038", "mrqa_searchqa-validation-2304", "mrqa_searchqa-validation-2368", "mrqa_searchqa-validation-2467", "mrqa_searchqa-validation-2884", "mrqa_searchqa-validation-3013", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3573", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-398", "mrqa_searchqa-validation-4089", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-4836", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5177", "mrqa_searchqa-validation-5746", "mrqa_searchqa-validation-5812", "mrqa_searchqa-validation-5911", "mrqa_searchqa-validation-5922", "mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-663", "mrqa_searchqa-validation-6876", "mrqa_searchqa-validation-7154", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7375", "mrqa_searchqa-validation-7419", "mrqa_searchqa-validation-7829", "mrqa_searchqa-validation-7871", "mrqa_searchqa-validation-8214", "mrqa_searchqa-validation-8465", "mrqa_searchqa-validation-8638", "mrqa_searchqa-validation-8888", "mrqa_searchqa-validation-8985", "mrqa_searchqa-validation-9249", "mrqa_searchqa-validation-935", "mrqa_searchqa-validation-9372", "mrqa_searchqa-validation-9696", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-9789", "mrqa_searchqa-validation-9853", "mrqa_searchqa-validation-9902", "mrqa_searchqa-validation-9910", "mrqa_squad-validation-10369", "mrqa_squad-validation-10477", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-127", "mrqa_squad-validation-1371", "mrqa_squad-validation-2328", "mrqa_squad-validation-259", "mrqa_squad-validation-2691", "mrqa_squad-validation-280", "mrqa_squad-validation-2959", "mrqa_squad-validation-3052", "mrqa_squad-validation-3124", "mrqa_squad-validation-3144", "mrqa_squad-validation-3230", "mrqa_squad-validation-3241", "mrqa_squad-validation-335", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3608", "mrqa_squad-validation-3703", "mrqa_squad-validation-3919", "mrqa_squad-validation-4066", "mrqa_squad-validation-415", "mrqa_squad-validation-4326", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5422", "mrqa_squad-validation-5604", "mrqa_squad-validation-5726", "mrqa_squad-validation-5781", "mrqa_squad-validation-5960", "mrqa_squad-validation-6169", "mrqa_squad-validation-6502", "mrqa_squad-validation-6875", "mrqa_squad-validation-7064", "mrqa_squad-validation-7549", "mrqa_squad-validation-7717", "mrqa_squad-validation-7751", "mrqa_squad-validation-8754", "mrqa_squad-validation-8904", "mrqa_squad-validation-8958", "mrqa_squad-validation-959", "mrqa_squad-validation-9716", "mrqa_triviaqa-validation-1019", "mrqa_triviaqa-validation-1038", "mrqa_triviaqa-validation-115", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-12", "mrqa_triviaqa-validation-1206", "mrqa_triviaqa-validation-1239", "mrqa_triviaqa-validation-1290", "mrqa_triviaqa-validation-1512", "mrqa_triviaqa-validation-1576", "mrqa_triviaqa-validation-1595", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-1806", "mrqa_triviaqa-validation-1879", "mrqa_triviaqa-validation-189", "mrqa_triviaqa-validation-1917", "mrqa_triviaqa-validation-2002", "mrqa_triviaqa-validation-2004", "mrqa_triviaqa-validation-2036", "mrqa_triviaqa-validation-205", "mrqa_triviaqa-validation-2075", "mrqa_triviaqa-validation-2140", "mrqa_triviaqa-validation-2170", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-2328", "mrqa_triviaqa-validation-2404", "mrqa_triviaqa-validation-2441", "mrqa_triviaqa-validation-2478", "mrqa_triviaqa-validation-2504", "mrqa_triviaqa-validation-2527", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-2565", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2705", "mrqa_triviaqa-validation-2730", "mrqa_triviaqa-validation-2762", "mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2939", "mrqa_triviaqa-validation-2975", "mrqa_triviaqa-validation-3002", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3043", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-3115", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3223", "mrqa_triviaqa-validation-3347", "mrqa_triviaqa-validation-341", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-3495", "mrqa_triviaqa-validation-3522", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3747", "mrqa_triviaqa-validation-3768", "mrqa_triviaqa-validation-384", "mrqa_triviaqa-validation-3936", "mrqa_triviaqa-validation-3967", "mrqa_triviaqa-validation-426", "mrqa_triviaqa-validation-4306", "mrqa_triviaqa-validation-4346", "mrqa_triviaqa-validation-4402", "mrqa_triviaqa-validation-4410", "mrqa_triviaqa-validation-4447", "mrqa_triviaqa-validation-447", "mrqa_triviaqa-validation-4655", "mrqa_triviaqa-validation-4711", "mrqa_triviaqa-validation-4727", "mrqa_triviaqa-validation-4740", "mrqa_triviaqa-validation-4750", "mrqa_triviaqa-validation-483", "mrqa_triviaqa-validation-4848", "mrqa_triviaqa-validation-4902", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5032", "mrqa_triviaqa-validation-5141", "mrqa_triviaqa-validation-5180", "mrqa_triviaqa-validation-5212", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-5312", "mrqa_triviaqa-validation-5560", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5667", "mrqa_triviaqa-validation-5695", "mrqa_triviaqa-validation-5763", "mrqa_triviaqa-validation-5819", "mrqa_triviaqa-validation-5823", "mrqa_triviaqa-validation-5853", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5867", "mrqa_triviaqa-validation-5897", "mrqa_triviaqa-validation-5915", "mrqa_triviaqa-validation-5952", "mrqa_triviaqa-validation-5989", "mrqa_triviaqa-validation-61", "mrqa_triviaqa-validation-6255", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6388", "mrqa_triviaqa-validation-6475", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6571", "mrqa_triviaqa-validation-6618", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6808", "mrqa_triviaqa-validation-6833", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7103", "mrqa_triviaqa-validation-7190", "mrqa_triviaqa-validation-7327", "mrqa_triviaqa-validation-7380", "mrqa_triviaqa-validation-7405", "mrqa_triviaqa-validation-7439", "mrqa_triviaqa-validation-7497", "mrqa_triviaqa-validation-7688", "mrqa_triviaqa-validation-839", "mrqa_triviaqa-validation-870", "mrqa_triviaqa-validation-917", "mrqa_triviaqa-validation-971"], "OKR": 0.83984375, "KG": 0.496875, "before_eval_results": {"predictions": ["New Orleans", "what you did", "\"The Beaver State\"", "the Rosetta Stone", "Japan", "crumpets", "Lord Bill Astor", "peripheral vision", "\"Paul Revere's Ride\"", "Canton", "Hormel Foods Corp.", "a consonant", "Theodore", "Parris Island", "Roger Williams", "Niels Bohr", "the sun", "Ahab", "an Abominable Dr. Phibes", "Surf's Up", "Scorpio", "a cat", "Finding Nemo", "the International Space Station", "Shakira", "Candice Bergen", "a shark", "Ireland", "George J. Mitchell", "Henry Wadsworth Longfellow", "Gauguin", "Elizabeth I", "bamboo", "animal Crackers", "Crete", "Frank Sinatra", "George Armstrong Custer", "Barney Stinson", "March 18", "Marlee Matlin", "Ben- Hur: A Tale of the Christ", "Yu Darvish", "Dan Rather", "KLM", "food combining", "ducti", "elephants", "Arkansas", "Bank of America", "a piccolo", "a tsuzumi", "Jason Marsden", "1998", "Garfield Sobers", "france", "Jimmy Carter", "carmen cans", "Detroit, Michigan", "the Troubles", "ARY Films", "Sri Lanka", "Ali Bongo", "Rod Blagojevich,", "the Islamic prophet Muhammad"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6646577380952381}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4116", "mrqa_searchqa-validation-11687", "mrqa_searchqa-validation-11963", "mrqa_searchqa-validation-16851", "mrqa_searchqa-validation-12262", "mrqa_searchqa-validation-11024", "mrqa_searchqa-validation-11056", "mrqa_searchqa-validation-9926", "mrqa_searchqa-validation-15", "mrqa_searchqa-validation-14283", "mrqa_searchqa-validation-702", "mrqa_searchqa-validation-777", "mrqa_searchqa-validation-13708", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-4666", "mrqa_searchqa-validation-209", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-1713", "mrqa_searchqa-validation-2630", "mrqa_searchqa-validation-9182", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-8612", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3439", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-3631", "mrqa_naturalquestions-validation-6637"], "SR": 0.578125, "CSR": 0.56546875, "retrieved_ids": ["mrqa_squad-train-36196", "mrqa_squad-train-40462", "mrqa_squad-train-10085", "mrqa_squad-train-33832", "mrqa_squad-train-13355", "mrqa_squad-train-44828", "mrqa_squad-train-3734", "mrqa_squad-train-19508", "mrqa_squad-train-59742", "mrqa_squad-train-23692", "mrqa_squad-train-47667", "mrqa_squad-train-74818", "mrqa_squad-train-33757", "mrqa_squad-train-67919", "mrqa_squad-train-6054", "mrqa_squad-train-33494", "mrqa_squad-train-82459", "mrqa_squad-train-49984", "mrqa_squad-train-44694", "mrqa_squad-train-78558", "mrqa_squad-train-32050", "mrqa_squad-train-44367", "mrqa_squad-train-31047", "mrqa_squad-train-51891", "mrqa_squad-train-83058", "mrqa_squad-train-67949", "mrqa_squad-train-6982", "mrqa_squad-train-86224", "mrqa_squad-train-42029", "mrqa_squad-train-1396", "mrqa_squad-train-8771", "mrqa_squad-train-78882", "mrqa_hotpotqa-validation-4434", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1649", "mrqa_naturalquestions-validation-2429", "mrqa_newsqa-validation-4059", "mrqa_triviaqa-validation-312", "mrqa_newsqa-validation-2444", "mrqa_searchqa-validation-14569", "mrqa_naturalquestions-validation-8175", "mrqa_newsqa-validation-227", "mrqa_hotpotqa-validation-558", "mrqa_triviaqa-validation-2276", "mrqa_triviaqa-validation-6352", "mrqa_squad-validation-978", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-2749", "mrqa_naturalquestions-validation-6254", "mrqa_triviaqa-validation-4599", "mrqa_naturalquestions-validation-10680", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-9329", "mrqa_naturalquestions-validation-7143", "mrqa_triviaqa-validation-7463", "mrqa_newsqa-validation-1290", "mrqa_hotpotqa-validation-1070", "mrqa_hotpotqa-validation-3773", "mrqa_newsqa-validation-2739", "mrqa_triviaqa-validation-2532", "mrqa_newsqa-validation-3130", "mrqa_naturalquestions-validation-2102"], "EFR": 0.0, "Overall": 0.543328125}]}