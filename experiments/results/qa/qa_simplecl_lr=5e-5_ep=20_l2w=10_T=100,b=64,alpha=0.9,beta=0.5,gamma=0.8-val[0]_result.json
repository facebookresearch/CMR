{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8420, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "a squared integer", "a Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "U.S. ship that was hijacked off Somalia's coast.", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8240675990675991}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.78125, "CSR": 0.8046875, "EFR": 0.9285714285714286, "Overall": 0.8666294642857143}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "on the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "its compilation of a vast institutional compendium named Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two-page", "Arizona Cardinals", "1991", "Mercury/Gemini veteran Wally Schirra, Eisele, and rookie Walter Cunningham", "Isiah Bowman", "the poor", "100\u2013150", "Executive Vice President of Football Operations", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "more integral within the health care system", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Madonna Martin", "NLP Stand For - Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Christopher Nolan", "water", "six Oscars", "It always begins with the music, of course.", "music director", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.71875, "QA-F1": 0.7849171661671661}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-803", "mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-8159", "mrqa_squad-validation-7949", "mrqa_squad-validation-235", "mrqa_squad-validation-3967", "mrqa_squad-validation-378", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.71875, "CSR": 0.7760416666666666, "EFR": 1.0, "Overall": 0.8880208333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "printed images", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "best-known legend", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "Jean-Claude Juncker", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster", "multiple revisions", "philanthropic initiative", "integer factorization problem", "necessity", "Isel", "adapted quickly and often married outside their immediate French communities", "Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "Channel Islands", "separating faith and reason", "Alberich", "charleston", "ireil", "Churchill Downs", "The port of Terneuzen", "charleston", "charl", "Germany", "study insects and their relationship to humans, other organisms, and the environment", "the limbic system", "Allan Border", "George Fox", "Virginia", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.6672743055555556}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-9286", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-3069", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_hotpotqa-validation-3821"], "SR": 0.640625, "CSR": 0.7421875, "EFR": 0.9130434782608695, "Overall": 0.8276154891304348}, {"timecode": 4, "before_eval_results": {"predictions": ["in higher plants", "Parliament of Victoria", "Zaha Hadid", "the Marquis de Vaudreuil", "Science and Discovery", "the Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "Battle of Olustee", "port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover in the basin", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related diseases", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "the Civil Protection Authority", "22 felony counts", "seven alleged militants", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a new model is simply out of their reach", "Muslim", "will be the first time any version of the Magna Carta has ever gone up for auction", "a unit of Time Warner", "15", "fighters", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "FBI", "a woman who may have been contacted through a Craigslist ad", "one", "celebrity-inspired names", "$1,500", "National Industrial Recovery Act", "tracey\u2019s younger son Travis", "Humberside Airport", "colombia"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6983774987267635}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.15999999999999998, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-7094", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-830", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.671875, "CSR": 0.728125, "EFR": 0.9523809523809523, "Overall": 0.8402529761904762}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "Connectional Table", "Deformational", "a data network based on this voice-phone network", "roughly 500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "Philippines", "Denver's Executive Vice President of Football Operations and General Manager", "1950s to 2011", "the spoils of the war", "German Te Deum", "1795", "Bermuda 419", "evaporated to cool oxygen gas", "Infinity Broadcasting Corporation", "\"semi-legal\" and was the only opposition group in Egypt able to field candidates during elections", "1972", "rudimentary", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "President of the United States negotiates treaties with foreign nations", "used in a compact layout to combine keys which are usually kept separate", "from an Ohio newspaper on 8 February 1925", "Herbert Hoover", "radius R of the turntable", "Panning", "Justin Timberlake", "the following 15 countries or regions have reached an economy of at least US $2 trillion by GDP in nominal or PPP terms", "As of 31 December 2013, the total size of the peacekeeping force is 98,200 police", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada", "speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman", "David Gahan", "The Stanley Hotel", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the day before the long fast for the Lenten fast", "Jaipur", "Johan Persson and Martin Schibbye", "torpedo boats", "Newport Gwen Dragons"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6409411549707602}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.56, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.25, 1.0, 0.7142857142857143, 0.1111111111111111, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8333333333333333, 0.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5833333333333334, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-376", "mrqa_squad-validation-7488", "mrqa_squad-validation-9908", "mrqa_squad-validation-3473", "mrqa_squad-validation-9635", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.546875, "CSR": 0.6979166666666667, "EFR": 0.9655172413793104, "Overall": 0.8317169540229885}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "a Serbian Orthodox priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "\"social and political action,\"", "1936", "New Birth", "gold", "a 3\u20130 lead on a Brandon McManus 34-yard field goal", "Vivienne Westwood", "reduction", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "\"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live and 5 Live Sports Extra", "1876", "screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "teachers in good standing with the college, and private schools may also require their teachers to be college peoples", "end of the season", "10", "Jacob, on the other hand, held on as the most popular boy's name for the 11th year in a row.", "African-Americans", "\"creates the precedent and possibility for undue regulation, censorship and legal abuse.\"", "\"Sesame Street's\" Grover, how to make gnocchi with Mario Batali, and the ins and outs of prettying up your home with any number of programs on HGTV.", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer, can put users in a dazed stupor for about two hours,", "in 5.1 and we go 'Whoa, listen to that,'", "on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170 were killed and hundreds of others were wounded", "North Korea", "first five Potter films", "you love the environment and hate using fuel", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse,", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "James Lillywhite, Alfred Shaw and Arthur Shrewsbury", "Colgate University", "Church of Christ, Scientist", "an unsaturated fat is a fat or fatty acid in which there is at least one double bond within the fatty acid chain", "canonical gospels and the book of Acts"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6851995043962334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.08695652173913043, 0.0, 0.0, 0.2857142857142857, 0.3636363636363636, 0.6666666666666666, 1.0, 0.16666666666666669, 0.25, 1.0, 0.0, 1.0, 0.16666666666666669, 0.3076923076923077, 1.0, 0.10526315789473685, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.4, 0.2222222222222222]}}, "before_error_ids": ["mrqa_squad-validation-800", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-3390", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.609375, "CSR": 0.6852678571428572, "EFR": 0.96, "Overall": 0.8226339285714286}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased trade with poor countries", "187 feet (57 m)", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "yellow chlorophyll precursor", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "Belgrade", "up to \u00a339,942", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "\"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto,", "at the country's third-largest oil refinery", "April 24 through May 2.", "Krishna Rajaram, a Fulbright Scholar and honor student at UCLA.", "early detection and helping other women cope with the disease.", "250,000", "Timothy Masters", "homicide by undetermined means", "permitted under Spanish Football Federation (RFEF) rules.", "12 hours in jail", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "Madeleine K. Albright", "Oxygen Channel's \"Dance Your Ass Off\"", "procedures that have been obtained from detainees through interrogation and cruel treatment, such as waterboarding, will no longer be admitted as evidence before the commissions", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "seeking help", "Japanese officials", "Tyndorf, Germany", "\"Empire of the Sun\" was made into a movie by Steven Spielberg.", "Norman given name Robert", "stronger with an unfair advantage", "Matthew Ward Winer", "Doc Holliday", "opposite R\u00fcgen island", "Mustique, St. Vincent & the Grenadines, West Indies", "green"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6777029590033622}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.9032258064516129, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.3636363636363636, 0.3636363636363636, 0.0, 0.5, 0.5, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4615384615384615, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-2091", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-17", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_newsqa-validation-3281", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-4305"], "SR": 0.578125, "CSR": 0.671875, "EFR": 0.9629629629629629, "Overall": 0.8174189814814814}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships with an agreement that they were not to serve again in the present war.", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "\"Journey's End\"", "immediate", "Levi's Stadium", "decidedly Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Sir Isaac Newton", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington", "autonomy", "largest center for breeding and exporting terrorism", "$12.3 million", "Fernando Gonzalez", "Graeme Smith", "more than 80 features to his name", "finance", "terminal brain cancer", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "separated", "Animal Planet", "bleeding profusely", "\"The situation is pretty much resolved,\"", "54 bodies", "early detection and helping other women cope with the disease", "Diversity", "$250,000", "Thursday", "Nazi Germany", "March 27", "Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "2050", "Alfredo Astiz,", "Abdullah Gul,", "Mikkel Kessler", "The Everglades,", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans, Louisiana", "many investors paying huge sums for individual bulbs", "MIBs", "olympics", "This is your new single-touch access to the NHL app"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6665674603174603}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.13333333333333333, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.2222222222222222, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-9903", "mrqa_squad-validation-10341", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1219", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6631944444444444, "EFR": 0.9230769230769231, "Overall": 0.7931356837606838}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"hoos\"", "50%", "Indian allies, had taken place for decades, leading to a brisk trade in European colonial captives from either side.", "the top 15 most populous", "CRISPR sequences", "six", "about 300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "the substance of the statement", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "cooperating with Turkey in engaging with the Taliban in Pakistan and Afghanistan.", "25", "a treadmill", "Jennifer Arnold and husband Bill Klein,", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East.", "6,000", "cortisone", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star,", "MDC head Morgan Tsvangirai.", "\" policing the world and Africa in particular?\"", "future relations between the Middle East and Washington", "canyon", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school,", "strife", "Robert Langdon, a Harvard symbology expert, and conspiracy theories galore.", "Columbia Police Department.", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "Shawn then calls Juliet and proceeds to give her clues about his whereabouts", "the immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "OutKast", "Groundhog Day", "\" Cleopatra, Queen of Denial\"", "a fairground"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6124844646634073}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.06896551724137931, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.1111111111111111, 0.1111111111111111, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-10185", "mrqa_squad-validation-2429", "mrqa_squad-validation-9194", "mrqa_squad-validation-9484", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.546875, "CSR": 0.6515625, "EFR": 1.0, "Overall": 0.82578125}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "cyanobacterial", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "pelvis and sacrum -- the triangular bone within the pelvis", "issued his first military orders as leader of North Korea", "precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon", "Willem Dafoe", "Maude", "Phillip A. Myers", "general astonishment", "two weeks after Black History Month", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer", "Christopher Savoie", "Touma", "Dangjin", "e-mails", "Hu Jintao", "Christian", "it pulls the scab and it cracks, and it starts to bleed.\"", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next", "President Bush", "Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one day", "kabinett", "Lionsgate", "James Lofton", "mysticism", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.609375, "QA-F1": 0.6728219696969697}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5454545454545454, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_squad-validation-8655", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.609375, "CSR": 0.6477272727272727, "EFR": 1.0, "Overall": 0.8238636363636364}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal.", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo of Byzantium", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "Who's Who", "pink mice", "antelope", "nipples", "Precambrian period", "'helpful' businesses", "Anastasia Dobromyslova", "Lady Gaga", "9", "Blake Griffin", "radish", "Robert Ludlum", "giant grubs", "Apollo Lunar Liftoff", "the largest showcase of Grand Prix racing cars in the world", "The 1992 film \u2018 Waynes World\u2019,", "Hebrew", "London Underground", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Wyoming", "2005", "1971", "minivans", "Benny Hill", "Rome", "peplos", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Monaco", "Wales", "Can't Get You Out of My Head", "Cody Miller", "Bloomingdale Firehouse", "Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6095928773469823}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true], "QA-F1": [0.5, 0.4, 1.0, 0.2608695652173913, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.6153846153846153, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-4642", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.53125, "CSR": 0.6380208333333333, "EFR": 0.9666666666666667, "Overall": 0.8023437499999999}, {"timecode": 12, "before_eval_results": {"predictions": ["Southern Border Region", "70-50's", "Panini", "Bills", "anti-colonial movements", "glacial", "protein A", "test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "basic constitutional rights and principles (particularly democracy, the rule of law and the social state principles)", "1788", "2006", "Roman Catholic", "the Edict of Nantes", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "John Mayer", "Sue Ryder", "Don Wayne", "Virgil", "France", "T.S. Eliot", "iceland", "spy Who Loved Me", "Vladivostok", "Sheryl Crow", "satellite communication", "Camellia sinensis", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "astronomy", "gin", "George Clooney", "Eric Coates", "James Chadwick", "Beatles", "Monopoly", "champagne", "abundant rainfall", "the United States", "Brigit Forsyth", "Lord Melbourne", "\"State of Japan\"", "problem play", "Thomas Edward Lawrence,", "Kent", "Paul Durand-Ruel", "Standard Motor Company", "white", "Switzerland", "soda water", "people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "bremen", "david", "Buster Keaton"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6270013588561976}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.8387096774193548, 0.3846153846153846, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9126", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_squad-validation-3161", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_newsqa-validation-3860"], "SR": 0.578125, "CSR": 0.6334134615384616, "EFR": 0.9259259259259259, "Overall": 0.7796696937321937}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "\"it would appear to be some form of the ordinary Eastern or bubonic plague\"", "had their own militia", "days, weeks and months", "Over 61", "quality of a country's institutions", "cilia", "gravity", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "HYMENAEUS", "Zeus", "albinism", "Suez Canal", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "cuddly new pet", "The Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "reptile", "strong cold southwest wind", "table tennis", "the National Library of Medicine", "penhaligon", "Gandalf", "Sherlock Holmes", "Jinnah International", "Monday", "capital", "rosary", "soap", "liquor", "Avro Lancaster", "Genesis", "Charlie Brooker", "chamomile", "Harrods", "2007", "Christina Ricci", "Scarface", "pale yellow", "Everest", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Nook", "Steven Green", "period", "fortune", "geography", "Synchronicity"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6609375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-2875", "mrqa_squad-validation-6933", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-7177", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-5320", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.5625, "CSR": 0.6283482142857143, "EFR": 0.9642857142857143, "Overall": 0.7963169642857143}, {"timecode": 14, "before_eval_results": {"predictions": ["seven months old", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep in peace", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "they were at least partly the product of a declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "in outer space", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat", "2020", "1974", "332", "1936", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "between 2 World Trade center and 3 World Trade Center", "Kevin Spacey", "allhallowtide", "78", "white blood cell", "International Border", "President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "October 1, 2014", "the United States", "claims adjusters", "neck", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "Animals are divided by body plan", "three", "annual plants", "long", "kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "a police badge", "BBC building in Glasgow, Scotland", "a thick stack of paper"], "metric_results": {"EM": 0.5, "QA-F1": 0.6382075917741679}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.9523809523809523, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_squad-validation-2523", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-7309", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.5, "CSR": 0.6197916666666667, "EFR": 0.96875, "Overall": 0.7942708333333334}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "a special episode of The Late Late Show with James Corden", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "60", "Seattle, Washington", "Battle of Antietam", "Andy Cole and Shearer", "In Time", "2nd century", "Glenn Close", "three times", "Agostino Bassi", "The first five seasons of Prison Break have been released on DVD and Blu - ray in Regions 1, 2, and 4", "a beach in Malibu, California", "the church at Philippi", "Aernoutsz", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "Grey Wardens", "Dr. Lexie Grey", "Majandra Delfino", "September 1972", "Uruguay", "Alex Skuby", "Thomas Middleditch", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of National Intelligence", "Defence Against the Dark Arts", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal. The Man", "burt Hammersmith", "Rachel Kelly Tucker", "Bohemia", "boxelder bug", "Code 02PrettyPretty", "musician", "opposition group, also known as the \"red shirts,\"", "the abduction of minors", "Nevada", "Pablo Neruda", "Stage Stores", "1881"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6217924003080253}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.8, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.09523809523809523, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_searchqa-validation-5103"], "SR": 0.515625, "CSR": 0.61328125, "EFR": 0.9032258064516129, "Overall": 0.7582535282258065}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Vancouver", "Microsoft Office", "SAVE", "Scandinavian Airlines", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising", "45%", "more than two decades", "BAFTA TV Award Best Actor winner", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson, David Michener, and the team of John Musker and Ron Clements", "Sir William McMahon", "North Sea coast", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "the Chengdu Aircraft Corporation (CAC) of China", "Delacorte Press", "Neighbourhoods", "Secretariat", "Marcus Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Amway", "Parlophone Records", "South Africa", "Surrey", "My Sassy Girl", "Charles Russell", "Boyd Gaming", "Anthony Davis of the New Orleans Pelicans", "1970", "Glenn Close", "leontine Mary Welch", "Neighbours", "Ewan McGregor", "2011", "Robert Browning", "an enslaved African American who led", "expanding U.S. sanctions against Zimbabwe", "Brown-Waite"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6809625270562771}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.9090909090909091, 0.3636363636363636, 0.3636363636363636, 1.0, 0.4, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-955", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.5625, "CSR": 0.6102941176470589, "EFR": 1.0, "Overall": 0.8051470588235294}, {"timecode": 17, "before_eval_results": {"predictions": ["force of gravity acting on the object balanced by a force applied by the \"spring reaction force\"", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "inner chloroplast membrane", "Charlie Sheen", "Little Stevie Wonder", "beaver", "La Boh\u00e8me Giacomo Puccini", "red itchy swelling, a burning or stinging sensation, itchy white bruises, and, in some cases, a severe allergic reaction that leads to diarrhea, cramps and wheezing", "Talavera de la Reina", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "sighthounds", "Plato", "London Pride", "a reference mark", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "Lagertha", "weight plates", "\"big house\"", "Hadrian", "US", "human flea", "Los Angeles, London, Sydney, Switzerland", "Essen", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Robert Crombie", "Jessica Simpson", "Boy George", "Finland", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "It was a Confederate victory", "New Jewel Movement", "40 million years ago", "U.S. 93", "Anjuna beach in Goa", "Marius Ivanovich", "Oshkosh", "two", "\"The World\"", "\"The Sunday Thing\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5586397058823529}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10351", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-3132", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5052", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.46875, "CSR": 0.6024305555555556, "EFR": 0.9411764705882353, "Overall": 0.7718035130718954}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "The Hustons", "Matt L. Jones", "Mediterranean Sea", "inability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Alison", "1993", "775 rooms", "Destiny's Child", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "2 September 1990", "Coton", "4 ( 40 -- 54 % )", "Zoe Badwi", "1995", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "aortic valve", "July 21, 1861", "Dr. Addison Montgomery", "state or other organizational body", "empty line", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "a violation of nature", "September 2017", "moral", "Rising Sun Blues", "Part 2", "Dumbo", "the failure of the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "mentor", "Tom Hanks", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6503199468193075}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.19999999999999998, 1.0, 0.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.08695652173913042, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-3232", "mrqa_hotpotqa-validation-4735"], "SR": 0.5625, "CSR": 0.600328947368421, "EFR": 0.9642857142857143, "Overall": 0.7823073308270676}, {"timecode": 19, "before_eval_results": {"predictions": ["the law as the Holy Spirit's tool to work sorrow over sin in man's heart, thus preparing him for Christ's fulfillment of the law offered in the gospel", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "Barack Obama", "the girl who disappeared in February, plans to file for divorce from the girl's stepmother,", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "any resources that could be found there", "Tuesday in Los Angeles.", "forgery and flying without a valid license", "Anil Kapoor", "19", "President Obama", "the city's reputation for glamour and hedonism came with a side order of carjackings and gangland shootouts", "The Louvre", "snowstorm", "exotic sports cars", "a dad.", "Moammar Gadhafi", "Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18,", "\"Steamboat Bill, Jr.\" (Charles Reisner, 1928)", "Russia", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "the banned substance cortisone", "\u00a341.1 million", "Kingman Regional Medical Center", "Laura Ling and Euna Lee", "Manmohan Singh's Congress party", "Michael Jackson", "to go the White Palace and show him to come to Pakistan and control it because he is a super power.\"", "40 militants and six Pakistan soldiers dead", "World number two Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Lousiana", "the Southeast", "jenkins", "Nancy Sutley", "her son has strong values.", "the infant who became the center of an international end-of-life debate, died peacefully in his sleep at his Windsor, Ontario, home,", "back at work", "the initial necropsy or animal autopsy", "27", "Corbin Bleu and Karina Smirnoff", "John Adams", "cabbage", "Zager and Evans", "Robert Matthew Hurley", "fourth term", "obscenity", "(Oliver) Cromwell", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5479452838827839}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333336, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.5, 0.33333333333333337, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.5, 0.0, 1.0, 0.5714285714285715, 0.6666666666666666, 0.6666666666666666, 0.0, 0.923076923076923, 0.33333333333333337, 0.8333333333333333, 1.0, 1.0, 0.0, 0.0, 0.7692307692307693, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.40625, "CSR": 0.590625, "EFR": 0.9473684210526315, "Overall": 0.7689967105263158}, {"timecode": 20, "before_eval_results": {"predictions": ["19th", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "fabric", "three empty vodka bottles,", "training Afghan police and troops,", "Bobby Darin,", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "she was humiliated by last month's incident,", "composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's development of a nuclear weapon", "12 shades of violet, including a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, soothing near-black on red-eyes when it's time to sleep.", "using recreational drugs", "ceo Herbert Hainer", "Brett Cummins,", "children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "\"E! News\"", "Sudanese nor orphans", "jobs", "saying Tuesday the reality he has seen is \"terrifying.\"", "Khalid Sheikh Mohammed, seen in a December sketch, was waterboarded 183 times in a month, a memo says.", "Mexican's attorney general's office", "Republicans", "saving and planning for retirement", "An undated photo of Alexandros Grigoropoulos,", "deciding the duties of the new prime minister has been a sticking point in the negotiations.", "a 57-year old male", "Kim Jong Il seems to be \"testing the new administration.\"", "Angola", "Gary Brooker", "the creation of an Islamic emirate in Gaza,", "boogeyman Jason Voorhees", "The United States had been seeking the death penalty against al-Qahtani, and he was held in isolation until April 2003,", "Sea World in San Antonio", "avid Washington Redskins fan and loved to travel,", "about 50", "Ku Klux Klan", "MGM prohibited the release until The Wizard of Oz ( 1939 ) had opened", "Branford College", "Bury", "stamens", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "mice followed, in the '80s | clone.", "Hodel", "gives them access to US courts", "Coldplay"], "metric_results": {"EM": 0.375, "QA-F1": 0.5019445686187516}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 0.0, 0.0, 1.0, 0.9523809523809523, 0.6, 0.25, 0.23076923076923078, 0.8, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.05714285714285715, 0.0, 1.0, 0.15384615384615385, 0.22222222222222224, 1.0, 0.0, 0.10526315789473685, 1.0, 1.0, 0.0, 0.0, 0.06451612903225808, 0.0, 0.9333333333333333, 0.6666666666666666, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.33333333333333337, 1.0, 0.1818181818181818, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-10284", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.375, "CSR": 0.5803571428571428, "EFR": 0.95, "Overall": 0.7651785714285714}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "Russia, France, and also Poland,", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "both shoulders", "Madonna's", "Glasgow", "latitude and longitude coordinates", "Australia", "giblet", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Ness", "Roman Catholic", "New South Wales", "a gentle cat with a somewhat shy nature around strangers.", "Taiwan", "Harrisburg", "mustela erminea,", "percussion", "Dr John Sentamu", "rochoon", "Pongo", "Anne Boleyn", "Pye", "Holly Johnson", "Emma Chambers", "charlemagne", "the community", "Russell Crowe", "Theodore Roosevelt", "rochina", "Puck", "Senoj Nosnibor", "chamaemelum nobile", "England", "tarn", "SS Constitution", "Albert Square", "Newbury", "the Old Testament", "70 million people", "Target Corporation", "\"The Omega Man\"", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "international NGO", "M. Jeff Thompson", "the proceeds from sales go to organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.546875, "QA-F1": 0.5807291666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-6408", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-3569", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.546875, "CSR": 0.5788352272727273, "EFR": 0.9655172413793104, "Overall": 0.7721762343260188}, {"timecode": 22, "before_eval_results": {"predictions": ["The flushing action of tears and urine", "1765", "primarily along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials", "Vicodin,", "Christianity", "Robert Peary", "pearl", "Utah Territory", "Carrie Underwood", "liqueur Drambuie", "he made his horse a consul, his palace a brothel, and his", "Google", "Langston Hughes", "pain tolerance", "samuel chagall", "mambo dance", "lariat", "new landscape", "USS lST Ship", "prey drive", "David Beckham", "arturo Toscanini", "economics", "Miracle in the Andes: 72 Days on the Mountain and My Long Trek", "lyceum", "Montenegro", "discus", "plab", "basidiomycota", "james", "norma thorne-Smith", "Idi Amin", "jedoublen/jeopardy", "a body, body part, or personal object", "terracotta", "Plutarch", "president of New York City", "masa harina", "40 seconds", "the Vikings.", "fairfield Street", "champs-Elysees", "typhoid fever", "fjord", "tourism", "Williamsburg", "telegraph", "University of Missouri-St. Louis", "hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off", "jen Knox", "the internal reproductive anatomy", "$612.4 million in North America and $1.528 billion in other countries", "risk factors for disease and targets for preventive healthcare", "jape", "Tesco", "Mallard", "Bruce McLaren", "the Battelle Energy Alliance.", "IT", "debris", "$10 billion", "Bailey, Colorado,"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4518582112332112}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.5, 0.15384615384615385, 0.14285714285714285, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6437", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_searchqa-validation-16854", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-68", "mrqa_newsqa-validation-1997"], "SR": 0.359375, "CSR": 0.5692934782608696, "EFR": 0.9024390243902439, "Overall": 0.7358662513255567}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "Atlantic Ocean", "domestic cat in America,", "daughter", "Basel, Switzerland", "The Argonauts", "prometheus", "Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "multi-user dungeon", "Italy", "khaki", "magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "Mendip", "Barack Obama,", "the Earth", "Nafea Faa Ipoipo", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "Air traffic control, Air-defense systems, and Antimissile systems", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "a cyclone's center", "Fife", "radio", "Adidas", "Snarked", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "\"White\" and \"Black\"", "flour and water", "Ross Elliott", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7685355392156863}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3164", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848"], "SR": 0.703125, "CSR": 0.5748697916666667, "EFR": 1.0, "Overall": 0.7874348958333334}, {"timecode": 24, "before_eval_results": {"predictions": ["illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "the chosen machine model", "20th Century Fox", "1997", "a suite of network protocols", "Noriko Savoie", "11 to 12", "nine-wicket", "the Korean peninsula", "he was led away in handcuffs after being sentenced in a New Jersey court for fatally shooting a limo driver on February 14, 2002.", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Jason Chaffetz", "money or other discreet aid for the effort", "Sarah,", "illegal crossings", "environmental", "rooland Varga and Janos Szabo", "Afghan police", "Saturday", "38", "70,000 or so", "Climatecare,", "\"E! News\"", "coach", "Steve Williams", "fast-food chain", "recite her poetry", "Pastor Paula White", "2008", "Diego Maradona", "Dog patch Labs Europe", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Liza Murphy,", "the hiring record of minorities", "Samson D'Souza, 29,", "former U.S. secretary of state.", "At least 33", "five", "improve health and beauty.", "contraband", "campus patrols", "Alwin Landry's", "Krishna Rajaram,", "Sunday", "killing", "an Irish feminine name", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Dublin", "radio", "art", "the 16th season", "23", "South America", "freestyle", "the Nightingale Museum", "the Crystal Skull"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5219751602564102}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.6153846153846153, 0.5, 0.0, 0.0, 0.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.3333333333333333, 0.2666666666666667, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.11111111111111112, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.4444444444444445]}}, "before_error_ids": ["mrqa_squad-validation-6846", "mrqa_squad-validation-610", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-2954", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.390625, "CSR": 0.5675, "EFR": 1.0, "Overall": 0.78375}, {"timecode": 25, "before_eval_results": {"predictions": ["The programme is listed in Guinness World Records as the longest-running science fiction show in the world,", "Thomas Savery", "Vicodin", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "separatist", "Eleven", "269,000", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "off the north coast of Puerto Rico.", "Russian air force", "34", "The eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "customers", "Tom Baer", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "bikinis", "Brian Mabry", "changed the way for gamers to be able to engage in their favorite past time via handheld devices", "Sunday.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "Some truly mind-blowing structures are being planned for the Middle East.", "a passenger's name", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego,", "women who were working as prostitutes", "A family friend of a U.S. soldier captured by the Taliban said his friends and family want Pfc. Bowe Bergdahl to \"stand tall, stand firm.\"", "Twitter", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "National Police", "heart", "Hyderabad", "Asia", "to stay, abide", "Las Vegas", "Jackson Pollock", "wye", "Louisiana", "January 19, 1943", "King Duncan", "Georgia", "thimble", "taking a walk"], "metric_results": {"EM": 0.40625, "QA-F1": 0.49040357213127145}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.8750000000000001, 1.0, 0.6666666666666666, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.29411764705882354, 0.4444444444444445, 1.0, 0.0, 0.07407407407407408, 0.6666666666666666, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-11832", "mrqa_searchqa-validation-9476"], "SR": 0.40625, "CSR": 0.5612980769230769, "EFR": 0.9736842105263158, "Overall": 0.7674911437246963}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "their phycobilisomes", "Off-Off Campus", "clerical", "\"The military fired warning shots into the air and sprayed water cannons to disperse the crowd.", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "six", "legitimacy of that race.", "celebrity pontificating about the plight of the environment", "three", "Monday", "Scarlett Keeling", "two years", "nearly 28 years", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "in July", "Akshay Kumar", "Graham's wife", "collaborating with the Colombian government,", "\"disagreements\" with the Port Authority of New York and New Jersey,", "September,", "Michelle Rounds", "James Newell Osterberg", "strangulation and asphyxiation and had two broken bones in his neck,", "Lana Clarkson", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "\"People of Palestine\"", "dependable Camry", "raping her", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "Mohammed Mohsen Zayed,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "\"Don't Ask, Don't Tell.\"", "fallen comrades lost in the heat of battle", "barter -- trading goods and services without exchanging money", "semi-autonomous organisational units", "one", "Bongos", "Jack Frost", "the innermost digit of the forelimb", "1988", "25 million", "Peoria, Illinois", "Hawaii", "shallow water near the bottom, as deep as 477 m but typically 75-150 m;", "KingLear", "Ottoman Empire"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6339434523809524}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.1714285714285714, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-2195", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.546875, "CSR": 0.5607638888888888, "EFR": 1.0, "Overall": 0.7803819444444444}, {"timecode": 27, "before_eval_results": {"predictions": ["in the early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "bank robber John Dillinger,", "what caused the collapse of the building which contained the city's historical archives,", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "eight Indian army troopers, including one officer, and 17 militants,", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "in a Starbucks", "BADBUL", "98 people,", "2008", "near the Somali coast", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Swat Valley", "South Dakota State Penitentiary", "Iran", "last month", "will be at the front of the line, self-righteously driving under the speed limit on his or her way to save the world.", "in July", "three international aid agencies", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death", "Scardia", "fractured pelvis and sacrum", "Wednesday", "abduction of minors.", "gun", "Jeanne Tripplehorn", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "wheat", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "Missouri", "video", "beta blockers"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7560966033487586}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5333333333333333, 0.3636363636363636, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.06896551724137931, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4094", "mrqa_newsqa-validation-4138", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-436", "mrqa_triviaqa-validation-3389", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-14535"], "SR": 0.609375, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "technological superiority", "1981", "forgery and flying without a valid license,", "a racially-tinged remark made by his former caddy,", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "Genocide Prevention Task Force.", "shoot down the satellite", "semiconductors", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault", "the shipping industry -- responsible for 5% of global greenhouse gas emissions,", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "\"The Rosie Show,\"", "Form Design Center.", "\"executed\" eight people on February 6 in the town of Rio Bravo because the Indians were gathering information about the rebels to give to the Colombian military.", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "one day,", "executive director of the Americas Division of Human Rights Watch,", "750", "nearly 100", "Matthew Fisher,", "The Ski Train", "Boys And Girls alone", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators", "inconclusive", "5:20 p.m. at Terminal C", "environmental and political events.", "$250,000", "100% of its byproducts", "School-age girls", "5,600", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "legislation that would let prisons jam cell-phone signals within their walls.", "a deceased organ donor,", "bragging about his sex life on television", "a vertebral column ( spine )", "January to May 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "Hugh Casson", "a self-referential time-related adage, coined by Douglas Hofstadter", "\"The Dark Tower\"", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain in the Civil War", "Castle Rock", "fish"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7247918823326432}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 0.0, 1.0, 0.8, 0.0, 1.0, 0.8, 1.0, 1.0, 0.6857142857142856, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3253", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.640625, "CSR": 0.5651939655172413, "EFR": 1.0, "Overall": 0.7825969827586207}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure", "his brother Kusala,", "438,000", "Marty Ingels", "coaxial", "Pakistani", "Everbank Field", "7 members appointed by the chief executive", "Battle of Dresden", "Arabella Churchill", "1965", "Charles de Gaulle Airport", "Championnat National 3", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1963", "coca wine", "puzzle video", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos giant rat,", "Tom Kartsotis", "2017", "Wayman Tisdale", "Mexico", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey", "Apalachees", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "into a field in Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Diploma Program", "Richard Parker", "off the southernmost tip of the South American mainland", "Charlton Heston", "allergic reaction", "Peter Townsend,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia,", "peel and devein shrimp", "Australia"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6903016254578755}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_squad-validation-8164", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4048", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.609375, "CSR": 0.5666666666666667, "EFR": 0.88, "Overall": 0.7233333333333334}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "effects of deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a cooperative where farmers pool their resources in certain areas of activity", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Dirk Werner Nowitzki", "lifetime", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E", "New Jersey", "Norse mythology", "86,112", "Celtic", "Ouse and Foss", "Springfield, Massachusetts", "British comedian", "\"Apatosaurus\"", "29 September 1888 \u2013 20 May 1937", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "New York City", "The Seduction of Hillary Rodham", "2005", "Lambic", "Ubisoft", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "veto power", "Joseph E. Grosberg", "Chelsea Does", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "New York", "Olympic Games", "Aston Park", "2005", "228", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Chief Joseph"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6768924825174825}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4446", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-3926", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905"], "SR": 0.5625, "CSR": 0.5665322580645161, "EFR": 1.0, "Overall": 0.783266129032258}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "lveldi sland", "Wyoming", "a huge terrestrial globe", "georgia park", "Campaign Finance/Money", "A People's History of the United States", "capital of The Bahamas", "a gemstone formed by the nacreous inner shell", "AIDS", "Thomas Beekman", "trains a grande vitesse", "geuseppe verdi", "termites", "capital of China", "georgia state", "georgia state", "georgia state", "Yves Saint Laurent", "multiple sexes grow antlers", "a college student at Wittenberg", "the War of 1812", "georgia moses", "georgia", "a parade", "georgia state", "Asiatic", "a flurry", "Gilson Lavis", "georgia", "a polarized electron source", "(Milton) Berle", "george herbert walker bush", "a Congolese independence leader", "flight simulation", "georgia", "Dan Marino", "Mars", "clownfish", "E = mc2", "Guru Pitka", "Las Vegas", "millet", "a butterfly", "heavy drinking", "orangutan", "Ohio State's (OSU) campus cable network", "soothsayer warning Julius Caesar", "an Israeli ultranationalist", "David Spares Saul's", "Gettysburg National Military Park", "Jack Gleeson", "thirteen", "Buddhist missionaries", "Count Carl Johan", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "\"has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "knocking the World Cup off the front pages for the first time in days.", "12.3 million people worldwide"], "metric_results": {"EM": 0.234375, "QA-F1": 0.2989955357142857}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-567", "mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-14507", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-1768", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-3856", "mrqa_searchqa-validation-11913", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-4159", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-7151", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-4905", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-13033", "mrqa_naturalquestions-validation-5896", "mrqa_naturalquestions-validation-5808", "mrqa_triviaqa-validation-3265", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.234375, "CSR": 0.55615234375, "EFR": 0.9183673469387755, "Overall": 0.7372598453443877}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Henry Addington", "40", "Libya", "Shania Twain", "Hillsborough", "glucagon", "New York Yankees", "rapid eye movement", "green", "Ann Dunham", "Ba'ath Party", "French", "Jim Branning (John Bardon)", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New Years Day", "Prince Andrew and Sarah Ferguson", "Mercury", "watt", "Jack Douglas", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "S\u00e3o Paulo", "optimism", "aged 75 or older", "Jennifer Lopez", "1664", "Annie Lennox", "Fred Perry", "Downton Abbey", "Martina Hingis", "septs", "Cyclops", "The Woodentops", "Michael Miles", "shirley Bassey", "gulliver's Travels", "Pomona", "Milan", "Mike Skinner", "Appalachian Trail", "a black Ferrari", "Variable", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone.", "providing safety and physical security,", "a Spanish ballet dancer", "Helvetica", "lung"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5568452380952381}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6656", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-16567"], "SR": 0.484375, "CSR": 0.5539772727272727, "EFR": 0.9393939393939394, "Overall": 0.7466856060606061}, {"timecode": 33, "before_eval_results": {"predictions": ["hymns", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "hay fever,", "jesuit mrs Churchill", "getafix", "Brighton", "Belfast", "wind", "fire insurance", "Robin Hood's A Holy Grail", "West Point", "Andy Warhol", "La Mancha", "John Cable", "rykjavik", "the solar system", "potatoes", "Moldova", "Mitsubishi A6M Zero Fighter", "warblers", "George Sand", "Estimate", "baroudeur", "clon", "pet Sounds", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Manila", "beaver", "Mel Blanc", "leopard", "Moffitt", "stanese", "phil Woolas", "5000 meters", "horse racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone National Park", "St. Francis Xavier", "luzon", "Hugh Laurie", "Buddhism", "Will Champion", "Ohio", "Port Melbourne", "Osbald", "Scarface", "forgery and flying without a valid license", "Shetha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory", "Liza Murphy,", "Spock", "Kazakhstan", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.64375}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2399", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-11382"], "SR": 0.609375, "CSR": 0.5556066176470589, "EFR": 0.96, "Overall": 0.7578033088235294}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "prairies", "Bologna, Italy", "George Santayana", "marsupials", "Alice Cooper", "heart failure", "trumpet", "Marc Warren", "a person cluting their face, screaming in anguish alone on a dock.", "shildon", "appalachian mountain range", "roll-on roll-off", "ballet", "epic disasters", "george rejects", "lizards", "Blackburn Lancashire", "man Without a Star", "The Mystery of Edwin Drood", "pommel horse", "birds", "Dick Van Dyke", "Egremont", "manhunt", "Diego Velazquez", "phrixus", "Basil Feldman", "Canada", "ink sac", "Pears soap", "Some Like It Hot", "Mull", "Ireland", "robbie creynberg", "sea horse", "plutonium", "magma", "Passepartout", "welcome", "Czechoslovakia", "Estonia", "shrek", "26.22", "Cleveland Brown", "Heston Blumenthal", "One Direction", "spain", "Jupiter", "Stringer", "Charles Lindbergh", "September 2001", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "an older generation", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5140625}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-3837", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-78"], "SR": 0.453125, "CSR": 0.5526785714285714, "EFR": 1.0, "Overall": 0.7763392857142857}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "Matlock", "American Civil War", "shoa", "cetaceans", "Arafura Sea", "labyrinth", "the Euphrates River", "czech republic", "to plow", "Spain", "carousel", "bullfighting", "smith brady", "countertenor", "cats", "fidelio", "Guys and Dolls", "jean Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "indiopia", "eddisbury", "G. Ramon", "jean fonda", "rachmaninoff", "Finland", "stars", "Mille Miglia", "spadefoot", "blackboard jungle", "50p", "Muriel Spark", "happy birthday", "seven", "opossum", "pickwick", "presliced bread", "Saga Noren", "raven", "jean", "soybeans", "kings and blurred bus", "Etruscan", "Ken Burns", "jean park", "gelding", "Pyotr Tchaikovsky", "Sheikh Mujib", "saturn", "Donna", "season four", "the atrioventricular node", "yeeun", "tomato", "2002", "problems with the way Britain implements European Union employment directives.", "l'Aquila earthquake", "March 24,", "duke anlam", "equinox", "Pocahontas"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5546875}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-3021", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-4758", "mrqa_naturalquestions-validation-1091", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.484375, "CSR": 0.55078125, "EFR": 0.9393939393939394, "Overall": 0.7450875946969697}, {"timecode": 36, "before_eval_results": {"predictions": ["the Iranian Islamic Revolution", "kim", "city of acacias", "branson", "Gordon Ramsay", "luton Town", "jon jon smith", "sulfur dioxide and nitrogen oxides", "Margot", "ringway airport", "Portuguese", "travelocity", "The Avengers", "thirsk", "ethiopia", "sounds of silence", "a ghost", "rapeseed", "bartertown", "stanford", "th Strasbourg, Alsace, France", "Bolivia", "jen donne", "Uranus", "Rio Grande", "clowns", "Midnight Cowboy", "ethiopia", "jane crawford", "king james I", "One Foot in the Grave", "Bronx", "peter evison", "George Santayana", "stalls", "borowdale", "crackerjack", "julian torquemada", "julian finzi", "Canada", "rum", "lake Union", "ghee", "George III", "edan boy band one Direction", "hyperbole", "oldpatricktoe", "June", "jeff Tracy", "Ceylon", "screwdrivers", "the Kansas City Chiefs", "G minor", "My Summer Story", "1974", "Nightmares", "Amberley Village", "lack of a cause of death", "Canadian Prime Minister Stephen Harper", "her mother,", "cixi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4671875}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9574", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-4817", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-2834", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_hotpotqa-validation-5545", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-12", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.40625, "CSR": 0.546875, "EFR": 0.9736842105263158, "Overall": 0.760279605263158}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "roofs of the choir side", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist Charles Lyell", "Dakar", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "London, England", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "freehold easements", "Joe Lo Truglio", "cell nucleus", "Anakin and Obi - Wan", "Travis Tritt and Marty Stuart", "1976", "Barry and Robin Gibb", "Matt Czuchry", "Pradyumna", "1902", "On the west", "Psychomachia", "New Jersey Devils", "two", "7.6 mm", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Lisa Stelly", "Canadian Rockies continental divide east to central Saskatchewan", "The Maginot Line", "Prussia", "dumbo", "purple rain", "Charles Guiteau", "Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "cannonball run", "chilpancingo", "Tuesday"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6649150705876249}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.25, 0.5454545454545454, 1.0, 0.0, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-8514", "mrqa_hotpotqa-validation-5119", "mrqa_searchqa-validation-2335"], "SR": 0.5625, "CSR": 0.5472861842105263, "EFR": 0.9642857142857143, "Overall": 0.7557859492481203}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in positions 14 - 15, 146 - 147 and 148 - 149", "Joseph M. Scriven", "Lady Gaga", "Chicago metropolitan area", "the president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County", "nobiliary particle", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma `` man ''", "Pakistan", "21 February", "Tagalog or English", "Bryan Cranston", "thylakoid membranes", "low mood", "Felix Baumgartner", "it lies just north of the state capital, Raleigh", "December 1922", "less than ten seconds remaining", "602", "stable, non-radioactive rubidium - 85", "between $10,000 and $30,000", "R2E Micral CCMC", "1931", "University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The `` Southern Cause ''", "Randy", "that country's surprise attack on Pearl Harbor the prior day", "Joseph Stalin", "into the intermembrane space", "divergent tectonic", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "mrs John Major", "roddy doddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "overhaul domestic policies", "10 below", "Henry Ford", "david McCullough", "Rendezvous with Rama", "CERN", "paulho"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6384803612280392}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.21052631578947367, 1.0, 0.761904761904762, 0.0, 0.0, 1.0, 0.6666666666666666, 0.32, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.515625, "CSR": 0.546474358974359, "EFR": 0.9032258064516129, "Overall": 0.724850082712986}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "active osmotic water absorption", "Philippe Petit", "R2E Micral CCMC", "January 2004", "southwest and along the Yangtze ; it is planted in March to June and harvested in October and November", "Toby Keith", "wide area networking", "17 - year - old", "alternative rock", "Set six months after Kratos killed his wife and child, he has been imprisoned by the three Furies for breaking his blood oath to Ares", "the Beldam / Other Mother, the ruler of the Other World", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "A 30 - something man ( XXXX )", "Gestalt psychology", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Stefanie Scott", "Richard Crispin Armitage", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "diffuse nebulae", "effectively overturned the Plessy v. Ferguson decision of 1896, which allowed state - sponsored segregation, insofar as it applied to public education", "McKim Marriott", "John F. Kelly,", "Charles Sherrington", "1890", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Kerry Shale as Tadheus `` Tad '' Stone", "Mark Jackson", "Michael Buffer", "`` There is one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and through all and", "on location", "The federal government received only those powers which the colonies had recognized as belonging to king and parliament", "1958", "Cody Fern", "questions about the name of the war, the tariff", "prophets and beloved religious leaders", "4.5", "Juan Manuel de Ayala", "Joseph Smith,", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "\"Me and Bobby McGee\"", "Squalus acanthias", "The Jungle", "ABBA"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5913214899887694}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.19047619047619047, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.3076923076923077, 0.17142857142857143, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.10909090909090907, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-10341", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-4731"], "SR": 0.46875, "CSR": 0.54453125, "EFR": 0.9411764705882353, "Overall": 0.7428538602941177}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants", "Joan Rivers", "early detection", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "one American diplomat to a \"prostitute\"", "since 2004", "NATO", "Switzerland", "Monday", "second", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "spending billions to revitalize the nation's economy,", "T.I.", "Oaxaca, Arizona", "Robert Barnett", "$627", "41", "Nick Adenhart", "a strict interpretation of the law", "Derek Mears", "Sylt", "rural Tennessee", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats", "dual nationality", "Section 60", "Ali Bongo", "the Transportation Security Administration", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "A Brazilian supreme court judge", "Derek Mears", "Operation Crank Call", "help rebuild the nation's highways, bridges and other public-use facilities", "East Java", "St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "location in Mexico", "Snickers", "monoceros", "phycombe", "Anaheim, California", "uncle", "Bergen", "embalming", "Cartagena", "graphical", "UK Kennel Clubs"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6996633512448265}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.08, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.5714285714285715, 1.0, 1.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 1.0, 0.9411764705882353, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_naturalquestions-validation-10583"], "SR": 0.53125, "CSR": 0.5442073170731707, "EFR": 0.9666666666666667, "Overall": 0.7554369918699186}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1997", "positive, zero, or negative scalar quantity", "layered systems of sovereignty", "Megan Park", "the formal currency of the European Union", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "The pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "international aid", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "In England, births were initially registered with churches, who maintained registers of births", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "to collect menstrual flow", "pigs", "General George Washington", "Spanish", "Howard Ellsworth Rollins Jr", "an integral membrane protein that builds up a proton gradient across a biological membrane", "through the right atrium to the atrioventricular node, along the Bundle of His and through bundle branches", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements )", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Intertropical Convergence Zone ( ITCZ )", "Missouri River", "the right to be served in facilities which are open to the public", "the frontal lobe", "10 June 1940", "at Tandi, in Lahaul", "Alberich", "the middle ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "September 21.", "Denver, Colorado.", "Provincial Reconstruction Team for the Sadr City and Adhamiya districts of Baghdad City,\"", "the United States", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.53125, "QA-F1": 0.66851620856676}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 0.8235294117647058, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-5368", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2387", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.53125, "CSR": 0.5438988095238095, "EFR": 0.9, "Overall": 0.7219494047619048}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water", "Middlesex County, Province of Massachusetts Bay", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Alexander Graham Bell's Volta Laboratory", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea to The south", "to bring", "Field Marshal Paul von Hindenburg", "Ceramic", "the Soviet Union", "Covington, Kentucky", "New Mexico", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption", "December 15, 2017", "on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive", "L.K. Advani", "differential erosion", "Glenn Close", "the long form in the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "Puerto Rico Electric Power Authority ( PREPA )", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "the Northeast Monsoon", "March 16, 2018", "Joan Baez", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "asexually", "1926", "Beijing", "starting in 1560s", "Dewey ( Erik Per Sullivan )", "Leon Huff", "between 1765 and 1783", "Vanaheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two", "prostate cancer,", "wyvern", "Lord Fauntleroy", "a waistcoat", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6161365978444466}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.4799999999999999, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.09090909090909093, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.9767441860465117, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-5371", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.5421511627906976, "EFR": 0.9411764705882353, "Overall": 0.7416638166894665}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "February 27, 2007", "Luke's in the Boo, Playback Recording Studio and Secret Garden Studios", "to provide jobs for young men", "Lynne", "2013", "as the arms of the king of Ireland", "Miami Heat", "1982", "After World War I", "October 1927", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Brutus", "\u00e9douard Manet", "Virgil Ogletree", "Edward Kenway ( Matt Ryan )", "Haliaeetus ( sea eagles )", "rootlets", "Alex Ryan", "a habitat", "2018", "Windows Media Video ( WMV )", "100 members", "Toledo", "embryo", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "in Paradise, Nevada", "Alicia Vikander as Lara Croft,", "late January or early February", "Ashoka", "the compartments were intended to safeguard the King's Chamber from the possibility of a roof collapsing under the weight of stone above the Chamber", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority", "Bumblebee", "into the Christian biblical canon", "New England", "AMX - 30", "honey bees", "Mary Chapin Carpenter", "on permanent display at the Louvre Museum in Paris", "over two days in July 2011", "February 7, 2018", "Florida", "American comedy web television series", "Puerto Rico ( Rich Port )", "considered to be unfair", "summer", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bon auto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"peregruzka\"", "Michigan", "acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.453125, "QA-F1": 0.579709145021645}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.0, 1.0, 0.5000000000000001, 1.0, 0.0909090909090909, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.32, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.09523809523809525, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977", "mrqa_searchqa-validation-13337"], "SR": 0.453125, "CSR": 0.5401278409090908, "EFR": 1.0, "Overall": 0.7700639204545454}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Laurel, Mississippi", "about the outdoors, especially mountain-climbing.", "Indianola", "Escorts Limited, an engineering company that manufacture agricultural machinery, machine construction and material handling equipment and railway equipment", "the British military", "1992", "Cher", "northwestern Georgia", "Jim Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Leucippus", "Caesars Entertainment Corporation", "Terrence \"Uncle Terry\" Richardson", "Reinhard Heydrich", "Karl Kraus", "Brock Hart", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Marvin Hamlisch", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa, Florida", "outKast", "Richard Street", "Zaire", "the Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer", "South America", "2006", "perjury", "Operation Overlord", "a blind girl named Selina D'Arcy, opposite Sidney Poitier", "over 9,000 employees", "Rosalind Bailey", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "tab", "Kent", "almost 9 million", "Bahrain", "2008", "small.", "Moses", "Their", "Wilson Pickett"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6467948717948718}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.8, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1020", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.546875, "CSR": 0.5402777777777779, "EFR": 1.0, "Overall": 0.7701388888888889}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "the power to regulate interstate commerce", "Naomi Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "future AC/DC founders Angus Young and Malcolm Young", "GmbH", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sullenberger III", "(V-GLASS) system", "Pacific War", "Romantic", "Hugh Dowding", "AMC Theatres", "New York Islanders", "fennec", "1978", "John Surtees", "French", "Pacific Place", "the Matildas", "\"Bad Blood\"", "Rudebox", "the E22", "Giuseppe Verdi", "Engirundho Vandhaal", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faisal Qureshi", "the British Army", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Frances Ethel Gumm", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "\"This Love\"", "Saudi Arabia", "Bob Turner", "two"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6126927759740259}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.09090909090909091, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-6575", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-8327", "mrqa_searchqa-validation-2897"], "SR": 0.546875, "CSR": 0.5404211956521738, "EFR": 1.0, "Overall": 0.7702105978260869}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland shark", "The Word", "Abraham Lincoln", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "the death penalty statutes", "xerophyte", "Jackie Robinson", "Manhattan", "Dian Fossey (Sigourney Weaver)", "MI5", "Harrow-on-the-Hill", "creme anglaise", "ice cream", "pork", "curling", "Victoria Coren", "Gettysburg", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "Barack Obama", "Canada", "a personalized all-access pass", "Dominican Republic", "Iggy Pop", "Stephen King", "Hinduism", "caryatid", "feet", "Florida", "Mary Poppins", "Glyn Jones", "Port Moresby Harbour", "Connecticut", "Quentin Blake", "whooping cough", "The Daily Herald", "(1939\u20131945)", "\"permissible\"", "2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1944", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia", "death", "Flopsy & Mopsy", "Dan Eggen and Elizabeth Williamson", "How to Keep Young Mentally", "\"Divide the living child in two, and give half to the other\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6026041666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-7647", "mrqa_triviaqa-validation-6978", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1660", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.515625, "CSR": 0.5398936170212766, "EFR": 1.0, "Overall": 0.7699468085106382}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "dave goya", "Culloden", "Runic", "estoril", "cricket", "Planck", "rotherham United", "heat transfer", "Misery", "Styal", "olukord", "blind beggar", "Mr Brainwash", "l Leroy Burrell", "parlophone", "Wild Atlantic Way", "john Denver", "ankh-Morpork", "noddy go to Toyland", "Lackawanna six", "Brazil", "horseshoes", "muezzin", "a window", "a ship", "madame bovary", "Apollo 11", "Cellophane", "Nikola Tesla", "Nicky hart", "Evita", "an albino sperm whale", "Randy Turpin", "east fife", "st Pancras International Station", "social environment", "sliced bread", "dilbert", "mayor of casterbridge", "nunc dimittis", "French", "medea", "Burgundy", "cribbage", "The Beatles", "Johannesburg", "Paris", "muffin man", "South Korea", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas, to Veracruz, Mexico,", "if the airline doesn't perform, the credit card company still has your money and can give it right back to you.", "Robert Frost", "King Henry VIII", "o Kaiser", "Mitsubishi Eclipse"], "metric_results": {"EM": 0.625, "QA-F1": 0.6729910714285715}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-2610", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.625, "CSR": 0.5416666666666667, "EFR": 1.0, "Overall": 0.7708333333333334}, {"timecode": 48, "before_eval_results": {"predictions": ["Route sixty-six", "sesame street", "chicken", "cabbage", "australian", "jimmy bolt", "emma", "Ash tree", "opossum", "New Zealand", "jug band", "100", "goldfinger", "1983", "pike", "Genghis Khan", "1875", "tax collector", "pennies", "marmara", "Wars of the Roses", "bagram", "jimmy lemmie", "Chrysler", "ushanka", "korky the cat", "Sacred Theology", "United States", "Brazil", "pei Tang", "biathlon", "Idaho Falls", "Charlie Chan", "Vienna", "white", "jaws", "paul Rudd", "rabbit", "Scottish flag", "jimmy Leadbetter", "Orson Welles", "Sanskrit", "menorah", "post-impressionist", "Texas", "Super Bowl Sunday", "a rudder", "Little Tommy Stout", "marmole king", "azalea", "Ireland", "Chuck Noland", "Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park, Kenya", "2010", "Vancouver, British Columbia,", "10 below", "Nearly all", "coins", "the American Kennel Club", "Omaha", "jimmy jedoublen/jeopardy"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5477430555555556}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-263", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_hotpotqa-validation-2352", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.484375, "CSR": 0.5404974489795918, "EFR": 1.0, "Overall": 0.770248724489796}, {"timecode": 49, "before_eval_results": {"predictions": ["jimmy stewart", "shahcheh-e Namak", "tobacco", "france", "dutch Francis", "daniel boone", "Thames Street", "odore roosevelt", "satyrs", "crabs", "lite boheme", "IBM", "wishbone", "Garrick club", "Lackawanna six", "master Humphrey\u2019s Clock", "jimmy bowart", "American Civil War", "dark", "jennifer leachman", "jimmy Robertson", "spain", "saint Basil", "jimmy wonka", "severn", "australian", "south", "droughts", "guinea", "c Clement Attlee", "Wars of the Roses", "Chemnitz", "Fan Graphs", "mackinaw", "quinine", "wali Muhammad,", "belize", "American Folk Song", "hair loss", "track cycling", "Charlie Drake", "robin hood", "Chris Martin", "noddy", "jimmy jennifer jonese", "rugby", "honda", "steely Dan", "isham jones", "tobacco", "cows", "free floating", "Tom Selleck", "New Orleans", "a pinball machine", "Texas Tech University Health Sciences Center", "Loughborough Technical Institute", "Sharon Bialek", "the United States", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "George Babbitt", "dutch", "Elaine stritch", "four"], "metric_results": {"EM": 0.3125, "QA-F1": 0.3808423913043478}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.17391304347826086, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-12598", "mrqa_searchqa-validation-3615"], "SR": 0.3125, "CSR": 0.5359375, "EFR": 1.0, "Overall": 0.76796875}, {"timecode": 50, "UKR": 0.763671875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.775390625, "KG": 0.4578125, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo language", "Harold Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Sunyani West District", "pronghorn", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger", "9", "CR-X", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional literature", "Giuseppe Fortunino Francesco Verdi", "Laban Movement Analysis", "Cecily Strong", "J. Robert Oppenheimer", "invoicing", "seasonal television specials", "4 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "Pamela Chopra", "1901", "Pope John X", "The Curious Case of Benjamin button", "Electronic Attack Squadron 135", "Doug Pruzan", "Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "a jug", "terra Firma", "UNICEF", "9 a.m.", "Lord Byron", "Van Helsing", "Kufic", "a long-range missile"], "metric_results": {"EM": 0.5, "QA-F1": 0.6258871336996337}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.3333333333333333, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.0, 0.4615384615384615, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5173", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4925", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.5, "CSR": 0.5352328431372548, "EFR": 0.96875, "Overall": 0.700171568627451}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field in Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "a historic house museum", "\"Realty Bites\"", "24", "Razor Ramon", "Morita therapy", "Forbes", "St. George, Maine", "Kramer Guitars", "senior men's Lithuanian national team", "International Boxing Federation", "35", "Conservatorio Verdi in Milan", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "World Outgames", "Homebrewing", "Umberto II", "Presbyterian Church (USA),", "neuro-orthopaedic Irish veterinary surgeon", "in their home country", "North Sea", "17 October 2006", "67,575", "Oxford", "\"Advanced Dragons & Dragons\"", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Edward Whitacre", "Mission Inn Hotel & Spa", "180", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "McKenna's Fort", "Scunthorpe", "Canadian comedian", "Cook's Landing Place", "Boules at the 1900 Summer Olympics", "1936", "1970", "the most prestigious venues in the world, including Royal Albert Hall and The Kennedy Center", "Budget Rent a Car", "Japan", "cave lion", "June 6, 1959", "Donna Mills", "'s something missing in my heart", "735 feet ( 224 m )", "Alaska", "Blanche and Baby Jane", "maxilla", "anti-trust laws.", "4.6 million", "Iran,", "tea rose", "John J. Pershing", "Colorado Bulldog", "Vertigo"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5645348575036074}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, false, false], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.8, 1.0, 0.33333333333333337, 0.5, 0.0, 0.6666666666666666, 0.4, 1.0, 0.8, 0.0, 1.0, 0.8, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.16666666666666666, 0.0, 1.0, 0.3333333333333333, 0.5, 0.5, 1.0, 1.0, 0.8571428571428571, 0.25, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-2053", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-14080"], "SR": 0.390625, "CSR": 0.5324519230769231, "EFR": 0.9743589743589743, "Overall": 0.7007371794871795}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "non-voters", "3", "up to 100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "Camping World Stadium in Orlando", "Advanced Systems Format", "the Ramones", "Al Pacino", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the Gospel of Matthew", "30 years after Return of the Wars", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1960", "the British military launched a campaign to capture the Colony of Canada ( part of New France )", "1972", "U.S. states of Oregon and Washington", "coercivity", "2006", "Malware", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "clay", "one person", "The Parlement de Bretagne", "Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "typically closes for two and half weeks in late summer", "currency option", "first published in the First Folio in 1623", "a normally inaccessible mini-game", "the medulla oblongata", "1998", "Gibraltar", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "Steptoe and Son", "Gerry Adams", "Child actor", "Saoirse Ronan", "Revolution Studios", "The Kirchners' party", "Tottenham", "Sovereign Wealth Funds", "Indian, Insular, and Alaska Native Affairs", "yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6391281512605043}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.13333333333333333, 0.2857142857142857, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-10706", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-9142", "mrqa_naturalquestions-validation-9099", "mrqa_newsqa-validation-3704", "mrqa_newsqa-validation-318", "mrqa_newsqa-validation-577", "mrqa_searchqa-validation-1310", "mrqa_searchqa-validation-4527"], "SR": 0.546875, "CSR": 0.5327240566037736, "EFR": 0.896551724137931, "Overall": 0.6852301561483409}, {"timecode": 53, "before_eval_results": {"predictions": ["Alston", "a personal god", "Handel", "\"Green Acres\"", "Life's Refinements", "Clark Coconut Zagnut", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Eagle Airlines", "her coronation", "Vermont", "Notch", "candy store", "Oncorhynchus", "Pudd'nhead Wilson", "maine", "the tapir", "France", "Spam", "Stephen Dedalus", "Early labour", "Banon", "Friday", "Dragon", "centaur", "Parkhill", "Lebanon", "Manifest Destiny", "Al Gore", "Disability Act", "Bali", "Streets of Philadelphia", "Korea", "Glucosamine", "Madagascar", "The Only Way to Win", "Hizballah", "astrachan (curly lambswool)", "Susan Faludi", "Dr. Dre", "Al Lang Stadium", "Fidel Castro", "fudge", "Transcontinental Railroad", "Laborers' International Union", "goldfish", "hormones", "a dive", "yellowtail", "watermelon", "between the Mediterranean Sea to the north and the Red Sea tothe south", "Helsinki", "Zeus", "Van Morrison", "antelope", "manufacturer, distributor, and marketer", "Rocky Mountain Institute", "21", "stolperstein", "nearly 2,000", "insurgent small arms fire", "3,000 kilometers (1,900 miles),", "Lambic"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5104166666666666}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-7039", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-1108", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-4242", "mrqa_triviaqa-validation-1000", "mrqa_triviaqa-validation-7747", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-1792"], "SR": 0.453125, "CSR": 0.53125, "EFR": 0.9714285714285714, "Overall": 0.6999107142857144}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "in a nearby river bottom", "the vascular cambium", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "in elocution teaching", "on the Isle of FERNANDO 'S?, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "45 %", "handheld subscriber equipment", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Guy Berryman", "the Ming dynasty", "for the red - bed country of its watershed", "Thomas Jefferson", "The Intolerable Acts", "National Industrial Recovery Act", "semi-autonomous organisational units within the National Health Service in England", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "October 27, 1964", "the Finch family's African - American housekeeper", "Somatic", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "Philippines", "driving", "Goddess of Revenge", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "January 11, 2015", "Seminole Tribe", "Defense of Marriage Act", "Alinghi", "Eiffel Tower", "barnacles", "animal trainer", "Ewan McGregor"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6661442562855101}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4615384615384615, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506"], "SR": 0.546875, "CSR": 0.5315340909090909, "EFR": 1.0, "Overall": 0.7056818181818182}, {"timecode": 55, "before_eval_results": {"predictions": ["Edward III", "golf", "purple", "aeoline", "Ascot racecourse", "euro", "Loretta Lynn", "Survivor Series", "born To Be Wild", "chop suey", "Ross MacManus", "Coronation Street", "\"S Sierra One from Sierra Oscar\"", "South Africa", "Saddam Hussein", "New Zealand", "Tyrrhenian", "Bobby Sands", "MauritaniaMauritania", "Galileo Galilei", "Bolivia", "Bob Giraldi", "Mozambique Channel", "ash", "Edward VII", "Edward VI", "testicles", "Guatemala", "Brian lara", "Caroline Aherne", "Byron", "S\u00e8vres", "Simi knife", "Kipps: The Story of a Simple Soul", "frankincense", "Serena Williams", "Lome", "far-right", "Wagner", "Utrecht", "1709", "Mitford", "Kansas", "Spider-Man", "louse", "Skylab", "ostrich", "Hugh Quarshie", "a stern tube", "Batman", "Beijing", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack Ridley", "Linux Format", "Stage Stores", "26", "\"I have issued an order. I don't want these people interfered with in any way,\"", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5729166666666666}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-1803", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5554", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-5957", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.546875, "CSR": 0.5318080357142857, "EFR": 0.9655172413793104, "Overall": 0.6988400554187193}, {"timecode": 56, "before_eval_results": {"predictions": ["ireland", "Bolivia", "The Telegraph", "liver", "fado", "Drunk Crosswords", "Galway Bay", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "George Eliot", "central business district", "koftas", "benazir Bhutto", "cricketer", "Sam Mendes", "jen steed", "way back Attack", "ninth", "business", "leofric godiva", "scorcese", "Mexico", "Towy", "paris", "1984", "Swansea", "8", "shintoism", "Sussex", "george iv", "Mickey Mouse", "oxygen", "Prince Albert", "centilla-La mancha", "quietly", "Dodoma", "radiohead", "Wilson", "Loch lomond", "Pyrenees", "South Korea", "gelatine", "Papua New Guinea", "Gulf of Suez", "Yorkshire", "a\u00e9roport roissy-Charles de Gaulle", "sankt Moritz", "French Revolution", "old Kent Road", "on your way in one of two ways, cremation or inhumation", "anion", "iron", "creation of the office in 1789", "Chris Pine", "Yorgos Lanthimos", "Spurs", "Venus Williams", "off Somalia's coast.", "Shanghai", "a peacock skirt", "Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5601715686274509}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-2762", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-2075", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.484375, "CSR": 0.5309758771929824, "EFR": 1.0, "Overall": 0.7055701754385966}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "valen shapiro", "micelles", "river lee", "Rudolf Nureyev", "Jessica", "placebo", "weather", "lakes placid", "a sovereign state", "braille", "William Boyd", "saint Cecilia", "Caroline Garcia", "morecambe and Wise", "maggie Gilkeson", "butcher", "cowpox", "foxhunting", "Stockholm", "france", "Brothers in Arms", "anosmia", "Lunar Prospector probe", "Chemnitz", "herbygrass", "yellow", "raven", "caracas", "ennio morricone", "British", "spain", "timesigns", "torandot", "adaba", "mauna Kea", "eat porridge", "sue Ellen ewing", "marriage", "Boutros Ghali", "france", "Sinclair Lewis", "New Mexico", "garden of Gethsemane", "decision tree", "14.504", "Sunday Times", "principality of France", "kristiania", "keirin", "selenium", "vehicle that is both four - wheel - drive and primarily a road car", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "he was diagnosed with skin cancer.", "Shiza Shahid,", "Perseid meteor shower", "accordion", "bones", "Marky wahlberg"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6203125}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-6704", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-4351", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-7012", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-16209"], "SR": 0.53125, "CSR": 0.5309806034482758, "EFR": 1.0, "Overall": 0.7055711206896552}, {"timecode": 58, "before_eval_results": {"predictions": ["rubbing", "Jonah", "The Color Purple", "c Cyprus", "Jacqueline Susann", "chile", "Hudson", "spinal column", "a Bahamas", "the Sons of Liberty", "Napoleon Bonaparte", "c Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "marty", "pump spray", "Siberia", "William Pitt the Younger", "five", "Friday the 13th", "rotherham", "godfather", "wrinkles", "Nostradamus", "jihad", "harpoons", "mandy manilow", "financial services", "Conrad n. Hilton", "jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "viscount nelson", "the bald eagle", "meatball", "Lammermoor", "hurricanes", "home improvement", "Great Lakes", "armthur hailey", "nu", "new orleans", "a single death", "little mermaid", "howard", "injecton", "Pell grants", "beryl", "watermark", "19 July 1990", "Incudomalleolar joint", "Louis XV", "mzizia", "Mansion House", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "the Dutch patent office", "Nasser Medical Institute", "Auckland", "becoming bald"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5450520833333333}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-13207", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-12813", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-2704", "mrqa_searchqa-validation-4789", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-12017", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-856", "mrqa_newsqa-validation-1225", "mrqa_triviaqa-validation-2596"], "SR": 0.46875, "CSR": 0.5299258474576272, "EFR": 0.9705882352941176, "Overall": 0.699477816550349}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "italianmoneyguy.com", "whisky", "Leonard Bernstein", "magnesium", "attendolo", "the Danube", "the albatross", "George Costanza", "the Smashing Pumpkins", "a sentence", "Ohio State", "William Tecumseh Sherman", "Pakistan", "Theology of God", "Great Britain", "Sally Field", "Barbara Cartland", "rum", "Pringles", "Paul Hamm", "a type of classical male singing voice", "East Siberia", "Nimble", "a simple man with a low I.Q. and good", "Clue", "a comic", "#5367", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "\"We Are Marshall\"", "General Motors Fairfax Assembly Plant", "Barbados", "Ambassador to Vietnam", "silk", "y", "the Unicorn of Scotland", "Scrabble", "the humerus", "Grease", "Petruchio", "the Philippines", "a fungus", "Ernesto \"Che\" Guevara", "Yale University", "Oscar Wilde", "aeneas", "dian fossey", "a map", "an iron -- nickel alloy and some other elements", "ABC", "an opinion in a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court which gives rise to its judgment", "pear", "Melbourne", "jape", "Ringo Starr", "Do Kyung-soo", "Hanna, Alberta", "Majid Movahedi,", "\"came under fire\" after admitting they learned of the death from TV news coverage,", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "Priam"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5656262706695581}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.25806451612903225, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.47058823529411764, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-8167", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-10144", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-12241", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-6415", "mrqa_searchqa-validation-16858", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-4918", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745"], "SR": 0.46875, "CSR": 0.52890625, "EFR": 0.9117647058823529, "Overall": 0.6875091911764706}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha,", "four", "Sippin' on Some Syrup", "Ving Rhames, Jake Weber, and Mekhi Phifer", "Maersk Group", "Salem", "Karl-Anthony Towns", "five", "Gust Avrakotos", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1858", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "Tom Courtenay", "Erinsborough", "2015", "Vladimir Menshov", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Site", "Eardwulf", "\"God and the just cause\"", "Swiss", "Emperor Augustus", "World War I", "at age 27", "Northwest Indiana", "five", "Rodney Crowell", "Mendel", "near major hotels and in the parking areas of major Chinese supermarkets", "scales", "Frankfurt", "Apollon", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III,", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6263621794871794}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-399", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-6034", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.546875, "CSR": 0.5292008196721312, "EFR": 0.9655172413793104, "Overall": 0.6983186122102883}, {"timecode": 61, "before_eval_results": {"predictions": ["ghaedheil", "Chicago Bears", "girls", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Cartoon Network", "1983", "Rio Ferdinand", "264,152", "2,664", "841", "Cher", "Australian Broadcasting Corporation (ABC)", "Cecil Kimber", "Walt Disney and Ub Iwerks", "1979", "15 mi", "January 23, 1898", "John W. Henry", "Bolton", "Argentinian", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "New York and New Jersey", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "dziga Vertov", "Friday", "Oklahoma Sooners", "2002\u201303", "7pm", "1866", "gorgoroth", "Serie B", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth and Gary Goldman", "Golden Calf for Best Actor", "Lykan Hypersport", "the final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer", "1951", "35,124", "21 years and 154 days", "September 30", "Jimmy Flynn", "powers in the Eastern Bloc ( the Soviet Union and its satellite states )", "his finger", "Ronald Reagan", "One Thousand and One", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "promoting fuel economy and safety while boosting the economy.", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "James Watt", "T.S. Eliot", "Anastasia", "Games"], "metric_results": {"EM": 0.5, "QA-F1": 0.6509901519072714}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.4, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 0.09523809523809525, 0.5217391304347826, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129"], "SR": 0.5, "CSR": 0.5287298387096775, "EFR": 1.0, "Overall": 0.7051209677419356}, {"timecode": 62, "before_eval_results": {"predictions": ["Dayton Memorial Hall", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Babylon", "a card (or cards) during a card game", "water", "Sean Yseult", "law", "October 5, 1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "John Nicholas Galleher", "German", "Gareth Jones", "consulting services", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Axl Rose", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "\"The Big Bang Theory\"", "the German princely Battenberg family", "dice", "Tomorrow May Never Come", "Dungeness crab", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "David Anthony O'Leary", "Jeremy Hammond", "Reginald Engelbach", "American", "the fourth Thursday", "Minneapolis", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard John Seddon", "the heart", "Sitka, Alaska", "launch a group that will serve as an alternative to the Organization of American States.", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "Bob Bogle", "circumference", "Austin", "a station wagons", "2001"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6596354166666667}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 0.2727272727272727, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-928", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-7093", "mrqa_searchqa-validation-12404"], "SR": 0.546875, "CSR": 0.5290178571428572, "EFR": 0.9655172413793104, "Overall": 0.6982820197044336}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "a pair of 1981 datings", "\"I'll have my bond\"", "gene flow", "Beluga whales", "Nicholas II", "tuna", "shalom", "Russia", "a chimp", "\"The Larry Sanders Show", "Mendoza", "Thor", "Saint Albans", "astride", "Borneo", "Versailles", "Breakfast cereal", "new york", "whipped cream", "yellowfin", "Macbeth", "Edgar Degas", "Led Zeppelin", "War & Peace", "Dutchman", "Bruce Willis", "a small Southern town", "Peter Falk", "John Tyler", "Hank Aaron", "tranfgrelTion", "Wall Street", "sake", "Notre Dame", "Portland", "Lafayette", "The Indianapolis 500", "Toy Story", "improv", "Sarah Jessica Parker", "water", "Nikolai Gogol", "Oscar Wilde", "Fletcher Christian", "weaving", "Pope John Paul II", "Greenland", "in sanctification", "The Marx Brothers", "a trellis", "Phillip Schofield and Christine Bleakley", "enterocytes", "Reverend J. Long", "string", "sexual imagination", "a mountain peak in the Karakoram Range in northern Kashmir", "Garrett Morris", "1966", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "Three thousand", "al-Maliki"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5483258928571428}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-4522", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-1267", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-15192", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-14853", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-10461", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-4565", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.46875, "CSR": 0.528076171875, "EFR": 0.9705882352941176, "Overall": 0.6991078814338236}, {"timecode": 64, "before_eval_results": {"predictions": ["giant pumpkins", "Seminole Tribe", "billions of dollars in Chinese products each year,", "\"green-card warriors\"", "228", "a traditional form of lounge music", "2005", "contaminated groundwater", "consumer confidence", "Fernando Gonzalez", "in the southern port city of Karachi,", "Dan Parris, 25, and Rob Lehr, 26,", "Jason Chaffetz", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "Russia", "Barack Obama", "Sunday", "Gerfa Yeatts Lunsmann,", "France", "380,000", "be silent.", "iTunes", "security and military operations.", "\"gotten the balance right\"", "a dozen", "10", "\"Quiet Nights,\"", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Iran", "$7.8 million in cash", "engineering and construction", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "fractured pelvis and sacrum", "five dead bodies", "to step up.", "first-degree murder", "Moscow", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda,", "Garth Brooks", "Oxbow,", "an Iranian court", "different women coping with breast cancer", "Michael Schumacher", "Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Tim Passmore", "Odoacer", "Ted Heath", "Estonia", "is our children learning", "Anne", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Hipparchus", "President Woodrow Wilson", "Tampa Bay"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6115889319014318}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.8]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-236", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-10515", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.46875, "CSR": 0.5271634615384615, "EFR": 0.9705882352941176, "Overall": 0.6989253393665159}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "\"I always kind of admired him, oddly.\"", "North Korea", "February 12", "Mandi Hamlin", "United Nations", "\"falling space debris,\"", "outside the military recruiting center.", "voluntary manslaughter", "emergency room at LakeWest Hospital in neighboring Willoughby,", "Chris Robinson", "Sandy Olssen", "\"black box\"", "34", "E. coli", "More than 15,000", "against meat consumption by covering themselves in fake blood and lying in human-sized meat packages.", "The Sopranos", "government", "during childbirth", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "Graeme Smith", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "not necessarily better...some vitamins and minerals can be toxic in high doses,\"", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "Nafees A. Syed", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "the immorality of these deviant young men", "Wednesday.", "managing his time.", "not including co-pays or deductibles.", "bipartisan", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "13", "drug cartels", "state", "Trevor Rees,", "at least 28 passengers,", "the leader of a drug cartel", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "in solitary confinement at the Prince George's County Correctional Center,", "the Genocide Prevention Task Force,", "243 days", "Kirstjen Nielsen", "1937", "20", "Wisconsin", "\"Mr Loophole\"", "Arlo Looking Cloud", "Lake Huron", "1694", "the Golden Fleece", "Gustav", "Amish TV", "6teen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6035251480975165}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.2727272727272727, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 0.4, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2911", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-3127", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-993", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-3469", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692", "mrqa_searchqa-validation-5235"], "SR": 0.515625, "CSR": 0.5269886363636364, "EFR": 1.0, "Overall": 0.7047727272727273}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar jamming", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "about a mile north of the village of Dunvegan", "steel tower,", "\"lodges\") in the resulting pond", "Stilwell", "Tallinn,", "a mechanical model of the solar system", "coelacanth", "Belgium", "Dennis Potter,", "calciumcis", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "California condor", "Ohio", "turbomachine", "Hattie Jacques,", "Superintendent Jack Meadows (Simon Rouse)", "0 for 7", "Hamlet", "gauteng", "Crackerjack pencil", "Bleak House (1854)", "carousel", "Spain", "Terry McCann,", "Special sauce", "Les Dennis", "Kansas City", "Hard Times", "Tuscany", "18 meters", "Singapore", "Dinkley", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "John Fitzgerald Kennedy", "Hong Kong", "Chuck Yeager", "Melanie Bush,", "northern France", "stamp", "Moby Dick", "Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "the American philosophy of pragmatism", "21 July 2015 on A&E", "Bern", "28 June 1945", "\"a violent and brutal extremist group with a number of individuals affiliated with al Qaeda.", "25", "Pakistan's", "Yves Saint Laurent", "Rush", "Topix", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.484375, "QA-F1": 0.594047619047619}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2, 0.5, 0.4, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.09523809523809525, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-5468", "mrqa_triviaqa-validation-283", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-5912", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-5331", "mrqa_triviaqa-validation-7476", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-7211", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-3319", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_triviaqa-validation-7014", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.484375, "CSR": 0.5263526119402986, "EFR": 0.8787878787878788, "Overall": 0.6804030981456355}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Alaska", "Christina Pickles", "August 9, 1945", "after obtaining the consent of the United Kingdom", "products under the same name", "Olivia Olson", "Tokyo", "Pyeongchang County, South Korea", "602", "March 11, 2018", "5.7 million customer accounts", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "first week of April", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "the Royal Air Force ( RAF )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "currently ongoing", "Krypton", "November 25, 2002", "IBM", "Soviet Union", "435", "off - road vehicles", "Elk and Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand to New Guinea", "Frank Oz", "1954", "2010", "Missouri River", "\u00c6thelstan", "viola", "Greece", "John Churchill", "Gregg Charles Popovich", "Asiana Town", "Araceli Valencia,", "Eleven", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "hyperbole"], "metric_results": {"EM": 0.515625, "QA-F1": 0.617680565048986}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-5363", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-4085", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025"], "SR": 0.515625, "CSR": 0.5261948529411764, "EFR": 0.9354838709677419, "Overall": 0.6917107447817836}, {"timecode": 68, "before_eval_results": {"predictions": ["dusseldorf", "Roberta Flack", "sesame seed", "heiresses", "September 19", "Barnaby Rudge", "Buddha", "Amharic", "1963", "discus", "red top", "royal yacht Britannia", "Chester RacecourseChester Racecourse,", "Washington State", "Jews of the Middle East", "lyndon", "Saint Basil's", "Peru", "the keel", "Evander Holyfield", "a crosse or lacrosse stick.", "Buddhism", "New Orleans", "soda", "fat", "Richie McCaw", "brash", "Ken Burns", "Paddy Doherty", "Barry Howard and Yvonne", "phi", "Hungary", "So Solid Crew", "blues-rock", "Pennsylvania", "the main Caucasus range", "Scottish", "morningtown Ride", "Jupiter", "The Woodentops", "son or daughter", "two", "Queens Park Rangers", "wake onLAN", "giants", "back fabric", "B\u00e9la Bart\u00f3k", "Hugh Dowding", "Montpelier,", "February", "Arthur, Prince of Wales", "15.1 percent", "seventeen", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 31, 1995,", "Amanda Knox's aunt Janet Huff's", "Dubai", "suicide notes taking responsibility for the murders of his family.", "deep roots", "Russia", "mullet", "Jimmy Carter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.546155753968254}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.0, 0.4, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 0.3333333333333333, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-7919", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-787", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-10485"], "SR": 0.46875, "CSR": 0.5253623188405797, "EFR": 1.0, "Overall": 0.704447463768116}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey Archer", "Chicago", "California Chrome", "dar es salaam", "Sarah Keays", "miss marple", "Elkie Brooks", "United Parcel Service", "Novak Djokovic", "piano", "Cambridge", "bennet", "The Spice Girls", "syrupy", "the Addams Family", "Doubting Castle", "beetle", "australian", "graham greaves", "Harry Shearer", "9-13 years", "pirate day", "penny", "spice girls", "48 Hours", "AFC Wimbledon", "germany", "Tombstone", "Friedrich Nietzsche", "c Cambridge", "South Africa", "Bagram", "Pygmalion", "bajan", "cassis", "Dieppe Raid", "Dengue fever", "left book club", "triathlon", "Kevin Spacey", "dividing of cells into additional cell bodies", "something in the air", "\"sound and light\")", "how", "fox terrier", "Alberta", "fondue", "kilimanjaro", "magic circle", "romanian", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Lear", "London Luton Airport", "Sarah Winnemucca", "Antigua & Barbuda", "\"The workers should be dealt (with) with compassion and should not be pushed so hard that they resort to whatever that had happened in Nodia\"", "it is in the best interest for both of them.", "\"The deceased appeared to have been there for some time.\"", "Vanilla Ice", "Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.5, "QA-F1": 0.5684671952976281}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.06451612903225806, 0.10526315789473685, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-2520", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-5378", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-1346", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002"], "SR": 0.5, "CSR": 0.525, "EFR": 1.0, "Overall": 0.704375}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew - Somerville", "a complex sentence", "New South Wales", "Ashrita Furman", "Lana Del Rey", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "2018", "the term originated in Missouri, during the Kirtland period of Latter Day Saint history, circa 1834", "Swedien and Jones", "in 1902", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "2001", "the city of Indianapolis", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Steve Lukather", "$100", "the team that lost the pre-game coin toss", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W \ufeff / \ufefa 26.617 \u00b0 N 81.617", "smacking a fly on her mirror and removes its corpse", "around 2011", "New Jersey Devils", "ulnar nerve", "2018", "British Indian Association", "indigenous", "Western Australia", "Carol Worthington", "1830", "alcohol", "thanksgiving for a good harvest", "born November 28, 1973", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "Bangalore", "Anthony Hopkins", "Jesus", "1996", "holographic method", "flanders", "martin", "Gillian Leigh Anderson", "direct scattering and inverse scattering", "45th Infantry Division", "it should stay that way.", "2009", "an open window that fits neatly around him.", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.5, "QA-F1": 0.6820287963670317}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.5, 0.0, 1.0, 1.0, 0.823529411764706, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.823529411764706, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.25, 0.5714285714285715, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8, 0.8333333333333333, 1.0, 0.7499999999999999, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8290", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-5562", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-706", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-3858", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.5, "CSR": 0.5246478873239437, "EFR": 0.875, "Overall": 0.6793045774647888}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "inner core", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama Action", "forks, plate, butter knife, and napkin generally are placed to the left of the dinner plate", "red", "off the rez", "either in front or on top of the brainstem", "March 14, 1942", "Agamemnon", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Temperton", "Pakistan", "Tessa Peake - Jones", "connected behaviors, rights, obligations, beliefs, and norms", "United Nations Peacekeeping Operations", "part of the normal flora of the human colon", "Noahic Covenant", "Shirley Mae Jones", "Heat transfer by thermal radiation", "Luke 6 : 67 -- 71", "on August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "the optic chiasma", "letter series", "September 25", "in the Blue Ridge Mountains of Virginia", "the Confederacy", "1955", "electron donors", "2", "Montreal Canadiens", "in 1985", "On 1 September 1939, Germany invaded Poland", "three levels", "product-market fit", "Wyatt", "the last book accepted into the Christian biblical canon", "In the 1920s", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "camellia sinensis", "eEC", "mumbai", "Frank Fertitta, Jr.", "\"Coronation Street\"", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "complicated and deeply flawed", "a house party in Crandon, Wisconsin,", "butterflies", "Rocky Mountain spotted fever", "$500", "Afghan"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6219126672335904}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.5263157894736842, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.35294117647058826, 0.75, 0.0, 1.0, 1.0, 0.6086956521739131, 0.0, 0.4444444444444445, 1.0, 1.0, 0.7692307692307693, 0.75, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.6666666666666666, 0.0, 0.0, 0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.453125, "CSR": 0.5236545138888888, "EFR": 1.0, "Overall": 0.7041059027777778}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day", "Afghanistan", "a foam", "Alice Paul", "(Aragorn)", "Christopher Darden", "a jelly Belly", "a cloudy day", "Daniel Berrigan", "wheat", "Carole King", "(black spain capital during emperor cesar (battle of Munda)", "the Pro-Jig Clamp Set", "Christo Vladimirov Javacheff", "Wichita", "USDA", "Gilligan's Island", "Penelope", "Tom Harkin", "Channel Islands", "Hershey", "Penelope", "me", "Bonobo", "Harry's Harbor", "Veep", "billet", "lullaby", "a ruby", "Pan's Labyrinth", "(Sir James Matthew) Barrie", "John Irving", "a Demonstrative pronoun", "the Who", "the Aegean Sea, the Dardanelles-Sea of Marmora-Bosporus", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "World War II", "Beijing", "Lee Harvey Oswald", "(General Custer) Custer", "Force", "breath", "Stockholm", "Alaska", "a puff", "Mausolus of Caria in Asia Minor", "qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani", "magi", "Exodus", "saint Cecilia", "Germany", "1989 until 1994", "Suzuki YZF-R6", "the nose, cheeks, upper jaw and facial tissue from a female cadaver", "Donald Trump and Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.5, "QA-F1": 0.5892900654413813}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.14814814814814814, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.9473684210526316, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-16049", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_naturalquestions-validation-6720", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1587"], "SR": 0.5, "CSR": 0.5233304794520548, "EFR": 0.96875, "Overall": 0.697791095890411}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "Happy Days", "Rita Mae Brown", "Bolivia and Paraguay", "Kansas", "grasshopper", "the commander", "Sure", "the Bicentennial", "brood", "a bystander", "the Big Sleep", "Maryland", "Lowenbrau", "pen", "Herod", "the Lone Ranger", "Malaysia", "Xavier High School", "Bruce Rauner", "Goofy", "Walter Payton", "Everest", "( Winston) Rodney", "pindar poem", "the eiders", "the Tom Thumb", "Prince Edward Island", "the Mad Hatter", "L-Tryptophan", "Cincinnati", "to aid the athlete's performance", "concert grand", "ketchup", "peanut butter", "soccer", "Tom Petty and the Heartbreakers", "Tuscany", "Tunisia", "Rosa Parks", "inch", "Paris", "(William Henry Harrison) Harrison", "Corinthian", "carats", "Bern", "Prada", "Chicago", "anything inside you", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "Tipping Point", "skara", "the dogger Bank", "NBA 2K16", "ethereal wave", "Ronald Lyle \" Ron\" Goldman", "\"Sesame Street\"", "\"fusion teams,\"", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7269345238095238}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-13761", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-3004", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_triviaqa-validation-2254", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410", "mrqa_newsqa-validation-3105"], "SR": 0.65625, "CSR": 0.5251266891891893, "EFR": 1.0, "Overall": 0.704400337837838}, {"timecode": 74, "before_eval_results": {"predictions": ["Urban Outfitters", "The Tyger", "\"Thunder Road\"", "the Last Supper", "Baccarat", "Rook", "Harlem", "Bosch", "hulls", "a rehab facility", "a cricket", "India", "Children of Men", "Skagway", "a petition", "Hippolyta", "a species", "John Galt", "spinach", "milk", "(kWh)", "a fertile imagination", "World War I", "student loans", "the Gateway Arch", "Itzhak Perlman", "Wolfgang Puck", "a dachshund", "the Monitor", "Cyprus", "Milwaukee", "a hot latte", "Kevin Costner and Tim Robbins", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Gerald Ford", "Speed Racer", "the USA", "Aristotle", "Emergency Room", "the Eagles", "An American Tail", "a bus", "an argyle", "Honda", "a wallaby", "a leather feather", "Mark Twain", "Thomas Gibson", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Christopher Bolam,", "pawns", "India", "House of Habsburg-Lorraine", "the highest commissioned SS rank", "Kansas\u2013Nebraska Act of 1854", "Orbiting Carbon Observatory,", "South Africa", "Tuesday.", "two"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7338541666666667}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-9320", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.671875, "CSR": 0.5270833333333333, "EFR": 0.9523809523809523, "Overall": 0.6952678571428572}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "China in modern times", "from 1900 to 1920", "DNA at the origin", "Yuzuru Hanyu", "Michael Crawford", "silk floss", "American country music group The Nitty Gritty Dirt Band", "Gustav Bauer, the head of the new government", "November 2016", "Empiricism", "Identification of alternative plans / policies", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "Greenland ( / \u02c8\u0261ri\u02d0nl\u0259nd / ; Greenlandic : Kalaallit Nunaat, pronounced ( kala\u02d0\u026cit nuna\u02d0t )", "Johnson", "Song of Songs", "Taron Egerton as Johnny, a teenage gorilla who wants to sing, though his father would rather have him follow his criminal footsteps", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Divyanka Tripathi", "September 24, 2012", "Only two men, Lex Luger and Rick Rude, have held the championship for a continuous reign of one year ( 365 days ) or more", "Michael Christopher McDowell ( born December 21, 1984 )", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the homicidal thoughts of a troubled youth", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "+, -, *, and / keys", "December 15, 2016", "Kid Creole and the Coconuts", "after 800", "2010", "Microfilaments", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna, led by former president Mahinda Rajapaksa, secured the most seats and local authorities", "1773", "Buddhism", "introverted Sensing ( Si ), Extroverted Thinking ( Te ) and Extrovert Intuition ( Ne ) )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "midland", "Thomas Stearns Eliot", "Kent Hovind", "aviation pioneer Lieutenant Colonel Horace Meek Hickam", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum -- the triangular bone within the pelvis.", "239 years", "to recognize gain or loss on the settlement of foreign currency", "Blackbird", "Sara Ramirez", "September 25, 2017"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6317362890732456}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0909090909090909, 0.4, 0.0, 1.0, 1.0, 0.8, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 0.4444444444444445, 0.5714285714285715, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8333333333333333, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-3862", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-5781", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.53125, "CSR": 0.5271381578947368, "EFR": 0.9666666666666667, "Overall": 0.6981359649122807}, {"timecode": 76, "before_eval_results": {"predictions": ["a dress to wear to the neighborhood dance", "Walter Mondale", "a system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1942", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "15", "John F. Kennedy, at 43 years, 163 days of age on election day", "23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "The Hunger Games : Mockingjay -- Part 2 ( 2015 )", "the President of India", "to signify cunnilingus", "28 %", "Elvis Presley", "a Native American nation from the Great Plains", "Jack Scanlon", "July 2014", "Elijah Wood", "head - up", "Doug Pruzan", "by October 1986", "The 1975", "inside the cell nucleus", "pathology", "1986", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Jourdan Miller", "Panzerkampfwagen VIII Maus", "limited period of time", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England Patriots ( 5 - 4 )", "40 %", "Janie Crawford", "in the west by the east coast of Queensland, thereby including the Great Barrier Reef, in the east by Vanuatu ( formerly the New Hebrides ) and by New Caledonia", "2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "St. Louis Blues", "around 1872", "Colman", "starch", "carbon", "the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery F.C.", "Phelan Beale", "one", "Government Accountability Office", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "a suit", "Heroes: Reborn", "the netherworld", "since 1983."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5985947039072039}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.15384615384615385, 0.0, 0.2, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.30769230769230765, 0.4615384615384615, 0.0, 0.0, 1.0, 0.16, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-6137", "mrqa_naturalquestions-validation-5719", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_searchqa-validation-1664", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.484375, "CSR": 0.5265827922077921, "EFR": 0.9393939393939394, "Overall": 0.6925703463203463}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus, (Another name for shingles is herpes zoster.)", "MUD1", "Roddy Doyle", "GRELES DICKENS PRESENT THE CHARACTER OF MR JAGGERS", "Prussia", "Rudyard Kipling", "Spongebob", "Exile", "an enclave which is entirely enclosed", "South Dakota", "Brian Close", "Cabbage", "l Leeds", "Edinburgh", "meter maid", "cricketer", "france", "Neptune", "Vimto Cordial", "phobia", "leicestershire", "carry On Cleo", "afro-Asiatic", "sense of taste", "single paradiddle-diddle", "shallow seas", "sesame seed", "hurdles", "The Centaurs", "tallest building in the world", "American football", "Paula Wagner", "Harold Warne", "Giglio", "d Copenhagen", "Haight-Ashbury", "Geoffrey Rush", "Harry patch", "nursery Comics", "film magazine", "Inigo Jones", "sonar", "Nelson Mandela", "Today", "a trousseau", "Utah", "Mark Darcy", "reptilian", "a supercontinent", "Salyut 1", "Puerto Rico", "Evermoist", "62", "Matthew Gregory Wise", "1861", "voice actress", "Limbo", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6163589015151515}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2362", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.546875, "CSR": 0.5268429487179487, "EFR": 1.0, "Overall": 0.7047435897435899}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he acted in self defense in punching businessman Marcus McGhee.", "1960", "\"It didn't matter if you were 60, 40 or 20 like I am.", "\"momentous discovery\"", "Al-Aqsa mosque", "Dilshan put Sri Lanka back on top again in the final session with a 74 stand which was ended when the debuted was given out caught at short-leg off Harbhajan,", "as soon as 2050,", "secluded island of sylt", "the media", "in the southern city of Najaf.", "Sen. Barack Obama", "Arnoldo Rueda Medina,", "left his indelible fingerprints on the entertainment industry.", "ketamine.", "Brian David Mitchell,", "Defense of Marriage Act", "Jacob,", "Ronaldinho", "the Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "\"brain hacking\"", "\"Swingin' Down the Lane.\"", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda,", "Manmohan Singh's", "to reflect on their crimes, wrest through feelings of guilt and transform themselves during their rehabilitative journey,", "J. Crew", "\"My gut started feeling like something just wasn't right,\"", "10,000", "Meira Kumar", "antihistamine and an epinephrine", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III", "million dollars", "bribing other wrestlers to lose bouts,", "people", "they don't feel Misty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "10 percent", "the return of a fallen U.S. service member", "designers love models.", "Anthony Quinn as Craig Belden", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "the well.", "China", "Capture of the Five Boroughs", "I Should Have Known Better", "pornographicstar", "God", "charlie", "Fannie Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6341334033613446}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.058823529411764705, 1.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1, 1.0, 1.0, 0.24, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 1.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-1390", "mrqa_naturalquestions-validation-4008", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-15636"], "SR": 0.53125, "CSR": 0.5268987341772151, "EFR": 1.0, "Overall": 0.704754746835443}, {"timecode": 79, "before_eval_results": {"predictions": ["1866", "Ulysses S. Grant", "Yangtze River", "Jacob", "Queen Anne Stuart", "The New York Times", "Scotland", "Oklahoma", "the communist revolution", "the USS Nautilus", "Sir Humphrey Davy", "seoul", "1/2 hours", "smallpox", "the Dead Sea", "the fairway", "NYPD Blue", "elevation", "Mao Zedong", "Harriet M. Welsch", "Mickey Mouse", "Xerox", "blitz", "Jamaica", "gossip", "an exothermic reaction", "canabalism", "Morocco", "Surf's Up", "Yao Ming", "tax collection", "clothing", "Andrew Marvell", "fruits", "Bollywood", "\"Titanic\"", "Take Me Out to the Ballgame", "Parapet para-pet", "Joe Lieberman", "chocolate", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Surinam", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal virgins", "The Lord of the Rings: The Return of the King", "Barack Obama", "H CO ( equivalently OC ( OH ) )", "in a thousand years", "W. Edwards Deming", "Clara wieck", "Douglas Trendle", "Extras", "Ricky Marco", "Edith Cavell", "Forbes", "20 minutes of cardio five days a week.", "22", "John Demjanjuk", "1,776"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6410511363636364}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7272727272727272, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-4897", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-13610", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-2149", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-2118", "mrqa_naturalquestions-validation-3561"], "SR": 0.515625, "CSR": 0.5267578125, "EFR": 0.967741935483871, "Overall": 0.6982749495967743}, {"timecode": 80, "before_eval_results": {"predictions": ["Homebrewing", "the German Empire", "Tim Whelan", "North Shore", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "associated with Cybele", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Norwood", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "the Manor of More", "England, Scotland, and Ireland", "the Workers' Party", "those that either own exotic animals or have been captured for illegally smuggling them,", "his exploration and settlement of what is now Kentucky,", "six", "Mauthausen-Gusen", "Adrian Peter McLaren", "Lisburn Distillery F.C.", "Ted Nugent", "New York", "Viscount Cranborne", "The Frog Prince", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "Boulder High School", "Dutch", "November of that year", "Boston, Massachusetts", "Kaley Christine Cuoco", "Brendan O'Brien", "Delphine Software International", "Sullivan University College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31", "September 15, 2012", "Queen Elizabeth II", "Vienna", "Malaysia", "I, the chief executive officer, the one on the very top,", "Iran's nuclear program.", "alternative-energy vehicles", "\"jazz's\"", "*ceph\"a*s[e^]f\"[.a]*l[u^]s)", "Henry VIII", "M&M's"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6163194444444444}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.11111111111111112, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-237", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1830", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999"], "SR": 0.53125, "CSR": 0.5268132716049383, "EFR": 1.0, "Overall": 0.7047376543209877}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies", "acid house", "Esteban Ocon", "Lady Frederick Windsor", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "half of the Nobel Prize in Physics", "Adam Karpel", "rock and roll", "1957", "Windermere", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John W. Henry", "2009", "Jenson Alexander Lyons Button", "French composer Ambroise Thomas", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "English Electric Canberra", "3 August 1916", "Smithsonian", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "English", "Ericsson", "interstate commerce", "1935", "Imperial War Museum", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow", "Cliff Thorburn", "Kim Clijsters", "Mombasa, Kenya,", "Benazir Bhutto, who was assassinated Thursday in Rawalpindi,", "rudiments", "New York City Ballet", "volts", "Willa Cather"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5411345598845598}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-4081", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-4359", "mrqa_triviaqa-validation-873", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.421875, "CSR": 0.5255335365853658, "EFR": 1.0, "Overall": 0.7044817073170732}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "four", "October 29, 1895", "Turkmenistan", "the Earth", "Standard Oil", "2007", "Norwegian", "The Late Late Show", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "The Worm", "Herman's Hermits", "Nikhil Banerjee", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Tom Rob Smith", "a novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "The parkway", "Teatro Carlo Felice", "every aspect of public and private life", "Gary Ross", "Hanford Site", "Commissioner", "Sam tick,", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Serial", "Epithelium", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "Ringo Starr", "1882", "off the coast of Dubai", "The incident Sunday evening", "not doing more", "ibm-l-lpic1104", "the Polio Vaccine", "the treble clef", "gun charges"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7880208333333334}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882"], "SR": 0.734375, "CSR": 0.5280496987951807, "EFR": 0.8823529411764706, "Overall": 0.6814555279943303}, {"timecode": 83, "before_eval_results": {"predictions": ["Massachusetts", "Metacomet", "Chicago", "Leon Trotsky", "a loaf", "a atlas", "The New York Times", "Thomas Beekman", "Ugly Betty", "Winnie the Pooh", "Charles Gounod", "Alexander Graham Bell", "(Vijay) Singh", "the Sea of Mist", "a modem", "Canada", "the Boston Red Sox", "Jon Stewart", "Mussolini", "eastern Kentucky", "Jane", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "Africa", "the banjo", "Northern Virginia", "Belle Watling", "Mozart", "Chicago", "New York's Lunatic Asylum", "Lord Byron", "meningitis", "Mt. Suribachi", "perfluorinated", "the Rolling Stones", "Edie Falco", "USA", "Oneonta College", "1936", "the CN Tower", "The Hurricane", "inheritance", "Maryland", "the northern cardinal", "Japan", "a mad cow", "New Brunswick", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "Cliff Thorburn", "China's total population", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul John Manafort Jr.", "1959.", "The son of Gabon's former president", "the United States", "in mid November"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5601934523809523}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-7861", "mrqa_searchqa-validation-8682", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-9230", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-4122", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3923", "mrqa_naturalquestions-validation-8884"], "SR": 0.46875, "CSR": 0.52734375, "EFR": 0.9411764705882353, "Overall": 0.6930790441176471}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "James Hook", "Jabez Stone", "William Howard Taft", "vermouth", "Pemmican", "Olivia Newton-John", "Oahu", "Joseph Smith", "phylum Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "Stuffed Poblano Chiles", "Thomas Jefferson", "the legislative process", "soy miso", "Old School", "the DEW Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "the American Economic Association", "Robert Bruce", "Zinc", "oxys", "gargantua", "Elke Sommer", "a bird", "Robin Williams", "Philadelphia", "Ivory soap", "Benito Mussolini", "The Five People You Meet in Heaven", "the anglerfish", "the S-Type R", "Thomas Jefferson Family Cemetery", "Mohandas Gandhi", "Brazil", "Jim Thorpe", "the Office", "Dustin Hoffman", "King Lear", "to descend through the air", "the Bicentennial Symphony", "Haunted Mansion", "Rembrandt", "Gilligan's Island", "a stride", "\"Buffalo Bill Letters\"", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "a horizontal desire", "Charlie Drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Asashoryu,", "because of what they had done to Muslims in the past,\"", "secretary of state", "Newcastle Falcons"], "metric_results": {"EM": 0.5, "QA-F1": 0.5828993055555556}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.26666666666666666, 0.7499999999999999, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-16336", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-2724"], "SR": 0.5, "CSR": 0.5270220588235295, "EFR": 1.0, "Overall": 0.7047794117647059}, {"timecode": 85, "before_eval_results": {"predictions": ["Punishment", "Postcards from the Edge", "birds", "Virginia", "hot chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "Hamlet", "\"Aired\"", "Wee", "Gertrude Stein", "John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi Hedren", "object oriented programming", "Nova Scotia", "coffee", "timber", "Absinthe", "Zeus", "marsupials", "quid", "(John Wilkes) Booth", "Anthony Newley", "Swimmer's Ear", "Henry", "frequencies", "Cyrillic", "Jeff Probst", "high school", "Nasser", "The Moment of Truth", "Laura", "Lupus", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "George Clinton", "the Black Sea", "Katharine Hepburn", "the dollar", "Young Frankenstein", "Shout", "to form a higher alkane", "comprehend and formulate language", "Hellenic Polytheism", "Venezuela", "The Shootist", "Sega Saturn", "the National Society of Daughters of the American Revolution", "Leonard (Johnny Galecki)", "44,300", "it has not", "At least 88", "1981 drowning death,", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\""], "metric_results": {"EM": 0.578125, "QA-F1": 0.6964743589743589}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.5, 0.5, 0.0, 0.9743589743589743]}}, "before_error_ids": ["mrqa_searchqa-validation-2788", "mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-7459", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-10836", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-16963", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-2819", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.578125, "CSR": 0.5276162790697674, "EFR": 1.0, "Overall": 0.7048982558139535}, {"timecode": 86, "before_eval_results": {"predictions": ["John Garfield as Al Schmid", "at a given temperature", "season ten", "October 28, 2007", "seven", "absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "in Egypt", "privatized", "Stephen A. Douglas", "fled to exile in the Netherlands", "the 9th century", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "Atelier de Construction", "Egypt", "the base of the right ventricle", "beer brewed", "Justin Timberlake", "Solange Knowles & Destiny's Child", "relative to the player", "Earle Hyman", "Husrev Pasha", "Anna Maria Demara", "The Osmonds", "735 feet ( 224 m )", "It is a homodimer of 37 - kDa subunits", "shredded cheese", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the biblical Book of Exodus", "cartilage", "SIP ( Session Initiation Protocol )", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "innermost in the eye while the photoreceptive cells lie beyond", "Donna Mills", "Donna", "Annette Crosbie", "Bobby Kennedy", "Minder", "leopard", "Tim Burton", "Association of Commonwealth Universities", "St. Paul, Minnesota.", "102", "two", "\"Like a Rock\"", "cats", "George III", "Norway"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6653307629870129}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 1.0, 0.9166666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, 0.20000000000000004, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.28571428571428575, 0.14285714285714288, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-5113", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-3582", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-366"], "SR": 0.546875, "CSR": 0.5278376436781609, "EFR": 0.9310344827586207, "Overall": 0.6911494252873563}, {"timecode": 87, "before_eval_results": {"predictions": ["Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "the Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teen Titan Go!", "a skerry", "Book of Judges", "torpedo boats", "9 February 1971", "San Francisco, California", "\"Three's Company\"", "9,984", "Cecily Legler Strong", "Marktown", "the Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237", "timeline of Shakespeare criticism", "Balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden, on the southern coast", "Noel Gallagher", "James Gandolfini", "U2 360\u00b0 Tour", "Michael Jordan", "Scarface", "Austro-Hungarian Army", "St. George", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "Nova Planta Decree of Majorca and Ibiza", "Vancouver", "Urijah Faber", "four", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "those at the bottom of the economic government whom the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "the 1920s", "Blue laws in the United States", "James Hargreaves", "Puff the Magic Dragon", "Hindi", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "the composer of \"Phantom of the Opera\" and \"Cats\"", "Thesaurus", "Bath", "Winnipeg", "a greeting which is used by some on birthdays, and by others in response to `` Merry Christmas '' and `` Happy New Year ''"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6612854737854739}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.5, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 0.5714285714285715, 1.0, 0.5, 1.0, 0.0, 0.0, 0.25, 0.0, 1.0, 0.0, 0.12121212121212123]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4507", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-2094", "mrqa_searchqa-validation-2044", "mrqa_searchqa-validation-15272", "mrqa_naturalquestions-validation-9361"], "SR": 0.546875, "CSR": 0.5280539772727273, "EFR": 1.0, "Overall": 0.7049857954545455}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as many as 250,000", "Ameneh Bahrami", "40", "state senators", "2007", "by text messaging", "Hawaii.", "Haiti", "Brazil's", "\"wow.\"", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "the burning World Trade Center", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "left without loved ones, without homes, without life's belongings.", "Jason Chaffetz", "summer", "in the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "allegedly involved in forged credit cards and identity theft", "that anything could have stopped Robert Hawkins from going on a murderous rampage at an Omaha, Nebraska, shopping mall on Wednesday.", "Ricardo Valles de la Rosa", "Islamabad", "Toffelmakaren", "Wednesday", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra", "Nigeria", "201-262-2800", "South Africa", "very dark and very cold place.", "Chad", "President Obama", "Tuesday", "to reach car owners who haven't complied fully with recalls.", "Mashhad", "Plymouth Rock", "Alina Cho", "Spaniard Carlos Moya", "last week", "a treadmill", "\"Osama's alive,\"", "10", "second", "Central Germany ( German : Mitteldeutschland )", "Rust", "gastrocnemius muscle", "Granada", "Hickory", "Portugal", "June 17, 2007", "England", "Black Elk", "Mornay", "Kwanzaa", "\"TO LOOK GUILTY\"", "Javan leopard"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7204736053420264}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 0.8571428571428571, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5263157894736842, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.5, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3110", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-1201", "mrqa_naturalquestions-validation-8625", "mrqa_triviaqa-validation-6987", "mrqa_searchqa-validation-2749"], "SR": 0.609375, "CSR": 0.5289676966292135, "EFR": 1.0, "Overall": 0.7051685393258428}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "Michael Michael Schibbye and Persson", "killing rampage.", "Eintracht Frankfurt", "they did not receive a fair trial.", "federal officers' bodies", "American Bill Haas", "Larry Ellison,", "have been unable to pass significant restrictions on war funding", "a renaissance of the game in the region.", "Joan Rivers", "Mitt Romney has scored the endorsement of Bob Dole,", "Lt. Lauri Burgett,", "KBR", "Coptic Christians", "Alicia Keys", "two years", "the body of the aircraft", "North Korea", "chairman of the House Budget Committee,", "pattern matching.", "Teen Patti", "almost 9 million", "U.S. senators", "American wielding a big stick", "London and Buenos Aires", "escaped injury", "Nazi Germany", "President Obama", "a bank", "two", "illegal immigrants", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States", "Sunday,", "is a city of romance, of incredible architecture and history.", "Stella McCartney", "clogs", "debris", "Alicia Keys", "ALS6", "The EU naval force", "over 1,000 pounds", "Iran's Green Movement of protesters", "make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "provides nearly $162 billion in war funding", "Kathrin Hoelzl", "three", "postero - medially towards the optic chiasm", "Hugo Weaving", "aragonite", "Lester", "Olympia", "Bruce R. Cook", "Los Angeles, California", "86,112", "(Lewis) Carroll", "a soap opera", "the CPI", "Penrhyn Castle"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5907557975113122}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.26666666666666666, 1.0, 0.2, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.923076923076923, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-3753", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-213", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_hotpotqa-validation-2460", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.453125, "CSR": 0.528125, "EFR": 1.0, "Overall": 0.7050000000000001}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon", "Ebony", "Cook County", "Sartre", "Wordsworth", "Boston", "James K. Polk", "Harpy", "lacrosse", "Naples", "a Dormouse", "the Jews", "a cow pie", "Paradise Lost", "Beautiful", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "an earthquake", "\"Breezes Of\"", "Actress", "The Bionic Woman", "the multitude", "a tan", "Narnia", "a comet", "Mount Sinai", "Kamehameha", "(Elbert) Gary", "an epitaphic", "crowded", "\"Duke\"", "Orlans", "The Wall", "Pulp Fiction", "Hester Prynne", "pajamas", "China Airlines", "bagpipe", "a stork", "shushed", "Henry David Thoreau", "Encephalitis", "Fiji", "Sydney", "central Saskatchewan", "Ellen is restored to life and is married to Bobby", "The long - hair gene", "tenerife", "Another Day in Paradise", "The Danelaw", "Donald Wayne Johnson", "Robert Allen Iger", "Manchester Airport", "Iowa,", "16", "Japan", "financial gain,"], "metric_results": {"EM": 0.625, "QA-F1": 0.6721354166666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-5423", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-257", "mrqa_searchqa-validation-7563", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-15887", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-4827", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-10583", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-793", "mrqa_hotpotqa-validation-4724", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.625, "CSR": 0.5291895604395604, "EFR": 0.9583333333333334, "Overall": 0.6968795787545787}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff", "track cycling", "Light Middleweight", "Christopher Nolan", "Johann", "highball", "Conan Doyle", "Godiva", "the brain", "six", "Bashir", "dog sport", "The Double", "arsenic", "beta", "Mickey Mouse", "volume", "The Welcome Stranger", "the recorder", "UAE", "Genesis", "Ladysmith", "californium", "Oscar De La Hoya", "Arizona Diamondbacks", "George Orwell", "Golda Meir", "Marc Brunel", "\"to the tooth,\"", "William Shakespeare", "1960's", "Some Like It Hot", "Beaujolais", "morphine", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "Roger of Montgomery", "St. Thomas \u00e0 Becket", "bullfighting", "leicestershire", "cycling", "Crimean Tatar", "bedding", "Switzerland", "Shanghai", "Duke Orsino", "Girl Scout Promise", "the Swordfish", "France", "New South Wales", "France", "17 - year - old Augustus Waters", "1898", "January 1923", "South Asian Games", "Ramanaidu Daggubati", "four", "1,500", "12", "38 feet", "the Marquis de Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6183035714285714}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7142857142857143, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-1651", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-3037", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-369", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134"], "SR": 0.546875, "CSR": 0.5293817934782609, "EFR": 0.9655172413793104, "Overall": 0.6983548069715143}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "1979 to 2013", "two", "1987", "Meghan Markle", "2006", "alcoholic drinks", "Seoul", "Dutch", "Director of Central Intelligence", "political correctness", "Russell Humphreys", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "November 23, 2011", "over 3 million", "Mazda Capella", "Jack St. Clair Kilby", "\"Seducing Mr. Perfect\"", "water", "more than 70", "Black pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko Takeshita", "\"Apatosaurus\"", "TD Garden", "homosexuality, gay sex, and the gay bear subculture", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"short windward\", referring to the fact that this is the shorter of the two windward districts on the island", "2013", "Washington", "Prudence Jane Goward", "Vince Guaraldi", "\"What's My Line?", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Lauren Lane", "Archduke of Austria", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "defense against rain rather than sun", "European Central Bank", "Jane Seymour", "Willie Nelson", "1984", "Argentine", "15", "Ali Bongo", "Antietam", "your medical bills", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6848815247252747}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-5328", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-2770", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.5625, "CSR": 0.5297379032258065, "EFR": 1.0, "Overall": 0.7053225806451613}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "stand-up comedian", "Edward R. Murrow College of Communication", "Liesl", "Stage Stores", "training Day", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "High Knob", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the Provisional Irish Republican Army", "Tel Aviv", "Chevy", "nature of human sexual response", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "Yolande Cornelia \" Nikki\" Giovanni, Jr.", "Robert Sylvester Kelly (born January 8, 1967), known professionally as R. Kelly,", "2013", "Jericho Union Free School District", "January 15, 1975", "John R. Dilworth", "actor and former fashion model", "18.7 miles", "Dyn, Inc.", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Fordyce", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich is a suburb in the City of Burnside, Adelaide, South Australia", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow", "George Martin", "Timo Hildebrand", "Adam Dawes", "Maasai phrase \"Enkare Nairobi\"", "Rockland, Maine", "2009", "Vietnam War", "Toto", "9 February 2018", "Todd Griffin", "Gabriel Byrne and Kevin Spacey", "Funchal", "British", "Scudetto", "it would", "to \"move down\" from the new-car market", "Caroline Ponsonby", "Florida", "Africa", "Agriculture"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6408617424242424}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2095", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-3226", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694", "mrqa_searchqa-validation-15207"], "SR": 0.53125, "CSR": 0.5297539893617021, "EFR": 1.0, "Overall": 0.7053257978723405}, {"timecode": 94, "before_eval_results": {"predictions": ["\"if a man does not keep pace with his companions, perhaps it is because he hears a different drummer.\"", "Hitler", "\"Wings,\"", "Simon Cowell", "their last", "the neon sign", "lifejackets", "Ian Fleming", "the Shrew", "Anne Frank's", "Bora Bora", "My Name Is Earl", "Nassau", "a geisha", "France", "the Barbary pirates", "CIA", "antimicrobial", "the iPhone", "the Temptations", "Phonetics", "Crosby, Stills & Nash", "Frasier", "plants", "a balloon", "the Court of Cassation", "Chiapas", "\"Jeopardy\"", "Afghanistan", "Australia", "water buffalo", "Asia", "the College of Dental Medicine", "pitch", "Pete Rose", "Queen Esther Hadassa", "South Africa", "Bacall", "Goldeneye", "agriculture", "Dumbo", "Edith Wharton", "Bonnie Raitt", "marsupials", "Italian", "The Crow", "Lou Gehrig", "the Ambersons", "the mongoose", "Russell Crowe", "Ecuador", "only apocalyptic document in the New Testament", "four", "elected from the citizens of the jurisdiction in which they serve", "Friends", "frankincense", "the solar system", "Robert the Bruce", "the series \"Runaways\"", "Pieter van Musschenbroek", "Seoul", "\" Fortunately, I've been feeling better every single day since surgery and this weekend my doctors gave me the green light to get back to work.\"", "the Klan experienced a huge resurgence.", "The Krankies"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5970734126984127}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [0.1111111111111111, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-1782", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-1024", "mrqa_searchqa-validation-13172", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-11593", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-11108", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-991", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-804", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_searchqa-validation-1165", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.484375, "CSR": 0.5292763157894738, "EFR": 0.9696969696969697, "Overall": 0.6991696570972887}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "Teaching at Houghton", "Lady Godiva", "Beat The Clock", "Dame Ninette de Valois", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "a child", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "Donald Duck", "Joseph Haydn", "Willa Cather", "the Dow Jones Industrial Average", "Aunt Jemima", "the fowls", "New Kingdom", "The Iliad and The Odyssey", "The Amanda Show", "Ted Danson", "O. Henry", "middle-aged", "B.B. King", "Jacqueline Lee", "Donovan", "plankton", "Candlestick Park", "jointer plane", "compensation", "Vodka", "corned beef", "Adam", "women", "Ivy Dickens", "woozy", "Thor", "Panopolis", "calamine", "Sicily", "Admiral Horatio Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Caleb", "1957", "Hong Taiji", "The Hellfire Club", "\"Little arrows\"", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "at the exit in question,\"", "more than 4,000", "Teresa Hairston", "Pakistan"], "metric_results": {"EM": 0.578125, "QA-F1": 0.646875}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-6244", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-11613", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-4819", "mrqa_searchqa-validation-8870", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-1558", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-12050", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-417", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.578125, "CSR": 0.52978515625, "EFR": 0.9629629629629629, "Overall": 0.6979246238425926}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "Franking", "Unbreakable", "Holy Week", "Tijuana", "Wizard", "a byte", "Planned Parenthood", "Jamie Lee Curtis", "The Simpsons", "an Abduction", "Alexander Graham Bell", "north-east", "baffle", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "giant", "Medusa", "zoology", "Lucia di Lammermoor", "globes", "cricket", "Stephen Hawking", "St. Francis of Assisi", "luminous", "The Scarlet Letter", "2016", "drug rehab", "pastries", "The Hundred Years' War", "the Met", "milk and honey", "3", "a hump", "The Beatles", "Bronx", "saccharides", "King Kong", "Cubism", "Umbria", "hoop cheese", "Mcescher", "Oahu", "urine", "Scott Fitzgerald", "aria", "Dorothy Aykroyd", "Marquette University", "the monk", "Fall 1998", "irritation", "Bart Howard", "the Netherlands", "Marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "in early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.625, "QA-F1": 0.7072916666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16364", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-7573", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.625, "CSR": 0.5307667525773196, "EFR": 0.9583333333333334, "Overall": 0.6971950171821306}, {"timecode": 97, "before_eval_results": {"predictions": ["35 cm", "gold rings", "Gaston Leroux", "Concorde", "gold", "European Economic Community", "Canterbury and Lancaster", "Vietnam", "Florentius", "Wanderers", "Emilia Fox", "Amnesty International", "Krak\u00f3w", "Shaft", "gal", "Ramadan", "Bizet", "Count Basie Orchestra", "Pegida", "plutonium", "Sheree Murphy", "Edward Hopper", "Einstein", "Faversham", "Justin Trudeau", "Julia Roberts", "Time Team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "Andes", "Christian Wulff", "a wish", "usk", "spider", "Malcolm Turnbull", "Daily Herald", "Nairobi", "Alan Turing", "ilage", "the heart's conduction system", "Puck", "Hula-Hoops", "Dubonnet", "Pride and Prejudice", "Rocky Graziano", "Sweater", "Today newspaper", "Today", "Gene Vincent", "Midgard", "changes in gene expression", "The Chesapeake", "Ben Faulks", "a Taylor series", "part of the flotilla that attacked the radar station in Dwarka, India", "Panic! at the Disco", "John Auer,", "Tuesday's iPhone 4S", "Christopher Savoie", "Plouton", "Ingenue", "World War I", "Joseph"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6070075757575757}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-2098", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_hotpotqa-validation-3784", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947"], "SR": 0.59375, "CSR": 0.5314094387755102, "EFR": 1.0, "Overall": 0.705656887755102}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "belfast", "Jerry Mouse", "mares' tails", "Procol Harum", "Alt", "armagh", "st. Ives", "Uganda", "st pancras", "lactic acid", "villefranche", "Robinson Crusoe", "told both news and rumours", "\u201cMy Favorite Martian,\u201d", "whist", "a fear of snakes", "Madagascar", "Wyatt", "July", "One Direction", "The West Wing", "Prince Harry", "1994", "titanium", "pushchair", "Pegasus", "Alaska", "james fimore Cooper", "Brazil", "the rhizome", "action", "eyes", "Ukrainian", "bowie knife", "Nile", "a rat", "Independence Day", "Tinie Tempah", "porto", "Catholic", "a collapsible support assembly", "beard", "an angel", "borough of Oldham, in Greater Manchester, England", "The Sunday Post", "Bobby Darin", "emirate", "Nick Griffin", "mansfield park", "South Africa", "Ian Harrowell", "drivers who qualified for the 2017 Playoffs", "Florida", "twenty-three", "Mexican War on Drugs", "her relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi ethnic minority and the Hutu majority", "The Tempest", "Naples", "David", "heavier than a feather"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5521949404761904}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4444444444444445, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-4125", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_naturalquestions-validation-9588", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_searchqa-validation-6488", "mrqa_hotpotqa-validation-3713"], "SR": 0.484375, "CSR": 0.5309343434343434, "EFR": 0.9696969696969697, "Overall": 0.6995012626262627}, {"timecode": 99, "UKR": 0.767578125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.794921875, "KG": 0.5203125, "before_eval_results": {"predictions": ["\"The people kill him with the blocks,", "37th", "dismissed all charges", "U.S. Defense Department", "11", "inmates", "Kenyan", "prostate cancer", "Philip Markoff,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her;", "\"Red Lines,\"", "\"The Kirchners", "an African-American woman", "Arsene Wenger", "Arnold Drummond", "Carrousel du Louvre", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "during a world tour in the mid-1990s.", "Alejandro Peralta Alvarez,", "Kerstin Fritzl,", "Amnesty International.", "The Tinkler", "\"Here Comes the Sun.\"", "fill whatever vacuum the U.S. leaves behind.", "a lump in Henry's nether regions", "failed to obtain an agreement.", "snow,", "\"Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "at the school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "officers,", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "Three thousand", "burning of a church.", "The cause of the child's death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "about 2,000", "facing Lake Washington", "Cirque du Soleil", "9", "for the rest of the year", "hydrogen", "Bobby Darin", "foreign investors", "the neck", "wrigley", "CBS", "round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "Arthur Miller", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.59375, "QA-F1": 0.649043231074481}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.25, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793", "mrqa_searchqa-validation-6438"], "SR": 0.59375, "CSR": 0.5315624999999999, "EFR": 0.8846153846153846, "Overall": 0.6997980769230769}]}