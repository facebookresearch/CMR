{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4070, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "Los Angeles Times", "the Broncos", "anticlines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Atlantic", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "infected corpses", "United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "squared integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Buddhism", "Matthew 16:18", "U.S.-flagged Maersk Alabama", "Rwanda", "revelry", "his health", "American Hugo Vihlen", "the outskirts of a small Southern town"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7744791666666666}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-5112", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-4289", "mrqa_squad-validation-9655", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_squad-validation-8014", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.71875, "CSR": 0.7734375, "EFR": 0.8888888888888888, "Overall": 0.8311631944444444}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Mercury/Gemini", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "compensated for their patient care skills", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "The Spice Girls", "Johnsonkip", "the company's factory in Waterford City, Ireland", "nitrogen", "Annemarie Moody", "Agulhas Current Flow Rates", "six", "It always begins with the music", "conductor", "Illinois", "Rafael Palmeiro Corrales", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.78125, "QA-F1": 0.8033424908424909}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-235", "mrqa_squad-validation-3967", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936"], "SR": 0.78125, "CSR": 0.7760416666666666, "EFR": 0.42857142857142855, "Overall": 0.6023065476190476}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "Eastern Bloc city", "Sakya", "woodcuts", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "music", "Upper Lake", "northern China", "giving her brother Polynices a proper burial", "political figures", "President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "philanthropic initiative", "integer factorization", "necessity", "Isel", "adapted quickly and often married outside their immediate French communities", "former Pakistani Prime Minister Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "the Channel Islands", "in no way", "Alberich", "9", "How Emeril Really Feels About the Word", "Churchill Downs", "The port of Terneuzen", "tetrahedron", "in September 1955 20 million listeners tuned in to hear the \u2018everyday story of country folk\u2019.", "India", "study insects and their relationship to humans", "the limbic system", "Allan Border", "George Fox", "Maryland", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.671875, "QA-F1": 0.7099330357142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_hotpotqa-validation-3821"], "SR": 0.671875, "CSR": 0.75, "EFR": 0.6190476190476191, "Overall": 0.6845238095238095}, {"timecode": 4, "before_eval_results": {"predictions": ["in higher plants", "Parliament of Victoria", "Zaha Hadid", "the French", "Science and Discovery", "the Army", "pedagogy", "the red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "The Skirmish of the Brick Church", "the port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "2010", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "the Italian government", "22", "terror groups that they say were planning numerous suicide attacks, including in the country's largest city of Karachi.", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a new model is simply out of their reach", "Muslim", "will be the first time any version of the Magna Carta has ever gone up for auction", "The Closer", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "celebrity-inspired names", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "colombia"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7376632130124777}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3, 0.15999999999999998, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.71875, "CSR": 0.74375, "EFR": 0.8888888888888888, "Overall": 0.8163194444444444}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a high-level marketing manager, was given the job of turning the business around", "500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "1950s to 2011", "the characteristics of the conquering peoples", "German Te Deum", "1795", "Bermuda 419", "by compressing and cooling it", "Infinity Broadcasting Corporation", "semi-legal", "1972", "rudimentary", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "used in a compact layout to combine keys which are usually kept separate", "from an Ohio newspaper on 8 February 1925", "President since Woodrow Wilson, with the notable exception of Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "the correct angle \u03b8 to aim so as to hit the target at the edge of the turntable", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey, the United Kingdom", "member states on a voluntary basis. As of 31 December 2013, the total size of the peacekeeping force is 98,200 police, troops, and military experts", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada on December 10, 2007", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman reprising his role as detective Alex Cross", "David Gahan", "Overlook Hotel in his 1977 bestseller The Shining and its 1980 film adaption of the same name, as well as the location for the 1997 miniseries", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the day before Ash Wednesday and usually falls between February 3 and March 9", "Jaipur", "Johan Persson and Martin Schibbye", "torpedo boat destroyers", "Newport"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6610128929789206}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.45454545454545453, 0.1111111111111111, 0.0, 0.13793103448275862, 0.0, 1.0, 1.0, 0.0, 0.3448275862068965, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.5, 0.08333333333333334, 0.5833333333333334, 0.2666666666666667, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4836", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-7488", "mrqa_squad-validation-3473", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.578125, "CSR": 0.7161458333333333, "EFR": 0.8888888888888888, "Overall": 0.802517361111111}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "the New Birth", "gold", "a 3\u20130 lead", "Vivienne Westwood", "reduction", "disease", "TGIF", "Confucian propriety and ancestor veneration", "Luther's rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members in good standing with the college, and private schools may also require their teachers to be college peoples", "end of the season", "10", "Jacob", "African-Americans", "will not support the Stop Online Piracy Act", "Chuck Bass", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea's reclusive leader Kim Jong- Il", "first five Potter films", "know what's important in life", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "James Whitehouse", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "Church of Christ, Scientist", "unsaturated fats are comprised of lipids that contain?", "Luke 6 : 67 -- 71"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7225308819470004}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.2666666666666667, 0.5, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.75]}}, "before_error_ids": ["mrqa_squad-validation-800", "mrqa_squad-validation-2133", "mrqa_squad-validation-486", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.640625, "CSR": 0.7053571428571428, "EFR": 0.782608695652174, "Overall": 0.7439829192546583}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased trade with poor countries", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "prolamellar body", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "up to \u00a339,942", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "\"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto", "at the country's third-largest oil refinery", "April 24 through May 2", "Krishna Rajaram", "early detection and helping other women cope", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "William S. Cohen", "\"Dance Your Ass Off\"", "military trials for some Guant Bay detainees", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "a \"stressed and tired force\" made vulnerable by multiple deployments", "Japan", "repairing", "British author J.G. Ballard, whose boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun", "Norman given name Robert", "Olympics", "Matthew Ward Winer", "Doc Holliday", "opposite R\u00fcgen island", "Mustique", "green"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6629940115498496}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9032258064516129, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 0.2608695652173913, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-8883", "mrqa_squad-validation-1556", "mrqa_squad-validation-2091", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-417", "mrqa_newsqa-validation-3281", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-2858"], "SR": 0.59375, "CSR": 0.69140625, "EFR": 0.7692307692307693, "Overall": 0.7303185096153846}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "The British provided medical treatment for the sick and wounded French soldiers", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "\"Journey's End\"", "immediate", "Levi's Stadium", "Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Einstein", "fast forwarding", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "separated", "Animal Planet", "crashing his private plane into a Florida swamp.", "there were no radar outages and said it had not lost contact with any planes", "54 bodies", "early detection", "Diversity", "$250,000", "to alleviate the flooding", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "2050", "Alfredo Astiz, a former Navy captain whose boyish looks and deceitful ways", "Abdullah Gul", "Carl Froch", "The Everglades, known as the River of Grass,", "The original chromosome and the copy are now called sister chromatids", "Gibraltar", "New Orleans, Louisiana", "many investors paying huge sums for individual bulbs", "Captain Steven Hiller", "eat too many chockies, these, & you may find yourself crook,", "Give up-to-date St. Louis Blues statistics, schedules, rosters and much more on Hockey-Reference.com."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6685810899626689}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0909090909090909, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 0.3076923076923077, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3910", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6805555555555556, "EFR": 0.7307692307692307, "Overall": 0.7056623931623931}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "His wife Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"coo\", \"hoos\" and \"strang\"\u2014which is how they were pronounced in the Anglo-Saxon language.", "30%\u201350%", "very badly disposed towards the French, and are entirely devoted to the English.", "United States", "CRISPR sequences", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement.", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "providing the basic securities that Turkey can be a great partner.", "average of 25 percent", "a gym", "Jennifer Arnold and husband Bill Klein, who both have skeletal dysplasia, a bone-growth disorder that causes dwarfism,", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "two and a half hours", "Elin Nordegren", "Europe, Asia, Africa and the Middle East.", "6,000", "the banned substance cortisone.", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star,", "Morgan Tsvangirai.", "policing the world and Africa", "liquidity", "in a canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school, their books burned, as the hard-core Islamic militants spread their reign of terror across parts of Pakistan.", "strife in Somalia", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia Police Department.", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "after Shawn's kidnapping", "the immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "OutKast", "Groundhog Day", "\" Cleopatra, Queen of Denial\"", "a singer who takes a job working with a struggling carnival."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6214968194635714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.08, 0.4, 0.0, 0.5217391304347825, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 0.5, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.53125, "CSR": 0.665625, "EFR": 0.6666666666666666, "Overall": 0.6661458333333333}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan", "water", "internal strife", "yellow fever", "DC traction motor", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "Friday", "fractured pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "snow, sleet, freezing drizzle or rain.", "Willem Dafoe", "Maude", "Phillip A. Myers", "Korean military", "two weeks after Black History Month was mocked in an off-campus party that was condemned by the school.", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Spc. Megan Lynn Touma,", "Dangjin", "e-mails", "Hu Jintao", "magazine", "The teen faces a lifelong recovery from his injuries,", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett - Wines made with fully ripened grapes.", "Lionsgate.", "James Lofton", "Mysticism", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.65625, "QA-F1": 0.7193959686147187}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.14285714285714285, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.65625, "CSR": 0.6647727272727273, "EFR": 0.8181818181818182, "Overall": 0.7414772727272727}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "The Soup Dragon", "antelope", "nipples", "the Triassic Period", "pio-  neers' Society, Ltd.", "Anastasia Dobromyslova", "Lady Gaga", "9", "Blake Griffin", "radish", "Robert Ludlum", "a great power", "shuttle", "The Donington Grand Prix Collection is, quite simply, the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "The London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Massachusetts", "2005", "1971", "Chrysler", "dolt", "Rome", "petticoat", "Enrico Caruso", "Elizabeth Arden", "lightweight baby buggy with a collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "the 14th most common surname in Wales and 21st most common in England", "Can't Get You Out of My Head", "Ray Looze", "The 6-story building, previously used as a meat cold storage facility, had no windows above the ground floor and no fire detection or suppression systems.", "Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6329832740671204}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.2608695652173913, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.4444444444444444, 0.0, 0.0, 0.27586206896551724, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.546875, "CSR": 0.6549479166666667, "EFR": 0.7931034482758621, "Overall": 0.7240256824712644}, {"timecode": 12, "before_eval_results": {"predictions": ["Southern Border Region", "70-50's", "Panini", "new laws or amendments to existing laws as a bill; a committee of the Parliament can present a bill in one of the areas under its remit", "anti-colonial movements", "the Rhine Valley", "A", "by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship.", "\"so long as\" the EU works towards the democratisation of its institutions, and has a framework that protects fundamental human rights,", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Lowestoft", "Jessica Simpson", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "Eric Pickles", "Sir Hugo Drax", "Vladivostok", "Sheryl Crow", "TESLAR Satellite", "Camellia sinensis", "AFC Wimbledon", "Charles Hawtrey", "Malaysia's capital Kuala Lumpur", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "a pluvial was an extended period of abundant rainfall lasting many thousands of years.", "the United States", "Brigit Forsyth", "Lord Melbourne", "\"Land of the Rising Sun\"", "The Tragedy of Troilus and Cressida", "David Lean", "Kent", "Renoir\u00b4s art historian, collector, and editor of the Gazette des Beaux-Arts Charles Ephrussi,", "the Standard Motor Company", "white", "Switzerland", "gin", "people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "bremen", "David", "\"The Screening Room\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6474798387096774}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8387096774193548, 0.26666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9452", "mrqa_squad-validation-6655", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-1262", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_newsqa-validation-3860"], "SR": 0.609375, "CSR": 0.6514423076923077, "EFR": 0.72, "Overall": 0.6857211538461538}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "the Black Death", "their own militia", "days, weeks and months", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "god of Weddings", "gods", "albinism", "the Suez Canal", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "crazed Holiday", "The Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "lizard", "strong cold southwest wind", "table tennis", "cMAJ", "penhaligon", "Gandalf", "monsieur C. Auguste Dupin", "Jinnah International", "Monday", "capital of Venezuela", "beads", "soap", "highball", "Avro", "\"Follow You Follow Me\"", "Charlie Brooker", "melon balm leaves and flowers can be steeped a bit longer, up to 15 minutes, to release more of its lemony flavor.", "harrods", "2007", "Christina Ricci", "Scarface", "pale yellow to golden", "Everest", "bubba", "June 12, 2018", "Filipino American", "London's West End", "Lambic", "Nook", "Steven Green", "c", "cunY-CoLAG", "coder", "Synchronicity"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6177083333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-6933", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6708", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_naturalquestions-validation-3162", "mrqa_hotpotqa-validation-5340", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-6628"], "SR": 0.5625, "CSR": 0.6450892857142857, "EFR": 0.8571428571428571, "Overall": 0.7511160714285714}, {"timecode": 14, "before_eval_results": {"predictions": ["seven months old", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep in peace", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "decline state of mind", "13 May 1899", "The Deadly Assassin and Mawdryn undead", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1936", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "World Trade Center", "Kevin Spacey", "1 November", "78", "white blood cell", "International Border", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "January 12, 2017", "United States", "claims adjuster", "uterus and uterine tubes", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "annual plants", "long", "Kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "a police badge", "BBC building in Glasgow, Scotland", "a thick stack of paper"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6522264194139193}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 0.0, 0.5, 0.2857142857142857, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2339", "mrqa_squad-validation-2523", "mrqa_squad-validation-1454", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.53125, "CSR": 0.6375, "EFR": 0.9, "Overall": 0.76875}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "late night talk shows", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "octave", "1962 World's Fair", "Battle of Antietam", "the award was shared between three players both times", "In Time", "by the early 3rd century the cross had become so closely associated with Christ that Clement of Alexandria", "Glenn Close", "four times", "Agostino Bassi", "The first five seasons of Prison Break have been released on DVD and Blu - ray in Regions 1, 2, and 4", "Malibu, California", "The letter was written to the church at Philippi, one of the earliest churches to be founded in Europe", "Dutch navy captain Jurriaen Aernoutsz", "September 2017", "Sergeant Himmelstoss", "1546", "tranjane fonda", "Bhupendranath Dutt", "Grey Wardens", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "December 19, 1971", "Uruguay defeated Argentina 4 -- 2 in front of a crowd of 68,346 people", "Alex Skuby", "Thomas Middleitch", "The National Legal Aid & Defender Association ( NLADA ) is the oldest and largest national, nonprofit membership organization devoted to advocating equal justice for all Americans", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of National Intelligence", "Defence Against the Dark Arts teacher", "Isaiah Amir Mustafa", "May Bates", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "a 17 - year - old African American in his office", "Rachel Kelly Tucker", "Bohemia", "boisea trivittata", "Code 02PrettyPretty", "musician", "opposition group, also known as the \"red shirts,\"", "the abduction of minors", "$6.2 trillion", "a poet, teacher, and feminist", "Stage Stores", "1881"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5398094177082664}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.2, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.28571428571428575, 1.0, 0.2222222222222222, 1.0, 0.10526315789473684, 1.0, 0.6666666666666666, 1.0, 0.09523809523809523, 1.0, 0.3157894736842105, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.15384615384615385, 0.0, 0.5, 0.37037037037037035, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7736", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5271", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_searchqa-validation-13473", "mrqa_searchqa-validation-5103"], "SR": 0.421875, "CSR": 0.6240234375, "EFR": 0.8648648648648649, "Overall": 0.7444441511824325}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Robert Watson", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Western Xia", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Office", "SAVE", "SAS Fr\u00f6sundavik Office Building", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson", "Sir William McMahon", "the North Sea", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "Pakistan Aeronautical Complex (PAC)", "Delacorte Press", "Neighbourhoods", "Secretariat", "Marcus Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "South Africa", "Surrey", "The Girl", "Charles Russell", "Boyd Gaming", "Anthony Davis of the New Orleans Pelicans", "1991", "Glenn Close", "Mary Welch", "Neighbours", "Ewan McGregor", "2011", "Alice Lloyd College", "a enslaved African American who led", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6644040854978355}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 0.2857142857142857, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8509", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5514", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.5625, "CSR": 0.6204044117647058, "EFR": 0.9642857142857143, "Overall": 0.79234506302521}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "inner chloroplast membrane", "Charlie Harper", "steveland Hardaway Morris", "Beaver", "La Boh\u00e8me", "formic acid", "Talavera de la Reina", "Zimbabwe", "Mr. Boddy", "Ted Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "London Pride", "a reference mark located on a ship\u2019s hull that indicates the maximum depth to which the vessel may be safely immersed when loaded with cargo", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "lagertha", "weight plates", "\"big house\"", "Hadrian", "the US", "flea", "Moonee Ponds, a suburb in Melbourne, Victoria.", "Hamburg", "mulberry", "Tangled", "The French Connection", "CBS", "Manchester United (13), Chelsea (4), Arsenal (3), Manchester City (2), Blackburn Rovers and Leicester City (1)", "Robert Cromposer", "Jessica Simpson", "the British public", "Corsican Republic", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "Union forces", "New Jewel Movement", "cetaceans (whales, dolphins, porpoises, etc.) from which they diverged about.", "U.S. 93", "Anjuna beach in Goa", "Ivanov", "Oshkosh", "two hits in 1965, \"Papa's Got a Brand New Bag\" and \"I Got You.\"", "jeopardy/1870_Qs.txt at master  jedoublen/jeopardy", "\"The Sunday Thing\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6054819595410628}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.08695652173913042, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.375, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.5625, "CSR": 0.6171875, "EFR": 0.6428571428571429, "Overall": 0.6300223214285714}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "extremely high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "Coppolas and, technically, the Farrow / Previn / Allens", "Anna Faris", "peninsular mainland", "Aphasia is an inability to comprehend and formulate language because of damage to specific brain regions", "Splodgenessabounds", "Tyrion", "electron donors", "Alison", "( 1985 -- 1993 )", "775 rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Alice", "20 November 1989", "Coton in the Elms", "55 -- 69 %", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "1995", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "Killer Within", "Western Australia", "arterioles", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "an optional message body", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "a violation of nature", "September 2017", "moral", "Rising Sun Blues", "Part 2", "1941", "the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "jegna", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6665521032974593}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 0.2857142857142857, 0.0, 0.6666666666666666, 0.4210526315789474, 1.0, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.59375, "CSR": 0.615953947368421, "EFR": 0.8461538461538461, "Overall": 0.7310538967611335}, {"timecode": 19, "before_eval_results": {"predictions": ["the law as the Holy Spirit's tool to work sorrow over sin in man's heart, thus preparing him for Christ's fulfillment of the law offered in the gospel.", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "CNN", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "any resources that could be found there", "Tuesday in Los Angeles.", "forgery and flying without a valid license", "Anil Kapoor", "19", "President Obama", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "sports cars", "11 healthy eggs and, this week, all 11 of them hatched -- the last one on Wednesday.\"", "Mutassim", "two Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18, the publicist said.The Glasgow, Scotland concert has been shifted from this Sunday to May 1,", "\"Stagecoach\" (William Wyler, 1959)", "NATO fighters", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "fast cars, drink and celebrity parties", "Kingman Regional Medical Center", "CNN", "Manmohan Singh", "Michael Jackson", "speak of a place called \"slaughter square\" where the Taliban leave the bodies of their victims with notes saying \"do not remove for 24 hours.\"", "40 militants and six Pakistan soldiers dead", "Roger Federer", "subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Louisiana", "Southeast", "Misty Croslin", "Carol Browner", "\"It's one thing that I learn at a very early age is I don't get caught up in gossip, the picture with the bong thing. It was a picture.\"", "a tracheotomy", "back at work", "Georgia Aquarium", "27", "Karina Smirnoff", "John Adams", "parsley", "Zager & Evans", "Bobby Hurley", "fourth term", "obscenity", "(Oliver) Cromwell", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5449371167781494}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.923076923076923, 0.6666666666666666, 0.8695652173913044, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-7208", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.421875, "CSR": 0.60625, "EFR": 0.918918918918919, "Overall": 0.7625844594594595}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "clothes that are consistent and accessible", "three empty vodka bottles,", "secretary of defense on China, Taiwan, Hong Kong and Mongolia, and was deputy director for strategy, plans and policy on the Army staff.", "Bobby Darin,", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "composer of \"Phantom of the Opera\" and \"Cats\" and one of Britain's richest men,", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's nuclear program.", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, soothing near-black on red-eyes when it's time to sleep.", "using recreational drugs", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "E! News", "three French journalists, a seven-member Spanish flight crew and one Belgian", "jobs", "saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "Mexican's attorney general's office responded with a statement saying that it would investigate the video and any group that tries to take justice into its own hands.", "Republicans", "full time into his company, Ripken Baseball, without taking any break, lessening the emotional jolt of retirement.\"", "Thessaloniki and Athens, where police killed the teen.", "signed a power-sharing deal with the opposition party's breakaway faction, his party said Tuesday, though Mugabe's opponents denied the claim.", "a dependable Camry know what's important in life,", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Gary Brooker", "jund Ansar Allah, or Soldiers of the Partisans of God,", "bogeyman Jason Voorhees", "\"The techniques they used were all authorized, but the manner in which they applied them was overly aggressive and too persistent,\"", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "about 50 formal applications", "Ku Klux Klan", "1939", "Branford College", "Bury", "stamens", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "mice followed, in the '80s | clone. right: Dave.", "Hodel", "access to US courts", "Coldplay"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4920192943630443}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.14285714285714288, 0.23076923076923078, 0.8, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.14814814814814814, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.19047619047619047, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.25, 1.0, 0.22222222222222224, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.390625, "CSR": 0.5959821428571428, "EFR": 0.7948717948717948, "Overall": 0.6954269688644688}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "Austria, Prussia, Russia, France, and also Poland,", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "both shoulders", "Madonna's", "Glasgow", "a satellite-based navigational system that can tell users exactly where they are on Earth.", "Australia", "Giblet s", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Lomond", "celibacy", "Tasmania", "medium-sized cat, fine-boned, long, and firmly muscled.", "capital of China", "Harrisburg", "mink mink,", "glockenspiel", "Dr John Sentamu", "national women's soccer team", "Cruella de Vil", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "charlemagne", "clubhouse", "Russell Crowe,", "Warren G. Harding", "ACC", "Puck", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "Michel", "Albert Square", "Newbury", "the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation", "Sister, Sister", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "GNGO", "Swamp Fox", "better conditions for inmates, like Amnesty International.", "Oprah Winfrey.", "his mother"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6560229700854702}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.578125, "CSR": 0.5951704545454546, "EFR": 0.8148148148148148, "Overall": 0.7049926346801347}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin", "reed", "Robert Peary", "pearls", "blackbird Hundreds.", "Carrie Underwood", "drambuie", "he made his horse a consul, his palace a brothel, and his...", "University of Michigan", "Langston Hughes", "Jimmy", "kramm", "Tito Puente", "riata", "unFINISHED", "lST", "prey drive", "Pele", "Arturo Toscanini", "economics", "Miracle", "proscenium arch", "Montenegro", "discus", "jedoublen", "basidiomycota", "james", "Ally McBeal", "Idi Amin", "deere", "a body, body part, or personal object associated with a saint", "terra cotta", "Plutarch", "lawyer and politician", "sourdough", "50", "the Vikings.", "74 Fairfield Street", "le quatorze juillet", "typhoid fever", "a long, narrow inlet formed by the partial submergence of an unglaciated river valley.", "baviere-quebec.org", "Williamsburg", "The telegraph", "University Post Office", "a chemical reaction to speed up but is not used up", "John Knox", "the internal reproductive anatomy", "$657.4 million in North America and $1.528 billion in other countries", "epidemiology is the study and analysis of the distribution and determinants of health and disease conditions in defined populations", "jape", "Tesco", "A4", "Norman Graham Hill", "the Battelle Energy Alliance", "IT products and services,", "debris", "$10 billion", "out in the woods"], "metric_results": {"EM": 0.375, "QA-F1": 0.47224886020841905}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.3076923076923077, 0.0, 1.0, 1.0, 0.0, 0.16666666666666669, 1.0, 0.5, 0.15384615384615385, 0.45454545454545453, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-1118", "mrqa_hotpotqa-validation-4804"], "SR": 0.375, "CSR": 0.5855978260869565, "EFR": 0.825, "Overall": 0.7052989130434782}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "the Chancel Chapel", "Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "cat", "the daughter of Tony Richardson and Vanessa Redgrave", "UEFA", "Argonauts", "prometheus", "Altamont Speedway Free Festival", "John F Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conductor", "a multi-user real-time virtual world described entirely in text.", "Italy", "khaki", "an igneous rock", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama,", "the Earth", "Nafea Faa Ipoipo?", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "an earthquake", "Fife", "Money Saving", "Adidas", "the Hunting of the Snark", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "the opponent's", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6995251225490196}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5725", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-5936", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848"], "SR": 0.65625, "CSR": 0.5885416666666667, "EFR": 0.7727272727272727, "Overall": 0.6806344696969697}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "Fox", "1997", "a suite of network protocols", "Noriko Savoie", "15", "first home series defeat on Australia in almost 16 years", "between Pyongyang and Seoul", "killed a man, the latter cheated on his wife.", "11", "fly following a regular maintenance service on December 25, 2009,", "Alwin Landry's supply vessel Damon Bankston", "Jason Chaffetz", "money or other discreet aid for the effort if it could be made available,", "Sarah", "illegal crossings into U.S. waters.", "environmental", "Italy in the quarterfinals,", "Afghan security forces", "Saturday", "38", "70,000 or so", "climatecare, one of Europe's most experienced providers of carbon offset,", "E! News", "coach", "Steve Williams", "McDonald's", "writing her short stories", "pastor Paula White", "2008", "Diego Maradona", "Dog patch Labs", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"  - the central attraction of golf remains at all the film's core.", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Liza Murphy", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state.", "At least 33", "five", "improve health and beauty.", "contraband", "that students can help stop crime from happening.", "Alwin Landry's", "Krishna Rajaram,", "Sunday,", "killing", "sinead", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radar", "art", "NBA All-Star Game and All-NBA Team", "23", "South America", "freestyle", "the Nightingale Museum", "the Crystal Skull"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5999197327457025}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5555555555555556, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.125, 0.0, 1.0, 1.0, 0.4, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.5, 0.4444444444444445]}}, "before_error_ids": ["mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3338", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.4375, "CSR": 0.5825, "EFR": 0.9444444444444444, "Overall": 0.7634722222222222}, {"timecode": 25, "before_eval_results": {"predictions": ["its 50th anniversary special", "Thomas Savery", "Vicodin, generically known as hydrocodone", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "separatist", "Eleven", "269,000", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "38 feet", "Eintracht Frankfurt", "150", "a man had been stoned to death by an angry mob.", "Russian bombers", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "the shoreline of the city of Quebradillas.", "Russian air force", "34", "The president ordered the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "customers", "Tom Baer.", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "a two-piece bathing suit", "Brian Mabry", "iTunes, which completely changed the business of music,", "Sunday", "60 euros", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "some truly mind-blowing structures", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego", "five prostitutes and a runaway involved in the drug trade.", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "keystroke", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "National Police", "heart", "Hyderabad", "Sinai Peninsula or simply Sinai ( / \u02c8sa\u026ana\u026a / ; Arabic : \u0633\u064a\u0646\u0627\u0621\u200e S\u012bn\u0101\u02bc", "to stay, abide", "Las Vegas Boulevard, commonly referred to as the Las Vegas strip, or the strip, is where many of the flashier and best known casinos operate.", "Jackson Pollock", "Lyrical", "Mississippi", "October 4, 1970", "King Duncan", "Brasstown Bald", "thimble", "a stride."], "metric_results": {"EM": 0.390625, "QA-F1": 0.4884369521499456}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.8750000000000001, 1.0, 0.6666666666666666, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2777777777777778, 0.4444444444444445, 1.0, 0.0, 0.07407407407407408, 0.6666666666666666, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1422", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832"], "SR": 0.390625, "CSR": 0.5751201923076923, "EFR": 0.7692307692307693, "Overall": 0.6721754807692308}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "pro-democracy activists clashed Friday with Egyptian security forces", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot.", "Hong Kong's Victoria Harbor", "2002", "seven", "the legitimacy of that race.", "if it make you want to save the rainforests,", "three", "Monday", "Scarlett Keeling", "two years,", "nearly 28 years", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "July for A Country Christmas,", "Akshay Kumar", "Graham's wife", "\"against people who independent of their race, religion, ethnicity, social condition etc. accepted money and put themselves at the service of the army in an area that is the object of military operations.\"", "\"disagreements\" with the Port Authority of New York and New Jersey,", "during childbirth", "Michelle Rounds", "David Bowie,", "the death of Prince George's County police Cpl. Richard Findley,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri,", "dependable Camry", "sexual assault", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "in his 60s, is incarcerated at the Supermax prison in Florence, Colorado, as is Zayed.", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "the repeal of the military's \"don't ask, don't tell\" policy", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units within the National Health Service in England", "at least 90 % of the FCS maximum of 63 scholarship equivalents over a two - year period", "Matt Monro", "William Edward \"Jack\" Frost,", "the innermost digit of the forelimb", "1952", "25 million", "Peoria, Illinois", "Honolulu", "\"The eyes of these croaking critters usually bulge, but they retract & push down on the mouth to help in swallowing", "incense", "Ottoman Empire"], "metric_results": {"EM": 0.625, "QA-F1": 0.6785615079365079}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.72, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-10451", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-5856", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.625, "CSR": 0.5769675925925926, "EFR": 0.8333333333333334, "Overall": 0.705150462962963}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "bank robber John Dillinger,", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Seasons of My Heart", "Haleigh", "Whitney Houston", "Kris Allen", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "eight Indian army troopers, including one officer, and 17 militants,", "\"There's no chance of it being open on time.", "Karen Floyd", "14", "in a Starbucks this summer.", "BADBUL", "98", "2008", "near the Somali coast", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Pakistan's combustible Swat Valley,", "South Dakota State Penitentiary", "Iran", "November 26,", "people have chosen their rides based on what their cars say about them.", "in July", "The Red Cross, UNHCR and UNICEF", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "at the Form Design Center.", "fractured pelvis and sacrum", "Wednesday at the age of 95", "the abduction of minors.", "gun", "Jennifer Aniston, Marta Kauffman, co-creator of the series \"Friends\" and Kristin Hahn, who was the executive producer of \"The Departed.\"", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "apteka", "largest city", "beta blockers"], "metric_results": {"EM": 0.625, "QA-F1": 0.7704348211446225}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.38095238095238093, 1.0, 0.6666666666666666, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5333333333333333, 0.3636363636363636, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.33333333333333337, 1.0, 1.0, 0.1739130434782609, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4138", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3770", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-2108", "mrqa_newsqa-validation-436", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-14535"], "SR": 0.625, "CSR": 0.5786830357142857, "EFR": 1.0, "Overall": 0.7893415178571428}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "rule", "1981", "forgery and flying without a valid license,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "Genocide Prevention Task Force.", "shoot down the satellite", "Intel has systematically given PC makers and stores rebates to keep computers with AMD chips off the shelves.", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "13", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has,\"", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "The Rosie Show", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "For weeks,", "executive director of the Americas Division of Human Rights Watch,", "750", "300", "Matthew Fisher", "The Ski Train", "Boys And Girls alone", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "inconclusive", "5:20 p.m. at Terminal C", "environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5,600 people every year,", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "state and federal level.In January, U.S. Rep. Kevin Brady, a Texas Republican, introduced legislation that would let prisons jam cell-phone signals within their walls.", "a deceased organ donor,", "bragging about his sex life", "have a vertebral column ( spine ) ; invertebrates don't", "December 11, 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "Festival of Britain on London's South Bank.", "Douglas Hofstadter", "The Dark Tower series", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain", "Castle Rock", "anchovy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6856994987224794}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.9655172413793104, 1.0, 0.0, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.4, 1.0, 0.0, 1.0, 0.1904761904761905, 1.0, 0.1111111111111111, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-229", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_hotpotqa-validation-5376", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.5625, "CSR": 0.578125, "EFR": 0.8214285714285714, "Overall": 0.6997767857142857}, {"timecode": 29, "before_eval_results": {"predictions": ["stagnant", "poison", "estimated 438,000 species", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor.", "coaxial", "Pakistan A", "Everbank Field", "14 directly elected members, 12 indirectly elected members representing functional constituencies and 7 members appointed by the chief executive.", "the German Campaign of 1813", "John Churchill,", "1965", "Charles de Gaulle Airport", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1963", "coca wine", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Oryzomyini", "Tom Kartsotis", "2017", "Wayman Tisdale", "Mexico", "Kolkata", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "23 March 1991", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey", "Seminole and Miccosukee", "Virginia", "NBA Slam Dunk Contest.", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "a field in Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes,", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18, the IB Middle Years Program", "Bengal tiger", "off the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "Peter Townsend,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia", "peel and devein shrimp", "Australia"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6806662087912088}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.5, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8164", "mrqa_squad-validation-4347", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-2701", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.578125, "CSR": 0.578125, "EFR": 0.8518518518518519, "Overall": 0.7149884259259259}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Werner Nowitzki", "the Cecil B. DeMille Award", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E", "New Jersey", "Norse mythology", "86,112", "Celtic", "Ouse and Foss", "the United States and Canada", "British comedian", "Apatosaurus", "1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "national and international media,", "The Seduction of Hillary Rodham", "2005", "Lambic", "Tom Clancy's The Division", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "nuclear weapons", "Joseph E. Grosberg", "Chelsea Lately", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "New York", "discus thrower", "Aston Villa", "2005", "228", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post-Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7161553030303031}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.59375, "CSR": 0.5786290322580645, "EFR": 0.7692307692307693, "Overall": 0.6739299007444168}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "Silent Snow, Secret Snow", "Knott's Berry Farm", "Iowa", "A People's History of the United States", "Nassau", "mollusks", "HIV", "Martin Van Buren", "Shink Hansen systems", "Rigoletto", "aardwolf", "Beijing", "Roger Bannister", "Inuk", "Death Valley", "Yves Saint Laurent", "reindeer", "Fortinbras", "the War of 1812", "Anna Mary Robertson", "lunar", "Nevilles Superette", "The New York Times Fiction Best Sellers of 2004", "Spectacled bear", "charleston", "George Harrison.", "Monty Python and the Holy Grail", "cathode", "Milton Berle", "George Herbert Walker Bush", "Patrice Lumumba", "lunar module", "Almagro", "Dan Marino", "Mars", "a clownfish", "E = mc2", "Guru Pitka", "Las Vegas", "millet", "bee", "a Connecticut Yankee in King Arthur's Court", "orangutan", "Baja California", "Soothsayer", "Yitzhak Rabin", "Saul", "Gettysburg National Military Park", "Jack Gleeson", "Plank", "Buddhism", "Carl Johan", "Portugal", "John Mayall, Cyril Davies, Long John Baldry and Alexis Korner", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million people worldwide"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6306919642857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.42857142857142855, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-13033", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.59375, "CSR": 0.5791015625, "EFR": 0.9230769230769231, "Overall": 0.7510892427884616}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Herbert Henry Asquith", "40", "Libya", "Shania Twain", "Sheffield Wednesday", "glucagon", "The New York Yankees", "rapid eye movement", "green, red, white", "Ann Dunham", "Prime Minister Abd al-Karim Qasim", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Sarah Ferguson", "Mercury", "power factor of one", "Tom Jones", "Subway's", "Madagascar", "Swansea City", "Gatcombe Park", "Rio de Janeiro", "his faith that \"something will turn up\"", "74", "Jennifer Lopez", "1664", "Eurythmics", "Fred Perry", "Downton Abbey", "Martina Hingis", "a painter", "cyclops", "Watch with Mother", "Michael Miles", "Sheryl Crow", "Gulliver's Travels", "piers", "Milan", "Mike Skinner", "Appalachian Trail", "a black Ferrari", "The word \"algebra\"", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone.", "providing the basic securities that Turkey can be a great partner.", "Jennifer Aronofsky", "a Swiss typeface", "lungs"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5352128623188406}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.08695652173913043, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-7490", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6656", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.46875, "CSR": 0.5757575757575757, "EFR": 0.7647058823529411, "Overall": 0.6702317290552584}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "chicken Caesar", "Hudson Bay", "florida", "hay fever", "abigail Masham", "Getafix", "Brighton", "Belfast", "wind", "fire", "Robin Hood's", "West Point", "Andy Warhol", "La Mancha", "John T. Cable", "Paz", "solar system", "potatoes", "Moldova", "Mitsubishi A6M Zero", "warblers", "Franz Liszt", "Estimate", "a boudeur-rouleur", "clon", "Pet Sounds", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Manila", "beaver", "Mel Blanc", "leopard", "mccitt", "Ellen DeGeneres", "Phil Woolas", "5000 meters", "racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone National Park", "St. Thomas", "luzon", "Hugh Laurie", "Buddhism", "Guy Berryman", "Ohio", "Port Melbourne", "\u00c6thelwald Moll", "Scarface", "forgery and flying without a valid license,", "Group D, Bundesliga Herder Bremen beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory", "Liza Murphy", "Spock", "Astana", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5911458333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3524", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-2126", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.546875, "CSR": 0.5749080882352942, "EFR": 0.8620689655172413, "Overall": 0.7184885268762677}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "steppes steppe", "Bologna, Italy", "George Santayana", "opossum", "Alice Cooper", "diastolic", "trumpet", "peter Kay.", "The Cry", "shildon", "Appalachian Trail", "MS Herald of Free Enterprise", "ballet", "krakatoa", "george george", "lizards", "Blackburn", "Frankie Laine", "The Mystery of Edwin Drood", "pommel horse", "bird", "Dick Van Dyke", "Egremont", "Numb3rs", "Francisco de Goya", "phrixus", "Basil Feldman,", "Canada", "ink", "pears soap", "Some Like It Hot", "Mull", "Ireland", "Mike Meyers", "hippocampus", "plutonium", "magma", "Passepartout", "Thank you", "georgia", "Austria", "shrek", "26.22", "Cleveland Brown", "heston Blumenthal", "One Direction", "Flint", "Uranus", "Stringer", "Charles Lindbergh", "September 2001", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "peter Tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6555555555555556}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.5625, "CSR": 0.5745535714285714, "EFR": 0.8928571428571429, "Overall": 0.7337053571428571}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "John Forster", "Matlock", "American Civil War", "shoa", "cetaceans", "Arafura Sea", "The Labyrinth", "Tigris", "Austria", "to make wrinkles in one's face", "Spain", "Carousel", "bullfighting", "Mike Brady,", "tenor", "alpo", "fidelio", "Guys and Dolls", "jean Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "india", "eddisbury", "G. Ramon", "jane martine", "rachmaninoff", "Finland", "stars with gravity", "Mille Miglia", "caves", "Bill Haley & His comets", "spain", "Muriel Spark", "happy birthday to You", "seven", "opossum", "Pickwick Papers", "presliced bread", "Saga Noren", "raven", "jordan", "bPA", "nelsons Column", "Etruscan", "Ken Burns", "grosvenor crescent", "Great Britain's Heather Stanning and Helen Glover", "e. T. A. Hoffmann", "Mujib", "spain", "Donna", "season four", "the sinoatrial node", "yubin, Yeeun", "tomato", "governor of Saint Paul Norm Coleman", "workers put down their tools last Wednesday.", "L'Aquila earthquake", "March 24,", "sesli Szlk", "equinox", "Pocahontas"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5345238095238095}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5537", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-4328", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.46875, "CSR": 0.5716145833333333, "EFR": 0.8823529411764706, "Overall": 0.7269837622549019}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "kim", "Acacias", "branson", "Gordon Ramsay", "mansfield town", "Robert Kennedy", "sulfur dioxide", "Margot Betti", "Manchester Airport", "Portuguese", "travelocity", "The Avengers", "Richmond", "dane", "paul Simon", "a ghost", "canola", "Tina Turner", "Benjamin Barker", "p Preston North End", "Bolivia", "John Donne", "Uranus", "Rio Grande", "Percheron", "The Graduate", "philippines", "ginger Rogers", "James I of Scotland", "One Foot in the Grave", "Bronx Mowgli", "mike deller", "George Santayana", "Finger Tab", "scafell Pike", "Wee Jimmy Krankie and his father", "joan de torquemada", "julie du Pr\u00e9", "Canada", "rum and cola", "seattlepi.com", "ghee", "George III", "joan james bay", "hyperbole", "oldpatricktoe-end", "June", "jane island", "Ceylon", "screwdrivers", "Kansas City Chiefs", "G minor", "My Summer Story", "1974", "The Outsiders", "Amberley Village", "lack of a cause of death and the absence of any soft tissue on the toddler's skeletal remains", "President Obama", "her father, Josef Fritzl,", "cixi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.5, "QA-F1": 0.5755208333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.75, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.25, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-5196", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.5, "CSR": 0.5696790540540541, "EFR": 0.71875, "Overall": 0.644214527027027}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "piped masonry", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist James Hutton", "N 17.44667 \u00b0 N", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1990", "Shawn", "Kiss", "January to May 2014", "Los Angeles", "September 28, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "two parties", "Sarah Silverman", "cell nucleus", "Anakin", "Travis Tritt and Marty Stuart", "1983", "Bee Gees", "Matt Czuchry", "Pradyumna", "compulsory registration of births with the United Kingdom government is a practice that originated at least as far back as 1853", "On the west", "Psychomachia, '' an epic poem written in the fifth century", "New Jersey Devils of the National Hockey League ( NHL ) and the Seton Hall Pirates men's basketball", "two", "7.6 mm", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Gloria", "the Hudson Bay", "Maginot Line", "France", "dumbo", "purple rain", "Charles Guiteau", "Gettysburg Address", "iTunes", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "Cannonball Run", "Oaxaca", "Tuesday"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7690455142860833}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 0.0, 0.0, 1.0, 0.787878787878788, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_triviaqa-validation-6008"], "SR": 0.671875, "CSR": 0.5723684210526316, "EFR": 0.8095238095238095, "Overall": 0.6909461152882206}, {"timecode": 38, "before_eval_results": {"predictions": ["Humphry Davy", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in positions Arg15 - Ile16", "Charles Crozat Converse", "Lady Gaga", "Chicago metropolitan area", "president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County ( 1894 )", "nobiliary particle", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma", "Pakistan", "The ladies'single figure skating competition of the 2018 Winter Olympics was held at the Gangneung Ice Arena", "Tagalog or English", "Bryan Cranston", "thylakoid membranes", "mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County, it lies just north of the state capital, Raleigh", "1922", "18 Divisional Round", "602", "stable, non-radioactive rubidium", "Membership is believed to cost between $10,000 and $30,000", "the studies and developments department of the French firm R2E Micral", "1931", "the University of Oxford", "Cherbourg in France and Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The statesmen who led the secession movement", "Randy", "that country's surprise attack on Pearl Harbor the prior day", "Joseph Stalin", "into the intermembrane space", "divergent tectonic", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "mrs Sir John Major", "Roddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "General Motors'", "David McCullough", "Rendezvous with Rama", "CERN", "l Lisbon"], "metric_results": {"EM": 0.5, "QA-F1": 0.5996820807602457}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false], "QA-F1": [0.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8695652173913044, 0.0, 0.4, 1.0, 0.4, 0.4666666666666666, 0.3333333333333333, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5569", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2512", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_newsqa-validation-3486", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.5, "CSR": 0.5705128205128205, "EFR": 0.9375, "Overall": 0.7540064102564102}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "ATP, generated by the root respiration : as the root cells actively take part in the process, it is called active absorption", "Philippe Petit", "September 1980", "January 2004", "southwest and along the Yangtze", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "heavy metal", "Set six months after Kratos killed his wife and child, he has been imprisoned by the three Furies", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "experimental psychology", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Phil Johnston", "Richard Crispin Armitage", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "diffuse interstellar medium ( ISM ) of gas and dust", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "Secretary of Homeland Security isirstjen Nielsen", "Santiago Ram\u00f3n y Cajal", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "is a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Tad '' Stone", "Mark Jackson", "Michael Buffer", "one faith, one baptism, one God and Father of all, who is over all and through all and in all", "on location", "federal government", "New England", "Cody Fern", "questions about the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "prophets and beloved religious leaders", "4.5", "Juan Manuel de Ayala", "Prophet Joseph Smith, Jr.", "funny Folks (1874 - 1894)", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "Pearl", "spiny", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.484375, "QA-F1": 0.597983546488771}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4210526315789474, 1.0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.17142857142857143, 1.0, 0.0, 0.0, 1.0, 0.11764705882352941, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-8323"], "SR": 0.484375, "CSR": 0.568359375, "EFR": 0.8484848484848485, "Overall": 0.7084221117424243}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants", "Joan Rivers", "women to be really observant of their breast health and do regular breast self-examination.\"", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "Zimbabwe President Robert Mugabe", "2004", "NATO", "Switzerland", "Monday", "second", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "he wants to spend billions to revitalize the nation's economy, a plan the campaign of his likely Republican opponent said would slow economic growth with higher taxes.", "Clifford Harris,", "Baja California Language College", "Robert Barnett", "$627", "41", "Adenhart", "a strict interpretation of the law,", "Derek Mears", "Sylt", "about 30 miles southwest of Nashville", "Tuesday", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "Section 60", "Ali Bongo", "her lawyer, celebrity attorney Gloria Allred,", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "Brazilian supreme court judge on Tuesday", "Derek Mears", "Operation Crank Call", "help rebuild the nation's highways, bridges and other public-use facilities", "East Java", "St. Louis, Missouri", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "released in 2007", "P.V. Sindhu", "on location in Mexico, where both the village and the U.S. border town were built for the film", "Snickers candy bars", "monoceros", "abbot", "Anaheim, California", "uncle", "Bergen", "embalming", "bistro", "a graphical user interface", "German Shepherds have a two - layer coat which is close and dense with a thick undercoat"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6761602603448643}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.13953488372093023, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.29629629629629634, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.5714285714285715, 1.0, 0.0, 0.9523809523809523, 0.3076923076923077, 0.2857142857142857, 1.0, 1.0, 0.9411764705882353, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.08695652173913045, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 0.10526315789473682]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3794", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.46875, "CSR": 0.5659298780487805, "EFR": 0.8823529411764706, "Overall": 0.7241414096126255}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "1890s", "Stephen A. Douglas", "1997", "displacement", "the modern state system", "Megan Park", "the currency used by the institutions of the European Union", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "A remittance is a transfer of money by a foreign worker to an individual in his or her home country", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "1902", "Kris Kringle", "Yuzuru Hanyu", "to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "A firm, flexible cup - shaped device worn inside the vagina to collect menstrual flow", "pigs", "General George Washington", "Spanish", "Coalhouse Walker Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the sinoatrial node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements )", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups.", "the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall", "Missouri River", "the right to be served in facilities which are open to the public", "frontal lobe", "10 June 1940", "Tandi", "Alberich", "the middle ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "on September 21.", "Denver, Colorado.", "the Sadr City and Adhamiya districts of Baghdad City,\"", "President Logan", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6848739495798319}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.11764705882352941, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2387", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.546875, "CSR": 0.5654761904761905, "EFR": 0.896551724137931, "Overall": 0.7310139573070608}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water also absorbs heat ; it thereby cools the smoke, air, walls, and objects that could act as further fuel", "Middlesex County, Province of Massachusetts Bay, within the towns of Lexington, Concord, Lincoln, Menotomy ( present - day Arlington ), and Cambridge", "chlorine and bromine from manmade organohalogens", "Michael", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring", "Field Marshal Paul von Hindenburg", "Ceramic art", "the Soviet Union's 1976 achievement of thirteen gold medals", "Covington, Kentucky", "New Mexico", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption, while at the same time increasing power and recycling boiler - water", "December 15, 2017", "about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "L.K. Advani", "differential erosion", "Glenn Close", "Gospel of Matthew in the middle of the Sermon on the Mount, and the short form in the Gospel of Luke", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "electricity generation, power distribution, and power transmission on the island", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "President Lyndon Johnson", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "by producing an egg through parthenogenesis", "1926", "Durban, South Africa", "starting in 1560s", "Erik Per Sullivan", "Lou Rawls", "between 1765 and 1783", "Alfheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two awards.", "prostate cancer,", "wyvern", "Lord Fauntleroy", "a key ring or a decorative key fob", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.643905238844702}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.972972972972973, 0.2857142857142857, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0625, 1.0, 0.9387755102040816, 0.14814814814814814, 0.6666666666666666, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.9767441860465117, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.5632267441860466, "EFR": 0.8235294117647058, "Overall": 0.6933780779753762}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "February 27, 2007", "she was `` sick of keeping all these feelings inside and not speaking up for myself ''", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "the arms of the king of Ireland", "Miami Heat", "1981", "In the early 20th century,", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "Camille Pissarro", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier", "a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "SURFACE", "Alex Ryan", "habitat", "2018", "Advanced Systems Format ( ASF )", "100 members, two from each of the 50 states", "Toledo", "Transvaginal ultrasonography", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "Paradise, Nevada", "Alicia Vikander", "in late January or early February", "Ashoka", "the name of a work gang", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority ( PREPA )", "Bumblebee", "into the Christian biblical canon", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "armored fighting vehicle", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "February 7, 2018", "Florida", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "in the southwestern part of the island", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "winter", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site,", "\"We want to reset our relationship and so we will do it together.'\"", "Michigan", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6295573332649352}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.8333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.0, 0.5714285714285715, 0.4705882352941177, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9189189189189189, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.3225806451612903, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-9723", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.46875, "CSR": 0.5610795454545454, "EFR": 0.7941176470588235, "Overall": 0.6775985962566844}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "aluminum foil", "Laurel, Mississippi", "mountain-climbing.", "Indianola", "insurance", "the British military on suspicion of being an American sympathizer in the American Revolutionary War.", "1992", "Cher", "Alabama", "Jim Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "5,656", "Leucippus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer.", "South America", "2006", "perjury and obstruction of justice", "Operation Overlord", "Mary Elizabeth Hartman", "over 9,000 employees", "Malcolm Terris", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "The Finger Tab", "Kent", "almost 9 million", "Bahrain", "2008", "'fair and square'", "Moses", "Chapter 5", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6023008241758242}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.2857142857142857, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.515625, "CSR": 0.5600694444444445, "EFR": 0.8709677419354839, "Overall": 0.7155185931899641}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "in September 1903", "the power to regulate interstate commerce", "Donna Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "A hard rock/blues rock band, they have also been considered a heavy metal band, although they have always dubbed their music simply \"rock and roll\"", "GmbH", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sully", "Manhattan Project", "Pacific War", "Romantic", "Hugh Dowding", "AMC Entertainment Holdings, Inc.", "New York Islanders", "fennec", "1978", "six different constructors taking the first six positions.", "French", "Pacific Place", "the Female Socceroos", "\"Bad Blood\"", "\"SexyBack\"", "the E22", "Giuseppe Verdi", "Engirundho Vandhaal", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Aamina Sheikh, Hasan Ahmed, Neelam Muneer, Zaheen Tahira, Ismat Zaidi, Sami Khan and Faisal Qureshi", "the British Army", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model T.", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Maroon 5", "Saudi Arabia", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6319324876689807}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 0.5714285714285715, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.23529411764705882, 1.0, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-4054", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327"], "SR": 0.546875, "CSR": 0.5597826086956521, "EFR": 0.8620689655172413, "Overall": 0.7109257871064467}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican National Committee's website address is GOP.com", "1996", "5", "Greenland shark", "The Word", "Abraham Lincoln's", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "the death penalty", "xerophyte", "Jackie Robinson", "Staten Island", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "a sauce of lemon juice, parsley, salt, pepper, and drawn butter", "be made from almost any meat that comes in pieces large enough to fit the bill", "curling", "Victoria Coren Mitchell", "Gettysburg Civil War", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "President Obama", "Canada's", "Bologna Song Lyrics - Daniel Bedingfield", "Dominican Republic", "Ziggy Stardust and Diamond Dogs", "Stephen King", "Hinduism", "caryatid", "feet", "all of its land in North America and Spain gave up Florida's busiest port.", "Mary Poppins", "Glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Daily Herald", "numerous", "kosher", "2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1944", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "How to Keep Young Mentally", "a living child"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5601562499999999}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6789", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1987", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1660", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.484375, "CSR": 0.5581781914893618, "EFR": 0.9090909090909091, "Overall": 0.7336345502901354}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "david Beckham", "inverness", "Runic", "Spain", "cricket", "Max Planck", "rotherham United", "heat transfer", "Misery", "Styal", "stately", "blind Beggar", "Brainwash", "Leroy Burrell (United States)", "parlophone", "Wild Atlantic Way", "John Denver", "Ankh-Morpork", "noddy", "Lackawanna Six", "Brazil", "roach", "muezzin", "a window", "on a ship s bottom next to the keel", "bovary", "Apollo 11", "flit", "Nikola Tesla", "tom Henderson", "evita", "sperm whale", "joseph roman", "East Fife", "St Pancras International Station", "social environment", "presliced bread", "Dilbert", "Aristotelian Tragedy", "nunc dimittis", "French", "Medea", "Burgundy", "cribbage", "w/e 5th Feb 2005", "Johannesburg", "France", "muffin man", "korea", "Prince James, Duke of York and of Albany ( later King James II & VII )", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Veracruz, Mexico", "if the airline doesn't perform, the credit card company still has your money and can give it right back to you.", "Robert Frost", "King Henry VIII", "Tucker, GA", "2002 Mitsubishi Lancer OZ Rally"], "metric_results": {"EM": 0.625, "QA-F1": 0.6653645833333333}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618"], "SR": 0.625, "CSR": 0.5595703125, "EFR": 0.7083333333333334, "Overall": 0.6339518229166667}, {"timecode": 48, "before_eval_results": {"predictions": ["Route 66", "sesame Street", "meat rag\u00f9 and besciamella", "cabbage", "Adelaide", "jimmy", "fleece", "Ash tree", "marsupials", "New Zealand", "jug band", "60", "uric Goldfinger", "1984", "small pikeb", "Mongol Empire", "1875", "tax collector", "pennies", "jimmy", "Wars of the Roses", "bagram Collection Point", "maie Gilkeson", "Chrysler", "fur hat", "korky the cat", "education", "the United States", "Brazil", "pei Tang", "biathlon", "Idaho Falls", "Charlie Chan", "Vienna", "white", "jaws", "Paul Rudd", "rabbit", "Scotland's", "jerry Leadbetter", "Orson Welles", "Hinduness", "menorah", "Dutch", "texas", "Super Bowl Sunday", "a quant pole", "Little Tommy Stout", "joie jax", "Rhododendron", "Ireland", "Chuck Noland", "Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "through Greece, the birthplace of the Olympics,", "10 below", "100 to 150 troops", "coins", "the American Kennel Club", "Omaha", "Dick & Jane"], "metric_results": {"EM": 0.5, "QA-F1": 0.5825892857142857}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-11366"], "SR": 0.5, "CSR": 0.5583545918367347, "EFR": 0.78125, "Overall": 0.6698022959183674}, {"timecode": 49, "before_eval_results": {"predictions": ["sledge", "shahcheh-e Namak", "alcohol", "Francis", "mrrick", "Daniel Boone", "Thames Street", "jennifer joseph roosevelt", "satyrs", "a type known for being very good to eat.", "La Boh\u00e8me", "IBM", "wishbone", "garrick club", "Lackawanna 6", "barnaby", "britten", "the American Civil War", "dark", "jennifer leachman", "Jimmy Robertson", "Florence", "Basil", "victoria", "severn", "jigalong", "South Africa", "bunch grasses", "guinea", "c Clement Attlee", "the Hundred Years War", "Chemnitz", "statistical history", "chubs, whitefish, squawfish, rainbows, cutthroats, and bull trout", "j Joseph Dubonnet", "Rick Stewart", "Belize", "Library of Congress", "hair loss", "sprint", "Charlie Drake", "robin hood", "Chris Martin", "flintstone", "jennifer deed", "rugby", "honda", "steely Dan", "11", "tobacco", "cows", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "Tom Selleck", "New Orleans", "superhuman abilities", "Texas Tech University Health Sciences Center", "Loughborough Technical Institute", "Herman Cain", "the United States", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "George Babbitt", "south west of the Cherokee Outlet, north of the Texas Panhandle, east of New... From the establishment of Beaver City's post office until 1890, the Strip's post", "ladies who Lunch", "four"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4558087891538102}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true], "QA-F1": [0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.8, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.06451612903225806, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 1.0, 0.0, 0.17391304347826086, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-12598", "mrqa_searchqa-validation-3615"], "SR": 0.328125, "CSR": 0.55375, "EFR": 0.8372093023255814, "Overall": 0.6954796511627908}, {"timecode": 50, "UKR": 0.8046875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.798828125, "KG": 0.48984375, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "Kansas", "Angelo Bruno", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo", "Harold Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Sunyani West District in the Brong-Ahafo Region of Ghana", "pronghorn", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger Jr.", "9", "CR-X del Sol", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional", "Francesco Verdi", "Laban Movement Analysis", "Cecily Strong", "Sam Waterston", "invoicing the employees' work based on an hourly rate, measuring the work effectiveness and project management", "seasonal television specials", "nearly 8 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "playback singer", "1901", "Pope John X.", "BAFTA Award for Best Production Design", "VAQ-135", "Alex Skuby", "Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "a vessel", "EMI", "UNICEF", "9 a.m.", "George Byron", "Van Helsing", "kufic", "a long-range missile"], "metric_results": {"EM": 0.5, "QA-F1": 0.6468354562104561}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, false, true, false, false], "QA-F1": [0.8, 0.5, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5454545454545454, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-5783", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.5, "CSR": 0.5526960784313726, "EFR": 0.9375, "Overall": 0.7167110906862745}, {"timecode": 51, "before_eval_results": {"predictions": ["Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "Atat\u00fcrk Museum Mansion", "Realty Bites", "24 NCAA sports", "Razor Ramon", "psychoanalysis", "Forbes, New South Wales", "St. George, Maine", "Heart", "Lithuanian national team", "International Boxing Hall of Fame", "35", "Conservatorio Verdi in Milan", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "World Outgames", "Homebrewing", "Umberto II", "Presbyterian Church", "neuro-orthopaedic Irish veterinary surgeon", "in their home country", "North Sea", "17 October 2006", "67,575", "Oxford", "Oric", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Edward Whitacre", "largest Mission Revival Style building in the United States", "21 flights daily", "George Adamski", "\"Hand of Thrawn\" novels", "Switzerland national team", "Ardfert in County Kerry, Ireland", "Scunthorpe", "Canadian comedian", "Captain Cook's Landing Place", "Summer Olympic Games unofficial programme in 1900", "1936", "1960s", "Royal Albert Hall and The Kennedy Center", "Budget Rent a Car", "Japan", "cave lion", "1959", "Donna Mills", "Is this the feeling I need to walk with / Tell me why I can't be there where you are / There's something missing in my heart", "735 feet ( 224 m )", "Alabama", "Blanche", "maxillae", "Microsoft", "4.6 million", "government", "tea rose", "John Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6110644257703082}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 0.5714285714285715, 0.8, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.4, 1.0, 0.8, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.5, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1260", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_triviaqa-validation-4184", "mrqa_searchqa-validation-10653"], "SR": 0.453125, "CSR": 0.55078125, "EFR": 0.9142857142857143, "Overall": 0.7116852678571428}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "The unknown is how the Romans kept track of who was eligible to vote", "3 lines of reflection and rotational symmetry of order 3 about its center", "up to 100,000 write / erase cycles", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel ( born 18 August 1942 ) was the first one - million - pound winner on the television game show Who Wants to Be a Millionaire? in the United Kingdom", "once again be hosted by Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Al Pacino", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "Gospel of Matthew", "30 years after Return of the Wars", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility vehicles and off - road vehicles, but has also included pickup trucks in the past", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock ( January 23, 1737 ( O.S. January 12, 1736 ) -- October 8, 1793 )", "1960", "The British military launched a campaign to capture the Colony of Canada ( part of New France )", "1972", "in the U.S. states of Oregon and Washington", "coercivity", "2010", "malicious software", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "birch", "one person", "The Parlement de Bretagne", "password recovery tool for Microsoft Windows", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "April 20, 1983", "typically closes for two and half weeks in late summer", "currency option", "1603", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas, developed by Rockstar North", "the medulla oblongata", "2018", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula, is the subject of an irredentist territorial claim by Spain", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "The Offer", "Paul Maskey", "Child actor", "Saoirse Ronan", "Happy Madison Productions", "The Kirchners", "north London rivals Tottenham", "Gordon Brown", "veterans", "yellow fever", "winter solstice", "Netflix"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6246826123599949}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.15384615384615385, 0.14285714285714288, 0.6666666666666666, 0.0, 0.13793103448275865, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.4, 0.058823529411764705, 0.967741935483871, 0.0, 0.13333333333333333, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-3567", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-9142", "mrqa_naturalquestions-validation-3959", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-2688", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-4527"], "SR": 0.515625, "CSR": 0.5501179245283019, "EFR": 0.8709677419354839, "Overall": 0.7028890082927571}, {"timecode": 53, "before_eval_results": {"predictions": ["Al Lenhardt", "the Big Bang", "Handel", "Green Acres", "life's Refinements", "Clark Coconut Zagnut", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines de Mexico S.A.", "her coronation", "Vermont", "Windsor County Vermont", "candy store", "Oncorhynchus", "Pudd'nhead Wilson", "Sydney", "tapir", "France", "Spam", "Dedalus Wagner", "early", "Camembert", "Friday", "the Golden Legend", "Centaurs", "Mentor", "commander of the Lebanese armed forces", "Manifest Destiny", "Al Gore", "disabilities", "Bali", "Philadelphia (1993)", "Germany", "Glucosamine", "Madagascar", "an", "a celebration, stunt, spectacle", "busby", "Susan Faludi", "Dr. Dre", "Al Lang Stadium", "Fidel Castro", "fudge", "Kanga", "Service Employees International Union", "black moor", "auxins", "a dive in which the body is first bent at the waist and then straightened.", "yellowtail", "Nitrides of boron & silicon are used to make crucibles", "between the Mediterranean Sea to the north and the Red Sea in the south", "in Athens", "Zeus", "Van Morrison", "antelopes", "main and regular sodas, 100 percent juices, juice drinks, waters, sports and energy drinks, teas and coffees, and milk-and soy-based beverages", "Rocky Mountain Institute", "21", "stolperstein", "nearly 2,000", "insurgent small arms fire", "3,000 kilometers (1,900 miles)", "Lambic"], "metric_results": {"EM": 0.484375, "QA-F1": 0.536532738095238}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.9, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-7039", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-7315", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-904", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-379", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-4242", "mrqa_triviaqa-validation-7747", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-1792"], "SR": 0.484375, "CSR": 0.548900462962963, "EFR": 0.9393939393939394, "Overall": 0.7163307554713805}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "in a nearby river bottom", "stems and roots of certain vascular plants", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "in teaching elocution", "the Isle of FERNANDO 'S!, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "approximately 11 %", "Bell Labs", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Chris Martin", "the Ming dynasty", "the red - bed country of its watershed", "those colonists of the Thirteen Colonies who rebelled against British control", "The Intolerable Acts", "National Industrial Recovery Act ( NIRA )", "semi-autonomous organisational units within the National Health Service in England", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg of Mainz", "1885", "the 1964 Republican National Convention in San Francisco, California", "the Finch family's African - American housekeeper", "Somatic", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "driving Miss Daisy", "Vengeance", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "December 31, 2015", "Seminole", "the Defense of Marriage Act", "Alinghi", "the Eiffel tower", "barnacles", "a dog", "gervais"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6633056588019823}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.4615384615384615, 0.5555555555555556, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.5882352941176471, 1.0, 0.888888888888889, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.515625, "CSR": 0.5482954545454546, "EFR": 0.8064516129032258, "Overall": 0.689621288489736}, {"timecode": 55, "before_eval_results": {"predictions": ["Edward III", "golf", "purple", "accordion", "Ascot", "Litas", "Loretta Lynn", "Survivor Series", "Born To Be Wild", "chop suey", "Ross MacManus", "Coronation Street", "The Bill", "hanchelle Gibbs", "Saddam Hussein", "New Zealand", "Tyrrhenian Sea", "Bobby Sands", "Mauritania", "Hans Lippershey", "Bolivia", "Bob Giraldi", "Mozambique Channel", "ash", "Edward VII", "Thomas Cranmer", "testicles", "Guatemala", "muralitharan", "Caroline Aherne", "Byron", "S\u00e8vres", "Mau Mau Revolution", "kipps: The Story of a Simple Soul", "guggul", "Serena Williams", "capital of Togo", "Pegida", "Alberich", "Utrecht", "1709", "Mitford sisters", "Kansas", "Miles Morales", "vine plagues", "Skylab", "ostrich", "Hugh Quarshie", "a stern tube", "Batman", "korea", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jackie", "Linux Format", "Stage Stores", "26", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6661458333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.640625, "CSR": 0.5499441964285714, "EFR": 0.391304347826087, "Overall": 0.6069215838509316}, {"timecode": 56, "before_eval_results": {"predictions": ["argentina", "Bolivia", "The Telegraph", "liver", "palta", "Drunk Crosswords", "Galway Bay", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "George Eliot", "the north-west corner of the central business district", "meatloaf", "Benazir Bhutto", "right-handed", "Sam Mendes", "Tara King", "way back Attack", "ninth", "business", "godiva", "darius adkins", "Mexico", "Towy", "three", "1984", "Swansea", "one", "shintoism", "Sussex", "king george", "mouse", "oxygen", "Prince Albert", "talavera de la Reina", "do I have to use earplugs", "Dodoma", "crawford", "Wilson", "lomond", "Pyrenees", "South Korea", "gelatine", "Papua New Guinea", "the Suez Canal", "Yorkshire", "a\u00e9roport de Gaulle", "Sankt Moritz", "the French Revolution", "the old Kent Road", "one of the Vikings nine realms", "An acetate / \u02c8\u00e6s\u026ate\u026at / is a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base", "iron", "creation of the office in 1789", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "one of the shocks of the year", "off Somalia's coast.", "Shanghai", "cape", "Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5424632352941177}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-2762", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-2319", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-1010", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.46875, "CSR": 0.5485197368421053, "EFR": 0.7352941176470589, "Overall": 0.6754346458978329}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "jimmy holborn", "rennet", "Lee", "Rudolf nureyev", "Jessica", "placebo", "weather", "lake placid", "independence of the Vatican as modern state.", "contractions", "William Boyd", "Cecilia", "Caroline Garcia", "Morecambe and Wise", "maggie Gilkeson", "butcher", "variolae vaccinae", "fox hunting", "Stockholm", "France", "far away", "anosmia", "lunar surveyor probe", "Chemnitz", "rue", "yellow", "raven", "Caracas", "ennio morricone", "the American Revolutionary War", "Spain", "timesigns", "Turandot", "algiers", "Mount McKinley", "eat porridge", "Howard Keel", "marriage", "Boutros Ghali", "zugspitze", "Sinclair Lewis", "New Mexico", "garden of gethsemane", "a tree diagram worksheet", "2", "Bild Newspaper", "France", "Kristiania", "keirin", "selenium", "action utility vehicles", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "Michael Jackson was in good health, contrary to media reports he was diagnosed with skin cancer.", "a group of college students of Pakistani background", "Perseid meteor shower", "accordion", "bones", "Marky wahlberg"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6533854166666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-5042", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-4653", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-2743", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-2238", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-16209"], "SR": 0.5625, "CSR": 0.548760775862069, "EFR": 0.6785714285714286, "Overall": 0.6641383158866995}, {"timecode": 58, "before_eval_results": {"predictions": ["rubbing", "Jonah", "Hughe", "Constantinople", "Jacqueline Susann", "Brazil", "Hudson River", "spinal column", "Nassau", "Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "ruby", "deep Woods", "Siberia", "William Pitt the Younger", "five", "CAKES", "largest city in New Hampshire", "The Godfather", "cancer", "Nostradamus", "jihad", "harpoons", "mandy manilow", "finance", "Conrad Hilton Jr.", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the Battle of Trafalgar", "bald eagle", "menudo", "Panax", "hurricanes", "Home Improvement", "Kashmir", "Airport", "noun", "Bourbon French Parfums", "a single death", "Journey Under the Sea", "brothers", "lethal", "college grants", "emerald", "watermark", "19 July 1990", "Incudomalleolar joint", "Louis XV", "Zimbabwe", "Mansion House", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "becoming bald or fear of being around bald people."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5453869047619048}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-12684", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-5458", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-1938", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225", "mrqa_triviaqa-validation-2596"], "SR": 0.46875, "CSR": 0.5474046610169492, "EFR": 0.9117647058823529, "Overall": 0.7105057483798605}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "the 1&1 website", "the distillation process", "Leonard Bernstein", "magnesium", "attendolo", "Danube", "the albatross", "Seinfeld", "Smashing Pumpkins", "a sentence", "Ohio State", "Sherman", "Pakistan", "Theology of God", "Leinster", "Sally Field", "Barbara Cartland", "rum", "a Pringles can", "Paul Hamm", "profundo", "East Siberia", "Nimble", "Forrest Gump", "Clue", "two identical wisecracking magpies", "#5367", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "trade winds", "New Hampshire", "silk", "W", "unicorns", "Scrabble", "humerus", "The Bodyguard", "Petruchio", "the Philippines", "tofu", "Che Guevara", "Yale University", "Oscar Wilde", "Aeneas", "Dian Fossey", "a map", "an iron -- nickel alloy and some other elements", "ABC", "a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court", "pear", "Melbourne", "The Big Bopper", "Ringo Starr", "Do Kyung-soo", "Hanna", "Majid Movahedi", "National Intelligence Service, and Defense Minister Kim Kwan Jim", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.\"", "Priam"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6460597826086956}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.34782608695652173, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-12241", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745"], "SR": 0.578125, "CSR": 0.5479166666666666, "EFR": 0.8518518518518519, "Overall": 0.6986255787037037}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "close to 50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha", "four", "Sippin' on Some Syrup", "Chris Stebbins", "Arnold", "Los Angeles", "Karl-Anthony Towns", "five", "Charlie Wilson", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location,", "1858", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "lower Manhattan", "Homeland", "2016", "American Airlines", "green and yellow", "Champion Jockey", "March 2012", "Tom Courtenay", "Erinsborough", "2015", "Vladimir Valentinovich Menshov", "The Birds", "Londonderry", "York County, Maine", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Site", "Eardwulf", "God", "Swiss", "Augustus", "World War I", "at age 27", "Marktown", "five", "Rodney Crowell", "Mendel", "near major hotels and in the parking areas of major Chinese supermarkets", "scales", "d\u00fcsseldorf", "Apollo", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III", "quarantina", "Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6680288461538462}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3132", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-5717", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.578125, "CSR": 0.5484118852459017, "EFR": 0.8518518518518519, "Overall": 0.6987246224195507}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls aged 11 to 18", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Cartoon Network", "1983", "Rio Gavin Ferdinand", "264,152", "2,664", "841", "first and second segment", "Australian Broadcasting Corporation (ABC)", "MG Car Company Limited", "Walt Disney and Ub Iwerks", "1979", "15", "January 23, 1898", "John W. Henry", "Bolton", "Argentinian", "Them", "137\u201373", "John Snow", "New York and New Jersey campaign", "2013\u201314", "Melbourne Storm", "University of Nevada, Las Vegas", "21", "Dovzhenko", "Friday", "Oklahoma Sooners", "2002\u201303", "7pm", "1866", "Gaahl", "Serie B", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf", "Furious 8", "the final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer", "1951", "35,124", "154 days", "March 29, 2018", "Jimmy Flynn", "the Soviet Union and its satellite states", "finger", "Ronald Reagan", "One Thousand and One", "Long troop deployments", "protecting 50,000 jobs in the last 18 months and would continue to shed jobs without this program.", "forcibly drugging", "James Watt", "T.S. Eliot", "ANastasia", "appearances"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6397680623973727}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.7499999999999999, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.06896551724137931, 0.25, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129", "mrqa_naturalquestions-validation-715"], "SR": 0.5625, "CSR": 0.5486391129032258, "EFR": 0.9285714285714286, "Overall": 0.7141139832949308}, {"timecode": 62, "before_eval_results": {"predictions": ["\u00c9cole des Beaux-Arts", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Babylon", "a card (or cards) during a card game", "water", "Sean Yseult", "court systems in several common law jurisdictions", "October 5, 1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "Simon Bolivar Buckner", "German", "Gareth Jones", "consulting", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "jewelry designer", "Guns N' Roses", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "Mountbatten family", "the roll, or a series of rolls, of a pair of dice", "Kal Ho Naa Ho", "Dungeness crab", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "Martin O'Neill", "HackThis Site", "Reginald Engelbach", "American", "Black Friday", "Minnesota", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin", "Richard Seddon", "the heart", "Yakutat", "to launch a group that will serve as an alternative to the Organization of American States.", "\"Now that we know Muhammad is an Ennis man, we will be back,\" Ali's wife Lonnie told Britain's Daily Telegraph newspaper.", "Bob Bogle", "the removal of the circumcision from the human penis", "The Hague", "a shooting-brake", "2001"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6553554042664497}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.11764705882352941, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.7272727272727272, 0.6666666666666666, 1.0, 0.0, 0.0, 0.34782608695652173, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4046", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-3658", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-12404"], "SR": 0.546875, "CSR": 0.5486111111111112, "EFR": 0.8275862068965517, "Overall": 0.6939113386015325}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"I'll have my bond\"", "a list of strings", "Beluga whale", "Nicholas II", "tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "mendoza", "Thor", "Arusio", "astride", "Borneo", "Versailles", "to have tea", "Raleigh", "whipped cream", "Yellowfin", "Macbeth", "Jean-Michel Basquiat", "Led Zeppelin", "War & Peace", "Dutchman", "Moonlighting", "the outskirts of a small Southern town", "Peter Falk", "John Tyler", "Atlanta", "a tranfgrelTion", "the 80 Greatest Quotes About Money", "sake", "Notre Dame", "Portland", "Charles-Franois de Broglie", "The Indianapolis 500", "Toy Story", "Dead Serious Improv", "Sarah Jessica Parker", "water", "Nikolai Gogol", "Oscar Wilde", "Fletcher Christian", "weaving", "Karol Wojtyla", "Greenland", "John", "The Marx Brothers", "watermelon", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts", "duodenal cytochrome B ( Dcytb )", "Reverend J. Long", "violin", "sexual imagination", "the 2nd highest peak in the world", "Garrett Morris", "1966 US tour", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "Three thousand", "al-Maliki"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6260551948051948}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-1267", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-14853", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-3642", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.546875, "CSR": 0.548583984375, "EFR": 0.9310344827586207, "Overall": 0.7145955684267241}, {"timecode": 64, "before_eval_results": {"predictions": ["some of the most gigantic pumpkins in the world,", "Seminole Tribe", "billions of dollars in Chinese products each year,", "green-card warriors", "228", "love and loss", "2005", "contaminated groundwater, hundreds of buildings used for plutonium enrichment that need to be torn down, and underground tanks that are full of radioactive sludge.", "consumer confidence", "Fernando Gonzalez", "the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "Dan Parris, 25, and Rob Lehr, 26,", "Jared Polis", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah, overloading that facility.", "Russia", "Obama", "Sunday", "her husband and her abductors.", "France", "41,280", "be silent.", "iTunes", "Kenyan and Somali governments", "\"gotten the balance right\"", "a dozen", "10", "Quiet Nights", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Iran", "123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "grabbed the gun and  took her own life.", "fractured pelvis and sacrum", "five", "to step up.\"", "first-degree murder", "Russia", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda", "Garth Brooks", "Oxbow", "Ameneh Bahrami", "different women coping with breast cancer in five vignettes.", "Michael Schumacher", "Luiz Inacio Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Tim Passmore", "Theodosius I", "Ted Heath", "Estonia", "is our children learning?\"", "Princess Elizabeth", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Hipparchus", "April 2, 1917", "the middle"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6569754464285714}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5555555555555556, 0.0, 1.0, 0.1904761904761905, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8750000000000001, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-44", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-10515", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.53125, "CSR": 0.5483173076923077, "EFR": 0.7, "Overall": 0.6683353365384616}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "he felt a close affinity to John Dillinger", "North Korean Taepodong-2 missile", "February 12", "Mandi Hamlin", "United Nations", "\"falling space debris,\"", "at a Little Rock military recruiting center", "voluntary manslaughter", "if you don't get to the hospital to have surgery to drain the fluid, \"the deterioration can happen very quickly,\"", "Chris Robinson", "Grease", "Cipro", "34", "24 illnesses in multiple states,\"", "More than 15,000", "a good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "Iran,", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "not regulated.\"More is not necessarily better...some vitamins and minerals can be toxic in high doses,\" particularly the fat-soluble ones which the body stores like Vitamins A, D, E and K,", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "around 1610,", "Gulf of Aden,", "Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "the immorality of these deviant young men does not provide solutions that prevent gang rape from happening.", "in five days.", "managing his time.", "not including co-pays or deductibles.", "bipartisan", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "as adults", "drug cartels", "state", "Trevor Rees-Jones,", "28 passengers,", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "Genocide Prevention Task Force.", "243 days", "Kirstjen Nielsen", "1937", "20", "Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "New England", "1694", "the Golden Fleece", "Gustav", "Amish", "Matthew Knight"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5824686004784689}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-3469", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-3285"], "SR": 0.515625, "CSR": 0.5478219696969697, "EFR": 0.9032258064516129, "Overall": 0.7088814302297165}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "ra(dio) d(etecting a(nd) r(anging)", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "about a mile north of the village of Dunvegan,", "ArcelorMittal Orbit", "lodges", "Joseph Stillwell", "Tallinn,", "solar system", "coelacanth", "Belgium", "Dennis Potter", "Calcium", "Eric Coates", "george c Cox", "Mel Brooks", "The California condor", "Ohio", "wind turbines", "harridan Grizelda Pugh,", "police drama The Bill", "0 for 7", "Hamlet", "Johannesburg", "Crackerjack", "Bleak House", "Rodgers and Hammerstein", "Spain", "minder", "special sauce", "Les Dennis", "Kansas City", "Hard Times", "Tuscany", "tallest building in the world", "Singapore", "Dinkley, and Norville \"Shaggy\" Rogers", "Pakistan International Airlines", "gold, red, blue, black and white.", "France", "Tomorrow Never Dies", "John Fitzgerald Kennedy", "Hong Kong", "Chuck Yeager", "violet- Elizabeth Bott", "northern France", "stamp collecting", "Moby Dick", "from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective", "21 July 2015", "Bern", "28 June 1945", "not", "25 years", "Pakistan", "Yves Saint Laurent", "Eric Clapton", "Topix", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6704680735930736}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.09090909090909091, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1709", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-5331", "mrqa_triviaqa-validation-7476", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-613", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.5625, "CSR": 0.5480410447761195, "EFR": 0.8928571428571429, "Overall": 0.7068515125266525}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Alaska", "Dolph Lundgren", "August 9, 1945", "after obtaining the consent of the United Kingdom", "a cake", "Olivia Olson", "Beijing", "Pyeongchang County, South Korea", "602", "April 7, 2016", "5.7 million customer accounts", "Initially, all games in the International Series were held in London", "the United States Congress", "David Joseph Madden", "new wave rock band The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "Royal Air Force ( RAF )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US privacy Act", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "18th century", "Mariah Carey", "Spektor", "respiratory acid", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Chernobyl Nuclear Power Plant", "435", "off - road vehicles", "Kanawha Rivers", "American country music duo The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand to New Guinea", "Frank Oz", "1954", "2010", "Missouri River", "alsatian", "lutenist", "Greece", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town building", "Araceli Valencia,", "Eleven", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi", "hyponomatopoeia"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6273531840966051}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-4085", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_newsqa-validation-2025", "mrqa_searchqa-validation-12184", "mrqa_triviaqa-validation-4040"], "SR": 0.546875, "CSR": 0.5480238970588236, "EFR": 0.7586206896551724, "Overall": 0.6800007923427992}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "Roberta Flack", "sesame seed", "eldest or heir apparent", "September 19", "Barnaby Rudge", "Buddha", "Amharic", "1963", "discus", "tabloid", "the Royal Festival Hall", "chester racecourse", "California", "Jews of Iberia (in Hebrew, Sepharad) and the Spanish diaspora", "Romanian", "Saint Basil's", "Peru", "the keel", "Evander Holyfield", "middies", "buddhist", "New Orleans", "soda", "fat like oil or lard", "Steve Hansen", "brashy", "Ken Burns", "Paddy Doherty", "yvonne", "phi - the 21st letter of the Greek alphabet", "Hungary", "So Solid Crew", "blues-rock", "Pennsylvania", "caucausus", "australia", "wakeers", "Jupiter", "Woodentop", "a child", "two", "Queens Park Rangers", "wiziwig", "giants", "cotton", "b\u00e9la bal\u00e1zs", "Hugh Dowding's father, Arthur Dowding", "Montpelier", "February", "prince of aragon", "annual income of US $11,770", "318", "Chris Rea", "Tomasz Adamek", "scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine.", "March 30, 2025", "Knox's parents,", "Dubai", "rabbit hole, if you will,", "held", "Russia", "American adventure comedy film", "Jimmy Carter"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5282986111111112}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.19999999999999998, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.5, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5714285714285715, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-2964", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-1848", "mrqa_triviaqa-validation-3417", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-10485"], "SR": 0.453125, "CSR": 0.5466485507246377, "EFR": 0.8285714285714286, "Overall": 0.6937158708592133}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey archer", "Chicago", "California Chrome (who is set to be retired in January 2017 as a 6-year-old),", "Dar es Salaam", "Sarah Keays", "Miss Marple", "Elkie Brooks", "UPS", "Nadal", "piano", "Cambridge", "Fitzwilliam Darcy", "the Spice Girls", "syrupy", "addams", "Doubting Castle", "beetle", "australian", "england", "Harry Shearer", "9-13 years", "pirate day", "the Carolingian penny", "Spice Girls", "48 Hours", "AFC Wimbledon", "france", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "bagram", "Pygmalion", "bajan", "cassis", "Dieppe Raid", "dengue fever", "The Left Book Club", "triathlon", "barbershop quartet", "dividing of cells into additional cell bodies", "Strictly Come Dancing", "sound and light", "Par-5", "jack Russell terrier", "prairie", "raclette", "Denali", "The Magic Circle", "Potsdam Conference", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Cordelia", "London Luton Airport", "Sarah", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Madagascar, Mauritius, Mayotte, R\u00e9union, Seychelles,", "he said Chaudhary's death should serve as a warning to management,", "they don't feelMisty Cummings and Crystal Sheffield, Haleigh's mother, are not considered suspects,", "\"remained at the bottom of the hill surviving on leaves and water from a nearby creek,\" the report said.", "Vanilla Ice", "Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6291567852437419}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.17391304347826086, 0.08, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-2520", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002"], "SR": 0.546875, "CSR": 0.5466517857142856, "EFR": 0.7241379310344828, "Overall": 0.6728298183497536}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew - Somerville", "complex sentence", "Australia", "Ashrita Furman", "No Secrets", "1994", "2010", "12 November 2010", "1 October 2006", "1977", "2018", "the term originated in Missouri, during the Kirtland period of Latter Day Saint history, circa 1834", "Vincent Price", "1966", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the city of Indianapolis", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Steve Lukather", "U.S. dollar banknotes", "the referee", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "If These Dolls Could Talk", "around 2011", "Seton Hall Pirates", "ulnar nerve", "November 2016", "British Indian Association", "indigenous to many forested parts of the world", "Western Australia", "Carol Worthington", "1830", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "a good harvest", "28", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Anthony Hopkins", "Jesus Christ", "1996", "holography", "Spanish", "martin", "Gillian Leigh Anderson", "the theory of direct scattering and inverse scattering", "45th Infantry Division", "\"it should stay that way.\"", "2009", "an open window", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6711973330999066}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.23529411764705882, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-2623", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-2384", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-2658", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.578125, "CSR": 0.5470950704225352, "EFR": 0.7777777777777778, "Overall": 0.6836464446400626}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "inner core", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama Action", "on the table or, more formally, may be kept on a side table", "zinc silicate primer and vinyl topcoats", "off the rez", "either in front or on top of the brainstem", "On March 14, 1942", "Aegisthus", "Epithelium", "Erika Mitchell Leonard", "Daya", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "an expected or free or continuously changing behaviour and may have a given individual social status or social position", "United Nations Peacekeeping Operations", "displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "Noahic Covenant", "Shirley Mae Jones", "heat transfer by thermal radiation may be minimized by silvering flask surfaces facing the gap", "Luke 6 : 67 -- 71", "August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "retinal ganglion cell axons and glial cells", "letter series", "August 21", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal, and the southern terminus is at an interchange with US 250 near Interstate 64 ( I - 64 ) in Rockfish Gap", "The Southern Cause", "1955", "electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions, and couples this electron transfer with the transfer of protons ( H ions ) across a membrane", "2", "Montreal Canadiens", "2002", "on 3 September, after a British ultimatum to Germany to cease military operations was ignored, Britain and France declared war on Germany", "three levels", "minimum viable product that addresses and solves a problem or need that exists", "Wyatt `` Dusty '' Chandler ( George Strait )", "last book accepted into the Christian biblical canon", "In the 1920s, Louis W. Sauer developed a weak vaccine for whooping cough at Evanston Hospital ( Evanston, IL )", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "Camellia sinensis", "euratom", "Mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "complicated and deeply flawed", "Crandon, Wisconsin,", "butterflies", "Rocky Mountain Fever", "11:30 a.m.", "drug labs, markets and convoys."], "metric_results": {"EM": 0.40625, "QA-F1": 0.5379711304523359}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.35294117647058826, 0.33333333333333337, 1.0, 1.0, 1.0, 0.12121212121212122, 0.0, 0.0, 1.0, 1.0, 0.7272727272727273, 0.75, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6341463414634146, 0.0, 1.0, 0.12903225806451613, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.4444444444444445, 0.11764705882352941, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.40625, "CSR": 0.5451388888888888, "EFR": 0.9473684210526315, "Overall": 0.717173336988304}, {"timecode": 72, "before_eval_results": {"predictions": ["Michigan's", "Afghanistan", "red sauce", "suffrage", "B.", "Christopher Darden", "a gourmet jelly bean", "a cloudy day", "Daniel Berrigan", "wheat", "Carole King", "Spain", "Pro-Jig Clamp Set", "Christo Vladimirov Javacheff", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "Tom Harkin", "Channel Islands", "Krackel", "Penelope", "Pronouns", "Bonobos", "Harry's Harbor Bizarre(2)", "Veep", "alex", "a cradle song", "Burma Ruby stone", "Pan's Labyrinth", "Sir James Matthew Barrie", "John Irving", "singular", "the Who", "Europe and Asia", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "hemp", "Beijing", "Lee Harvey Oswald", "George Armstrong Custer", "Newton's", "breath", "Stockholm", "Alaska", "a puff", "Mausolus of Caria in Asia Minor", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "Genesis", "Saint Cecilia", "Germany", "1989 until 1994", "600", "the nose, cheeks, upper jaw and facial tissue from a female cadaver in the first near-total face transplant in the United States,", "Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5830357142857143}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1459", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-14960", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-14147", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681"], "SR": 0.46875, "CSR": 0.5440924657534247, "EFR": 0.8529411764705882, "Overall": 0.6980786034448025}, {"timecode": 73, "before_eval_results": {"predictions": ["Baltimore", "Happy Days", "Rita Mae Brown", "Bolivia", "New Hampshire", "grasshopper", "the commander", "Sure", "1876", "brood", "an onlooker", "Humphrey Bogart", "Maryland", "a Lion's beer", "pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Barry Goldwater", "Goofy", "Walter Payton", "Mount Everest", "Winston Rodney", "a pindar poem", "a bird", "the Tom Thumb", "St. John's Island", "the Mad Hatter", "tryptophan", "Cincinnati", "to aid the athlete's performance", "concert grand", "tomato sauce", "peanut butter", "soccer", "Tom Petty", "Tuscany", "Tunisia", "Rosa Parks", "inch", "Paris", "William Henry Harrison", "Corinthian", "a gram", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "Tipping Point", "Scotland", "the North Sea", "James Harden", "eternally wave", "Ron Goldman", "\"Mad Men\"", "fusion teams", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7078125}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-16935", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-4837", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-11341", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15975", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_triviaqa-validation-4662", "mrqa_hotpotqa-validation-5148"], "SR": 0.671875, "CSR": 0.5458192567567568, "EFR": 0.9523809523809523, "Overall": 0.7183119168275418}, {"timecode": 74, "before_eval_results": {"predictions": ["Urban Outfitters", "The Tyger", "Thunder Road", "the Last Supper", "Baccarat", "Rook", "Harlem", "Hertogenbosch", "hulls", "Drug Rehab & Treatment Center", "cricket", "India", "Children of Men", "Skagway, Alaska", "a petition", "Hippolyta", "a species", "John Galt", "Spinach", "milk", "the current reading from the present one", "Fecund", "World War I", "Federal Student Loans", "Tony's", "Itzhak Perlman", "Wolfgang Johannes Puck", "dachshund", "Monitor", "Cyprus", "Milwaukee", "a hot latte", "a baseball movie starring Kevin", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Richard Cheney", "Speed Racer", "U.S.A.", "Aristotle", "ER", "Eagles", "An American Tail", "a bus tour", "argyle anlam", "Toyota", "a Wallaby", "a leather feather", "Mark Twain", "Greg", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Christopher Bolam", "pawns", "northwest India", "House of Habsburg-Lorraine", "SS-Obergruppenf\u00fchrer", "Kansas\u2013Nebraska Act", "Orbiting Carbon Observatory", "South Africa", "Tuesday", "two"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7223958333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-9320", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-5344", "mrqa_searchqa-validation-3342", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3779", "mrqa_hotpotqa-validation-686"], "SR": 0.640625, "CSR": 0.5470833333333334, "EFR": 0.8695652173913043, "Overall": 0.7020015851449275}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "state", "1908", "at the origin and synthesis of new strands, accommodated by an enzyme known as ligase, results in replication forks growing bi-directionally from the origin", "Javier Fern\u00e1ndez", "Michael Crawford", "silk floss tree", "Hold On", "Allies", "November 2016", "Empiricism", "Identification of alternative plans / policies", "underlings", "North America", "Johnson", "Song of Songs", "Taron Egerton as Johnny", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Ekta Kapoor", "September 24, 2012", "Only two men", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "homicidal thoughts of a troubled youth", "Dan Bern and Mike Viola ( of the Candy Butchers )", "Daniel A. Dailey", "Mickey Mantle", "the +, -, *, and / keys", "December 15, 2016", "Kid Creole and the Coconuts", "AD 1 immediately follows the year 1 BC", "2010", "microfilament", "1983", "John Roberts", "President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna, led by former president Mahinda Rajapaksa, secured the most seats and local authorities.", "1773", "Buddhist missionaries", "By functions", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "york", "t. s. Eliot", "k Kent Hovind", "Lieutenant Colonel Horace Meek Hickam", "Adam Rex", "his comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "debt", "Blackbird", "Sara Ramirez", "September 25, 2017"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5558147421839856}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.10526315789473684, 0.0, 0.23076923076923073, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.125, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.515625, "CSR": 0.5466694078947368, "EFR": 0.7741935483870968, "Overall": 0.6828444662563667}, {"timecode": 76, "before_eval_results": {"predictions": ["makes Maria a dress to wear to the neighborhood dance", "Walter Mondale", "state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1928", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "at least 28 vowel forms", "Theodore Roosevelt, who became president at the age of 42 years, 322 days, following William McKinley's assassination", "23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple origins of replication on each linear chromosome that initiate at different times ( replication timing ), with up to 100,000 present in a single human cell", "restarting play after a minor infringement", "A footling breech", "The Hunger Games : Mockingjay -- Part 2 ( 2015 )", "the President of India", "to signify cunnilingus and the gesture is often off - colour", "28 %", "Elvis Presley", "N\u0289m\u0289n\u0289\u0289", "JackScanlon", "the eighth episode of Arrow's second season", "Elijah Wood", "head - up display", "Doug Pruzan", "1984", "Donna Reed", "in organelles, such as mitochondria or chloroplasts", "pathology", "1986", "introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan, though with a somewhat different meaning ( similar to the meaning used by the British associationists )", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Jourdan Miller", "wagen VIII Maus ( `` Mouse '' )", "limited period of time", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England Patriots ( 5 - 4 )", "40 %", "Janie Crawford's `` ripening from a vibrant, but voiceless, teenage girl into a woman with her finger on the trigger of her own destiny", "in the east", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "St. Louis Blues ( 3 in 1968 -- 1970 )", "around 1872", "Colman", "starch", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Ken Howard", "one", "Government Accountability Office report", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "Double-breasted", "Heroes", "a lush, plentiful version of the Egypt of the living", "since 1983"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5862270127287323}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.25, 0.0, 1.0, 0.0, 0.35294117647058826, 0.0, 0.2, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 0.0, 0.0, 0.7692307692307692, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.32258064516129037, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.30769230769230765, 0.4615384615384615, 0.0, 0.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.2, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-10195", "mrqa_naturalquestions-validation-5719", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.46875, "CSR": 0.5456574675324675, "EFR": 0.6176470588235294, "Overall": 0.6513327802711995}, {"timecode": 77, "before_eval_results": {"predictions": ["a herpes virus, (Another name for shingles is herpes zoster.)", "Zork", "Roddy Doyle", "Jaggers", "Prussia", "jennifer kipling", "Spongebob", "Exile", "an enclave which is entirely enclosed by another nation.", "South Dakota", "Brian Close", "a caterpillar", "Leeds", "Edinburgh", "a traffic warden", "cricketer", "France", "Neptune", "VimtoVimto", "people or society.", "leicestershire", "carry On Cleo", "afro-Asiatic", "sense of taste", "snare drum", "pangea", "sesame seed", "hurdles", "The Centaurs", "tallest building in the world", "American Football", "Charlie Chaplin", "kitty", "Giglio Island", "Copenhagen", "\"Upper Haight\"", "jon Voight", "Harry patch", "nursery comics", "Sight & Sound", "Inigo Jones", "ra(dio) d(etecting a(nd) r(anging)", "Nelson Mandela", "Today", "trousseau", "Utah", "Mark Darcy", "reptilian", "Africa, India, Madagascar, Australia and Antarctica", "salyut 1", "india", "Evermoist", "62", "Matthew Gregory Wise", "1861", "Zola", "Limbo", "12.3 million", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$4.5 million"], "metric_results": {"EM": 0.546875, "QA-F1": 0.606351461038961}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-7531", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-7005", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2362", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.546875, "CSR": 0.5456730769230769, "EFR": 0.6551724137931034, "Overall": 0.6588409731432361}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he believed he was about to be attacked himself.", "1964", "\"the voice of change,\"", "\"momentous discovery\"", "Al-Aqsa mosque", "Dilshan put Sri Lanka back on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "media", "Sadr City", "Barack Obama", "Arnoldo Rueda Medina,", "left his indelible fingerprints on the entertainment industry.", "pizza, the other for the drug ketamine.", "Brian David Mitchell,", "Defense of Marriage", "Jacob", "Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "people will be malicious and try to compromise peoples' health using computers, especially if neural devices become more widespread.\"", "1957", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda", "Manmohan Singh", "cope in prison.", "J. Crew", "one day, Nicole noticed a UPS delivery box where it shouldn't be. \"I'm like, 'How did this brand of box get on my back balcony?'", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "Eleven", "don't feelMisty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Barack Obama", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "10", "return of a fallen U.S. service member", "model", "Steve", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "well", "China", "Capture of the Five Boroughs", "Jim Diamond", "pornographicstar", "God", "petroleum", "Fannie Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5793290043290042}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809523, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 0.5, 0.18181818181818182, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-1390", "mrqa_naturalquestions-validation-4008", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-15636"], "SR": 0.484375, "CSR": 0.5448971518987342, "EFR": 0.7272727272727273, "Overall": 0.6731058508342923}, {"timecode": 79, "before_eval_results": {"predictions": ["1866", "Grant", "Yangtze River", "Genesis", "Queen Anne Stuart", "NY Times I Herman", "Scotland", "Oklahoma", "the communist revolution", "the Nautilus", "Humphry Davy", "seoul", "1/2 hours", "smallpox", "Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet", "Mickey Mouse", "Xerox", "blitz", "Jamaica", "gossip", "an exothermic reaction", "the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "U.S. government", "clothing", "Andrew Marvell", "vegetables", "Bollywood", "\"Titanic\"", "Take Me Out to the Ballgame", "a parapet", "the first name of dramatist Orton", "chocolate", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Surinam", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal Virgins", "The Lord of the Rings: The Return of the King", "Barack Obama", "H CO ( equivalently OC (OH ) )", "in a thousand years", "W. Edwards Deming", "Clara", "Douglas Trendle", "Ricky Gervais and Stephen Merchant,", "RickyRubio", "edith cavell", "Forbes", "20 minutes of cardio five days a week.", "22", "Demjanjuk,", "1,776"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6741612554112554}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.5, 0.6666666666666666, 1.0, 0.8, 0.28571428571428575, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14620", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-889", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-2149", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-2118", "mrqa_naturalquestions-validation-3561"], "SR": 0.546875, "CSR": 0.544921875, "EFR": 0.8620689655172413, "Overall": 0.7000700431034482}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "Tim Whelan", "the North Shore", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "associated with the mother goddess in the deepest layers of pre-Greek myth,", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "Manor of the More", "Commonwealth of England, Scotland, and Ireland", "Workers' Party", "those who work with animals", "his exploration and settlement of what is now Kentucky,", "six", "Mauthausen-Gusen", "Adrian Peter McLaren", "Distillery", "Ted Nugent", "New York", "Viscount Cranborne", "The Princess and the Frog", "the Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Martins", "Boulder High School in Boulder, Colorado", "Dutch", "November of that year", "Boston, Massachusetts", "\"The Big Bang Theory\"", "Brendan O'Brien", "Delphine Software International", "University of Kentucky College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate and a 150 - member House of Representatives", "September 15, 2012", "Andy Murray", "Vienna", "Malaysia", "Akio Toyoda", "Iran's nuclear program.", "alternative-energy vehicles", "Bix", "(two)", "Court Jester or Fool", "M&M's"], "metric_results": {"EM": 0.59375, "QA-F1": 0.710842803030303}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.19999999999999998, 0.19999999999999998, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-237", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-1305", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-15999"], "SR": 0.59375, "CSR": 0.5455246913580247, "EFR": 0.8846153846153846, "Overall": 0.7046998901946819}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies of World War I", "Acid house", "Esteban Ocon", "Queen Elizabeth II's first cousin Prince Michael of Kent", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "half of the Nobel Prize in Physics", "Adam Karpel", "American R&B singer, guitarist, songwriter and music producer", "1903", "Windermere", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "Jenson Alexander Lyons", "Ambroise Thomas", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "English Electric Canberra", "3 August 1916", "Washington, D.C.", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Marius Goring, Ralph Richardson, Cyril Luckham, Sebastian Shaw and Emlyn Williams", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow grade selection", "The Sand Trap", "Kim Clijsters", "the Horn of Africa.", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "elementary", "The New York City Ballet", "voltage", "Willa Cather"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5779487420791769}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 0.18181818181818182, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2608695652173913, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-4359", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-388", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.46875, "CSR": 0.5445884146341464, "EFR": 0.8823529411764706, "Overall": 0.7040601461621233}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "four", "July 23, 1971", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian", "\"The Late Late Show\"", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney", "The Worm", "Herman's Hermits", "Ustad Vilayat Khan", "810", "German", "Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Richard Price", "Novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "the Blue Ridge Parkway", "La Scala, Milan", "every aspect of public and private life", "Gary Ross", "Hanford Nuclear Reservation", "Commissioner", "Sam tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epidermis", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "ringo", "1883", "off the coast of Dubai", "Sunday's security breach", "not doing more since taking office.\"", "hard drives", "polio", "the treble clef", "a bond hearing Friday,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7244257478632479}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-2244", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-1559", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-7459", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732", "mrqa_newsqa-validation-1245"], "SR": 0.640625, "CSR": 0.5457454819277108, "EFR": 0.8695652173913043, "Overall": 0.7017340148638029}, {"timecode": 83, "before_eval_results": {"predictions": ["May 29, 1917", "Metacomet", "Chicago", "Leon Trotsky", "a loaf", "a large chart", "The New York Times", "Martin Van Buren", "America Ferrera", "the Pooh", "Charles Gounod", "Alexander Graham Bell", "(Vijay) Singh", "fog", "a modem", "China", "the Boston Red Sox", "Comedy Central", "Hitler", "Man", "Jane's Electro-Optic Systems", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "Africa", "the banjo", "Ulysses S. Grant", "Belle Watling", "Mozart", "American alternative rock band", "Nellie Bly", "Lord Byron", "meningitis", "Douglas MacArthur", "3M", "The Rolling Stones", "Edie Falco", "The Beach Boys", "Oneonta College", "1936 Summer Olympics", "the CN Tower", "The Hurricane", "inheritance", "Maryland", "the cardinal", "Japan", "mad cow", "Prince Edward Island", "Hindu", "pronghorn", "January 2, 1971", "San Francisco", "Moscazzano", "cliff thorburn", "China's total population,", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul John Mueller Jr.", "on horseback in 1959.", "The son of Gabon's former president", "the United States", "in mid November"], "metric_results": {"EM": 0.5, "QA-F1": 0.6086309523809523}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-3392", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-4619", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-16652", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3923", "mrqa_naturalquestions-validation-8884"], "SR": 0.5, "CSR": 0.5452008928571428, "EFR": 0.90625, "Overall": 0.7089620535714285}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Blackbeard", "Jabez Stone", "William Howard Taft", "vermouth", "Pemmican", "Newton-John", "Oahu", "Joseph Smith", "Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "poblano chiles", "Thomas Jefferson", "legislation", "tofu", "Old School", "the Distant Early Warning Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "Variety", "Robert the Bruce", "Zinc", "oxys", "Gargantua", "Elke Sommer", "hoof", "Robin Williams", "Philadelphia", "laundry soap", "Giuseppe Garibaldi", "Morrie Schwartz", "anglerfish", "Jaguar S-Type R", "Thomas Jefferson Family Cemetery", "Mahatma Gandhi", "Brazil", "Jim Thorpe", "the Office", "Jack Crabb", "William Shakespeare", "Frank", "the Bicentennial Symphony", "Haunted Mansion", "Rembrandt", "Gilligan's Island", "to walk with long steps", "buffalo Bill", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "a horizontal desire", "Charlie Drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Asashoryu", "angry over the treatment of Muslims,", "former U.S. secretary of state. William S. Cohen", "Newcastle Falcons"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5826789529914529}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.4, 0.0, 0.5, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.7692307692307693, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-12089", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-2724"], "SR": 0.484375, "CSR": 0.544485294117647, "EFR": 0.9696969696969697, "Overall": 0.7215083277629233}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "hot chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play's the thing\"", "\"The Carol Burnett Show\"", "a panic", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi", "an object oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthe", "Miles Klee", "marsupial", "quid", "Lincoln", "Anthony Newley", "Swimmer's Ear", "Henry", "5", "Greek", "Jeff Probst", "\"Hopelessly Devoted\"", "Nasser", "The Moment of Truth", "Laura", "Ethiopia", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "Bill & George Clinton", "the Straits of Dardanus", "Katharine Hepburn", "American", "Young Frankenstein", "Shout", "to form a higher alkane", "comprehend and formulate language", "Hellenic Polytheism", "Venezuela", "The Shootist", "Sega Saturn", "National Society of Daughters of the American Revolution", "Leonard", "44,300", "it has not intercepted any", "At least 88", "drowned in the Pacific Ocean on November 29, 1981,", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\""], "metric_results": {"EM": 0.578125, "QA-F1": 0.687099358974359}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.33333333333333337, 0.5, 0.6666666666666666, 0.9743589743589743]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-10463", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.578125, "CSR": 0.5448764534883721, "EFR": 0.8148148148148148, "Overall": 0.6906101286606374}, {"timecode": 86, "before_eval_results": {"predictions": ["John Garfield as Al Schmid", "at a given temperature", "season ten", "October 28, 2007", "seven units of measure", "absorbed the superhuman powers and the psyche of Carol Danvers", "Port Said to the southern terminus of Port Tewfik at the city of Suez", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the First Epistle of John at 5 : 7 -- 8", "between the stomach and the large intestine", "Gupta", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "German", "the pulmonary arteries", "Lager", "Justin Timberlake", "Destiny's Child", "position in blackjack relative to the player", "Russell Huxtable", "Husrev Pasha", "Will", "Donny Osmond", "735 feet ( 224 m )", "by polymerizing the first few glucose molecules, after which other enzymes take over", "meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "September 8, 2017", "SURFACE FORA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Hebrew", "nasal septum", "Session Initiation Protocol", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "JackScanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "innermost in the eye while the photoreceptive cells lie beyond", "Donna Mills", "Donna", "Annette Crosbie", "Bobby Kennedy", "Minder", "leopard", "Patricia Arquette", "University Grants Commission", "Symbionese Liberation Army", "102 new jobs for a minimum of nine weeks.", "two", "\"Like a Rock\"", "a cat", "King George III", "Norway"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6301467551733613}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 0.4, 0.761904761904762, 0.28571428571428575, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.11764705882352942, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-5696", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808"], "SR": 0.515625, "CSR": 0.5445402298850575, "EFR": 0.7096774193548387, "Overall": 0.6695154048479792}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol.  2", "Arlo Looking Cloud", "Jyothika Sadanah", "Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teenitans Go!", "The Ramna Stacks", "Book of Judges", "torpedo boats and later submarines", "9 February 1971", "San Francisco, California", "Three's Company", "9,984", "Diondre Cole", "Marktown", "The Rose Theatre", "1 million acre", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237 square miles", "Shakespeare's reputation", "Balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden, on the southern coast", "Noel Gallagher", "Michael Rispoli", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "Austro-Hungarian Army", "St. George", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "his son Louis", "Helsinki, Finland", "Urijah Faber", "four operas", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "November 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "those at the bottom of the economic government whom the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "1920s", "Blue laws", "James Hargreaves", "Puff the Magic Dragon", "Hindi", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "composer", "Thesaurus", "Bath", "Winnipeg", "to offer the hope that a happy day being marked would recur many more times"], "metric_results": {"EM": 0.625, "QA-F1": 0.7090071097883598}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-527", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_searchqa-validation-15272"], "SR": 0.625, "CSR": 0.5454545454545454, "EFR": 0.9166666666666666, "Overall": 0.7110961174242424}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus shifts of backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "as many as 250,000 unprotected civilians", "Ameneh Bahrami", "40", "state senators", "in an Internet broadband deal with a Chinese firm.", "by text messaging", "Hawaii", "Haiti", "Brazil's", "\"wow.\"", "the Transportation Security Administration", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks, and believe he may have sought to participate, possibly as the \"20th hijacker.\"", "Empire of the Sun", "the burning World Trade Center", "collaborating with the Colombian government,", "Washington Redskins fan and loved to travel, but lived just 10 minutes away from where his mother and stepfather raised him.", "time", "the earthquake's devastation.", "Chaffetz", "summer", "southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "stolen the personal credit information of thousands of unsuspecting American and European consumers,", "having trained law enforcement personnel watching people as they enter the mall", "Ricardo Valles de la Rosa,", "Islamabad", "Toffelmakaren", "Wednesday", "Microsoft", "1995", "Jaime Andrade", "Casalesi Camorra clan", "Nigeria", "201-262-2800", "South Africa", "\"We're opening new chapters. And in fact, because some of this information is so new and it's so different from the way we use to think about the moon,", "Chad", "President Obama", "Tuesday", "to reach car owners who haven't complied fully with recalls.", "Mashhad", "Plymouth Rock", "Alina Cho", "Federer", "last week", "gym or facing days of bad weather.", "AbdulMutallab", "10", "second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "axes", "Portugal", "June 17, 2007", "England", "Black Elk", "hollandaise", "kwanzaa", "\"to look like\"", "Javan leopard"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6615501934157604}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.10526315789473684, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4615384615384615, 1.0, 0.6153846153846153, 0.125, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5555555555555556, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.17647058823529413, 1.0, 0.0, 0.5, 0.16666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3110", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-2641", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749"], "SR": 0.5625, "CSR": 0.5456460674157304, "EFR": 0.7142857142857143, "Overall": 0.6706582313402889}, {"timecode": 89, "before_eval_results": {"predictions": ["Salt Lake City, Utah,", "above zero (3 degrees Fahrenheit)", "Swedish Prime Minister Fredrik Reinfeldt", "killing rampage.", "HSH Nordbank Arena", "they did not receive a fair trial.", "The federal officers' bodies", "Bill Haas", "Larry Ellison,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "rising disposable income and an increasing interest in leisure pursuits, a growing number of courses, more television coverage and availability of EU funds,", "Joan Rivers", "The public endorsement", "Phoenix, Arizona, police", "KBR", "a Muslim and a Coptic family", "Jennifer Aniston, Marta Kauffman, co-creator of the series \"Friends\" and Kristin Hahn,", "two years", "the body of the aircraft", "the United States, Japan, Russia, South Korea and China,", "will not support the Stop Online Piracy Act,", "pattern matching.", "Teen Patti", "almost 9 million", "U.S. senators", "the situation of America wielding a big stick for the last eight years.", "London and Buenos Aires", "she returned to Pakistan in October after President Pervez Musharraf signed an amnesty lifting corruption charges.", "Nazi Germany", "Nafees A. Syed,", "a bank", "two", "illegal immigrants", "At least 38", "Sri Lanka,", "The BBC", "\"wipe out\" the United States if provoked.", "after they ambushed a convoy carrying supplies for NATO forces in southern Afghanistan,", "is a city of romance, of incredible architecture and history.", "Stella McCartney", "clogs", "debris", "Jennifer Aniston, Marta Kauffman, co-creator of the series \"Friends\" and Kristin Hahn, who was the executive producer of \"The Departed.\"", "ALS6,", "The EU naval force", "over 1,000 pounds", "time", "help make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "The supplemental spending bill also contains a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "Lindsey Vonn", "three", "the optic chiasm", "Hugo Weaving", "aragonite", "\u201creckless\u201d", "Olympia", "Bruce R. Cook", "Los Angeles", "86,112", "Lewis Carroll", "a soap opera", "the consumer price index", "peterrhyn castle"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5756676045030193}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [0.7272727272727273, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.19354838709677416, 1.0, 1.0, 0.5, 0.0, 0.0, 0.23529411764705885, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.1739130434782609, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.1, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-906", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-3753", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3267", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.484375, "CSR": 0.5449652777777778, "EFR": 0.8787878787878788, "Overall": 0.7034225063131313}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon", "Ebony", "Cook", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "a Dormouse", "the Romans", "a cow pie", "Paradise Lost", "Beautiful", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "Earthquakes", "July 1966", "Best Supporting Actor", "The Bionic Woman", "5000", "wrinkles", "Narnia", "comet Tempel 1", "Mount Sinai", "Kamehameha", "(Elbert) Gary", "corporality", "crowded", "\"Duke\"", "Orlans", "Another Brick in the Wall", "Pulp Fiction", "Hester Prynne", "pajama", "Dynasty Class", "a bagpipe", "a stork", "cruises", "Henry David Thoreau", "Encephalitis", "the Philippines", "Sydney", "Hudson Bay", "restored to life", "The long - hair gene is recessive", "the Canaries", "Another Day in Paradise", "The Danelaw", "Donald Wayne Johnson", "Robert A. Iger", "Manchester Airport", "Iowa,", "16", "North Korea", "financial gain,"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7223958333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-9946", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-7563", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-4724", "mrqa_newsqa-validation-1072"], "SR": 0.6875, "CSR": 0.5465315934065934, "EFR": 1.0, "Overall": 0.7279781936813187}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff, Wales", "keirin", "welterweight and Light Middleweight", "Christopher Nolan", "Wolfgang von Goethe", "a highball", "Conan Doyle", "Godfigu", "brain", "six", "Bashir", "dog sport", "The Double", "arsenic", "omega", "Mickey Mouse", "Clove", "The Welcome Stranger", "recorder", "UAE", "Genesis", "Ladysmith", "californium", "Robert Guerrero", "Arizona Diamondbacks", "George Orwell", "Goldie Myerson", "Brunel", "to the tooth,\" meaning that it still has a little bite.", "William Shakespeare", "early 1960s", "Some Like It Hot", "Beaujolais", "morphine", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "Roger of Montgomery", "St. Thomas \u00e0 Becket", "bullfighting", "leicestershire", "cycling", "the Crimean Tatar", "bedding", "Switzerland", "Shanghai", "Duke Orsino", "\"Founder's Day\"", "the Swordfish", "France", "Australia", "France", "17 - year - old Augustus Waters", "1898", "January 1923", "The 1984 South Asian Games", "Rana Daggubati", "four", "1,500", "a group of teenagers.", "38 feet", "Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6267857142857143}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.7142857142857143, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-11134"], "SR": 0.546875, "CSR": 0.5465353260869565, "EFR": 0.6896551724137931, "Overall": 0.6659099747001499}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "from 1979 to 2013", "two", "2001", "Meghan Markle", "2006", "alcoholic drinks for consumption on the premises", "Seoul, South Korea", "Dutch", "the 43rd Vice President of the United States from 1981 to 1989", "political correctness", "Russell Humphreys", "Wisconsin and the Upper Peninsula of Michigan", "Tuesday, January 24, 2012, at 8 p.m. ET/PT.", "over 3 million", "Mazda", "Jack St. Clair Kilby", "\"My Father\"", "water", "more than 70", "a type of blood pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko Takehita", "patosaurus", "TD Garden", "Due to the controversial and explicit nature of many of their songs,", "Sam Kinison", "Melbourne Storm", "Hawaii", "2007", "Texas", "Prudence Jane Goward", "Vincent Anthony Guaraldi", "\"What's My Line?\"", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Mathew Sacks", "Charles VI", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "defense against rain rather than sun", "the eurozone", "Jane Seymour", "Willie Nelson", "1984", "Argentine", "around 3.5 percent", "Ali Bongo", "Antietam National Battlefield", "your premium", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6755208333333333}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.4, 0.0, 0.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1662", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-372", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-2586", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.53125, "CSR": 0.5463709677419355, "EFR": 0.8666666666666667, "Overall": 0.7012794018817204}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "Edward R. Murrow", "Liesl", "Stage Stores", "\" Training Day\"", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "the Crab Orchard Mountains", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the Provisional Irish Republican Army (IRA) in Northern Ireland", "Tel Aviv", "Chevy Motor Car Company", "the tissues of the outer third of the vagina", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America: A Journal for Writers and Readers", "Love Letter", "2013", "Half Hollow Hills Central School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Scottish novelist and poet", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow", "George Martin", "Kevin Kur\u00e1nyi", "Adam Dawes", "Enkare Nairobi", "Rockland", "2009", "Vietnam War", "Toto", "9 February 2018", "Cheap trick", "Gabriel Byrne, Kevin Spacey, Benicio Del Toro, Kevin Pollak, and Stephen Baldwin", "Funchal", "British", "Scudetto", "it would investigate the video and any group that tries to take justice into its own hands.", "because a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6998384581105169}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.2857142857142857, 0.4444444444444445, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.2222222222222222, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5586", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-4194", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694"], "SR": 0.59375, "CSR": 0.546875, "EFR": 0.8461538461538461, "Overall": 0.6972776442307692}, {"timecode": 94, "before_eval_results": {"predictions": ["\"if a man does not keep pace with his companions, perhaps it is because he hears a different drummer.\"", "Hitler", "Mrs. Miniver", "Cowell", "Eagles", "a neon tube", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "Anne Frank", "Bora Bora", "Cops", "Nassau", "a geisha", "France", "the corsairs", "CIA", "antimicrobial", "the Blackberry", "fasting", "Phonetics", "Crosby, Stills and Nash", "Frasier", "paper tickets", "a rocket", "the Court of Cassation", "Yucatan", "Jeopardy", "Afghanistan", "Australia", "buffalo", "the northeastern landmass", "the College of Physicians and Surgeons", "pitch", "Peter Edward \"Pete\" Rose Sr.", "Esther", "South Africa", "Slim", "GoldenEye", "anthropology", "Dumbo", "Edith Wharton", "Aretha Franklin", "marsupials", "Italian", "The Crow", "three", "Orson Welles", "mongoose", "Russell Crowe", "Ecuador", "Apokalypsis", "four", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "Friends", "frankincense", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "the Runaways", "Pieter van Musschenbroek", "Seoul", "\" Fortunately, I've been feeling better every single day since surgery and this weekend my doctors gave me the green light to get back to work.\"", "the Klan experienced a huge resurgence. Its membership was skyrocketing, and its political influence was increasing, so Kennedy went undercover to infiltrate the group.", "The Krankies"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6656125992063492}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.1111111111111111, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-579", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-9760", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.59375, "CSR": 0.5473684210526315, "EFR": 0.8076923076923077, "Overall": 0.6896840207489878}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Mallow", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "The Memory Keepers daughter", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "Dow Jones Industrial Average", "Aunt Jemima", "fowls", "dynasties", "Homer", "Amanda Bynes", "Danson", "O. Henry", "middle-aged", "B.B. King", "Jacqueline Lee", "Donovan", "Cephalopod", "Candlestick Park", "a carpenter's plane", "just compensation", "Vodka", "pickled", "Adam", "Joan of Arc", "Ivy Dickens", "faint", "thunder", "Ham", "calamine", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Caleb", "1957", "Jurchen Aisin Gioro clan", "wilt", "Little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "Newark's Liberty International Airport,", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6461309523809524}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-13003", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-10119", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-12050", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-15970", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.578125, "CSR": 0.5476888020833333, "EFR": 0.8518518518518519, "Overall": 0.698580005787037}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "Pietro Vannucci", "Unbreakable", "Holy Week", "Tijuana", "Wizard", "kilobytes", "Planned Parenthood", "Jamie Lee Curtis", "Ellen DeGeneres", "saray", "Alexander Graham Bell", "the Northern Mountain covered region of India", "a baffle", "corpulent", "The Cartoonists", "Erin Go Bragh", "Queen Victoria", "giant slalom", "Medusa", "zoology", "Lucia di Lammermoor", "a globe", "cricket", "Stephen Hawking", "St. Francis of Assisi", "lumens", "The Scarlet Letter", "2016", "a rehab facility", "pastries", "The Hundred Years' War", "Metropolitan Museum of Art", "milk and honey", "3", "Stenosis", "The Beatles", "the Bronx", "a disaccharide", "King Kong", "Cubism", "Umbria", "Cottage cheese", "MC Escher", "Oahu", "the kidney", "Scott Fitzgerald", "aria", "The three comics, plus Ernie Hudson, play the New York City-based team", "Marquette University", "The House of Rothschild", "Fall 1998", "infection, irritation, or allergies", "Bart Howard", "the Netherlands", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "in early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6927083333333334}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16364", "mrqa_searchqa-validation-4803", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-11397", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-14498", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-7573", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-333", "mrqa_naturalquestions-validation-2666", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.609375, "CSR": 0.5483247422680413, "EFR": 0.92, "Overall": 0.7123368234536083}, {"timecode": 97, "before_eval_results": {"predictions": ["35 cm", "gold rings", "Gaston Leroux", "Concorde", "gold", "European Economic Community", "Glasgow and that of Westminster", "Vietnam", "Florence", "Wanderers", "Emilia Fox", "Amnesty International", "krak\u00f3w", "Shaft", "gal", "Ramadan", "bizet", "the Count Basie Orchestra", "Pegida", "uranium", "Eva Strong", "Edward Hopper", "Einstein", "faversham", "Justin Trudeau", "Robin Williams", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "Bolivia", "Christian Wulff", "marinated dried fruits", "river usk", "spider", "Malcolm Turnbull", "Daily Herald", "Nairobi", "Alan Turing", "tendon", "the right atrium", "Puck", "Hula-Hoops", "Dubonnet", "Lady Susan", "Rocky Graziano", "sweater", "Today", "Today", "Gene Vincent", "Midgard", "a reaction of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus, causing changes in gene expression", "USS Chesapeake", "Ben Faulks", "as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "the right bank of the Gomti River", "Art of Dying", "Sergeant. Jason Bendett", "iPhone 4S", "Christopher Savoie", "Plouton", "Ingenue", "First World War", "Joseph"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6799107142857144}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.11428571428571427, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-4272", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947", "mrqa_searchqa-validation-1427"], "SR": 0.640625, "CSR": 0.5492665816326531, "EFR": 0.7391304347826086, "Overall": 0.6763512782830523}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "eagles", "jerry mouse", "cirrus uncinus", "procol harum", "river alt", "british city", "bude", "Uganda", "st Pancras", "lactic acid", "villefranche", "Robinson Crusoe", "once a week", "my Favorite martian", "whist", "fear of snakes", "Madagascar", "Wyatt", "April", "One Direction", "The West Wing", "Prince Harry", "1994", "titanium", "leicestershire", "Pegasus", "alaskan", "jenimore Cooper", "Brazil", "the rhizome", "rawhide", "eyes", "karst", "bowie knife", "the Congo River", "tiger", "Independence Day", "Tinie Tempah", "Portugal", "Greek", "pushchair", "beard", "Amy", "oldham, in Greater Manchester, England", "Sunday Post", "darin", "emirate", "jimmy armstrong", "lady Susan", "South Africa", "Cam Clarke", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican War on Drugs", "relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi ethnic minority and the Hutu majority", "The Tempest", "Naples", "Solomon", "heavier than a feather"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5621775793650793}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.5, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-6169", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-2151", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.453125, "CSR": 0.5482954545454546, "EFR": 0.8, "Overall": 0.6883309659090909}, {"timecode": 99, "UKR": 0.78515625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.80859375, "KG": 0.51015625, "before_eval_results": {"predictions": ["stoned to death by an angry mob.", "37", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob", "crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "Red Lines", "The Kirchners", "Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "Arsene Wenger", "Arnold Drummond", "Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "Alejandro Peralta", "Kerstin Fritzl,", "Amnesty International.", "the Dr. Octopus", "\"Let it Roll: Songs by George Harrison\"", "overthrow the socialist government of Salvador Allende in Chile,", "a lump in Henry's nether regions", "reached an agreement late Thursday", "snow,", "\" Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "students at the school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "Three thousand", "burning of a church.", "death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "2,000", "park bench facing Lake Washington", "Cirque du Soleil", "9", "for the rest of the year", "nihonium", "Bobby Darin", "foreign investors", "neck", "wrigley", "CBS", "round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.546875, "QA-F1": 0.653476314791839}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.7741935483870968, 1.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.25, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2925", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793"], "SR": 0.546875, "CSR": 0.54828125, "EFR": 0.7586206896551724, "Overall": 0.6821616379310345}]}