{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4140, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "P,NP-complete, orNP-intermediate", "Daniel Burke", "the highest terrace", "major national and international patient information projects", "three", "net force", "12 January", "1976\u201377", "Cleveland, Phoenix, Detroit and Denver", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30%", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "teachers in publicly funded schools", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8169890873015873}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.78125, "CSR": 0.7734375, "EFR": 0.9285714285714286, "Overall": 0.8510044642857143}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "accelerate to six times its normal speed", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "1898", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay in Alaska", "120 m ( 390 ft )", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj )", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "the Ironclads", "Spain"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8090759500915752}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.888888888888889, 0.4444444444444445, 1.0, 0.4, 1.0, 0.34285714285714286, 0.38095238095238093, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.71875, "CSR": 0.7552083333333334, "EFR": 0.9444444444444444, "Overall": 0.8498263888888888}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle which uses rubisco", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw), who may sign them into law", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "December 1971", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7590888278388278}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.5714285714285715, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-8833", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.65625, "CSR": 0.73046875, "EFR": 0.9545454545454546, "Overall": 0.8425071022727273}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Bruno Mars", "the Yuan dynasty", "same-gender marriages", "red algae red", "after their second year", "1960s", "narcotic drugs were controlled in all member states", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15 Saturn V rockets", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "the kettle and the Cricket", "Gandhi", "Bucharest", "The Little Foxes", "Betamax", "Leonard Nimoy", "8/4 x 365", "Terry Noe", "the University of Arizona", "Marshall Dillon", "the Bosporus Bridge links", "The Best Hotels on Bali", "Mary F. Kennedy", "LASER abbreviation", "George Dapra", "Saturn", "Orchids and other rare plants are potted in peat moss to keep them from", "why", "Andrew Taggart, Emily Warren and Scott Harris", "fear of riding in a car", "American", "Mexican military"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6564123376623376}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2804", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.5625, "CSR": 0.696875, "EFR": 1.0, "Overall": 0.8484375}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "complexity theory", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely to member state size", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kenyan athletes (particularly Kalenjin)", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Santa Clara, California", "ten million people", "the Lippe", "Video On Demand content", "mathematical models of computation", "semester calendar", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "The Jewish Star", "the League of the Three Emperors", "the field of science", "143,007", "the National Intelligence Council (NIC)", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "(Bones remains the oils base man still)", "German", "Fort Valley, Georgia", "American", "Easy (TV series)", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "(Hansi) Harris", "corruption", "The (usually vain) attempt to answer the question, \"How long have I got, doc?\"", "Dover Beach"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7657584602897103}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 0.3846153846153846, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.75, 1.0, 0.30769230769230765, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-6218", "mrqa_squad-validation-4919", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-12", "mrqa_squad-validation-9753", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.6875, "CSR": 0.6953125, "EFR": 1.0, "Overall": 0.84765625}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the Court of Justice of the European Union", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government (or to change cultural traditions, social customs, religious beliefs, etc...revolution doesn't have to be political", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "larger fortunes generate higher returns", "Spanish", "Structural geologists", "president and CEO", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "the Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Elizabeth Langenkamp (born July 17, 1964)", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "Liverpool and England international player", "Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "25.2 % ( 79 out of 313 )", "Algeria", "romantic", "the Eastern part", "Polar Bear", "The first section of the Atlantic City Boardwalk"], "metric_results": {"EM": 0.625, "QA-F1": 0.7615742050025138}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.2, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.20512820512820512, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-3939", "mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-7543", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.625, "CSR": 0.6852678571428572, "EFR": 0.9583333333333334, "Overall": 0.8218005952380953}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "input", "means to invest in new sources of creating wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "the Alter Rhein (\"Old Rhine\")", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "entire length of the lake", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "a deterministic Turing machine", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid ruler", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "1974", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy role-playing game", "Martin \"Marty\" McCorm (born 20 July 1983)", "Black Mountain College", "a historic house museum in Ankara, Turkey", "Bothtec", "Cody Miller", "140 to 219", "John Locke", "Christophe Lourdelet", "Pablo Escobar", "African descent", "Mexico City", "Sleeping Beauty", "October 2, 1967 to August 21, 1995", "1985", "Noddy Goes To Toyland", "Ali Bongo", "Raphael Chex", "Ray Harroun", "Emily Blunt", "David Tennant"], "metric_results": {"EM": 0.625, "QA-F1": 0.6884672619047618}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6, 0.5, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-7547", "mrqa_squad-validation-9183", "mrqa_squad-validation-1819", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-3510", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-3413", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.625, "CSR": 0.677734375, "EFR": 0.9583333333333334, "Overall": 0.8180338541666667}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "during the compression stage relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "the constituting General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet-powered tailless delta wing", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham", "A55", "Ranulf de Gernon", "\u00c6thelstan", "Madras Export Processing Zone", "44", "NCAA's Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "diastema ( plural diastemata )", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.75, "QA-F1": 0.8055871212121213}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-1501", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305"], "SR": 0.75, "CSR": 0.6857638888888888, "EFR": 1.0, "Overall": 0.8428819444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "French", "Museum of the Moving Image in London", "sent missionaries", "pyrenoid and thylakoids", "Woodward Park", "refusal to submit to arrest", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "youngest publicly documented people to be identified as transgender", "Trent Alexander-Arnold", "David Michael Bautista Jr.", "Black Friday", "American actor, singer and a DJ", "Prince Amedeo", "Lambic", "Baja California Peninsula", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "Afroasiatic", "James Tinling", "Italy", "2015 Masters Tournament", "Kristoffer Rygg", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "King Massinissa", "more than 22 million", "morphine sulfate oral solution 20 mg/ml", "Harvard Law", "freshwater catfish"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6872549372571609}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.678125, "EFR": 1.0, "Overall": 0.8390625}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "tight end Owen Daniels", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "not covered in any newspapers", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks", "it was a school within the Austro-Hungarian Military Frontier", "devised a Standard Model", "Tolui", "the Rhine-Ruhr region", "course of study", "God to turn us from our sin-corrupted human will to the loving will of the Father", "the University of Kansas", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "the \"Mr. Magoo\" character", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Bath, 1820", "Ector County", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Caviar", "Sir Giles Gilbert Scott", "the rig did not know whether it was working when they fled the burning rig", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "London"], "metric_results": {"EM": 0.609375, "QA-F1": 0.713504400832907}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 0.2, 0.8, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04878048780487805, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6927", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-10309", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_squad-validation-9803", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_naturalquestions-validation-7415", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.609375, "CSR": 0.671875, "EFR": 1.0, "Overall": 0.8359375}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "The climate is cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "\"shock\"", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "Cash for Clunkers", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "deciding the duties of the new prime minister has been a sticking point in the negotiations", "lack of a cause of death", "200", "pizza, the other for the drug ketamine", "opposition party members", "Missouri", "Reid's dismissal", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "the Employee Free Choice act", "Bush administration", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "Christopher Savoie", "Dan Parris, 25, and Rob Lehr, 26", "near Fort Bragg", "two", "nearly $2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "Winehouse", "Ark of the Covenant ( the Aron Habrit in Hebrew )", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "Thomas Hardy", "Selby", "1994", "The Conjuring", "Australia", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6549011752136753}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.6, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.546875, "CSR": 0.6614583333333333, "EFR": 0.9310344827586207, "Overall": 0.796246408045977}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "Christ who is the victor over sin, death, and the world.", "Napoleon", "new technology and machinery", "Arley D. Cathey,", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives,", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars,", "the Catechism", "beneath the university's Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "Marrix", "Salvador Allende", "Harold Pinter", "Hawaii", "Erik", "Marsyas", "the 1940 Rodgers and Hart musical Pal Joey.", "Mary Seacole", "green", "Indonesia", "Jesus", "Antonio", "European Economic Community", "Christine Keeler", "Jesus", "John Joseph \"Jack\" Nicholson", "four", "Netherlands", "Sugar Baby Love", "Rosa Parks", "Sean", "Bill and Taffy Danoff", "beginning at Stage 1", "Travis", "The Show", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "Rudyard Kipling", "barber", "Harry Hopman", "Murrah Federal Office Building", "Evita", "a litter of pipes on the mantelpiece", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's", "no mention of their relationship with co-stars Chris Noth or John Corbett?", "a delegation of American Muslim and Christian leaders", "bath Cavendish", "University of South Carolina", "Juan Martin Del Potro."], "metric_results": {"EM": 0.515625, "QA-F1": 0.5802331349206349}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 0.5, 0.07142857142857144, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120"], "SR": 0.515625, "CSR": 0.6502403846153846, "EFR": 0.967741935483871, "Overall": 0.8089911600496278}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "mole", "Democritus", "phoebus", "Anne Boleyn", "a man was the 2nd U.S. president to be assassinated.", "Steve McQueen", "Portugal", "jazz tenor saxophonist", "one", "komando Pasukan Khusus", "the county\u2019s largest urban area", "a liquid form", "zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "aniridia", "Charles A. Carpenter", "River Forth", "woe", "NOW Magazine", "a black mare", "Italy", "Canada", "typhoid fever", "fred Turner", "action figure", "a bumpersticker", "2010", "the volume of a given mass of a gas increases or decreases by the same factor as its temperature", "Venezuela", "aaron", "phoebus", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Chris Weidman", "Athletics Stadium", "one", "Virgin America", "aaron", "phoebus", "Iran's parliament speaker", "Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike."], "metric_results": {"EM": 0.5, "QA-F1": 0.5401041666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-2463", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.5, "CSR": 0.6395089285714286, "EFR": 0.96875, "Overall": 0.8041294642857143}, {"timecode": 14, "before_eval_results": {"predictions": ["an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically bonded to each other", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow", "public", "the most cost efficient bidder", "sassafras", "Continent", "thighbone", "Olympia", "Ukraine", "shrews", "stanley johnson", "bennett", "amber", "Princeton University", "The executioner's Song", "angle", "bishkek Tajikistan", "anamosa", "stanley johnson", "The Comedy of Errors", "asylum", "film", "knife", "fiery light", "Cologne", "Leadership Academy for Girls", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "silk laurel", "cowboys", "Winston Churchill", "shrew", "south Korea", "burt Reynolds", "South Korean", "detroit", "windjammer", "tramp", "George Washington", "Augusta", "counter clockwise direction", "March 31, 2013", "Nick Hornby", "Coldplay", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama's current \"middle way approach,\"", "mother's market", "Israel"], "metric_results": {"EM": 0.40625, "QA-F1": 0.48671875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.25, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-3488", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-4647", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084"], "SR": 0.40625, "CSR": 0.6239583333333334, "EFR": 0.9736842105263158, "Overall": 0.7988212719298247}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rijn", "1996", "wine", "German", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "crossword", "Jerry Maguire", "Strongsville, Ohio", "Flemish", "MasterCard", "Grant Wood", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "a tan or brown macule", "a gang of ex-cons", "Toronto Maple", "Zsa Zsa Gabor", "Stanislavsky", "Utah", "rum", "(Rabbit) Angstrom", "Johann Strauss II", "Bill", "Grant Wood", "the University of Siena", "The Fun Factory", "a beer", "Manfred von Richthofen", "Nacho Libre", "copper", "devils or demons", "the hemlock", "Lowell Bergman", "poetry", "The Runza Way", "deficient", "Mrs. Miniver", "Grant Wood", "a parrot", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "Grant Wood", "a tin star", "Noir", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "three", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.546875, "QA-F1": 0.60625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-6772", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.546875, "CSR": 0.619140625, "EFR": 1.0, "Overall": 0.8095703125}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho Chi Minh", "circumference", "the Inuit's dwelling", "Detroit", "the Blue Jays", "Walt Whitman", "Ray Bradbury", "hate crimes", "King Julien", "Nicolas Sarkozy", "Rubicon", "(Conello)", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Thomas", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "Bellerophon", "Balaam", "The Wharton School", "The Caine Mutiny", "Rolling Stone", "(Charlie) Woolworth", "(John) Coltrane", "peace sign", "oxygen", "the Sphinx", "Jan Hus", "The USA Network", "Mavericks", "Onegin", "Macy's", "a spinning mule", "Santa Claus", "(Denzel) Washington", "negligence", "the courts", "attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "prisoners", "salary", "the punishment for the player"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6945684523809523}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-3690"], "SR": 0.640625, "CSR": 0.6204044117647058, "EFR": 0.9565217391304348, "Overall": 0.7884630754475703}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Benjamin Vail", "a telephone ring", "the Party of National Unity", "22 miles", "the dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "the latest from Keep Hope Alive Radio", "the Philippines", "the Mausoleum", "Million Dollar Baby", "Switzerland", "previously, it had", "The Old Man and the Sea", "French", "Joe Louis", "the Nemean lion", "Les Trois Mousquetaires", "the Bayeux Tapestry", "a covered shelter", "China", "the mainstream Jafari School of", "notes placed at the bottom of a page", "Stephen Hawking", "Mrcus Tullius Cicero", "Memphis", "Pepsi", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "a Belgian-owned Canadian beer company", "sicko", "Oman", "Chevy", "a play", "Lake Erie", "Don Juan", "Ian Fleming", "a horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "a salt", "Bromley-By- Bow", "the Ruul", "Cartoon Network", "a small child", "know what's important in life", "Rabbani, a former Afghan president who had been leading the Afghan peace council, was killed in an attack at his home.", "a nuclear weapon", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6014583333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-7710", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-2709", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-14588", "mrqa_searchqa-validation-4410", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-6024", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-105", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.5625, "CSR": 0.6171875, "EFR": 1.0, "Overall": 0.80859375}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "Tesla's friend", "tentacles", "Robert R. Gilruth", "computational", "same-gender marriages", "2006", "the mid-18th century", "orange", "MASH", "the Sistine Chapel", "bielaruski", "the flanker", "a trowel", "Big Bang", "The Sex Pistols", "endodontist", "Saturn", "the Cliffs of Denmark", "Genoa", "Galt", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Kansas", "Seattle", "a rose", "the Confusion Cookery", "10", "the Civil War", "alevin", "Paul McCartney", "omega-3", "The School of Athens", "Bachman Turner Overdrive", "ParaNorman", "Paddy Shack", "Tokyo", "Panama", "Confession", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "the Bear", "a quake", "Judas", "the elephant", "Pomerania", "Sweden", "a clandestine love affair", "our Country", "May 2010", "Statista", "Sugarloaf", "Thailand", "gender queer", "Minister for Social Protection", "the National Archives", "his house", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Michigan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5439236111111111}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.1111111111111111]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_squad-validation-1648", "mrqa_squad-validation-1696", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-3343", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.4375, "CSR": 0.6077302631578947, "EFR": 0.9722222222222222, "Overall": 0.7899762426900585}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified plants", "Earth", "more than 53,000", "one", "poet", "two points", "20,000", "the kip", "in skeletal muscle and the brain", "2014", "a single peptide bonds", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia", "Proposition 103", "mindfulness", "Charlene Holt", "Frank Theodore", "1991", "118", "The Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Toledo, Bowling Green, and Mount Union", "a form of business network", "a cylinder of glass or plastic", "an opposing, self - maintaining infinite cycle based on natural history", "Wakanda", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "an individual worm", "February 28", "the Lykan", "the American Civil War", "an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "a man called Lysander", "Earth", "the Mediterranean world", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "the olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6204551091269841}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 1.0, 0.625, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.515625, "CSR": 0.603125, "EFR": 0.967741935483871, "Overall": 0.7854334677419355}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "70", "death of a heretic", "his Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "\"bystander effect\"", "\"Listen, don't rush on boats to leave the country. Because I'll be honest with you: If you think you will reach the U.S.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer in five vignettes", "well over 1,000 pounds", "political dead-end we lived in then", "Mutassim", "Oklahoma City's Will Rogers World Airport", "Polo", "Joe Jackson", "Amstetten", "computer problems left travelers across the United States waiting in airports", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus shifts", "Brad Blauser", "September, 2004", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "in all of Lifeway's 100-plus stores nationwide", "Akio Toyoda", "\"There's no chance of it being open on time. Work has basically stopped,\" Bloomberg said during a press conference Thursday.", "\"There is a pressing need for them to be released,\"", "\"We're set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "the children that a French charity attempted to take to France from Chad for adoption", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "winter solstice", "Whitsunday", "\"the mouths of two rivers.\"", "\"Dumb and Dumber\"", "The 2004 Nokia Sugar Bowl", "Earl Warren", "\"parallel to the optical axis\"", "autu", "season five", "The Force Fighters ( 2015 )"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6088017798174048}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.8750000000000001, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.1904761904761905, 0.08, 0.05714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-2466", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-3226", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.515625, "CSR": 0.5989583333333333, "EFR": 1.0, "Overall": 0.7994791666666666}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers.", "San Diego-Carlsbad-San Marcos metropolitan area", "chief electrician", "Newton", "static friction, generated between the object and the table surface", "the assassination of US President John F. Kennedy the previous day", "the Kenyan forces crossing of the joint border as \"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "not the one to be dealt with by us.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Louisiana Gov. Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad, Iran.", "Amanda Knox's aunt", "jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Cal Ripken Jr.", "J.G. Ballard", "Dr. Conrad Murray", "Sarah", "making me thinking about what I would want to do when I got out of the game.", "1981", "\"17 Again,\"", "Nigeria", "$81,88010", "Republican", "EU naval force", "Allison Bridges", "Omar Bongo", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5.", "he underestimated the number of swimmers who would come to swim at the club.\"", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military strike", "The White House Executive Chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2012)", "Northumbrian", "Ophelia", "Elena Ceausescu", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Eduard Leopold,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6002791173287497}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 0.13333333333333333, 0.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.1, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.5, "CSR": 0.5944602272727273, "EFR": 0.96875, "Overall": 0.7816051136363636}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Germans", "New York and Virginia,", "two", "glowed even when turned off.", "Pastor Paula White", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "her most important work is her charity, the Happy Hearts Fund.", "backbreaking labor", "a federal judge in Mississippi", "the department has been severely affected by the earthquake,", "$22 million", "severe flooding", "a music video on his land.", "walked off the job January 28 to protest the hiring of hundreds of foreign workers for a construction project at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "the commissions are OK, \" provided that they are properly structured and administered.\"", "Kase Ng", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "women.", "it will be the longest domestic relay in Olympic history,", "Zimbabwe's main opposition party said Sunday.", "No. 1", "nine", "four bodies", "Friday", "The tower will be built in the Saudi town of Jeddah and will be part of a larger project that will cost $26.7 billion", "a Muslim with Lebanese heritage,", "Tuesday night", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "only one", "his salary", "alwin Landry's supply vessel Damon Bankston", "researchers have developed technology that makes it possible to use thoughts to operate a computer, maneuver a wheelchair or even use Twitter", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Fakih", "the Isthmus of Corinth", "Nalini Negi", "( 2017 - 12 - 10 )", "Runcorn", "collarbone", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6015234038513502}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.22222222222222224, 1.0, 1.0, 0.0, 0.8235294117647058, 1.0, 0.5, 0.10526315789473685, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.046511627906976744, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-1743", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.453125, "CSR": 0.5883152173913043, "EFR": 1.0, "Overall": 0.7941576086956521}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "56,", "Yemen", "2005", "Karen Floyd", "six Iraqis and wounded 10 others,", "those missing", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over,\"", "threatening messages", "stop Noriko Savoie from being able to travel to Japan for summer vacation.", "Citizens are picking members of the lower house of parliament,", "fake his own death", "the charges \"in the interest of justice.\"", "martial arts,", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "April", "Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.\"", "Zuma", "haute, bandeau-style little numbers", "five", "Iraqi Prime Minister Nouri al-Maliki", "2000", "about 50", "15-year-old", "in body bags on the roadway near the bus,", "al Fayed's", "Desmond Tutu", "$1.4 million", "Jobs", "$81,880", "provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "atransformiation, change of mind, repentance, and atonement", "Jason Lee", "REM sleep", "a word that functions as the name of some specific thing or set of things,", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "the Thinkpad", "Apollo 13 Commander", "Florida"], "metric_results": {"EM": 0.5625, "QA-F1": 0.663197353830665}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.962962962962963, 0.19999999999999998, 0.5, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9787234042553191, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-957", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.5625, "CSR": 0.5872395833333333, "EFR": 1.0, "Overall": 0.7936197916666666}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "The Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Lindsey Vonn", "Frenchwoman", "him to step down as majority leader.", "United Nations World Food Program vessels", "gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "ancient Egyptian antiquities in the world", "invited camps in the Philadelphia area to use his facility because of the number of pools in the region closed due to budget cuts this summer.", "like the video-game challenge of continuously trying to best your own fuel economy achievements,\"", "1979", "Heshmatollah Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh,", "Michael Arrington,", "one out of every 17 children under 3 years old in America", "President Sheikh Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "\"Britain's Got Talent\"", "military personnel", "placed behind the counter.", "11", "one", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "to introduce those unfamiliar with a vegan diet to some of the flavorful foods they can eat.", "Amado Carrillo Fuentes", "Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "would compromise the public broadcaster's appearance of unbiasedity.", "\" you know -- black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "Drug trafficking is a transnational threat, and therefore national initiatives have their limitations,\"", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance for parts of the Midwest", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "Washington.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance Your Ass Off.\"", "Russian residents and worldwide viewers,", "\"Rockers of the Lost Ark.\"", "committing adultery,", "nucleus", "establishment of a confederated Germany, the division of Italy into independent states, the restoration of the Bourbon kings of Spain, and the enlargement of the Netherlands to include what in 1830 became modern Belgium", "Sebastian Lund ( Rob Kerkovich )", "President Carter", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5501147573868106}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.25, 0.18181818181818182, 0.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.23529411764705882, 0.4, 0.05555555555555555, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.14285714285714288, 0.0, 0.7499999999999999, 0.0, 1.0, 0.0, 0.10256410256410256, 1.0, 0.0, 1.0, 0.4, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0689655172413793, 0.6666666666666666, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.453125, "CSR": 0.5818749999999999, "EFR": 1.0, "Overall": 0.7909375}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "large scale", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "10:29 a.m.", "specialist", "beetle", "phylum", "Wayne Allwine", "Westminster Abbey", "holography", "Pelias", "Joshua Radin.", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "quant pole", "copper and zinc", "Tigris", "Cordelia,", "pamphlets, posters, ballads", "pityriasis capitis", "50", "a Rh\u00f4ne Grape Varietal", "Joseph Smith,", "Huntington Beach, California", "palladium", "the moon", "13.", "petticoat", "The Apartment", "France", "Clement Attlee", "Stockholm", "Peter Parker", "Goldie Myerson,", "Salvatore Ferragamo,", "bullfight", "Sparks", "Ginger Rogers", "the Mayflower", "Comedy Playhouse", "citric", "Charles Darwin", "John  Denver,", "Mrs. Boddy", "Marie Van Brittan Brown", "Southern California Timing Association", "1995,", "Bourbon County", "Taylor Swift", "Ciesza, Charli XCX, Jacob Plant, and Jennifer Lopez.", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "Rima Fakih is a Muslim with Lebanese heritage,", "Amy Bishop", "calathus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5517156862745098}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.1764705882352941, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-5986", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.484375, "CSR": 0.578125, "EFR": 0.9696969696969697, "Overall": 0.7739109848484849}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "New York studio", "elephants", "a charcoal powered grill, stove or hot plate", "Frank McCourt", "Michael Strogoff", "Judy Cassab", "Margo Leadbetter", "eec", "\u201cA\u201d", "city of Sheffield, England", "Famous Players-Lasky Corporation", "MTV", "Gerald Durrell", "jzebel", "County Cork", "jason", "Arabian", "Halifax", "mccartney", "jason", "Stephen Potter", "Carlos the jackal", "Edwina Currie", "st Moritz", "Robert Maxwell", "1768", "\u201cFor Gallantry,\u201d", "a Tuesday's child", "chicago", "Cahaba", "The Good Life", "Tahrir Square", "plutonium", "a mrs mrs f\u00e8re", "27", "Jack Ruby", "tintoretto", "Eric Coates", "Saudi Arabia", "arson", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "canterbury", "Tokyo", "Edgar Lungu", "49 cents", "a heart rate that exceeds the normal resting rate", "672", "\"Linda McCartney's Life in Photography\", \"Some Like It Hot\", \"Kubrick's Napoleon: The Greatest Movie Never Made\", \"Saturday Night Live: The Book\",", "Robert Frost's former home", "@", "Juan Martin Del Potro.", "27,", "german", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.484375, "QA-F1": 0.4981770833333333}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4166666666666667, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-1354", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_searchqa-validation-12829"], "SR": 0.484375, "CSR": 0.5746527777777778, "EFR": 1.0, "Overall": 0.7873263888888888}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "forced Tesla out leaving him penniless.", "benazir Bhutto", "nuclear", "at least 27 Awa Indians", "(l-r) Paul McCartney, Yoko Ono Lennon, Olivia Harrison and Ringo Starr", "FBI Special Agent Daniel Cain,", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Afghanistan", "Florida Everglades", "made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "a 15-year-old boy", "$163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "carbon neutral airline.", "oaxaca", "Orbiting Carbon Observatory", "Switzerland", "Robert Redford", "Janet and La Toya,", "more than 22 million people in sub-Saharan Africa", "hours", "combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "his injuries,", "al-Shabaab", "by posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opry Mills,", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "President Barack Obama", "\"gotten the balance right\"", "The oceans", "burned his back", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "1925", "Gilda", "jeremy wilson", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "the Empire State Building", "Disraeli", "sun"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6151909722222222}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816"], "SR": 0.515625, "CSR": 0.5725446428571428, "EFR": 1.0, "Overall": 0.7862723214285714}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai", "Monday night", "Bailey, Colorado", "journalists and the flight crew will be freed,", "40", "Illuminati", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "Japan", "Arizona", "South America and Africa.", "Tetris", "outside influences", "aid to Gaza,", "two people and injuring more than a dozen,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "immediate release into the United States of 17 Chinese Muslims", "the helicopter went down in Talbiya,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England", "Cash for Clunkers program", "\"project work\"", "talk show queen", "80 percent of a woman's face", "in London's 20,000-capacity O2 Arena.", "to try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "the late Beatle's", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "a UH-60 Blackhawk helicopters collided in northeastern Baghdad as a result of clashes between U.S.-backed Iraqi forces and gunmen.", "Rima Fakih", "Old Trafford", "to help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "West Side Story", "The Fifth Amendment", "New Zealand", "Merck & Co.", "Fort Albany", "Knoxville, Tennessee", "grey Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.546875, "QA-F1": 0.668631026373867}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.3636363636363636, 0.3333333333333333, 0.4799999999999999, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 0.31578947368421056, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647058823529412, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4004", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-7116", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.546875, "CSR": 0.5716594827586207, "EFR": 0.9310344827586207, "Overall": 0.7513469827586207}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "primarily in Polk County, Florida", "sex organs", "the Russian army", "diffuse nebulae", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "maintenance utility", "July 4", "pick yourself up and dust yourself off and keep going '", "John Ridgely", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "October 12, 1979", "a drug", "on the 2013 non-fiction book of the same name by David Finkel", "jonny", "Ethel `` Edy '' Proctor", "ranking used in combat sports,", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar collateral ligament of elbow joint", "Robin Williams", "Watson and Crick", "Gorakhpur", "Patris", "al - Khulaf\u0101\u02beu ar - R\u0101shid\u016bn", "Lake Powell", "decorative ornament", "September 6, 2019", "its population", "substitute good", "Archie Marries Veronica", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh", "the United States economy", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "used obscure languages as a means of secret communication", "Donny Osmond", "Carthage", "George", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "helicopters and boats, as well as vessels from other agencies,", "Saturday", "Rickey Henderson", "Russia", "\"Harold & Kumar Go to White Castle\""], "metric_results": {"EM": 0.40625, "QA-F1": 0.5345524267399266}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.8, 0.7142857142857143, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.3846153846153846, 1.0, 0.0, 0.25, 1.0, 0.5, 0.5, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10678", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.40625, "CSR": 0.5661458333333333, "EFR": 0.9210526315789473, "Overall": 0.7435992324561403}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "walker", "a chief of the Delaware nation", "shoes.", "nine", "Rashid Akmaev,", "acetylene", "'Archer' Jokes", "Bran", "raccoon", "What's in a name", "Winston Rodney", "sand", "Nanjing", "Montana", "walking Camelot Knight", "Louis XIV", "\"What a joy to breathe the balmy air of Grosvenor Square\"", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "a disaster", "a map of the Earth", "refused to attend the victor's inauguration,", "\"Y\" 2 \"K\": An Eskimo", "Fat man", "Hair", "William Randolph Hearst", "pumice", "ale", "Hominidae", "telephone operators", "\"Letra de Year 3000\"", "john jones", "\"The New Colossus\"", "yelp", "Bernard Fokke", "Sarah, Duchess of York", "Benjamin Braddock", "\"Tom Terrific\"", "bronchodilators", "Forty", "fluorescent lights", "Red Lake Indian Reservation", "Lexus' new RC Fbased GT3", "Earl Long", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "five", "Alberto Juantorena", "R&B vocal group", "\"Awake\"", "Doctor of Philosophy", "Pakistan", "in Atlanta", "Sonia Sotomayor"], "metric_results": {"EM": 0.40625, "QA-F1": 0.46651785714285715}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-8514", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-13464", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-7231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-3579", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.40625, "CSR": 0.5609879032258065, "EFR": 1.0, "Overall": 0.7804939516129032}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the retina", "volume", "a squint", "Joseph Conrad", "Diners' Club Card", "Christian Dior", "August Wilson", "Juliet", "Notre Dame", "Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "glutamate", "Chance", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Prince William", "Ugly Betty", "R", "a horse having a reddish-brown horse", "New Jersey", "Lake Ontario", "Matthew Perry", "Marissa Jaret Winokur", "Grant", "kismet", "Willy Wonka", "heavy", "aluminum", "(Matthew) Brady", "Ned Kelly", "an assemblage", "gravitational", "Isis", "a quiver", "Heroes", "on the two tablets", "the source of the donor organ", "seven units", "Dr. A.G. Ekstrand", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years", "Arsene Wenger", "the early Beatles knew they were a good band and were pretty sure of themselves,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6604166666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-10344", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10526", "mrqa_triviaqa-validation-2878", "mrqa_newsqa-validation-2123"], "SR": 0.5625, "CSR": 0.56103515625, "EFR": 1.0, "Overall": 0.780517578125}, {"timecode": 32, "before_eval_results": {"predictions": ["the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "Black Death", "Kenneth Dwight", "John Stuart Mill", "Oblivion", "CIA", "piano", "Rickey Henderson", "Jawaharlal Bhutto", "in the Wisconsin Magazine for Life Sciences on how to make a purple carrots", "John Grunsfeld", "the Buhddist Temple", "1976", "Galileo Descartes", "quarks", "Dust jacket", "Rudy Giuliani,", "the Espionage Act", "a scallop", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel, cask, or tun", "the 1984 Summer Olympics", "Hugo Chvez", "Sprockets", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Tiger Woods", "Los Angeles", "the east wind", "Richard III", "cutting waiting, improved care, transform", "the pen", "Mexico", "Douglas Adams", "Celso Santebanes", "Hawaii", "(Henry) Fleming", "Prussia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Lewis Carroll", "Part 1", "Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6250246313246886}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913042, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.5625, "CSR": 0.5610795454545454, "EFR": 1.0, "Overall": 0.7805397727272727}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "the annual White House Correspondents' Association dinner", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "in New Delhi, India", "the station", "protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "a Little Rock military recruiting center", "Cash for Clunkers", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in", "a missile", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space,", "CNN", "no chance", "a children\\'s hospital in St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "a portrait", "a member of the self-styled revolutionary Symbionese Liberation Army -- perhaps best known for kidnapping Patricia Hearst --", "an incident which was described by judge Henry Globe as an \"explosion of violence.\"", "two tickets to Italy", "Colombia", "in-cabin lighting system", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "NATO", "$40 and a bread.", "a replacement, African National Congress Deputy President Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "a family of Portuguese descent", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "M&M\\'s", "The Star-Spangled Banner"], "metric_results": {"EM": 0.609375, "QA-F1": 0.698846460932858}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.7499999999999999, 0.9333333333333333, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-3588"], "SR": 0.609375, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "rights.", "Washington State's decommissioned Hanford nuclear site,", "in Yemen", "going out of business for one reason or another,", "nearly $2 billion in stimulus funds", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Kenya", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduras", "Brazil", "three", "strife in Somalia", "Roy", "the WBO welterweight title", "Burrell Edward Mohler", "Meredith Kercher.", "a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "a lump in Henry's nether regions was a cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "a $158 green skirt and $298 bead and rhinestone cardigan", "Department of Homeland Security Secretary Janet Napolitano", "543", "the patient, who prefers to be anonymous,", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville", "in critical condition", "in Seoul", "Nicole", "that she was going to be on the Olympic medals podium.", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "an influential religion to enter china along the silk route", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1754", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5641186504467754}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2628", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_searchqa-validation-7879"], "SR": 0.46875, "CSR": 0.5598214285714286, "EFR": 1.0, "Overall": 0.7799107142857142}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "wine", "Nantucket", "an Islamic leadership position.", "a common forest tree in Kentucky", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "Purple", "the Black Sea", "the Battle of the Little Bighorn", "the Shakers", "bellwether", "The spectacular company", "chips", "Boxer", "The Spiderwick Chronicles", "Florence Harding", "Las Vegas", "choosing actors", "the Rose Bowl", "Norman Rockwell", "Henna", "light tunais", "Napa", "Euro 2016", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "Saturday Night Fever", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "a sundae", "Grace Evans", "50 million", "Volitan Lionfish", "Charlie Sheen", "feodor m Mikhailovich", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "Argentine", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6166666666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.515625, "CSR": 0.55859375, "EFR": 1.0, "Overall": 0.779296875}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "nothing gained", "silver", "Supernanny", "the Atlantic", "Cincinnati", "a tower", "(Henry) Hudson", "the gun blast tubes", "dry ice", "Theodore Roosevelt", "Entourage", "the eel", "Philadelphia", "The Museum of Modern Art", "the unicorns", "(John C.) Fremont", "Russia", "(Alan) STREISAND", "Hermann Hesse", "the Taj Mittal", "(Willie) Harry", "Carmen", "Margaret Mitchell", "(Cla) Frollo", "Sultans of Swing", "Pandarus", "the word", "(Burt) Reynolds", "the Sphinx", "(Louis) Armstrong", "Mecca", "American New Wave band", "Arby\\'s Restaurant Group", "coffee", "The Lgion", "Robert Burns", "the Hulk", "Atlanta", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "a bull", "SportsCenter", "Edith Piaf", "Ivan III", "a prologue", "birch", "master carpenter Anthony Mayfield", "Jack Gleeson", "(Phil) Hurtt", "animals Phobia", "Massachusetts", "Starachowice", "(Charles) Laughton", "2009", "Democratic", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6640625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-2964", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-3131", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_triviaqa-validation-1125", "mrqa_hotpotqa-validation-2162", "mrqa_hotpotqa-validation-2000", "mrqa_newsqa-validation-3951"], "SR": 0.59375, "CSR": 0.5595439189189189, "EFR": 0.9615384615384616, "Overall": 0.7605411902286903}, {"timecode": 37, "before_eval_results": {"predictions": ["Switzerland", "impressionist", "John Y. Brown Jr.", "oats", "Romney", "Ivan", "Sally Field", "Charles Lindbergh", "diplomats at Egypt\\'s embassy", "pi", "tin", "the Mississippi River", "Cousin Eddie", "w", "Marriott", "the Principality of Monaco", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the crane", "a claw", "Dr. Alan Frosst", "the Gulf of Mexico", "Austin", "Euclid", "Eva Peron", "Cain", "Edward Asner", "X-Men", "the Louvre", "the chinook", "Prison Break", "Mercury", "Maine", "a sheep\\'s milk cheese", "Meg", "Rainer Maria Rilke", "Henry Bigelow", "Hans", "Peter Bogdanovich", "Billy Joel", "Pilate", "boat propulsion", "the ice age", "nolo contendere", "Jr. Walker", "Czech Republic", "a seewhat", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Henry Henry", "Mariette", "Charles Quinton Murphy", "\"Bubbly\"", "Australian", "the sins of the members of the church", "$22 million", "\"17 Again\"", "Nelson County"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6286458333333333}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-2766", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6487", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.578125, "CSR": 0.560032894736842, "EFR": 1.0, "Overall": 0.780016447368421}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospira", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "non-traditional", "a canoe", "Pineapple Marshall", "Witness", "Jack the Ripper", "3800", "Alan Shore", "taxonomy", "Spain", "the brain", "Francesco Schettino", "Macbeth", "comedy", "Mary Poppins", "Casowasco Camp", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "married", "Livin' On A Prayer", "Sherlock Holmes", "cotton candy", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "nongruent", "non-NAYG-roh", "Katamari Damacy", "Bill Murray", "Margaret Thatcher", "Harry Potter and the Philosopher Stone", "Manganese", "forest", "Olympia", "Waylon Jennings", "The Bridge on the River Kwai", "Brazil", "British Columbia", "Oliver Stone", "Scrapple", "Oona Castilla Chaplin", "September 24, 2017", "John Cooper Clarke", "different levels of importance of human psychological and physical needs", "one", "Fraser Island", "the Wright brothers", "sexual activity", "Sam ticker", "Sandro Bondi", "voluntary manslaughter", "the need for reconciliation in a country that endured a brutal civil war", "Pygmalion"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5522939644607843}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.11764705882352941, 1.0, 0.06250000000000001, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_naturalquestions-validation-6347", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_hotpotqa-validation-2005", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.484375, "CSR": 0.5580929487179487, "EFR": 1.0, "Overall": 0.7790464743589743}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "Wikis", "the Byzantine Empire", "a gay marriage", "Jefferson", "Ford Madox Ford", "the Orinoco River", "a q-tip", "California", "Dixie\\'s Land", "a nonprofit institution that helps improve policy and decisionmaking through research and analysis", "Warren Harding", "a engrave", "William", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a torque", "Tito", "a chomady Kennel Club", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "26.2", "Prince", "a perennial herb", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer who took exception to her \"inappropriate behavior\" while filming a music video on his land.", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5680803571428571}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-14076", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-8155", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.5, "CSR": 0.556640625, "EFR": 1.0, "Overall": 0.7783203125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "Flavivirus", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "\"Away In A Manger\"", "Tsavo East National Park", "New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "most awarded female act of all-time", "Premier League club Manchester United and the England national team", "The Rite of Spring", "David Allen", "over 26,000", "Kristin Scott Thomas", "Mayor Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Overland Park, Kansas", "1999", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leon Uris", "Erika Mitchell Leonard", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "its responsibility to assure that all collection instruments and environments are sterile and of first use", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "Portia", "the Mayor of Casterbridge", "Leonardo DiCaprio", "a narcissistic ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7260256185807656}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-3874", "mrqa_hotpotqa-validation-3027", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_naturalquestions-validation-6326"], "SR": 0.609375, "CSR": 0.5579268292682926, "EFR": 1.0, "Overall": 0.7789634146341463}, {"timecode": 41, "before_eval_results": {"predictions": ["a interception", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "The Valley Swim Club", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as", "piano", "$250,000", "\"prostitute\"", "an underground parking garage", "tax", "Los Ticos", "acute stress disorder", "Russia and China", "Facebook and Google,", "a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "Pakistan", "23 years.", "a head injury.", "North Korea", "an open window", "Leo Frank", "(l-r) Paul McCartney", "Florida", "Mugabe", "free", "three", "United Kingdom Dance Championships.", "on-loan David Beckham claimed his first goal in Italian football.", "\"He is more American than German.\"", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Fayetteville, North Carolina,", "The crash destroyed four homes and killed two people who lived in at least one of the homes", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "radius R of the turntable", "the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "B-24 Liberator", "Nut & Honey Crunch", "Oakdale", "Melbourne", "Guillermo del Toro", "Virginia", "Monty Python and the Holy Grail", "1523", "Department of Transportation"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6479166666666667}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.16666666666666669, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.8, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-2346", "mrqa_searchqa-validation-1519"], "SR": 0.515625, "CSR": 0.5569196428571428, "EFR": 1.0, "Overall": 0.7784598214285714}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "China", "Zimbabwe,", "Italian Serie A title", "a sixth member of a Missouri family", "her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "President Robert Mugabe", "42 years old", "\"I want to give peace to my nation,\"", "glaciers in the European Alps may melt as soon as 2050,", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "\"His sole reason for being on Flight 253 was to kill all of the passengers and himself.", "Myanmar", "authorities had recovered Mesac Damas' vehicle at Miami International Airport, and they believe that he left on a flight to Haiti.", "his business dealings", "the Islamic militant group Abu Sayyaf,", "poems telling of the pain and suffering of children just like her", "the program was made with the parents' full consent.", "Barack Obama", "The Red Cross, UNHCR and UNICEF", "Russia", "debris", "not guilty of affray by a court in his home city on Friday.", "capital murder and three counts of attempted murder", "Basel", "17", "a Daytime Emmy Lifetime Achievement Award.", "state senators who will decide whether to remove him from office", "31 meters (102 feet)", "its nude beaches.", "women and breast cancer.", "a Florida girl who disappeared in February,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying your face off in public", "Capitol Hill,", "\"theoretically\"", "1940's", "March 22,", "three different videos that we like and want to know which ones you think are the best.", "Beirut, Lebanon", "\"Antichrist\"", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "2002", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "the Pyrenees"], "metric_results": {"EM": 0.484375, "QA-F1": 0.624444349053724}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5714285714285715, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.09523809523809523, 0.0, 0.0, 0.16666666666666669, 1.0, 0.8, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.5, 1.0, 0.3076923076923077, 0.5333333333333333, 0.4, 0.0, 0.5, 0.8, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-2624", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1891", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-800", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.484375, "CSR": 0.5552325581395349, "EFR": 0.9696969696969697, "Overall": 0.7624647639182522}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "\"The U.S. subcontracted out an assassination program against al Qaeda... in early 2006.\"", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "The National Infrastructure Program,", "After the war,", "The station", "Krishna Rajaram,", "a hot tub alongside a man's lifeless, naked body", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Camp Lejeune, North Carolina", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Hyundai", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "militants in Afghanistan", "Seminole Tribe", "Rima Fakih", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama", "nuclear warheads", "U.S. Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "most of those", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Aston Villa", "small-holder farmer", "cue ball", "1822", "The Dressmaker", "Trilochanapala", "garlic croutons", "the buffalo", "ruby slippers", "the occipital lobe"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6234738201110483}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 0.7272727272727273, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.484375, "CSR": 0.5536221590909092, "EFR": 1.0, "Overall": 0.7768110795454546}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Duval County", "Benj Pasek and Justin Paul,", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Highlands Course", "Franconia, New Hampshire", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley Village", "What Are Little Boys Made Of", "Berea College", "the Chicago Bears", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "Diego Rub\u00e9n Tonetto", "Radcliffe College", "James A. Garfield", "Ford", "weighed against the feather of truth", "India", "German", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "central", "sixth - largest country", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "Riddles in the Dark", "early to bed"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6508634868421053}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.578125, "CSR": 0.5541666666666667, "EFR": 1.0, "Overall": 0.7770833333333333}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "Indian Ocean waters near the Gulf of Aden,", "three", "crocodile eggs", "Colorado prosecutor", "Polis", "Saturday.", "a few bodies that had been pulled out of the rubble laying dead in the sidewalk", "in July", "to sniff out cell phones.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie meals", "one of its diplomats in northwest Pakistan", "the ireport form", "government", "Nine out of 10 children", "police", "Raymond Soeoth of Indonesia and Amadou Diouf of Senegal in West Africa,", "a crocodile", "a bronze medal", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers", "Obama's", "King Birendra,", "the cause of the child's death will be listed as homicide by undetermined means,", "Casey Anthony,", "officers at a Texas  airport", "12 off-duty federal agents in southwestern Mexico,", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers,", "2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "enkuklios paideia or `` education in a circle '' -- of late Classical and Hellenistic Greece", "Enid Blyton", "Johnny Mathis", "The Golden Child (1986)", "Champion Jockey", "Luca Guadagnino", "Stankonia", "Maya Angelou", "the Romans' fault", "a jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6432043650793651}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.888888888888889, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.515625, "CSR": 0.5533288043478262, "EFR": 1.0, "Overall": 0.7766644021739131}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\" Viewers can vote online, via phone calls or by text messaging,", "without bail", "12.3 million", "Mexico", "United", "Vivek Wadhwa,", "Brett Cummins,", "the Indian army", "Saturday", "Nicole", "the legitimacy of that race.", "the diversity the collaborations provide,", "\"who knows where things may go from here tomorrow,\"", "Africa", "American", "bartering -- trading goods and services without exchanging money", "on Wednesday.", "promise to improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry", "on June 6, 1944", "\"Dozens of journalists have been detained without trial, and several sentenced to long prison sentences,\"", "two", "October 19,", "\"I sincerely apologize to Tiger and anyone else I have offended.", "Seoul,", "fuel economy and safety", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback Forestry in Medford, Oregon,", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "\"Test scores and graduation rates", "one", "blobs of orange to art as night falls.", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "fox hunting", "New York", "travel diary", "16,116", "smoke", "sap", "a mumblebee", "Rowan Blanchard (born October 14, 2001)"], "metric_results": {"EM": 0.546875, "QA-F1": 0.628305821527329}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.1, 0.0, 1.0, 0.12500000000000003, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.15384615384615388, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3968", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-980", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-2502", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573", "mrqa_searchqa-validation-917", "mrqa_hotpotqa-validation-664"], "SR": 0.546875, "CSR": 0.5531914893617021, "EFR": 1.0, "Overall": 0.7765957446808511}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Chicago", "The Wind's Twelve Quarters", "child actor", "Dennis H. Kux", "drawing the name out of a hat.", "Brett Ryan Eldredge", "Hero Indian Super League", "two or three", "Badfinger", "Lady Frederick Windsor", "animal", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue between Corinthian Avenue and North 22nd Street", "1930", "5,112", "1992", "residential", "14,673", "6'5\" and 190 pounds", "Mickey Gilley", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Ulver and the Troms\u00f8 Chamber Orchestra", "1730", "London Luton Airport.", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Jane Ryan", "Randall Boggs", "a Passion", "Charlestown, Massachusetts,", "lion", "Royal", "World War II", "Knoxville, Tennessee", "Three's Company", "Doomtree", "Labour", "\"Linda McCartney's Life in Photography\"", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Farlake", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "a cloakroom", "Bank of England"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6541113400488401}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, true, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 1.0, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5349", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-744", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5530598958333333, "EFR": 1.0, "Overall": 0.7765299479166666}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "Helsinki", "ryegrass", "offensive", "fire", "deep meaningful and soothing annual", "Fawn Hall", "waived all privileges", "ding-dong", "The Great Showman Dead", "Peter John", "cathode", "a torque screw", "gold", "Marlon Brando", "middle high German", "lunatics", "University of Kentucky", "reddish", "Brussels", "Macbeth", "General Lee", "piracy", "best place to look for the Almighty", "Martin Luther", "Clue", "best story writer", "German", "Andrew Johnson", "seven years", "Mike Connors", "Jungle Jim", "Jim Inhofe", "sancire", "Corpus Christi", "Africa", "an ostrich", "divinely inspired", "late at night", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a strike", "a bat", "West Virginia", "James Monroe", "movie house", "deep purple", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambilevous", "chariots", "Humberside Airport", "265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "a head injury.", "Pope Benedict XVI", "Charles II"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5391850490196077}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-10470", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.46875, "CSR": 0.5513392857142857, "EFR": 1.0, "Overall": 0.7756696428571428}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "(P.C.) Anderson", "carioca", "Treasure Island", "Pocahontas", "improv", "(Whizzer) White", "an octave", "an aerosol", "Great American Novel", "(Matthew) Broderick", "(Joseph) Campbell", "Margaret Mitchell", "Charles Busch", "the Percheron", "( Ernest) Lawrence", "a rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "the tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "the small intestine", "the mouthpiece", "Key West", "the Fellowship of the Ring", "\" Please Mr. Please\"", "scalpels", "Manhattan", "February 2", "Leontyne Price", "composting", "Lauren Hutton", "Christopher Columbus", "(Phil) Mickelson", "Mikhail Nikolayevich Baryshnikov", "the Pierian spring", "plc", "a tawb robe", "Philadelphia", "peanut butter", "Invisible Man", "cork", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "the Sequel", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "Sunday evening", "three", "poems", "Mechante Navstrechu"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6375}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, true, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.13333333333333333, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_hotpotqa-validation-116"], "SR": 0.5625, "CSR": 0.5515625, "EFR": 1.0, "Overall": 0.77578125}, {"timecode": 50, "UKR": 0.734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.80078125, "KG": 0.47109375, "before_eval_results": {"predictions": ["Fatih Ozmen", "Volvo 850", "Skyscraper", "C7", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hawaii", "Robert Downey, Jr.", "J\u00fcrgen M. Geissinger", "CDP", "Visigoths", "Anaheim", "Reinhard Heydrich", "the Big Ben clockface", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "senior Leadership Team of 17 other executives, oversee the Firm's businesses", "19th-century", "Hillary Scott", "HackThis Site", "the 43rd Vice President of the United States", "Premier League club Tottenham Hotspur and the England national team", "10 November 2017", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "political commentator", "Adelaide Lightning", "Operation Neptune", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "50 km north-northeast of Bologna", "agricultural Extension Service", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "first woman of Indian origin", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "United States House of Representatives", "February 9, 2018", "1980", "Nacio Herb Brown", "Michael Hart", "the Precambrian", "island-towns", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England", "the three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "Zeina,", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5611458333333332}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.5, 0.5, 0.0, 0.4, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.4799999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-7101", "mrqa_triviaqa-validation-4774", "mrqa_triviaqa-validation-535", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-13015"], "SR": 0.453125, "CSR": 0.5496323529411764, "EFR": 1.0, "Overall": 0.7111764705882353}, {"timecode": 51, "before_eval_results": {"predictions": ["1898", "a wooden Indian", "What You Will", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Kalokuokamaile", "Gothic Revival", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "the White Knights of the Ku Klux Klan", "WikiLeaks", "Three card brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback", "ARY Group", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Eunice Kennedy Shriver", "No. 17", "Mark Neary Donohue Jr.", "a Peach or a nectarine", "Switzerland", "Richard Price", "Archie Andrews", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League group stage", "Magdalen College", "Kanab, Utah", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "devonian", "a string of obscure words", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29", "(Joseph) Holt", "hunter sauce", "The Tolkien", "carbon"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6889694940476191}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.5, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-4744", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-2803", "mrqa_hotpotqa-validation-1263", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.609375, "CSR": 0.55078125, "EFR": 1.0, "Overall": 0.71140625}, {"timecode": 52, "before_eval_results": {"predictions": ["My Antonia", "King Henry VIII", "lead", "the Rose Bowl", "a 747", "amber", "Denmark", "terriers", "Katrina & the Waves", "Galilee", "freestyle", "celtic", "spores", "the Stargate", "Lou Reed", "Stonewall Jackson", "northern Europe", "combat boots", "canvas", "celtic", "The X-Files", "Frankie Muniz", "a blue whale", "Hudson Bay", "Coupvray", "kinetic", "Santeria", "Richard Bach", "a Statue of Liberty", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "a cornucopia", "Ralph Burns", "Ankara", "condensation", "to be a poem should not mean, but be", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Como agua para chocolate", "Niger-Congo", "Applebee's", "John Tyler", "Daniel Craig", "humility", "computer programming", "Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "if the concentration of a compound exceeds its solubility", "The Yellow Rolls-Royce", "Bristol", "Gregory v. Helvering", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert,", "1936", "South America and Africa.", "red carpet, on ski slopes and boats, at Wimbledon and elsewhere.", "fake his own death by crashing his private plane into a Florida swamp.", "the Stockton & Darlington Railway"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6665545825702075}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.625, 1.0, 0.923076923076923, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6153846153846153, 0.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-3526", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-316", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.59375, "CSR": 0.5515919811320755, "EFR": 0.9615384615384616, "Overall": 0.7038760885341074}, {"timecode": 53, "before_eval_results": {"predictions": ["Helen Oxenbury", "Saint Etienne", "After Shawn's kidnapping", "manage the characteristics of the beer's head", "cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "Karewa soil", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "in a cell", "global crowdfunding platform focused on creativity and merchandising", "Most days are sunny throughout the year", "the senior career official at the Mint has been Acting Principal Deputy Director David Motl", "the Catholic Monarchs of Castile and Aragon", "Wisconsin", "September 1972", "2017", "the Allies", "the settlement of the sedimentation", "observing the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "the dromedary", "13", "the five - year time jump", "A complex sentence", "Halliwell, French, Timomatic and Sandilands", "the Coriolis force", "the five - year time jump", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Jethalal Gada", "74", "warning signs", "various submucosal membrane sites", "noble gas", "the Immigration and Naturalization Service's Fore Forensic Document Laboratory", "four distinct levels", "Janie Crawford", "Pepsi", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Charles Strickland", "USA Today serving as its", "creeks", "Terence Winter", "Ian Fleming", "over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "off the coast of Dubai", "the Northwest Territories", "zhizni v chetyroykh", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5158580713268214}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 0.08333333333333334, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.2666666666666667, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3076923076923077, 0.29629629629629634, 1.0, 0.28571428571428575, 0.5, 1.0, 0.0, 0.5, 0.3076923076923077, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-2220", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-4748", "mrqa_hotpotqa-validation-2693", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.359375, "CSR": 0.5480324074074074, "EFR": 0.926829268292683, "Overall": 0.6962223351400181}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "fajitas", "George Harrison", "Kanawha Rivers", "1803", "President pro tempore of the Senate", "3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "A justice of the peace ( JP ) is a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Beyonc\u00e9", "Arkansas", "Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "John F. Kelly", "cylinder of glass or plastic that runs along the fiber's length", "anembryonic gestation", "741 weeks", "Zimbabwe", "London", "Hillary Clinton\\'s", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "the Impeccable,", "it's historical, inspiring, creative, romantic and beautiful.", "Tater Tots", "Yemen", "quod erat demonstrandum", "(Bob) Dalton"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6452392172473309}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.4827586206896552, 1.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 0.4, 1.0, 1.0, 1.0, 1.0, 0.07407407407407407, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.53125, "CSR": 0.5477272727272727, "EFR": 0.9, "Overall": 0.6907954545454545}, {"timecode": 55, "before_eval_results": {"predictions": ["Leona Stevenson ( Barbara Stanwyck ) is the spoiled, bedridden daughter of wealthy businessman James Cotterell ( Ed Begley )", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "American frigate USS Chesapeake", "In 1967, Celtic became the first British team to win the competition, coming back from 1 -- 0 down after a Sandro Mazzola penalty to beat Internazionale 2 -- 1", "Columbia River Gorge", "the Northeast Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "Biotic -- Biotic resources are obtained from the biosphere ( living and organic material ), such as forests and animals", "2015, in the United States, the poverty threshold for a single person under 65 was an annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "creating a so called minimum viable product that addresses and solves a problem or need that exists", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "depolarization of the cardiac muscle begins at the sinus node", "a strong, weight transferral synovial plane joint with irregular elevations and depressions that produce interlocking of the two bones", "HTTP / 1.1", "Brooklyn, New York", "1 mile ( 1.6 km )", "pop ballad", "8 December 1985", "prophase I of meiosis", "2007", "Arnold Schoenberg", "an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "the books of Exodus and Deuteronomy", "a teenage porcupine punk rocker who takes part in an alternative - rock music duo with her boyfriend Lance", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outside ( skin ) and the inside cavities and lumina of bodies", "2007", "Vanessa received an SMS which reveals that Dan was `` G gossip Girl ''", "10,605", "Tom Thornton", "Sebastian Vettel", "San Antonio, Texas", "Megatron", "Eukarya", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "gauvin Campbell", "Celebrity Big Brother", "Sir Roger Casement", "(James) Garner", "Boston, Massachusetts", "Robert Jenrick", "Robert Matthew Hurley", "improve the military's suicide-prevention programs.", "five", "\"She is such a complicated, fascinating character, and watching her growth and lack of growth is something that is really interesting,\"", "sarah palabra", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6183183014972782}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 0.6666666666666666, 0.07692307692307693, 1.0, 0.5714285714285715, 1.0, 0.0, 0.11764705882352941, 0.21052631578947367, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.14285714285714288, 0.10526315789473684, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.7096774193548387, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.0, 0.9, 1.0, 0.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-6540", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.46875, "CSR": 0.5463169642857143, "EFR": 0.9705882352941176, "Overall": 0.7046310399159664}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "anti- Nazi Germany", "sita", "16", "1877", "1999", "Old Trafford", "Tami Lynn", "U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "John Findley Wallace", "Nepal", "Aernoutsz", "4 September 1936", "heat", "1940", "Authority", "April 1st", "Luke Feilder UK", "noon Eastern Time", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Dennis C. Stewart", "Walter Pauk", "1979", "the septum", "Buddhism", "the forex market", "`` Singing the Blues '' by Guy Mitchell", "Henry Moseley", "Nigel Lythgoe", "the third season concluded on October 1, 2017", "gastrocnemius", "Art Carney", "introduced and elaborated as early as in 1651", "March 26, 1973", "1986", "on location", "President Lyndon Johnson", "prenatal", "a Nativity scene", "1840", "2007", "Branson", "first baseman", "Tumi Holdings, Inc.", "River Shiel", "brewer", "Polo", "not for sale,", "ego", "Nova Scotia", "Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6366300366300366}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.19047619047619047, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5700", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-7486", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096"], "SR": 0.609375, "CSR": 0.5474232456140351, "EFR": 0.96, "Overall": 0.702734649122807}, {"timecode": 57, "before_eval_results": {"predictions": ["England", "Manchester - by - the - Sea, Massachusetts", "The Golden Gate Bridge", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "acquire an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Fred E. Ahlert", "the January 2017 patch", "Ozzie Smith", "Mark Jackson", "2017", "two - year terms", "by January 2018", "in plants and other living organisms", "September 30", "avian origin", "President Gerald Ford", "September 8, 2017", "1998", "social ideology", "Spektor", "an object that forms", "the nucleus", "1955", "Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "transposition changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music", "a number of friends ( who provide their phone numbers in advance )", "refer to a god of the Ammonites, as well as Tyrian Melqart", "P.V. Sindhu", "Carpenter", "Asuka", "126", "Klaus Meine", "Brazil", "UNESCO / ILO Recommendation concerning the Status of Teachers", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "American country music duo Brooks & Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Richard Hope-Hawkins", "liver", "Heineken International", "Irish Chekhov", "Gust Avrakotos", "Mark Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "the Mayan settlement"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5788505591630592}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 0.6666666666666666, 0.5, 0.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.9142857142857143, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3, 0.8181818181818181, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-9578", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_triviaqa-validation-7305", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.4375, "CSR": 0.5455280172413793, "EFR": 0.9166666666666666, "Overall": 0.6936889367816093}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "in London's West End in 1986", "Idaho", "July 18, 2013", "Exodus", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "a patronymic surname, which arose separately in England and Wales", "iron", "the Reverse - Flash", "Los Angeles, California", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "commissioned by McVitie and Price in the UK in 1927 and named after Jaffa oranges", "Relieving Chambers", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "m\u0113ninx", "Seattle, Washington", "27 January -- 16 April 1898", "on the slopes of Mt. Hood in Oregon", "Emma Watson", "LED illuminated display", "stuffing", "1917", "January 2004", "Bonnie Plunkett ( Allison Janney )", "smen", "the Israelites were encamped at the foot of biblical Mount Sinai", "Macon Blair", "non-coding sequences", "each state's DMV, which is required to drive", "the Convention's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "on 13 February", "276", "the early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "March 1995", "Zuzu & Zaza Zebra", "endometriosis", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\" and", "Mend,", "peppermint oil", "the FBI.", "a ferry", "Leland Stanford", "Mexico City", "Nepal"], "metric_results": {"EM": 0.453125, "QA-F1": 0.652148467851593}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.2857142857142857, 1.0, 0.0, 1.0, 0.92, 1.0, 0.8, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.33333333333333337, 0.8750000000000001, 0.0, 0.2857142857142857, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.2222222222222222, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5641025641025641, 1.0, 0.0, 1.0, 0.8, 0.0, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-9332", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231"], "SR": 0.453125, "CSR": 0.5439618644067796, "EFR": 0.9142857142857143, "Overall": 0.6928995157384988}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Abiotic", "9 ( VIIII )", "a useless, time - wasting activity", "head coach", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "January 2018", "George Strait", "climate on the Earth", "Herman Hollerith", "94 by 50 feet", "gears that can be changed to allow a wide range of vehicle speeds, and also in the differential, which contains the final drive to provide further speed reduction at the wheels", "Gibraltar", "chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Roxette", "Long Island", "1988", "Italy", "Rococo - era France", "Michael Crawford", "the Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 7", "1950s", "Maximilien Robespierre", "XXXX", "December 25", "Made a searching and fearsome moral inventory of ourselves", "Italian architect and art theorist Leon Battista Alberti", "starting on January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Pink Floyd", "Chicago", "dijon", "Lucas Stephen Grabeel", "15,024", "actress and model", "the test results by the medical examiner's office,", "15-year-old's", "Thursday,", "Vietnam", "the cello", "Richard", "(Son of Sam)"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7446363532301032}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-3750", "mrqa_hotpotqa-validation-3979", "mrqa_hotpotqa-validation-4797", "mrqa_newsqa-validation-3727", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465"], "SR": 0.671875, "CSR": 0.54609375, "EFR": 0.9523809523809523, "Overall": 0.7009449404761905}, {"timecode": 60, "before_eval_results": {"predictions": ["a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "certiorari", "silk floss", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "the people of the United States", "eighth", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "Introduced in 1957", "Clare Torry", "ummat al - Islamiyah", "Brazil", "Parashara ( c. 400 -- c. 500 AD ), the author of V\u1e5bksayurveda ( the science of life of trees )", "Domhnall Gleeson", "Brazil and Paraguay", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "Jericho in the Levant region", "\"The closest approach to the original sound\"", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain", "\"Empire of the Sun,\"", "Hector Berlioz", "The Killing Fields", "the Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6575586219336219}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, false, true, true, true, true, false], "QA-F1": [0.11111111111111112, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 0.5, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1282"], "SR": 0.53125, "CSR": 0.5458504098360656, "EFR": 0.8666666666666667, "Overall": 0.6837534153005465}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "shared", "Jason Marsden", "New Mexico", "In 1889", "Poems : Series 1", "William the Conqueror", "March 2, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "1980s", "David Gahan", "Emma Watson", "a presidential veto", "2018", "first bull running is on 7 July, followed by one on each of the following mornings of the festival, beginning every day at 8 am", "2010", "no more than 4.25 inches ( 108 mm )", "Judi Dench", "Madhouse", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "the 18th century", "Thomas Jefferson's", "Ian McKellen", "Space is the Place", "Brad Dourif", "counter clockwise", "Joanne Wheatley", "vice president", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The Union's forces", "Brooks & Dunn", "\"Maljanne\"", "South America", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.625, "QA-F1": 0.7083398199023199}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.24000000000000002, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.07692307692307691, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-1856", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.625, "CSR": 0.5471270161290323, "EFR": 0.9166666666666666, "Overall": 0.6940087365591399}, {"timecode": 62, "before_eval_results": {"predictions": ["one season from 1952 until 1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Javier Fern\u00e1ndez", "Tim Russert", "the West was much more rural in its character and more readily adopted Latin as its common language", "toys or doorbell installations", "a microfilament", "in positions Arg15 - Ile16", "the northernmost point on the Earth", "the leader of the `` A- Team '' was revealed to be CeCe Drake", "Eduardo", "1868 war veterans", "1971", "Leo Arnaud", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1936", "Paul McCartney", "Djokovic", "James Hutton", "January 1923", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Billy Bishop Toronto City Airport on the Toronto Islands in Toronto, Ontario, Canada", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans", "the port of Nueva Espa\u00f1a to the Spanish coast", "the tax rate paid by a small business", "ecosystems", "White House Executive Chef", "the International Border ( IB )", "lead vocalist Bart Millard", "a woman named Sarah Whitehead", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal drummer", "Selden", "American Seung-Hui Cho", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Queen Elizabeth I (queen of England)", "the Entente Council", "Chief Oshkosh", "River Welland"], "metric_results": {"EM": 0.453125, "QA-F1": 0.579401905964406}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.5, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.28571428571428575, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-9494", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-10077", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.453125, "CSR": 0.5456349206349207, "EFR": 1.0, "Overall": 0.7103769841269842}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "The Hustons", "sacroiliac joint", "Identification of alternative plans / policies", "Mexico", "the development of electronic computers in the 1950s", "the Internal Revenue Service", "Balaam", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "at luncheon", "Kristy Swanson", "Jakkur, Bangalore, India", "in a thousand years", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "on Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "the Inland Fisher Guide Plant in the West Trenton section of Ewing Township, New Jersey", "Burt Hammersmith", "Cameron Fraser", "Austin and Pflugerville", "three times", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "calypso", "Jiles Perry (JP) Richardson Jr,", "The Pentagon", "Pisgah National Forest", "Lola Dee", "Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "the Pussycat Dolls", "tuberculosis", "May 4"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5812821293290042}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.4, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 0.5, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3339"], "SR": 0.484375, "CSR": 0.544677734375, "EFR": 0.8787878787878788, "Overall": 0.6859431226325758}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Pittsburgh", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Burwell Johnston, Jr.", "Nia Temple Sanchez", "Vanessa Hudgens", "top division of Mexican football, Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "a synthesizer-heavy arrangement", "January 30, 1930", "Doctor of Philosophy", "the Irish Government's Health Service Executive", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes of Balquhither\"", "Westminster system", "I. helicon", "For Love Alone", "October 4, 1970", "King of the House of Valois", "J. Robert Oppenheimer", "Transporter 3", "March 14, 2000", "Gauteng province", "the Vietnam War", "Bill Walton", "the Darling River", "Brian Keith Bosworth", "over 140 million", "English", "Teri Garr", "the employer", "the third round", "Wyoming", "Wee Jimmy Krankie", "people or society", "would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "black, red or white,", "trying to prevent attempted defections as the country goes through a tumultuous transition,", "Billy Corgan", "Rome", "a long distance (6)", "Southport, North Carolina"], "metric_results": {"EM": 0.5, "QA-F1": 0.6375}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8, 0.0, 0.4444444444444445, 0.0, 0.8, 0.5, 0.0, 1.0, 0.5, 0.8333333333333333, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-5596", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-5297", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474"], "SR": 0.5, "CSR": 0.5439903846153846, "EFR": 0.9375, "Overall": 0.697548076923077}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "\"Arrested Development\"", "Albert,", "September 30, 2017", "322,520", "the New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire in Atlanta", "Odense Boldklub", "Henry I", "Jared Leto", "Gweilo", "Tufts College", "Prince Aimone of Savoy-Aosta", "1936", "The Wu-Tang Clan", "\"Hey Dad\"", "a midtempo hip hop ballad with a pop refrain, sung by Rihanna", "melodic hard rock", "G\u00e9rard Depardieu", "concentration camps", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse", "Kings Point, New York", "current 49ers placekicker Robbie Gould", "The Gang", "the town of Hempstead", "Port Clinton", "1969", "Wayne Conley", "the Australian coast", "Faith", "turns out to be a terrible date", "the Celtics", "Girl Meets World", "CHO", "eight", "from 1848 to 1852", "Sippin' on Some Syrup", "Jim Harrison", "the third Viscount", "Arabella Churchill", "Benny", "two Grammy awards", "The S7 series", "2017", "a lightning strike", "September 2000", "Thomas Jefferson", "Luxembourg", "\u0153\u043e\u043b\u0434\u0430 \u041c\u0430\u0431\u043e\u0432\u0438\u0447", "The Muffin Man", "President George Bush", "as", "Vernon Forrest,", "Yonkers", "blown", "supernatural", "Dan Aykroyd"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5586319062881562}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-1557", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_triviaqa-validation-2994", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.46875, "CSR": 0.5428503787878788, "EFR": 1.0, "Overall": 0.7098200757575758}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Sheffield Wednesday", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Chris Rock", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "pangea", "an international award given each year to a living architect who, in the opinion of select Pritzker Prize jury, has made profound achievements in the world of architecture.", "Guy the Gorilla", "a man holding up a lighted match", "Port Moresby", "orange", "kursk", "pyrotechnic", "South Korea", "Annie Lennox", "a goose", "a superhero", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington John Adams", "Ellice Islands", "Meta", "the 'Flower of Scotland'", "about a mile north of the village of Dunvegan", "a double basses", "The Spice Girls", "Mr Loophole", "Istanbul", "from the cheerful \u201cLibiamo\u201d (\u201cLet Us drink\u201d) in La traviata (1853)", "Texas", "Pablo Picasso", "The Potsdam Conference", "Rajasthan", "Saintpaulia", "bali", "Guys And Dolls", "a British general", "Haytham Kenway", "Djokovic", "1912", "fennec", "1927", "Nikolai Trubetzkoy", "Vernon Forrest,", "Linda Hogan,", "development of two courses on the Black Sea coast in Bulgaria.", "Andrew Wyeth", "viruses", "Steve Wynn", "a substitute good"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6814583333333333}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.07999999999999999, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-1464", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3214", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-2425", "mrqa_newsqa-validation-2391", "mrqa_searchqa-validation-16515"], "SR": 0.640625, "CSR": 0.5443097014925373, "EFR": 0.8695652173913043, "Overall": 0.6840249837767683}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less,", "Thailand", "Les Bleus", "tranquil beaches,", "took on water", "Werder Bremen", "Secretary of State", "Obama", "21 percent", "Fernando Caceres", "six Africans dead.", "there's no evidence as to the cause of death,", "America's Cup", "Cambodian territory", "Uzbekistan", "voluntary manslaughter", "Jenny Sanford", "isabella", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones", "two contestants.", "Fiona MacKeown", "the Southern Baptist Convention,", "Graeme Smith", "former U.S. secretary of state.", "he didn't elaborate.", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "for the two remaining crew members", "hanging a noose in a campus library,", "tickets to Italy by calling Expedia.", "Oxbow,", "there were no reports of ground strikes or interference with aircraft in flight,", "21-year-old", "Jacob Zuma", "toffelmakaren", "former Procol Harum bandmate Gary Brooker", "an outstanding arrest warrant relating to a domestic violence case last year,", "Pew Research Center", "face transplant", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "New Testament", "Phil Mickelson", "dumbo", "Led Zeppelin", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "julie taymor", "Perkins", "director", "men use violence within relationships to exercise power and control"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6418679971988795}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.5714285714285715, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1711", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.5625, "CSR": 0.5445772058823529, "EFR": 1.0, "Overall": 0.7101654411764706}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "as soon as 2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura", "their homes in Bhola", "off Somalia's coast.", "in time as another American icon's wheels come off.", "5-1 win", "President Barack Obama,", "Lifeway, the Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally from China", "after nine years.", "at least 300", "Thursday,", "always hot and humid and it rains almost every day of the year.", "Israeli", "The drama of the action in-and-around the golf course", "1993", "act, and it doesn't matter that they're non-state actors.", "25", "\"Zed,\" a Columbian mammoth whose nearly intact skeleton is part of what is being described as a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford,", "in a remote part of northwestern Montana", "killing rampage.", "identity theft", "Bailey, Colorado,", "U.S. Justice Department", "Unseeded Frenchwoman Aravane Rezai", "noose incident occurred two weeks after Black History Month", "\"Doogie Howser, M.D.\"", "British", "six", "he was released Friday and taken to the Australian embassy in Bangkok, where he stayed until leaving for Australia at about midnight.", "a bank", "\"race for the future... and it won't be won with a president who is stuck in the past.\"", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds).", "stand down.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man", "Taron Egerton as Johnny", "Italy", "\"Book 1: Sowing\"", "purpurea", "Nellie Melba", "The King of Hollywood", "1979", "the backside", "Russia", "garcinia cambogia", "Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5505389792499167}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.4, 1.0, 0.3636363636363636, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0625, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-1168", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-430", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4976", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337"], "SR": 0.453125, "CSR": 0.5432518115942029, "EFR": 0.9428571428571428, "Overall": 0.6984717908902691}, {"timecode": 69, "before_eval_results": {"predictions": ["Epithelium ( epi - + thele + - ium )", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Texas A&M University", "Paradise, Nevada", "Reverse - Flash", "Hathi Jr", "a liquid crystal on silicon ( LCoS ) ( based on an LCo S chip from Himax )", "Spektor", "Star Spangled Banner", "Boston Celtics center Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "July 2010", "an address bar", "in air", "1996", "Carol Worthington", "September 6, 2019", "1972", "1902", "uprooted", "at angles less than vertical", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "in normal conditions", "the 1980s", "Pasek & Paul", "in a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear", "eusebeia", "Daniel Suarez", "White House Executive Chef", "place of trade", "25 years after the release of their first record", "the bank", "The Abbott and Costello Show", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "Eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "Northrop P-61 Black widow", "26", "The woman", "2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6856524403239557}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8, 0.0, 1.0, 0.6666666666666667, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9411764705882353, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809525, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3436", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_newsqa-validation-1639"], "SR": 0.59375, "CSR": 0.5439732142857143, "EFR": 0.9230769230769231, "Overall": 0.6946600274725274}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "Longlines", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "an ascender", "Nala", "a wannabe rockstar", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "the investment bank Friedman Billings Ramsey", "the NFL", "14 \u00b0 41 \u2032 34 '' N 17 \u00b0 26 \u2032 48 ''", "1 January 1904", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methodssuch as dictionary attacks, brute force and cryptanalysis attacks", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "a premedication for medical or dental procedures", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral, in the Tremont neighborhood of Cleveland, Ohio", "Ray Charles", "a jazz funeral without a body", "2004", "in over seven years", "John De Vito", "Malware", "an ex ( plural is exes )", "Beorn", "North Dakota", "Donald Trump", "around 100,000", "1967", "Rajasthan", "Sodor", "the eye", "44,300", "2008", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6174509521885589}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1081081081081081, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.7096774193548387, 0.35294117647058826, 0.9454545454545454, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.16, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-4442", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.53125, "CSR": 0.543794014084507, "EFR": 0.9333333333333333, "Overall": 0.6966754694835682}, {"timecode": 71, "before_eval_results": {"predictions": ["David O. Dykes", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "photographer", "clown", "the Titanic", "Campania", "Hadrian", "Madagascar", "d\u00edaz", "Nick Weall", "Manet", "Gary Sparrow", "shuttle Columbia", "Edinburgh City F.C.", "Lacock Abbey", "Ian Fleming", "Canada", "estate", "Honda", "Greenock", "ABBA", "sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby", "Rudolf Hess", "travis de la Recherche Scientifique, National Fund for Scientific Research", "Stieg Larsson", "Facebook Stories", "1957", "menhir", "steel", "rotherham United", "Joseph Priestley", "dogs", "international team competition in sport,", "Periodic Table", "CameroonCameroon", "land between two rivers", "Timothy Carroll", "Cuba", "indiget", "Patience", "Chubby Checker", "Quentin Tarantino", "smartphones and similar devices to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 16th hole", "in San Francisco", "After strong sales into the 90s", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "monthly", "We wanted to be 100 percent carbon neutral from launch so we partnered with ClimateCare, one of Europe's most experienced providers of carbon offsets,", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lashings", "the Civil War", "How", "a peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.578125, "QA-F1": 0.643328373015873}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 0.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-4322", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-10030", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-11196"], "SR": 0.578125, "CSR": 0.5442708333333333, "EFR": 1.0, "Overall": 0.7101041666666666}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "Thames", "Altamont Speedway", "Hanna-Barbera", "26.22", "talus bone", "overprotective", "Samson", "Connecticut", "Daedalus", "Michael Ondaatje", "pand hysteria", "a goad", "peter parker", "fourteen", "radars", "Queen Elizabeth II", "german autry", "hippocampus", "Frank Miller", "tennis", "gollancz", "Atlantic Ocean", "New Zealand History", "Chatsworth House", "spain", "Budapest", "eyelid", "hiberqvarna", "b Benedict Cumberbatch", "aug. 24", "a fatty hump on their shoulders", "Octavian", "Venezuela", "Southwest Airlines", "spain Boulevard", "john McFee", "Derwent Water", "sesame", "Laos", "Allardyce", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "spirals", "1917", "Joan Rivers", "Greece", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito", "martin vermeer", "Dumbo the Flying elephant", "1580s North Carolina", "pythons"], "metric_results": {"EM": 0.421875, "QA-F1": 0.49583333333333335}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4380", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-208", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.421875, "CSR": 0.5425941780821918, "EFR": 0.972972972972973, "Overall": 0.704363430211033}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish", "Speedway World Championship", "Mercer", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Roswell", "Helen Mirren", "racehorse breeder", "Schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "\"Wragby Road\"", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "American investigative journalist Jane Mayer", "Obafemi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "33-member", "American television personality and film actress", "1967", "mathematician", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "a suburb", "schoolteacher", "People v. Turner", "Bill Ponsford", "Aamina Sheikh", "one", "Jean-Claude Van Damme", "Mike Holmgren", "Gauteng", "Herman Hollerith", "6 -- 14 July", "parashiyot", "paramitas", "1881", "broadcasting", "\"A $13 million global crime ring,", "Netflix", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6618482429029304}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-3845", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-1002", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.59375, "CSR": 0.543285472972973, "EFR": 0.9615384615384616, "Overall": 0.7022147869022869}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid", "ketchup", "igloo", "a house fly", "The Timberland boot", "The New York Times", "Burma", "Latvia", "spleen", "goodbye", "rely", "Ramesses II", "wine", "The esophagus", "Dallas Cowboys", "The King Jesus Gospel", "twist", "Marie Tussaud", "Biscay", "The Ziz", "March", "Ferdinand Magellan", "Verbal Kint", "prostitutes", "an oblate spheroid", "The Aviator", "Gioachino Rossini", "On the border between Veracruz and Puebla", "tail", "Nashville", "Hanging Gardens of Babylon", "the Starfighter", "Billy Crystal", "wrinkles", "LaSalle", "Qubec", "pope", "The Drew Carey Show", "Onagraceae", "Moonlighting", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Alice Dunnigan", "the Indian Ocean", "In vitro fertilisation", "Diogenes", "pastry", "On a sticker to put the first letter of the recipient's last name on the jar", "the Electric Company", "the following day", "Roger Dean Stadium", "March 31, 2013", "Beatles", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "giving birth to baby daughter Jada, who was watching her mum from the stands again on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5649230072463768}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5217391304347825, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-10018", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-2220", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-976", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801"], "SR": 0.46875, "CSR": 0.5422916666666666, "EFR": 1.0, "Overall": 0.7097083333333333}, {"timecode": 75, "before_eval_results": {"predictions": ["18", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "In 2006, 2007 -- 2008, January -- April 2012, and again in July -- October 2012", "1963", "king Gautamiputra Satakarni", "Jos\u00e9 Mart\u00ed", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "long - distance two - way communications", "28 July 1914", "St. Pauli Girl Special Dark", "908 mbar ( hPa ; 26.81 inHg )", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "the fictional Iron River Ranch, Colorado", "Valens and Richardson", "American singer - songwriter - actress Debbie Gibson", "Lula", "31 January 1934", "Camp Green Lake", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "the gut flora itself appears to function like an endocrine organ", "Kyla Coleman", "Bill Belichick", "December 19, 1971", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Partridge", "On April 3, 1973, Martin Cooper, a Motorola researcher and executive, made the first mobile telephone call from handheld subscriber equipment, placing a call to Dr. Joel S. Engel of Bell Labs, his rival", "Neil Young", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "many forested parts of the world", "arithmetic", "archery", "red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "\"I've always had my baby fat, but as I got to college I started gaining more,\"", "0-0 draw", "the Romanov Dynasty", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6162482433851919}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.7027027027027027, 1.0, 0.375, 0.0, 0.0, 1.0, 0.9428571428571428, 1.0, 0.0, 0.6, 0.5714285714285715, 0.6, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.4, 0.17647058823529413, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-4076", "mrqa_searchqa-validation-12989", "mrqa_newsqa-validation-1646"], "SR": 0.453125, "CSR": 0.5411184210526316, "EFR": 0.9714285714285714, "Overall": 0.7037593984962406}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island", "the Peace of Westphalia of 1648", "Authority", "Jughead Jones", "American rock band Los Lonely Boys", "the Great Plains and U.S. Interior Highlands region", "cakes", "Kiss", "18 September to 31 October", "Julie Adams", "during World War II", "Michael G. Hutton", "January 2004", "Ella Eyre", "Hank J. Deutschendorf", "Tennessee Titans", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins, and the lyrics to most of the suite's sections consist of his thoughts about her and their imminent breakup", "southern Turkey", "to encounter antigens passing through the mucosal epithelium", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Heather Roth", "Transvaginal ultrasonography", "by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IV", "Virginia", "Saphira hatches", "September 2017", "an Irish feminine name", "British group Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "southernmost part of the Balkan peninsula with two additional smaller peninsulas projecting from it : the Chalcidice and the Peloponnese", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "Vickers Vimy", "Apple PXS 1) 1970 $290", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million.", "San Diego,", "CNN.com", "jazz funeral", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6636006056296788}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 1.0, 0.375, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4850", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170"], "SR": 0.578125, "CSR": 0.541599025974026, "EFR": 0.9259259259259259, "Overall": 0.6947549903799903}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 8", "Live and Let Die", "Giuliano Bugiardini", "metal", "pulsar", "Seth", "Honda Motor Company", "\"Erroneous\" Number One", "Hitler", "\"Bard of Avon\"", "2010 FIFA World Cup 2010", "Elizabeth I", "June", "Italy", "1960's", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "Iceland", "Uranus", "rum", "apples", "Aberlemno", "Roddy Doyle", "the U.S Olympic Trials", "Separate Tables (1958)", "his most famous invention on June 25, 1876", "Beatrix Potter", "magpie", "comets", "sport with the largest number of Olympic disciplines is skiing, however, was discontinued after the 2008 Summer Olympics.", "Kansas City Royals", "Ra\u00fal Castro", "Bowie\u2019s first #1 hit in the USA with Fame.", "Scotland", "Red Admiral", "Illinois", "green", "Splash", "South Africa", "menorah", "Good Will Hunting", "slug", "otters", "John McCarthy", "John Mortimer", "Kellogg\u2019s Special K", "line code", "native to Asia", "Liam Cunningham", "Foofa", "Fuenlabrada", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "Saint Bernard", "France", "Barnard College", "photovoltaic solar panels."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6513144841269842}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7254", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.578125, "CSR": 0.5420673076923077, "EFR": 1.0, "Overall": 0.7096634615384615}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Verdi", "month of May", "Al Pacino", "Mohanda Karamchand", "an larger than 1000 to be written by increasing the number of arcs", "Mr. Golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "director of the Security Service", "a 965-foot ocean liner", "Funchal", "woman", "spaghetti harvest", "Northern Ireland", "woman", "Marcel Duchamp", "Quatermass Experiment", "Mumbai", "an  elaborate statue", "1875", "raven", "hound", "Susie", "st leger", "$x^2", "Narendra Modi", "Richard Wagner", "quentin Tarantino", "Argentina", "woman", "Kitzb\u00fchel", "Tunisia", "barbara mandrell", "steppes steppe", "Romania", "brindisi", "phoebe", "Emeril Lagasse", "fifa", "endora", "woman", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "Ireland", "'The Italian Job' (1965)", "woman", "Colombia", "island of Ireland", "1 - 2 spinal nerve segments above the point of entry", "magnetic stripe `` anomalies '' on the ocean floor", "the Northern Kingdom of Israel, Samaria", "folk-song", "Martin O'Malley", "1992", "sculptures", "Sunday's", "Al-Shabaab", "The Old Man and the Sea", "Edward I", "Malodie McDaniel", "there were no radar outages and said it had not lost contact with any planes during the computer glitches."], "metric_results": {"EM": 0.453125, "QA-F1": 0.5693940556992028}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.35294117647058826, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.9, 1.0, 0.7692307692307693, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-7920", "mrqa_hotpotqa-validation-2327", "mrqa_searchqa-validation-7161", "mrqa_searchqa-validation-6534", "mrqa_newsqa-validation-904"], "SR": 0.453125, "CSR": 0.5409414556962026, "EFR": 1.0, "Overall": 0.7094382911392405}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS Amethyst", "Libya", "tomato", "Kyoto Protocol", "costume", "Bull Moose Party", "know", "jerry laMotta", "resistance", "hanie McDaniel", "South Africa", "indigestion", "discretion", "eva", "will be assessing their performance in the process, individually and within their teams", "George Washington", "Corinth Canal", "Ede & Ravenscroft", "Iceland", "ascot", "european", "burt", "gangsters", "bitches", "Duncan", "UK Independence Party", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "rambo", "Julian", "The IT Crowd", "ilie nastase", "carters", "charlie croker", "Richard Curtis", "Terms of Endearment", "ireland", "ireland", "1790", "argyle", "charomile", "hitler", "orchid", "Hilary Swank", "aberdeen", "latitude 90 \u00b0 North", "the 18th century", "nine hours from Coordinated Universal Time ( UTC \u2212 09 : 00 )", "just 18 minutes", "England", "Sri Lanka Freedom Party", "\"Steamboat Bill, Jr.\"", "Afghanistan's Helmand province,", "KCNA", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5395535714285714}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16, 0.5714285714285715, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-374", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-4551", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2468", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-889", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5872", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7640", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-2404", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.46875, "CSR": 0.5400390625, "EFR": 0.9705882352941176, "Overall": 0.7033754595588235}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2", "dress shop", "Robert Gillespie Adamson IV", "Colon Street", "to get rich and escape the cycles of poverty and abuse on the reservation", "Jason Momoa", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "Canadian Rockies continental divide east to central Saskatchewan", "base homeostasis", "Miami Heat", "March 29, 2018", "four of the 50 states of the United States in their full official state names", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas, or tolled ( quota ) highways", "set to 0.05 ( 5 % ), implying that it is acceptable to have a 5 % probability of incorrectly rejecting the null hypothesis", "Tom Burlinson, Red Symons and Dannii Minogue", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Santa Clara Pueblo, New Mexico", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "2001 Indian epic sports - drama film, directed by Ashutosh Kumarariker, produced by Aamir Khan and Mansoor Khan, and written by Gowariker and Abbas Tyrewala", "1996", "American rock band Los Lonely Boys", "appearances", "foreign exchange market ( FX )", "The Hustons", "Sunday Post", "Karl Pilkington", "pei Tang", "1860", "back to December", "Buck Owens", "\"Up\"", "\"Empire of the Sun,\"", "off east  Africa", "modificre", "molly ringwald", "faerie", "skull and crossbones"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7181930322966508}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.7499999999999999, 0.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.10526315789473684, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.640625, "CSR": 0.5412808641975309, "EFR": 0.9130434782608695, "Overall": 0.6921148684916801}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Berenice II", "nuclear warheads", "capitals", "pep", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "Marcia Clark", "Jenny", "gestation", "ravens", "J. R.R. Tolkien", "James Franco", "the Blue Ridge Mountain range", "British Guiana", "bathrobe", "buddha", "Apple", "Southampton, Virginia", "barbels", "A Chorus Line", "Piazza del Campo", "Saoirse Ronan", "a feeling of sadness about something that you did or did not do", "de Havilland", "Virginia", "College of William", "a dog recently recognized by AKC", "Louisiana", "Matthew Vassar", "New York", "place-setting", "The Police", "Air France", "Fnelon", "Heracles", "trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "yodeling", "the Indian Ocean", "a syringe with a needle fine enough to pierce the skin", "Charlotte Corday", "nanosecond", "Didelphodon vorax", "Mason Alan Dinehart", "a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a great deal on location", "2010", "cymbal", "Madagascar", "Tom Hiddleston", "Estadio Victoria", "Borough of Allerdale", "Zimbabwean President Robert Mugabe", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.5, "QA-F1": 0.5958705357142857}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-8284", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390"], "SR": 0.5, "CSR": 0.5407774390243902, "EFR": 0.96875, "Overall": 0.7031554878048781}, {"timecode": 82, "before_eval_results": {"predictions": ["USS Nautilus", "the Hopi", "Vatican City", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "Mark", "Marilyn Monroe", "Souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,047 m2", "\"Darwinthe\"", "Frans Hals", "the Black Sox Scandal", "(desert lynx)", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "nouveau", "autobahn", "Germanic", "the California quail", "curtsy", "lacrosse", "Toronto", "hard", "King David", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "point", "(Lee) Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "between 1881 and 1885 ( connecting with Ottawa Valley and Georgian Bay area lines built earlier ), fulfilling a promise extended to British Columbia when it entered Confederation in 1871", "$2.187 billion", "On the west", "Austria", "acai", "the Benedictine Order", "Pansexuality", "\"Titus Andronicus\"", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6772961469534049}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25806451612903225, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.578125, "CSR": 0.5412274096385542, "EFR": 0.9629629629629629, "Overall": 0.7020880745203034}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "Trinity College", "Algeria", "(Franz) Joseph Haydn", "Dick Cheney", "the black market", "an", "Saturday Night Fever", "the United States", "pizza al taglio", "a turtle", "the Empire State Building", "White blood cells", "a trifle", "dogwood", "Qubec", "(Larry) McMurtry", "Kellogg\\'s", "Helen of Troy", "Sweatshirts", "a kilogram", "Napoleon", "dentures", "the Arctic area of Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "the American Bell Telephone Company", "Pancho Gonzales", "the Aleutians", "the Mormons", "Lady Jane Grey", "Tommy", "the crescent", "bulgaria", "an egg", "Nicolaus Copernicus", "Chiles Rellenos", "William Safire", "the Dominican monastery of this Church", "London", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "\"Casablanca\"", "T. R. M. Howard", "Parlophone", "9:20 p.m. ET Wednesday.", "the U.N. aid agency", "1995,", "four"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6661458333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-11669", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-537"], "SR": 0.59375, "CSR": 0.5418526785714286, "EFR": 1.0, "Overall": 0.7096205357142857}, {"timecode": 84, "before_eval_results": {"predictions": ["Syria", "Catherine of Aragon", "Judas Iscariot", "Windsor, Ontario", "Stephen Douglas", "comrade", "The Great Gatsby", "a fox", "Sexuality", "a baseball club", "Solomon", "Federer", "a bicycle", "Johnson County", "Jericho", "a push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the American Revolution", "the Philippines", "St Mark", "Eragon", "\"Strawberry Fields Forever\"", "Louisiana", "Mexico", "jolly Roger", "engrave", "daisy Miller", "\"The Stag\"", "X", "a ship", "Kamehameha", "a wolf", "Jamestown", "Jerry Maguire", "the north magnetic pole", "Oyster Bar", "a orangutan", "Candlestick Park", "Zimbabwe", "a bow", "Patty Duke", "Plural", "Hoffmann", "a calico", "Frankie Muniz", "during season two", "a compound sentence", "40", "Neptune", "Nowhere Boy", "August 1973", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Carrefour", "financial gain,", "a Nazi concentration camp,", "Agent Mark Steinberg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6875}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-8329", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.609375, "CSR": 0.5426470588235295, "EFR": 1.0, "Overall": 0.7097794117647059}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Winnie The Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "(F.O.J) Smith", "Strawberry Fields", "The Hague", "Geena Davis", "Pharmacy", "( Kit) Carson", "the NFL", "( Jimmy) Doolittle", "pneuma", "Shakespeare in Love", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "(the NIV)", "The X-Files", "(Nature Cure)", "Mensa", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a Booster seat", "The Salt Lake Tabernacle Choir", "the Venetians", "a (acorn) squash", "the Warsaw Pact", "Sparta", "the Sunday New York Times", "anode", "(Star Trek)", "the National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "(HAIR)", "the Texas Rangers", "Fluoxetine", "H CO ( equivalently OC ( OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College and Balliol", "Leeds", "Bexar", "General Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Charles Sherrington"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6505952380952381}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692"], "SR": 0.609375, "CSR": 0.5434229651162791, "EFR": 1.0, "Overall": 0.7099345930232558}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a short distance", "a real animal", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "the Palatine hill", "California", "the Mississippi", "Alpha", "Quebec City", "oyster", "Texas Chainsaw Massacre", "a dome", "a Medal of Honor", "Manet", "Plutarch", "Milan", "Celia", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "the Sadler", "Vasco da Gama", "Millard", "a coarse twilled fabric", "Finnegans Wake", "a salutation", "the black market", "professor", "S-waves", "Maastricht", "Delilah", "synapses", "croissant", "\"Magnificent Inn\" Grand Hotel", "lungs", "fuchsia", "metacarpal", "a pool", "Warsaw", "a trowel", "the Mercury Seven", "Taiwan", "Gettysburg", "NCAI", "a trout", "\"I'd Like to Get You on a) Slow Boat to China\"", "1959", "the first season of NCIS", "$75,000", "Zimbabwe", "15", "a stonemason's yard", "Agent Carter", "Orson Welles", "Manhattan, New York City,", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6230045995670995}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-6251", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.5625, "CSR": 0.5436422413793103, "EFR": 1.0, "Overall": 0.7099784482758621}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists", "Michael Crawford", "Alka Yagnik", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "5,770 guaranies", "Geoffrey Zakarian", "4.5 pounds or 2.04 kg", "Walmart", "Ian Petrella", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Robert Duvall", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "secession", "The Osmonds", "( Russian : \u0427\u0442\u043e \u0434\u0435\u043b\u0430\u0442\u044c?, tr. Chto delat '? )", "Taiwan", "Anakin", "Jeff East", "one", "Mary Elizabeth Ellis", "Ed Roland", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "Washington", "the 2nd century", "Triple threat", "1998", "Nicolas Anelka", "foreign investors", "Louis XVIII", "marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool", "Robber baron", "December 20, 1951", "Crick", "Aconcagua", "Bake Off", "1924", "Robert Loggia", "zona glomerulosa", "Fionnula Flanagan", "last summer.", "social issues like homelessness and AIDS.", "fourth time lucky", "banker", "eyes", "the Cubs", "a pickpocket"], "metric_results": {"EM": 0.4375, "QA-F1": 0.542408310039771}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7741935483870968, 0.0, 1.0, 0.1, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.05714285714285715, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-6424", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-995", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-9976", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.4375, "CSR": 0.5424360795454546, "EFR": 0.9444444444444444, "Overall": 0.6986261047979798}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "from Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "\"The three were seized early Monday after police raided a bus station in Sargodha, a city located about 120 miles (190 km) south of Islamabad in Pakistan's Punjab province.", "Salt Lake City, Utah,", "normal maritime", "Toffelmakaren", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "\"The oceans are growing crowded, and governments are increasingly trying to plan their use.", "In the last four weeks, authorities arrested three men with suicide vests who were plotting to carry out the attacks,", "\"It should be \"perezagruzka\" (the Russian word for reset,)", "club managers,", "Long Island", "90", "FBI negotiators", "Reggae legend Lucky Dube,", "The United States has designated a Kurdish militant group in Turkey as a terrorist organization, the State Department said.", "At least 14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "the Defense of Marriage Act", "Europe,", "\"The idea that this was a fly-by-night [is]... not true. I used it routinely.\"", "immediate release into the United States of 17 Chinese", "Greeley, Colorado,", "Festival Foods in Kansas City, Missouri,", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "drugs", "Daniel Radcliffe", "1.2 million", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million", "Krishna Rajaram,", "a long-range missile", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas ministry spokesman Taher Nunu", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "\"The United States can learn much from Turkey's expertise on Afghanistan and Pakistan -- not the kind of society the Taliban has been providing.", "the Yemeni port city of Aden", "10 municipal police officers", "Carl and Ellie", "central business district of Bangkok", "journalists and the flight crew", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Chris Hemsworth", "prime minister", "England and Ireland", "beef", "Sleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5793325399338363}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.058823529411764705, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.1111111111111111, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.5, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 0.0, 0.4, 1.0, 0.2, 0.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 0.33333333333333337, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.4375, "CSR": 0.5412570224719101, "EFR": 1.0, "Overall": 0.709501404494382}, {"timecode": 89, "before_eval_results": {"predictions": ["Pease Air National Guard Base", "Kim So-hyun", "president", "Comedy Film Nerds", "9\u201310 March 1945,", "2011", "John D Rockefeller", "during the early 1970s", "Asiana Town building", "rock and roll", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks", "Fabbrica Italiana Automobili Torino", "Chrysler", "Australia", "chimpanzee", "\"Traumnovelle\" (\"Dream Story\")", "Joshua Rowley", "Robert Digges Wimberly Connor", "Yitzhak Edward Asner (born November 15, 1929)", "the Beatles", "Baden-W\u00fcrttemberg, Germany", "2001 NBA All-Star Game", "\"Flashing Lights\"", "95 AD", "1614", "French", "\"The Manhunter\"", "Mondays", "James Ager Worthy", "\"I, (Annoyed Grunt)- Bot\"", "laundering Building", "1987", "Kalokuokamaile, the older brother of Kamehameha I, founder of the Kingdom of Hawaii", "17 October 2006", "melodic hard rock", "the Home Rule Party", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act of 1854", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "elbow", "the Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "\"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "for flooding from Hurricane Irene that pummeled the East Coast last August and for damages from Tropical Storm Lee in Schoharie, Tioga, Broome, Greene, and Orange counties."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6996527777777778}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.0, 0.3333333333333333, 0.0, 0.16666666666666669, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-7701", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.59375, "CSR": 0.5418402777777778, "EFR": 1.0, "Overall": 0.7096180555555556}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2003", "singer", "Pakistan", "1754", "\"To Save a Life\"", "VfL Wolfsburg", "d\u00eds", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Fuli", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "Heathrow", "\"Binaural\" (2000)", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama", "Scandinavian design", "Mike Pence", "Barack Obama's Cabinet", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian Church (USA)", "138,535 people", "Ry\u016bky\u016ban", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravity", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "Mexico", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "kite surfers", "Robert", "Barbie", "Thunderball", "CO2", "Walgreens"], "metric_results": {"EM": 0.53125, "QA-F1": 0.614230595039019}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.30434782608695654, 0.0, 1.0, 1.0, 0.2564102564102564, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-3261", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1363", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-4050", "mrqa_triviaqa-validation-4655", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.53125, "CSR": 0.5417239010989011, "EFR": 0.9666666666666667, "Overall": 0.7029281135531136}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Sony", "a Jaguar", "Tony's Restaurant", "Friday", "Sabino Canyon", "Ricky Gervais", "Babe Ruth", "south west america", "Arkansas", "Vince Lombardi", "Iustitia", "contemporary", "Steppenwolf", "bucolic", "Tito Puente", "Hydrogen", "Johnny Cash", "malignant disease", "Margaret", "Las Vegas", "San Francisco", "1960s", "Mary Baker Eddy", "Bank One", "Oberlin College", "The Wright Brothers", "Badminton", "John Deere", "Shanifa Rahmawati", "Chrysler", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Haroun", "a bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Evita", "Kingston", "a key", "Ghost", "Francisco Pizarro", "Mesopotamia", "Jean-Paul Marat", "Cetshwayo", "the Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "jingle", "Bobby Brown", "british town of Aquae Sulis", "1.5 million", "Macomb County", "Kristoffer Rygg", "Veracruz", "Monday", "23", "a English Anglican cleric and theologian"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6255208333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_triviaqa-validation-3665", "mrqa_hotpotqa-validation-2255", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-979", "mrqa_hotpotqa-validation-4539"], "SR": 0.5625, "CSR": 0.5419497282608696, "EFR": 1.0, "Overall": 0.7096399456521739}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico Virginia", "the East", "William Shakespeare", "William Shakespeare", "a (disease)", "Alaska", "Sputnik", "Richmond", "the 1960s", "Java", "Haydn", "Marius Petipa", "the Flag", "vulcanization", "Heathcliff", "Muhammad", "Rome", "The Curse of the Black Pearl", "Charles de Gaulle", "Richmond", "the wolverine", "Josphine de Beauharnais", "salt", "a felony", "Rossini", "Texas", "Lapland", "Tom", "Roman Polanski", "Joan Didion", "the frigate", "Baltimore", "the Bay of Bengal", "John Morton", "Hillary Clinton", "Terrific", "the geology of Mars", "six sides", "Olympia", "the Ship of Fools", "a scare zone", "Tom", "a genie", "Margaret Mitchell", "Frances", "Vin Diesel", "a cremation", "the French & Indian War", "a manic episode", "central Saskatchewan", "lighter", "a scuffle with the Beast Folk", "Bond", "Germany", "Caernarfon", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6059027777777777}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-14332", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.546875, "CSR": 0.542002688172043, "EFR": 1.0, "Overall": 0.7096505376344087}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Alice Cooper", "Telma Hopkins", "Mel Gibson", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners, ( Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "Pacific Grove", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form", "Audrey II", "January 2017", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "American production duo The Chainsmokers", "13 May 1787", "Prince James, Duke of York & of Albany ( later King James II & VII ) sailed in the harbor at New Amsterdam, threatening to attack", "his brother", "Seattle, Washington", "honey bees", "Article 1, Section 2, Clause 3 of the United States Constitution", "Robin Williams", "Napoleon", "Hem Chandra Bose", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "ice giants", "hyperinflation", "1939", "Richard Masur", "Sanaa Lathan", "the Philippines", "Sauron", "Lana Del Rey", "position", "159", "The Third Five - year Plan", "Rah, Rah, Jayhawk, Go KU", "works in a bridal shop", "activates a relay which will handle the higher current load", "A patent", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood\\'s A Holy Grail", "nide", "February 13, 1946", "Crystal Dynamics", "Congo", "Jason Chaffetz", "\"The Da Vinci Code,\"", "Jenny Sanford.", "Khrushchev", "Julie Andrews", "the Headless Horseman", "Leo Frank, a northern Jew who'd moved to Atlanta to supervise the National Pencil Company factory."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6371093270764323}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.9824561403508771, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7272727272727273, 0.0, 0.0, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_hotpotqa-validation-3077", "mrqa_newsqa-validation-3374", "mrqa_newsqa-validation-3849"], "SR": 0.53125, "CSR": 0.5418882978723405, "EFR": 0.9333333333333333, "Overall": 0.6962943262411347}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "Thon MarialMaker", "Battle of Chester", "the youngest TV director ever", "28 January 1864, Halifax, Yorkshire, England", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away.", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural", "6", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "Pantone Inc.", "Las Vegas Boulevard", "The Design Inference", "Barbara Ryan Coleman", "Tim McIntire", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevrolet Corvette", "In 1991 he received a Primetime Emmy Award for Outstanding Supporting Actor in a Drama Series for \"thirtysomething\"", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "\"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "Tony Manero", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "\"Holinshed's Chronicles\"", "June 26, 2018", "Commonwealth Universities", "1 April 1985", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "the densest giant planet", "The alveolar process", "Dortmund - Ems Canal", "Hugh Quarshie", "Alexander III", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria.", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6826954539125591}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true], "QA-F1": [0.8333333333333333, 0.4, 1.0, 1.0, 0.6666666666666666, 0.3157894736842105, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.47619047619047616, 1.0, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-1656", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.546875, "CSR": 0.5419407894736843, "EFR": 1.0, "Overall": 0.7096381578947368}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1950", "Roy Spencer", "1484\u20131564", "Comcast Xfinity", "World of Wonder", "March", "Russian", "Han Solo", "July 25", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "\"Northern Lights\"", "non-alcoholic", "Mach number", "Sami Brady", "Maine", "Encore Las Vegas", "Baa, Baa", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1935", "Sargent Shriver", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor", "Song Il-gon", "Teen Titans Go!", "Mickey Mouse cup", "\"The Member of the Wedding\"", "right-hand", "\"Sheen Michaels Entertainment\"", "Sela Ward", "seal hunting", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers women's basketball team", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress meeting at the Pennsylvania State House ( Independence Hall ) in Philadelphia on July 4, 1776", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La Fenice", "April.", "\"The Da Vinci Code,\"", "Dogpatch Labs", "iceberg", "a fuel cell", "Victoria", "Venus Williams"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6579600041771094}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true], "QA-F1": [0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-1059", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-1151", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_naturalquestions-validation-360", "mrqa_triviaqa-validation-4831", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503", "mrqa_searchqa-validation-9695"], "SR": 0.546875, "CSR": 0.5419921875, "EFR": 1.0, "Overall": 0.7096484375000001}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "The Highwaymen", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3", "chocolate-colored", "The 1962 Italian Grand Prix", "1908", "Neneh Cherry", "Eminem", "\"Love Streams\"", "In a Better World", "the Shropshire Union Canal", "\"Killpool 2\"", "The Killer", "October 2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "\"Strictly Come Dancing\"", "a Native American", "John Francis Kelly", "early Romantic period", "$700 million", "the Sun", "Bhushan Patel", "1692", "the power to regulate interstate commerce", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "a third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "isosceles", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "a pastry cream", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7866702741702742}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-1698", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-5842", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789", "mrqa_searchqa-validation-13280"], "SR": 0.671875, "CSR": 0.5433311855670103, "EFR": 0.9523809523809523, "Overall": 0.7003924275895925}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "The Caucausus range", "David Bowie", "Joe Davis", "Granada", "Treaty of Brest-Litovsk", "Georg Wilhelm Friedrich Hegel", "Paramounts", "Marilyn Monroe", "fish", "1957", "1919", "transsexual", "Fred Astaire", "greece", "Scotland Yard", "Inverness, Aberdeen, Glasgow and Edinburgh", "loving and giving", "Charles Lindburgh", "Rudyard Kipling", "1921", "The Full Monty", "Desdemona", "avocado", "Frans Hals", "Syriza", "Ford", "soybean", "Cole Porter", "1826", "w WJacobs", "Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "an elephant", "Bobby Fischer", "end -shion", "Westminster Abbey", "Canada", "Ric Pipino", "Edward VII", "Tombstone", "S\u00e3o Miguel Island island of Cape Verde", "Mr. Men and Little Miss", "cathedral Church of Worcester", "Mercury", "December 7, 1941", "The malleus", "Nadia Comaneci", "Neil Armstrong", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Naval Air Station Whidbey Island", "95 AD", "170", "Chuck Bass", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6192708333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-4459", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.5625, "CSR": 0.5435267857142857, "EFR": 0.9642857142857143, "Overall": 0.7028125000000001}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan", "deutschneudorf", "suspects allegedly involved in forged credit cards and identity theft led authorities to a $13 million global crime ring,", "his health and about a comeback.", "poems", "then-Sen. Obama", "woman", "581 points", "The Everglades,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.\"", "Phillip A. Myers.", "(\"Swingin' Down the Lane.\"", "share personal information.\"", "London and Buenos Aires", "a Yemeni cleric and his personal assistant,", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "he was an Ennis man, we will be back,\"", "stars of TLC's \"The Little Couple,\"", "WBO welterweight title", "Austin, Texas,", "17-month", "him to be included in the family allowance.", "Manmohan Singh's", "we need to get businesses hiring again.", "death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina.", "Bill Haas", "Consumer Reports", "28", "step up.\"", "42", "since 1983.", "improve health and beauty.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Derek Mears", "he believed every nation should set its own goals.", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "fifth", "Haeftling", "on the table", "Asuka", "Bart Millard", "Nissan", "stone arch bridges", "jMW Turner", "Marx Brothers film", "Indian", "early 20th-century Europe", "hold business' IT systems hostage", "Shakespeare in Love", "W. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5926735223345393}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.23728813559322035, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.38095238095238093, 0.7272727272727272, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2182", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2749", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191"], "SR": 0.484375, "CSR": 0.5429292929292929, "EFR": 0.9090909090909091, "Overall": 0.6916540404040404}, {"timecode": 99, "UKR": 0.7109375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.8046875, "KG": 0.48671875, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "most performed song of all time", "Oregon State Beavers", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate", "Pain Language", "Broadcasting House in London", "London Tipton", "\"Barney Miller\".", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "What's Up", "Saturday Night Live", "strongly associated with Gaia and Cybele", "Tumi Holdings, Inc.", "Black Ravens", "commercial", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Krusty the Clown", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "Detroit rock band, the MC5", "James City County", "Arab", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Neotropical realm", "Sister, Sister", "five", "Mark Radcliffe", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "an idea of laying out a tournament ladder by arranging slips of paper with the names of players on them", "Frank Zappa", "1991", "applea", "Fred Trueman", "Scotland", "Sullenberger", "Mario Balotelli", "Friday,", "Lifeboat", "a yobibyte", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6518452380952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.5, 0.5714285714285715, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.8, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6799999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2031", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2083", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.546875, "CSR": 0.54296875, "EFR": 1.0, "Overall": 0.7090625}]}