{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8220, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "the Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "the Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "about 0.7%", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normans/Normanz", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.859375, "QA-F1": 0.88125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-7552", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 0.8888888888888888, "Overall": 0.8780381944444444}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "the Qur'an", "the Brotherhood", "high demand", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "linear", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the decision problem in Presburger arithmetic", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial", "leg leg", "\"A visit from St. Nicholas\"", "guardian", "Constitution Day", "guardian", "leg leg", "time goes", "guardian", "leg leg", "abolitionists", "one mile above sea level"], "metric_results": {"EM": 0.625, "QA-F1": 0.6963812229437228}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-7408", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.625, "CSR": 0.7864583333333334, "EFR": 0.9583333333333334, "Overall": 0.8723958333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "tenes", "calcitriol", "Warsaw", "time and space", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "the fundamental means by which forces are emitted and absorbed", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "Mollusca", "Orestes", "the Galapagos Islands", "the \"Today\" show host did a terrible job", "the process by which water changes from a liquid to a gas", "the Forty-Davidson Museum in Milwaukee, Wisconsin", "a cocoa favorite", "a major raw", "the Mycenaean kingdoms", "a biological process that displays an endogenous, entrainable", "the Belasco Theatre", "the Normandy Landings", "John Dillinger", "the tibia", "Il Trovatore", "the South Pole", "the Tweed"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6846252705627706}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-1775", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-6338", "mrqa_triviaqa-validation-2595"], "SR": 0.65625, "CSR": 0.75390625, "EFR": 1.0, "Overall": 0.876953125}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "the secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "the New Testament", "experience, ideology, and weapons", "25", "May 2013", "Torchwood", "capturing prey", "C4", "pasture", "Ford", "1,300,000", "confusing between carbon dioxide and oxygen", "two tumen", "eight", "A computational problem", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empire", "the domestic legislation of the Scottish Parliament", "how much of an impact", "Michael Bloomberg", "the oceans are growing crowded", "innovative, exciting skyscrapers", "a cancerous tumor", "the war years", "semiconductors", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block", "the foyer of the BBC building", "Christianity", "Manchester City", "Noriko Savoie", "three", "change course", "Tsvangirai", "a Lion Among Men", "January 2, 1971", "sweetener", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7173036165223665}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.1111111111111111, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.2, 0.0, 1.0, 0.25, 0.0, 0.7272727272727273, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7606", "mrqa_squad-validation-9250", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-4258", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.640625, "CSR": 0.73125, "EFR": 1.0, "Overall": 0.865625}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven classes", "the Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "pharmacists practicing in hospitals", "a seal", "Philip Howard", "Duke Richard II of Normandy", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "the constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC", "two", "George Westinghouse", "by disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "D, E or F", "the Louvre", "Leo Frank", "Athens", "Graziano Transmissioni", "opposition parties", "204,000", "United's", "the release of the four men", "putting a personal and human face on the issue", "Ed McMahon", "the Magna Carta is expected to fetch at least $20 million to $30 million,", "Hillary Clinton, Connecticut Sen. Chris Dodd, Texas Rep. Chet Edwards, Nebraska Sen. Chuck Hagel, Virginia Gov. Tim McAuliffe, former Georgia Sen. Sam Nunn, Rhode Island Sen. Jack Reed", "Friday", "Obama", "ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promoting fuel economy and safety while boosted the economy", "resting heart rate over 100 beats per minute", "a small draught horse, around three-fourths of a ton, and is without feathered legs", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6946402879858138}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2666666666666667, 0.06451612903225806, 0.0, 0.4, 1.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.15384615384615385, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-7260", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-6644", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.59375, "CSR": 0.7083333333333333, "EFR": 0.9230769230769231, "Overall": 0.8157051282051282}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "the University of Chicago Press", "$2 million", "2015", "1762", "biased", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "autumn of 1991", "William Smith", "William Pitt", "geochemical component", "theory that the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1", "nerves", "1700", "New Germany", "polysaccharides", "Howard Dean", "the circulatory system", "Troggs", "God took millions of years to make everything.", "Slovakia", "Diana", "slave trade", "vena cava", "a flower, a shell, a boat, a bug and a dance", "bull's-eye", "Tartarus", "cyclorama - Search-ID.com", "Si-Tchun", "Persian Achaemenid Empire", "LAP", "Germany", "net worth", "Duke of Clarence", "microns, or thousandths of a millimeter", "Detective Eagan", "Judas", "Hurley", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "United States", "FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6683602855477856}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.45454545454545453, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.609375, "CSR": 0.6941964285714286, "EFR": 1.0, "Overall": 0.8470982142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "little", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Eisenhower Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "\u201ccapability deprivation\u201d", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Laker", "Earth", "tornado", "Rodeo", "hog", "Barack Obama", "Kenny G", "a small, half size cup used for serving espresso", "a tutu", "Annapolis", "spring", "klammeraffe", "Artificial female", "Allah", "bones", "Python", "Bible: In the Beginning", "Cold Mountain", "Faith Hill", "Ben Affleck", "U.S.", "\"unconquerable will of the occupied territories\"", "time", "Yardbird and Bird", "Sweden", "Philippines", "atomic numbers 1 ( hydrogen ) to 118 ( oganesson )", "destroyed", "Perfume: The Story of a Murderer", "20%", "Georgetown", "Essex Eagles", "Alzheimer's"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6013020833333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.25, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_naturalquestions-validation-10073", "mrqa_triviaqa-validation-3911", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.546875, "CSR": 0.67578125, "EFR": 1.0, "Overall": 0.837890625}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu in the north", "silent", "22", "the park", "1965", "tidal currents", "combustion", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "the Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube at Passau", "Yahweh", "leather", "the Pullman Palace Car Company", "a dark red-purple plum", "a Lunar eclipse", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "the tonka bean", "a fraction", "Hypnos", "Texas", "IHOP", "alexandria", "the Bill of Rights", "an optional writing test", "Rio de Janeiro", "chapter 5", "Southern California", "Harry Whittington", "alexandria", "William Donald Scherzer", "Edward Hopper", "the CIA", "d'Artagnan", "painted Caves", "1985", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.5, "QA-F1": 0.5850206500172532}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.5, 0.0, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.5, "CSR": 0.65625, "EFR": 1.0, "Overall": 0.828125}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "Second World War", "integer factorization", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration", "prep schools", "soft power", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes, the most characteristic musical instrument in the region", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Hera", "the vine", "Dwight", "Cuba", "the Battle of Thermopylae", "Khazars", "Kroc", "cricket", "white", "Washington State", "Carmen", "Genoa", "50%", "tarn", "972; 451; 100; or 25", "Buffalo", "Ann Widdecombe", "scalene", "the Rockingham Arms", "Tuesday", "beryllium nitrate", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "Kajagoogoo", "a reddish-purple berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "David Rehbein", "J. Crew", "Deval Patrick", "Bea Benaderet"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6265624999999999}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-9870", "mrqa_squad-validation-5376", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.546875, "CSR": 0.6453125, "EFR": 1.0, "Overall": 0.82265625}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio network", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "the Roman Catholic Church", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "the faecal-oral route (turd to tongue transmission)", "a fast-growing tree with fragrant spring flowers", "Ken Russell", "Dan Dare", "mucia", "the Smiths", "Evander Holyfield", "Turkey", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "puck", "UV Ultraviolet", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "Titanic", "William Tell", "Christian Dior", "a shaggy, candy-loving dog", "Mendip Hills", "Wichita", "the Passover", "New Croton Reservoir in Westchester and Putnam counties", "The Way You Move / Hey Ya!", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Monty Python and the Holy Grail", "Roman Polanski"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7450892857142857}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710"], "SR": 0.734375, "CSR": 0.6534090909090908, "EFR": 1.0, "Overall": 0.8267045454545454}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "disturbed", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "Killer T cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "\"party\" + Allah \"God\"", "1968", "Whist", "Nile River", "Toscana", "achromatopsia", "pigment", "Pluto", "iron and carbon", "platinum or palladium", "Hague", "Vancouver Island", "Ironside", "George Smiley", "gorky", "trout", "Beyonce", "Wordsworth", "Good Food", "Queen Elizabeth II", "jonimo Lobo", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "vitamins A and K.", "huddsyn", "peninsula", "Shrek", "Oslo", "lions", "rhododendron", "Chicago", "Franklin D. Roosevelt", "Shanghai", "Bartlett Sher", "motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "Snake River Valley", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception, Rome, Italy", "Poe", "julibo"], "metric_results": {"EM": 0.5625, "QA-F1": 0.618161525974026}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09090909090909091, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4510", "mrqa_squad-validation-8252", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.5625, "CSR": 0.6458333333333333, "EFR": 1.0, "Overall": 0.8229166666666666}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "720p high definition", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky", "The Handmaid's Tale", "pygmy chimpanzee", "The Fault in Our Stars", "CR-X", "puzzle", "1898", "400 MW", "tag team", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack St. Clair Kilby", "Ryan Babel", "Ramzan kadyrov", "July 16, 1971", "1933", "What's Up", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties", "constant johnson", "little Miss Muffet", "pre-Columbian times"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7142857142857142}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-5889", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_naturalquestions-validation-8227"], "SR": 0.6875, "CSR": 0.6490384615384616, "EFR": 1.0, "Overall": 0.8245192307692308}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000 years of art", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Ranulf de Gernon", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Gilbert du Motier", "Gujarat", "three", "Winter Haven", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "my Beautiful Dark Twisted Fantasy", "FCI Danbury", "a few", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide of 1994", "Larnelle Harris", "Commander in Chief of the United States Armed Forces", "2015, 2017", "1982", "rod", "Chris Robinson", "gossip Girl", "cymatics", "out", "Egyptian Goddess of Creation", "Richie Unterberger"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6692708333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5494", "mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-1441", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5625, "CSR": 0.6428571428571428, "EFR": 1.0, "Overall": 0.8214285714285714}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular", "Inherited wealth", "December 1963", "1970", "religious freedom", "Spreading throughout the Mediterranean and Europe", "the kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "mathematical models of computation", "Vistula River", "100 to 150", "Apple announcing plans that could move iTunes into the cloud.", "at the school", "March 8", "Democrats and Republicans", "the Catholic League", "over 1,000 pounds", "requested the pardon", "Friday", "a spurned suitor", "stories of different women coping with breast cancer", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills -- began falling onto the stern of his ship", "stressed out", "$40 and a bread", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "more than 4,000", "World Cup giant slalom in Lienz", "the results by a chaplain about 1:45 p.m.", "four Americans", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls", "Buddhism", "J. Crew", "U.S.", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "\"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "the Irish capital", "Democrat", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument", "the oche", "Sevens", "England", "Yemen", "domenikos Theotokopoulos", "giant", "mercury"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5166077152014652}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7999999999999999, 0.23999999999999996, 0.0, 0.7499999999999999, 0.0, 0.6666666666666666, 0.0, 0.5, 0.2857142857142857, 0.25, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191"], "SR": 0.4375, "CSR": 0.6291666666666667, "EFR": 0.8888888888888888, "Overall": 0.7590277777777777}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "a prime number", "The committee created the 50 fund", "Camisards", "$40 million", "GTE.", "1,100", "spinat", "Oligocene", "Melodie Rydalch", "Charles Darwin", "a Little Rock military recruiting center", "March 24", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56,", "Georgia prosecutor's", "a secret long hidden by the brotherhood", "Heshmatullah Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Atlanta", "resources", "66, served as vice-chairman of Hussein's Revolutionary Command Council.", "two Emmys", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Burundi", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing", "President Bush", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "economic disaster.", "resigned", "attended the Democratic National Convention", "a strict interpretation of the law", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "blue", "Capitol Building", "The Left Book Club", "holography"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5477699239417989}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.5, 0.6428571428571429, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.375, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.5, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.3, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-397", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-411", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.421875, "CSR": 0.6162109375, "EFR": 0.972972972972973, "Overall": 0.7945919552364865}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers", "look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Kris Allen, the guy next door", "Brian Smith", "\"Hillbilly Handfishin'\"", "President Robert Mugabe", "voluntary negligence", "foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "injuries,", "30 years ago", "murder", "next year", "\"China is a different matter,", "Christopher Savoie", "Anil Kapoor", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire,", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your environmental efforts", "two women", "once on New Year's Day and once in June,", "Monday,", "women", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "World War I", "1950s,", "heavy fighting between U.S.-backed Iraqi troops and al-Sadr's", "Brazil jolted the global health community in 1996 when it began guaranteeing free anti-retroviral treatment to HIV/AIDS patients.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "first of three films that comprise the \"Three Colours\"", "2001", "vingtaines", "U.S.", "George Blake", "Bogota"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6356926088024878}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4000000000000001, 1.0, 1.0, 0.0, 0.5, 0.6923076923076924, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 0.5, 0.923076923076923, 0.0, 1.0, 0.0, 1.0, 0.2, 0.12903225806451615, 0.5, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-914", "mrqa_newsqa-validation-2041", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.515625, "CSR": 0.6102941176470589, "EFR": 0.967741935483871, "Overall": 0.7890180265654649}, {"timecode": 17, "before_eval_results": {"predictions": ["relatively equal distributions of wealth", "in hospitals", "questions and answers in the catechism", "Genesis", "Captain Francis Fowke,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Illinois Reform Commission", "\"Mad Men\"", "London Health Sciences Centre", "$50 less,", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked,", "guerrillas", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Gary Brooker", "peppermint oil was found to be the most effective of the three therapies,", "Helmand province", "forcibly injecting them with psychotropic drugs", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April.", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "UNHCR", "how health care can affect families.\"", "Appathurai", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "Lashkar-e-Tayyiba (LeT)", "Friday,", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "hid his money", "without the restrictions congressional Democrats vowed to put into place", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Jokai crater", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "a number plus", "rice", "Halifax"], "metric_results": {"EM": 0.515625, "QA-F1": 0.597743228993229}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.7499999999999999, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6359", "mrqa_squad-validation-2338", "mrqa_squad-validation-2408", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.515625, "CSR": 0.6050347222222222, "EFR": 0.967741935483871, "Overall": 0.7863883288530467}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam movement", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\" Teen Patti\"", "Argentina", "Congress", "28", "Frank Ricci,", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "saying Tuesday the reality he has seen is \"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.\"", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "North Korea", "Al Shabaab may have been plotting an attack timed to coincide with the event,", "fossil was found along with 16 other deposits at the site that paleontologists \"tree-boxed\" along with the surrounding dirt, creating 23 massive crate weighing between 5 and 53 tons that were then lifted out intact.", "Turkey can possibly make the greatest contribution by helping the United States frame the challenges", "because the federal government is asleep at the switch,", "Molotov cocktails, rocks and glass.", "problems with the way Britain implements European Union employment directives.", "Ben Roethlisberger", "Andrew Morris,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China,", "Lindsey Vonn", "in an interview Tuesday on CNN's \"Larry King Live.\"", "prisoners' rights and better conditions for inmates, like Amnesty International.", "Obama could be successful as a black candidate in part because of his \"light-skinned\" appearance and speaking patterns \"with no Negro dialect, unless he wanted to have one.\"", "Brazil", "Saluhallen,", "trying to detonate an explosive device in his underwear", "two people", "40-year-old", "Peshawar", "Casey Anthony,", "Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "a leak in a Dike", "\"Sunny After afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth Tudor", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.5, "QA-F1": 0.641272548284059}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.8571428571428571, 0.8571428571428571, 1.0, 0.0, 0.9696969696969697, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.07692307692307691, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.33333333333333337, 0.9152542372881356, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 0.9090909090909091, 0.2702702702702703, 0.0, 0.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_newsqa-validation-2847", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-11385"], "SR": 0.5, "CSR": 0.5995065789473684, "EFR": 0.96875, "Overall": 0.7841282894736842}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Danny Trevathan", "11", "if he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "Chuck Bass", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell,", "17", "Satsuma, Florida,", "Naples", "Hugo Chavez", "London", "California", "off the front pages for the first time in days.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "overnight passenger boats", "individual pieces.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CBS, CNN, Fox and The Associated Press.", "Flint, Michigan", "patrolling the pavement in protective shoes", "About 100,000 workers", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "too many glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor Air National Guard Base", "GZA, \"Grandmasters\"", "Suffragist", "Canterbury", "Tunisia", "Silver", "Bonnie & Clyde"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6511914803033223}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.10526315789473685, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.8, 1.0, 0.5, 0.28571428571428575, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-3783"], "SR": 0.46875, "CSR": 0.59296875, "EFR": 0.9117647058823529, "Overall": 0.7523667279411765}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "100,000", "they each supported major regional wars known as proxy wars", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "91.9 by 49.2 ft", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956", "1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Yale University", "62", "team", "November 2014", "Gavrilo Princip", "in Christian eschatology", "October 1941", "peace between two entities ( especially between man and God or between two countries", "charbagh", "Cee - Lo", "After Shawn's kidnapping", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour", "three", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "single particle in a plane two coordinates define its location so it has two degrees of freedom", "Mo Farah", "wild animals", "American", "Hoosick,", "CEO of an engineering and construction company", "1.2 million", "the third pig", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6450031433027756}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.3333333333333333, 1.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.9696969696969697, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-6891", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5900297619047619, "EFR": 0.9666666666666667, "Overall": 0.7783482142857143}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "the One Ring to rule them all", "the Washington metropolitan area", "Pure water", "the breast or lower chest of beef or veal", "Sargon II", "Tagalog or English", "The Edwin Smith Papyrus was written around 1600 BC", "From 1976 to 1983", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford", "by the early 3rd century", "in positions Arg15 - Ile16", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "a foreign exchange option", "1957", "1776", "1963", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "In the 1979 -- 80 season", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Julie Gonzalo", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "waterfront home on Chesapeake Bay", "cricket", "the Major General of the Navy", "Marktown, Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "pardoning Richard Nixon", "Ellen DeGeneres", "1961", "American punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5533407513646484}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.28571428571428575, 0.16666666666666666, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.3333333333333333, 1.0, 0.0, 0.5, 0.6666666666666666, 0.08333333333333333, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-3984"], "SR": 0.40625, "CSR": 0.5816761363636364, "EFR": 1.0, "Overall": 0.7908380681818181}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River", "Stanford University", "linebacker", "the Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "President Andrew Johnson", "Hellenism", "Mark Jackson", "Manhattan Island", "American electronic music duo The Chainsmoker and British rock band Coldplay", "an annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "the namesake town of Manchester - by - the - Sea, Massachusetts", "two", "Thomas Jefferson", "Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "Burbank, California", "Portia de Rossi", "2014", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Kirk Douglas as Matt Morgan", "Jodie Foster", "February 27, 2007", "Avi Lake", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side of the tibia", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff", "London", "bloodstream or surrounding tissue", "2005", "the authentic intercalary date, February 29", "1840s", "9.7", "Montgomery", "if he was not named Romeo he would still be handsome and be Juliet's love", "Hotel California", "Queen Elizabeth II", "\u00ef\u00bf\u00bd", "Brendan O'Brien", "2005", "Dan Tyminski", "The 19-year-old woman", "southern port city of Karachi,", "at least nine", "Bassel al-Assad", "the New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6244419064731564}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.33333333333333337, 0.8, 1.0, 1.0, 0.5, 0.18181818181818182, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.4, 0.4444444444444445, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-4410", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.484375, "CSR": 0.5774456521739131, "EFR": 0.8787878787878788, "Overall": 0.728116765480896}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "its many castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Denver linebacker Von Miller", "Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 )", "Thaddeus Rowe Luckinbill", "by the early - to - mid fourth century", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd ( born October 22, 1938 )", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager, who in December 1986 had piloted the first aircraft to fly around the world without stopping or refueling", "heart sounds, often described as a lub and a dub ( or dup ), that occur in sequence with each heartbeat", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "1922 to 1991", "Terry O'Neill", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "either two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "the `` 0 '' trunk code", "April 1, 2016", "investment bank Friedman Billings Ramsey", "New York City", "cutting surfaces", "Massachusetts Compromise", "Justin Timberlake", "the forces of Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid", "In 1871 A.D. Pt. Buddhiballav Pant", "eyes", "The History Boys", "salted, non-fertilized eggs (roe)", "the White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers. A staff sergeant in the U.S. Air Force,", "Osama", "Antarctica", "the spinal cord", "enoki"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6174435533002467}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 0.13333333333333333, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.17391304347826084, 0.07999999999999999, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.21052631578947367, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_squad-validation-8990", "mrqa_squad-validation-44", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.4375, "CSR": 0.5716145833333333, "EFR": 0.9722222222222222, "Overall": 0.7719184027777777}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "1996", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "Radio City Music Hall", "Charles Whitman", "C. H. Greenblatt", "\"The Social Network\"", "A55", "Corendon", "86", "Minneapolis", "the village of Dornie", "Fatih Ozmen", "U.S.", "Pacific Place", "senior staffers", "the Donny & Marie Showroom, at the Flamingo Las Vegas", "City of Westminster", "2016", "Wildhorn", "New York University School of Law", "Original Crip Homies", "Harper's Bazaar", "dementia", "Ferrara", "Operation Watchtower", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Lee Alexander", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "Lucky", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "The Tenth Planet ( 1966 )", "the Stig", "Jehan Mubarak", "Medellin", "Joe Jackson", "alternative-energy vehicles", "2004.", "genes", "olive", "Stockholm"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6864297161172161}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.30769230769230765, 0.8571428571428571, 0.4, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-5516", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.5625, "CSR": 0.57125, "EFR": 0.9642857142857143, "Overall": 0.7677678571428572}, {"timecode": 25, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "the Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Leigh Lambert", "Shenandoah National Park", "BBC Formula One coverage", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders", "PBS stations nationwide,", "second largest", "tricarboxylic acid", "in 1911", "Johnnie Ray", "\"The Five\"", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedo boats", "1972", "Geographical Indication tag", "Buck Owens and the Buckaroos", "Cleveland Cavalers", "World Championship Wrestling", "1994", "TD Garden", "Chechen Republic", "Chrysler", "Princeton University", "in 2005", "Tenochtitlan", "Tax Reform Act of 1986", "Lou Gehrig", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "mikeana Buddhism", "\"Death, be not\"", "green"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6787326388888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.8, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.578125, "CSR": 0.5715144230769231, "EFR": 0.9259259259259259, "Overall": 0.7487201745014245}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Anthony Mackie", "late eighteenth century", "\"The Snowman\"", "1979", "Premier League club", "port city of Aden", "British", "second cousin", "1985", "Archie Andrews", "before", "1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "Mazatl\u00e1n", "racehorse breeder and owner", "Las Vegas", "1919", "Jon Bernthal", "\"Love Streams\"", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "New Executive Office Building", "6,396", "on the Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Ewan McGregor", "1963", "a peplos", "Car", "A Nutshell", "361", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Singapore", "postcards"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6199662316849817}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-5102", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-3515"], "SR": 0.53125, "CSR": 0.5700231481481481, "EFR": 1.0, "Overall": 0.7850115740740741}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "WWE 2K18", "Kolkata", "\"Dumb and Dumber\"", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "British Overseas Territories", "most awarded female act of all-time", "Sumitomo Rubber Industries", "Bonkile", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "\"The Merchant of Venice\"", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Jaimeister", "Kalokuokamaile", "his father", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Jim Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "American", "Wildhorn, Bricusse and Cuden", "Hotch Kiss M1914", "James Brolin", "Prussian statesman", "January 2004", "Michael Stipe", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "c clef", "nasal polyps", "Warp Drive"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5789995822890559}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3776", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.515625, "CSR": 0.5680803571428572, "EFR": 1.0, "Overall": 0.7840401785714286}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Hanover", "Henry Mancini", "altaic", "Gordon Ramsay", "Gorbachev", "an Air Force disc jockey who'sbeen flown in from another assignment to a post at the center of the escalating conflict in Vietnam.", "secretly", "Charlton Heston", "Anna (Julia Roberts)", "a scythe", "balsam fir", "Paddy Doherty", "spotted", "the wonders of the World", "Libya", "Yeehaw", "bia 515", "Iraq", "Who\u2019s Who", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "a father figure", "April", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "a tomboy in nature,", "David Beckham", "Manhattan", "Marc Norman", "The Greatest", "singer and performer", "in England", "a habanero", "piano", "Tacoma", "Penrhyn Castle", "Cardiff", "Baton Rouge", "a pair", "Tahrir Square", "Romanian", "the \"useful life period\"", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "Meerkat", "Greek", "Passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "June 4, 1931", "North America", "Florida's Everglades.", "Trisha Yearwood", "glamorous, sexy and international.", "How I Learned to Drive", "a set of steak knives", "shark"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4904885912698413}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.28571428571428575, 0.39999999999999997, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-4432", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-3909", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-12186"], "SR": 0.40625, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Kyrie Irving", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "negotiates treaties with foreign nations", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "retina", "japan fears", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "Charles Frederickson ( Nick Sager )", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "1960", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Anna Faris", "1995", "i want to be with you everywhere", "improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Dusty", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century.", "January 2, 1971", "The Miracles", "a domain ( Latin : regio ), also superkingdom or empire,", "arm", "jimmy borley", "Charlie Sheen", "\"Twice in a Lifetime\"", "Nineteen Eighty-Four", "Bardot", "teenager", "Long Island convenience store", "Romney", "Peter", "heart disease", "bronchitis"], "metric_results": {"EM": 0.5, "QA-F1": 0.5886979166666666}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.56, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.5, "CSR": 0.5604166666666667, "EFR": 0.96875, "Overall": 0.7645833333333334}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "corey", "Spanish Republic", "taximeter", "jaguar", "kurie vykdo bet kokio pobdio ekonomin veikl.", "Harry Reid", "Ray", "axis", "forge", "boxing", "madam lebret", "flowers", "Blackbird", "Footprints", "Caliban", "Royal Vale", "federal", "Tommy Lee Jones", "zacchaeus", "The Memory Keeper's daughter", "(1876)", "hubris", "Yahtzee", "Tony Danza", "markup language", "hives", "74.3", "William S. Hart", "(Every son that is born ye shall cast into the river)", "Pride and Prejudice", "greeK ALPHABET", "kosher wine", "Munich", "Michael Jordan", "Candlemas", "(St.) W. iv. 2. 49", "Hikaru Sulu", "tropical rainforests", "dough", "kyushu", "honey", "Boston", "toy company", "Arctic Ocean", "the new Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1911", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "adidas", "anti-trust laws."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6067708333333334}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-3963", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391"], "SR": 0.546875, "CSR": 0.5599798387096775, "EFR": 0.9655172413793104, "Overall": 0.762748540044494}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "June 26, 1970", "Bloomingdale Firehouse", "elise Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack County", "Gust Avrakotos", "\"The Late Late Show\"", "Mark Anthony", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland County", "\"Slaughterhouse-Five\"", "Shohola Falls", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "The Highwaymen", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Isabella Palmieri", "Hathi Jr.", "1935", "geryon", "slow", "\"Cruisin'\"", "the Rockies", "AMD", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7511618589743589}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2268", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.671875, "CSR": 0.5634765625, "EFR": 1.0, "Overall": 0.78173828125}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 6", "jellyfish", "March", "clogs", "Mickey Mouse", "the World Health Organization", "won the most Oscars Walt Disney", "Kofi Annan", "carbon dioxide", "the right to print was strictly controlled in England", "Taggart", "Solo", "the Gulf of Mexico", "Manfred Mann", "Sven Goran Eriksson", "Barry Taylor", "Route 66", "Brussels", "Flora MacDonald", "John Poulson", "Charles de Gaulle", "the Treaty on European Union", "Jack \"Jack\" Frost", "Saskatchewan (Province)", "Laurent Planchon", "the Solent", "vomiting", "Basketball Page 30", "Bristol Aeroplane Company", "Spinach", "Tony Meo", "\u201cArgo\u201d", "Gemini", "Surrey", "1969", "chippenham", "Budapest", "The Coquimbo", "William Shakespeare", "borax", "interconnects the cities, towns and suburbs of the Ruhr", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units", "Miller Brewing", "northwestern Italian coast", "Melbourne", "the earthquake", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "collared dove", "Germany"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5358245920745921}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-7050", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.46875, "CSR": 0.5606060606060606, "EFR": 0.9117647058823529, "Overall": 0.7361853832442067}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "The National Football Conference ( NFC ) champion Philadelphia Eagles", "Doc '' Brown, Ph. D.", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline", "Jesus'birth", "a habitat", "irsten Simone Vangsness", "Central Germany", "Andrew Johnson", "Bart Cummings", "Menelaus", "electors", "Julia Ormond", "Sauron", "1961", "Aaron Lewis", "2013", "`` leapling '', a `` leaper '', or a `` leap - year baby ''", "novelization", "a usually red oxide formed by the redox reaction of iron and oxygen in the presence of water or air moisture", "Spain", "Taylor Hayes", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "paid monument", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "16", "the Ramones", "completed in 1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "New Jersey", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "singer and a DJ", "cricket fighting", "Luis Resto", "drama that pulls in the crowds", "German death camp", "Islamabad", "Tunisia", "RAND Corporation", "alberta"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5501025007816179}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 0.4444444444444445, 0.5, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.4, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-8963", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.453125, "CSR": 0.5574448529411764, "EFR": 0.9714285714285714, "Overall": 0.7644367121848739}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "the Finch family's African - American housekeeper", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission", "Universal Pictures", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets and beloved religious leaders", "state legislators of Assam", "digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility", "Lenny Jacobson", "temperature at which the phase transition occurs", "`` mind your manners ''", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "Sunday, 2 September to Wednesday, 5 September 1666", "California State Route 1", "The management team", "in various submucosal membrane sites", "enabled business applications to be developed with Flash", "Steveston Outdoor pool", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "If the car is slowed initially by manual use of the automatic gear box", "early Christians of Mesopotamia", "Tennesseeitans", "lowest air temperature record", "a cliffhanger showing the first few moments of Sam's next leap", "on a bronze plaque and mounted inside the pedestal's lower level", "Cheerios", "munyon", "Brian Close", "future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "Olympic medal", "Henry Ford", "Toyota", "Abraham Lincoln", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread"], "metric_results": {"EM": 0.4375, "QA-F1": 0.583500744047619}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.3333333333333333, 0.19999999999999998, 0.888888888888889, 1.0, 0.8, 0.0, 0.0, 0.375, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3571428571428571, 0.761904761904762, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.4375, "CSR": 0.5540178571428571, "EFR": 0.9444444444444444, "Overall": 0.7492311507936508}, {"timecode": 35, "before_eval_results": {"predictions": ["repressing those domestic Islamists who attacked it", "mild euphoric", "James McConkey", "Venezuela", "Croatia", "ring magazine", "Peter Pan", "del Sarto", "Arctic Ocean", "egg in front of the opening, so the egg is sucked in by the differential in this between the inside & outside of the bottle", "dams", "Lafayette", "Elijah Muhammad", "a period of depression or unhappy listlessness.", "Village People", "Alexander Pushkin", "Australia", "Munich", "puebla", "working the 9 to 5 schedule is outdated and ineffective to", "the papacy", "the Delta Is.....", "a typical day", "Pierre-August Renoir", "l'una", "Les Huguenots", "Innsbruck", "Charles Keating Jr.", "Microsoft", "asparagus Fern", "the Trump Organization", "vikings", "Atlantic City", "Blackwater USA", "elephant", "American Airlines", "ibex", "Odysseus", "Geronimo", "Kensington Palace", "butch Cassidy", "Nassau", "Pocahontas", "the Lion, the Witch, and the Wardrobe", "Dagny Taggart", "chalkboard scrape", "the CME", "Las Vegas", "danskin are not just for dancing", "wheat", "Pablo Casals", "an ostrich or common ostrich (Struthio camelus)", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "Senate Democrats", "63", "\"perezagruzka,\" which means 'overcharged.'\""], "metric_results": {"EM": 0.4375, "QA-F1": 0.5606646825396826}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-16363", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-13449", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.4375, "CSR": 0.55078125, "EFR": 0.9722222222222222, "Overall": 0.7615017361111112}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "between 2 World Trade center and 3 World Trade Center", "``", "Santa Monica", "a stepping stone in the development of the modern state system", "Will", "31 January 1934", "Filipino", "1773", "random - access memory", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Raghu", "Olivia Olson", "1990", "Nickelback", "Bill Pullman", "BC Jean", "never made", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "the retinal ganglion cells of one retina", "the 1980s", "in soils", "card verification value ( CVV )", "`` rebuke with all authority ''", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle ''", "Mike Czerwien", "103", "Vienna", "English", "Australia", "Stalin", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Dennis Haysbert", "Quinn", "Towcester"], "metric_results": {"EM": 0.609375, "QA-F1": 0.715366838023088}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.888888888888889, 0.0, 1.0, 1.0, 0.9523809523809523, 0.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.09523809523809523, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2833", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161"], "SR": 0.609375, "CSR": 0.5523648648648649, "EFR": 0.88, "Overall": 0.7161824324324324}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "\u201cShine,\u201d", "a cappella", "albinism", "Henry Hunt", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "The Today Show", "English", "copper", "Dawn French", "David Bowie's", "M\u00fcnchen", "Doris Lessing", "Scooby-Doo", "Swaziland", "the elephant House at London Zoo", "Kent", "the Humber", "points based scoring system", "automobile", "Kent", "Rodgers & Hammerstein", "Boy George", "Galileo Galilei", "Zelle", "Scotland Yard", "Marilyn Manson", "Medellin", "The Tempest", "spark-ignition", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Iraq", "Belle de Jour", "Morecambe", "Abba", "a geologic episode, change, process, deposit, or feature that is the result of the action or effects of rain", "white", "Asaph Hall", "France", "Snowbell", "kunsky- Trendle", "psychology, sociology, anthropology, religious studies, medicine and forensic science", "David Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "Washington.", "heavy turbulence", "different women coping with breast cancer in", "&quot;", "a flower that a child can draw on a slate, a woman can work in silk,", "Madonna's", "March 24"], "metric_results": {"EM": 0.5, "QA-F1": 0.5435732546607159}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291", "mrqa_searchqa-validation-7454"], "SR": 0.5, "CSR": 0.5509868421052632, "EFR": 0.96875, "Overall": 0.7598684210526316}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "the liver", "40", "table salt", "mischievous comedy", "cuba", "bak house", "denny Redmond", "davis", "a head", "hound", "hanover", "a sun", "king Charles I", "work", "scales", "Dirty Dancing", "vengeance", "diana Ross", "Montezuma", "a 1934 Austin seven box saloon", "Paul Anka", "b Carthage", "hanpool", "William Shakespeare", "Blade Runner", "Jay-Z", "leopard", "cymbals", "\u201cSanta Buddies\u201d", "La traviata", "norman tebbit", "fidelio", "South Africa", "Christian dior", "scrobbesbyrig", "killer whale", "krybera", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "a b Baron", "lizard", "bridge", "frauds", "a sea monster", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Lynn", "piano", "\"It didn't matter if you were 60, 40 or 20 like I am.", "sweden", "French Guiana", "cuba", "a second son", "Tiger Woods"], "metric_results": {"EM": 0.5, "QA-F1": 0.5766369047619048}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-1254", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.5, "CSR": 0.5496794871794872, "EFR": 0.9375, "Overall": 0.7435897435897436}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Aldi", "Midnight Cowboy", "georgia", "seborrheic dermatitis", "Amanda Barrie", "steam engines", "Cameroon", "central Stockholm", "Tangled", "dogs", "georgia davis", "Bulls Eye", "Napoleon", "Laurent Planchon", "Martin Clunes", "Jane Austen", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "john Mellencamp", "isambard Kingdom Brunel", "georgia", "1957", "Devon", "villefranche", "white wine", "micelles", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "Shanghai", "Spain", "grows", "Tuesday", "Guru Nanak", "bleak house", "Harry Potter", "phosphorus", "Little Jack Horner", "bristol", "dolores haze", "cuckoo", "Miss Marple", "Ford", "Alice Cooper", "Majorca", "hemoglobin", "Bengal tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "Dr. Death in Germany", "forgery and flying without a valid license", "183", "the log cabin", "St. Patrick's Day", "linebacker", "Sondheim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.46279761904761907}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-10", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6153", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-777", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.421875, "CSR": 0.546484375, "EFR": 0.972972972972973, "Overall": 0.7597286739864866}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "washington", "Thomas de Quincey", "the black death", "horse", "buffalo", "indian queen Cleopatra", "a raven", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "voltage drop", "the Arabian Gulf", "secretary", "charles", "matricide", "jack Nicholson", "\u201cTonight Is Another Day\u201d", "diesel", "Tomorrow Never Dies", "Sudan", "a Great Dane", "indianapolis", "indian", "New Hampshire", "James I", "Hazell", "the Philippines", "purple rain", "everyHit.com", "warblers", "Hell Upside Down", "Venice", "9", "Southwest Airlines", "a boy", "Jeffery deaver", "The Comedy of Errors", "charlie", "glyn Jones", "President Richard Nixon", "abonologists", "epeiric (or \"shelf\") sea", "radicalization", "rodinsons", "Kitty Softpaws", "1998", "Tanvi Shah", "EN World web site", "the 100th anniversary of the first \"Tour de France\" bicycle race", "the Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "boy Buddha", "grunge", "nibelung", "inequality of opportunity was found in the Balkans and Central Asia"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5228365384615385}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.4375, "CSR": 0.5438262195121951, "EFR": 0.9444444444444444, "Overall": 0.7441353319783197}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "rhea", "nippon Sangyo", "golden fleece", "Roddy doddy dixon", "a counting table", "Robin Hood", "aeolus", "Velazquez", "South African", "nuevo Circo", "oregon", "tchaikovsky", "Mortimer Lightwood", "Scotland", "Punch", "David Bowie", "Buzz Aldrin", "jordan paul sartre", "jordan", "dicks turpin", "rust", "jane krakowski", "wales", "tbilisi", "Mel Gibson", "othello", "a hole", "Glenn Close", "Lacock Abbey", "alex b'Stard", "domestic cat", "anita Brookner", "jerry vii", "bunned grandmother", "the Black Sea", "bagram", "Susie Dent", "a power surge", "Vienna", "The Archers", "Shylock", "John Philip sousa", "chicago", "jimmy boyard", "shakespears Sister", "The Six Mascots", "tyne", "habsburg Monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "from 1993 to 1996", "Denzel Washington and John Travolta", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones", "darino", "doc Holliday", "a cake", "alexa"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5334155701754386}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-14680", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.484375, "CSR": 0.5424107142857143, "EFR": 0.9696969696969697, "Overall": 0.7560538419913421}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics", "a shortfall in their pension fund", "Borussia Dortmund", "Ivory Coast", "revolution of values", "Jeddah, Saudi Arabia", "40", "chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "27,", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "Marty Abrams", "Michoacan Family", "64", "in her home", "fastest circumnavigation of the globe in a powerboat", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007 and has been coaching at Independiente.", "E! News", "Florida", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace.", "an ice jam", "toxic smoke from burn pits", "zulfikar Ali Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "Cal Ripken Jr.", "his relative's house", "cancer", "Majid Movahedi", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning", "recycles 100% of its byproducts which supplies 80% of the operation energy at the plant.", "about 5:20 p.m.", "Former Mobile County Circuit Judge Herman Thomas", "we say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "a man's lifeless, naked body", "\"release\" civilians", "Dodi Fayed", "the shipping industry", "when a population temporarily exceeds the long term carrying capacity of its environment", "Barcelona", "emperor Cuauhtemoc", "nissan", "Misery", "charles purdy", "Italo Balbo", "Thorgan", "River Clyde", "chile", "jimmy johnson", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.390625, "QA-F1": 0.48165268656996596}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.8000000000000002, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.4444444444444445, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 0.0, 0.6, 0.14545454545454548, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-5597", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.390625, "CSR": 0.5388808139534884, "EFR": 0.9743589743589743, "Overall": 0.7566198941562314}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.,", "1943", "Volvo 850", "the Mountain West Conference", "the Atlanta Hawks", "Western Europe", "movie scripts", "Continental AG", "the Championship", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood", "Emmanuel Ofosu Yeboah", "Attack the Block", "Bhushan Patel", "1986", "1964", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "Lynyrd Skynyrd", "2008\u201309", "coaxial", "Northern Lights", "three different covers", "Malayalam", "Regno di Dalmazia", "August 11, 1946", "Vincent Landay", "(born September 6, 1967)", "Estadio de L\u00f3pez Cort\u00e1zar", "Nickelodeon Animation Studio", "Nicolas Vanier", "1985", "Gal Gadot", "Meghan Markle", "Texas Raiders", "Bremen, Germany", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "trademark", "blue", "elbow", "Citizens", "Employee Free Choice act", "the release of the four men", "a rake", "jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6955754164313948}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_newsqa-validation-2070"], "SR": 0.640625, "CSR": 0.5411931818181819, "EFR": 1.0, "Overall": 0.7705965909090909}, {"timecode": 44, "before_eval_results": {"predictions": ["British Prime Minister Edward Heath", "Sean Yseult", "Washington, D.C.", "5.3 million", "sexy Star", "Conservatorio Verdi in Milan", "vice president", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Andrew Joseph \" Andy\" Cohen", "Danish national ice hockey team", "January 11, 2016", "Margarine Unie", "death sentence", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer Guitars", "the Dominican Republic", "Humberside Airport", "2017 Major League Baseball draft", "Douglas Jackson", "wooden", "Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona community", "Boston Celtics", "Austrian", "The Division of Fawkner", "50 Cent", "American singer Toni Braxton", "Hindi", "Richard Masur", "Brian Patrick Friel", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Centers for Medicare and Medicaid Services (CMS)", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Elgar\u2019s", "last summer", "almost 100", "into the Southeast,", "the jeffersons tv show", "a stick to fish the filemot frith for treasures", "by... what differed for women was the status of their authority in the wider community.", "One Direction"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7284855769230769}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.609375, "CSR": 0.5427083333333333, "EFR": 0.84, "Overall": 0.6913541666666667}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "quod erat demonstrandum", "Elizabeth II", "the Belgae", "Dr. Joel Fleischman", "a pale-yellow, edible vegetable fat", "Kokomo", "Esther", "Warren Harding", "Monte Halparin", "mini golf", "CNN's", "Punxsutawney, Pennsylvania", "pozsony", "yellow fever", "sea otters", "the 13th letter of the alphabet", "a submarine sandwich", "rod", "and illegal wiretapping", "horse training", "astronomer", "Mickey Mouse", "a bud", "Associate Professor", "the Foot", "Medusa", "a staircase", "tabby", "the staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Sparta", "Vegetarianism", "peace sign", "Morrie Schwartz", "English Monarchs These 2", "Rajasthan", "sexy Beast", "a true salt fountain", "NHL", "a samt ar-rs road", "How shall he cut it", "scheduled meeting", "Wordsworth", "brushes", "a planet nor a natural satellite", "a wish", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "New York City", "Isle of Wight", "a Peppercorn class A1", "Queen In-hyun's Man", "Oneida Limited", "Michael Jordan", "Libreville, Gabon", "tickets", "the station", "tuscaloosa"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4942708333333333}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-9878", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7347", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.40625, "CSR": 0.5397418478260869, "EFR": 0.9736842105263158, "Overall": 0.7567130291762014}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\" to which they were entitled institutionally and legally,", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "winston", "faggot", "gander", "California Chrome", "Pluto", "Route 66", "the Altay", "Sindh\u016b", "Movie", "the Great Victoria Desert", "German state of North Rhine-Westphalia", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield in North East England", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "tank museum", "South Korea", "pigs", "definitely, maybe", "Holzi194", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "second", "the Susquehanna River", "Argentina", "Darth Vader", "Frankfurt", "chipmunk", "Goldie Hawn", "pulsar", "Belgium", "horses", "liqueurs", "Benfica", "Sun Lust Pictures", "Games played", "making Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "Twilight", "the Carrousel du Louvre", "Speed Racer", "a novel", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.578125, "QA-F1": 0.629092261904762}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true], "QA-F1": [0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-3654", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.578125, "CSR": 0.5405585106382979, "EFR": 1.0, "Overall": 0.7702792553191489}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Venice", "Sinclair Lewis", "Patrick Newell", "Renard", "egg tempera", "Scott Glenn", "v\u00e1clav Havel", "Dick Van Dyke", "the Pre-R Raphaelite Brotherhood", "Tina Turner", "2010", "lough", "glasses", "perfume", "Duke Orsino", "iron", "Copenhagen", "The Apprentice", "waterline", "Cubism", "sahara desert", "the Advisory Council of Science and Industrial Research", "eucharistia", "Charlotte's Web", "James Bond", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "Call My Bluff", "a", "chile", "Frank McCourt", "oats", "Caroline Aherne", "LDV", "starch", "Pears soap", "Donna Summer", "Pillar", "nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "a police janitor", "a-teamautos", "football", "801,200", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "Speedway World Championship", "beautiful", "Eleven", "Michelle Obama", "kbenhavn", "Communist Manifesto", "SARA", "fluoroquinolone"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5907816142191142}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-6892", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_newsqa-validation-1804"], "SR": 0.546875, "CSR": 0.5406901041666667, "EFR": 1.0, "Overall": 0.7703450520833334}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "\u00c6thelred the Unready", "creatures Comforts", "British Airways", "William McKinley", "1905", "Vanilla Air", "Mineola", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "mash-Up", "argentina", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "177026 March 1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Edward James Olmos", "Bury St Edmunds, Suffolk, England", "Prussian", "o", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers", "924", "381.6 days", "North Carolina", "Selinsgrove", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "space shuttle", "basil", "clio Awards", "The Rosie Show", "California-based Current TV", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Julius Caesar", "lava field", "the Library of Congress", "thylakoid membranes"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6734827898550725}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-3680", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.578125, "CSR": 0.5414540816326531, "EFR": 0.9629629629629629, "Overall": 0.752208522297808}, {"timecode": 49, "before_eval_results": {"predictions": ["baseball, oin\u0103, ( Italy) and pes\u00e4pallo", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "Talib Kweli", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Erdman Berry", "Love Hina", "eastern India", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "Albert Ball", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "the New York-New Jersey Highlands", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "international following", "Royce da 5'9\" (Bad) and Eminem (Evil)", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "Kj\u00f8benhavns Boldklub", "Robert Jenrick", "Golden Globe Awards", "Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "Edward Elgar", "republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "Lt Presley O'Bannon", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6680431547619048}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-173", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-1476", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.5625, "CSR": 0.541875, "EFR": 1.0, "Overall": 0.7709375}, {"timecode": 50, "UKR": 0.716796875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.80859375, "KG": 0.48046875, "before_eval_results": {"predictions": ["Disha Patani", "Eardwulf", "Fife, Scotland", "about 26,000", "Spain, Mexico and France", "1981", "geons & Dragons", "February 26, 1948", "Albert Lee Ueltschi", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "Epic Records", "IFFHS World's Best Goalkeeper", "Muggsy Bogues", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931 \u2013 May 31, 2016", "Scrappy", "Picric acid", "Las Vegas", "CBS's", "pioneering New Zealand food writer", "fantasy role-playing game", "feats of exploration", "Dolly Records", "Bergen County", "Matthieu Vaxivi\u00e8re", "Newcastle United's Cheick Tiot\u00e9", "Monica Seles", "Harvey Birdman", "Biloxi", "New York Yankees", "1903", "Charles Hastings Judd", "Mark \"Chopper\" Read", "ethereal darkwave", "VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer Bears", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "The Games are expected to take place between 27 July and 7 August 2022", "1800", "season seven", "glycerol", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "intestines", "Ben Kingsley", "1.2 million", "84-year-old", "Jacob's", "corroboration", "Matt Damon", "Mitch Murray"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5964657738095238}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.25, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.8571428571428571, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.14285714285714288, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770"], "SR": 0.453125, "CSR": 0.5401348039215687, "EFR": 0.9428571428571428, "Overall": 0.6977702643557423}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County, New York", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia and New Zealand", "Richard Price", "1942", "water sprite", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "General Edward Lawrence Logan International Airport", "Blackpool Football Club", "Fenris", "100 million", "James Gregory", "Volvo S70", "1978", "July 25 to August 4", "Sela Ann Ward", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom", "Oracle Corporation", "Paris", "John Andr\u00e9", "Three-card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Morozov", "their evocative music on indigenous flutes, panpipes and drums, as well as stringed instruments", "The Dragon", "two", "Outside", "Traumnovelle", "the Chechen Republic", "actress and model", "The 1995\u201396 season", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover", "Citgo", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee,", "Presley Smith", "the hydrological cycle or the hydrologic cycle", "Edward Bowdich", "Jet Harris", "Melissa Duck", "in a tenement in the Mumbai suburb of Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.\"", "the Dalai Lama's current \"middle way approach,\"", "Popular Science", "longton", "Latter-day Saints", "They were growing more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.5, "QA-F1": 0.6490162181568431}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.5, 0.4, 0.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3333333333333333, 0.1904761904761905, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.5, 1.0, 0.125, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-185", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_searchqa-validation-5108", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.5, "CSR": 0.5393629807692308, "EFR": 1.0, "Overall": 0.7090444711538462}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Bandai", "St Augustine's Abbey", "The Washington Post", "Shusett", "Dizzy Dean", "UHF channel 44", "North Kesteven", "West African", "The Beatles", "\"Menace II Society\"", "September", "March 30, 2025", "the Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Easy", "CBS", "Brickyard", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter, Paul and Mary", "Kathleen O'Brien", "Blackstone", "on the north bank of the North Esk", "Paris Charles de Gaulle Airport", "Hard rock", "Sunye and Sohee", "Ecko Unlimited", "Muhammad Ali", "the University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "Sister, Sister", "David Dunn", "William Bradford", "FieldTurf", "his fifth", "Benj Pasek and Justin Paul", "a hand injury", "Freedom Day", "Johnny Cash", "the pulmonary arteries", "Pope Benedict XVI", "France", "Taekwondo", "She is the Magneto to my Wolverine, the Saruman to my Frodo, the Dr. Octopus to my Spiderman.", "since 1983", "the legitimacy of that race.", "the Duke of Norfolk", "Italy", "chile pepper", "a star"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6507316468253967}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-3459", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5343", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2925", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.515625, "CSR": 0.5389150943396226, "EFR": 1.0, "Overall": 0.7089548938679245}, {"timecode": 53, "before_eval_results": {"predictions": ["a jedoublen/jeopardy", "Friedrich Nietzsche", "give up the ship", "Carnarvon", "Ireland", "Glaciers", "white", "Marie-Antoinette", "Aunt Bee", "Great Smoky Mountains National Park", "grasshopper", "Ohiopyle State Park", "Nostradamus", "Hodgkin's lymphoma", "The Flying Dutchman", "white", "josefellow", "The Crow", "the plain of Attica", "John Keats", "Scott", "a backpacking route", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Dostoevsky", "Mike Rowe", "Resident Evil", "Daughter", "July 14th", "the United Arab Emirates", "Dramamine", "K.C. Fields", "a parade", "the Negro", "hortense de Beauharnais", "Theodore Roosevelt", "Staten Island", "Transformers: Earth Wars", "Crystal Light", "the Yankees", "Answer", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "an ear", "Indira Gandhi", "a rotating radar dome", "the Director of National Intelligence", "the graft fuses the two vertebrae together", "2018", "Rubenshuis", "weasel", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license", "Michoacan state,", "should have met with the Dalai Lama", "Carpenter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.62734375}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.25000000000000006, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-16117", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-12841", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-3486"], "SR": 0.546875, "CSR": 0.5390625, "EFR": 1.0, "Overall": 0.708984375}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "162-W-1", "Phil Sedgmen", "peter cammarelle", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "armoured", "Adrian", "Denmark", "the Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "YouTube", "$SPX", "Mrs Merton", "blues", "Compare carRent", "Brazil", "baloney", "peter crouch", "Michael Faraday", "George W. Bush", "a small fox terrier", "haddock", "June & June", "Tim Peake", "Phil Redmond", "tamales", "Argentina", "St Moritz", "Good Neighbors", "Woody's horse", "Penelope Keith", "Sinclair Lewis", "deer", "puzach", "Barry White", "Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "`` Fix You ''", "`` Killer Within ''", "during prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "The Worm", "\"The Golden Girls.\"", "\"the most dangerous precedent in this country, violating all of our due process rights.\"", "sex scandal", "Easy Rawlins", "President William McKinley", "The Bee", "Knigsberg"], "metric_results": {"EM": 0.515625, "QA-F1": 0.588858695652174}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.08695652173913043, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-6992", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-3131", "mrqa_naturalquestions-validation-2440", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-1750", "mrqa_searchqa-validation-12187", "mrqa_searchqa-validation-14797"], "SR": 0.515625, "CSR": 0.5386363636363636, "EFR": 0.9354838709677419, "Overall": 0.6959959219208212}, {"timecode": 55, "before_eval_results": {"predictions": ["ensure that detainees are not drugged unless there is a medical reason to do so.", "the man was dead", "Larry King", "a vigilante group whose goal is the eradication of the Zetas", "customers", "the United States", "in Iraq", "work at the Iranian consulate", "parachuted to the ground", "documents", "Matthew Chance", "rapid growth", "Bright Automotive", "NASCAR", "Clifford Harris", "a Muslim background", "Copts", "adult reality show", "chandni Chowk Goes to China.", "Tens of thousands of new voters", "urged NATO to take a more active role in countering the spread of the", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament", "Bill Clinton", "Iran", "Daniel Radcliffe", "\"deeply intimate portrait will provide viewers with a raw and honest look inside a musical dynasty.\"", "Ronald Reagan UCLA Medical Center", "hanged in 1979", "Sixteen", "remains unknown,", "dogs who walk on ice in Alaska.", "an impromptu memorial for the late singer", "Naturalist Charles Darwin", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy", "this is not a project for commercial gain.", "Gustav's top winds", "Rwanda", "twice", "Bob Johnson", "the idea that the Richmond students did nothing because of the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "Confederate forces", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Thom Yorke", "Charlie Sheen", "engraver", "Francis Keogh Gleason", "the \"First Family of Competitive eating\"", "Valley Falls", "the linen queen", "Mount Kosciuszko", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6230654761904761}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true], "QA-F1": [0.6, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.4, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-566", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_triviaqa-validation-7529", "mrqa_searchqa-validation-1388", "mrqa_searchqa-validation-12033"], "SR": 0.53125, "CSR": 0.5385044642857143, "EFR": 0.9333333333333333, "Overall": 0.6955394345238095}, {"timecode": 56, "before_eval_results": {"predictions": ["the B-52 Stratofortress", "peso", "Nucleus", "steroids", "Starship Troopers", "Stalin", "the Ogallala aquifer", "conception", "the reticulated python", "William Proxmire", "George Orwell", "Takana", "wood", "Coach Carter", "Brachiosaurus", "a giant leap", "Psycho", "a believer", "Athens", "Extreme", "zoo", "Have You Neverbeen Mellow", "Mickey Gilley", "Oral Roberts", "the staff", "the Hippodrome", "Tin", "Ganges", "The mysterious Island", "Dave Brubeck", "She Wore a Yellow Ribbon", "Stevie Wonder", "Danville, Virginia", "Jupiter", "spiders", "Apple", "depression", "the Mausoleum", "Act One", "the Star of Bombay", "Rhapsody in Blue", "the Ziegfeld Girl", "Sunshine Moonshine", "Ronald Reagan", "Mount Kilimanjaro", "militia", "Delaware", "Graceland Mansion", "the Mikoyan MiG-31", "Don Corleone", "the oral stage (first year of life), the anus stage ( second year)", "President John F. Kennedy", "Siddharth Arora / Vibhav Roy", "in the pouring rain at a rest stop", "Munich", "Central London Railway", "1123", "Julie Kavner", "Benedict of Nursia", "A Boltzmann machine", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5479166666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-4802", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-11485", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-5209", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-1463", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658"], "SR": 0.46875, "CSR": 0.5372807017543859, "EFR": 0.9411764705882353, "Overall": 0.6968633094685243}, {"timecode": 57, "before_eval_results": {"predictions": ["Russia", "bamboo", "Merlin", "sculpture", "Alien", "Live Large", "mariachi", "Drake", "excruciating", "Kilimanjaro", "an opinion", "the Godfather", "forgiveness", "Catholic", "Paris", "Twenty", "New York", "a tortoise", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "mohs", "Katharine McPhee", "Henry Ford", "Prince", "(Cnut)", "spiral", "George Stephanopoulos", "egg", "(Vijay) Singh", "geometric", "Baton Rouge", "Daniel Boone", "Chariots of Fire", "a newt", "Sweden", "incense", "an eyelid", "Hong Kong", "The Addams Family", "viruses", "Sanders", "Bait-and-switch", "Winston Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Zelah Clarke", "University of Oxford", "1,467", "Vision of Love", "allegations of abuse", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6869791666666666}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15237", "mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-2637", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-7113", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-12380", "mrqa_searchqa-validation-5688", "mrqa_triviaqa-validation-7432", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.609375, "CSR": 0.5385237068965517, "EFR": 0.96, "Overall": 0.7008766163793103}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "room for an owners suite and six further double-king sized suites", "pulling Turkey into any kind of engagement with the Taliban", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs", "\"I tried to treat Jackson's insomnia with natural remedies testified that Jackson told her that doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school in South Africa", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "Akio Toyoda", "ancient rituals", "a man's lifeless, naked body", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "military trials", "137", "Nirvana", "Patrick McGoohan,", "55-year-old", "Zimbabwe President Robert Mugabe", "new Touch,", "Dr. Maria Siemionow,", "International Polo Club Palm Beach in Florida.", "Mugabe and Tsvangirai", "all three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "a full garden and pool, a tennis court, or several heli-pads", "Turkey can play an important role in Afghanistan as a reliable NATO ally. The question is: How can Turkey best help", "Polo because \"it was the sport of kings.", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "funded by a German company and affiliated with the group Bread for the World", "magazine", "CNN's Campbell Brown", "farmer Alan Graham", "February 12", "Arizona", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "strict interpretations of sharia, a thief is punished by having a hand cut off.", "trading goods and services without exchanging money", "three", "two more countries", "Many of those who haven't bought converters are poor, older than 55, rural residents or racial minorities,", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Fred Bright, the district attorney in Milledgeville,", "Taylor Michel Momsen", "Stefanie Scott", "In late - 2011, she announced plans for a clothing and jewelry line called House of Maryse, and later began working as a realtor", "james Starley", "Zaire", "balsamic vinegar", "DreamWorks Animation", "Debbie Harry", "2004", "a face cord", "Jude Law", "Existentialism", "Nancy Walker"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5368621482683983}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.72, 1.0, 1.0, 0.7272727272727273, 1.0, 0.4, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.8, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 0.0, 0.41666666666666663, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-780", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-659", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_newsqa-validation-2871", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-6426", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.453125, "CSR": 0.5370762711864407, "EFR": 0.9142857142857143, "Overall": 0.6914442720944309}, {"timecode": 59, "before_eval_results": {"predictions": ["Archer,", "Pakistan", "IndyCar Series", "Vernon Kay", "Everglades", "ten episodes", "Tyler Posey", "Maxwell Atoms", "Scandinavian design", "Hugh Hefner", "Benj Pasek and Paul", "Toxics Release Inventory", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "Denver, Colorado", "Edward M. Kennedy", "aircraft", "21st Century Fox", "Pennsylvania's", "Danielle Fernandes Dominique Schuelein- Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "NATO", "was the 8th Nawab of Pataudi", "authoritarian", "AOL Inc.", "World War II", "coca wine", "President Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Golden Globe", "New Jersey", "Ian Rush", "German", "Hawaii", "the youngest TV director ever", "Arthur William Bell III", "Henry J. Kaiser", "Delaware River", "Jean Acker", "InBev", "MG Car Company Limited", "Boston Celtics", "May 2008", "the second", "24 hours later", "Brian Steele", "employment in which a person works a minimum number of hours defined as such by his / her employer", "Ceefax", "Dieppe Raid", "hanover", "the iconic Hollywood headquarters of Capitol Records,", "228", "son of Gabon's former president", "stocks", "Thomas Edison", "Han Solo", "Jeannie Longo-Ciprelli"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6046570616883117}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, true, false, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.6666666666666665, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.25, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.8, 1.0, 0.09090909090909091, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4375", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-4248", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3372", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-5185", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636", "mrqa_newsqa-validation-153"], "SR": 0.484375, "CSR": 0.5361979166666666, "EFR": 0.9696969696969697, "Overall": 0.7023508522727273}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "Rivers", "'overcharged.'\"", "Alison Sweeney,", "the Carrousel du Louvre", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "\"Up\"", "eight Indian army troopers, including one officer, and 17 militants,", "269,000", "flooding was so fast that the thing flipped over,\"", "\"Sesame Street's\" Grover,", "Patrick McGoohan,", "ambassadors", "Afghan security forces", "The Arkansas weatherman", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell,", "\"wider relationship\"", "\"Watchmen\"", "Noida, located in the outskirts of the capital New Delhi.", "in body bags on the roadway near the bus,", "Afghanistan", "10 to 15 percent", "No reason", "Joan Rivers", "an engineering and construction company", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "illegal immigrants", "navy dress", "$86,000 a month,", "Too many glass shards left by beer drinkers in the city center,", "legitimacy of that race.", "Nigeria", "Dr. Christina Romete,", "Hong Kong's Victoria Harbor", "Drottningtorget", "a senior at Stetson University", "tweets", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "gold", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "the Pacemakers", "Khartoum", "Stand by Me", "French"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5285851579294085}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.19047619047619047, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2608695652173913, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1954", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409", "mrqa_hotpotqa-validation-2403"], "SR": 0.453125, "CSR": 0.5348360655737705, "EFR": 0.9428571428571428, "Overall": 0.6967105166861827}, {"timecode": 61, "before_eval_results": {"predictions": ["peanut and milk", "space shuttle", "Santaquin City, Utah, home Sunday", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "Johnny Carson", "Bob Bogle,", "183", "Russia of today.", "two goals in a 4-1 Serie A win at Bologna on Sunday", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon.", "Henry Ford", "two soldiers and two civilians from the Defense and State departments", "Mark Fields", "Luiz Inacio Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "16 Indiana National Guard soldiers", "the body of the aircraft", "Venus Williams", "onto the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "the world's tallest building,", "Canada.", "$7.8 million", "Polo because \"it was the sport of kings.", "Zimbabwe's main opposition party", "United", "surgical anesthetic propofol", "she was humiliated by last month's incident, in which she was forced to grotesque remove the piercings", "CNN", "school,", "Hurricane Gustav", "HPV", "two courses", "outfit from designer", "the two bodies out of the plant,", "second-degree aggravated battery.", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Thailand", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker", "27,", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "emergency aid", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Italy", "Brighton", "eagle", "Umberto II", "The Longest Yard", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7055515619249172}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true], "QA-F1": [0.25, 0.0, 0.888888888888889, 0.15384615384615385, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-492", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_triviaqa-validation-517", "mrqa_hotpotqa-validation-2827"], "SR": 0.59375, "CSR": 0.5357862903225806, "EFR": 1.0, "Overall": 0.7083291330645161}, {"timecode": 62, "before_eval_results": {"predictions": ["1-0", "portrait", "Current TV", "200", "rapper T.I.", "media", "Friday", "going through a metamorphosis from blobs of orange to art as night falls.", "Arizona", "is the U.N. nuclear watchdog agency's strongest warning yet that Iran could be aiming to build a nuclear weapon.", "\"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "56,", "April 28", "former Boca Juniors teammate", "Fernando Caceres", "the license plate \"BADBUL,\"", "Nirvana frontman,", "nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "residential area in East Java", "\"Body Works\"", "diplomatic relations", "supermodel", "10 below", "1,073", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked,", "girls", "Israel", "food, music, culture and language of Latin America", "a lump in Henry's nether regions was a cancerous tumor.", "Tennessee", "Bright Automotive,", "nuclear weapon", "changed the way the world consumed media", "exploration traded in for the comforts of home and domestic Bliss.", "165-room", "\"does not want the thing to be in the media.", "al Qaeda", "media", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "Chinese President Hu Jintao", "United States", "Nakheel Tower", "speaking out about a cause someone feels passionate about.", "25 years", "Anil Kapoor", "President Obama and Britain's Prince Charles", "Wembley Stadium", "a ligand - binding site on a receptor or enzyme", "up to 40.5 metres ( 133 ft )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Robert Arthur Mould", "331", "2006", "Ruth Bader Ginsburg", "champion", "Seth", "\u2013hen"], "metric_results": {"EM": 0.375, "QA-F1": 0.5139579020013803}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.5, 0.0, 0.5, 1.0, 0.5714285714285715, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.08695652173913043, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.26666666666666666, 1.0, 0.22222222222222224, 0.8, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1371", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-4598", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746", "mrqa_triviaqa-validation-3869"], "SR": 0.375, "CSR": 0.533234126984127, "EFR": 1.0, "Overall": 0.7078187003968254}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the New York Philharmonic Orchestra in North Korea", "about the shootings, handed over the AR-15 and two other rifles and left the cabin.", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "the German Foreign Ministry,", "$89", "South African ministers and the deputy president", "Pakistan", "Japan", "The United Nations is calling on NATO to do more to stop the Afghan opium trade", "poor.", "starting place", "Sixteen", "poems", "Iowa,", "Technological Institute of Higher Learning of Monterrey,", "Baseball Hall of Fame in July.", "Golden Gate Yacht Club of San Francisco", "at least 300", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "and renewable energy at home everyday,\"", "the Obama and McCain camps", "The Ministry of Defense", "part", "The minister later apologized, telling CNN his comments had been taken out of context.", "Fernando Torres", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars\"", "civilians,", "March 3, 2008,", "peanuts, nuts, shellfish and fish tend to be lifelong,", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Christianity and Judaism", "The Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "'overcharged.'\"", "since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "turlough, or turlach", "1910", "Kirk Douglas", "Rockefeller Center,", "Vikram, Jyothika and Reemma Sen", "Raden Panji Nugroho Notosusanto", "Royal Navy rank of Captain", "Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7257810236163431}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.2857142857142857, 0.4827586206896552, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.07692307692307691, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.5, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-2986", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.609375, "CSR": 0.534423828125, "EFR": 0.92, "Overall": 0.6920566406249999}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear", "15-year-old", "July 23.", "Alwin Landry", "an American who entered the country illegally from China", "Chester Arthur Stiles,", "United States", "Pakistan's High Commission in India", "Wednesday", "Wigan Athletic", "Adriano", "poems", "Sgt. Jones", "A 22-year-old college student in Boston, Massachusetts,", "to sniff out cell phones.", "Longo-Ciprelli", "Switzerland", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944", "\"I don't quit. I'm not tired. I're just getting started.\"", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "presidential salary", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "a free laundry service.", "rural California,", "Robert Park", "11th year in a row", "100,000", "future relations between the Middle East and Washington", "school", "a plaque", "death squad killings", "a nuclear weapon", "Kitty Kelley", "\"The missile defense system is not aimed at Russia,\"", "Multnomah Falls, about 90 miles east.", "Lindsey oil refinery in eastern England.", "Fred Bright, the district attorney in Milledgeville, Georgia,", "science fiction", "trading goods and services without exchanging money", "more than two years,", "And he won it after facing various challenges and turning them to advantage.", "$40 billion", "G Chat away message", "Bobbyindal", "he acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs", "angular rotation", "360 \u00b0 - system", "Darlene Cates", "Colette", "crow", "Rhys Williams", "2015", "11", "January 15, 2016", "a harpsichord", "Jordan", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6176492184715869}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.30769230769230765, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 0.8181818181818181, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.4444444444444444, 0.4444444444444445, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.0, 0.0, 0.10526315789473685, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3859", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-5667", "mrqa_searchqa-validation-4278"], "SR": 0.484375, "CSR": 0.5336538461538461, "EFR": 0.9696969696969697, "Overall": 0.7018420381701632}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry Zeiger", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Port-au-Prince harbor", "Uzbekistan.", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "identity documents", "Denver, Colorado.", "\"He hears what I'm saying, but there's just no coming through,\"", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "more than 80 features to his name,", "The meter reader who led authorities last week to remains believed to be those of Caylee Anthony", "could be secretly working on a nuclear weapon", "his bodyguard-turned-informant delivered three machine guns and two silencers to the hip-hop star,", "Carol Fowler", "Glenn McConnell,", "\"I hope people look at the content of the speech, not just the delivery.", "April 22.", "Manuel Mejia Munera", "outfit from designer", "two Israeli soldiers,", "Ozzy Osbourne", "Sarah Brown's", "Carol Browner", "Molotov cocktails, rocks and glass.", "eight.", "Fullerton, California,", "Hawaii", "Bill Haas", "A Lion Among Men.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Kr\u00f8yer", "Gyanendra, 60,", "near the grave.", "Gadahn, also known as Azzam the American,", "Turkey", "Polo because \"it was the sport of kings.", "Texas and Oklahoma to points east,", "\u00a320 million ($41.1 million) fortune", "unwanted horses in the past year that her resources are stretched to the breaking point.", "a million", "8th-grade graduation,", "Kerstin and the rest of the family were also able to move into an apartment at a regional clinic nearby.", "it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "Comancheria", "assemble a stable, protective protein shell to protect the genome", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "North Chicago, in Lake County, Illinois", "Eran Kolirin", "brine shrimp", "Coastal University", "Herod", "leopard"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5038060466079042}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5263157894736842, 0.0, 0.2222222222222222, 1.0, 0.10526315789473685, 0.0, 0.0, 0.18181818181818182, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.07407407407407407, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.14285714285714288, 0.0, 0.14285714285714288, 1.0, 0.0, 0.1111111111111111, 0.6666666666666666, 1.0, 0.0, 0.35294117647058826, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_hotpotqa-validation-3069", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.390625, "CSR": 0.5314867424242424, "EFR": 0.9743589743589743, "Overall": 0.7023410183566433}, {"timecode": 66, "before_eval_results": {"predictions": ["Spanish Davis Cup hero Fernando Verdasco,", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "uranium enrichment activities.", "\"green-card warriors\"", "space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Rock Bridge State Park,", "Two U.S. filmmakers were injured", "Harris won two awards.", "Pfc. Bowe Bergdahl", "many different", "President Bush", "$17,000", "Employee Free Choice Act", "assassination of President Mohamed Anwar al-Sadat", "Thomas,", "snowstorm to hit Britain", "Arnold Drummond", "Madonna", "the content of the speech, not just the delivery.", "the Bush administration's controversial system of military trials for some Guant Bay detainees.", "themes about love and loss.", "Larry King", "250,000", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "1980,", "Omar", "Scotland", "Morgan Tsvangirai.", "Tutsis the privileged ethnicity,", "his business dealings for possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "Millvina Dean,", "dental work done, including removal of his diamond-studded braces.", "Sovereign Wealth Funds", "fake his own death", "arson", "a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "Lashkar-e-Tayyiba (LeT), an Islamic militant group based in Pakistan.", "Henrik Stenson", "1995", "a red minivan ran a red light and struck two vehicles at an intersection,", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "Why he's more American than a German,", "not doing more since taking office.", "Television demonstrations", "American Indian allies", "naturalization law for the United States, the Naturalization Act of 1790", "Sigurd the Dragonslayer", "blancmange", "apples", "Manhattan Project", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "joplin", "Italy", "Potomac", "Numbers 22 : 28"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5314466030132149}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 0.8571428571428571, 0.5, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.7142857142857143, 1.0, 0.5, 0.0, 0.8750000000000001, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2105263157894737, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3301", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3390", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-12973"], "SR": 0.40625, "CSR": 0.5296175373134329, "EFR": 0.9736842105263158, "Overall": 0.7018322245679498}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "Autobahn", "candelabrum", "Jaipur", "tea", "the Ordovices", "Peter Scudamore", "Wordsworth", "Ginger Rogers", "Palace of Culture", "borax", "siam", "peregrines", "Dm, Em, and Am", "muscle tissue", "track & field", "the Oaks", "rain", "Greyhound Racing Association", "HMS Amethyst", "dog", "sergeant", "whistling tune, the Colonel Bogey March,", "Cyprus", "King George VI", "ankle joint", "Greyfriars", "honeycomb structures", "flea", "a burial cloak", "the Big Bopper", "NBA", "L. P. Hartley", "sestos", "Arsenal", "Entropy", "No body, that's what we mean", "green", "elia Earhart", "James Hogg", "lacrimal fluid", "Laufey", "The Virgin Spring", "Manfred von Richthofen", "Cain", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "the Boston Red Sox", "1967 onwards", "the Kelvin scale", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "between South America and Africa.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "12 to 36 months old"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6525669642857143}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-4883", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-4050", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.5625, "CSR": 0.5301011029411764, "EFR": 0.9642857142857143, "Overall": 0.7000492384453781}, {"timecode": 68, "before_eval_results": {"predictions": ["Bunkhouse", "smen", "the southern borders of West Virginia and Kentucky", "the Americans", "California", "2018", "Redwood National and State Parks", "Zuzu & Zaza Zebra", "257,083", "the colony, Caparra, was founded on August 8, 1508 by Juan Ponce de Le\u00f3n", "Norman", "Gustav Bauer", "Shawn", "if the concentration of a compound exceeds its solubility", "the United States", "first published in the First Folio in 1623", "the eye ( of ) round", "1957", "360", "electron shells", "into the gastrointestinal tract through a series of ducts", "Lori McKenna", "Wisconsin", "Tbilisi, Capital of Georgia", "from the Latin centum", "1799", "Paul to the Philippians", "His last starring role was as Boston police detective Barry Frost", "Elvis Presley", "2009", "thirteen Academy Award nominations", "most of Sweden's political energy in the international arena had been directed towards the preservation of the League of Nations", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "Steve Russell", "12", "4 January 2011", "New Zealand to New Guinea", "Bill Russell", "Seattle, Washington", "the internal auditory canal of the temporal bone", "2010", "Buddhism", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "April", "fearful man, all in coarse gray with a great iron on his leg", "Huff & puff: Can You blow down the third pig\u2019s brick home", "Brad Silberling", "1941", "Nickelodeon Studios", "July in the Philippines", "iCloud service", "Thursday", "bonobo", "toward", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5766230828982846}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.3076923076923077, 0.25, 1.0, 1.0, 0.4615384615384615, 0.5, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_searchqa-validation-12035"], "SR": 0.484375, "CSR": 0.5294384057971014, "EFR": 0.9393939393939394, "Overall": 0.6949383440382082}, {"timecode": 69, "before_eval_results": {"predictions": ["whitechapel", "Uganda", "anthonyville horror", "Brazil", "amoraya", "sixteen pieces", "Bristol", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "chimbridge", "colorblindness", "thailand", "Prussian Landsturm", "Russia", "1925 novel", "cooperative", "180", "blue", "Marvin Hart", "maggie smith", "Andre Agassi", "hawk", "daily national newspaper", "john le car\u00e9", "Papua New Guinea", "Albania", "animals", "mata hari", "the different levels of importance of human psychological and physical needs", "polo", "gulliver", "ratings", "Saturday Night Live", "Bayern", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Cleopatra", "wagons", "one Canada Square in Canary Wharf,", "Charlie Brown", "corvidae", "snarked", "general strike", "Tokyo japan", "sippon", "Walter Mondale", "fresh nuclear fuel", "the plane crash in 1959", "Scotty Grainger Jr.", "The Kingkiller Chronicle", "3.9 mi", "$1.5 million.", "Buddhism", "took her own life.", "space shuttle", "Smithfield", "Ivan Denisovich", "10 Years"], "metric_results": {"EM": 0.5, "QA-F1": 0.5520359848484848}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-3373", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-608", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-16464"], "SR": 0.5, "CSR": 0.5290178571428572, "EFR": 1.0, "Overall": 0.7069754464285715}, {"timecode": 70, "before_eval_results": {"predictions": ["leigh Ann Fetter", "three", "high jump", "ejaz Khan", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grape plagues", "evolution", "Philip Larkin", "shropshire", "kent", "rabbit", "jack brabham", "posh", "hanover", "algebra precalculus", "armagh", "Pete Sampras", "prussian 2nd Army", "Red", "cats", "The French Connection", "George Orwell", "moaning Myrtle", "Milan", "United Arab Emirates", "CeeLo Green", "photographer", "Justin Bieber", "Ionian", "Mahjong", "scar", "\"Stars on 45 Medley\"", "Cheltenham & Gloucester", "knife", "Istanbul", "Margaret Thatcher", "Achille Lauro", "Botham", "stop motion effects", "lemullet", "Ellis Island,", "Melanesian", "diagon", "Dick Advocaat", "john Huston", "van Gogh", "Ted Talley", "Martin vanuren", "Moscow", "2005", "the governor of West Virginia,", "Payaya Indians", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "was being treated there after being admitted on Wednesday.", "2010", "Asian qualifying Group 2", "Jerry Rice", "leotard", "Henry Ford", "hips"], "metric_results": {"EM": 0.546875, "QA-F1": 0.60625}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-103", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6305", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-3914", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-2817"], "SR": 0.546875, "CSR": 0.5292693661971831, "EFR": 0.9310344827586207, "Overall": 0.6932326447911608}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot", "Kim Sung-su", "British", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "Cielos del Sur S.A.", "October 15, 2013", "Neha Sharma", "Japan", "Quentin Coldwater", "1812", "Kew", "\"Apprendi v. New Jersey\"", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Michael Sheen", "11", "mid-tempo", "approximately 20 mi west of central London,", "1942", "Pollywood", "Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1 draw", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone", "\"First Blood\"", "California", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "detention camp", "France", "Wordsworth", "Spain", "greater latitude in selecting legal representation", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "freeview"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7755443295739348}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-4299", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-1398", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-3874", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-381", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.71875, "CSR": 0.5319010416666667, "EFR": 1.0, "Overall": 0.7075520833333334}, {"timecode": 72, "before_eval_results": {"predictions": ["read therefore", "the defendant owed a duty to the deceased to take care", "around 100,000", "2004", "the NFL", "9th century", "Bob Dylan, George Harrison, Jeff Lynne", "Telma Hopkins", "2014 Winter Olympics in Sochi, Russia", "Pir Panjal Railway Tunnel", "nearby objects show a larger parallax than farther objects when observed from different positions", "Iraq", "1885", "the final episode of the series", "Wisconsin", "the motion of the continents", "the stems and roots of certain vascular plants", "the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "an Islamic shrine located on the Temple Mount", "2010 World Series", "Massachusetts", "Mark Jackson", "John Coffey", "Eastern Hemisphere and Western Hemisphere", "need to repent in time", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Kida", "Instagram's own account", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "the federal government", "2013", "England", "near major hotels and in the parking areas of major Chinese supermarkets", "when the cell is undergoing the metaphase of cell division", "79", "Yugoslavia", "the cell obtains nutrients and metabolizes them, grows, reads its DNA, and conducts other `` normal '' cell functions", "1853", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "De' Andre Hunter", "Dante Pastula", "Daya Jethalal Gada", "system of state ownership of the means of production", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "de Havilland Moth", "architecture", "Bermuda", "win world titles in four weight classes", "their unusual behavior, such as the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "Parody", "a prostitute", "Ashlee Simpson", "greece"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5455927752802753}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, true, true, true, false, true, false], "QA-F1": [0.125, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.5, 0.5, 0.2857142857142857, 0.36363636363636365, 0.14285714285714288, 0.0, 0.4, 1.0, 1.0, 0.0, 0.22222222222222224, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.46875, "CSR": 0.5310359589041096, "EFR": 0.9705882352941176, "Overall": 0.7014967138396455}, {"timecode": 73, "before_eval_results": {"predictions": ["along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "December 14, 2017", "Barbara Windsor", "the ninth w\u0101", "Italian Campaign", "Bart Millard", "Jesse Wesley Williams", "Lucius Verus", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "Paul the Apostle", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "In 1927, the provisional Indian Olympic Committee formally became the Indian Olympic Association ( IOA )", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning Thieves", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Jane Fonda", "Arnold Schoenberg", "the national and state legislatures", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Vampire", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1878", "to `` help bring creative projects to life ''", "President Lyndon Johnson", "Joseph Nye Welch", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Phillip Paley", "Neil Diamond", "Sichuan", "rubber", "Reggie", "Tampa", "1980", "January 28, 2016", "Jaipur", "18th", "in July", "taro", "You Bet Your Life", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7308936403508772}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.21052631578947367, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-4500", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-4104", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_hotpotqa-validation-2215"], "SR": 0.6875, "CSR": 0.5331503378378378, "EFR": 0.9, "Overall": 0.6878019425675677}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Russell Stover Candies", "hub", "franchise", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "labor unions", "China", "blitz", "new wave", "a commune", "a ring", "Thames", "A repertoire", "hockey", "fairy tales", "David", "The Color Purple", "whales", "Jane Addams", "Viola de Lesseps", "Tanzania", "Biosphere 2", "an inch", "death", "Henry Wadsworth", "Fred Thompson", "Geneva", "humility", "bdellium", "California", "diatomaceous", "the debt ceiling", "pig", "Titicaca", "Existentialism", "ashes", "emperor", "Jack London", "Isaac Newton", "Charles I", "Kevin Costner", "Antichrist", "treble clef", "uranium", "Louisiana", "The Hot Chick", "red Worm", "August 21", "1990", "four", "Spey", "pappy", "Denmark", "Trappist beer", "4,530", "Steve Prohm", "seven", "Airbus A330-200", "Berkeley", "Manitowoc County, Wisconsin"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6609375}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true], "QA-F1": [0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-10874", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-7832", "mrqa_searchqa-validation-13598", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-8909", "mrqa_triviaqa-validation-7472", "mrqa_hotpotqa-validation-1307", "mrqa_newsqa-validation-1572"], "SR": 0.609375, "CSR": 0.5341666666666667, "EFR": 0.96, "Overall": 0.7000052083333334}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "Rosalind Bailey", "Pebble Beach", "vehicles designed for off - road use", "Turing", "B.F. Skinner", "hydrogen", "Great Britain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "the First Epistle of John at 5 : 7 -- 8", "Asuka", "Jason Momoa", "Amanda Bynes", "the President", "Spanish missionaries, ranchers and troops", "Gustav Bauer", "art of the Persian Safavid dynasty from 1501 to 1722", "natural killer cells", "around 2.45 billion years ago ( 2. 45 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Yente", "March 31, 2017", "Incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "the lower of the overall continuous assessment score ( OCAS ) and overall examination score ( OES )", "summer of 1979", "John Roberts", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "the band's name while studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units", "Rigg", "electron donors", "San Francisco 49ers", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "f\u00e8in", "Lakeland", "1967", "Yubin", "100 metres", "sedative", "a sailboat matching the description of the missing sailor whose five Texas A&M University crew mates were hoisted out of the Gulf of Mexico earlier in the day after their sailboat capsized.", "\"peregruzka\"", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7144132402555956}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.4, 0.9032258064516129, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.958904109589041, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.07142857142857142, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-438", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-2810", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_searchqa-validation-3069", "mrqa_hotpotqa-validation-3909"], "SR": 0.5625, "CSR": 0.5345394736842105, "EFR": 0.9285714285714286, "Overall": 0.6937940554511278}, {"timecode": 76, "before_eval_results": {"predictions": ["tintoretto", "scotch", "repechage", "Harris", "Angela Anderson Lee", "Costa Brava", "Northumberland", "birds with black, blue or splash plumage patterns", "steerpike", "SS Constitution", "Bleak HouseBleak House", "four", "the Indus valley", "Selfie", "jaws", "Charlie Cairoli", "The Hague", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "sistine Chapel, Vatican City, 2005", "Patrick Kielty", "8 minutes", "Janine Lecroix", "Red Crescent ambulance", "john worthen", "Margaret Thatcher", "Hooky Street", "sam Nixon", "johnny johnstone", "Bonn", "lieutenant general", "snakes", "Coral Sea", "Constantine III", "Madonna", "par-5 hole", "beer", "the knee", "Ice Age: The meltdown", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Desdemona", "Hawley Harvey Crippen", "fifty-six", "1799", "1979", "1976", "Gupta Empire", "stunt performer", "2004", "Rwandan genocide", "Steve Williams", "heavy snow and ice was heading from Texas and Oklahoma to points east, with 8 to 10 inches of snow possible in some locales,", "fight outside of an Atlanta strip club on October 3,", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6027157738095239}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-7046", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2600", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2870", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-6645", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.515625, "CSR": 0.5342938311688312, "EFR": 0.967741935483871, "Overall": 0.7015790283305405}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1884", "Cook's Landing Place", "M2M", "Lady Victoria Hervey", "FX", "president", "Diamond Rio", "lola Dee", "master builder", "UFC 50  UFC 50: The War of '04", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "\"O\"", "Nobel Prize", "glee", "Paul Corbould", "his advocacy of young earth creationism and intelligent design.", "2 November 1902", "January", "orishas", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "future AC/DC founders", "James Franco", "London", "Kelly Bundy", "British", "Norway", "Military Band of Hanover", "around 8000 BC", "2011", "Peter Seamus O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "beer", "Biola University", "Eugene O'Neill", "Morita therapy", "Lola", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "a bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Nancy Birtwhistle", "Mel Gibson", "1987", "San Francisco", "peter david peter Purves", "Vancouver", "college campus.", "$106,482,500", "15-year-old's", "Cleopatra", "Church & Dwight", "the Persian Gulf", "drumroll"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6715300324675324}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.3636363636363636, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.8000000000000002, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-5222", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-2168", "mrqa_searchqa-validation-4417", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.5625, "CSR": 0.5346554487179487, "EFR": 0.9642857142857143, "Overall": 0.7009601076007326}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "August 1991", "Nigel Lythgoe", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta, Georgia", "The management team", "Medicaid", "soon after", "Ali", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "the external genitalia", "May 2017", "September 19, 1977", "DNA at the origin", "1956", "between 8.7 % and 9.1 %", "minor key symphonies", "Divyanka Tripathi", "Newfoundland", "Einar Bj\u00f8rndalen", "31 December 1960", "following graduation with a Bachelor of Medicine, Bachelor of surgery degree", "pre-Christian festivals that were celebrated around the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "member states", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "twin-faced sheepskin", "5,922", "1866", "two", "2006", "eight or nine", "Lake Superior", "Thames", "Liceo", "red"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6714657738095239}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.08333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5714285714285715, 0.2222222222222222, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_hotpotqa-validation-1250", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.59375, "CSR": 0.5354034810126582, "EFR": 0.9615384615384616, "Overall": 0.7005602635102239}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "the Sugar Bowl", "1858", "heavy metal", "Hong Kong professional footballer", "1875", "The The The Onion", "his most brilliant student", "Juilliard School", "World Outgames", "1812", "Peach", "1935", "the Philadelphia Eagles", "Victorian England", "The War of '04", "Australian", "pinball machine", "Alpine climate and landscapes, in particular for skiing and mountaineering", "Baudot code.", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "Shameless", "from 1241 until his death in 1250", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Barry Sanders", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1926", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset theater", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "gollum", "Melbourne", "paddington bear", "54-year-old", "American Muslims", "random events", "Richmond", "Venezuela", "Old Stone Age", "rally at the State House next week"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7518677503052503}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, false], "QA-F1": [0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-808", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-3221", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-4171", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_searchqa-validation-13343", "mrqa_newsqa-validation-4059"], "SR": 0.609375, "CSR": 0.536328125, "EFR": 1.0, "Overall": 0.7084374999999999}, {"timecode": 80, "before_eval_results": {"predictions": ["the Tribune", "chardonnay", "\"The chief business of the American people is business\"", "beach volleyball", "\"Jack & Diane\"", "hot springs", "a Philosopher\\'s Stone", "Dell", "pro bono", "American politician and businessman who was the 46th Vice President of the United States", "a kind of grammatical", "Glinda", "Yggdrasill", "the black rat", "Sorbonne", "The Merry Wives of Windsor", "kowtow", "Mars", "the Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "bread", "a katzenjammer", "Cuisinart", "Travertine", "Bob Dole", "Ross Ice Shelf", "director", "Taiwan", "the grizzly bear", "Pleasure Island", "Czech Republic", "the opera house", "the bison", "go home", "Jodie Foster", "Cleopatra VII", "the Mummy", "White Fang", "the pest could pose as big a threat to cotton farming in the South as the beetle", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1937", "53", "The Lightning Thief", "Brazil", "Edinburgh", "gennadiy Samokhin", "Wynonna Judd", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant,", "tells stories of different women coping with breast cancer in five vignettes.", "a level of autonomy that will allow them to protect and preserve their culture, religion and national identity. In exchange, China could continue to claim Tibet as part of its territory.", "Joanne Wheatley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6199068740399385}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.06451612903225806, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-8319", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-14953", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813", "mrqa_newsqa-validation-479"], "SR": 0.546875, "CSR": 0.5364583333333333, "EFR": 0.9655172413793104, "Overall": 0.7015669899425288}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "Indonesia", "The Generation Game", "The Firm", "red hair", "15", "Spanish", "Georgia", "Olivia Smith", "sow", "eucharist", "greece", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$50", "Liverpool", "the Count Basie Orchestra", "Manhattan", "stone arch", "The Blind Beggar", "jean", "jimmy duleepsinhji", "Mallard", "Ambroz Bajec-Lapajne", "Apollo", "1963", "Bologna", "bear", "Coleraine", "jean", "Timothy", "Addis Ababa", "motorcycle", "the internal kidney", "endurance", "tomato stew", "Mark Twain", "Doctor Who", "Yosemite National Park", "IBM", "40", "the First World War", "passion", "Thetis", "7", "georgia", "100 years", "Benedict XVI", "Jesse Triplett", "Orlando", "LED illuminated", "41st", "Mel Blanc", "Mauthausen-Gusen", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine auto-injector", "cowardly lion", "Danny Elfman", "Bolivia", "a solar year", "Morgan Earp"], "metric_results": {"EM": 0.5, "QA-F1": 0.5490405701754386}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.19999999999999998, 1.0, 1.0, 0.0, 0.10526315789473684, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-2707", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-4133", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_triviaqa-validation-6728", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-2103", "mrqa_searchqa-validation-14665"], "SR": 0.5, "CSR": 0.5360137195121951, "EFR": 0.96875, "Overall": 0.702124618902439}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Illinois", "1,696", "Melville, NY, USA", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "local level", "Tufts University", "High Court of Admiralty", "Sir Christopher Wren", "\"Isla de Xativa\"", "her gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Akosua Gyamama Busia", "5.3 million", "six", "a polypeptide chain", "Brady John Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Hallett Cove", "Juan Manuel Mata Garc\u00eda", "Malayalam movies", "Pittsburgh Steelers", "pronghorn", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "American comedian and actor", "the Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association", "American", "the Corps of Discovery, with William Clark", "pubs, bars and restaurants", "Andrew", "Wisconsin and the Upper Peninsula of Michigan", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament", "illnesses", "Thomas Joseph \"T. J.\" Lavin", "drawn on the bank's own funds and signed by a cashier", "16 December 1908", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "\"came under fire\" after admitting they learned of the death of TV news coverage, Yonhap reported.", "Samuel Herr, 26, and Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "Richard Nixon", "right", "Edward VIII"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6488236826936413}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.375, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.08695652173913043, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.31578947368421056, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-538", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-1186", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.53125, "CSR": 0.5359563253012047, "EFR": 1.0, "Overall": 0.7083631400602409}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys", "Mickey Mantle", "Titanic", "Earth", "Bill Clinton", "Graceland", "Cambodia", "elevators", "David Copperfield", "Terminator", "Humpty Dumpty", "a vowel", "a goat", "Splash Down in the Pacific", "The Ghost of Tom Joad", "Dracula", "the Atlas Mountains", "a windpipe", "Mrs. Miniver", "Tom Hardy", "Italy", "a low ebb", "sheep", "Casey Jones", "Brady Hawkes", "Hope", "navy", "Dresden", "flippant", "Arkansas", "Marcel Duchamp", "a sloop", "toilet paper", "Sesame seeds", "Iceland", "a nocturnal mammal", "the Monty Hall problem", "a bee", "Janet Reno", "Mark Twain", "Gianlorenzo Bernini", "Essen", "Clover Hill", "Thailand", "a man who had died", "a cereal", "Pamela Anderson", "Theodor Seuss Geisel", "Whitehorse", "Scott McClellan", "Edd Kimber", "six", "Steffy Forrester", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two", "her abusive husband"], "metric_results": {"EM": 0.5, "QA-F1": 0.559375}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-7801", "mrqa_searchqa-validation-1643", "mrqa_searchqa-validation-5144", "mrqa_searchqa-validation-15322", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14643", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-3314", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-3590"], "SR": 0.5, "CSR": 0.5355282738095238, "EFR": 1.0, "Overall": 0.7082775297619047}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "a mansard roof", "Cuisinart", "the alveoli", "the Boston Massacre", "a ghost", "Simn Bolvar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "a diamond", "Picasso", "Arlington House", "John Paul II", "the hood", "Aulis", "South Dakota", "natural selection", "Department of the Interior", "Cyrus the Younger", "Humpty Dumpty", "Schembechler", "Gucci, Prada & Sergio Rossi", "Vermont", "a chimp", "a computer desktop", "The Man in the Iron Mask", "New Zealand", "international fashion model", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Dr. Moreau", "an organ", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the flag", "seed", "the stiletto", "cheese", "Kentucky", "Bora Bora", "Titanic", "a physician", "the \"Fisherman\\'s ring\"", "RBIs", "the forex market", "the Tin Woodman", "a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "london", "a sphere", "Disney California Adventure", "Lochaber, Highland, Scotland", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "Baku"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7511656746031746}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14524", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-14923", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-2558", "mrqa_newsqa-validation-1793", "mrqa_triviaqa-validation-5654"], "SR": 0.65625, "CSR": 0.5369485294117646, "EFR": 0.9545454545454546, "Overall": 0.6994706717914438}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "Old Lady", "Opechancanough", "James Clemens", "Joyce", "The Big Red One", "a hangover", "endodontist", "a desktop microcomputer", "South Dakota", "Talbot", "Frasier Crane", "George B. McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "John Gotti", "I.M. Pei", "The Name of the Rose", "a Continental Congress", "Norway", "Lewis", "'thoughts and Prayers' are Not Enough - and What Is  Faith", "Steve McQueen", "Firebird", "Sweet Home Alabama", "Vietnam", "Montana", "Huckabee", "a Bill of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "Hercules", "Manitoba", "Madonna", "a hat", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Churchill", "Torvill and Dean", "the Black Eyed Peas", "\"I think, therefore I am\"", "the Kingdom of Serbia", "prophets", "early 1988", "Toy Story", "Harriet Tubman", "the Great British Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Juliet", "Hercules Huerta Rios, also known as \"La Burra\" or \"El Junior,\"", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6801525297619048}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-295", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-10582", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-6557", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-12332", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-2188", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-1491", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.578125, "CSR": 0.5374273255813953, "EFR": 1.0, "Overall": 0.708657340116279}, {"timecode": 86, "before_eval_results": {"predictions": ["the cob", "Barbara Walters", "the Bosphorus and Dardanelles", "hoover", "\"Stopping by Woods on a Snowy Evening,\"", "Cheetah Rivera", "coffee", "Frog", "Knott\\'s Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Perseus", "Charles de Gaulle", "anode", "Bernini", "Ovid", "Pablo Escobar", "Abraham Lincoln", "Catherine of Aragon", "modify", "a protective transparent membrane", "Bank of America", "copper", "push", "Kiss Me, Kate", "Errol Flynn", "plutonium", "Bismuth", "a kahk", "Amistad", "a 2000 American sports drama film directed by Robert Redford,", "The Simpsons", "the Ladies Pro Tour", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge Family", "Jammu & Kashmir", "\"A pyramid unfinished\"", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Meriwether Lewis", "Lima beans", "Will & Grace", "Robber Barons", "De Wayne Warren", "2017", "Trinidad", "Twitty", "golf", "\" Dialogues des Carm\u00e9lites\"", "England", "35,124", "between June 20 and July 20.", "The syndicate, founded by software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6742931547619048}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-3046", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-6375", "mrqa_searchqa-validation-11379", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-783", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-2461"], "SR": 0.59375, "CSR": 0.5380747126436782, "EFR": 0.9230769230769231, "Overall": 0.6934022021441203}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "the zona glomerulosa of the adrenal cortex in the adrenals gland", "late 19th and early 20th centuries", "\"Tom Jones\"", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "\"Martian Manhunter\"", "Easy", "Dayton Memorial Hall", "Gareth Barry", "Robert John Day", "\"Bambi, a Life in the Woods\"", "1896", "iPod Classic", "2017", "The Timekeeper", "from May 5 to July 8, 2014", "Ben Ainslie", "torpedoes", "Xherdan Shaqiri", "Miami Gardens, Florida", "the Miami Marlins", "Netherlands", "Dallas/Fort Worth Metroplex", "Althea Rae Janairo", "four", "Jim Davis", "Kurt Vonnegut Jr.", "chocolate-colored", "Haryana", "1837", "Blackpool Football Club", "Pippa", "DS Virgin Racing Formula E Team", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "1943", "Paradise, Nevada", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "1885", "2015", "the Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Damian Green", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice act", "\"peregruzka\"", "Port-au-Prince", "Wimbledon", "Brazil", "Bullwinkle", "baseball"], "metric_results": {"EM": 0.546875, "QA-F1": 0.621391369047619}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.2, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-1902", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-3946", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_searchqa-validation-14393", "mrqa_searchqa-validation-4094"], "SR": 0.546875, "CSR": 0.5381747159090908, "EFR": 1.0, "Overall": 0.7088068181818181}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "Apple Lisa", "\"Veyyil\" (2006)", "Victoria, Duchess of Kent", "Umina Beach", "from 1989 until 1994", "Adelaide \" Addie\" Miethke", "Pensacola", "Consigliere", "Joseph Cheshire Cotten, Jr.", "7", "the Bologna Process", "Peoria, Illinois", "Iran", "Dick Ebersol", "Philip K. Dick", "University of Texas Longhorns football", "\"O\"", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German Shepherd", "The Vaudevillains", "Mansoor Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "rhythm and blues dance", "Carrefour S.A.", "Premier League", "Bob Zmuda", "Edward Albert Heimberger", "Chicago", "Ford Island", "\"The Times Higher Education Guide\"", "Derry City F.C.", "Beverly Hills and North Hollywood", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The Bad Hemingway Contest", "Coll\u00e8ge de France", "Germanic", "Oklahoma State", "Akshay Kumar", "2015", "diastema", "Thames Street", "tom stoppard", "brazil", "Dube was killed in an attempted car-jacking as he dropped his children off at a relative's house,", "an average of 25 percent", "super-yacht designers Wally is still in the design stage", "fish", "Livin' On A Prayer", "the electoral college", "josef kipling"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6582933125901875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 1.0, 0.4, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.125, 0.4, 0.5454545454545454, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-812", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-3009", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-5078", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-3335", "mrqa_hotpotqa-validation-37", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.546875, "CSR": 0.5382724719101124, "EFR": 1.0, "Overall": 0.7088263693820225}, {"timecode": 89, "before_eval_results": {"predictions": ["Michael Manasseri", "various bigfoot-like sightings", "World War II", "Mike Pence", "Mickey Gilley's", "Levi Weeks", "Durrani Empire", "Arvo P\u00e4rt", "The Itchy & Scratchy Show", "First Street", "5249", "the Dutch Empire", "Tchaikovsky", "The Hit Factory", "October 20, 2017", "Antilocapra americana", "Lord's Resistance Movement", "1965", "1943", "the Big 12 Conference in the National Collegiate Athletic Association (NCAA)", "1959", "31 January 1933", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "the University of Kentucky", "\"The Sun on Sunday\"", "Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies.", "B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Bernd Bertie", "Lismore", "EQT Plaza", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "north", "the State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "gildrose", "World War II", "George Santayana", "label products that contain any of the most common allergens -- milk, eggs, fish, shellfish, peanuts, tree nuts, wheat and soy", "an annual road trip,", "101", "a pouring spout", "inhale", "saliva", "Venus Williams"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7168391504329004}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1550", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-5595", "mrqa_triviaqa-validation-6118", "mrqa_newsqa-validation-3736", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-3153"], "SR": 0.65625, "CSR": 0.5395833333333333, "EFR": 0.9545454545454546, "Overall": 0.6999976325757575}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "Tennessee Whiskey", "the integument", "a motorcycle", "New Coke", "Abigail Adams", "Labor unions", "University of Hawaii", "the leg", "Cristina Yang", "The Omega Man", "van Gogh", "an eruption", "Atlanta", "\"The ARIA Australian Top 100 Singles 1995\"", "Paddington Bear", "Duxbury", "a skyscraper", "1950", "television news", "a puppet", "a renowned fugitive Czech Resistance leader", "seven", "Nike", "bck", "Sweden", "Lamborghini", "a judge", "John Philip Sousa", "oregano", "New South Wales", "smashed up bars", "Ho Chi Minh", "Martha\\'s Vineyard", "Wayne Gretzky", "apples", "Transformers: Earth Wars", "An American in Paris", "Taiwan", "The Parent Trap", "Aloha", "William Donald Scherzer", "\"Gentleman Jim\" Corbett", "Michael Joseph Jackson", "Firebird", "Sicily", "Bill Frist", "a dollar", "apocrypha", "Hercule Poirot", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "poland", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "a monthly allowance,", "Aung San Suu Kyi", "75.", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5245764652014653}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-12132", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-16072", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-11552", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-8688", "mrqa_searchqa-validation-1958", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.46875, "CSR": 0.538804945054945, "EFR": 0.9705882352941176, "Overall": 0.7030505110698125}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Crayola & Smith", "a giant slalom", "silicone", "Banana & Chocolate Top Banana Bar", "Lake Ontario", "The Devil\\'s Dictionary", "AILD", "Macbeth", "Suez Canal", "Stephen Hawking", "Ecuador", "Chicago", "local broadcasters", "acetylene", "scrapple", "Tennessee", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "St Lewis", "slanting", "Cracker Jack", "Ford", "the Flop", "phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "France", "orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes", "Ovid", "2012", "Grendel", "fish", "Ascomycota", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "eyes", "the sound barrier", "Cyprus", "the members of the actual club", "Nala", "Etienne de Mestre", "USA43SC6390", "2.1", "kendo", "Rawlings", "Adam Levine", "Syracuse", "Stuttgart", "The National Telecommunications and Information Administration", "legislation that would let prisons jam cell-phone signals within their walls.", "Bed and breakfast"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5796874999999999}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.19999999999999998, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-15688", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-7773", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-10784", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_hotpotqa-validation-1014", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.515625, "CSR": 0.5385529891304348, "EFR": 1.0, "Overall": 0.708882472826087}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "A. Hopkins", "sharia", "yente", "Occlusion", "a referendum", "alfalfa", "Phaedra", "Franklin D. Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "Australian", "Beethoven", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "the velocity", "The Secret", "an acre", "the finale", "Frederick Douglass", "William Conrad", "Jericho", "the burning bush", "a gastropod shell", "Indian tribes", "Australia", "Freaks and Geeks", "(Edouard Manet)", "Finding Nemo", "Frdric Franois Chopin", "a calculator", "a soap opera", "Amman", "Van Halen", "Permanent Select Committee on Intelligence", "Amyotrophic lateral sclerosis", "grapes", "Nancy Lopez", "Der Zauberberg", "Hudson\\'s Bay", "Beguile", "hoo'zher", "a den", "a loaf of bread", "a mead", "the Mossad", "mnagerie", "an aide-de-camp", "Judith Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "( Diego) de Goya", "Shut the *freak* up", "Panther", "paracyclist", "the XXIV Summer Universiade", "Asashoryu's", "the world's tallest building,", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6492559523809525}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-4268", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-1688", "mrqa_searchqa-validation-6365", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-1122", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.546875, "CSR": 0.5386424731182795, "EFR": 1.0, "Overall": 0.7089003696236559}, {"timecode": 93, "before_eval_results": {"predictions": ["the Department of Labor", "Standard Oil", "La Ciudad de los Reyes", "English", "archbishop", "Clark", "India", "The Carpenters", "Wyoming", "Mary Queen of Scots", "the Crimean War", "the centre", "a thermostat", "a bad speed", "a sapphire", "a florida", "a windshield", "grace", "taxis", "the Davis Cup", "Blackbeard", "William of Orange", "Emily Dickinson", "the stikhos", "Simon Wiesenthal", "Mercury and Venus", "Conrad Hilton", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "All Hallows", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Walter Scott", "the War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO", "cancerous tumor.", "Stuttgart", "Charles Quinton Murphy"], "metric_results": {"EM": 0.75, "QA-F1": 0.8098958333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-10246", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-10500", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-3138", "mrqa_hotpotqa-validation-751"], "SR": 0.75, "CSR": 0.5408909574468085, "EFR": 1.0, "Overall": 0.7093500664893617}, {"timecode": 94, "before_eval_results": {"predictions": ["the assassination", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "David Lynch", "F Thomas G Nazareth", "pine", "Wild Bill Hickok", "2D", "hydrogen", "vodka", "lava", "Anthrax", "Jamaica", "Sacher Torte", "Hillary Clinton", "a coyote", "CVS/pharmacy", "Sulfur", "the leader of the late insurrection in Southampton, Virginia", "Jacques Marquette", "overbite", "The Silence of the Lambs", "the nucleus", "Benjamin Franklin", "a millimeter", "Megan Fox", "Philip", "Unicef", "the Battle of the Little Bighorn", "Marie Curie", "the Archangel Cat", "Dustin Hoffman", "Nebraska", "\"E-T\"", "vodka", "John", "LOUIS XIV", "Vnus impudique", "Yellowbook", "Toyota Grand Cherokee", "Scout Finch", "Liechtenstein", "the Joker", "Pulp Fiction", "Mao Zedong", "Nereid", "dinosaurs", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson & Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle and long distance", "Stratfor", "Arthur Schnitzler's 1926 novella \"Traumnovelle\" (\"Dream Story\")", "1985", "Manuel Mejia Munera", "seven", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.5, "QA-F1": 0.5785714285714285}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-818", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.5, "CSR": 0.5404605263157894, "EFR": 1.0, "Overall": 0.709263980263158}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "the magic lantern", "the cassowary", "Atonement", "a palette", "ice cream", "Cherry", "Tajikistan", "Theology", "Forrest Gump", "a piles", "a hot dog", "Guy Ritchie", "Dixie\\'s Land", "Alfred Nobel", "Karen Blixen", "a climbing facility", "Sindbad", "a ziggurat", "the toe", "private research university", "\"War of the Worlds\"", "Homer", "Steve Jobs", "J. P. Richardson", "Manwich", "salinity", "Julius Caesar", "Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "Battlestar Galactica", "Rugby School", "Titan", "Francis", "Samuel", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "2016", "a moose", "the Sikkim region", "the Barbary Coast", "a skunk", "Neal Dahlen", "a permanent, fast - drying painting medium", "Reverend J. Long", "bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions,", "BBC", "FIFA Women\\'s World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "\"There are already many other restaurants in the mall, so we will only be one of the many restaurants that offer visitors their products.\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.684375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.06666666666666667]}}, "before_error_ids": ["mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-14076", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.640625, "CSR": 0.54150390625, "EFR": 0.9565217391304348, "Overall": 0.7007770040760869}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Melanie Martinez", "InterContinental Hotels & Resorts", "Kaley Christine Cuoco", "1869", "Tango in the Night", "T.S. Eliot", "based on sovereign states", "30 October 1918", "St. Augustine", "Robyn", "Peggy Lipton, who knew Vincent Price, suggested Price for the vocal part, which Price agreed to do", "Nicole Gale Anderson", "Tiffany Adams Coyne", "a region in Greek mythology", "Randy Watson", "20 November 1989", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "The Star Spangled Banner", "Thomas Stone", "meaning `` save, rescue, savior ''", "the Canadian Rockies continental divide east to central Saskatchewan", "March 11, 2018", "Khrushchev", "Addie Horton", "International Border ( IB )", "Ancylostoma duodenale", "Toronto Bypass between Weston Road and Highway 11 ( Yonge Street )", "Wakanda and the Savage Land", "The player character is recruited into the Grey Wardens, an ancient order that stands against demonic forces known as `` Darkspawn '',", "1996", "the Jos Plateau", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "Majandra Delfino", "August 29, 2017", "a convergent plate boundary", "in ancient Mesopotamia", "detailing the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "18", "Matt Monro", "Bill Russell", "green", "December 14, 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover Limited", "His son", "propofol,", "Courtney Love,", "his Seattle home.", "music of intense emotion", "East of Eden", "the Himalayas", "1919"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5737883370284687}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.8947368421052632, 0.0, 1.0, 0.5714285714285715, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10096", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_hotpotqa-validation-3348", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.46875, "CSR": 0.5407538659793815, "EFR": 0.9411764705882353, "Overall": 0.6975579423135233}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Sachchidananda Sinha", "2001 -- 2002 season", "New England", "2007", "New Croton Reservoir in Westchester and Putnam counties", "the mid-1970s", "Etienne de Mestre", "Billie", "Arnold Schoenberg", "1000 BC", "meditation", "Panzerkampfwagen VIII Maus", "An empty line", "Ian Hart", "contestants", "in the 1898 Treaty of Paris", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Hermia", "Shakespearean actresses and car salespeople", "Procol Harum", "2018", "the world", "James Rodr\u00edguez", "nitrogenous base, a five - carbon sugar ( ribose or deoxyribose ), and at least one phosphate group", "Hathi Jr", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals )", "1983", "Instagram's own account", "the last book accepted into the Christian biblical canon", "when matching regions on matching chromosomes break and then reconnect to the other chromosome", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "American swimmer Michael Phelps", "Brittany Paige Bouck", "In the outbreak of war in 1914, the United States declared neutrality and worked to broker a peace", "Taylor Morshower", "April 29, 2009", "Laodicea, near Denizli", "Gibraltar", "red, white, and blue", "U.S. Fund for UNICEF", "Salt Lake City", "Schengen Area (EU)", "The King", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "\"The Da Vinci Code\"", "Barbara Streisand", "Brave New World", "a phobia", "cryogenics", "anxiety"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5805533988957902}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.4, 0.0, 1.0, 0.5, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4347826086956522, 1.0, 0.5714285714285715, 0.4444444444444445, 0.07142857142857144, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.125, 0.0, 0.0, 0.5, 1.0, 1.0, 0.25, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-564", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786", "mrqa_searchqa-validation-15118"], "SR": 0.46875, "CSR": 0.5400191326530612, "EFR": 0.8823529411764706, "Overall": 0.6856462897659064}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "an American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Laurence Fishburne", "Rockbridge County", "Mumbai, Maharashtra", "Atlanta", "\"Perfect Strangers,\"", "public", "Nelson County", "video game", "boundary river", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall in Industry, California", "neo-Nazi", "Hugh Michael Horace Dancy", "Bisexuality", "Adam Dawes", "1621", "Steven Selling", "Chief of the Operations Staff of the Armed Forces High Command", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "Australian", "1968", "Longford", "Dirk Werner Nowitzki", "highland regions of Scotland", "Kansas State 52\u201321", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett's \"Eleuth\u00e9ria\"", "Bay Ridge, Brooklyn", "The Sun on Sunday", "their unusual behavior", "1952", "start fires, hunt, and bury their dead", "In February 2011", "Dmitri Mendeleev", "honda", "Utah", "Moby Dick", "two Metro transit trains that crashed the day before, killing nine,", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "Lula da Silva", "\"Sweet Home\"", "Gone Home", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6129464285714286}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.2, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.6, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-4863", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_hotpotqa-validation-1650", "mrqa_hotpotqa-validation-2759", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-2545", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15800"], "SR": 0.546875, "CSR": 0.5400883838383839, "EFR": 1.0, "Overall": 0.7091895517676768}, {"timecode": 99, "UKR": 0.708984375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.77734375, "KG": 0.48125, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "PBS", "The Bears", "1987", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point Foundry", "The Grandmaster", "satirical erotic romantic comedy", "The Process", "Vikram", "1949", "BAFTA TV Award Best Actor", "Duke University", "defender", "Levi Weeks", "219", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "1853", "1948", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan", "Richard Arthur", "mentalfloss.com", "May 4, 2004", "3 mi", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "John Alexander", "18", "2011", "the last Ice Age", "Tennessee", "wish FM", "(John) Galliano", "Ford", "in Section 60.", "Seoul", "circumnavigate", "the colon", "a 15th anniversary", "a mollusca"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6949032738095238}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false], "QA-F1": [0.25, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-1036", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-5960", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2265", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.609375, "CSR": 0.54078125, "EFR": 0.92, "Overall": 0.685671875}]}