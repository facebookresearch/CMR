{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 9000, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "graph isomorphism", "Thomas Murphy", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "the net force", "12 January", "1976\u201377", "The E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "the Council of Chalcedon", "complicated definitions", "coordinating lead author of the Fifth Assessment Report", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation of a drug treatment for an individual", "2014", "late 1970s", "30% less steam", "1983", "Happy Days", "1,230 kilometres", "Saturday, 23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "fossils in sedimentary rocks", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Howard Wolowitz", "Daenerys", "Raabta"], "metric_results": {"EM": 0.75, "QA-F1": 0.783077061373245}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-5952", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-9931", "mrqa_squad-validation-2611", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.75, "CSR": 0.7578125, "EFR": 0.9375, "Overall": 0.84765625}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "Smith and Jones", "1767", "53,000", "Fu\u00dfach", "leptin", "have a supporting function", "7 West 66th Street", "patent archives", "All members of Parliament", "4-week period", "six", "Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "The Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "1898", "Commander (CDR) Command Module Pilot", "citizenship", "Merritt Island", "physician, lawyers, engineers", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay", "120 m ( 390 ft )", "The Winds of Winter", "100 members", "photo-electric", "Welch, West Virginia", "Independence", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "Spain"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7868785294566545}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 0.6666666666666666, 0.888888888888889, 0.0, 1.0, 0.4, 1.0, 0.06666666666666667, 0.38095238095238093, 0.0, 0.5, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-9559", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-4072", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.7291666666666667, "EFR": 0.9523809523809523, "Overall": 0.8407738095238095}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "a civil disobedients' use of force and violence and refusal to submit to arrest", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six teams", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "Yam route systems", "Stairs", "genetically modified crops", "around 300,000", "three sites", "DeMarcus Ware", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Bruno Mars", "the Calvin cycle", "the Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown San Bernardino", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "the Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "the optic chiasma", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "September 1973", "the One Ring", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.625, "QA-F1": 0.7584334935897435}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 0.7142857142857143, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6798", "mrqa_squad-validation-4108", "mrqa_squad-validation-180", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8584", "mrqa_squad-validation-8763", "mrqa_squad-validation-126", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_squad-validation-384", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.625, "CSR": 0.703125, "EFR": 0.9583333333333334, "Overall": 0.8307291666666667}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the use of outbreaks during the Middle Ages gave it the name that has become the medical term.", "approximately 80 avulsions", "15", "Presque Isle (near present-day Erie, Pennsylvania) on Lake Erie's south shore", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "the 1960s", "the freedom to provide services applied, it was directly effective, and the rule was probably unjustified", "Napoleon", "Immunology", "geophysical surveys", "topographic", "130 million cubic foot (3.7 million cubic meter)", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments", "force, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "the Jews and in diatribes against \"Turks\" (Muslims) and Catholics", "six", "the Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste, Franco Frattini, the Justice, Freedom and Security Commissioner, proposed with Dimas to create criminal sentences for \"ecological crimes\"", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "linked groups or chains, still always anchored to a thylakoid", "motorway underpass without pedestrian access", "use of remote sensing for the conservation of the Amazon is also being used by the indigenous tribes of the basin to protect their tribal lands from commercial interests", "religious beliefs", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "the use of these \"on the hearth is the luckiest thing in all the world!\"", "the Natal Advertiser", "the Impaler", "The Little Foxes by Lillian Hellman", "the 1982 Sony SL-2000 portable", "Leonard Nimoy", "8/4 x 365 = 730 days", "1994", "the University of Arizona", "the title \"Marshal Dillon\"", "Wannabe\" and \"Say You'll Be There\"", "the Best Hotels on Bali: Legian Resort on Seminyak Beach; 2.", "The new nightspot Teddy's made this presidential Hollywood hotel a happening # Quiz # Question. 0:29", "LASER", "the Kids on a magical journey through this author's fairy tales on the Flying Trunk ride at Tivoli", "Jupiter", "the egret flower of the Far East - Botany Boy", "use the word \"non\" to indicate \"not\" it is", "Andrew Taggart, Emily Warren and Scott Harris", "use in a car", "American", "Enrique Torres"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5161039365579008}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.11764705882352941, 0.5, 1.0, 0.6666666666666665, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 0.2, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 0.5714285714285715, 0.48484848484848486, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4876", "mrqa_squad-validation-9357", "mrqa_squad-validation-10204", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-390", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2526", "mrqa_squad-validation-4157", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-4315", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.390625, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "a Turing machine operating in time f(n) that solves the problem", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans' Mercedes-Benz Superdome", "fell from his horse while hunting and died because of the injury", "the member state cannot enforce conflicting laws", "British bacteriologist J. F. D. Shrewsbury", "a mouth that can usually be closed by muscles; a pharynx (\"throat\")", "inversely to member state size", "Europe", "to help him leave Gospi\u0107 for Prague where he was to study", "a substantial number of colonies had been designed to provide economic profit and to ship resources to home ports in the seventeenth and eighteenth centuries", "$37.6 billion", "Kenyan athletes (particularly Kalenjin)", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "the Golden Gate Bridge", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau (1685)", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "ten million", "the Lippe", "HD channels and Video On Demand content", "time and storage", "four half-courses per term", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Nassau Herald", "the League of the Three Emperors", "the field of science awarded by universities in many countries", "143,007", "Bill Clinton", "Waltham Abbey, Essex", "Secretariat", "a type of Russian made RF connector", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.", "Thomas Christopher Ince", "American Choppers", "drawing the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy (TV series)", "Woolsthorpe-by-Colsterworth", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia and broadcast on ITV in the United Kingdom", "Br'er Rabbit or Brer Rabbit or Bruh Rabbit", "corruption", "a doctor still up and working after 24 hours", "Dover Beach"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7543342465677025}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666669, 1.0, 1.0, 0.6060606060606061, 0.9090909090909091, 1.0, 0.18181818181818182, 0.14814814814814817, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.75, 0.8571428571428571, 0.9523809523809523, 1.0, 1.0, 0.923076923076923, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5882352941176471, 0.0, 1.0, 0.2222222222222222, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-127", "mrqa_squad-validation-6218", "mrqa_squad-validation-4517", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-9928", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-2941", "mrqa_squad-validation-12", "mrqa_squad-validation-2865", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-5227", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-2315", "mrqa_naturalquestions-validation-1692", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.59375, "CSR": 0.6328125, "EFR": 1.0, "Overall": 0.81640625}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "courts of member states", "the dot", "three", "a negative long-term impact", "fear of their lives", "80", "1521", "Gibraltar and the \u00c5land islands", "a plant's free phosphate supply", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "to force certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "the Silk Road", "San Diego", "a German Nazi colonial administration", "the Council on Advanced Studies in the Social Sciences and Humanities", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural", "president and CEO", "indulgences for the living", "BSkyB", "a terrorist organisation", "Cam Newton", "U2", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "She has co-written twenty of Swift's officially-released songs and singles, including \"White Horse,\" \"Teardrops on My Guitar,\" and \"You Belong with Me", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "the Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp", "Thomas Henry Moray", "Toyota Grand Prix of Long Beach", "(IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk", "Charmed", "Cleopatra \" Cleo\" Demetriou", "Liverpool and England international player", "Oregon", "Rickie Lee Skaggs", "48,982", "the Ashanti Region", "73", "Algeria", "a Wall Street executive", "Biafra", "Polar", "Atlantic City"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7265000318309142}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9545454545454546, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.4, 1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-5213", "mrqa_squad-validation-8914", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_hotpotqa-validation-4317", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-226", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971"], "SR": 0.609375, "CSR": 0.6294642857142857, "EFR": 1.0, "Overall": 0.8147321428571428}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "the Duchy of Prussia, the Channel Islands, and Ireland", "the working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "solution", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "papacy", "homologous recombination", "a modern canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "northern", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "single-tape", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid ruler", "Perth", "Ian James Rush", "Gerry Adams", "New Orleans Saints", "1974", "four", "Harris Museum, Art Gallery & Preston Free Public Library", "A. E. Housman", "the capital of the Socialist Republic of Vietnam", "Sevens", "fennec", "Bart Conner", "fantasy role-playing game", "Martin McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Ray Looze", "140 to 219", "Father of Liberalism", "Christophe Lourdelet", "Pablo Escobar", "Afro-Russians", "Mexico City", "Sleeping Beauty", "Tomorrowland", "2006", "Noddy Goes To Toyland", "Omar Bongo", "Raphael Chex Cereal", "Ray Harroun", "Charlie's Angels", "David Tennant"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6996031746031746}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 0.8, 1.0, 0.0, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-3091", "mrqa_squad-validation-9287", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-1898", "mrqa_hotpotqa-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-3510", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.59375, "CSR": 0.625, "EFR": 0.9615384615384616, "Overall": 0.7932692307692308}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "radiant energy of \"invisible\" kinds", "arms", "two independent mechanisms", "minor", "Fringe or splinter", "17", "lower", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Han Chinese and Khitans", "bought prints for broadcast, or by private individuals who acquired them by various means", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "imp My Ride", "Don Johnson", "Good Kid, M.A.D City", "25 million", "8,515", "13 October 1958", "Avro Vulcan", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Ai-Ling Lee", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham, Greater London, England", "A55", "Ranulf de Gernon", "Olaf Guthfrithson", "West Tambaram", "44", "NCAA's Division I", "Harriet Tubman", "Crawley Town", "Dragon TV", "Greek-American", "diastema", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir\u00b4s", "Manchester"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7001736111111111}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-1501", "mrqa_squad-validation-3405", "mrqa_squad-validation-9859", "mrqa_squad-validation-8356", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-1423"], "SR": 0.609375, "CSR": 0.6232638888888888, "EFR": 1.0, "Overall": 0.8116319444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["$159 million", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules, which have paired electron spins; this prevents spontaneous combustion", "Edict of Fontainebleau", "Museum of the Moving Image in London", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "force and violence and refusal to submit to arrest", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin,", "a pivotal event in the Arab Muslim world", "transgender teenage girl", "John Alexander", "David Michael Bautista Jr.", "Thanksgiving Day", "American actor", "Prince Amedeo", "Lambic", "the port of Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "U.S. states of Kentucky, Virginia, and Tennessee", "Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marco Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "500 ft", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "79th Masters Tournament", "vocalist Kristoffer Rygg", "Sullivan University", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscous", "1.5 million", "morphine sulfate", "renoir", "renoir"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6283961993888465}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.88, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7173", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1061", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.546875, "CSR": 0.615625, "EFR": 0.9310344827586207, "Overall": 0.7733297413793103}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan Ecological and Historic Preserve", "Tesco store", "vertebrates", "Because of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Owen Daniels", "Anderson", "other greater inequality and potential economic instability", "Gamal Abdul Nasser", "immune responses beginning to decline at around 50 years of age due to immunosenescence", "counterflow", "John B. Goodenough, mathematician and Fields Medal recipient Paul Joseph Cohen, and geochemist Clair Cameron Patterson", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and the Daleks", "he was profoundly influenced by a math teacher Martin Sekuli\u0107.:32 The classes were held in German, as it was a school within the Austro-Hungarian Military Frontier", "a Standard Model", "Tolui", "Rhine-Ruhr region", "pedagogy", "It is that power which enables us to love and motivates us to seek a relationship with God through Jesus Christ", "Kansas State 52\u201321", "Gladstone Region, Queensland, Australia", "James T. Kirk", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The satirical news Network", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Naruto", "Tom Jones", "Russell Humphreys", "Barbara Niven (born February 26, 1953)", "13\u20133", "Eliot Spitzer", "5,042", "European culture", "Texas Instruments (TI)", "Tianhe Stadium", "1952", "the fourth Thursday", "William Shakespeare", "Germany", "New Jersey", "Bath, 1820", "Ector County, Texas, United States", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana and South Africa", "Heather Stebbins", "Caviar", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "the Comoros Islands off Africa", "Onomastic Sobriquets In The Food And Beverage Industry", "the bin"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5784895202843872}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.08, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.5, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.9600000000000001, 0.0, 1.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-5010", "mrqa_squad-validation-2032", "mrqa_squad-validation-940", "mrqa_squad-validation-7502", "mrqa_squad-validation-6495", "mrqa_squad-validation-8072", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_squad-validation-9803", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_hotpotqa-validation-1036", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-7415", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.46875, "CSR": 0.6022727272727273, "EFR": 1.0, "Overall": 0.8011363636363636}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "to pressure the lazy, inspire the bored, deflate the cocky", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "The climate is cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "second oil shock", "cytotoxic natural killer cells", "violence", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh and a small number of trains extended to Glasgow, Aberdeen and Inverness", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "$700 billion", "a planned training exercise designed to help the prince learn to fly in combat situations", "U.S. 93", "on the Ohio River near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "he still is involved with the talks, and that the power-sharing deal with the MDC offshoot is part of larger deal that has not been signed by anyone", "there's no evidence as to the cause of death,", "200", "a very small number of young people taking drugs", "a \"prostitute\" and threatening to oust another from his country.", "Missouri", "the case is closed", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a 'frat house for geeks'", "her home", "the Employee Free Choice act", "Bush administration", "a day after near-simultaneous bomb attacks in the ancient Indian city killed at least 63 people and wounded more than 200", "This is not a project for commercial gain", "their own", "Kaka", "Japanese ex-wife", "U.S. filmmakers", "near Fort Bragg in North Carolina", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "the singer", "Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "The truth was, that as she now stood excited, wild, and honest as the day", "Richmond", "1994", "The Conjuring", "the Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5887547676610176}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.0, 0.5, 0.4, 1.0, 0.0, 0.16216216216216217, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 0.15384615384615383, 0.8, 1.0, 0.0, 0.2727272727272727, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1919", "mrqa_squad-validation-3087", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-3637", "mrqa_squad-validation-6588", "mrqa_squad-validation-5287", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.4375, "CSR": 0.5885416666666667, "EFR": 1.0, "Overall": 0.7942708333333334}, {"timecode": 12, "before_eval_results": {"predictions": ["ignored the warning.", "more wealth than half of all Americans combined.", "every good work designed to attract God's favor", "Napoleon", "mass production", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation,", "1227", "lower lake", "three", "Elders", "587,000 square kilometres", "Private Bill Committees", "Mark Ronson", "the Catechism", "Stagg Field", "Ian Botham", "E. T. A. Hoffmann", "Vincent Motorcycle Company", "Frenchie", "C\u00e9sar Mendoza", "Harold Pinter", "Hawaii", "Jens Stoltenberg", "Apollon", "Pal Joey", "Mary Seacole", "green", "Indonesia", "Jesus", "Antonio Stradivari", "The EU", "Christine Keeler", "Hell", "Nicholson", "four", "Germany", "Sugar Baby Love", "Rosa Parks Bus", "Sean", "John Denver", "Stage 1", "Travis", "The Show", "Robert Kennedy", "Q is the only letter in the alphabet that does not appear in the name of any of the United States.", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "a French author", "barber", "Rod Laver", "Murrah Federal Office Building", "Evita", "oldpatricktoe-end", "a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Duchess Eleanor of Aquitaine", "Gilley's Club", "hardly ever", "a delegation of American Muslim and Christian leaders", "bath & his own son", "University of South Carolina", "Juan Martin Del Potro."], "metric_results": {"EM": 0.421875, "QA-F1": 0.49055059523809524}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10141", "mrqa_squad-validation-7458", "mrqa_squad-validation-2262", "mrqa_squad-validation-7974", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_squad-validation-670", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6727", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-7367", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120"], "SR": 0.421875, "CSR": 0.5757211538461539, "EFR": 0.9459459459459459, "Overall": 0.7608335498960499}, {"timecode": 13, "before_eval_results": {"predictions": ["Cram\u00e9r", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "anton", "moles", "phoebus", "Diego Garcia", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "salvador tatum", "one", "komando Pasukan Khusus", "the county in the northwest of England", "carbon dioxide", "zanesville", "julius Connors", "Antarctica", "julius gilding", "aniridia", "t.S. Eliot", "River Forth", "woe", "spider-Man", "julius", "salvador Mussolini", "Canada", "typhoid fever", "lady antonada", "salvador", "al Bundy", "2010", "einasto", "Venezuela", "fred stooge", "aaron", "40", "phrenology", "San Francisco", "Fall 1998", "Xanthippus", "Christopher James \" Chris Weidman", "Drillers Stadium", "one", "Cathay Pacific Airways", "julius phelan", "Administrative Professionals Day", "Iran", "Group E winners AS Roma in the last 32 of Europe's second-tier club competition."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5020833333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8994", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_hotpotqa-validation-1390", "mrqa_newsqa-validation-605", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-2281"], "SR": 0.46875, "CSR": 0.5680803571428572, "EFR": 1.0, "Overall": 0.7840401785714286}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically bonded to each other", "Aristotle", "St. George's Church", "Matt Smith", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "private citizen", "the most cost efficient bidder", "kung fu grip", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Olympia", "kung fu grip", "gaius caesar augustus thumpadori", "gaius caesar augustus germanicus", "kung fu grip", "amber", "andrew johnson", "The executioner's Song", "gaius caesar augustus germanicus", "kung fu grip", "anamosa's famous artist", "andrew johnson", "The Comedy of Errors", "gaius caesar kung fu grip", "gaius caesar", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Cologne", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Kosovo", "andrew johnson", "Paris", "tennis", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "andrew johnson", "gaius caesar augustus germanicus", "kung fu grip", "kung fu grip", "kung fu grip", "boogity", "gaius caesar germanicus", "andrew johnson", "gaius caesar augustus germanicus", "Augusta", "clockwise", "March 31, 2013", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama's", "goblin's Market", "kuntar"], "metric_results": {"EM": 0.328125, "QA-F1": 0.37916666666666665}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.1, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-3488", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-4647", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084", "mrqa_newsqa-validation-1406"], "SR": 0.328125, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "around 28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "Deabolis", "April 20", "the Gaulish name", "1996", "wine", "Switzerland", "Melbourne", "enter the priesthood", "the Seattle Seahawks", "IBM", "crossword", "Jerry Maguire", "Cleveland", "Flemish", "Mastercard", "General Motors Corporation", "Heinz Field", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "supplementary", "Kurt Russell", "Toronto Maple Leaf", "Zsa Zsa Gabor", "Vladimir Nemirovich-Danchenko", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "a fox", "pro bono", "Italy", "one", "a brown beer", "Anthony Fokker", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the hemlock", "Jeffrey Wigand", "poetry", "lettuce", "supplementary", "Casablanca", "supplementary", "the Bunsen burner", "a Geiko", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "Brandon Jennings", "a tin star", "noir", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.484375, "QA-F1": 0.575}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7041", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-10571", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-5713", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.484375, "CSR": 0.5478515625, "EFR": 1.0, "Overall": 0.77392578125}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "gaseous", "1997", "late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "military troops", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho Chi Minh", "circum", "the Inuit", "Detroit", "the (Montreal) Blue Jays", "Walt Whitman", "Ray Bradbury", "hate crimes", "Madagascar", "Nicolas Sarkozy", "Rubicon", "(Roger) Costello", "Six Flags", "(Louisa) May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The two went and stood side by side before a great mirror", "Crystal Pepsi", "Hillary Clinton", "King Philip", "(Roger) Bellerophon", "Balaam", "Wharton", "The Caine Mutiny", "100 Greatest Guitarists", "Biggly Wiggly supermarkets", "(John) Coltrane", "peace symbol", "oxygen", "the Sphinx", "Jan Hus", "Cowboy Troy", "the Mavericks", "Onegin", "Macy's", "a spinning machine", "Santa Claus", "(Roger) Antony", "a nurse", "the United Kingdom", "another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "(Cesar) Duarte", "( Brad) Blauser", "his salary", "the punishment"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5956330128205127}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-3785", "mrqa_squad-validation-1796", "mrqa_squad-validation-3132", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1759"], "SR": 0.515625, "CSR": 0.5459558823529411, "EFR": 0.967741935483871, "Overall": 0.7568489089184061}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "Curia Maior", "Stratigraphers", "trade unions", "94.1", "earn as much as a healthy young man;", "Centrum", "Robert Lane and Benjamin Vail", "Swezey", "the Orange Democratic Movement", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "The Crystal Method", "Puerto Rico", "The Mausoleum", "Million Dollar Baby", "preston", "The Viscounts", "The Old Man and the Sea", "French", "Joe Louis", "the lion", "The Three Musketeers", "the Bayeux Tapestry", "Porch", "Inner Mongolia", "Sunni", "notes", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "Blue", "Michael Moore", "Oman", "Chevy", "Ingenue", "Lake Erie", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "preston", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute", "the Boomerang soundtrack", "preston", "Bromley", "the Ruul", "Courage the Cowardly Dog", "a small child", "the Challenger", "\"Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "a nuclear weapon", "\"Three Little Beers,\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.5736019736842105}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2105263157894737, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-990", "mrqa_squad-validation-7273", "mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_squad-validation-8420", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-5971", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-7811", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-3449", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.53125, "CSR": 0.5451388888888888, "EFR": 1.0, "Overall": 0.7725694444444444}, {"timecode": 18, "before_eval_results": {"predictions": ["matching white pants", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "the mid-18th century", "orange", "A Raisin in the Sun", "Moses", "White Russia", "a flanker", "a trowel", "\"Big Bang\"", "the Monkees", "endodontist", "a bathtub", "Denmark", "Genoa", "Fanchette", "Jersey Boys", "a door", "Kansas", "Jaclyn Day", "six", "rice", "21", "the Civil", "Copeina arnoldi", "Paul McCartney", "omega-6", "\"Disputa\"", "TCOB", "horror", "Bill Murray", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "riverrun", "Wordsworth", "Norway", "Bear", "a tremors", "Judas", "an elephant", "Mazurek Dbrowskiego", "Sweden", "a covert operation", "\"All for Our Country\"", "May 2010", "Camp David", "a bay", "Thailand", "gender queer", "Minister for Social Protection", "Elster", "the home", "Robin Williams", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4876132246376811}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, true, false, true, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-11114", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-3343", "mrqa_naturalquestions-validation-2870"], "SR": 0.40625, "CSR": 0.537828947368421, "EFR": 0.9736842105263158, "Overall": 0.7557565789473684}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "Mars", "53,000", "one", "Israeli poet", "two", "20,000", "kip", "in skeletal muscle and the brain", "2014", "two peptide bonds", "the Ottawa Senators 7 - 4", "Saturday", "a zygote with n pairs of chromosomes", "volcanic activity", "Montgomery", "a speakeasy", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Captain Leland Stottlemeyer", "1991", "electron shells", "The Cornett family", "acid rain", "October 22, 2017", "unattainable", "he cheated on Miley", "2001", "democracy", "735 feet", "1871", "Lex Luger", "Toledo, Bowling Green, and Mount Union", "business network", "a cladding of a different glass, or plastic", "Abraham Gottlob Werner", "in Wakanda and the Savage Land", "unfair", "Necator americanus and Ancylostoma duodenale", "February 28 or March 1", "the Middle East", "the American Civil War", "an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "she eventually marry", "British and French Canadian fur traders", "semi-autonomous", "Lou Rawls", "Hermia", "Jupiter", "Europe", "15", "John Robert Cocker", "Israel", "video game", "a palace", "olfactory", "Eucalyptus", "a lionish mane", "oxygen"], "metric_results": {"EM": 0.390625, "QA-F1": 0.545220455606485}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.4, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.6666666666666666, 0.4705882352941177, 0.0, 0.1818181818181818, 0.0909090909090909, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_squad-validation-3581", "mrqa_squad-validation-880", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-1502", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-2379", "mrqa_searchqa-validation-12372", "mrqa_triviaqa-validation-2227"], "SR": 0.390625, "CSR": 0.53046875, "EFR": 0.9743589743589743, "Overall": 0.7524138621794871}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "Cloth of St Gereon", "Thomas Sowell", "more than 70 pioneers in science and engineering, including Albert Einstein", "celibacy", "His Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\"", "Jacob Zuma", "gang rape", "Florida", "7,000", "Wednesday", "201-2800", "different women coping with breast cancer", "1,000 pounds", "\"no need to fight the oppression of the former Mubarak regime.\"", "Saadi", "Texas", "Polo", "\"The Jacksons: A Family Dynasty\"", "Amstetten", "computer problems left travelers across the United States waiting in airports", "Silvan Shalom", "Jonathan Breeze", "Steve Jobs", "12-hour", "prisoners", "September", "consumer confidence", "5:20 p.m.", "North vs. South", "India", "1964", "Davidson", "Swat Valley", "month of three people with ties to the U.S. Consulate in Ciudad Juarez", "1979", "Kim Jong Il", "The Tom Joyner Morning Show", "Akio Toyoda", "\"There's no chance of it being open on time. Work has basically stopped.\"", "the immediate release into the United States of 17 Chinese Muslims", "Frank Rijkaard's squad.", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "adoption", "40", "\"Friday the 13th\"", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter festivals", "Pentecost", "Aberdeen", "\"Dumb and Dumber\"", "The Tigers", "Chief Justice Earl Warren", "a converging lens", "Etruscan root autu", "season six", "The Force Wars film in 1977"], "metric_results": {"EM": 0.375, "QA-F1": 0.48381028693528694}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.6153846153846153, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.923076923076923, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.20000000000000004]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-2757", "mrqa_squad-validation-2466", "mrqa_squad-validation-7937", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.375, "CSR": 0.5230654761904762, "EFR": 1.0, "Overall": 0.7615327380952381}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "San Diego-Carlsbad-San Marcos metropolitan area", "chief electrician position", "Newton", "the applied force is opposed by static friction, generated between the object and the table surface", "death of US President John F. Kennedy", "\"a common enemy to both countries.\"", "Winter Park at Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Awearness Fund", "on his land.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"mentally deranged person steeped in the inveterate enmity towards the system\" in the North.", "\"The View\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers program", "\"I'm certainly not nearly as good of a speaker as he is.\"", "9:20 p.m. ET Wednesday.", "Venus Williams", "Mashhad, Iran.", "Amanda Knox", "\"Mexican Venice,\"", "more than $17,000", "Barney Stinson,", "Luiz Inacio Lula da Silva", "father's parenting skills.", "two contestants.", "Bill,", "J.G. Ballard", "doctors", "Sarah,", "choosing for retirement long before his career neared its end.", "October 6, 1981", "\"17 Again,\"", "Nigeria", "$81,88010.", "Republicans", "EU naval force", "Allison Bridges", "son of Gabon's former president", "last running steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "skeletal dysplasia,", "London Heathrow's Terminal 5.", "strongly denied charges of racism after his club canceled the swimming privileges of a nearby day care center whose children are predominantly African-American.", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action", "the First Family", "Cliff's father, Russell Huxtable", "Willy Russell", "London", "\"Mortal Kombat X\"", "Northumbrian", "Ophelia", "Romania", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5639399662837162}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.25, 0.8, 1.0, 0.2666666666666667, 0.15384615384615383, 0.0, 0.4, 1.0, 0.0, 0.0, 0.5454545454545454, 0.42857142857142855, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.5, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-1285", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-4038", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1949", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-913", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-107"], "SR": 0.40625, "CSR": 0.5177556818181819, "EFR": 0.9736842105263158, "Overall": 0.7457199461722488}, {"timecode": 22, "before_eval_results": {"predictions": ["Tesla devised several experimental devils to produce X-rays.", "WMO Executive Council and UNEP Governing Council", "northern and southern Germans", "New York and Virginia", "two", "glowed even when turned off.", "a number of celebrities and ministers,", "scientists know about Earth's closest neighbor.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor,", "a federal judge in Mississippi", "\"is responsible for security on the streets,", "$22 million", "severe flooding", "music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewife of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Sachina Verma", "Larry King", "Steven Chu", "racially motivated.", "Marines", "male veterans", "longest domestic torch relay", "Harare.", "No. 1 slot", "four", "four bodies", "Friday,", "to be over a kilometer (3,281 feet) high.", "Rima Fakih", "Tuesday night", "CIA interrogators", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "brain signals", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning about tendon problems.", "84-year-old", "Kim Jong Il.", "Fakih", "paris", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "paris", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "The Cricket on the Hearth"], "metric_results": {"EM": 0.375, "QA-F1": 0.5179125280268183}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.3333333333333333, 0.22222222222222224, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.5, 0.19999999999999998, 0.23529411764705882, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 0.75, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-88", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-3239", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.375, "CSR": 0.5115489130434783, "EFR": 1.0, "Overall": 0.7557744565217391}, {"timecode": 23, "before_eval_results": {"predictions": ["chlorophyll a and phycobilins", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "19,600", "in Yemen,", "2005.", "Karen Floyd", "Four Americans", "the missing person,", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Omar bin Laden", "Jared Polis", "Janet and La Toya,", "Hyundai Steel", "30", "Michael Krane,", "lightning strikes", "Evans", "Sabina Guzzanti", "the flooding was so fast that the thing flipped over,\"", "threatening messages", "Christopher Savoie", "drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "\"Kambakkht Ishq,\"", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank,", "April", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani", "Zuma", "oldest documented bikinis -- haute, bandeau-style little numbers", "nine", "al-Maliki", "2000", "50", "15-year-old", "in body bags on the roadway near the bus,", "Trevor Rees and the back of Princess Diana's head", "Desmond Tutu", "$17,000", "Toy Story", "$81,880", "provide school districts with federal funds", "a spiritual conversion", "Jason Lee", "REM sleep", "nounA", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "The U.S. Founders and Cyrus the Great of Persia", "NASA Astronaut", "Florida"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5305071447649573}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.5, 0.0, 0.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0625, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.4, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-968", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-1876", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.46875, "CSR": 0.509765625, "EFR": 1.0, "Overall": 0.7548828125}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great.", "the Yuan dynasty", "manually suppress the fire.", "compound", "Nigeria", "American Lindsey Vonn", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "him to step down as majority leader.", "United Nations World Food Program", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "to best your own fuel economy achievements,\"", "1979", "one of its diplomats in northwest Pakistan", "jazz", "an antihistamine and an epinephrine", "Bangladesh,", "Michael Arrington,", "17 children under 3 years old in America", "U.N. High Commissioner for Refugees", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "\"I Dreamed a Dream,\"", "military personnel", "placed behind the counter.", "11", "one", "Michael Partain,", "her fianc\u00e9", "racial intolerance.", "a vegan diet to some of the flavorful foods they can eat.", "Carrillo Leyva", "the self-styled revolutionary Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "would compromise the public broadcaster's appearance of impartiality.", "it -- you know -- black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade after a new survey showed how the drug dominates Afghanistan's economy.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks,", "the coast of Dubai", "military veterans", "two Metro transit trains that crashed the day before,", "eight", "Mark Obama Ndesandjo", "the plus-sized.", "Russia, South Korea, China, South Africa, Brazil, Beirut and Poland.", "\"The Screening Room\"", "adultery,", "the control center of the cell", "Vienna", "a fictional team of Naval Criminal Investigative Service ( NCIS ) agents stationed out of New Orleans, Louisiana and led by Special Agent Dwayne Cassius Pride ( Scott Bakula )", "President Woodrow Wilson", "Tom Watson", "Sandi Toksvig", "The Spyker F1 Team", "prime minister", "Anaheim, California,", "Faxa Bay", "wedlock", "carbon"], "metric_results": {"EM": 0.375, "QA-F1": 0.5144720193341517}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4615384615384615, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.4, 0.11764705882352941, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.3076923076923077, 0.0, 0.05555555555555555, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.7499999999999999, 1.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 1.0, 0.08, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.14814814814814814, 0.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8428", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4128", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-970", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-13756"], "SR": 0.375, "CSR": 0.504375, "EFR": 1.0, "Overall": 0.7521875}, {"timecode": 25, "before_eval_results": {"predictions": ["\"theo-democracy,\"", "Treaty of Logstown", "Mario Addison", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "phylum Arthropoda", "jimmy carter", "Ub Iwerks", "England Cathedrals", "holography", "Pelias", "Daniel Boaventura", "Northumbria", "Yale", "cricket", "Seymour Hersh,", "quant", "copper and zinc", "the Tigris River", "Cordelia", "many kinds of publications that told both news and rumours.", "jimmy carter", "33", "Rh\u00f4ne Grape Varietal", "Joseph Smith", "Huntington Beach, California", "gold", "the moon", "13.", "jimmy carter", "The Apartment", "Canada", "Winston Churchill", "Stockholm", "Spider-Man", "Golda Meir", "Rodd & Gunn,", "bullfight", "\"The Number One Song in Heaven\"", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "Denver", "I run a specialized hotel and a telephone service which provides gentlemen with the company of a young lady,", "Marie Van Brittan Brown", "southern California", "1995", "Bourbon County", "Taylor Swift", "Rihanna", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "The Detroit, Michigan,", "Amy Bishop,", "calastrally", "the Louvre", "7300"], "metric_results": {"EM": 0.421875, "QA-F1": 0.47202818627450976}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.8, 0.9, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1764705882352941, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9661", "mrqa_squad-validation-825", "mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-6456", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-7678", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-6038", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.421875, "CSR": 0.5012019230769231, "EFR": 0.972972972972973, "Overall": 0.7370874480249481}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "peter park", "elephants", "charcoal", "mccourt", "jules Verne", "peter parker", "peter parker", "Schengen Area", "red", "city of chicago", "peter parker", "puckett", "Gerald Durrell", "jonathan", "Ireland", "jason", "mare", "Halifax", "Noises Off", "jonathan mccartney", "Frank Wilson", "peter parker", "Edwina Currie", "peter parker", "peter parker", "1768", "\u201cThe George Medal.", "woe", "chicago", "Montgomery", "The Good Life", "Tahrir Square", "osmium", "porthos", "27", "jason mccartney", "tintoretto", "peter parker", "Saudi Arabia", "peter parker", "Thailand", "Sydney", "peter parker", "Tunisia", "Prince Philip", "chicago", "Tokyo", "Edgar Lungu", "49 cents", "over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\"", "Stonecoast", "e-mail", "peter parker", "27,", "pym of nantucket", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4765625}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, false, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-736", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-354", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-1150", "mrqa_searchqa-validation-12829"], "SR": 0.4375, "CSR": 0.49884259259259256, "EFR": 0.9722222222222222, "Overall": 0.7355324074074074}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80 percent", "more than 70", "showed little interest in Tesla's ideas for new types of motors and electrical transmission equipment", "Benazir Bhutto", "nuclear program.", "Awa", "Starr", "Daniel Cain", "acid attack by a spurned suitor.", "Wally Island", "1993", "after Wood went missing off Catalina Island,", "she told Behar.", "Afghanistan", "Florida everglades", "dilshan scored his sixth Test century of a remarkable year to give Sri Lanka a fine start to the third match of their series against India in Mumbai", "1950s", "64,", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos", "$4.5 million", "as the new kid on the block in the modern art scene", "carbon neutral airline.", "Arizona", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "his injuries,", "Somali border town of Afmado", "booked on an outstanding arrest warrant relating to a domestic violence case,", "sustain future exploration of the moon and beyond.", "his business dealings", "Opry Mills", "#1", "attempting illegal crossings", "producers can't be ready in time for the July debut,", "al Qaeda", "jacob parker", "should have met with the Dalai Lama.", "oceans", "henie andrade was kept in this closet for three days without food or water,", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "December 23, 1942", "1923 and 1925", "gilda", "jacob parker", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire State Building", "The Philadelphia Story", "black"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5271164165695416}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.5714285714285715, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.375, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.22222222222222224, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.19047619047619047, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2233", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2051", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.421875, "CSR": 0.49609375, "EFR": 1.0, "Overall": 0.748046875}, {"timecode": 28, "before_eval_results": {"predictions": ["a high enough quality to host a Super Bowl", "25-foot", "manipulates symbols", "Hyundai", "Monday night", "Florida to Colorado", "kidnapping the children and concealing their identities.", "40", "brutalized", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "Commander Lee Archambault and his six crewmates", "World-renowned security expert Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "a belt of low pressure that wraps around the planet.", "simple puzzle video game,", "outside influences", "aid to Gaza,", "rolled over Tuesday near Campbellton, Texas, killing two people and injuring more than a dozen,", "suppress the memories and to live as normal a life as possible;", "February 2008", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Two UH-60 Blackhawk helicopters crashed in northeastern Baghdad as a result of clashes between U.S.-backed Iraqi forces and gunmen.", "Lucky Dube, one of South Africa's most famous musicians, was killed in an attempted car-jacking", "Cash for Clunkers program", "\"project work\"", "Kitty Kelley,", "80 percent of the woman's face", "London", "to try to make life a little easier for these families by organizing the distribution of wheelchairs,", "Ozzy Osbourne", "$50 less,", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "felony drug", "At least 38", "Argentine", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million people worldwide", "Two UH-60 Blackhawk helicopters collided Saturday night while landing in northern Baghdad,", "Rima Fakih", "Old Trafford", "to `` help bring creative projects to life ''", "season two", "Mary Elizabeth Patterson", "Riff is the leader of the Jets.", "The Fifth Amendment", "Nepal", "Merck Sharp & Dohme", "Fort Orange", "Knoxville, Tennessee", "Pandit Nehru", "a process called where plants release water vapor into the pores", "hypomanic"], "metric_results": {"EM": 0.328125, "QA-F1": 0.49944401752336187}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.4, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.13793103448275862, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-445", "mrqa_squad-validation-1789", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1341", "mrqa_newsqa-validation-1178", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-2380", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4004", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_hotpotqa-validation-2284", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.328125, "CSR": 0.49030172413793105, "EFR": 0.9767441860465116, "Overall": 0.7335229550922213}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "oxygen", "Betty Meggers", "Numa Pompilius", "Polk County, Florida", "Reproductive system", "August von Mackensen", "near the end of their main sequence lifetime", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "in the central plains", "al - Mamlakah al -", "Southport, North Carolina", "ancient Mesopotamia", "cleanmgr. exe", "July 4", "''", "Ann Doran", "to cross the world's oceans for centuries", "October 12, 1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "a Cadillac", "Shakur and `` Brenda ''", "a ranking used in combat sports,", "Husrev Pasha", "Jodie Sweetin", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii", "`` Rightly Guided Caliphs ''", "in Lake Powell", "a decorative ornament", "September 6, 2019", "Article One of the United States Constitution", "substitute good", "Marries Veronica", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh of the Indian National Congress", "a major worldwide economic downturn", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "Native American languages", "Donny Osmond", "Rome and Carthage", "\"George Bush Sr.\"", "GmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's", "Rickey Henderson", "Russia", "a stoner comedy film"], "metric_results": {"EM": 0.375, "QA-F1": 0.5480216803997553}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.1111111111111111, 0.5, 0.0, 0.5, 0.4, 0.8, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.1739130434782609, 0.4, 0.0, 0.0, 1.0, 0.0, 0.3846153846153846, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.4, 0.8, 0.0, 1.0, 1.0, 1.0, 0.13333333333333336, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.18181818181818182, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10678", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.375, "CSR": 0.4864583333333333, "EFR": 0.95, "Overall": 0.7182291666666667}, {"timecode": 30, "before_eval_results": {"predictions": ["a setup phase in each involved node before any packet is transferred to establish the parameters of communication", "Pleurobrachia.", "1953", "AT&T", "pioneers", "the Delaware Chingachgook,", "shoes", "nine", "Rashid Akmaev,", "acetylene", "'Archer' Jokes", "fiber", "fox's", "What's in a name", "Winston Rodney", "sand", "Nanjing", "Montana", "eric", "Louis XIV", "\"What a joy to breathe the balmy air of Grosvenor Square\"", "The Online Dolly Parton Newsmagazine", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "Florence Henderson", "Frida Kahlo", "John and Abigail Adams,", "\"Y\" 2 \"K\":", "\"Fat man, you shoot a great game of pool.\"", "Act I.", "William Randolph Hearst", "a pumice", "ale", "shrews", "a telephone operator", "Year 3000", "Casey Jones", "\"The New Colossus\"", "yelping", "Richard Wagner", "Princess Beatrice of York", "Mrs. Robinson", "\"Tom Terrific\"", "bronchoconstriction", "four", "fluorescent lights", "Minnesota", "3252 miles", "Earl Long", "Neil Patrick Harris", "Greg", "1999", "vitamin D", "three", "Alberto Juantorena", "Boyz II Men", "Awake", "Doctor of Philosophy", "Pakistan", "Atlanta", "Sonia Sotomayor"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5096765350877193}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false], "QA-F1": [0.052631578947368425, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-13464", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-7137", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-723"], "SR": 0.484375, "CSR": 0.4863911290322581, "EFR": 1.0, "Overall": 0.743195564516129}, {"timecode": 31, "before_eval_results": {"predictions": ["traditional Mongol shamans", "Prospect Park", "the Iago omanensis", "a volume", "a squint", "Breakfast at Tiffany", "Diners' Club", "Christian Dior", "The Pittsburgh Cycle", "Juliet", "Notre Dame", "the Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania", "Mike Huckabee", "Queen", "a Beta-blocker", "three", "a mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin", "Prince William", "Ugly Betty", "a R", "Zechariah", "New Jersey", "the Elbow River", "Matt LeBlanc", "Marissa Jaret Winokur", "John Ford", "a kismet", "Willy Wonka", "a battery", "a light-colored roof", "Mathew Brady", "Ned Kelly", "a piles of papers", "a gravitational force", "Isis", "a quiver", "Isaac Mendez", "on the two tablets", "a kidney into a patient with end - stage renal disease", "seven", "Planck", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Arsene Wenger", "in Las Vegas."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6098958333333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-8204", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-16714", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14678", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-16666", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.53125, "CSR": 0.48779296875, "EFR": 1.0, "Overall": 0.743896484375}, {"timecode": 32, "before_eval_results": {"predictions": ["in weight", "Fresno Street", "Black Death", "Elton John", "John Stuart Mill", "Oblivion", "CIA", "piano", "Rickey Henderson", "Jawaharlal Nehru", "carrots", "Alan Shepard", "Angkor Wat", "Canada", "Matteo Pericoli", "a quark", "The King Jesus Gospel", "Giuliani", "the First", "Virginia", "Thor", "Haddonfield", "The Omega Man", "a pantry", "a barrel", "the 1984 Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Dirty Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Tiger Woods", "Los Angeles", "the east wind", "King Edward", "Labour", "a pen", "Kansas", "Douglas Adams", "Celso", "Hawaii", "Herbert Waring", "France", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "The Queen of Hearts", "Part 1", "Roy Eberhardt moves to Florida and into the town of Coconut Cove,", "piano", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "Dale Steyn", "Ignazio La Russa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6356646825396826}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7777777777777778, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_squad-validation-4703", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-1755", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-5516", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-15655", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-4090"], "SR": 0.546875, "CSR": 0.48958333333333337, "EFR": 1.0, "Overall": 0.7447916666666667}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "immunity and the self/nonself vocabulary", "a pool of blood beneath his head.", "hours", "28", "back at work", "in Oxbow,", "201-262-2800", "opium", "\"wacko.\"", "Saturday", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "New Delhi, India", "the station", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "forgery and flying without a valid license,", "in a shooting that killed one soldier and wounded another at a Little Rock military recruiting center", "Cash for Clunkers", "environmental", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in", "a missile strike or confrontation between the two countries at sea.", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Brooklyn, New York,", "over 1000 square meters", "CNN", "no chance", "St. Louis, Missouri.", "gunmen who attacked several targets in Mumbai on November 26,", "in Washington,", "two", "William Shakespeare", "Symbionese Liberation Army", "a fracas in a nightclub bar in the north-western of England city", "two tickets to Italy on Expedia.", "Colombia", "a softer violet hue", "horses", "1981,", "Los Angeles", "16", "Pope Benedict XVI", "India", "NATO", "akkordeon", "President Thabo Mbeki", "the Ming dynasty", "the Holy Roman Empire", "2014 -- 15", "1919", "Javier Bardem", "Scotland", "a family of Portuguese descent", "\" Terry the Tomboy\"", "Araminta Ross", "Mrs. Potts", "a Chocolate Candies", "the peace"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5555533008658009}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.6363636363636365, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6585", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.484375, "CSR": 0.4894301470588235, "EFR": 1.0, "Overall": 0.7447150735294117}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "rights.", "nearly $2 billion", "Yemen,", "concerns expressed this week about a certain carrier based in Texas.", "nearly $2 billion", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spanish Davis Cup hero Fernando Verdasco,", "South African", "children of street cleaners and firefighters.", "\"Apprentice,\"", "$3 billion", "hardship for terminally ill patients and their caregivers.", "Honduran", "Brazil", "three different videos", "violence, food shortages and widespread drought", "Roy", "the WBO welterweight title", "sixth member of a Missouri family", "Amanda Knox\\'s aunt Janet Huff", "Steven Green exhibited clear symptoms of acute stress disorder in Iraq", "Demi Moore and Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday", "a lump in Henry\\'s nether regions was a cancerous tumors.", "20", "Matthew Fisher", "$1.5 million", "Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "J. Crew,", "returning combat veterans", "543", "The patient,", "Robert Gates", "Israel", "rural Tennessee.", "in critical condition", "Seoul", "Nicole", "Holding the Olympic medal she and her mom always wanted,", "next week.", "Adam Lambert", "MMS inspector general,", "early detection and helping other women cope with the disease.", "James Whitehouse,", "journalists and the flight crew will be freed,", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Bokm\u00e5l", "alcohol", "The Revenger\\'s Tragedy", "1754", "Black Elk", "Sandy Duncan", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5906465322871572}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.42857142857142855, 0.9090909090909091, 0.19999999999999998, 1.0, 0.2, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16, 1.0, 1.0, 0.5714285714285715, 0.3636363636363636, 0.5, 0.5714285714285714, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-2628", "mrqa_newsqa-validation-3213", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_searchqa-validation-16463", "mrqa_searchqa-validation-7879"], "SR": 0.484375, "CSR": 0.4892857142857143, "EFR": 1.0, "Overall": 0.7446428571428572}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "Islamic leadership position", "sap", "Malibu", "Sisyphus", "sound absorption", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "a drunken monster", "Purple", "the Black Sea", "The Battle of the Little Bighorn", "The United Society of Believers", "a bellwether", "Time and Free Will", "potato chip", "Boxer", "The Spiderwick Chronicles", "Mabel Harding", "Las Vegas", "The 8 Secrets of Dutch Kids,", "the Rose Bowl", "Norman Rockwell", "Henna", "light tunais", "Napa Valley", "Italy", "Washington, D.C.", "Atlanta", "the klezmer", "Japan", "The Original Soundtrack", "12 men", "Nancy Pelosi", "Art of French cooking", "Jupiter", "Sadat", "a maraschino cherry", "Grace Evans", "50 million", "Volitan Lionfish", "HIV", "Edwin", "Bonnie Aarons", "5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "a knit in time", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina,", "Raymond Thomas", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5782825630252101}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true], "QA-F1": [0.35294117647058826, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-15861", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-7041", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12977", "mrqa_searchqa-validation-12788", "mrqa_naturalquestions-validation-590", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-1965"], "SR": 0.46875, "CSR": 0.4887152777777778, "EFR": 1.0, "Overall": 0.7443576388888888}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia State Fossil", "definition", "silver", "Supernanny", "the Atlantic Ocean", "Cincinnati", "a mosque", "( Henry) Hudson", "a Peashooter", "dry ice", "Elihu Root", "Entourage", "sea snakes", "Philadelphia", "The Museum of Modern Art", "the unicorns", "The Confederates name Richmond, VA as the Confederate Capital.", "Russia", "(Jackie) Peabodys", "Hermann Hesse", "the Taj Mittal", "a mnemonic device", "Carmen", "Margaret Mitchell", "(Mary) Frollo", "Sultans of Swing", "Troilus", "a cheerful sight", "(Burt) Reynolds", "the Sphinx", "( Louis) Armstrong", "Mecca", "The New Wave band", "Arby\\'s Restaurant Group", "coffee", "one", "(Robert) Burns", "The Incredible Hulk", "Atlanta", "the Memphis Belle", "Burkina Faso", "the Central Pacific Railroad", "Attorney General", "Icelandic", "a cattalo", "(Mary) Williamson", "Piaf", "Ivan the Terrible", "a poem", "roofing material", "an investor couple", "Jack Gleeson", "(Phil) Hurtt", "animals", "Massachusetts", "The Eastern Bloc", "Charles Laughton", "1987", "Democratic National Convention", "a meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5839285714285714}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-2572", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-3131", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-2683", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-1409", "mrqa_searchqa-validation-5571", "mrqa_searchqa-validation-14328", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_hotpotqa-validation-2000", "mrqa_hotpotqa-validation-5726", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-3951"], "SR": 0.5, "CSR": 0.4890202702702703, "EFR": 1.0, "Overall": 0.7445101351351351}, {"timecode": 37, "before_eval_results": {"predictions": ["Switzerland", "Impressionist", "KFC", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "1927", "Eritrea", "Pi", "tin", "the Mississippi River", "Clark Griswold", "the longest monosyllabic", "Marriott", "Kimpton Hotel", "Canada", "the Secret", "the Solomon Islands", "collagen", "China", "a compound", "the warblers", "a claw", "Alzheimer", "the Gulf of Mexico", "Stephen F. Austin", "a axiomatic system", "Evita", "Cain", "Ed Asner", "X- men", "the Louvre", "Alaskan", "Prison Break", "Mercury", "Maine", "sheep\\'s", "Meg", "two strings", "a deuce", "Hans Christian Andersen", "Peter Bogdanovich", "Barry White", "Jerusalem", "the improvidence of society itself", "the Huronian Ice Age", "nolo contendere", "Earl Bostie", "Prague", "Chicken of the Sea", "a strong move in Congress to limit the workweek to 30 hours", "Lucas McCain", "beta", "France", "Priam", "Mariette", "Ike Barinholtz", "Aron Ralston", "Australian", "the sins of the members of the church,", "$22 million", "\"Zac Efron,\"", "Nelson County"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5567708333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-6998", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-6997", "mrqa_naturalquestions-validation-2918", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-1824", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_newsqa-validation-1527"], "SR": 0.515625, "CSR": 0.48972039473684215, "EFR": 1.0, "Overall": 0.744860197368421}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospirosis", "a recession", "a fishtail skirt", "Jay Silverheels", "Singapore", "M1 Abrams", "brushes", "ferry", "Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Henry Gibson", "phylum", "Spain", "the brain", "Lord Jim", "Macbeth", "comedy", "Mary Poppins", "Casowasco", "The Fresh Prince of Bel-Air", "Nod", "watermelon", "paddle the baby out with the bathwater", "a wedding dress", "Livin", "Sherlock Holmes", "a milkshake", "Marie Antoinette", "Ford", "Marie Curie", "Roger B. Taney", "diagonals", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Harry Potter", "pyrolusite", "forests", "Olympia", "Allsup", "The Bridge on the River Kwai", "Brazil", "British", "Sydney Pollack", "copple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "different levels of importance of human psychological and physical needs", "one", "Fraser Island", "the Wright brothers", "sexual activity", "Sam ticker", "Sandro Bondi", "voluntary manslaughter", "\"trust in God's promises.\"", "Pygmalion"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6171770631329454}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.11764705882352941, 1.0, 0.07692307692307693, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_searchqa-validation-402", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_hotpotqa-validation-2005", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.53125, "CSR": 0.4907852564102564, "EFR": 1.0, "Overall": 0.7453926282051282}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "\"Boogie Woogie Bugle Boy\"", "Rome", "Charlton Heston", "Glory", "\"Cabaret\"", "The Bridge on the River Kwai", "the Fall of Constantinople", "Havisham", "Jefferson Davis", "Ford Madox Ford", "a delta", "a toothpick", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking through research and analysis", "Warren Harding", "a pattern", "Shue", "Francis Crick", "Jay and Silent Bob", "Heath", "South Ossetia", "\"VIOLA\"", "Hawaii", "a wrench", "Tito", "tSN", "Ratatouille", "inter-individual", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "a river", "Andrew Johnson", "26", "life", "a herb", "the endgame", "garbage out", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Constantinople", "precipitation", "Led Zeppelin", "a Tesla coil", "Denmark", "Anna Murphy", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "Mrs. Graham", "Bob Dole", "Ben Kingsely", "managing his time"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5264136904761905}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-459", "mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-16349", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11929", "mrqa_searchqa-validation-8155", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-4452", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11250", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.484375, "CSR": 0.490625, "EFR": 1.0, "Overall": 0.7453125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "horror", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "Flavivirus", "Sarah Newlin", "1934", "a record of 13\u20133", "We Need a Little Christmas", "Panthera leo melanochaita", "the New York Islanders", "1345", "nearly 80 years", "Jean Acker", "the Premier League", "The Gettysburg Address", "Whitney Houston", "the Premier League club Manchester United and the England national team", "Stravinsky\\'s \"The Rite of Spring\"", "1", "26,000", "Kristin Scott Thomas", "Edwin Mah Lee", "1958", "1993", "American burlesque", "Afro-Russian", "Loretta Lynn", "England", "the B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "he won the 2009 FINA World Championionship in the individual event at the age of 15,", "1994", "Overland Park", "The Second City", "Pinellas County", "beer", "Fulham", "the B-17 Flying Fortress", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mason Alan Dinehart", "an astonished Golde", "Sir Tom Finney", "the Central African Republic", "most high potential to be exposed to blood borne diseases and contaminants,", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "most like, \"Whatever!\"", "the Mayor of Casterbridge", "Leonardo DiCaprio", "a kiss - off to a manic ex-lover who did the protagonist wrong,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6575980392156863}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 0.0, 1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-2352", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_naturalquestions-validation-6326"], "SR": 0.578125, "CSR": 0.49275914634146345, "EFR": 1.0, "Overall": 0.7463795731707317}, {"timecode": 41, "before_eval_results": {"predictions": ["an early lead in Super Bowl 50", "10", "did not identify any of the dead.", "France", "2005.", "more than 4,000", "Arlen Specter", "taking place near the Champs de Mars,", "normal maritime", "Sri Lanka", "death of a pregnant soldier", "an average of 25 percent", "fatally shooting a limo driver", "The Al Nisr Al Saudi", "as", "piano", "$250,000", "a \"prostitute\" and threatening to oust another from his country.", "Zed\\'s fossil", "tax", "Los Ticos", "some three months before the crimes \"had the answers in front of her", "President Bush", "It will join Facebook and Google,", "Salt Lake City, Utah,", "Manmohan Singh's Congress party,", "Haiti", "Tuesday afternoon.", "Pakistan", "last 23 years.", "taking Morgan into the emergency room", "Tim Cahill scored twice as Australia came from a free kick in the section.", "an open window", "Leo Frank", "Paul McCartney and Ringo Starr", "taking risk to try to get to the U.S.", "President Robert Mugabe intends to rig", "free", "as adults", "100,000 British pounds ($161,000)", "on Sunday when on-loan David Beckham claimed his first goal in Italian football.", "He is more American than German.", "\"Twilight\"", "forgery and flying without a valid license,", "11,", "A third beluga whale belonging to the world's largest aquarium has died,", "Authorities in Fayetteville, North Carolina,", "The plane had a crew of 14 people and was carrying an additional 98 passengers,", "an endless war in Afghanistan.", "North Korea", "Rihanna", "radius R of the turntable", "from the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "B-24 Liberator", "Super Sugar Crisp", "Town of Islip", "Melbourne", "Guillermo del Toro", "Wall Street", "Monty Python", "Gustav I Vasa", "FMCSA"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4882733585858586}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.16666666666666669, 0.0, 0.0, 0.14285714285714288, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 0.21428571428571427, 0.0, 0.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-1227", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-2263", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-2414", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_hotpotqa-validation-2004", "mrqa_searchqa-validation-2346", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-1519", "mrqa_searchqa-validation-10945"], "SR": 0.34375, "CSR": 0.48921130952380953, "EFR": 1.0, "Overall": 0.7446056547619048}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona.", "Zimbabwe,", "Italian Serie A title", "Darrel Mohler", "dancing against a stripper's pole.", "\"Michoacan Family,\"", "WTA Tour titles", "MDC head Morgan Tsvangirai.", "42 years old", "She crafts poems telling of the pain and suffering of children just like her", "either stay home (which might be less depressing and won't add more airline emissions) or get a move on it and see the hot spots you just can't miss.", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CNN's Campbell Brown", "auxiliary lock", "1-1", "\"underwear bomber\"", "Myanmar", "authorities", "Marcus Schrenker,", "The U.S. Embassy in Manila on Monday confirmed Lunsmann's release in Basilan after she was held hostage by a still unidentified group of bandits.", "poems", "the program was made with the parents' full consent.", "Sen. Barack Obama", "The agencies", "Russia", "debris", "\"Can I just say how pleased I am with today's", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award.", "state senators", "31 meters (102 feet)", "nude beaches.", "about women and breast cancer.", "The father of", "shark River Park in Monmouth County", "three", "Islamabad", "partying", "Capitol Hill,", "Israel will not tolerate a nuclear weapon", "1940's", "March 22,", "think about saving the rainforests", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist\"", "World War II", "John Adams and Benjamin Franklin", "Jeff East", "Orion", "brown", "Selfie", "23 March 1991", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6629910714285714}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9600000000000001, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.5, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-932", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1297", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-6789", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.578125, "CSR": 0.49127906976744184, "EFR": 1.0, "Overall": 0.7456395348837209}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "the legitimacy of that race.", "28 of them", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain,", "Former detainees", "33-year-old man", "cast doubt on Woodward's assertion Tuesday in a conversation with \"American Morning\" host John Roberts.", "hardship for terminally ill patients and their caregivers,", "Araceli Valencia,", "Zac Efron", "finance", "$2 billion", "pesos", "1937,", "The station", "Karthik Rajaram,", "Arkansas weatherman", "Robert Mugabe", "Jenny Sanford,", "Afghanistan's", "Saturday.", "$1.5 million", "arrested online activists in an effort to stop the spread of dissenting information and opinions,\"", "could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Dangjin", "100 percent", "Saturday about 20 feet above flood stage.", "in Afghanistan,", "prisoners at the South Dakota State Penitentiary", "Seven", "200", "Pakistan", "Seminole", "Rima Fakih", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama's", "requested helicopters and unmanned aerial vehicles from the White House", "Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "104 feet long and 95 feet wide at the alcove.", "the second time", "Hamas", "54 bodies", "most tragic day in Binghamton,", "$50", "$60 billion on America's infrastructure.", "a new gene,", "Malayalam Odakkuzhal", "Mad - Eye Moody and Hedwig", "1964", "Villa Park", "\"the international peasant movement\"", "pool", "2010", "The Dressmaker", "Trilochanapala", "frosted", "a buffalo", "a whiter", "the parietal"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5653248076651609}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.125, 0.08695652173913043, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.25, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.7142857142857143, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.5714285714285715, 0.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2634", "mrqa_newsqa-validation-2642", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_newsqa-validation-228", "mrqa_naturalquestions-validation-6662", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2513", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.40625, "CSR": 0.48934659090909094, "EFR": 1.0, "Overall": 0.7446732954545454}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Duval County, Florida", "Benj Pasek", "Andes", "1952", "Angola", "19th-century", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Highlands", "Franconia, New Hampshire", "The Guadalcanal Campaign", "Dan Crow", "\"War & Peace\"", "Amberley", "the early 19th century", "Berea College", "2006", "Timoth\u00e9e Chalamet", "Charmian Anne Farnon", "Germany and other parts of Central Europe", "New York Islanders", "Amy Lysle Smart", "26,788", "the ethno-nationalist conflict in Northern Ireland known as the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "Edward Anthony Spitzka", "Ford", "divine punishment", "India", "Lutheranism", "\"Charmed\"", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "\"I'm Shipping Up to Boston\"", "American", "Jai McDowall", "a culturally distinct core area", "Australia", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "in Fayetteville, North Carolina,", "Chaucer", "rattlesnake", "first", "early to rise"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5442708333333333}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-4325", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.46875, "CSR": 0.48888888888888893, "EFR": 1.0, "Overall": 0.7444444444444445}, {"timecode": 45, "before_eval_results": {"predictions": ["De Angelo Williams", "with murder in the beating death of a company boss who fired them.", "the Indian Ocean waters near the Gulf of Aden,", "three", "crocodile eggs", "Colorado prosecutor", "the 2nd District of Utah.", "on Saturday.", "Haiti", "in July", "to sniff out cell phones", "the shoreline of the city of Quebradillas.", "Sharon Bialek", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "the Brundell family", "nearly $106.5 million", "low-calorie meals", "Heshmatollah Attarzadeh", "in the minds of millions.", "women", "Nine out of 10 children", "police", "Raymond Soeoth of Indonesia and Amadou Diouf of Senegal in West Africa,", "the jaws of a crocodile", "She wasn't the best \"coach,\" and she was kind of picky, but she had such a good eye,", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers.", "Obama's", "King Birendra,", "as belonging to missing Florida toddler Caylee Anthony,", "Caylee Anthony's", "Mandi Hamlin --", "Arnoldo Rueda Medina.", "UNICEF", "the pregnancy.", "228", "Kerstin and two of her brothers,", "2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "secession was slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "Lynne", "liberales", "Enid Blyton", "Johnny Mathis", "The Nutty Professor", "Champion Jockey", "Luca Guadagnino", "Sleepy Brown", "the Caged bird", "the shortest month of the year", "a jigger", "unarmed"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5656382095410628}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.625, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 0.08695652173913045, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-208", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-2600", "mrqa_newsqa-validation-898", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.484375, "CSR": 0.4887907608695652, "EFR": 1.0, "Overall": 0.7443953804347826}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\"Woz,\"", "without bail and will be arraigned June 25,", "12.3 million", "Mexico", "United", "Vivek Wadhwa,", "Brett Cummins,", "\"minimum collateral damage to property,\"", "Saturday", "Nicole", "legitimacy of that race.", "Adidas,", "Dennis Davern,", "Africa.", "American", "bartering -- trading goods and services without exchanging money --", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "forged credit cards and identity theft", "June 6, 1944,", "government", "81st minute", "October 19,", "\"It was a wrong thing to say,", "in Seoul,", "fuel economy and safety", "ALS6,", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback forest", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38,", "Her husband and attorney, James Whitehouse,", "schools.", "one of five Lebanese", "the most gigantic pumpkins in the world,", "cancer,", "two", "Schoenberg 1975, 218 ; Anon. n.d. ), or dodecaphony", "Brooklyn, New York", "Jean Fernel", "vorkosigan", "Japan", "fox hunting", "New York", "travel", "16,116", "\"Thank You for Smoking\"", "sugar", "bumblebee", "Sabrina Carpenter"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6545322785592816}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.9090909090909091, 0.6666666666666666, 0.11764705882352941, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_naturalquestions-validation-10525", "mrqa_triviaqa-validation-1729", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573", "mrqa_hotpotqa-validation-664"], "SR": 0.59375, "CSR": 0.4910239361702128, "EFR": 1.0, "Overall": 0.7455119680851063}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Wilmette, Illinois", "\"The Ones Who Walk away from Omelas\"", "teenage", "American politician, sociologist, and diplomat", "Midnight Oil", "Chris DeStefano", "I-League", "two or three", "The Iveys", "Lady Frederick Windsor", "animal", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930", "5,112", "1979", "retail, office and residential", "14,677", "6'5\"", "Mickey Gilley", "relations", "a puppy", "Mexican", "December 24, 1973", "1933", "a north-south state highway", "Kristoffer Rygg", "1733\u20131811", "London", "the Salzburg Festival", "McComb, Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Steven Vincent Buscemi", "oratorio", "Bunker Hill", "lion", "Royal", "World War II", "Knoxville", "\"Three's Company\"", "Dessa, Cecil Otter, P.O.S, Sims, Mike Mictlan, Paper Tiger, and Lazerbeak", "Labour Party", "Linda McCartney's Sixties: Portrait of an Era", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Farlake", "Mt Kenya", "Aung San Suu Kyi", "NATO's International Security Assistance Force", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "house of Representatives", "Lehman Bros International"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5525320165945166}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.16666666666666669, 0.6666666666666666, 0.3636363636363636, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1874", "mrqa_hotpotqa-validation-3162", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-2757", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-1466", "mrqa_hotpotqa-validation-4643", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-3238", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.453125, "CSR": 0.490234375, "EFR": 1.0, "Overall": 0.7451171875}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "Helsinki", "gari", "a offensive", "Vulcan", "the hexameters", "Fawn Hall", "waived all privileges", "Wanda", "Barnum & Bailey", "Johnny Weissmuller", "cathode", "a torque knife", "gold", "Marlon Brando", "Middle High German", "Renoir, Degas", "Kentucky Wildcats", "ruddy", "Brussels", "Mairghread Scott", "General Lee", "$18.2 billion", "Fyodor Dostoevsky", "Martin Luther's", "Clue", "Sir Arthur Conan Doyle", "German", "Abraham Lincoln", "the seventh year", "Mike Connors", "Tarzan's Desert Mystery", "Joe Biden", "sancire", "Corpus Christi", "Nigeria", "an ostrich", "a preamble", "the 8-hour", "Helen Keller's", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a strike", "the lance", "West Virginia", "James Madison", "movie theater", "Citation", "kritikos", "Khrushchev", "1904", "Maganlal Daiya", "Frank Saul", "ambidextrous", "chariot", "Humberside Airport", "265 million", "100 million", "social Security program", "head injury.", "Pope Benedict XVI", "Charles II"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5468276515151516}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-3474", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-6010", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-1805", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.484375, "CSR": 0.4901147959183674, "EFR": 1.0, "Overall": 0.7450573979591837}, {"timecode": 49, "before_eval_results": {"predictions": ["NSA", "the Heisman", "Brandi Chastain", "the Colorado River", "(P.J.) Parker", "carioca", "Treasure Island", "Pocahontas", "improvisation", "(Whizzer) White", "an octave", "an aerosol", "a magnum opus", "Ferris B Mueller's", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "a draft horse", "Ernest Lawrence", "a rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "the small intestine", "a mouthpiece", "Key West", "Sam", "Olivia Newton-John", "scalpels", "Manhattan", "February 2", "Leontyne Price", "a fertilizer", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "(Stephen) Bradshaw", "a dang'rous spring", "Paris", "a burnoose", "Philadelphia", "peanut butter", "Edgar Allan Poe", "leather", "Lex Luthor", "food and clothing", "( Schwarzenegger)", "Master Christopher Jones", "Hebrew", "a lack of atmosphere in the ground", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "the incident Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her;", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.6059027777777779}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.53125, "CSR": 0.4909375, "EFR": 0.9666666666666667, "Overall": 0.7288020833333333}, {"timecode": 50, "UKR": 0.666015625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.8359375, "KG": 0.4640625, "before_eval_results": {"predictions": ["Fatih Ozmen", "850", "Skyscraper", "a Corvette", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "1987", "Hilo", "Robert Downey, Jr.", "Continental AG", "band director", "Visigoths", "Mark Twain Riverboat", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "Guggenheim Partners", "19th-century", "Lady Antebellum", "Stratfor", "vice president", "Tottenham Hotspur", "1958", "Vixen", "Forbidden Quest", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Mark Twain", "The Spectator", "Adelaide Lightning", "Operation Neptune", "Walter R\u00f6hrl", "\"Lonely\"", "ten", "The Lion Guard", "Bologna", "an institution of higher education in the United States designated by a state to receive the benefits of the Morrill Acts of 1862 and 1890.", "Indooroopilly Shoppingtown", "2008", "Matt Flynn", "American", "hamburgers", "England", "very thin variety of Italian pasta", "Luigi Segre", "the House of Representatives", "February 16, 2018", "R2E Micral", "Nacio Herb Brown", "Michael Hart", "Precambrian", "Mull", "his death cast a shadow over festivities", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "tracheotomy", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.359375, "QA-F1": 0.46725035919540225}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6206896551724138, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4200", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1417", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-3352", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-7101", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-13015"], "SR": 0.359375, "CSR": 0.48835784313725494, "EFR": 1.0, "Overall": 0.6908746936274509}, {"timecode": 51, "before_eval_results": {"predictions": ["1898", "a cigar store Indian or wooden Indian", "Of Apollonius and Silla", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Kekaaniau", "Gothic Revival mansion", "Rochester", "J. Robert Oppenheimer", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "\u00c6nima", "the Wikimedia Foundation", "Flashback", "ARY Digital Network", "2001", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "February 21, 1961", "Rochdale", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Robert Sargent Shriver", "No. 17 and 35", "American Mark Donohue", "Peach", "German", "Richard Price", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "Nazi Germany", "Separate Tables", "the Celtic Sea", "devonian", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award.", "last week,", "Jean Lafitte", "hunter sauce", "devonian", "carbon"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6217955221861472}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-5442", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-2654", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-5493", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-4525", "mrqa_hotpotqa-validation-2206", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.53125, "CSR": 0.4891826923076923, "EFR": 1.0, "Overall": 0.6910396634615384}, {"timecode": 52, "before_eval_results": {"predictions": ["My ntonia", "King Henry VIII", "lead", "the Rose Bowl", "a Boeing 747 airliner", "amber", "Denmark", "terriers", "The Waves", "Earth", "freestyle", "dutchcharts", "cancer", "Stargate SG-1", "Lou Reed", "Stonewall Jackson", "northern Norway", "Emma Peel", "canvas", "ferns", "The X-Files", "Frankie Muniz", "Ocean Life", "Lake Superior", "January 4, 1809", "kinetic", "Santera", "Jonathan Livingston Seagull", "freedom", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "Zeus", "All That Jazz", "Ankara", "condensation", "eight", "Henry", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Like Water for Chocolate", "NigerCongo languages", "Applebee's", "John Tyler", "Daniel Craig", "humility", "computer programming", "Norway", "A footling breech", "when mixing solvents or changing their temperature", "The Yellow Rolls-Royce", "Bristol", "tax", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert,", "1961", "the equator", "the clothes we make for the runway", "fake his own death by crashing his private plane into a Florida swamp.", "The National Railway Museum"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5633184523809524}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, true, false], "QA-F1": [0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-4668", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-16018", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-16650", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-3526", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.515625, "CSR": 0.48968160377358494, "EFR": 1.0, "Overall": 0.691139445754717}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Neil Young", "After Shawn's kidnapping", "manage the characteristics of the beer's head", "a cocoon made of shed skin and mucus", "the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "birch", "in place on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Andy Cole and Shearer", "season two", "the human genome", "maintains a global crowdfunding platform focused on creativity and merchandising", "the most comfortable climatic conditions of the year", "David Motl", "the Catholic Monarchs of Castile and Aragon", "Madison, Wisconsin", "December 19, 1971", "the season", "Gustav Bauer", "a primary source of food for many organisms on estuaries, including bacteria", "observing the magnetic stripe `` anomaly '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "a dromedary", "13", "the five - year time jump", "a compound sentence", "Halliwell, French, Timomatic and Sandilands", "the Coriolis force", "the five - year time jump", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the host community", "Jethalal Gada", "over 74", "a small yellow sign under the main warning sign, as well as a standalone variation on the standard speed limit sign", "the gastrointestinal tract, oral passage, breast, lung, salivary glands, eye, and skin", "a noble gas", "as of 2000", "four", "Janie Crawford", "Justin Timberlake", "In their first appearance, The Tenth Planet ( 1966 ), they are explained as being the product of humans from Earth's nearly identical `` twin planet '' of Mondas", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Charles Strickland", "USA Today serving as its", "creeks,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "the Unity Summit of Latin America and the Caribbean", "off the coast of", "the Northwest Territories", "Anton Chekhov", "a benjamin", "the death of a pregnant soldier whose body was found Saturday morning in a motel,"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5752571385335511}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 0.10526315789473685, 0.6666666666666666, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 0.9411764705882353, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.21428571428571427, 0.6470588235294118, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.23076923076923078, 0.3076923076923077, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-3243", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-8459", "mrqa_newsqa-validation-2516"], "SR": 0.4375, "CSR": 0.4887152777777778, "EFR": 0.9444444444444444, "Overall": 0.6798350694444444}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues", "Mexican cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices", "George Harrison", "the Elk and Kanawha Rivers", "1803", "the heads of federal executive departments", "3000 BC", "a password recovery tool for Microsoft Windows", "``On season 1's `` A Telling Silence, '' Jack finds a basset hound whom he names Rip ( after Rip Van Winkle )", "Western Australia", "Buffalo Bill", "May 3, 2005", "Ellen is restored to life and is married to Bobby", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "a judicial officer, of a lower or puisne court", "the four principal phases of the Moon are new moon, first quarter, full moon, and third quarter ( also known as last quarter )", "Jeff East", "Charlene Holt", "December 1, 1969", "September 15, 2012", "covers heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Beyonc\u00e9", "Arkansas", "Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "Secretary of Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "a yolk sac with a diameter of 28 mm", "741 weeks", "Southern Rhodesia", "Lugano", "Sarah Palin", "Tampa", "the Japanese conquest of Burma", "kitty Hawk", "Starr", "the ship of", "Prague was \"wow.\"", "Tater Tots", "Yemen", "quod erat", "Daltons"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5512725402661065}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.058823529411764705, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09523809523809525, 1.0, 1.0, 0.0, 0.3333333333333333, 0.875, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-9091", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-940", "mrqa_hotpotqa-validation-1265", "mrqa_newsqa-validation-2127", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593"], "SR": 0.453125, "CSR": 0.4880681818181818, "EFR": 0.9142857142857143, "Overall": 0.6736739042207792}, {"timecode": 55, "before_eval_results": {"predictions": ["11 : 15 p.m.", "John Barry", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "the sex organs, such as ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis", "Peter Andrew Beardsley MBE", "USS Chesapeake", "Celtic", "Columbia River Gorge in the U.S. states of Oregon and Washington", "the Northeast Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "forests and animals", "the poverty threshold for a single person under 65 was an annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "`` Product / market fit means being in a good market with a product that can satisfy a problem or need that exists", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque", "Ernest Rutherford", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "a strong, weight transferral synovial plane joint", "png HTTP / 1.1", "the Brewster family", "1 mile ( 1.6 km )", "pop ballad written by Bob Thiele ( as `` George Douglas '' ) and George David Weiss", "8 December 1985", "during meiosis", "21 June 2007", "Arnold Schoenberg", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "Exodus and Deuteronomy", "a teenage porcupine punk rocker", "a multinational chain of full service", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outermost layer of human skin is composed of dead stratified squamous, keratinized epithelial cells", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Tom Thornton", "Ferrari driver Sebastian Vettel", "the men's National Collegiate Athletic Association ( NCAA ) Division I college basketball national champion for the 2017 -- 18 season", "the Sun Harvester", "biological taxonomy", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Tevin Campbell", "My Big Fat Gypsy fitness DVD", "Roger Casement", "Robert Lloyd", "Oxford, UK", "Robert Jenrick of the Conservative Party", "Robert Matthew Hurley", "urging more help for military members, especially for those returning from war.", "five", "\"The Closer.\"", "london", "Madonna", "Eiffel Tower", "Teddy Riley"], "metric_results": {"EM": 0.359375, "QA-F1": 0.48761641314357157}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.0, 0.47058823529411764, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.5714285714285715, 1.0, 0.0, 0.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 0.8, 0.25, 0.0, 0.0, 1.0, 0.2666666666666667, 1.0, 0.5714285714285715, 0.0, 1.0, 0.7878787878787877, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16, 0.0, 0.1290322580645161, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.09523809523809522, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-8719", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-3008", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-5371", "mrqa_hotpotqa-validation-2296", "mrqa_newsqa-validation-1887", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136"], "SR": 0.359375, "CSR": 0.4857700892857143, "EFR": 0.975609756097561, "Overall": 0.6854790940766551}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "Raghuwanshi dynasty", "16", "1877", "1999", "Manchester United Football Club", "Tami Lynn", "lines placed in an upright triangle", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Marcus Aurelius", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "the Dutch", "4 September 1936", "oxidized", "1940", "Authority", "April 1st", "DJ Lance Rock", "noon Eastern Time", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "negative affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Andrea Lamas", "Walter Pauk", "1980", "the septum", "Gentry Buddhism", "the foreign exchange market", "18", "Sir Ernest Rutherford", "Tabitha and Napoleon", "mid - night", "gastrocnemius muscle", "Art Carney", "Thomas Hobbes in his Leviathan", "March 26, 1973", "London", "a great deal on location", "President Lyndon Johnson", "prenatal development of the human heart", "roast turkey", "1840", "2007", "Branson", "broadcaster", "Tumi", "Loch Moidart", "james garnerer", "Polo because \"it was the sport of kings.", "the music label", "ego", "Nova Scotia", "Sir Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6420386904761906}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.4000000000000001, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-2280", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-7852", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-4571", "mrqa_hotpotqa-validation-1439", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-5421", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.546875, "CSR": 0.48684210526315785, "EFR": 0.9655172413793104, "Overall": 0.6836749943284935}, {"timecode": 57, "before_eval_results": {"predictions": ["the Old French tailleur ( `` cutter '' )", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "to acquire an advantage without deviating from basic strategy", "that country's surprise attack on Pearl Harbor the prior day", "the coffee shop Monk's", "Joe Young", "the birth of a Sim", "Ozzie Smith", "Mark Jackson", "1983", "Resident Commissioner", "January 2018", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "swine flu", "Gerald Ford", "September 8, 2017", "1998", "a political ideology", "Spektor", "a focal point", "Cell nuclei", "1973", "May 17, 2018", "Henry Haller", "a key signature at the beginning to designate the pitches that make up that scale", "a thirty - second call to one of a number of friends ( who provide their phone numbers in advance )", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root `` king ''", "P.V. Sindhu", "not for help", "Asuka", "October 19, 1961 -- January 19, 1963", "Scorpions", "Brazil", "UNESCO / ILO", "a document of the United States Department of Defense, issued upon a military service member's retirement, separation, or discharge from active duty", "on an inward spiral where it would eventually cross the event horizon", "to eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "during prenatal development in the central part of each developing bone", "skeletal muscle and the brain", "Don Cook", "Ireland", "Felicity Huffman", "In 1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Brian Patrick Friel", "Charlie Wilson", "Mark Sanford.", "Cesar Laurean", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5727471498334628}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.19999999999999998, 0.7499999999999999, 0.14285714285714288, 0.0, 0.6153846153846153, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.21052631578947367, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6956521739130436, 0.15384615384615385, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7027027027027027, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.3, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-9251", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-2646", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-2713", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.453125, "CSR": 0.48626077586206895, "EFR": 0.9142857142857143, "Overall": 0.6733124230295566}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "North Dakota", "July 18, 2013", "Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979", "separately in England and Wales", "iron", "the Reverse - Flash", "Los Angeles, California", "the British Empire", "other common form of Jaffa cakes are circular, 2 \u2044 inches ( 54 mm ) in diameter and have three layers : a Genoise sponge base, a layer of orange flavoured jam and a coating of chocolate", "\" Lady Arbuthnot's Chamber ''", "Nebuchadnezzar", "Eddie Murphy", "17 - year", "1923", "the brain and spinal cord", "Seattle, Washington", "October 1898", "on the slopes of Mt. Hood in Oregon", "Emma Watson", "a liquid crystal on silicon ( LCoS )", "cranberry sauce", "1917", "2003", "Bonnie Plunkett", "smen", "on the march or before the Israelite army, the host of fighting men", "Macon Blair", "genome", "to identify persons who are unable or don't want to drive", "Convention was founded with the dual purpose of abolishing the monarchy and drafting a new constitution", "four", "divergent tectonic plate", "Steve Russell", "to the well - being, welfare or safety of an individual or a group of individuals", "Columbia University", "the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "2017", "276", "the early 1960s", "President Yahya Khan", "Thespis", "Manhattan", "Wednesday, 5 September 1666", "March 1995", "Zuzu", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\"", "pipelines and hostage-taking", "gastroenterology", "the FBI.", "a ferry", "Leland Stanford", "Mexico City", "phewa"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5674124545065442}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.92, 0.5, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0625, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.3076923076923077, 0.6666666666666666, 0.8750000000000001, 0.0, 0.4347826086956522, 0.0, 0.5, 0.0, 0.0, 1.0, 0.125, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.9565217391304348, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-9403", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3396", "mrqa_naturalquestions-validation-8847", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231", "mrqa_triviaqa-validation-1216"], "SR": 0.40625, "CSR": 0.4849046610169492, "EFR": 0.8947368421052632, "Overall": 0.6691314256244424}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "IX ( one less than 10 )", "the ultimate exercise for the bored and lazy ''", "quarterback", "July 2012", "Audrey II", "Tim Russert", "Masha Skorobogatov", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "American country music singer George Strait", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F )", "Herman Hollerith", "94 by 50 feet ( 28.7 by 15.2 m )", "in the transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential, which contain the final drive to provide further speed reduction at the wheels", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "October 1, 2014", "Miracles", "the Omnibus Budget Reconciliation Act of 1990", "Roxette", "Long Island", "1988", "German", "Rococo - era France", "Sarah Brightman", "the Devastator, chases the Tantive IV above Tatooine", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 9, 1945", "1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century the Western Christian Church had placed Christmas on December 25, a date that was later adopted in the East", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "De pictura", "January 2, 1971", "J. Presper Eckert", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Jokers Wild", "Chicago", "duchy", "Lucas Stephen Grabeel", "15,006", "actress and model", "the results by a chaplain about 1:45 p.m. per jail policy.", "30-year-old", "Thursday,", "Vietnam", "a bass", "Richard", "Vinny"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6269087160972241}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.37037037037037035, 0.2580645161290323, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.1818181818181818, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-5275", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-34", "mrqa_triviaqa-validation-4764", "mrqa_hotpotqa-validation-3979", "mrqa_hotpotqa-validation-4797", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.53125, "CSR": 0.48567708333333337, "EFR": 0.9666666666666667, "Overall": 0.6836718749999999}, {"timecode": 60, "before_eval_results": {"predictions": ["government regulations ( including the jurisdiction's corporations law ) and the organization's own constitution and bylaws", "1996", "used obscure languages as a means of secret communication during wartime", "the remaining tomb Dracula", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "By petition for a writ of certiorari, filed by a party to a case that has been decided by one of the United United States courts of appeals or by the United States Court of Appeals for the Armed Forces", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists", "Lorenzo Lamas", "Mahatma Gandhi", "French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi", "eighth season", "Erica Rivera", "John Young", "Russia", "2020 National Football League", "Charles Perrault", "1990", "James `` Jamie '' Dornan", "left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Clare Torry", "ummat al - Islamiyah", "Brazil", "V\u1e5bksayurveda", "Domhnall Gleeson", "the Guaran\u00ed peoples of South America, who called it ka'a he'\u00ea ( `` sweet herb '' ).", "agriculture", "St. John's, Newfoundland and Labrador", "from the Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "if displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "The episode typically ends as a cliffhanger showing the first few moments of Sam's next leap ( along with him again uttering `` Oh, boy! '' on discovering his situation )", "10 Stigwood Avenue", "1902", "early Sumerian site settled during this period, around 5300 BC", "the closest approach to the original sound\"", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker", "Atlantic Ocean", "daughter of the 7th Duke of Marlborough", "Division of Fawkner", "Kris Allen", "Kurt Cobain's", "novel and film \"Empire of the Sun,\"", "Hector Berlioz", "the Khmer Rouge massacres", "the Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6469917513395774}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 0.14814814814814817, 0.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.1621621621621622, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.32, 1.0, 0.5, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.7272727272727272, 0.6956521739130436, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-4613", "mrqa_newsqa-validation-3279", "mrqa_searchqa-validation-8785", "mrqa_newsqa-validation-1282"], "SR": 0.546875, "CSR": 0.4866803278688525, "EFR": 0.8620689655172413, "Overall": 0.6629529836772188}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "shared until 2010 -- 11, when Dimitar Berbatov and Carlos Tevez both scored 20 goals that season to tie for the award", "Jason Marsden", "New Mexico", "After the Reform Act of 1832 Sussex", "1890", "William the Conqueror", "March 2, 2016", "July 20, 2017", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Dan Stevens", "legislation", "2018", "from 6 -- 14 July", "the 2009 model year", "4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "the 18th century", "Thomas Jefferson's", "Elijah Wood", "Jumping on the Moon", "Brad Dourif", "counter clockwise", "Joanne Wheatley", "vice president", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The First Battle of Bull Run", "American country music duo Brooks & Dunn", "kautta", "south america", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Obama", "Sri Lanka's Tamil rebels", "One of Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6959023268398268}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.59375, "CSR": 0.4884072580645161, "EFR": 0.9230769230769231, "Overall": 0.6754999612282878}, {"timecode": 62, "before_eval_results": {"predictions": ["1953", "beneath the liver", "James Ray", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Eastern and Southern Slavic peoples", "toys or doorbell installations", "microfilament", "in the pancreas by protein biosynthesis as a precursor called chymotrypsinogen that is enzymatically inactive", "the northernmost point on the Earth", "CeCe Drake", "Eduardo", "American internationalist General Carlos Roloff and Seraf\u00edn S\u00e1nchez in Las Villas", "1971", "Leo Arnaud or L\u00e9oArnaud ( / \u02c8le\u026a. o\u028a \u0251\u02d0r \u02c8no\u028a / ; July 24, 1904 -- April 26, 1991 )", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "Canada's parent country the United Kingdom", "1912", "Eric Clapton", "Djokovic", "James Hutton", "January 1923", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Billy Bishop Toronto City Airport on the Toronto Islands in Toronto, Ontario, Canada", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans", "the port of Nueva Espa\u00f1a to the Spanish coast", "10.5 %", "Great Plains and U.S. Interior Highlands region", "White House Executive Chef", "International Border ( IB )", "Bart Millard", "a woman named Sarah Whitehead", "Rolihlahla Mandela", "Midnight Cowboy", "Austrian", "heavy metal drummer", "Selden", "Muslim Eid-ul-Adha", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Queen Elizabeth", "France", "Oshkosh", "River Welland"], "metric_results": {"EM": 0.5625, "QA-F1": 0.661338458994709}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, false], "QA-F1": [0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.5, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.28571428571428575, 1.0, 0.5, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7211", "mrqa_triviaqa-validation-7273", "mrqa_triviaqa-validation-5245", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_hotpotqa-validation-1201"], "SR": 0.5625, "CSR": 0.48958333333333337, "EFR": 1.0, "Overall": 0.6911197916666667}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "The Hustons", "sacroiliac joint", "Identification of alternative plans / policies", "Cuernavaca, Durango", "development of electronic computers in the 1950s", "United States", "the angel of the Lord ( Numbers 22 : 22 )", "Bhupendranath Dutt", "George III", "April 13, 2018", "a bread roll ( generally on a bread plate, sometimes in the napkin ), napkin, and flatware ( knives and spoons to the right of the central plate, and forks to the left )", "Kristy Swanson as Duckette", "Jakkur, Bangalore, India", "in a thousand years", "2001", "the European economy had collapsed", "Ringo Garza", "Ben Findon", "incudomalleolar joint", "Terry Reid", "political energy in the international arena had been directed towards the preservation of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "enabled business applications to be developed with Flash", "Forbes Burnham", "on Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court", "Alicia Vikander as Lara Croft", "237,846", "February 27, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115 home runs", "ten times", "Shannen Doherty", "a Czech word, robota", "Arthur `` The President '' Flanders", "Caroline Sterling", "Austin and Pflugerville", "three times", "the misuse or `` taking in vain '' of the name of the God of Israel", "four distinct levels", "Geothermal gradient", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "Trinidadian and Tobagonian British", "the Big Bopper", "the Pentagon", "Pisgah National Forest", "Lola Dee", "Robert Mugabe", "on Capitol Hill,", "to discuss water shortages in the major Tigris and Euphrates rivers,", "impressionism", "the Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5347373820441255}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.4444444444444444, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.10526315789473682, 1.0, 0.761904761904762, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.18181818181818182, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.125, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.20000000000000004, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7492", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-6825", "mrqa_hotpotqa-validation-3339", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-198", "mrqa_searchqa-validation-8333"], "SR": 0.40625, "CSR": 0.48828125, "EFR": 0.9210526315789473, "Overall": 0.6750699013157895}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra Fort", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian (born December 7, 1980)", "Len Wiseman", "Viglen Ltd", "1983", "Randall Boggs", "Detroit, Michigan,", "Kunta Kinte", "the World Series", "Pittsburgh", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Sanchez", "Vanessa Hudgens", "Liga MX", "McG", "Peter Seamus O' Toole", "March 8, 1942", "Michael Stipe", "January 30, 1930", "Doctor", "Irish Government's Health Service Executive", "James Weldon Johnson", "Wilmington, co-educational university located in Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes of Balquhither\"", "Westminster system", "Ionolyce", "\"For Love Alone\"", "January 19, 1943", "King of France", "Sam Waterston", "Transporter 3", "1986", "Midrand, Gauteng province", "the Vietnam War", "William Theodore Walton III (born November 5, 1952)", "the Darling River", "The Boz", "140 million", "American", "Teri Garr", "the employer", "2002 -- 2003", "Wyoming", "Wee Jimmy Krankie", "cholera", "immediate release", "black, red or white, and women in the impoverished city are concerned that they will not be able to purchase clothing that conforms to the order,", "Both Won Sei Hoon, who heads South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "The Smashing Pumpkins", "new zealand", "a 16 letter phrase", "a seafood restaurant"], "metric_results": {"EM": 0.453125, "QA-F1": 0.574609851953602}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.0, 0.4, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5671", "mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2804", "mrqa_hotpotqa-validation-4198", "mrqa_hotpotqa-validation-2632", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-3275", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474", "mrqa_naturalquestions-validation-8542"], "SR": 0.453125, "CSR": 0.4877403846153846, "EFR": 1.0, "Overall": 0.6907512019230768}, {"timecode": 65, "before_eval_results": {"predictions": ["Stephen Lee", "TV series \"Archer\"", "Albert", "September 30, 2017", "237,520", "the New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the Winecoff Hotel fire", "Odense Boldklub", "Stephen", "Scott Eastwood", "Gweilo", "Tufts University", "Prince Aimone of Savoy-Aosta", "1920", "The Wu-Tang Clan", "for Love Alone", "a pop refrain", "rock music", "G\u00e9rard Depardieu", "rural areas", "Summerlin, Clark County, Nevada", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse University", "Kings Point, New York", "Robbie Gould", "Paddy's Pub in South Philadelphia", "Baldwin", "Port Clinton", "November 20, 1942", "Charlie Murphy", "the Australian coast", "Hurricane Faith", "turns out to be a terrible date", "the Celtics", "Good Luck Charlie", "Citric acid", "eight", "from 1848 to 1852", "Sippin' on Some Syrup", "Jim Harrison", "Sir Patrick Barnewall", "Arabella Churchill", "Lester Ben \"Benny\" Binion", "two Grammy awards", "S6", "2017", "Qutab Ud - Din - Aibak", "London", "Thomas Paine", "Luxembourg", "Golda Meir", "Muffin Man", "President Bill Clinton", "as", "Vernon Forrest,", "Yonkers", "blown", "the supernatural", "Dan Aykroyd"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5954126602564103}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4000000000000001, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.4, 0.25, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1941", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-4360", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2978", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-368", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.484375, "CSR": 0.4876893939393939, "EFR": 1.0, "Overall": 0.6907410037878787}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Sheffield Wednesday", "Paraguay", "126 mph", "Absalom", "Terry \" Terry\" Hall", "1991", "Anthony Joshua", "George III", "Zsa Zsa Gabor", "ambidevous", "Nic\u00e9phore Ni\u00e9pce", "Richard Feynman", "Permian", "an international award given each year to a living architect", "Guy the Gorilla", "a man holding up a lighted match", "Port Moresby", "green", "the Kursk nuclear submarine", "pyrotechnic", "China", "Annie Lennox", "a boar", "a superhero", "Echidna", "Syria", "Wyoming", "Professor Brian Cox", "Benjamin Franklin", "Albert Finney", "Scotland", "24", "Thomas Jefferson John Adams", "Ellice Islands", "Meta", "a Oil Capital of Europe", "about a mile north of the village of Dunvegan", "a narrow-bored wooden instrument", "Spice Girls", "\"Mr Loophole\"", "Istanbul", "cheerful \u201cLibiamo\u201d (\u201cLet Us drink\u201d) in La traviata (1853)", "Texas", "Pablo Picasso", "Potsdam Conference", "Rajasthan", "Saintpaulia", "Indonesian", "Glee", "Cardigan", "Ratonhnhak\u00e9 : ton and Haytham Kenway", "Djokovic", "1912", "The fennec fox", "1927", "Nikolai Trubetzkoy", "Vernon Forrest", "Linda Hogan", "in the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "Peter Hurd", "pathogens", "Steve Wynn", "A substitute good"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5310496794871794}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.15384615384615385, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-697", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-2232", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-1689", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-6737", "mrqa_triviaqa-validation-4036", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-1464", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_newsqa-validation-2391", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-9098"], "SR": 0.46875, "CSR": 0.48740671641791045, "EFR": 1.0, "Overall": 0.690684468283582}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less", "Thai army", "Les Bleus", "tranquil beaches", "took on water", "Schalke", "Secretary of State", "Ali Larijani", "21 percent", "Fernando Caceres", "one of the most feared Camorra gangs.", "no evidence", "America's Cup", "Cambodian territory", "Bahrain", "voluntary manslaughter", "Jenny Sanford", "Isabella, Emma, Olivia, Sophia, Ava, Emily, Madison, Abigail, Chloe and Mia.", "Miami Beach, Florida,", "all-star film", "cell phones", "two contestants.", "Fiona Mac Keown", "Roland S. Martin", "South African captain Graeme Smith", "co-chairs of the Genocide Prevention Task Force", "didn't elaborate.", "8", "two Manchester, England shows", "for the two remaining crew members from the helicopter,", "real action", "two tickets to Italy", "Oxbow,", "There were no reports of ground strikes or interference with aircraft in flight,", "21-year-old", "Jacob Zuma", "Toffelmakaren.", "former Procol Harum bandmate Gary Brooker", "civil disturbance call,", "ece Basaran", "olfactory receptors in the brain,", "Kenyan and Somali", "30,000", "1983", "he elicits support from his fellow Muslims for \"our weapons, funds and Jihad against the Jews and their allies everywhere.\"", "North Korea", "Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "Koine Greek : apokalypsis", "Phil Mickelson", "Dumbo", "Yardbirds", "1969", "\"$10,000 Kelly,\"", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "yishai", "Marilyn Monroe", "director", "from a socially reinforced sense of entitlement"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6056242859551684}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.4, 0.0, 0.28571428571428575, 0.1818181818181818, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10810810810810811, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3588", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-293", "mrqa_naturalquestions-validation-833", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.578125, "CSR": 0.48874080882352944, "EFR": 1.0, "Overall": 0.6909512867647059}, {"timecode": 68, "before_eval_results": {"predictions": ["Ferraris", "as soon as 2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California,", "German Chancellor Angela Merkel", "son of Gabon's former president", "politically and culturally", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "U.S. ship that was hijacked off Somalia's coast.", "in time", "AS Roma", "President Barack Obama,", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally from China on Christmas Eve.", "2000.", "at least 300", "Thursday", "hot and humid", "Israel", "drama that pulls in the crowds", "2008.", "root out terrorists within its borders.", "25", "\"Zed,\" a Columbian mammoth", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Seven-time world champion Michael Schumacher", "Jobs", "Jenny Sanford", "in a remote part of northwestern Montana", "genocide", "forged credit cards and identity theft", "Bailey, Colorado,", "John Demjanjuk", "Frenchwoman Aravane Rezai", "two weeks", "\"Doogie Howser, M.D.\"", "British", "six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man ''", "Taron Egerton as Johnny", "Italy", "\"Book 1: Sowing\"", "coneflower", "Nellie Melba", "Clark Gable", "1979", "the backside", "Sweden", "spotted hyena", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5227389861155105}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.9090909090909091, 0.0, 0.19512195121951217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-1736", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4976", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.421875, "CSR": 0.4877717391304348, "EFR": 1.0, "Overall": 0.6907574728260869}, {"timecode": 69, "before_eval_results": {"predictions": ["cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge and karma", "Kevin Sumlin", "Paradise, Nevada", "Professor Eobard Thawne", "Hathi Jr", "a liquid crystal on silicon ( LCoS )", "Spektor", "The Star Spangled Banner", "Bill Russell", "The Parable of the Unjust Judge", "July 2010", "a protocol ( http )", "at 343 m / s in air", "1996", "Carol Worthington", "September 6, 2019", "1972", "initially", "uprooted", "at angles less than vertical", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Vince Vaughn", "under normal conditions", "1980s", "Pasek & Paul", "a 1920 play R.U.R.", "epidemiology", "2013", "Frankie", "eusebeia", "Daniel Suarez", "White House Executive Chef", "a place of trade, entertainment, and education", "influence and significance of the artists'contributions to the development and perpetuation of rock and roll", "the bank's own funds", "The Abbott and Costello Show", "Waylon Jennings", "a dramaturg", "the Rolling Stones", "Sun Tzu", "Pre-evaluation", "eucalyptus tree", "inflation", "Charlie Hall Chase 89", "John M. Dowd", "December 17, 1974", "Northrop P-61 Black widow", "26", "The woman", "2050,", "West Point", "Paul Bunyan", "the thyroid", "1965"], "metric_results": {"EM": 0.53125, "QA-F1": 0.631421974764366}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4347826086956522, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.23076923076923078, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-3436", "mrqa_naturalquestions-validation-1178", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-6937", "mrqa_newsqa-validation-1639"], "SR": 0.53125, "CSR": 0.4883928571428572, "EFR": 0.9, "Overall": 0.6708816964285714}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a collection of instructions that performs a specific task when executed by a computer", "January 2, 1971", "grated cheese", "Oakland Athletics", "Bonhomme Carnaval", "1792", "a long line", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "in Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "investment bank Friedman Billings Ramsey", "the NFL", "14 \u00b0 41 \u2032 34 '' N 17 \u00b0 26 \u00b0 N 17.44667 \u00b0 W \ufeff / 14.69278", "1 January 1904", "recover many kinds of passwords using methods such as network packet sniffing, cracking various passwords, brute force and cryptanalysis attacks", "a minimum number of hours defined as such by his / her employer", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer ( SCNT )", "UN General Assembly", "Benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a tradition in brass band parades in New Orleans, Louisiana", "2009", "May 31, 2012", "Linda Hamilton's real - life son Dalton Abbot", "Malware", "ex", "Beorn", "South Dakota", "John F. Kennedy", "100,000", "1967", "Rajasthan", "Sodor", "eye", "44,300", "2008", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "Humpty Dumpty", "Southeast Asia", "500-room"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6689441463016831}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.888888888888889, 0.35294117647058826, 0.7916666666666667, 0.11764705882352942, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-7551"], "SR": 0.5625, "CSR": 0.4894366197183099, "EFR": 0.9642857142857143, "Overall": 0.6839475918008049}, {"timecode": 71, "before_eval_results": {"predictions": ["David O. Dykes", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Helvellyn Lower Man, White Side, Stybarrow Dodd, Great Dodd and Clough Head, and in the south leads to Nethermost Pike and Dollywaggon Pike", "stylist and assistant.", "clown", "Titanic Memorial Cruise", "Brundisium", "Hadrian", "Madagascar", "Barbizon school", "Renzo Piano", "Edouard Manet Luncheon", "Rodney", "shuttle Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "estate", "car and motorcycle", "Greenock", "Hep Stars", "Gillis Grafstr\u00f6m", "6", "Lord Snooty", "Greyfriars Bobby", "Rudolf Hess", "Chartered Institute for the Management of Sport and Physical Activity", "Stieg Larsson", "Music Stories", "1957", "\"Cromlech\"", "steel", "Rotherham and Barnsley", "Joseph Priestley", "dogs", "tennis", "the Periodic Table", "CameroonCameroon", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuban", "armrimony", "Patience", "chicago Checker", "Quentin Tarantino", "smartphones and similar devices to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "Augusta National Golf Club", "San Francisco", "In its first year", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "January", "We wanted to be 100 percent carbon neutral from launch so we partnered with ClimateCare, one of Europe's most experienced providers of carbon offsets,", "hiring veterans as well as job training for all service members leaving the military.", "$2.6 million from Enyimba in Nigeria ahead of Egyptian side Al-Ahly in what was one of the biggest transfers in African football.", "the American Civil War", "How do we know", "Peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6088489145658263}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.24000000000000002, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.07142857142857142, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3529411764705882, 0.0, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-6465", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-7542", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-5821", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-8965", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.53125, "CSR": 0.49001736111111116, "EFR": 1.0, "Overall": 0.6912065972222222}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby", "titanic", "Altamont Speedway", "The Jetsons", "26 miles", "tibia and fibula", "overprotective clownfish", "zechariah", "chicago", "Daedalus", "gary titanic novelist Michael Ondaatje", "uranus", "a goad", "spiderman", "14", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Queen Elizabeth II", "gary titanic", "sea horse", "Frank Miller", "tennis", "george Orwell", "Atlantic Ocean", "The discovery and colonisation of New Zealand", "chatsworth house", "stella mccartney", "paris", "eyes", "Husqvarna", "b Benedict Cumberbatch", "aug 24", "zebu", "Julius Caesar", "south america", "Southwest Airlines", "Sunset Boulevard", "martin titello", "Derwent Water", "sesame seeds", "Laos", "Allardyce", "gary titain", "gary titanic", "Miami", "Billaley", "corkscrew", "1768", "gary titanic", "spain", "The Ref refrigerator Perry", "Ghana", "as an extension to this procedure", "magnetic stripe `` anomalies '' on the ocean floor", "from 1999 to 2001", "Easy", "seven", "Karl Johan Schuster", "to the U.S. Holocaust Memorial Museum", "Robert Barnett", "Diego Milito", "dont Wanna leave Ft. Dutchboy", "Dumbo the Flying elephant", "Casey at the Bat", "Python"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4428819444444444}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.888888888888889, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6169", "mrqa_triviaqa-validation-1061", "mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5655", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7364", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-9987", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2420", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706"], "SR": 0.34375, "CSR": 0.488013698630137, "EFR": 1.0, "Overall": 0.6908058647260273}, {"timecode": 73, "before_eval_results": {"predictions": ["Charlie Nicholas", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1449", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Greek Revival", "The Ansonia Hotel", "Mount Rainier", "Helen Mirren", "striker", "Schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "\"Wragby Road\"", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "Jane Mayer", "Pierre Nlend Wom\u00e9", "Knowlton School of Architecture", "143,007", "Philadelphia", "33-member", "American television personality and film actress best known as the hostess of \" Wheel of Fortune\"", "1967", "mathematician, physicist, and spectroscopist", "samson", "St Andrew's Greeance", "Royal College of Music", "4145 ft", "the third-deadliest aircraft accident in the history of aviation,", "Lake County, Illinois", "\"Stuck in the Suburbs\"", "2013", "Michael Phelps", "suburb of Adelaide in the City of Port Adelaide Enfield", "schoolteacher", "People v. Turner", "Bill Ponsford", "Faysal Qureshi", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "54", "paramitas", "1881", "john thurinus", "he called it the largest and perhaps most sophisticated ring of its kind in U.S. history.", "Jobs", "Christianity and Judaism,", "blintz", "the Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.625, "QA-F1": 0.6889596463585435}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.35294117647058826, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.4, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.10714285714285712, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-3231", "mrqa_hotpotqa-validation-3128", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.625, "CSR": 0.4898648648648649, "EFR": 0.9583333333333334, "Overall": 0.6828427646396397}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ad", "ketchup", "Inuit", "compound eyes of flies", "Ginuwine", "\"Dancing with the Stars\"", "Republic of the Union of Myanmar", "Latvia", "spleen", "auf Wiedersehen", "rely", "Ramses", "wine", "the esophagus", "Dallas Cowboys", "the Bible", "the twist", "Marie Tussaud", "Biscay", "a giant griffin", "March", "Magellan", "Kevin Spacey", "a brothel", "a sphere", "The Aviator", "Rossini", "Mexico", "a tail", "Nashville", "Hanging Gardens", "the Starfighter", "Billy Crystal", "skin cancer", "Gerard", "city", "pontificio", "Mimi Bobeck", "Fuchsia", "Moonlighting", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "Bay of Bengal", "In vitro fertilisation", "Diogenes", "pastries", "Whatchamacallit", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "\"Lady Madonna\"", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "tennis", "more than 4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6104166666666666}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-6585", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801", "mrqa_newsqa-validation-3527"], "SR": 0.53125, "CSR": 0.4904166666666666, "EFR": 1.0, "Overall": 0.6912864583333332}, {"timecode": 75, "before_eval_results": {"predictions": ["18", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "AD 1600", "1963", "The Satavahanas", "Jos\u00e9 Mart\u00ed", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK and Olivia", "28 July 1914", "Lager", "908 mbar", "the North Atlantic Ocean", "February 7, 2018", "October 2000", "Lutheran Church of Sweden", "commemorating fealty and filial piety", "the fictional Iron River Ranch, Colorado", "Valens", "American singer - songwriter - actress Debbie Gibson", "Lula", "31 January 1934", "Austin", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "the winter solstice", "Yahya Khan", "sonil Grover and Jaideep Ahlawat appear in supporting roles with Kareena Kapoor Khan in a cameo", "synthesizing vitamin B and vitamin K as well as metabolizing bile acids, chromosols, and xenobiotics", "Kyla Coleman", "Bill Belichick", "September 1972", "Tim Passmore", "Venus Williams", "Spanish", "Lilian Bellamy", "13,000 astronomical units ( 0.21 ly )", "Elmer Gantry", "handheld subscriber equipment", "Saint Etienne", "1 lakh people", "Chuck Noland", "many forested parts of the world", "mathematics", "archery", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie", "0-0 draw away to Saudi Arabia", "Romanov Dynasty", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6133184523809523}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.9428571428571428, 1.0, 0.5, 0.6, 1.0, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.8333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-290", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-3229", "mrqa_searchqa-validation-12989", "mrqa_newsqa-validation-1646"], "SR": 0.453125, "CSR": 0.4899259868421053, "EFR": 0.9714285714285714, "Overall": 0.6854740366541353}, {"timecode": 76, "before_eval_results": {"predictions": ["$2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island", "the Peace of Westphalia of 1648", "Authority ( derived from the Latin word auctoritas ), as a concept, can be used to mean the right to exercise power given by the State ( in the form of government, judges, police officers, etc. )", "Jughead Jones", "American rock band Los Lonely Boys", "ecological regions", "cakes", "Kiss", "18 September to 31 October", "Mary Simpson", "during World War II", "Kirk Douglas", "2004", "Ella Eyre", "Hank J. Deutschendorf II", "Derrick Henry", "Stephen Stills'former girlfriend", "southern Turkey, dividing the Mediterranean coastal region of southern Turkey from the central Anatolian Plateau", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "261 B.C.", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Megyn Price", "an anembryonic gestation", "by polymerizing the first few glucose molecules, after which enzymes take over", "Matt Monro", "Christmas Tree", "IV", "No. 16 seed", "Saphira hatches", "September 2017", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "1974", "Spike", "regulatory site", "On the verge of combusting as Sweet's other victims have been shown to do -- until Spike stops her, telling her that the only way to go forward is to just keep living her life", "Agamemnon", "InterContinental Hotels Group", "peninsula", "Jason Flemyng", "peninsula", "Norman Mailer", "vickers vimy", "EMI", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million.", "Lake Henshaw and Mesa Grande and the La Jolla Indian Reservation in San Diego County.", "CNN.com", "jazz", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6734029931951324}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0689655172413793, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.36363636363636365, 0.962962962962963, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.6153846153846153, 0.0, 1.0, 1.0, 0.05555555555555555, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4850", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-14736"], "SR": 0.578125, "CSR": 0.4910714285714286, "EFR": 0.9259259259259259, "Overall": 0.6766025958994708}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Alessandro di Mariano Filipepi", "palladium", "Pulsar", "Seth", "honda", "\" Happy Christmas (War Is Over)", "Ozzy Van Halen", "Jessica", "FIFA World Cup", "Elizabeth I", "June 14th", "Italy", "1960", "Mel Brooks", "Belgium", "Chloroplasts", "Paul Dukas", "Iceland", "Uranus", "rum", "apple", "Arbroath", "Roddy Doyle", "the discus thrower", "Separate Tables", "the sound of the human voice", "kitty in Boots", "Magpie", "Bill Haley", "figure skating", "Kansas City", "Raul Castro", "Space Oddity", "Scotland", "Butterflies", "Illinois", "green", "\u201c Splashash\u201d", "Britain", "Shabbat", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Kellogg\u2019s Special K", "line code", "the family Sturnidae ( starlings and mynas ) native to Asia", "Liam Cunningham", "Brobee", "Fuenlabrada", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "St Bernard", "France", "Barnard College", "equator,"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5480406746031745}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-1265", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-149", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-101", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.46875, "CSR": 0.4907852564102564, "EFR": 1.0, "Overall": 0.6913601762820513}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Daniel Fran\u00e7ois Esprit Auber", "june", "apollozzo", "Mohanda Karamchand Gandhi", "I", "Mr. Golding", "a nerve cell cluster", "vitamin B3", "director of the Security Service", "ship", "Portugal's Madeira Islands", "bathsheba everdene", "spaghetti Harvest", "Northern Ireland", "woman", "duchamp", "The Quatermass Experiment", "Mumbai", "a statue", "1875", "raven", "hound", "Ted", "Estimate", "hard", "Modi", "Richard Wagner", "Tarantino", "Argentina", "farewell", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "steppes steppe", "Romania", "brindisi", "Monica", "Emeril Lagasse", "hitler", "Darrin", "hitler", "june", "Eva Herzigov\u00e1", "june", "Derry", "'Battle of Britain' ( 1965)", "horror fiction", "Colombia", "rolling hillsides of Ireland", "the anterolateral system", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "operas", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's strike", "Al-Shabaab", "The Old Man and the Sea", "Edward I", "the Cranberries", "Air traffic delays began to clear up Tuesday evening after computer problems left travelers across the United States waiting in airports,"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5169642857142857}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.28571428571428575, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-7072", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-1610", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-5712", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-35", "mrqa_triviaqa-validation-3903", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.40625, "CSR": 0.48971518987341767, "EFR": 0.9736842105263158, "Overall": 0.6858830050799467}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "francan", "HMS Amethyst", "italian", "tomato", "Kyoto Protocol", "costume shop", "Bull Moose Party", "know", "james laurel", "value of unknown resistance", "hanie Mc Daniel", "south africa", "indigestion", "discretion", "eva", "will be assessing their performance in the process,", "giuseppe pyle", "Corinth Canal", "ede", "Iceland", "ascot", "fruit", "kris Jenner", "gangsters", "doe", "macbeth", "european", "Argentina", "south Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "toplis", "Julian", "it Crowd", "\u00ef\u00bf\u00bd", "carrie", "q MJHL", "Richard Curtis", "terms of endearment", "China", "ireland", "1790", "bingfield", "chamomile", "hitler", "orchid", "Hilary Swank", "bingdeen", "diametrically opposite the South Pole", "18th century", "nine hours", "just 18 minutes", "England", "nationalism", "\"Steamboat Bill, Jr.\"", "hostile war zones,", "Rodong Sinmun", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5040625}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-374", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-4551", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1338", "mrqa_triviaqa-validation-2468", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_hotpotqa-validation-5333", "mrqa_newsqa-validation-3862", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.4375, "CSR": 0.48906249999999996, "EFR": 1.0, "Overall": 0.691015625}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Eleanor Roosevelt", "senators", "2", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Bruce Willis", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "from the Canadian Rockies continental divide east to central Saskatchewan", "H CO", "Miami Heat", "began on March 29, 2018", "four", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Danielle Silva", "British Indian Association", "bypasses", "the probability of rejecting the null hypothesis", "Tom Burlinson", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Santa Clara Pueblo, New Mexico", "Tbilisi", "genome", "North Atlantic Ocean", "people are federally recognized as the Comanche Nation, headquartered in Lawton, Oklahoma", "United Nations", "as of October 1, 2015", "2026", "318", "Director of the Federal Bureau of Investigation", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "February 10, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "epic sports - drama film, directed by Ashutosh Gowariker, produced by Aamir Khan and Mansoor Khan, and written by Treyariker and Abbas Tyrewala", "initially released as an arcade game in 1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market ( FX )", "The Hustons", "The Sunday Post", "on Sky1 HD and in the US on The Science Channel", "libya", "1860", "\"Back to December\"", "Buck Owens", "imaginative exuberance.", "\"Empire of the Sun,\"", "off Somalia's coast.", "modificre", "holly ringwald", "faerie", "skull and crossbones"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6611219203590527}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5714285714285715, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.11764705882352942, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-1373", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-6518", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.578125, "CSR": 0.4901620370370371, "EFR": 0.9259259259259259, "Overall": 0.6764207175925925}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Berenice I", "nuclear tests", "capitals", "Pizza Crusts", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Alois Alzheimer's", "Marcia Clark", "Jenny", "gestation", "ravens", "J.R. Tolkien", "James Franco", "Blue Ridge Mountain Range", "Guyana's", "a mixture of iron oxide and aluminum oxide", "Buddha", "iTunes for Windows", "a enslaved African American who led", "a catfish", "a chorus Line", "piazza del Campo", "Robbie Turner", "expressing regret", "Chloe Lattanzi", "Virginia", "College of William and. Mary", "a dogs of the Podengo", "Louisiana's", "Matthew Vassar", "kung fukylo", "cutlery", "The Police", "Air France", "Metastasio", "Heracles", "a trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "yodeling", "the Chagos Archipelago", "a syringe", "Robespierre", "a nanosecond", "Didelphodon vorax", "Mason Alan Dinehart ( born April 30, 1936 )", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "on location", "2010", "cymbal", "Madagascar", "Tom Hiddleston", "Estadio Victoria", "Borough of Allerdale", "Zimbabwean President Robert Mugabe", "70,000 or so", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5578124999999999}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-14468", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-16540", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-8284", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-2097", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-6250", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-2110", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390", "mrqa_newsqa-validation-1720"], "SR": 0.4375, "CSR": 0.4895198170731707, "EFR": 0.9722222222222222, "Overall": 0.6855515328590785}, {"timecode": 82, "before_eval_results": {"predictions": ["USS Nautilus", "the Apache", "China", "(John) Paul II", "the Yangtze River", "Gnarls", "the Parthenon", "a Therapist", "Marilyn Monroe", "Souvlaki", "Richard III", "the bald eagle", "the Louvre", "an acre", "the Galapagos Islands", "Frans Hals", "the Black Sox Scandal", "(desert)", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "nouveau", "bicycle", "Germanic", "the California quail", "curtsy", "lacrosse", "Toronto", "fo", "king david", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "the Hobbit", "the Red Sox", "W.C. Fields", "Yale University", "Graceland", "the Caspian Sea", "laces", "(Roger) Marvin", "New Brunswick", "Westminster Abbey", "Superbad", "\"The Granite State\"", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W", "Austria", "acai berry", "The Benedictine Order", "Pansexuality", "authorship of \"Titus Andronicus\"", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6829435412224591}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.41791044776119407, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-1437", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_searchqa-validation-5031", "mrqa_searchqa-validation-4122", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.546875, "CSR": 0.49021084337349397, "EFR": 1.0, "Overall": 0.6912452936746988}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon", "A.J. Foyt", "a vulture", "Long Island, Nantucket", "Ebony", "Trinity College", "Algeria", "Joseph Haydn", "Alexander Haig", "the black market", "a bulword puzzle", "Saturday Night Fever", "Japan", "Pizza Napoletana", "a chestnut", "the Empire State Building", "(WBC)", "a picayune", "florida", "Quebec", "Larry McMurtry", "Kellogg\\'s", "Helen of Troy", "a Sweatshirts", "gravity", "Napoleon", "wood", "the Lapland", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "AT&T", "Pancho Gonzales", "the Aleutians", "the Mormon", "Lady Jane Grey", "Tommy Tutone", "the crescent", "Iraq", "a grasshopper", "Copernicus", "a bulgaro", "Mr. Safire", "Leonardo da Vinci", "London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Edward G. Robinson", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Skeeter Davis", "\"Casablanca\"", "T. R. M. Howard", "The Shirehorses", "five days.", "DBG,", "1995", "four"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6459821428571428}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1916", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_triviaqa-validation-112", "mrqa_newsqa-validation-1339"], "SR": 0.578125, "CSR": 0.49125744047619047, "EFR": 1.0, "Overall": 0.6914546130952381}, {"timecode": 84, "before_eval_results": {"predictions": ["the Czech Republic", "Henry VIII", "Judas", "Windsor, Ontario", "(Stephen) Douglas", "comrade", "the Gatsby", "the foxes", "sexuality", "the Salaries", "1 Kings", "Roger Federer", "a bicycle", "Johnson", "Jericho", "a blackjack", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the Cherokee", "the Philippines", "St. Mark", "Eragon", "Penny Lane", "Louisiana", "Mexico", "jolly Roger", "engrave", "daisy Miller", "the Legion of Honour", "the Y chromosome", "a ship", "Kamehameha", "the wolf", "Jamestown", "Jerry Maguire", "the north magnetic pole", "the oyster", "the orangutan", "Candlestick", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico", "Frankie Muniz", "the sixty - day abstinence pact", "A complex sentence", "40", "Mars", "Nowhere Boy", "August 1973", "a nasal", "Richa Sharma", "Texas", "financial gain,", "in a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.609375, "QA-F1": 0.671875}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6488", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-9592", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_triviaqa-validation-2049", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.609375, "CSR": 0.49264705882352944, "EFR": 1.0, "Overall": 0.6917325367647058}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Winnie the Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "The Fountainhead", "Brahma", "\"Rough Stone Rolling\"", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Morse", "Strawberry Fields", "Amsterdam", "Geena Davis", "pharmacy", "( Kit) Carson", "no", "Doolittle", "pulmonary", "Shakespeare in Love", "Floyd McGregor Jr", "ABBA", "the League of Nations", "Marlee Matlin", "a house of prayer", "The X-Files", "( Zahir) Jinnah", "Mensa", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "high chairs", "the Salt Lake City Choir", "Venice", "a watermelon", "the Warsaw Pact", "Sparta", "smallpox", "anode", "to discover new and uncharted territory", "the National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "Prozac", "H CO ( equivalently OC ( OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight David \"Ike\" Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "evicted not because of anything they did, but because her landlord defaulted on the mortgage and the house fell into foreclosure.", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6268601190476191}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09523809523809525, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-10138", "mrqa_searchqa-validation-43", "mrqa_searchqa-validation-8960", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-6063", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.578125, "CSR": 0.493640988372093, "EFR": 1.0, "Overall": 0.6919313226744186}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy feet", "a sprint", "a snowman", "Joseph Bonaparte", "Chicago", "Aphrodite", "Cannery Row", "the Palatine Hill", "California", "the Mississippi", "Alpha", "Quebec City", "a pearls", "the Texas Chainsaw Massacre", "the rotunda", "a oak leaf cluster", "Edouard Manet", "Plutarch", "Mediolanum", "Celia", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "the Sadler", "Vasco da Gama", "Millard", "a twill", "Finnegans Wake", "a aleikum", "the black market", "a cockroach", "P-waves", "Maastricht", "Delilah", "a synapse", "a croissant", "Jalisco state", "a bronchial tubes", "fuchsia", "14 phalanges", "a pool", "Paramaribo", "a shovel", "the Mercury Seven", "China", "Gettysburg", "Ibtihaj Muhammad", "trout", "a slow Boat", "1959", "season two", "$75,000", "zimbabwe", "15", "the National Gallery", "Agent Carter", "\" Shadow of a Doubt\" (1943)", "Manhattan", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.5, "QA-F1": 0.5932291666666667}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-10131", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-11869", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-8225", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-16661", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-24"], "SR": 0.5, "CSR": 0.49371408045977017, "EFR": 1.0, "Overall": 0.691945941091954}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists and the Carlists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "5,770", "Geoffrey Zakarian", "4.5 pounds", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Milan, Italy", "American indie pop band Foster the People", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Mario Puzo", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "slavery", "The Osmonds", "the Russian revolutionary Vladimir Lenin", "Taiwan", "Anakin Jedi", "Jeff East", "two", "Ricardo Chavira", "Ed Roland", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "Washington", "the 2nd century", "Triple threat", "1998", "shared", "foreign investors", "Louis XVIII", "inverted - drop - shaped icon that marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool", "Robber baron", "December 20, 1951", "Watson", "Aconcagua", "\"Bake Off Bridge\"", "1924", "Eugene Levy", "zona glomerulosa of the adrenal cortex", "Nicole Kidman", "last summer.", "\"Awearness: Inspiring Stories About How to Make a difference\" (DK Adult)", "37", "banker", "a eyelid", "the Cubs", "pickpocket"], "metric_results": {"EM": 0.5, "QA-F1": 0.5976107955072021}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7741935483870968, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.05128205128205129, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.5, "CSR": 0.49378551136363635, "EFR": 0.96875, "Overall": 0.6857102272727272}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "Those arrested early Monday included the Pakistani Taliban's chief in Punjab, according to Anwar.", "Salt Lake City, Utah,", "normal maritime", "Inma Bazaar (Ostra Forstadsgatan 9)", "to make space for two ocean wind farms -- taking up 2 percent of the state's waters -- without angering fishing industries, killing whales or harming ecosystems.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "killed at three people and wounded 15 others,", "\"I would like to present you with a little gift that represents what President Obama and Vice President Biden and I have been saying and that is: 'We want to reset our relationship and so we will do it together.'\"", "as club managers,", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group", "14", "\"It was difficult for him to talk about. Difficult for us to listen to,\"", "Kerstin Fritzl,", "Defense of Marriage Act", "Europe", "for not doing more since taking office.", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "Greeley, Colorado,", "a grocery store", "flying glass and rocks.", "opium poppies", "Daniel Radcliffe", "more than 1.2 million people.", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million", "Krishna Rajaram,", "a long-range missile", "Emmy-winning Patrick McGoohan,", "he said Chaudhary's death should serve as a warning to management,", "Taher Nunu", "state senators", "2,000 euros ($2,963)", "Sunita Bhamb Kabul", "\"To the United States can learn much from Turkey's expertise on Afghanistan and Pakistan -- not the kind of society the Taliban has been providing.", "Yemen", "10 municipal police officers", "Carl", "central business district of Bangkok", "journalists and the flight crew", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England and Ireland", "beef", "Sleyman", "woodland", "Ramadan"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5580821903458072}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 0.1904761904761905, 1.0, 1.0, 0.0, 0.07407407407407407, 1.0, 0.13333333333333333, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.23255813953488377, 0.6666666666666666, 0.8571428571428571, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.07692307692307693, 0.0, 1.0, 0.5714285714285715, 0.3157894736842105, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.0, 0.33333333333333337, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-3441", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2192", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-3515", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763", "mrqa_searchqa-validation-6846"], "SR": 0.421875, "CSR": 0.4929775280898876, "EFR": 1.0, "Overall": 0.6917986306179775}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron (133 ARS)", "Kim So-hyun", "president", "\" Talking Dead\"", "9\u201310 March 1945", "2011", "John D Rockefeller's", "during the early 1970s", "Asiana Town", "rock and roll", "Rockland County", "Manitowoc County, Wisconsin,", "34.9 kilometres", "1967", "alcoholic drinks", "Fiat Chrysler Automotive NV", "Chrysler", "Australia", "gorillas", "\"Traumnovelle\" (\" Dream Story\"),", "Joshua Rowley", "Robert Digges Wimberly Connor", "Brad Wilk", "Beatles", "Baden-W\u00fcrttemberg, Germany", "2001 NBA All-Star Game", "Rihanna", "95 AD", "1614", "French", "\"The Manhunter from Mars\"", "Mondays", "Michael Jordan", "\"I, (Annoyed Grunt)-bot\"", "bank of chicago", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "Irish Parliamentary Party", "Jon M. Chu", "1822", "\"Mulberry\"", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act of 1854", "Scandinavian design", "Buck Owens", "Big Machine Records", "UK Mail, UPS, Parcelforce, DHL, Hermes, Royal Mail", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "the Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "\"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "\"I Woke Up In Love This Morning\"", "Mickey Spillane", "housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.629935515873016}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false], "QA-F1": [0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_searchqa-validation-16394", "mrqa_newsqa-validation-3369"], "SR": 0.53125, "CSR": 0.49340277777777775, "EFR": 0.9666666666666667, "Overall": 0.6852170138888889}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2004", "singer", "Pakistan", "1754", "\" Hero\"", "VfL Wolfsburg", "d\u00eds", "David Villa", "Adrian Peter McLaren", "2013", "early colonist of South Australia", "\" Cleopatra\"", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Devraj", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14,", "2,664", "Tamil", "Objectivism", "Chicago", "Gatwick Airport", "Riot Act", "Helensvale", "January 30, 1930", "22 September 2015", "October 29, 1985", "35,124", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Sir Seretse Goitsebeng Maphiri Khama, GCB, KBE", "Scandinavian design", "Mike Pence", "Barack Obama's Cabinet", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "Rated Before Christmas", "Presbyterian Church", "138,535 people", "Ry\u016bky\u016ban", "1972", "Stern-Plaza in Potsdam", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravity", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing speed record.", "Robert", "dolls", "Thunderball", "carbon dioxide", "Shout Wipe"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6555500394834635}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.30434782608695654, 1.0, 1.0, 1.0, 0.2564102564102564, 0.5, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-3261", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4116", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-2734", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-1363", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-4050", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-10146"], "SR": 0.5625, "CSR": 0.49416208791208793, "EFR": 0.9642857142857143, "Overall": 0.6848926854395604}, {"timecode": 91, "before_eval_results": {"predictions": ["Wings of Desire", "TouchTunes", "Jaguar", "the Gateway Arch", "Friday", "Sabino Canyon", "Orlando Bloom", "Babe Ruth", "the Home and Family", "Arkansas", "Mike Tyson", "themis", "collecting", "The Prairie Wolf", "bucolicus", "Oye Como Va", "Hydrogen", "Ben Jonson", "malignant disease", "Margaret", "Salt Lake City", "San Francisco", "1960s", "Mary Baker Eddy", "Bank One", "College of William & Mary", "the Wright Brothers", "badminton", "John Deere", "sonnet 43", "Pontiac", "Reptiles", "Georgia Bulldogs", "Key lime pie", "Lettuce", "the 101 Nights", "bumblebee", "Savannah", "Rickey Henderson", "herringbone", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Iraq", "Jean-Paul Marat", "Sir Henry Bartle Frere", "Bay of Montevideo", "a bank, drawn on the bank's own funds and signed by a cashier", "McDonald\u2019s", "Bobby Brown", "british town of Aquae Sulis", "1.5 million", "Macomb County", "Kristoffer Rygg", "boats are expected to arrive in Veracruz, Mexico,", "Monday night.", "23", "biographer"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5786221590909091}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.25, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1820", "mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-10498", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-3331", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-10866", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-6211", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_triviaqa-validation-3665", "mrqa_hotpotqa-validation-2255", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_newsqa-validation-979", "mrqa_hotpotqa-validation-4539"], "SR": 0.46875, "CSR": 0.4938858695652174, "EFR": 0.9705882352941176, "Overall": 0.686097945971867}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico, Virginia", "the East River", "Julius Caesar", "William Shakespeare", "yurtions", "Alaska", "Sputnik", "Richmond", "the period", "Java", "a baritone", "Reginald", "the Flag", "charring", "wuthering Heights", "Ali", "September 20, 1934", "the Black Pearl", "Charles de Gaulle", "Chesterfield Virginia", "a wolverine", "Josephine", "salt", "a subpoenas", "William Tell", "Texas", "Lapland", "Tom Canty", "Andrzej Wajda", "Joan Didion", "a frigate", "Baltimore", "the Bay of Bengal", "John Morton", "Clinton", "Terrific", "geology of Mars", "six", "Washington", "the Ship of Fools", "Haunted Zone", "tendang", "a genie", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "manic", "the Hudson Bay", "lighter", "a scuffle with the Beast Folk", "Jason Dench", "Alps", "Porthmadog (disease)", "Nairobi, Kenya", "\"Love Streams\"", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane, president of Green Apple Barter Services in Pittsburgh, Pennsylvania.", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5351896367521367}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-6225", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15084", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-6867", "mrqa_newsqa-validation-716"], "SR": 0.453125, "CSR": 0.49344758064516125, "EFR": 0.9714285714285714, "Overall": 0.6861783554147465}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Alice Cooper", "Telma Hopkins", "David Ogden Stiers", "1947", "drivers who were 2016 Pole Award winners, former Clash race winners, Former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "Highway 68 ( Holman Highway / Sunset Drive ) and 17 - Mile Drive marks the entrance to Pebble Beach", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Frieza's body in red fur", "Audrey II", "January 2017", "NIRA", "1922", "Julie Pru Kavner", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "Peter Stuyvesant", "his brother, who died in action in the United States Army", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3", "Bill Irwin", "Napoleon", "Hem Chandra Bose", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Uranus", "hyperinflation", "1939", "Lauren Blumenfeld", "Sanaa Lathan", "the Philippines", "Sauron", "Lana Del Rey", "a statistical advantage for the casino that is built into the game", "159", "Sino - Indian War of 1962", "Rah, Rah, Jayhawk, Go KU", "works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "activates a relay which will handle the higher current load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "During metaphase the X- shape structure", "dollar", "( Robin) Hood\\'s (Monty) Python\\'s A Holy Grail", "Snowshoe", "February 13, 1946", "Square Enix", "Congo River", "Jason Chaffetz", "\"The Da Vinci Code,\"", "\"Don't you know that is what Jenny Sanford. She is not going to humiliate herself by standing next to a story,\"", "Khrushchev", "( Julie) Andrews", "Headless Horseman", "(Mary) Phagan"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5581043956043956}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 0.33333333333333337, 0.8571428571428572, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666665, 0.0, 0.4615384615384615, 1.0, 0.2, 0.33333333333333337, 0.0, 0.25, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_hotpotqa-validation-102", "mrqa_newsqa-validation-3374", "mrqa_newsqa-validation-3849"], "SR": 0.453125, "CSR": 0.4930186170212766, "EFR": 0.9428571428571428, "Overall": 0.6803782769756839}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "Thon Maker", "Battle of Chester", "Guinness World Records", "1864", "on the shore,", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado", "Revengers Tragedy", "Japan", "rural", "8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "Pantone Matching System (PMS)", "Las Vegas Boulevard", "intelligent Design:", "Barbara Ryan Coleman", "William Scott Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevrolet Corvette Stingrays", "\"thirtysomething\"", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "\"Pour le M\u00e9rite\"", "audio mastering", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed\\'s Chronicles", "August 9, 2017", "Bangalore University", "1 April 1985", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "giant planet", "dental alveoli", "Dortmund", "kobina Eric", "Maria Alexandrovna", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6572172619047619}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, true], "QA-F1": [0.8333333333333333, 0.8, 1.0, 0.0, 0.5, 0.0, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.47619047619047616, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-1656", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.53125, "CSR": 0.493421052631579, "EFR": 1.0, "Overall": 0.6918873355263158}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies", "Sir Charles Benedict Ainslie, CBE", "1978", "The Golden Egg", "Scott Mosier", "1950", "Roy Spencer", "1964", "Kansas City, Missouri", "World of Wonder", "March", "Russian", "James Coburn, Camilla Sparv, Aldo Ray, Nina Wayne, Todd Armstrong, Robert Webber, Rose Marie, and Harrison Ford", "July 25", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "\"Northern Lights\"", "coca wine", "the Mach number (M or Ma)", "Terrina Chrishell Stause", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "Deputy Vice-Chancellor", "Song Il-gon", "Teen Titans Go!", "Liverpool F.C.", "Grammy Award", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "\"right\" whale to kill on a hunt", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "professional boxer", "Forever Living Products, Inc.", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "April.", "\"The Da Vinci Code,\"", "Dogpatch Labs Europe", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6626488095238094}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true], "QA-F1": [0.8, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-2580", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-1059", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4470", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-191", "mrqa_searchqa-validation-14503"], "SR": 0.546875, "CSR": 0.49397786458333337, "EFR": 1.0, "Overall": 0.6919986979166667}, {"timecode": 96, "before_eval_results": {"predictions": ["Prince Sung-won", "1927", "16,116", "The 2012 Summer Olympics", "at the end of the 18th century", "1942", "The Highwaymen", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Syracuse", "Jonghyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3", "chocolate-colored Labrador Retriever,", "Norman Graham Hill", "1952", "Neneh Mariann Karlsson", "Eminem", "\"Love Streams\"", "In a Better World", "The Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker and Matt Stone", "Pimp My Ride", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "John Francis Kelly", "early Romantic period", "The Food and Drug Administration", "the Sun", "Indraneil Sengupta", "1692", "the power to regulate navigation", "The Wu-Tang Clan", "\" Kids\"", "\"The Expendables 2\" (2008)", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "right", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "bread pudding", "a briefcase", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7957228535353535}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.8, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_hotpotqa-validation-4514", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789", "mrqa_searchqa-validation-1980"], "SR": 0.671875, "CSR": 0.4958118556701031, "EFR": 0.9047619047619048, "Overall": 0.6733178770864015}, {"timecode": 97, "before_eval_results": {"predictions": ["( Eddie) Redmayne", "caucausus", "David Bowie", "Steve Davis", "Granada", "Treaty of Brest-Litovsk", "Marx", "Paramounts", "Marilyn Monroe", "cyanoguttatus", "1957", "1930\u2019s", "transsexual", "Fred Astaire", "germany", "(George) Gently", "Long Island", "fair", "a airplane", "Rudyard Kipling", "1921", "\u201cHamish Macbeth\"", "Desdemona", "avocate", "(Frans) Hals", "New Democracy", "Ford", "soybean", "Cole Porter", "1830", "w W Jacobs", "Parthenon", "Paddy Doherty", "(Thomas) Aquinas", "Dubonnet", "elephant", "Tigran Petrosyan", "u", "Westminster Abbey", "Canada", "seal", "Edward VII", "Tombstone", "island of greece", "Mr. Tickle", "worcester Cathedral", "Mercury", "December 7, 1941", "middle ear", "Nadia Comaneci", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Electronic Attack Squadron 135", "95 AD", "170", "Mad Men", "Carol Fowler", "awe-inspiring", "the Caspian Sea", "Basilica Cathedral of Lima", "1922 to 1991"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5713541666666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-4459", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_newsqa-validation-4053", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_searchqa-validation-16068", "mrqa_naturalquestions-validation-7080"], "SR": 0.515625, "CSR": 0.4960140306122449, "EFR": 0.967741935483871, "Overall": 0.6859543182192231}, {"timecode": 98, "before_eval_results": {"predictions": ["he'll send a text message and e-mail to his supporters to let them know who his sidekick will be.", "Afghanistan's", "the hunt for Nazi Gold and possibly the legendary Amber Room will end Friday after the two men leading the expedition had a disagreement.", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems", "then-Sen. Obama", "She attorney, Gloria Allred,", "581 points", "The Everglades,", "Herman Cain", "Mark Hampton", "3-0", "what caused the collapse of the building", "Former Mobile County Circuit Judge Herman Thomas", "celebrities", "economic growth and creating opportunity for our people.", "Phillip A. Myers.", "I went to stay with my Uncle Jack in Miami Beach.", "\"scheduled testing,\"", "London and Buenos Aires", "Sheik Mohammed Ali", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "\"It was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\"", "(Bill) Arnold and husband Bill Klein,", "record breaking victory as he claimed his sixth world title at a different weight by beating Cotto on Saturday night.", "Austin, Texas,", "17-month", "him to be included in the family allowance.", "Manmohan Singh's Congress party,", "\"I'm certainly not nearly as good of a speaker as he is.\"", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fort Bragg in North Carolina.", "Bill Haas", "Consumer Reports magazine", "28", "step up.", "42 years old", "since 1983.", "particular health ailment or beauty concern.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Derek Mears", "\"I want to get the job done. We have identified a problem -- let's go solve it together.\"", "fastest circumnavigation of the globe in a powerboat -- and now Earthrace is for sale.", "$104,327,006", "18th time", "Haeftling,", "on a side table", "Shinsuke Nakamura", "Bart Millard", "nismo", "arch bridges", "jMW Turner", "the Marx Brothers film", "Indian", "World War I,", "a (department) who will hold their breath till they turn blue to get their way.", "The 70th Academy Awards", "(William) Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5272757796964033}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true], "QA-F1": [0.14285714285714285, 1.0, 0.34782608695652173, 0.9210526315789475, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.8333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.7692307692307692, 0.09090909090909091, 1.0, 0.0, 0.15384615384615383, 0.6666666666666666, 0.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.1, 0.15384615384615385, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-3008", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-2749", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-3853", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191", "mrqa_searchqa-validation-3745"], "SR": 0.390625, "CSR": 0.4949494949494949, "EFR": 0.9230769230769231, "Overall": 0.6768084086052836}, {"timecode": 99, "UKR": 0.685546875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.865234375, "KG": 0.484375, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "all time", "Oregon Ducks", "Arkansas", "2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "GZA", "Broadcasting House in London", "Lexy Gold", "sitcom \"Barney Miller\"", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "What's Up", "Saturday Night Live", "Mythology", "Tumi Holdings, Inc.", "Black Ravens", "residential", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Bardstown, Kentucky", "Abraham \"Grampa\" Simpson", "25 million", "Athenion", "James G. Kiernan", "Detroit rock band, the MC5", "James City County,", "Tunisian", "Linda Ronstadt", "United Kingdom", "21st birthday", "the Neotropical realm", "Sister, Sister", "five-time", "Stephen John Coogan", "13 May", "Kevin Spacey", "Stalybridge Celtic", "an idea of laying out a tournament ladder by arranging slip of paper with the names of players on them", "Frank Zappa", "1989", "applea", "fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Manchester United's", "Friday,", "Lifeboat", "a megabit", "his stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6676636904761905}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.6666666666666666, 0.64, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-5774", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-14144"], "SR": 0.53125, "CSR": 0.49531250000000004, "EFR": 1.0, "Overall": 0.70609375}]}