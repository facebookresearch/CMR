{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 7980, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Stanford University Professor of Comparative Literature Richard Rorty, and American writer and satirist Kurt Vonnegut", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8216187280399118}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay in Alaska", "120 m ( 390 ft )", "the eighth season will have only six episodes", "100", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "the Ironclads", "Spain"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7738026486978469}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.888888888888889, 0.4444444444444445, 0.6666666666666666, 0.4, 1.0, 0.5853658536585366, 0.38095238095238093, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.8571428571428571, "Overall": 0.7957589285714286}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "In October 1973, the price was raised to $42.22", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.6875, "QA-F1": 0.772172619047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.2, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.6875, "CSR": 0.72265625, "EFR": 1.0, "Overall": 0.861328125}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "that narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "evading it", "the kettle and the Cricket, at one and the same", "Gandhi", "Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4 x 365 = 730 days", "Tiger Woods' 1996 U.S. Amateur Win", "1867 to 1877", "Marshall Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "LASER abbreviation", "Jean Dapra", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "the fear of riding in a car", "American", "Mexican military"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6228263923576424}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.2666666666666667, 0.0, 0.3076923076923077, 0.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-2804", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.53125, "CSR": 0.684375, "EFR": 1.0, "Overall": 0.8421875}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "complexity theory", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million people", "the Lippe", "Video On Demand content", "time and storage", "semester", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "the League of the Three Emperors", "science", "143,007", "Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "(Bones remains the oils base man still)", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7922994438159879}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-9753", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.71875, "CSR": 0.6901041666666667, "EFR": 1.0, "Overall": 0.8450520833333334}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Benjamin Burwell Johnston, Jr.", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp (born July 17, 1964)", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "English former international footballer", "the Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "a novel", "the Eastern part", "Polar Bear", "The Atlantic City Boardwalk"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7736344537815126}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.3333333333333333, 0.5, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.609375, "CSR": 0.6785714285714286, "EFR": 1.0, "Overall": 0.8392857142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "input", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "nearly", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "a deterministic Turing machine", "Bart Starr", "oxygen", "the Karluk Kara-Khanid ruler", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCorm (born 20 July 1983)", "Black Mountain College", "a secularist and nationalist", "Bothtec", "Cody Miller", "140 to 219 passengers", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "2005", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Wheat Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7026041666666667}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-3091", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.65625, "CSR": 0.67578125, "EFR": 1.0, "Overall": 0.837890625}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "teachers through the web in order to earn supplemental income", "stratigraphic", "commensal flora", "a + bi", "the constituting General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers who made tape recordings of the show", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham", "A55", "Ranulf de Gernon, 4th Earl of Chester", "\u00c6thelstan", "Madras Export Processing Zone", "44", "NCAA's Division I", "Araminta Ross", "Manchester United", "Dragon TV", "Greek-American", "diastema ( plural diastemata )", "Shirley Horn", "Iran", "Bigfoot", "Papua New Guinea", "Edgar Degas", "Manchester"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7774621212121212}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-1501", "mrqa_squad-validation-2238", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-1423"], "SR": 0.71875, "CSR": 0.6805555555555556, "EFR": 0.8888888888888888, "Overall": 0.7847222222222222}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "French", "Museum of the Moving Image in London", "he sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the spin", "a pivotal event", "an American YouTube personality, spokesmodel, television personality, and LGBT rights activist", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "American actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "Afroasiatic", "James Tinling", "Italy", "the 79th Masters Tournament", "Ulver and the Troms\u00f8 Chamber Orchestra", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscous", "more than 22 million", "morphine sulfate oral solution 20 mg/ml", "The Firm", "a species of freshwater airbreathing catfish"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6738692344183331}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_naturalquestions-validation-10208", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.6734375, "EFR": 1.0, "Overall": 0.83671875}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "the Rhine-Ruhr region", "pedagogy", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The Onion", "Mickey Mouse series characters", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Halle Orchestra", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "the Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "The Londoner"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7266505478533095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.65625, "CSR": 0.671875, "EFR": 0.9545454545454546, "Overall": 0.8132102272727273}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "oil shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "a whole industry", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "does not involve MDC head Morgan Tsvangirai", "lack of a cause of death", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong from other parts of Asia", "opposition party members", "Missouri", "a \"Racism and racist conversations have no place today in America.\"", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "in her home", "Employee Free Choice", "Bush administration", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "a Japanese ex-wife", "Dan Parris, 25, and Rob Lehr", "apartment near Fort Bragg", "two", "nearly $2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "The singer's personal security guard, Andrew Morris", "the Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 )", "a late 19th century figurehead for female empowerment", "Richmondshire", "1994", "The Conjuring", "The Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6180441086691087}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-3637", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-2344", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.515625, "CSR": 0.6588541666666667, "EFR": 1.0, "Overall": 0.8294270833333334}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "Christ who is the victor over sin, death, and the world.", "Napoleon", "mass production", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "beneath the university's Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "richmond", "Salvador Allende", "Marie Antoinette (Fraser)", "Hawaii", "Erik Thorvaldson", "Apollo", "Pal Joey", "Mary Seacole", "green", "Indonesia", "supreme religious leader of the Israelites", "Antonio", "European Economic Community (EEC)", "Christine Keeler", "Jesus", "Jack Nicholson", "four", "Netherlands", "Sugar Baby Love", "Rosa Parks Bus", "Sean", "Bill and Taffy Danoff", "early", "Travis", "The Show", "Robert Kennedy", "Q", "an umbrella", "a French author", "barber", "Harry Hopman", "Murrah Federal Office Building", "Evita", "oldpatricktoe-end", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "no mention of their relationship with co-stars Chris Noth or John Corbett?", "a delegation of American Muslim and Christian leaders", "Royal Wives", "University of South Carolina", "Kim Clijsters."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6347470238095239}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 1.0, 0.07142857142857144, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_newsqa-validation-1150"], "SR": 0.578125, "CSR": 0.6526442307692308, "EFR": 0.9629629629629629, "Overall": 0.8078035968660968}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "in Medieval Latin, 9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "James Clerk Maxwell", "in whole by charging their students tuition fees.", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "moles", "leucippus", "fred", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz tenor saxophonist", "1/6", "komando Pasukan Khusus", "Carlisle", "liquid", "Chillicothe and Zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "aniridia", "stearns Eliot", "River Forth", "woe", "NOW Magazine", "j Jesse James", "Italy", "Canada", "typhoid fever", "Tina Turner", "action figure", "Walt Kowalski-Gran Torino", "2010", "einasto's law", "Venezuela", "fred stooge", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Chris Weidman", "Athletics Stadium", "one", "Virgin America", "jinn Stafford", "aaron stremlau", "Iran's parliament speaker", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike."], "metric_results": {"EM": 0.5, "QA-F1": 0.5537202380952382}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1002", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-2463", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.5, "CSR": 0.6417410714285714, "EFR": 1.0, "Overall": 0.8208705357142857}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public", "the most cost efficient bidder", "acorn", "gaius", "thighbone", "Olympia", "Ukraine", "shrews", "Teri Hatcher", "bennett", "amber", "high school football", "a pardon", "180 degree", "bishkek Tajikistan", "anamosa", "grouchy", "Ephesus", "an asylum", "jedoublen/jeopardy", "knife", "eyes", "Cologne", "ganley", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "buffalo", "raoul", "shrews", "Japan", "burt Reynolds", "thant", "boys", "accordion", "stanley johnson", "germanicus", "Augusta", "counter clockwise", "2013", "Tucker Crowe", "Coldplay", "December 24, 1973", "David Weissman", "bikinis", "Tibet", "memories of his mother", "Israel"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4536458333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7000000000000001, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084"], "SR": 0.390625, "CSR": 0.625, "EFR": 0.9743589743589743, "Overall": 0.7996794871794872}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Latin Rhenus", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "the word crossword", "Jerry Maguire", "Strongsville, Ohio", "Flemish", "MasterCard", "( Roger) Stempel", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "(solar lentigo)", "a gang of ex-cons rob a casino", "the Toronto Maple", "(Zsa) Gabor", "method acting", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "a kangaroo pal", "pro bono", "Universit degli Studi di Siena", "a candy store", "a brown ale", "Manfred von Richthofen", "Nacho Libre", "copper", "devils or demons", "the hemlock", "( Jeffrey S. Wigand)", "National Poetry Month", "The Runza Way", "a meager allowance", "1942", "blimps", "( Gustav Kirchhoff)", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "Grant Wood", "a tin star", "dark", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.5, "QA-F1": 0.6291666666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-13453", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.5, "CSR": 0.6171875, "EFR": 1.0, "Overall": 0.80859375}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho Chi Minh", "circumference", "the Inuit", "Detroit Rock City", "the Toronto Blue Jays", "Lincoln", "(Ray) Bradbury", "crimes committed out of hatred for someone's race", "King Julien XIII", "Nicolas Sarkozy", "Rubicon", "(Conello)", "17", "(Louisa) May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "(Bellerophontes)", "Balaam", "the Wharton School", "The Caine Mutiny", "The Allman Brothers Band", "(F.) W. Woolworth Company", "(John) Coltrane", "the peace sign", "oxygen", "the Sphinx", "Jan Hus", "The USA Network's original grassroots talent search", "Mavericks", "Onegin", "Macy's", "a cotton-spinning machine", "(Santa) Claus", "(Denzel) Washington", "negligence", "courts", "attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "prisoners", "salary", "punishment"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6490956959706959}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.6666666666666666, 1.0, 0.2, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-1759"], "SR": 0.53125, "CSR": 0.6121323529411764, "EFR": 0.9666666666666667, "Overall": 0.7893995098039215}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Robert Lane and Benjamin Vail", "a ring", "Party of National Unity", "22", "the Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "preston", "Puerto Rico", "The Mausoleum", "The World Through More Than One lens", "Switzerland", "German World Airlines", "The Old Man and the Sea", "French", "Joe Louis", "the Nemean lion", "d'Artagnan", "the Bayeux Tapestry", "Front Porch", "China", "Shia", "notes", "Hawking", "Cicero", "Memphis", "Mountain Dew", "The Little Prince", "Quilt", "FRAM", "the House of Representatives", "beer", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Summer", "Fiddler on the Roof", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "a base", "Bromley-By- Bowen", "the Ruul", "Cartoon Network", "Caylee Anthony", "what their cars say about them", "an Afghan president who had been leading the Afghan peace council", "nuclear", "The drama of the action in-and-around the golf course has enraptured fans of the game through the generations and around the world."], "metric_results": {"EM": 0.65625, "QA-F1": 0.6828497023809523}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.25, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-2709", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-1396", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.65625, "CSR": 0.6145833333333333, "EFR": 1.0, "Overall": 0.8072916666666666}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "the mid-18th century", "blood", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a halfback", "a trowel", "Big Bang", "The Sex Pistols", "endodontist", "Saturn", "the Cliffs of Dover", "Genoa", "Fanchette", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "polyantha", "The Hampton Inn", "10", "the Civil War", "alevin", "Paul McCartney", "omega-3", "The School of Athens", "Bachman Turner Overdrive", "horror", "Cinderella story", "Tokyo", "Panama", "Confession", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "bears", "a quake", "Judas", "elephants", "Pomerania", "Sweden", "a covert operations", "country", "May 2010", "in the majority of the markets the company has entered", "Sugarloaf Mountain", "Thailand", "gender queer", "Minister for Social Protection", "Germany", "the estate", "Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.484375, "QA-F1": 0.578558737458194}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-10266", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-2870"], "SR": 0.484375, "CSR": 0.6077302631578947, "EFR": 1.0, "Overall": 0.8038651315789473}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "Earth", "53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Saturday", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Bill", "1991", "118", "Cornett family", "Acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic", "a natural history and not on the Biblical account", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Necator americanus and Ancylostoma duodenale", "February 29", "the Lykan", "disagreements involving slavery and states'rights", "an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "a man called Lysander", "Jupiter", "east", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "an olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6332775297619048}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.625, 0.0, 0.2, 0.8, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.515625, "CSR": 0.603125, "EFR": 0.967741935483871, "Overall": 0.7854334677419355}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape", "illegal crossings", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "over 1,000 pounds", "\"no need to fight the oppression of the former Mubarak regime.\"", "Mutassim", "south of there... from Memphis [Tennessee] to Little Rock [ Arkansas], and even over to Chattanooga (Tennessee)", "Polo", "Joe Jackson", "Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus", "prisoners", "September, 2004", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "GospelToday", "\"It is I, the chief executive officer, the one on the very top, should be responsible for this,\"", "\"There's no chance of it being open on time. Work has basically stopped.\"", "\"There is a pressing need for them to be released,\"", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter", "Whitsunday", "Aberdeen", "\"Dumb and Dumber\"", "The Tigers compiled an 11\u20131 regular season record and then defeated the No. 5 Georgia Bulldogs in the SEC Championship Game", "Minton", "focal point", "autu", "season five", "Revenge of the Wars ( 2005)"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6030789139588482}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.4, 1.0, 0.923076923076923, 0.8571428571428571, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2666666666666667, 0.08, 0.052631578947368425, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.3333333333333333, 0.22222222222222224]}}, "before_error_ids": ["mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.484375, "CSR": 0.5974702380952381, "EFR": 1.0, "Overall": 0.7987351190476191}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "El Centro metropolitan area and San Diego-Carlsbad-San Marcos metropolitan area", "chief electrician", "Newton", "static friction, generated between the object and the table surface", "the assassination of US President John F. Kennedy", "the Kenyan forces crossing of the joint border as \"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.\"", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad, Iran.", "Amanda Knox's aunt", "jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "nurse who tried to treat Jackson's insomnia with natural remedies", "Sarah", "will be inducted into the Baseball Hall of Fame in July.", "1981", "\"17 Again,\"", "Chevron", "$81,88010", "Republicans", "EU naval force", "Chris Robinson", "Andre Mba Obame", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5.", "\"It was never our intention to offend anyone,\"", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2008)", "Northumbrian", "\"Get Thee To A Nunnery\"", "Elena Ceausescu", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold,"], "metric_results": {"EM": 0.5, "QA-F1": 0.5928472263031086}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 0.4, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-3424", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107"], "SR": 0.5, "CSR": 0.5930397727272727, "EFR": 0.96875, "Overall": 0.7808948863636364}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia, especially.", "two", "glowed even when turned off.", "five female pastors", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor", "a federal judge in Mississippi", "the department has been severely affected by the earthquake,", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Kase Ng,", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain,", "women.", "longest domestic relay in Olympic history", "Zimbabwe's main opposition party", "No. 1", "nine", "Four bodies", "Friday", "Kingdom City", "Rima Fakih", "the two-hour finale.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "his salary", "Damon Bankston", "scientists", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning -- the FDA's strongest -- to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Rima Fakih", "Isthmus of Corinth", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "collarbone", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Viva Zapata", "The Cricket on the Hearth"], "metric_results": {"EM": 0.46875, "QA-F1": 0.622955274291991}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.20000000000000004, 1.0, 1.0, 0.0, 0.8235294117647058, 1.0, 0.5, 0.19999999999999998, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.23529411764705882, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.46875, "CSR": 0.5876358695652174, "EFR": 1.0, "Overall": 0.7938179347826086}, {"timecode": 23, "before_eval_results": {"predictions": ["phycoerytherin", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Hyundai", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over,\"", "threatening messages", "stop Noriko Savoie from being able to travel to Japan for summer vacation.", "citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "Tim Masters,", "martial arts", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani officials,", "Zuma", "haute, bandeau-style little numbers", "five", "Iraqi Prime Minister Nouri al-Maliki", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Jobs", "$81,88010", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "phase of sleep", "noun", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "Thinkpad", "Apollo 13", "Florida"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6502840620028121}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.962962962962963, 0.08333333333333333, 0.5, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0606060606060606, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458"], "SR": 0.5625, "CSR": 0.5865885416666667, "EFR": 1.0, "Overall": 0.7932942708333334}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria,", "Lindsey Vonn", "Unseeded Frenchwoman Aravane Rezai", "him to step down as majority leader.", "United Nations World Food Program vessels carrying food and relief supplies to war-torn Somalia,", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "will be at the front of the line, self-righteously driving under the speed limit on his or her way to save the world.", "1979", "Heshmat Tehran Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh", "Michael Arrington,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "behind the counter.", "11", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "all animal products.", "Vicente Carrillo Leyva, a leader of the Carrillo Fuentes drug cartel,", "Symbionese Liberation Army", "$8.8 million", "work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of unbiasedity.", "black is beautiful", "$104,327,006", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade after a new survey showed how the drug dominates Afghanistan's economy.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance\"", "famous faces like NHL hockey star Alexander Ovechkin, Russian Vogue editor in chief Aliona Vodianova, acclaimed conductor Valery Gergiev, the \"Russian Madonna\"", "\"Pullers of the Lost Ark.\"", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "the division of Italy into independent states", "Sebastian Lund ( Rob Kerkovich )", "Jimmy Carter", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6136793675954426}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.4, 0.06896551724137931, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.05555555555555555, 1.0, 0.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 1.0, 1.0, 0.08, 0.1142857142857143, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.484375, "CSR": 0.5825, "EFR": 0.9696969696969697, "Overall": 0.7760984848484849}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "beetle", "arthropods", "Wayne Allwine", "St Pauls", "holography", "Pelias", "Daniel Boaventura", "Northumbria", "Harvard", "Australian cricketer", "Seymour Hersh,", "a long pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "pityriasis capitis", "three", "a spicy varietal", "Joseph Smith,", "Huntington Beach, California", "palladium", "the moon", "13", "a peplos", "The Virgin Spring", "Canada", "Winston Churchill", "Stockholm", "Peter Parker", "Goldie Myerson,", "Giorgio Armani,", "bullfight", "Sparks", "Ginger Rogers", "the Rock of Gibraltar", "Comedy Playhouse", "citric", "Charles Darwin", "John", "Miss Scarlet,", "Marie Van Brittan Brown", "Southern California", "1995", "Bourbon", "Taylor Swift", "Rihanna", "had his personal.40-caliber pistol,", "The Detroit, Michigan, radio station promotion", "Amy Bishop,", "cad", "the Louvre", "approximately 7300 students"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5388392857142856}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.453125, "CSR": 0.5775240384615384, "EFR": 0.9714285714285714, "Overall": 0.7744763049450549}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "eight", "affordable housing", "Mao Zedong", "Verona", "New York", "elephants", "a large party of guests.", "Frank McCourt", "jules Verne", "Judy Cassab", "moyra Fraser", "Schengen Area", "A", "city of Sheffield, England,", "Famous Players-Lasky Corporation", "the Beatles", "Gerald Durrell", "jzebel", "Cork", "jason", "Arabian", "Halifax", "Noises Off", "england", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "sonja Henie", "Jeremy Thorpe", "1768", "\u201cFor Gallantry;\u201d", "Wednesday's child", "Caucasus", "Cahaba", "The Good Life", "Tahrir Square", "uranium", "Count de la F\u00e8re", "27", "Jack Ruby", "tintoretto", "Eric Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "a heart rate that exceeds the normal resting rate", "672", "Linda McCartney's Life in Photography", "The Frost Place Advanced Seminar", "a keystroke", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.515625, "QA-F1": 0.559375}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.515625, "CSR": 0.5752314814814814, "EFR": 0.967741935483871, "Overall": 0.7714867084826762}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "forced Tesla out leaving him penniless.", "Benazir Bhutto,", "Iran's nuclear program.", "at least 27 Awa", "(l-r) Paul McCartney, Yoko Ono Lennon, Olivia Harrison and Ringo Starr", "Daniel Cain,", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Afghanistan", "The Everglades,", "made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "a 15-year-old boy", "about $163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "around 3.5 percent of global greenhouse emissions.", "ensenada", "Orbiting Carbon Observatory", "Switzerland", "harold ramford", "Janet and La Toya,", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "burned over 65 percent of his body after being set on fire,", "al-Shabaab", "posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "opryland", "Number Ones", "only normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Barack Obama,", "\"gotten the balance right\"", "The oceans", "\"scream and howl in pain\"", "doctors", "off the coast of Dubai", "Bill Haas", "Talisa Maegyr", "1932", "between 1923 and 1925", "gilda", "Nahum Tate", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "a rising sun"], "metric_results": {"EM": 0.453125, "QA-F1": 0.593829626148705}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 0.8, 0.28571428571428575, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 1.0, 0.0, 1.0, 0.6, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.453125, "CSR": 0.5708705357142857, "EFR": 1.0, "Overall": 0.7854352678571428}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai", "Monday night", "Bailey, Colorado,", "journalists and the flight crew will be freed,", "40", "Illuminati", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "between South America and Africa.", "Tetris", "Zimbabwe's electoral process.", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers program", "Vice's broadband television network.", "one of the most influential, powerful and admired public figures of our time,", "80 percent of the woman's face", "20,000-capacity O2 Arena.", "to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentine", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "17 Again", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "Puccini, in Turandot", "Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.5, "QA-F1": 0.6025881185807657}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4444444444444445, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 0.3529411764705882, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4004", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.5, "CSR": 0.568426724137931, "EFR": 0.96875, "Overall": 0.7685883620689655}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "Russian army", "diffuse nebulae", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "ancient Mesopotamia", "maintenance utility", "July 4, 1776", "\" pick yourself up and dust yourself off and keep going '", "John Garfield", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "1979", "Lorazepam", "2013 non-fiction book of the same name by David Finkel", "jonny", "Ethel `` Edy '' Proctor", "a ranking used in combat sports,", "Husrev Pasha", "Jodie Sweetin", "the palmar aspect of these fingers", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris", "the first four caliphs", "Lake Powell", "A tree - topper or treetopper", "September 6, 2019", "population", "substitute good", "Marries Betty", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Mamata Banerjee", "economy", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "people in the 20th century who used obscure languages as a means of secret communication during wartime", "Donny Osmond", "new Carthaginian Empire and the expanding Roman Republic", "George", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "the two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "\"Harold & Kumar Go to White Castle\""], "metric_results": {"EM": 0.375, "QA-F1": 0.5213315806057741}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0, 0.19999999999999998, 1.0, 0.7142857142857143, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.0, 0.5, 0.5, 0.5, 0.2857142857142857, 0.4, 1.0, 0.1, 1.0, 0.0, 1.0, 0.13333333333333336, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.19354838709677422, 1.0, 0.2, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.375, "CSR": 0.5619791666666667, "EFR": 0.95, "Overall": 0.7559895833333333}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "pioneers.", "Hutter", "shoes.", "novem", "Rashid Akmaev,", "acetylene", "an illegal substance", "fiber.", "a fox", "a rose by any other name", "Winston Rodney,", "sand", "Nanjing,", "Custer", "walking Camelot Knight #4 / French Taunter", "Louis XIV", "GILBERT & SullIVAN", "Fox Network", "Gaius Julius Caesar", "Ned Lamont", "the Boston Marathon", "fibreboard", "tin", "a wooden performance by Norwegian actor Toralv Maurstad", "Frida Kahlo", "his father had boycotted Thomas Jefferson's", "\"Y\" 2 \"K\": An Eskimo", "Fat man", "Hair", "William Randolph Hearst", "a basalt", "ale", "Eutheria", "telephone", "a song performed by English pop punk band Busted.", "Luther", "The New Colossus", "yelp", "Bernard Fokke,", "Sarah, Duchess of York", "Braddock", "a middleweight champion,", "bronchoconstriction", "Forty", "Argon Glow Lamps", "Red", "a Chenard", "Earl Long", "Neil Patrick Harris", "Owen Fielding", "1999", "vitamin D", "five", "Alberto juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan", "in Atlanta", "Sonia Sotomayor"], "metric_results": {"EM": 0.390625, "QA-F1": 0.44062500000000004}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-3579", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.390625, "CSR": 0.5564516129032258, "EFR": 1.0, "Overall": 0.7782258064516129}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park,", "the macula", "a cylinder", "a crossword clue", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "The Pittsburgh Cycle", "Juliet", "Notre Dame", "the Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a sandwich", "Chance", "kozo", "Tenzing", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate", "Ugly Betty", "R", "Zechariah", "New Jersey", "Lake Ontario", "Matt LeBlanc", "Baltimore", "John Ford", "fortune", "the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "gravitational force", "Isis", "a quiveir", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Dr. A.G. Ekstrand", "Duke Ellington", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon.\""], "metric_results": {"EM": 0.453125, "QA-F1": 0.5307291666666667}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16314", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-9799", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-114", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.453125, "CSR": 0.55322265625, "EFR": 1.0, "Overall": 0.776611328125}, {"timecode": 32, "before_eval_results": {"predictions": ["the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Emperor Norton", "CIA", "piano", "Rickey Henderson", "Indira Gandhi", "Daucus carota", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "a quark", "Show Boat", "Rudy Giuliani", "the Free Speech Clause", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel", "the Olympic Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Lindsay Davenport", "Los Angeles", "the east wind", "Richard III", "Labour", "The pen", "Croatia", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "France", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "The Queen of Hearts", "Part 2", "Coconut Cove", "aeoline", "a trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.625, "QA-F1": 0.6825201023391813}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.625, "CSR": 0.5553977272727273, "EFR": 1.0, "Overall": 0.7776988636363636}, {"timecode": 33, "before_eval_results": {"predictions": ["VHS, on MP3 CD-ROM, and as special features on DVD", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"something's wrong with this lady.\"", "the annual White House Correspondents' Association dinner", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Hundreds of women protest child trafficking and shout anti-French slogans Wednesday in Abeche, Chad.", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in five vignettes.", "a missile", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space,", "CNN", "no chance", "St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "The portrait of William Shakespeare", "Symbionese Liberation Army", "an incident which was described by judge Henry Globe as an \"explosion of violence.\"", "two tickets to Italy on Expedia.", "Colombia", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, calm near-black on red-eyes when it's time to sleep", "horses", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "Appathurai", "$40 and a bread.", "African National Congress Deputy President Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Harriet Tubman", "Mrs. Potts", "Peanuts Chocolate Candies", "The Star-Spangled Banner"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6488446041295306}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7058823529411765, 0.5, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.7499999999999999, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7682", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-1981", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-1622", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.5625, "CSR": 0.5556066176470589, "EFR": 1.0, "Overall": 0.7778033088235294}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "anti- strike", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcy", "nearly $2 billion in stimulus funds", "businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "children of street cleaners and firefighters.", "Piers Morgan", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduran", "Brazil", "environmental", "strife in Somalia,", "Roy", "the WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "lawyers trying to save their client from the death penalty", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "J. Crew.", "Department of Homeland Security Secretary Janet Napolitano", "543", "patients who received the first-ever near-total face transplant in the United States", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville,", "in critical condition", "Seoul,", "Nicole", "a school test score of 98 with a \"What about those other two points?\"", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "husband and attorney, James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "gentry", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1972", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.5, "QA-F1": 0.5879729211760463}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 1.0, 0.0, 0.3636363636363636, 0.9090909090909091, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.5, "CSR": 0.5540178571428571, "EFR": 1.0, "Overall": 0.7770089285714286}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position", "Northeastern Area State & Private Forestry", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "Purple taupe", "the Black Sea", "the Battle of the Little Bighorn", "the Shakers", "a bellwether", "immdiates de la conscience", "chips", "Boxer", "The Field Guide", "Mabel Harding", "Las Vegas", "The Bible", "the Rose Bowl", "Norman Rockwell", "Jackie Kennedy", "light tunais", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "a sundae", "Grace Evans", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Master of thunder, lightning", "Lou Gehrig", "meaning and origin", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina has always claimed sovereignty over the islands", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5854166666666667}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-13067", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.484375, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "nothing gained", "silver", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "the (Storch)", "dry ice", "Theodore Roosevelt", "Entourage", "eel", "Philadelphia", "The Museum of Modern Art", "the unicorns", "John C. Frmont", "Russia", "(Mary) StREISAND", "Hilda Rosner", "the Taj Mittal", "HISTORIC LEADERS", "Carmen", "Margaret Mitchell", "Quasimodo", "Sultans of Swing", "Pandarus", "languid", "(Burt) Reynolds", "the Sphinx", "Satchmo", "Saudi Arabia", "American new wave", "Arby\\'s", "coffee", "The Lgion", "Robert Burns", "The Incredible Hulk", "Atlanta", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "a wolf", "The Interruption", "Edith Piaf", "Ivan III", "prologue", "birch", "Anthony Mayfield", "Jack Gleeson", "(Phil) Hurtt", "animals phobia", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"State of Play\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6484375}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-4018", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_triviaqa-validation-1125", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-1525"], "SR": 0.59375, "CSR": 0.5532094594594594, "EFR": 1.0, "Overall": 0.7766047297297297}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "Kentucky Fried Chicken", "oats", "Mitt Romney", "Ivan", "Sally Field", "1927", "Egypt", "pi", "tin", "the Mississippi River", "a tuxedo", "w", "Marriott", "France", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Austin", "the axiomatic system", "Eva Peron", "Cain", "Edward \"Ed\" Asner", "X-Men", "the Louvre", "a chinook", "Prison Break", "Mercury", "Maine", "sheep's milk", "Meg", "Sonnets", "tennis", "Hans", "Peter Bogdanovich", "Billy Joel", "Jerusalem", "boat propulsion", "the Quaternary Period", "nolo contendere", "Junior Walker", "Czech Republic", "a tuna", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Little Prince\"", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again,\"", "Nelson County"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6880208333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-2766", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.640625, "CSR": 0.5555098684210527, "EFR": 1.0, "Overall": 0.7777549342105263}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospirosis", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "M1 Abrams", "marimba", "a canoe", "forgetting Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Alan Shore", "taxonomy", "Spain", "the brain", "Francesco Schettino", "Macbeth", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "marriage", "Livin' On A Prayer", "Sherlock Holmes", "a lollipop", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "reuleaux", "Inuit", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "The Queen of Spades", "manganese", "national forests", "Olympia", "Waylon Jennings", "David Lean", "Brazil", "British Columbia", "Platoon", "a scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "The Wright brothers", "sexual activity", "Sam tick,", "the L'Aquila earthquake,", "voluntary manslaughter", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6057291666666667}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.546875, "CSR": 0.5552884615384616, "EFR": 1.0, "Overall": 0.7776442307692308}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the Kwai", "the Byzantine Empire", "marriage", "Jefferson", "Ford Madox Ford", "the Amazon", "a ready-to-use cotton swab", "California", "Dixie", "RAND", "Warren Harding", "a pattern", "Costar", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "a karon sakson", "Ratatouille", "circadian fluctuations", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "26.2", "life", "a fungus", "experience", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5710565476190477}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-16349", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.5, "CSR": 0.55390625, "EFR": 1.0, "Overall": 0.776953125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000 people", "yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "We Need a Little Christmas", "Tsavo East National Park", "New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "Whitney Houston to play the title character in Rodgers and Hammerstein\u2019s television version of \"Cind Cinderella\"", "Premier League club Manchester United and the England national team", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas", "Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leon Uris", "Erika Mitchell Leonard ( born 7 March 1963 ), known by her pen name E.L. James", "Mase Dinehart", "Yente", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood", "by military personnel to hazardous materials in the United States, Japan and Iraq, including toxic smoke from burn pits in Iraq and contaminated water.", "two", "Iggy Pop invented punk rock.", "a riddle", "a man", "DiCaprio", "a narcissistic ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7155304974001095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.09523809523809522, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 0.41379310344827586, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_searchqa-validation-13997", "mrqa_naturalquestions-validation-6326"], "SR": 0.609375, "CSR": 0.5552591463414633, "EFR": 1.0, "Overall": 0.7776295731707317}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "was arrested in connection with the three-vehicle accident,", "Les Bleus", "2005", "more than 4,000", "Sen. Arlen Specter", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "The Al Nisr Al Saudi", "as", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax", "Los Ticos", "acute stress disorder", "Russia", "Facebook and Google,", "through a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "militants", "23 years.", "a head injury.", "Tim Cahill", "an open window", "Leo Frank", "Paul McCartney", "off Haiti's coast", "President Robert Mugabe", "don't have to visit laundromats", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "his son is fighting an unjust war", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died", "Fayetteville, North Carolina,", "the Hercules transport plane crashed about 6:30 a.m.", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "the B-24 Liberator", "cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "King of Sweden", "Department of Transportation"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6825673024891774}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.625, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-1519"], "SR": 0.546875, "CSR": 0.5550595238095238, "EFR": 1.0, "Overall": 0.7775297619047619}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe,", "Italian Serie A", "Darrel Mohler", "her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "MDC", "42", "taking on the swords of the Taliban.", "some great travel spots to be altered or ruined by global climate change.", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "Umar Farouk AbdulMutallab", "Myanmar", "Collier County sheriff's department", "his business dealings", "Filipino-American woman", "poems", "the program was made with the parents' full consent.", "(the Democratic VP candidate", "The Red Cross, UNHCR and UNICEF", "Russia", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award.", "state senators", "31 meters (102 feet)", "nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl who disappeared in February,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "\"theoretically\"", "1940's", "March 22,", "think are the best.", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist.\"", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Saturns", "brown", "Selfie", "2002", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6573379872782446}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.5, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_triviaqa-validation-1492", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.53125, "CSR": 0.5545058139534884, "EFR": 1.0, "Overall": 0.7772529069767442}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "\"fusion teams,\" as they're being called,", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "The National Infrastructure Program,", "After the war,", "The station", "Krishna Rajaram,", "lifeless, naked body", "Robert Mugabe", "the state's first lady,", "Camp Lejeune, North Carolina", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Elena Kagan", "Dangjin", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "a Muslim with Lebanese heritage,", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama", "helicopters and unmanned aerial vehicles", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "Zhanar Tokhtabayeba,", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Aston Villa Football Club", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "pool", "1822", "The Dressmaker", "Trilochanapala", "crote", "the buffalo", "ruby slippers", "the occipital lobe"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6567601951942985}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 0.923076923076923, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 0.3333333333333333, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.515625, "CSR": 0.5536221590909092, "EFR": 1.0, "Overall": 0.7768110795454546}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Duval County, Florida", "Benj Pasek and Justin Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Thomas Staubach", "1944", "Highlands Course", "Franconia, New Hampshire", "The Guadalcanal Campaign", "Dan Crow", "War & Peace", "Amberley", "What Are Little Boys Made Of", "Berea College", "the National Football League", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "Charles Guiteau", "Ford", "weighed against the feather of truth", "India", "German", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "The Joshua Tree", "the most common sinitic name for China", "sixth - largest country by total area", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "the One Ring", "healthy"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6235243055555556}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.53125, "CSR": 0.553125, "EFR": 1.0, "Overall": 0.7765625}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "the United States, NATO member states, Russia and India", "30", "crocodile eggs", "Colorado prosecutor", "Jason Chaffetz", "on Saturday.", "in Haiti", "in July for A Country Christmas,", "sniff out cell phones.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "Kim Jong Il seems to be \"testing the new administration.\"", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "police", "Sen. Joe Lieberman, I-Connecticut,", "a crocodile", "a bronze medal in the women's figure skating final,", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers.", "Obama's", "King Gyanendra,", "homicide by undetermined means,", "Casey Anthony, 22,", "officers at a Texas  airport", "12 off-duty federal agents in southwestern Mexico,", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "Latin liberalia studia", "a British children's writer", "Johnny Mathis", "Eddie Murphy's first movie", "Champion Jockey", "Luca Guadagnino", "Ms. Jackson", "unknown", "how timing shapes and supports brain function", "a jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6547783220069404}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.47619047619047616, 1.0, 1.0, 0.10526315789473685, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.53125, "CSR": 0.5526494565217391, "EFR": 0.9666666666666667, "Overall": 0.7596580615942029}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "can vote online, via phone calls or by text messaging,", "the Orange County District Attorney's Office.", "12.3 million", "Mexico", "Argentine", "Vivek Wadhwa,", "Brett Cummins,", "Indian army", "Saturday", "Nicole", "the legitimacy of that race.", "Adidas", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "allegedly involved in forged credit cards and identity theft", "June 6, 1944", "[Middle East and North Africa]", "twice", "October 19", "\"It was a wrong thing to say,", "Seoul,", "promotes fuel economy and safety while boosts the economy.", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback forest-firefighters", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "test scores and graduation rates", "one", "the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "fox hunting", "New York", "travel", "16,116", "smoke", "sap", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.6875, "QA-F1": 0.738746062964813}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.6875, "CSR": 0.5555186170212766, "EFR": 1.0, "Overall": 0.7777593085106382}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "A Rush of Blood to the Head", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Dennis H. Kux", "drawing the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "Badfinger", "Lady Frederick Windsor", "point-coloration pattern", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930s and 1940s", "5,112", "1979", "many artists' lofts and art galleries,", "14,673", "6'5\"", "Mickey Gilley's", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Messiah Part II", "Bunker Hill", "lion", "Royal", "World War II", "Knoxville", "Three's Company", "P.O.S,", "Labour", "Linda McCartney's Sixties: Portrait of an Era", "Erich Maria Remarque", "September 14, 2008", "73", "Buffalo Bill", "Romania", "the James Gang", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "halls", "Lehman Bros International"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6775816197691198}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.5, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-2757", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-2124", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5553385416666667, "EFR": 0.9310344827586207, "Overall": 0.7431865122126438}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "gari", "offensive", "Vulcan", "mating", "Fawn Hall", "waived all privileges", "mary vanda", "Barnum", "Johnny Weissmuller", "cathode", "Torque Wrench", "gold", "Marlon Brando", "Middle Dutch", "\"Inventing Impressionism\"", "University of Kentucky", "ruddy", "Brussels", "Macbeth", "General Lee", "$18.2 billion", "Fyodor Dostoevsky", "Martin Luther", "Clue", "London", "Germany", "Andrew Johnson", "15", "Mike Connors", "Jungle Jim", "Jim Inhofe", "sancire", "Corpus Christi", "Africa", "an ostrich", "a \"rigid\" constitution", "8-hours per day", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "split", "the Grail", "West Virginia", "James Monroe", "movie house", "the family chain of Amusement parks", "critic", "Khrushchev", "1904", "a young girl", "Jimmy Robertson", "ambidevous", "chariots", "Humberside Airport", "265 million", "100 million", "freezing gasoline prices for the rest of the year and lowering natural gas prices by 10 percent.", "a head injury.", "Pope Benedict XVI refused Wednesday to soften the Vatican's ban on condom use", "Charles II"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5294836956521739}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.484375, "CSR": 0.5538903061224489, "EFR": 1.0, "Overall": 0.7769451530612245}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman Trophy", "Brandi Chastain", "the Colorado River", "Pamela Anderson", "carnaval", "Treasure Island", "Pocahontas", "Drew", "(Whizzer) White", "a piccolo bass", "an aerosol", "a magnum opus", "(P.E.) Emmerich", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "the Percheron", "Ernest Lawrence", "a rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "the small intestine", "the mouthpiece", "Cuba", "the Fellowship of the Ring", "Olivia Newton-John", "repellents", "Manhattan", "February 2", "Leontyne Price", "compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Carrie Bradshaw", "the Pierian spring", "(1982)", "a burnoose", "Philadelphia", "peanut butter", "Ralph Ellison", "cork", "Lex Luthor", "food and clothing", "( Schwarzenegger ) and his companion, the thief Malak ( Walter )", "Master Christopher Jones", "Hebrew", "\"Meadowbank Thistle\"", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The incident Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.546875, "QA-F1": 0.6111111111111112}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.546875, "CSR": 0.55375, "EFR": 0.9655172413793104, "Overall": 0.7596336206896552}, {"timecode": 50, "UKR": 0.787109375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.849609375, "KG": 0.496875, "before_eval_results": {"predictions": ["Fatih Ozmen", "Volvo 850", "Skyscraper", "Cadillac Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hawaii County", "Robert Downey, Jr.", "Schaeffler AG", "band director", "Germanic", "Anaheim", "Reinhard Tristan Eugen Heydrich", "the Big Ben clockface", "Standard Oil", "The Longest Yard", "Chiwetel Umeadi Ejiofor", "president", "19th-century", "Hillary Scott", "WikiLeaks", "Vice President", "Tottenham Hotspur", "October 2016", "Vixen", "Forbidden Quest", "Rymill Park", "Balloon Street, Manchester", "May 1, 2011", "Monroe County", "political commentator", "Adelaide Lightning", "Operation Neptune", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "north-northeast of Bologna", "created the American Land-Grant universities and colleges", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "American", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "the United States House of Representatives", "February 16, 2018", "1980", "Nacio Herb Brown", "Michael Hart", "Precambrian", "Iona", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "a progressive neurological disease", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5361458333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.4799999999999999, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-817", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1417", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-7101", "mrqa_triviaqa-validation-4774", "mrqa_triviaqa-validation-535", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_searchqa-validation-13015"], "SR": 0.4375, "CSR": 0.5514705882352942, "EFR": 0.9722222222222222, "Overall": 0.7314573120915033}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "an Indian", "What You Will", "1898", "Stacey Kent", "1930 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Keka\u02bbaniau La\u02bbanui", "Gothic Revival mansion", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Group", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "the United States", "Sargent Shriver", "No. 17 and 35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Daniel Espinosa", "Archie", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "devonian coast", "devonian", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29 and November 5.", "The Baldwin Project", "hunter sauce", "The Quest of Erebor", "carbon"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6977627840909091}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3249", "mrqa_hotpotqa-validation-2803", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.609375, "CSR": 0.5525841346153846, "EFR": 1.0, "Overall": 0.737235576923077}, {"timecode": 52, "before_eval_results": {"predictions": ["My Antonia", "King Henry VIII", "lead", "the Rose Bowl", "VC-25", "amber", "Denmark", "terriers", "Katrina & the Waves", "Jerusalem", "freestyle", "celtic", "Ustilaginales", "Stargate", "Lou Reed", "Stonewall Jackson", "Fennoscandia", "Emma Peel", "canvas", "petticoat", "The X-Files", "Frankie Muniz", "the undersea world", "Georgian Bay", "Coupvray", "kinetic", "Santeria", "Starsky and Hutch", "a lighthouse", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "a cornucopia", "All That Jazz", "Ankara", "condensation", "be", "Uberti Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Como agua para chocolate", "NigerCongo", "TGI Fridays", "President John Tyler", "Daniel Craig", "humility", "programming", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "if the concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bristol", "Gregory v. Helvering", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "between South America and Africa.", "our clothes -- the clothes we make for the runway -- aren't concepts. They go into stores.", "fake his own death by crashing his private plane into a Florida swamp.", "Stockton & Darlington"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6554014995421245}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.625, 1.0, 0.923076923076923, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7142857142857143, 0.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-16650", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-1679", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.5625, "CSR": 0.5527712264150944, "EFR": 0.9642857142857143, "Overall": 0.7301301381401617}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Neil Young", "After Shawn's kidnapping", "to manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "clay", "slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "DNA is held in the sequence of pieces of DNA called genes", "global crowdfunding platform focused on creativity and merchandising", "Most days are sunny throughout the year", "David Motl", "The Portuguese", "Wisconsin", "September 1972", "2017", "Gustav Bauer", "detritus", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "an even - toed ungulate in the genus Camelus", "13", "the five - year time jump", "compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "the Coriolis force", "the five - year time jump", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "74", "warning signs", "the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "noble gas", "the Department of Health and Human Services", "four distinct levels of protein structure", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "The BETA game was released in September 2017", "Hercule Poirot", "Paul Gauguin", "brutal attacks on Muslims since the Brussels attack had not been reported.", "creeks,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds).", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "United Arab Emirates", "the Northwest Territories", "Uncle Vanya", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6708044067419068}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.7692307692307692, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3076923076923077, 0.7567567567567568, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.5, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.53125, "CSR": 0.5523726851851851, "EFR": 0.9, "Overall": 0.717193287037037}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "Tex - Mex cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "Paul McCartney", "Kanawha Rivers", "1803", "heads of federal executive departments who form the Cabinet of the United States", "3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "the original timeline is eventually restored", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "elected or appointed by means of a commission ( letters patent ) to keep the peace", "when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "the birth centenary of Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "Kirstjen Nielsen", "cylinder of glass or plastic that runs along the fiber's length", "anembryonic gestation", "741 weeks", "Zimbabwe", "Lugano, Switzerland", "Sarah Palin's", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "the ship of violating Chinese and international laws during its patrols,", "beautiful childhood because I didn't understand the whole concept of communism.", "Tater Tots", "Yemen", "quod erat demonstrandum", "the Dalton Gang"], "metric_results": {"EM": 0.5, "QA-F1": 0.6086480775042514}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.4827586206896552, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.06896551724137931, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.8571428571428572, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.18181818181818182, 0.11111111111111112, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-940", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.5, "CSR": 0.5514204545454545, "EFR": 0.875, "Overall": 0.7120028409090909}, {"timecode": 55, "before_eval_results": {"predictions": ["she hears two men planning a woman's murder", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "the Columbia River Gorge", "the Northeast Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "land, fresh water, air, rare earth metals and heavy metals including ores such as gold, iron, copper, silver", "annual income of US $11,770", "Saint Etienne", "the closing of the atrioventricular valves and semilunar valves, respectively", "minimum viable product that addresses and solves a problem or need that exists", "London", "Robert Cappucci", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "the sacroiliac joint", "HTTP / 1.1", "Brooklyn, New York", "1 mile ( 1.6 km )", "pop ballad", "8 December 1985", "during meiosis", "2007", "Arnold Schoenberg", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outside ( skin ) and the inside cavities and lumina of bodies", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Steve Bacic", "Sebastian Vettel", "Alamodome in San Antonio, Texas", "Meg Optimus", "Eukarya", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Wayne Allwine", "Big Fat Gypsy Wedding", "Joseph V. Micallef", "Robert Lloyd", "Boston, Massachusetts", "Robert Jenrick", "Bob Hurley", "improve the military's suicide-prevention programs.", "five", "\"TNT is a unit of Time Warner, as is CNN.\"", "rastislav", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5815146329792914}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.7878787878787877, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.0, 0.1290322580645161, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.46875, "CSR": 0.5499441964285714, "EFR": 0.9117647058823529, "Overall": 0.7190605304621849}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "raghu", "16", "1877", "1999", "Old Trafford", "Tami Lynn", "A symbol consists of three dots placed in an upright triangle and is read therefore", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "Jurriaen Aernoutsz", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "April 1st", "jonell Elliot", "the claims process starts at noon Eastern Time and ends 24 hours later", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "mental disorder characterized by at least two weeks of low mood that is present across most situations", "1989", "Liam Cunningham", "Lorenzo Lamas", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "septum", "Buddhism", "the forex market", "`` Singing the Blues '' by Guy Mitchell", "Sir Ernest Rutherford", "Nigel Lythgoe", "December 2, 2013", "gastrocnemius", "Art Carney", "introduced and elaborated as early as in 1651", "March 26, 1973", "1986", "on location", "President Lyndon Johnson", "prenatal development of the human heart", "a Nativity scene", "1840", "2007", "Branson", "first baseman", "Tumi Holdings", "River Shiel", "brewer", "Polo because \"it was the sport of kings.", "are not for sale,", "ego", "Nova Scotia", "Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7241796398046398}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-7486", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096"], "SR": 0.65625, "CSR": 0.5518092105263157, "EFR": 0.9090909090909091, "Overall": 0.7188987739234449}, {"timecode": 57, "before_eval_results": {"predictions": ["Old French tailleur ( `` cutter '' )", "Massachusetts", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "acquire an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Fred E. Ahlert", "January 2017", "Ozzie Smith", "Mark Jackson", "2017", "Representative and Delegates serve for two - year terms, while the Resident Commissioner serves for four years", "January 2018", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "avian origin", "Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "Cell nuclei", "1975", "May 17, 2018", "Ren\u00e9 Verdon", "preserves the intervallic relationships of the original scale", "`` Phone a Friend ''", "to refer to a god of the Ammonites, as well as Tyrian Melqart and others", "P.V. Sindhu", "Carpenter", "Asuka", "Wilt Chamberlain", "Klaus Meine and Herman Rarebell", "Uzbekistan", "UNESCO / ILO Recommendation concerning the Status of Teachers", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "Ronnie Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "Long Island", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Brian Friel", "Gust Avrakotos", "Mark Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5744173557082323}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.7499999999999999, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.21052631578947367, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.9142857142857143, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 1.0, 0.3, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.4375, "CSR": 0.5498383620689655, "EFR": 0.8055555555555556, "Overall": 0.6977975335249043}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "11 February 2012", "Idaho", "October 14, 2017", "Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "son of Edward", "iron", "the Reverse - Flash", "Los Angeles", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "Jaffa cakes", "the name of a work gang", "Zedekiah", "Eddie Murphy", "17 - year - old", "1923", "the brain and spinal cord", "Seattle", "( 27 January -- 16 April 1898 )", "Yosemite National Park", "Ewan McGregor", "LED illuminated display", "turkey", "1917", "January 2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "non-coding sequences", "each state'sDM, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "on 13 February", "276", "the early 1960s", "President Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zuzu & Zaza Zebra", "endometriosis", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles", "pipelines and hostage-taking", "peppermint oil", "the FBI", "a ferry", "Leland Stanford", "Mexico City", "Nepal"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6160597735597735}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.92, 1.0, 0.0, 0.0, 0.0, 0.8, 0.18181818181818182, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666669, 0.33333333333333337, 0.0, 0.0, 0.2857142857142857, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5641025641025641, 1.0, 0.0, 1.0, 0.8, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7895", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-3940", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-9332", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-10561", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231"], "SR": 0.453125, "CSR": 0.5481991525423728, "EFR": 0.9142857142857143, "Overall": 0.7192157233656175}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "9", "a useless, time - wasting activity", "head coach", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "George Strait", "climate on the Earth", "Herman Hollerith", "94 by 50 feet", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "October 1, 2014", "The Miracles", "hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Roxette", "Long Island", "1988", "Egypt", "Rococo - era France", "Michael Crawford", "Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 3, 1945", "1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century", "to turn our will and our lives over to the care of God as we understood Him", "De pictura", "1970", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Joker Wild", "Chicago", "Dijon", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office, Garavaglia said.", "15-year-old's", "Sunday", "Vietnam", "a bass", "Richard", "Son of Sam"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7314748469920884}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.9714285714285714, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.9090909090909091, 0.27586206896551724, 0.0, 0.0, 0.18181818181818182, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-34", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465"], "SR": 0.609375, "CSR": 0.54921875, "EFR": 0.88, "Overall": 0.7125625}, {"timecode": 60, "before_eval_results": {"predictions": ["a recognized group of people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "certiorari", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Charlie Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "the people of the United States", "eighth", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "January 15, 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Brazil", "Parashara", "Domhnall Gleeson", "Spanish botanist and physician Petrus Jacobus Stevus ( Pedro Jaime Esteve 1500 -- 1556 ), a professor of botany at the University of Valencia", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "Eridu is the oldest Sumerian site settled during this period, around 5300 BC, and the city of Ur also first dates to the end of this period", "\"The closest approach to the original sound\"", "Peter Sellers", "Colonel Tom Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain's", "\"Empire of the Sun,\"", "Hector Berlioz", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6848589691558442}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false], "QA-F1": [0.625, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-1282"], "SR": 0.578125, "CSR": 0.5496926229508197, "EFR": 0.8518518518518519, "Overall": 0.7070276449605343}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "shared until 2010 -- 11, when Dimitar Berbatov and Carlos Tevez both scored 20 goals that season to tie for the award", "Jason Marsden", "New Mexico", "In 1889", "Stanzas 1, 2, 4, and 6 employ end rhyme in their second and fourth lines, but some of these are only close rhyme or eye rhyme", "William the Conqueror", "February 16, 2016", "July 20, 2017", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Dan Stevens", "legislative act passed by the Congress of the United States and its predecessor, the Continental Congress", "In 1998", "from 6 -- 14 July", "the 2009 model year", "4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno ( born June 19, 1966, in Pueblo, Colorado )", "Ozzie Smith", "8 December 1985", "the 18th century", "Thomas Jefferson", "Elijah Wood", "cat in the hat", "Brad Dourif", "in a counter clockwise direction around the Sun", "Joanne Wheatley", "vice president", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The Union's", "American country music duo Brooks & Dunn", "a kippis", "South America", "The Pilgrim's Progress", "Bourbon County", "Argentina,", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "One of Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.5625, "QA-F1": 0.682269908910534}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 0.6666666666666666, 0.20833333333333331, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-3836", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.5625, "CSR": 0.5498991935483871, "EFR": 0.9285714285714286, "Overall": 0.7224128744239632}, {"timecode": 62, "before_eval_results": {"predictions": ["1952", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "toys or doorbell installations", "a microfilament", "in positions Arg15 - Ile16", "the northernmost point on the Earth", "rides themselves as `` A.D. ''", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "16 March 2018", "Hollywood, Los Angeles, California", "Merry Clayton", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1936", "Eric Clapton", "Djokovic", "James Hutton", "January 1923", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Toronto", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "from the port of Nueva Espa\u00f1a to the Spanish coast", "the tax rate paid by a small business", "ecological regions", "White House Executive Chef", "the International Border ( IB )", "Bart Millard", "a woman named Sarah Whitehead", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal", "Selden", "millions of Americans gather around their Thanksgiving dinner to celebrate this most American of holidays,", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "the United Nations", "Oshkosh", "The River Welland"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6270299723424724}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-9494", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_hotpotqa-validation-1201"], "SR": 0.546875, "CSR": 0.5498511904761905, "EFR": 1.0, "Overall": 0.7366889880952382}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "from 2005 to 2006", "the closing of the atrioventricular valves and semilunar valves, respectively", "the Coppolas", "SI joint", "Definition of the problems and / or goals", "Cuernavaca, Durango, and Tepoztl\u00e1n", "development of electronic computers", "the employer", "Numbers 22 : 22", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "at luncheon", "Andrew McCarthy as Blane McDonough", "Jakkur, Bangalore, India", "Five years later", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "Saturday evenings", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "ten", "Lori Rom", "from a Czech word, robota, meaning `` forced labor ''", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser ( who disappeared with \u00a3 60,000 of her savings )", "Austin and Pflugerville", "the history of the Philadelphia Eagles begins in 1933", "Exodus 20 : 7", "four", "Geothermal gradient", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "from the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "American singer and songwriter Lana Del Rey", "The Matterhorn", "calypso", "Jiles Perry Richardson Jr.", "The Pentagon", "Croatan, Nantahala, and Uwharrie", "Johnnie Ray", "Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5907654539088363}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.5, 0.2, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.4, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.11764705882352941, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_naturalquestions-validation-7669", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4240", "mrqa_searchqa-validation-8333"], "SR": 0.453125, "CSR": 0.54833984375, "EFR": 0.8857142857142857, "Overall": 0.7135295758928571}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "Liga MX", "Amber Heard", "Peter Seamus O'Toole", "March 8, 1942", "Michael Stipe", "January 30, 1930", "Doctor", "Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "Ionolyce", "For Love Alone", "October 4, 1970", "King of the House of Valois", "Julius Robert Oppenheimer", "Transporter 3", "March 14, 2000", "Gauteng", "Vietnam War", "Bill Walton", "the Darling River", "Brian Keith Bosworth", "over 140 million", "American", "Teri Garr", "the employer", "2002 -- 2003", "Wyoming", "Wee Jimmy Krankie and his father", "money", "would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white, and women in the impoverished city are concerned that they will not be able to purchase clothing that conforms to the order,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Rome", "sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.5, "QA-F1": 0.6187421085858587}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 0.0, 0.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071"], "SR": 0.5, "CSR": 0.5475961538461538, "EFR": 0.96875, "Overall": 0.7299879807692309}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "\"Arrested Development\"", "Albert", "September 30, 2017", "339,520", "the New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire", "Odense Boldklub", "Stephen", "Jared Leto", "Gweilo", "Christian Universalists", "Amedeo, 5th Duke of Aosta", "1936", "The Wu-Tang Clan", "\"Hey Dad\"", "midtempo hip hop ballad with a pop refrain, sung by Rihanna", "Hard rock", "G\u00e9rard Depardieu", "rural", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse", "Kings Point, New York", "Robert Paul \"Robbie\" Gould III", "Paddy's Pub", "Oceanside", "Port Clinton", "November 20, 1942", "Wayne Conley", "on the Australian coast", "Faith", "turns out to be a terrible date and Marge realizes that it is Homer she really wants.", "the Cleveland Celtics", "Everybody Hates Chris", "CHO", "eight", "1867", "Sippin' on Some Syrup", "Jim Harrison", "the third Viscount", "John Churchill", "Lester", "two Grammy awards", "The S7 series", "2017", "a lightning strike", "September 2000", "Thomas Jefferson", "Luxembourg", "golda mabovitch", "The Muffin Man", "President George Bush", "as", "former", "Yonkers", "blown", "supernatural", "Dan Aykroyd"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5580777691511387}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.5, 0.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.5217391304347825, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.3333333333333333, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-1557", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_triviaqa-validation-2994", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.4375, "CSR": 0.5459280303030303, "EFR": 0.9722222222222222, "Overall": 0.7303488005050506}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "wycombe", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidexterity", "Louis Daguerre", "Stephen Hawking", "strata", "a living architect", "Guy the Gorilla", "a man holding up a lighted match!", "Port Moresby", "orange", "Oscar II class submarine K-141 Kursk", "pyrotechnic", "South Korea", "Morgan Choir", "a goose", "for the Olympics.", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington James Monroe", "Ellice Islands", "Meta", "the 'Flower of Scotland'", "about a mile north of the village of Dunvegan", "d'amore", "The Spice Girls", "Mr Loophole", "Istanbul", "drinking song", "Texas", "Erik Aunapuu", "Yalta Conference", "Rajasthan", "African violet", "bali", "Glee", "Cardigan", "notorious Welsh pirate Edward Kenway, grandfather and father of Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway respectively", "Djokovic", "1912", "fennec fox", "1927", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest,", "Linda Hogan.", "development of two courses on the Black Sea coast in Bulgaria.", "N.C. Wyeth", "viruses", "Steve Wynn", "substitute good"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6482142857142856}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-1930", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391"], "SR": 0.59375, "CSR": 0.5466417910447761, "EFR": 0.8461538461538461, "Overall": 0.7052778774397245}, {"timecode": 67, "before_eval_results": {"predictions": ["$199", "Cambodia", "lievremont", "tranquil beaches.", "took on water", "Werder Bremen", "Secretary of State", "Obama", "21 percent", "Fernando Caceres", "an Italian and six Africans dead.", "no evidence", "America's Cup", "the 11th century Preah Vihear temple", "Bahrain", "voluntary manslaughter", "Jenny Sanford", "Emma.", "Miami Beach, Florida,", "\"Dear John,\"", "cell phones.", "two contestants.", "Fiona MacKeown", "the Southern Baptist Convention", "Graeme Smith", "former U.S. secretary of state.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies", "terrorize", "two tickets to Italy on Expedia.", "Oxbow,", "the FAA received no reports from pilots in the air of any sightings but the agency recieved \"n numerous\" calls from people on the ground from Dallas, Texas, south to Austin, Texas.", "21-year-old", "Jacob Zuma,", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call", "Pew Research Center", "can also taste a hamburger and pizza, and drink coffee from a cup, the \"things we take for granted every day,\"", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "New Testament", "Phil Mickelson", "Dumbo", "skiffle", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "julie taymor", "Perkins", "director", "batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6721377485232225}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 0.24390243902439027, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1935483870967742, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.578125, "CSR": 0.5471047794117647, "EFR": 0.9629629629629629, "Overall": 0.7287322984749456}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura this year.", "their homes in Bhola", "off Somalia's coast.", "Michigan.", "AS Roma beat Lecce 3-2", "President Barack Obama,", "the Southern Baptist Convention", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally", "2000", "at least 300", "Thursday,", "always hot and humid and it rains almost every day of the year.", "Israeli", "The drama of the action in-and-around the golf course", "2008", "root out terrorists within its borders.", "25", "a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "a remote part of northwestern Montana", "genocide", "identity theft", "Bailey, Colorado,", "U.S. Justice Department", "Aravane Rezai", "The noose incident occurred two weeks after Black History Month", "How I Met Your Mother", "British", "six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds).", "stand down.", "his past and his future", "Mombasa, Kenya", "a loanword of the Visigothic word guma `` man", "Taron Egerton", "Italy", "Hard Times", "coneflower", "Nellie Melba", "The King of Hollywood", "1959", "the backside", "Sweden", "garcinia cambogia", "Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6200892857142857}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.8, 0.4, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337"], "SR": 0.5625, "CSR": 0.5473278985507246, "EFR": 0.9285714285714286, "Overall": 0.7218986154244307}, {"timecode": 69, "before_eval_results": {"predictions": ["the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise, Nevada", "the Reverse - Flash", "Hathi Jr", "a liquid crystal on silicon ( LCoS )", "Spektor", "The Star Spangled Banner", "Bill Russell", "The Parable of the Unjust Judge", "by October 1986", "http://www.example.com/index.HTML", "1,484 m / s in water ( 4.3 times as fast as in air )", "1997", "Carol Worthington", "September 6, 2019", "1972", "1902", "SURFACE\u0430A of ROOTS", "back", "the Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "under normal conditions", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive Chef", "place of trade", "25 years after the release of their first record", "the bank", "The Abbott and Costello Show", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation", "eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "Northrop F-15 Reporter", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.578125, "QA-F1": 0.683773789616181}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 0.4347826086956522, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809525, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3436", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993"], "SR": 0.578125, "CSR": 0.5477678571428571, "EFR": 0.8518518518518519, "Overall": 0.7066426917989419}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a computer", "January 2, 1971", "minced meat", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "Longliners", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "Friedman Billings Ramsey", "the NFL", "17.44667", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "September 15, 2012", "Edward Furlong", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Donald Trump", "around 100,000 writes", "1967", "Rajasthan", "Sodor", "eyes", "44,300", "the 2008 presidential election", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "Humpty Dumpty", "Thailand", "500-room"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6726467483360866}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-5392", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-7551"], "SR": 0.59375, "CSR": 0.5484154929577465, "EFR": 0.8846153846153846, "Overall": 0.7133249255146262}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "photographer", "clown", "the Titanic", "Campania", "Hadrian", "Madagascar", "franc francois daubigny", "Michel Denance", "Manet", "Gary Sparrow", "Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "Honda", "Greenock", "ABBA", "Sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby", "Rudolf Hess,", "koninklijke Vlaamse Academie van Belgi\u00eb voor Wetenschappen en Kunsten", "Stieg Larsson", "Facebook Music Stories", "1957", "a giant menhir", "buildings", "Rotherham United", "Joseph Priestley", "dogs", "international team competition in sport,", "Periodic Table", "camar\u00f5es", "land between two rivers", "Timothy Carroll", "Cuba", "indiget", "Patience", "Ernest Evans", "Tim Roth", "establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 12th hole", "San Francisco", "after 5 years, it was earning $300,000,000 a year", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "monthly", "Jet Republic", "hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "the American Civil War", "Alan Greenspan", "peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6447454253440508}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3529411764705882, 0.08695652173913042, 0.8, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-6399", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880"], "SR": 0.59375, "CSR": 0.5490451388888888, "EFR": 0.9615384615384616, "Overall": 0.7288354700854701}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby darin", "Thames", "Altamont Speedway in San Francisco", "The Jetsons", "26.22", "tibia", "ocellaris", "Samson", "Connecticut", "Daedalus", "L\u00e1szl\u00f3 de Alm\u00e1sy", "Pandemonium", "a goad", "Peter Parker", "14", "radars", "Queen Elizabeth II", "tonto", "hippocampus", "Frank Miller", "tennis", "Eric Blair", "Atlantic Ocean", "The Treaty of Waitangi", "Chatsworth House", "Dirk Bikembergs", "d.C.", "eyes", "wolfman Speights", "augusta", "aug. 24", "taurine", "Octavian", "Venezuela", "Southwest Airlines", "SUNSET BOULEVARD", "Johnny Colla (saxophone, guitar) and Bill Gibson (drums)", "Derwent Water", "sesame", "Laos", "Allardyce", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "augusta", "1768", "Joan Rivers", "Athens", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito's", "Rembrandt Harmenszoon van Rijn", "Dumbo the Flying elephant", "Casey At the Bat", "pythons"], "metric_results": {"EM": 0.5, "QA-F1": 0.5685897435897436}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.5, "CSR": 0.5483732876712328, "EFR": 0.90625, "Overall": 0.7176434075342466}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer Bears", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "horse breeder", "Schutzstaffel", "Eddie Albert", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "American investigative journalist Jane Mayer", "Obafemi Martins", "Knowlton School", "143,007", "Philadelphia", "7", "American television personality and film actress", "2 July 1903", "mathematician", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "suburb", "schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Faysal Qureshi", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "parashah", "paramitas", "1881", "writing", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Pixar's \"Toy Story\"", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6911486370470745}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-3845", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.5625, "CSR": 0.5485641891891893, "EFR": 0.9642857142857143, "Overall": 0.7292887306949807}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid (RNA)", "ketchup", "igloo", "a fly", "drink You Away", "The New York Times", "Burma", "Latvia", "spleen", "auf wiedersehen", "rely", "Ramesses II", "wine", "the esophagus", "Super Bowl VI", "the Bible", "the twist", "Marie Tussaud", "Biscay", "Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "a brothel", "bulge", "The Aviator", "Gioachino Rossini", "Mexico", "tail", "Tennessee", "Hanging Gardens of Babylon", "The Last Starfighter", "Billy Crystal", "skin cancer", "LaSalie", "Qubec", "pontiff", "Mimi Bobeck", "Onagraceae", "Moonlighting", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "Bengal", "in vitro fertilisation", "Diogenes", "pastries", "Whatchamacallit", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "\"Lady Madonna\"", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "giving birth to baby daughter Jada,", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6446314102564101}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801"], "SR": 0.546875, "CSR": 0.5485416666666667, "EFR": 1.0, "Overall": 0.7364270833333334}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2004 -- 2005", "1963", "Satavahanas", "the Central Board of Artisans", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK and Olivia", "28 July 1914 to 11 November 1918", "St. Pauli Girl Special Dark", "908 mbar ( hPa ; 26.81 inHg )", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on a sound stage in front of a live audience in Burbank, California", "Valens and Richardson", "American singer - songwriter - actress Debbie Gibson", "Atticus Finch's children", "31 January 1934", "Austin, Texas", "the southeastern United States", "the gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "synthesizing vitamin B and vitamin K as well as metabolizing bile acids, sterols, and xenobiotics", "Kyla Coleman", "Bill Patriots", "December 19, 1971", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Bell Labs", "Neil Young", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "many forested parts of the world", "arithmetic", "Finger Tab", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw", "Hapsburg", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.701530324967825}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.7027027027027027, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5714285714285715, 0.6, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-1646"], "SR": 0.5625, "CSR": 0.5487253289473684, "EFR": 0.9642857142857143, "Overall": 0.7293209586466165}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries", "Total Drama World Tour", "Christopher Lloyd", "senators", "rape", "the fictional town of West Egg on prosperous Long Island", "layered systems of sovereignty", "Authority", "Archie Andrews", "American rock band Los Lonely Boys", "ecosystems", "cakes", "Kiss", "England", "Julie Adams", "During World War II", "Anthony Quinn as Craig Belden", "January 2004", "Ella Eyre", "Oscar", "Tennesseeitans", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Michelle Lawson", "Transvaginal ultrasonography", "It is a homodimer of 37 - kDa subunits and is classified as a glycosyl Transferase", "Matt Monro", "a Nativity scene", "IV", "first No. 1 seed to lose to a No. 16 seed since the field expanded to 64 teams in 1985", "Saphira hatches", "September 2017", "an Irish feminine name", "Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group family of brands", "peninsula", "Jason Flemyng", "peninsula", "Norman Mailer", "vickers Vimy", "plc", "Part I", "17 October 2006", "biochemist and academic Dr. Alberto Taquini", "$1.5 million", "San Diego,", "CNN.com", "a jazz funeral", "echidna", "Joey", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6659616318744608}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, true], "QA-F1": [0.15384615384615385, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.7999999999999999, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.5, 0.0, 0.09090909090909093, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.07407407407407408, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_hotpotqa-validation-1166", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-10528"], "SR": 0.578125, "CSR": 0.5491071428571428, "EFR": 0.7777777777777778, "Overall": 0.6920957341269841}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Giuliano Bugiardini", "gold", "pulsar", "Seth", "Accord", "\"Erroneous' Number One", "Adolf Hitler", "Hamlet", "2010 FIFA World Cup 2010", "Elizabeth I", "June", "Italy", "1960s", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "rum", "apples", "Aberlemno", "Roddy Doyle", "four", "Separate Tables", "telephones", "Beatrix Potter", "magpie", "comets", "swimming", "Kansas City", "Ra\u00fal Castro", "Space Oddity", "Scotland", "Red Admiral", "Illinois", "red", "Splash", "South Africa", "menorah", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "native to Asia", "Liam Cunningham", "Brobee", "Fuenlabrada", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "St Bernard", "France", "Barnard College", "the catamaran"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6269097222222222}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.5625, "CSR": 0.5492788461538461, "EFR": 0.9285714285714286, "Overall": 0.722288804945055}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Verdi", "April", "Al Pacino", "vVD Savarkar", "subtraction rule", "Mr. Golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "director of the Security Service", "a 965-foot ocean liner", "Funchal", "carey Mulligan", "spaghetti harvest", "Northern Ireland", "passport", "Marcel Duchamp", "quatermass experiment", "Mumbai", "phrasmide or Iphinoe", "1875", "a dove", "hound", "Ernie (Ernie)", "Estimate", "$x^2", "Narendra Modi", "Richard Wagner", "quentin tarantino", "Argentina", "hard", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "tundras tundra", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "the 11th Century Church", "darrin Stephens", "springtime for Hitler", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "island of chieftain o'Neill", "gambit", "horror fiction", "Colombia", "the Republic of Ireland", "axons of the tract cells cross over ( decussate ) to the other side of the spinal cord via the anterior white commissure, and to the anterolateral corner", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "Tudor music and English folk-song", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's strike", "al-Shabaab", "The Old Man and the Sea", "Edward I", "the Cranberries", "There were no radar outages and said it had not lost contact with any planes during the computer glitch."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5672148546918767}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.35294117647058826, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.125, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-5367", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-3903", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.46875, "CSR": 0.548259493670886, "EFR": 0.9117647058823529, "Overall": 0.7187235899106479}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS amethyst", "Libya", "tomato", "Kyoto Protocol", "costume shop", "Bull Moose Party", "european", "Jake La Motta", "resistance", "hattie McDaniel", "South Africa", "indigestion", "discretion", "ire shiwen", "baroness kren Brady", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "european", "burt", "gangsters", "doe", "Duncan", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "Rambo", "Julian WikiLeaks", "IT Crowd", "ilie nastase", "carters", "grety", "Richard Curtis", "terms of endearment", "China", "lothbrok", "1790", "argyle", "sit back", "driving Miss Daisy", "orchid", "Hilary Swank", "abdeen", "latitude 90 \u00b0 North", "18th century", "nine hours from Coordinated Universal Time ( UTC \u2212 09 : 00 )", "just 18 minutes", "England", "Sri Lanka Freedom Party", "\"Steamboat Bill, Jr.\"", "hostile war zones,", "Rodong Sinmun", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6525744047619046}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16, 0.5714285714285715, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-374", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-3862", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.59375, "CSR": 0.548828125, "EFR": 0.7692307692307693, "Overall": 0.6903305288461539}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2 total", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "the Hudson Bay", "base homeostasis", "Miami Heat", "March 29, 2018", "four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia )", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "19th - century", "autopistas", "set to 0.05 ( 5 % )", "Australian reality television talent show which premiered on 18 February 2007 on the Seven Network", "a stack of thin films is called a multilayer", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Santa Fe", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "the Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "Games", "the foreign exchange market ( FX )", "the Coppolas", "Sunday Post", "Karl Pilkington", "pei Tang", "1860", "\"Back to December\"", "Buck Owens", "\"Up\"", "\"Empire of the Sun,\"", "off the coast of Somalia", "modifier", "olly Ringwald", "faerie", "skull and crossbones"], "metric_results": {"EM": 0.625, "QA-F1": 0.7254092261904761}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.05714285714285715, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 0.0, 0.09523809523809523, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-2967", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.625, "CSR": 0.5497685185185186, "EFR": 0.875, "Overall": 0.7116724537037038}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "a container", "Berenice II", "nuclear warheads", "capitals", "pizza roll", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "fauvism", "Auguste Deter", "Christopher Darden", "Jenny", "gestation", "ravens", "J.R. Tolkien", "Dale", "Blue Ridge Mountain range", "Georgia", "a microstructure of Ferrous Alloys", "the belly button", "Apple", "Thomas R. Gray", "a catfish", "A Chorus Line", "Piazza del Campo", "Robbie Turner", "regret not speaking", "Olivia Newton-John", "Virginia", "College of William and Mary", "a dog recently recognized by AKC.", "Louisiana", "Vassar", "Japan", "tableware", "The Police", "Air France", "Scarlatti", "Heracles", "trudge", "The Doobies", "Albert Camus", "Volvo", "Rhode Island", "falsetto", "Indian Ocean", "a hypodermic needle", "Charlotte Corday", "a nanosecond", "bats", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a forest", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Borough of Allerdale", "Mugabe's opponents", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6182291666666666}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-13394", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-506", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868"], "SR": 0.515625, "CSR": 0.5493521341463414, "EFR": 0.9354838709677419, "Overall": 0.7236859510228167}, {"timecode": 82, "before_eval_results": {"predictions": ["the submarine", "the Hopi", "China", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "My Therapist", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,047 m2", "the Galapagos", "Frans Hals", "the Black Sox Scandal", "a lynx", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "art nouveau", "Autobahn", "Old English", "the California quail", "curtsy", "lacrosse", "Toronto", "assent", "King David", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "point laces", "Lee Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "On the west", "greece", "maqui berry", "the Benedictine Order", "Pansexuality", "authorship of \"Titus Andronicus\"", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7289930555555555}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.22222222222222224, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.640625, "CSR": 0.5504518072289157, "EFR": 0.9130434782608695, "Overall": 0.7194178070979571}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "vulture", "Nantucket", "Ebony", "Trinity College", "Algeria", "Joseph Haydn", "Dick Cheney", "the black market", "a number", "Saturday Night Fever", "China", "pizza al taglio", "a turtle", "the Empire State Building", "white", "a trifle", "dogwood", "Quebec", "Larry McMurtry", "Kellogg's", "Helen of Troy", "the sweatshirt", "W=Fd", "Napoleon", "ivory", "Lapland", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Ba", "Pancho Gonzales", "the Aleutians", "the Latter-day Saints", "Lady Jane Grey", "867-5309", "the crescent moon", "Iraq", "an egg", "Nicolaus Copernicus", "poblano chiles", "William Safire", "Leonardo da Vinci", "London", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "T. R. M. Howard", "Parlophone", "Wednesday.", "Daryeel Bulasho Guud", "1995", "four"], "metric_results": {"EM": 0.625, "QA-F1": 0.7322916666666667}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-537"], "SR": 0.625, "CSR": 0.5513392857142857, "EFR": 1.0, "Overall": 0.7369866071428571}, {"timecode": 84, "before_eval_results": {"predictions": ["Syria", "Catherine of Aragon", "Judas Iscariot", "Windsor, Ontario", "Stephen Douglas", "comrade", "the Great Gatsby", "a fox", "Sexuality", "Salaries", "Solomon", "John McEnroe", "a bicycle", "Johnson County", "Jericho", "push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "the Philippines", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "\"Jolly Roger\"", "engrave", "Daisy Miller", "The Stag", "X", "a ship", "Kamehameha", "an owl", "Jamestown", "Jerry Maguire", "the north magnetic pole", "oyster bar", "an Italian-American", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "season two", "A complex sentence", "40", "Neptune", "Nowhere Boy", "August", "a simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period, and descriptions in the poem Beowulf", "Richa Sharma", "Carrefour", "financial gain,", "in a Nazi concentration camp,", "agent Mark Steinberg"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7149697580645161}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.25806451612903225, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_hotpotqa-validation-5599", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.65625, "CSR": 0.5525735294117646, "EFR": 1.0, "Overall": 0.737233455882353}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "(The) Falconer", "Queen Latifah", "Ezra Cornell", "strawberry Fields", "The Hague", "Geena Davis", "pharmacy", "( Amos)", "the NFL", "Doolittle", "air", "Shakespeare in Love", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the money changers", "The X-Files", "The Dreaming Youth", "Mensa", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a Booster seat", "the Church of Jesus Christ of Latter-day Saints", "Veneto", "a watermelon", "the Warsaw Pact", "Sparta", "230", "anode", "the second pilot episode of the science fiction television series Star Trek", "the National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "Fluoxetine", "H CO ( equivalently OC (OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6354166666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.609375, "CSR": 0.553234011627907, "EFR": 0.84, "Overall": 0.7053655523255815}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy feet", "full", "a real animal", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "Palatine", "California", "Mississippi", "Alpha", "Quebec City", "a pearl", "Texas Chainsaw Massacre", "the rotunda", "a Medal of Honor", "Manet", "Plutarch", "Milan", "Celia", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "Vic-Wells", "Vasco da Gama", "Millard", "Coarse", "Finnegans Wake", "alamu", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "croissant", "\"Magnificent Inn\" Grand Hotel", "lungs", "fuchsia", "metacarpal", "a pool", "Trinidad", "a trowel", "Mercury", "China", "Gettysburg", "Switzerland", "trout", "a slow boat", "1959", "the first season of NCIS", "$75,000", "Zimbabwe", "15", "stonemason\\'s palace", "Agent Carter", "Orson Welles", "Manhattan", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6145833333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-16661", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.546875, "CSR": 0.5531609195402298, "EFR": 0.9310344827586207, "Overall": 0.7235578304597701}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists and the Carlists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "The virion must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "4.5 pounds or 2.04 kg", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Francis Ford Coppola", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "slavery", "The Osmonds", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "Australia", "Anakin Skywalker", "Jeff East", "one", "Portia de Rossi", "Jesse Triplett", "Kevin Garnett", "a star ( representing either the star of Bethlehem or the Star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "Brazil", "Selena Gomez", "Washington", "by the early 3rd century", "Triple threat", "in his first year at the Hogwarts School of Witchcraft and Wizardry", "shared", "foreign investors", "Napoleon", "marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Watson", "Aconcagua", "bake Off", "1924", "Noah Levenstein", "the zona glomerulosa of the adrenal cortex", "Nicole Kidman", "last summer.", "social change", "longest female cyclist of her generation", "banker", "eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6567793138760881}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.72, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7741935483870968, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.5625, "CSR": 0.5532670454545454, "EFR": 0.8571428571428571, "Overall": 0.7088007305194806}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "\"The three were seized early Monday after police raided a bus station in Sargodha, a city located about 120 miles (190 km) south of Islamabad in Pakistan's Punjab province.", "Salt Lake City, Utah,", "normal maritime", "hansa (Malmborgsgatan 6) and Triangeln (Sodra Forstadsgatan 41)", "aim of preventing our public-owned seas from turning into sprawling, watery versions of Houston, Texas, or Atlanta, Georgia.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "arrested three men with suicide vests who were plotting to carry out the attacks,", "\"We want to reset our relationship and so we will do it together.'\"", "club managers,", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "At least 14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "Justice Department motion filed last week in support of the Defense of Marriage Act -- which effectively bars the federal government from recognizing same-sex unions.", "Europe,", "\"This isn't new. This isn't different.\"", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Greeley, Colorado,", "Kansas City, Missouri", "army fired warning shots into the air and sprayed water cannons to disperse the crowd.", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million", "Krishna Rajaram,", "North Korea", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas ministry spokesman Taher Nunu", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "the Yemeni port city of Aden", "federal officers", "\"Beverly Hills Chihuahua\"", "central business district of Bangkok", "journalists and the flight crew", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England", "beef", "Sleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.5, "QA-F1": 0.6108880421404399}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.058823529411764705, 1.0, 1.0, 0.0, 0.0, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.6666666666666666, 0.24000000000000002, 0.0, 0.0, 0.0, 1.0, 0.0, 0.1142857142857143, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.17391304347826086, 0.0, 0.8, 0.0, 0.33333333333333337, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.5, "CSR": 0.5526685393258427, "EFR": 0.90625, "Overall": 0.7185024578651686}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Kim So-hyun", "president of Guggenheim Partners", "Comedy Film Nerds", "9\u201310 March 1945,", "2011", "John D Rockefeller's Standard Oil Company", "the early 1970s", "Asiana Town building", "American R&B singer, guitarist, songwriter and music producer", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks for consumption on the premises", "Fabbrica Italian Automobile Factory of Turin", "Chrysler", "Australian", "the bonobo", "\"Traumnovelle\" (\"Dream Story\")", "Joshua Rowley", "Robert Digges Wimberly Connor", "Yitzhak Edward Asner", "the Beatles", "Baden-W\u00fcrttemberg, Germany", "2001 NBA All-Star Game", "\"Rated R\" (2009)", "95 AD", "1614", "French", "\"The Manhunter from Mars\" in \" Detective Comics\" #225 (Nov. 1955)", "Mondays at 21:30 (KST)", "James Worthy", "\"I, (Annoyed Grunt)-bot\"", "HSBC Main Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act of 1854 (10 Stat.  277 )", "Scandinavian design", "Buck Owens", "Big Machine Records", "UPS, Parcelforce, DHL, Hermes, Royal Mail", "Flaw", "June 5, 2017", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "\"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "for housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.625, "QA-F1": 0.7032016594516595}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 0.5, 0.2, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.1818181818181818, 0.4, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.625, "CSR": 0.5534722222222221, "EFR": 0.9583333333333334, "Overall": 0.7290798611111111}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2009", "actress and singer", "Pakistan", "1754", "\"To Save a Life\"", "VfL Wolfsburg", "valkyries", "David Villa", "Adrian Peter McLaren", "from 2010 to 2013", "an early colonist of South Australia,", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Fuli", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "Gatwick Airport", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Goitsebeng Maphiri Khama, GCB, KBE", "Scandinavian design", "Mike Pence", "Barack Obama", "Flex-fuel", "Bulgarian", "1949", "Trappist beer", "waiting for Guffman", "Presbyterian", "138,535", "Ry\u016bky\u016ban", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "consistency", "Mexico", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert", "Mattel doll", "Diane Cilento", "CO2", "Walgreens"], "metric_results": {"EM": 0.578125, "QA-F1": 0.640377938034188}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2564102564102564, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_triviaqa-validation-4655", "mrqa_newsqa-validation-386", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.578125, "CSR": 0.5537431318681318, "EFR": 0.8148148148148148, "Overall": 0.7004303393365894}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Apple", "the Jaguar S-Type", "reputation", "Friday", "Perche", "Orlando Bloom", "Babe Ruth", "'Knots Landing'", "Arkansas", "Cus D'Amato", "Virgo", "Contemporary", "Steppenwolf", "bcolicus", "Tito Puente", "Hydrogen", "Ben Jonson", "lymphoma", "Margaret", "Salt Lake City", "San Francisco", "\"The Naked and the Dead\"", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "the Wright Brothers", "Badminton", "John Deere", "depth and height", "Chrysler", "Reptiles", "Georgia", "Key Lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Assyria", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a spirit-lifting jingle", "Bobby Brown,", "Bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "Texas A&M Offshore Sailing Team", "Monday night.", "eight", "minister and biographer"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6614583333333333}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-10498", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.546875, "CSR": 0.5536684782608696, "EFR": 0.9310344827586207, "Overall": 0.723659342203898}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico, Virginia", "the East", "William Shakespeare", "William Shakespeare", "ulcers", "Colorado", "Sputnik", "Richmond", "the \"Farewell\" period", "Java", "Haydn", "Reginald", "the Flag", "room temperature vulcanization", "Wuthering Heights", "Muhammad", "September 20, 1934", "Dead Man\\'s Chest", "Frederick Forsyth", "Chesterfield", "a chipmunk", "Josphine de Beauharnais", "salt", "a Spousal privilege", "Rossini", "Oman", "Spmi", "Tom Canty", "Ruth", "Joan Didion", "the frigate", "Baltimore", "the Bay of Bengal", "button-ginnett", "Hillary Clinton's", "Terrific", "geology", "six sides", "Olympia", "the Ship of Fools", "ghost town", "tendang", "fluid", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "manic", "the Hudson Bay", "lighter fluid", "a scuffle with the Beast Folk", "Judi Dench", "Switzerland", "Tan-y-Bwlch Station", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5694444444444444}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-12499", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15084", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.515625, "CSR": 0.5532594086021505, "EFR": 0.8709677419354839, "Overall": 0.711564180107527}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Alice Cooper", "Telma Hopkins", "David Ogden Stiers, Russell Means, Christian Bale, Billy Connolly, and Linda Hunt", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners, current Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "the last coin, a gold sovereign, was struck in London in November 1975", "Pacific Grove", "while in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Goku's body in red fur", "Audrey II", "the January 2017 patch", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "Prince James, Duke of York and of Albany ( later King James II & VII )", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3", "Robin Williams", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi, Capital of Georgia", "Tiffany Adams Coyne", "ice giants", "high rates of inflation and hyperinflation are caused by an excessive growth of the money supply", "1939", "Richard Masur", "Christine Dunford", "Tagalog or English", "Sauron", "Lana Del Rey", "a statistical advantage for the casino that is built into the game", "159", "The Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "Maria has just arrived from Puerto Rico for her arranged marriage to Chino, a friend of Bernardo's", "activates a relay which will handle the higher current load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood Men in Tights", "nide", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "The Da Vinci Code", "Jenny Sanford", "Nikita Khrushchev", "Julie Andrews", "Headless Horseman", "Leo Frank, a northern Jew who'd moved to Atlanta to supervise the National Pencil Company factory."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6063640979366711}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.9655172413793104, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 0.19047619047619047, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.08695652173913043, 0.0, 0.4615384615384615, 1.0, 0.2, 0.0909090909090909, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-11408", "mrqa_newsqa-validation-3849"], "SR": 0.484375, "CSR": 0.5525265957446808, "EFR": 0.7575757575757576, "Overall": 0.6887392206640877}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "ThonMaker", "Battle of Chester", "youngest TV director ever", "1864", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural", "number 6", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "CMYKOG process", "Las Vegas Boulevard", "intelligent design: The Bridge Between Science and Theology", "Anthony Herrera", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevy Corvette Stingrays", "In 1991 he received a Primetime Emmy Award for Outstanding Supporting Actor in a Drama Series for \"thirtysomething\"", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "the \"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians,", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "a working-class young man who spends his weekends dancing and drinking at a local Brooklyn discoth\u00e8que", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed's Chronicles", "August 9, 2017", "Commonwealth Universities", "1 April 1985", "Australian", "Bonkyll Castle", "February 5, 2015", "Zeffirelli", "giant planet", "alveolar", "Duisburg", "Hugh Quarshie", "king julie vtoroy", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7249986946532998}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.5, 0.3157894736842105, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.47619047619047616, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-4047", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.59375, "CSR": 0.5529605263157895, "EFR": 0.7692307692307693, "Overall": 0.6911570091093118}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1950", "Roy Spencer", "1484", "Shawnee Mission Parkway", "VH1", "March", "Russian", "Jack Ryan", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress, and radio and television presenting", "Northern Lights", "coca wine", "Mach number", "Sami Brady", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor at some institutions in the United Kingdom and Ireland", "Song Il-gon", "Teen Titans Go!", "Mickey Mouse cup", "five-time", "right-hand", "Sheen Michaels Entertainment", "Sela", "whale to kill", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S,", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "The Da Vinci Code", "Dog patch Labs", "iceberg", "a fuel cell", "Victoria", "Venus Williams"], "metric_results": {"EM": 0.625, "QA-F1": 0.7133680555555555}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true], "QA-F1": [0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.8, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-191", "mrqa_searchqa-validation-14503", "mrqa_searchqa-validation-9695"], "SR": 0.625, "CSR": 0.5537109375, "EFR": 0.9166666666666666, "Overall": 0.7207942708333334}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "2012 Summer Olympics", "at the end of the 18th century", "1942", "Johnny Cash and Waylon Jennings", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Mariann Karlsson", "Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "John Francis Kelly", "early Romantic period", "$700 million", "the Sun", "Bhushan Patel", "1692", "navigation by river", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "manager", "Arthur Conan Doyle", "scalene", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "bread pudding", "leather", "cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8437139249639249}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2789"], "SR": 0.71875, "CSR": 0.5554123711340206, "EFR": 0.9444444444444444, "Overall": 0.7266901131156931}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "the Caucasus range", "David Bowie", "John Spencer", "Granada", "Treaty of Brest-Litovsk", "Karl Marx", "Procol Harum", "Marilyn Monroe", "Texas cichlid", "1957", "1912", "transvestite", "Cortese", "paris", "Scotland Yard detective", "Inverness-shire", "loving and giving", "winnie Mae", "Rudyard Kipling", "1921", "Trainspotting", "Emilia", "avocate", "Frans Hals", "Syriza", "Ford", "soybeans", "Cole Porter", "1830", "w wJacobs", "Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "elephant", "Tigran Petrosyan", "indreamt", "Westminster Abbey", "Canada", "Seal", "Edward VII", "Tombstone", "Santo Ant\u00e3o Island", "Timbuctoo series", "Worcester Cathedral", "Mercury", "December 7, 1941", "the eardrum", "Kerri Strug", "Neil Armstrong", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "VAQ-135", "95 AD", "170", "\"Californication\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "from 1922 to 1991"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6729166666666666}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-229", "mrqa_hotpotqa-validation-2058", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.609375, "CSR": 0.5559630102040816, "EFR": 0.48, "Overall": 0.6339113520408164}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan's", "Deutschneudorf", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health", "poems", "then-Sen. Obama", "two women", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives,", "Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.", "Phillip A. Myers.", "I showed up at WAHR with the record that would play my theme song, \"Swingin' Down the Lane.\"", "share personal information.", "British", "a Yemeni cleric and his personal assistant,", "al-Maliki", "Egypt", "he has visited the birthplace of his ancestors in Ireland,", "Jennifer Arnold and husband Bill Klein,", "WBO welterweight title", "Austin, Texas,", "17-month", "to pay him a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "American Bill Haas", "Used Acura", "28", "step up.\"", "42 years old", "since 1983.", "health ailment or beauty concern.", "almost 100", "Al Alberto Espinoza Barron's", "Derek Mears", "\"By working together, we will set wise and effective policies.\"", "fastest circumnavigation of the globe in a powerboat", "$106.5 million", "18th", "Haeftling", "on the table", "Asuka", "Bart Millard", "Nissan", "stone arch", "Jane Austen", "the Marx Brothers film", "Indian", "early 20th-century Europe", "a hostage", "Shakespeare in Love", "w. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6491291603133709}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.9210526315789475, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.5714285714285715, 0.7272727272727272, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9090909090909091, 1.0, 0.5714285714285715, 1.0, 0.13333333333333333, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-900", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.484375, "CSR": 0.555239898989899, "EFR": 0.6060606060606061, "Overall": 0.6589788510101011}, {"timecode": 99, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.841796875, "KG": 0.52890625, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "Mach number", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "most performed song of all time", "Oregon Ducks football", "Arkansas", "2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "GZA", "Broadcasting House in London", "a boy who investigates a mystery after one of her teachers goes missing", "Barney Miller", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele,", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle cities", "Suspiria", "Silvia Navarro", "22,500 acres", "Warsaw, Poland", "Nelson County", "Kang", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "the MC5", "James City County", "Tunisian", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Americas and the entire South American temperate zone", "The Omega Man", "five-time", "Mark Radcliffe", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Frank Zappa", "1991", "apples", "Fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Fernando Torres", "Friday,", "Lifeboat", "a bit", "stock-broker", "Zulfikar Ali Bhutto"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7078325320512822}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.3333333333333333, 0.25, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_searchqa-validation-572", "mrqa_triviaqa-validation-5432"], "SR": 0.609375, "CSR": 0.55578125, "EFR": 0.84, "Overall": 0.706421875}]}