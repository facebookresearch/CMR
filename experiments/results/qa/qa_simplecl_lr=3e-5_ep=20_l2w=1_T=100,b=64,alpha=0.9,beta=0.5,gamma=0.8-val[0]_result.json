{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8060, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "the Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "the law as the Holy Spirit's tool to work sorrow over sin in man's heart", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "the problem of squaring an integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "in the same way as prices for any other good", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "the U.S. ship that was hijacked off Somalia's coast.", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.765625, "QA-F1": 0.815942599067599}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.48000000000000004, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-2520", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.765625, "CSR": 0.796875, "EFR": 1.0, "Overall": 0.8984375}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "On Tesla's 75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "allows those tainted by sin to nevertheless make a truly free choice to accept or reject God's salvation in Christ.", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two-page", "Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "Executive Vice President of Football Operations", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "more integral within the health care system", "declare martial law", "a customs union, and the principle of non-discrimination", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Robbie Williams and Liam Gallagher", "NaturalScore(27597247)", "the company's factory in Waterford City, Ireland", "nitrogen", "Annemarie Moody", "water", "six", "It always begins with the music, of course. The tune sticks with you long after the song is over; the sort of tune that makes it almost impossible to sit still.", "music director", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.71875, "QA-F1": 0.7787929412929413}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16216216216216214, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1637", "mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-9805", "mrqa_squad-validation-7949", "mrqa_squad-validation-235", "mrqa_squad-validation-378", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.71875, "CSR": 0.7708333333333334, "EFR": 1.0, "Overall": 0.8854166666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["the 1994 Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "the woodcuts", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "The best-known legend", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "the Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "the 50 fund", "integer factorization problem", "economic inequality", "Isel", "adapted quickly and often married outside their immediate French communities", "Benazir Bhutto", "Charles-Fer Ferdinand University", "he had drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "the ATP is synthesized there, in position to be used in the dark reactions", "the late 19th century", "the Channel Islands", "separating faith and reason in order to honor the separate spheres of knowledge that each applies to", "Alberich", "9", "Emeril Lagasse", "Churchill Downs", "The port of Terneuzen is the third largest in the Netherlands, after those of Rotterdam and Amsterdam", "the regular polyhedrons", "January 2, 7pm", "christopher", "study insects and their relationship to humans, other organisms, and the environment", "the limbic system", "christopher", "George Fox", "ireland", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.6870614035087719}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473684, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-9286", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-1189", "mrqa_squad-validation-1150", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_hotpotqa-validation-3821"], "SR": 0.640625, "CSR": 0.73828125, "EFR": 0.9565217391304348, "Overall": 0.8474014945652174}, {"timecode": 4, "before_eval_results": {"predictions": ["in plants that contain them", "Parliament of Victoria", "Zaha Hadid", "Fort Edward", "Science and Discovery", "Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "Battle of Olustee", "Sicily and the south of Europe", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "Roman Catholic", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "Italian government", "22", "terror groups that they say were planning numerous suicide attacks", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "because a new model is simply out of their reach", "Muslim", "will be the first time any version of the Magna Carta has ever gone up for auction", "Time Warner", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "mike at gunpoint at a Westin Hotel in Boston", "one", "miley Cyrus", "$1,500", "National Industrial Recovery Act", "tracey\u2019s younger son Travis", "Humberside Airport", "marylandata"], "metric_results": {"EM": 0.65625, "QA-F1": 0.694016510450334}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4615384615384615, 0.15999999999999998, 1.0, 0.9411764705882353, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-7094", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-8759", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.65625, "CSR": 0.721875, "EFR": 1.0, "Overall": 0.8609375}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a data network based on this voice-phone network was designed to connect GE's four computer sales and service centers", "500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "a way of reminding their countrymen of injustice", "June 1978", "Milton Latham", "1914", "Philippines", "Broncos", "the 1970s", "the spoils of the war", "German Te Deum", "1795", "Bermuda 419 turf", "air could be liquefied, and its components isolated, by compressing and cooling it", "Infinity Broadcasting Corporation", "\"semi-legal\" and was the only opposition group in Egypt able to field candidates during elections", "1972", "rudimentary immune system, in the form of enzymes that protect against bacteriophage infections", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "the Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "It is mainly for the purpose of changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "from an Ohio newspaper on 8 February 1925", "Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "radius R of the turntable", "Panning", "Justin Timberlake", "the economic systems of the uk germany and russia have in common", "troops, and military experts. European nations contribute nearly 6,000 units to this total", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada on December 10, 2007, in Hamilton, Brampton and Brantford. On February 1, 2008, they opened three more stores in Toronto", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "the present ( 2016 -- 2018, contemporaneous with airing ) and a storyline taking place at a set time in the past ; but some episodes are set in one time period or use multiple flashback time periods", "Morgan Freeman", "David Gahan", "it includes a restaurant, spa, and bed - and - breakfast and provides guided tours which feature the history and alleged paranormal activity of the site", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the day before the long fast for the Lent period", "Jaipur", "Johan Persson and Martin Schibbye", "torpedo boats", "Newport Gwent Dragons"], "metric_results": {"EM": 0.546875, "QA-F1": 0.669390326305961}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.8, 0.47058823529411764, 1.0, 0.13333333333333333, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 0.7200000000000001, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 1.0, 0.16, 0.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5833333333333334, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-9908", "mrqa_squad-validation-436", "mrqa_squad-validation-3473", "mrqa_squad-validation-9635", "mrqa_squad-validation-6450", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.546875, "CSR": 0.6927083333333333, "EFR": 0.9655172413793104, "Overall": 0.8291127873563218}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "Serbian Orthodox priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "New Birth", "gold", "a deficit", "Vivienne Westwood", "reciprocating Diesel engines, and gas turbines", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members in good standing with the college, and private schools may also require their teachers to be college peoples", "end of the season", "10 years in prison", "Jonas", "African-Americans", "will not support the Stop Online Piracy Act", "Chuck Bass", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "after time goes on, it kind of becomes more and more of a phenomenon", "on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea's reclusive leader Kim Jong-Il", "first five Potter films", "you love the environment and hate using fuel", "3 to 17", "two suicide bombers,", "lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse,", "instability in Somalia", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "James Lillywhite, Alfred Shaw and Arthur Shrewsbury", "Colgate University", "Church of Christ, Scientist", "unsaturated fats are comprised of lipids that contain?", "Luke 6 : 12 -- 16"], "metric_results": {"EM": 0.625, "QA-F1": 0.6936446639982825}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.5, 0.3076923076923077, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3370", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-3390", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442"], "SR": 0.625, "CSR": 0.6830357142857143, "EFR": 1.0, "Overall": 0.8415178571428572}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house", "yellow chlorophyll precursor", "spontaneous", "the courts of member states", "gold", "TARDIS", "Buckland Valley", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey", "dance show", "their \"Freshman Year\" experience", "India", "Benazir Bhutto,", "at the Lindsey oil refinery in eastern England", "April 24 through May 2", "Krishna Rajaram", "early detection", "250,000", "Tim Masters,", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "Madeleine K. Albright", "Oxygen Channel's \"Dance Your Ass Off\"", "military trials for some Guant Bay detainees", "Matthew Fisher", "Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "seeking help", "Japanese officials", "Too many glass shards", "\"Empire of the Sun\"", "Norman", "Olympics", "Matt Winer", "Doc Holliday", "opposite R\u00fcgen island", "Mustique", "green"], "metric_results": {"EM": 0.625, "QA-F1": 0.7205002658631692}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.9032258064516129, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.10256410256410256, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5333333333333333, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-3938", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4367", "mrqa_triviaqa-validation-2858"], "SR": 0.625, "CSR": 0.67578125, "EFR": 0.9583333333333334, "Overall": 0.8170572916666667}, {"timecode": 8, "before_eval_results": {"predictions": ["2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "\"Journey's End\"", "immediate", "Levi's Stadium", "decidedly Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "in variety of ways", "Einstein", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "separated", "Animal Planet", "crashing his private plane into a Florida swamp.", "\"The situation is pretty much resolved,\"", "54 bodies", "early detection and helping other women cope with the disease", "Diversity", "$250,000", "make sure water continues flow through the river channel and not spread out over land", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm", "The son of Gabon's former president", "2050", "Alfredo Astiz,", "Abdullah Gul,", "Mikkel Kessler", "The Everglades", "when the cell is undergoing the metaphase of cell division", "Spain", "New Orleans, Louisiana", "many investors paying huge sums for individual bulbs", "The perfect is the enemy of the good", "a little restaurant and tea shop", "it really aren't the same old St. Louis Blues"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6790486316802107}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.12121212121212123, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.2222222222222222, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-9903", "mrqa_squad-validation-6300", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-1710", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6666666666666667, "EFR": 1.0, "Overall": 0.8333333333333334}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "the General Sejm", "Derek Jacobi", "net force", "\"laeran\", meaning \"teach\"), \"burn\" (\"stream\") and \"gan\" (\"go\")", "50%", "\"All I can say is that the Natives of these localities are very badly disposed towards the French, and are entirely devoted to the English.", "the top 15 most populous", "CRISPR", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement", "the Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "providing the basic securities that Turkey can be a great partner.", "an average of 25 percent of U.S. consumers who get recall notices don't follow through and fix their vehicles", "a treadmill", "the couple's surrogate lost the pregnancy.", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours", "Elin Nordegren", "New York City", "6,000", "cortisone", "President Clinton", "delivered three machine guns and two silencers to the hip-hop star,", "MDC head Morgan Tsvangirai", "rig next week's elections in his favor,", "future relations between the Middle East and Washington", "a canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school", "strife", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "after Shawn's kidnapping", "the immediate physical and social setting in which people live or in which something happens or develops", "William Tell", "Andr\u00e9 3000", "Groundhog Day", "Cleopatra, Queen of Denial", "a fairground"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6189741894564844}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.08, 0.10526315789473684, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.25, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.4, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-10185", "mrqa_squad-validation-2429", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.546875, "CSR": 0.6546875, "EFR": 0.9655172413793104, "Overall": 0.8101023706896552}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York,", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "within the premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "pelvis and sacrum -- the triangular bone within the pelvis", "issued his first military orders as leader of North Korea", "heavy snow and ice", "Gainsbourg", "\"Maude\"", "Phillip A. Myers", "general astonishment", "two weeks after Black History Month", "58 people", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Lance Cpl. Maria Lauterbach", "Dangjin", "Sharp-witted. Direct. In control. Loyal.", "China", "magazine", "physical therapy", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "baugebiete", "Lionsgate", "James David Lofton", "mystic", "hair-like structures"], "metric_results": {"EM": 0.578125, "QA-F1": 0.663967803030303}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5454545454545454, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.578125, "CSR": 0.6477272727272727, "EFR": 1.0, "Overall": 0.8238636363636364}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "The combination of hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points,", "Elway", "Philo of Byzantium", "36", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "proustian", "antelope", "nipples", "the Precambrian period", "a co-  operative", "Anastasia Dobromyslova", "gagapedia", "9", "Space Jam", "radishes", "Robert Ludlum", "giant grubs", "(.mov)", "the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "London Underground", "United States", "orangutan", "Manet", "Willy Wonka", "Wyoming", "2005", "1971", "DodgeDodge", "dolt", "Venice", "petticoat", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "Wales", "Can't Get You Out of My Head", "Ray Looze", "Bloomingdale Firehouse", "Israel's vice prime minister compared Iran to Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6039296207264957}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.125, 1.0, 0.8, 1.0, 0.7857142857142858, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6153846153846153, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-1018", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.53125, "CSR": 0.6380208333333333, "EFR": 1.0, "Overall": 0.8190104166666666}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "90-60's", "Panini", "Bills", "anti-colonial movements", "the Rhine Valley", "protein A", "to be suspicious of even the greatest thinkers and to test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "the case of an express wish of the people to withdraw from the EU", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "Jessica Simpson", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "iceland", "spy", "Vladivostok", "Sheryl Crow", "iceland", "Camellia", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "cosmology", "gin", "George Clooney", "Eric Coates", "james chadwick", "\"No one was saved\"", "Monopoly", "champagne", "abundant rainfall", "the United States", "Brigit Forsyth", "George Leveson-Gower", "\"Land of the Rising Sun\"", "The History of Troilus and Cressida", "Thomas Edward Lawrence,", "Kent", "Edgar Degas", "Vanguard", "white", "Switzerland", "gin", "the people of France", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "Baden- wronglyttemberg", "David", "\"Stagecoach\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6523601146837034}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.8387096774193548, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_newsqa-validation-3860"], "SR": 0.609375, "CSR": 0.6358173076923077, "EFR": 1.0, "Overall": 0.8179086538461539}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "it would appear to be some form of the ordinary Eastern or bubonic plague", "the Huguenots had their own militia", "after the end of the Mexican War", "61", "the quality of a country's institutions and high levels of education", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron  Saffron", "hymenaeus", "Zeus", "albinism", "the Straits of Tiran", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "cuddly new pet", "the Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "a tiny 1\" (3 cm) up to 11 feet (3.5 m)", "strong cold southwest wind", "table tennis", "the National Library of Medicine", "penhaligon", "Gandalf", "Edgar Allen Poe", "Jinnah International Airport", "Monday", "the city of Caracas", "a crucifix", "soap", "liquor", "Avro Lancaster", "Genesis", "Charlie Brooker", "melbourne chamomile", "Harrods", "2007", "cher", "Scarface", "pale yellow", "aluminium double glazing", "bubba", "June 12, 2018", "Filipino", "London", "Lambic", "Nook", "Steven Green", "commas", "will send a package to precede your arrival by a day or two.", "emperor", "Synchronicity"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6069444444444445}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-7204", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-7177", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-372", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-6628"], "SR": 0.515625, "CSR": 0.6272321428571428, "EFR": 1.0, "Overall": 0.8136160714285714}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor of Theology", "mountainous areas", "sleep after it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "Jumping on the Moon", "2020", "1974", "332", "1997", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking", "Vienna", "World Trade Center", "Kevin Spacey", "All Hallows'Day", "78", "white blood cell", "Bangladesh", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "January 12, 2017", "United States", "Claims adjuster", "uterus and uterine tubes", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "annual", "boudin", "kew Gardens", "Nikita Khrushchev", "$500,000", "Alexandros Grigoropoulos,", "reaper", "NYPD", "the BBC building in Glasgow, Scotland", "\"Larry King Live\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6407373536789298}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.5, 1.0, 0.6956521739130436, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 0.2857142857142857, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2126", "mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_newsqa-validation-121", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.515625, "CSR": 0.6197916666666667, "EFR": 0.967741935483871, "Overall": 0.7937668010752689}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "a special episode of The Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "the John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based entrepreneurship", "950 pesos ( approximately $ 18 )", "note number 60", "Seattle, Washington", "Battle of Antietam", "Dimitar Berbatov and Carlos Tevez", "In Time", "by the early 3rd century", "Glenn Close", "three", "Agostino Bassi", "five", "Malibu, California", "the church at Philippi", "Dutch navy captain Jurriaen Aernoutsz", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "a warrior, Mage, or rogue coming from an elven, human, or Dwarven background", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "September 1972", "Uruguay", "Sam McMurray", "Matt Jones", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "the Director of National Intelligence", "D.A.D. a.", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "John Coffey", "Rachel Kelly Tucker", "Bohemia", "boxelder bug", "Code 02PrettyPretty", "Joe Dever", "the parliament within 15 days.", "the abduction of minors", "Nevada", "Chile", "Stage Stores,", "1881"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6077671026889777}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.42857142857142855, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_newsqa-validation-2674"], "SR": 0.515625, "CSR": 0.61328125, "EFR": 0.9354838709677419, "Overall": 0.774382560483871}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "the Arizona Cardinals", "Robert Watson", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland.", "Microsoft Office", "SAVE", "Scandinavian Airlines System Aktiebolag", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award", "Jello Biafra", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson", "Julian Dana William McMahon", "the North Sea coast", "7.63\u00d725mm Mauser", "the Academy Award for Best Animated Feature", "CAC FC-1 \"Xiaolong\"", "Delacorte Press.", "Neighbourhoods", "Secretariat", "Wake Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Amway", "Parlophone Records", "South Africa", "Surrey", "The Girl", "Charles Russell", "Boyd Gaming", "three different covers", "1966, 1967, 1968, 1970", "Glenn Close", "Florence Welch", "Neighbours", "Ewan McGregor", "2011", "pippa passes", "the leader of the late insurrection in Southampton, Va.", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.546875, "QA-F1": 0.655857683982684}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.3636363636363636, 0.2857142857142857, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8509", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.546875, "CSR": 0.609375, "EFR": 1.0, "Overall": 0.8046875}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m.", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "the inner chloroplast membrane", "Charlie Harper", "steveland Hardaway Morris", "beaver", "La Boh\u00e8me Giacomo Puccini", "formic acid", "Los Cristo de la Luz", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Plato", "Fuller's", "Fresh Water Load Line", "Nick Hornby", "The Comedy of Errors", "Charles V", "King of Mann", "welch", "weight plates", "\"big house\"", "Hadrian", "US", "human flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Hamburg", "avian Aqua Miser", "Tangled", "\"The French Connection\"", "CBS", "Leicester City", "Robert Cummings", "Jessica Simpson", "Culture Club", "Finland", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "It was a Confederate victory", "New Jewel Movement", "Africa", "U.S. 93", "Anjuna beach in Goa", "Lev Ivanov", "Oshkosh", "\"I Got You.\"", "\"The World\"", "\"The Sunday Thing\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6083333333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5052", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.515625, "CSR": 0.6041666666666667, "EFR": 1.0, "Overall": 0.8020833333333334}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "extremely high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "new magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "a balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "The Hustons", "Allison Janney", "the Isthmus of Corinth", "comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Laura Jane Haddock", "( 1985 -- 1993 )", "775 rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Coton in the Elms", "( 55 -- 69 % )", "The Vamps", "early to mid-2000s", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "the aortic valve", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "png HTTP / 1.1", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "`` Rising Sun Blues ''", "Part 2", "1941", "the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "mentor", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7037425658669265}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-4227", "mrqa_hotpotqa-validation-4735"], "SR": 0.65625, "CSR": 0.606907894736842, "EFR": 0.9545454545454546, "Overall": 0.7807266746411483}, {"timecode": 19, "before_eval_results": {"predictions": ["everything that is used to work sorrow over sin is called the law,", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "1965", "270,000", "Long troop deployments", "Joe Pantoliano", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother,", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "nearly three out of four Americans are scared about the way things are going in the country today", "the Falkland Islands to carry a government permit.", "Tuesday in Los Angeles.", "forgery and flying without a valid license", "Anil Kapoor", "19-year-old", "President Obama's surge plan to head to Afghanistan's restive provinces to support Marines and soldiers fighting a dug-in Taliban force.", "the city's reputation for glamour and hedonism", "The Louvre", "snowstorm", "sports cars", "a lizard-like creature from New Zealand", "Moammar Gadhafi", "two Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18,", "\"Stunt double Terry Leonard performs a hazardous jump from horseback to a truck as Indiana Jones in \" Raidersers of the Lost Ark.\"", "Russia", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a320 million ($41.1 million) fortune", "Kingman Regional Medical Center,", "Current TV", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Louisiana", "the Southeast", "The father of Haleigh Cummings, a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother,", "Barack Obama", "\"A Mother For All Seasons.\"", "The Maraachli case caught the attention of the group Priests for Life, which funded Joseph's transfer and treatment at the SSM Cardinal Glennon Children's Medical Center.", "back at work", "Georgia Aquarium", "27", "Derek Hough", "John Adams", "borsht (Borsch)", "Zager and Evans", "Robert Matthew Hurley", "fourth term", "obscenity", "Cromwell's elite cavalry", "Lapland", "1937", "Emad Hashim"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5551596840659341}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.2, 0.0, 0.4, 1.0, 1.0, 0.0, 0.1904761904761905, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.923076923076923, 0.6666666666666666, 0.8333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_searchqa-validation-8011", "mrqa_hotpotqa-validation-2922"], "SR": 0.453125, "CSR": 0.59921875, "EFR": 1.0, "Overall": 0.799609375}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C), set on July 8, 1905,", "Rhenus", "1331", "Death wish Coffee", "L", "Cameroon,", "just after midday on a cold December Monday in South Korea's capital when news of Kim Jong Il's death filtered through.", "ballots", "as easy as Fred Astaire dancing down a staircase.", "three empty vodka bottles,", "training Afghan police and troops, before trading his uniform for a diplomat's business suit.", "1959", "the injured Felipe Massa", "16", "his former Boca Juniors teammate and national coach Diego Maradona,", "she was humiliated by last month's incident,", "the composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "over 1,000 pounds", "Iran's nuclear program.", "a welcoming, bright blue-purple", "using recreational drugs", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Elspeth Cameron-Ritchie,", "on the set at \"E! News\" on Tuesday.\"", "three French journalists, a seven-member Spanish flight crew and one Belgian", "jobs", "\"terrifying.\"", "Khalid Sheikh Mohammed, seen in a December sketch, was waterboarded 183 times in a month,", "A video purporting to be from a vigilante group whose goal is the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "Republicans", "what will they do now?\"", "An undated photo of Alexandros Grigoropoulos,", "signed a power-sharing deal with the opposition party's breakaway faction, his party said Tuesday, though Mugabe's opponents denied the claim.", "a 57-year old male", "Kim Jong Il seems to be \"testing the new administration.\"", "Angola", "Gary Brooker", "the creation of an Islamic emirate in Gaza,", "\"Oh you're, you're really nice,\"", "tried by a U.S. military commision,", "Sea World in San Antonio,", "a job he liked at the U.S. Holocaust Memorial Museum,", "about 50", "the Ku Klux Klan", "1939", "Branford College", "Bury", "a female mating with more than one male", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "clone", "Hodel", "access to US courts", "the British rock group Coldplay"], "metric_results": {"EM": 0.328125, "QA-F1": 0.46382416468765153}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.6153846153846153, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.10526315789473684, 0.0, 0.0, 1.0, 0.9523809523809523, 0.6, 0.25, 0.23076923076923078, 0.8, 1.0, 0.8571428571428571, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.4444444444444445, 0.0, 0.0, 0.2857142857142857, 0.060606060606060615, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.10526315789473685, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4760", "mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_naturalquestions-validation-7987"], "SR": 0.328125, "CSR": 0.5863095238095238, "EFR": 1.0, "Overall": 0.7931547619047619}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness,", "the poor", "oxygen-16", "De Materia Medica", "Amazoneregenwoud", "regulations and directives", "\u201c Splash\u201d", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Somali waters", "Carlo Collodi", "Tony Blair,", "Illinois", "shoulders", "Madonna's", "Glasgow", "latitude and longitude coordinates", "Australia", "giblet", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Ness", "Jesuit", "New South Wales", "white", "Taiwan (or Republic of China)", "Harrisburg", "weasel", "glockenspiel", "Dr John Sentamu", "rochoon", "de Vil", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "emperor Charlemagne", "not to them but to the community.", "Russell Crowe,", "Theodore Roosevelt", "rochina", "Robin Goodfellow (Puck)", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "SS Constitution", "the fictional London Borough of Walford in the East End of London.", "Newbury", "the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation.", "Sister, Sister (1982 film)", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "\"international NGO\"", "Francis Marion", "Amnesty International.", "talk show queen Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6251945970695971}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-6314", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-7524", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.5625, "CSR": 0.5852272727272727, "EFR": 0.9642857142857143, "Overall": 0.7747564935064934}, {"timecode": 22, "before_eval_results": {"predictions": ["flushing action of tears and urine", "1765", "primarily along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin", "Rome", "Robert Peary", "pearl", "Utah", "Carrie Underwood", "whisky", "he made his horse a consul, his palace a brothel, and his", "Google", "Langston Hughes", "Pain tolerance", "harding", "Tito Puente", "lasso", "It's one thing to know many words - another to...", "a ship that has been preserved and converted into a museum open to the public, for educational or memorial", "rhodesian ridgebacks", "David Beckham", "Arturo Toscanini", "economics", "Miracle", "six feet by 24 feet.", "Yugoslavia (19431992) Croatia (1991)", "discus", "hard", "basidiomycota", "James Gandolfini", "Georgia Thomas", "Idi Amin", "blacksmith", "a body, or a personal item associated with a saint", "terracotta", "plutarch", "Rudy Giuliani", "masa", "two-minute", "the Vikings", "Mulberry Street", "Bastille Day", "typhoid fever", "river valley", "the capital of Bavaria", "Williamsburg", "\"Wire Rope Express\"", "Tualatin", "hydrogen peroxide", "John Knox", "the internal reproductive anatomy", "$5 highest - grossing film of all time worldwide in 1998, and remained so for twelve years, until Avatar ( 2009 )", "risk factors for disease and targets for preventive healthcare", "the Big Bopper", "Tesco", "Mallard", "Graham Hill", "the Battelle Energy Alliance", "IT", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "$10 billion", "Trenton, Florida"], "metric_results": {"EM": 0.4375, "QA-F1": 0.49216269841269844}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6437", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_hotpotqa-validation-68", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-1997"], "SR": 0.4375, "CSR": 0.5788043478260869, "EFR": 1.0, "Overall": 0.7894021739130435}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "the Chancel Chapel", "the Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "domestic cat", "the daughter of Tony Richardson", "UEFA", "the Argo", "prometheus", "Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a MUD (multi-user dungeon)", "Libya", "Khaki", "a sedimentary", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip", "Barack Obama,", "the Earth", "Nafea Faa Ipoipo", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "a signal", "Denis Law", "\"Love Is All Around\"", "William Golding", "Sally Ride", "Cyclone", "Fife", "Money Saving", "Adidas", "the Snarks", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "the opponent's", "flour and water", "Ross Elliott", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "President Pervez Musharraf", "Tennis Channel", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6784313725490196}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5725", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3049", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-4882", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-458"], "SR": 0.640625, "CSR": 0.5813802083333333, "EFR": 1.0, "Overall": 0.7906901041666666}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "Universal Studios and Walt Disney Studios", "1997", "a suite of network protocols", "his son, Isaac, and daughter, Rebecca.", "15", "nine-wicket", "Pyongyang and Seoul", "killed a man, the latter cheated on his wife.", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Jason Chaffetz", "money or other discreet aid", "Sarah Brown", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "environmental", "the United Arab Emirates", "Afghan security", "Saturday", "38", "70,000 or so", "Climatecare", "\"E! News\"", "coach", "Steve Williams", "McDonald's", "poetry", "five female pastors", "2008", "Diego Maradona", "Dog patch Labs", "The Stooges", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Sophia Stellatos", "to never make the cut for a face-to-face interview with the president", "police", "former U.S. secretary of state", "At least 33", "five", "get better skin, burn fat and boost her energy", "contraband", "it is primarily students, the reputed problem, who can best prevent acts of violence", "Alwin Landry's", "Krishna Rajaram", "Sunday", "killing", "Sinead", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "italy", "radar", "art", "the point guard position", "23", "it is spoken by the majority of the population, and where half of the rural population is monolingual", "freestyle", "the Nightingale", "Belief"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5364395540897133}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.2857142857142857, 1.0, 0.6153846153846153, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 1.0, 0.5, 1.0, 0.15384615384615383, 0.0, 0.20689655172413793, 1.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-610", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_hotpotqa-validation-2170", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.421875, "CSR": 0.575, "EFR": 1.0, "Overall": 0.7875}, {"timecode": 25, "before_eval_results": {"predictions": ["the \"most successful\" science fiction series of all time", "Thomas Savery", "Vicodin", "lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "a violent separatist campaign", "Eleven", "269,000", "The three men entered the E.G. Buehrle Collection", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers", "41", "Los Alamitos Joint Forces Training Base", "super-yacht designers Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "the shoreline of the city of Quebradillas", "the Russian air force", "34", "the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "The mysterious disappearance of Flight AF 447 over the Atlantic Ocean has fueled speculation among aviation experts about what caused the state-of-the-art airliner to come down.", "ensure there is no shortage of the drug while patients wait for an approved product to take its place", "Japanese businessmen", "Tom Baer", "Pakistan", "The oceans are kind of the last frontier for use and development,\"", "bikinis", "Brian Mabry", "changed the way for gamers to be able to engage in their favorite past time via handheld devices", "Sunday", "60 euros -- $89", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "some truly mind-blowing structures", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "2006", "In San Diego,", "Debora Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "A family friend of a U.S. soldier captured by the Taliban said his friends and family want Pfc. Bowe Bergdahl to \"stand tall, stand firm.\"", "Twitter", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "first line of law and order", "heart", "Hyderabad", "between the Mediterranean Sea to the north and the Red Sea", "to stay, abide", "Las Vegas", "Jackson Pollock", "Lyrical", "Mississippi", "January 19, 1943", "King Duncan", "Brasstown Bald", "a car, flatiron,", "a stride"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5417644313983827}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.782608695652174, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.29411764705882354, 1.0, 1.0, 0.0588235294117647, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.4, 0.888888888888889, 1.0, 0.8, 1.0, 0.1818181818181818, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832"], "SR": 0.4375, "CSR": 0.5697115384615384, "EFR": 1.0, "Overall": 0.7848557692307692}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "\"I shall never take a wife, as I feel at present.\"", "flying glass and rocks.", "Karthik Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "Six", "legitimacy of that race.", "think about saving the rainforests", "three", "Monday", "Scarlett Keeling", "two years,", "84-year-old", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "in July", "Akshay Kumar", "Alan Graham", "the Indians were gathering information about the rebels to give to the Colombian military.", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "James Newell Osterberg", "the death of Prince George's County police Cpl. Richard Findley,", "Phil Spector", "Kim Jong Il's", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "the \"People of Palestine\"", "older than the industry average,", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "Mohammed Ali", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "same-sex civil unions,", "fallen comrades lost in the heat of battle.", "barter -- trading goods and services without exchanging money", "semi-autonomous organisational units", "6 - 6", "Matt Monro", "Jack Frost", "the innermost digit of the forelimb", "in 1974", "over 20 million", "Peoria, Illinois", "Hawaii", "water", "King Lear", "Ottoman Empire"], "metric_results": {"EM": 0.5, "QA-F1": 0.5752724358974359}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.07692307692307693, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.72, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-79", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586"], "SR": 0.5, "CSR": 0.5671296296296297, "EFR": 1.0, "Overall": 0.7835648148148149}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building which contained the city's historical archives,", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Oakland A's", "eight Indian army troopers, including one officer, and 17 militants,", "There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "\"BADBUL,\"", "98 people,", "2008", "Gulf of Aden,", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Swat Valley,", "Iraq", "Iran", "November 26,", "people have chosen their rides based on what their", "July", "International Red Cross Committee, the U.N. High Commissioner for Refugees and UNICEF", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "at Hansa (Malmborgsgatan 6)", "fractured pelvis and sacrum", "Wednesday", "abduction of minors", "gun", "Aniston, Demi Moore and Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "apteka", "largest city", "beta blockers"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7452651515151515}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.05555555555555555, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5333333333333333, 0.3636363636363636, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.09523809523809525, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_naturalquestions-validation-6383", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-14535"], "SR": 0.671875, "CSR": 0.5708705357142857, "EFR": 1.0, "Overall": 0.7854352678571428}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "enforcing land officials into large debts that cannot be repaid, ownership of private industries", "1981,", "forgery and flying without a valid license,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "Genocide Prevention Task Force.", "shoot down the satellite", "semiconductors", "Whitney Houston", "New Haven, Connecticut, firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry", "Anil Kapoor", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "The Rosie Show,\"", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism", "the Dalai Lama's", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "For weeks,", "executive director of the Americas Division of Human Rights Watch,", "750", "at least 300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab", "some U.S. senators", "inconclusive", "5:20 p.m. at Terminal C", "fueled by environmental and political events", "$250,000", "100% of its byproducts", "School-age girls", "5,600", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "a bill in the Texas Legislature that would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "bragging about his sex life on television", "a vertebral column ( spine )", "January to May 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "St John's College,", "Douglas Hofstadter", "\"The Dark Tower\"", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain in the Civil War", "Castle Rock", "Neapolitan"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7207926263802622}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9565217391304348, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9047619047619047, 1.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.640625, "CSR": 0.5732758620689655, "EFR": 1.0, "Overall": 0.7866379310344828}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure on wages", "El Tem\u00fcr", "438,000", "Marty Ingels,", "coaxial", "Pakistani", "Everbank Field", "14 directly elected members, 12 indirectly elected members representing functional constituencies and 7 members appointed by the chief executive", "the German Campaign of 1813", "James FitzJames,", "1965", "Paris", "fifth", "Culiac\u00e1n, Sinaloa,", "seven children", "Syracuse", "1963", "non-alcoholic", "video", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos giant rat", "Tom Kartsotis,", "2017", "Wayman Tisdale", "Mexico", "Kolkata", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Adventures of Huckleberry Finn", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey", "the native populations living south of St. Augustine and in the Cape Canaveral area.", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18,", "Richard Parker", "off the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "King Edward VIII,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia", "shrimp", "Australia"], "metric_results": {"EM": 0.53125, "QA-F1": 0.624763431013431}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 1.0, 0.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4048", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-1197", "mrqa_hotpotqa-validation-1213", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585"], "SR": 0.53125, "CSR": 0.571875, "EFR": 1.0, "Overall": 0.7859375}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Prussian army", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations", "ten years of probation", "In Pursuit", "Bolton", "The Frost Report", "Kansas City crime family", "Dirk Werner Nowitzki", "lifetime achievements", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "various deities, beings, and heroes", "86,112", "Celtic", "Ouse and Foss", "Springfield, Massachusetts", "British comedian", "apatosaurus", "in 1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "New York City", "The Seduction of Hillary Rodham", "2005", "Lambic", "Ubisoft", "Argentina,", "Larry Alphonso Johnson Jr.", "Mike Mills", "veto power", "Joseph E. Grosberg", "\"Chelsea Lately\"", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "Seattle", "discus", "Aston Lower Grounds", "2005", "228 people", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post- traumatic stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7002935606060605}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-3926", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.578125, "CSR": 0.5720766129032258, "EFR": 1.0, "Overall": 0.7860383064516129}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "a huge terrestrial globe", "log ride", "Human rights issues", "Take Me", "Nassau", "mother of pearl", "HIV", "Thomas Beekman", "a network of rail lines", "Rigoletto", "aardwolf", "Beijing", "Roger Bannister", "1,000", "Death Valley", "Yves Saint Laurent", "reindeer", "some other country", "the War of 1812", "Anna Mary Robertson Moses", "Sailor Moon", "georgia guinea", "New York Times Fiction Best Sellers", "a bear", "a tornado", "George Harrison", "Monty Python and the Holy Grail", "negative electrode", "Milton Berle", "George Herbert Walker Bush", "President Patrice Lumumba", "lunar module", "Pedro de Valdivia", "Dan Marino", "Mars", "clownfish", "6.690 x10-27kg", "Guru Pitka", "Las Vegas", "millet", "a butterfly", "heavy drinking", "orangutan", "Baja California", "death of Caesar", "Yitzhak Rabin", "David Spares Saul's", "Gettysburg", "Jack Gleeson", "Plank", "Buddhism", "Carl Johan", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "caused a generator to fall apart and grind to a halt after a computer attack on its control system.", "knocking the World Cup off the front pages", "12.3 million"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5500938146997929}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08695652173913043, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2051", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587"], "SR": 0.53125, "CSR": 0.57080078125, "EFR": 1.0, "Overall": 0.785400390625}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "a quarter square kilometer", "(MP) Henry Addington", "40", "Libya", "Shania Twain", "Hillsborough", "insulin and glucagon", "The New York Yankees", "rapid eye movements", "green, red, white", "(A Singular Woman)", "(\u5c55\u5f00) e monarchy", "French", "(John Altman)", "Ohio", "Francis Matthews", "photography", "hematite", "Noah", "london", "New", "the Duke and Duchess of York", "Mercury", "watt", "Kenneth Williams", "Subway", "Madagascar", "Swansea City", "(Hansel and Gretel) cottage", "S\u00e3o Paulo", "His name has become synonymous with someone who lives in hopeful expectation.", "aged 75", "Jennifer Lopez", "25cl", "Annie Lennox", "Fred Perry", "Downton Abbey", "Martina Hingis", "(Mac)Ahern", "cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "gulliver", "peterona", "Italy", "The Streets", "Appalachian Mountains", "a black Ferrari", "a branch of mathematics", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "the banned substance cortisone", "it is dedicated to \"global security, prosperity and freedom.\"", "(Martin) Cody", "Helvetica", "(pulmonary)"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5399003623188405}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 0.5, 0.08695652173913043, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4343", "mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-4309", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-16567"], "SR": 0.453125, "CSR": 0.5672348484848485, "EFR": 1.0, "Overall": 0.7836174242424243}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "allergens like molds, pollen and animals", "jim attan Churchill", "Getafix", "january", "Belfast", "wind", "fire insurance", "Robin Hood", "West Point", "Andy Warhol", "sheep", "jim branley", "jimav\u00edk", "the solar system", "potatoes", "Moldova", "Mitsubishi", "a Dartford Warblers", "j.S. Bach", "Estimate", "baroudeur", "argon", "jim bran Wilson", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Philippines", "beaver", "mel Blanc", "clingy", "Moffitt", "Ellen DeGeneres", "phil Woolas", "5000 meters", "racing", "clump of molecules", "Newfoundland and Labrador", "crow", "Yellowstone", "St. Francis Xavier", "Manila", "jim shales", "Buddhism", "Guy Berryman", "Ohio", "Port Melbourne", "Osbald", "Scarface", "forgery and flying without a valid license,", "Group D,", "Liza Murphy", "Spock", "Kazakhstan", "Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6049479166666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7129", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_triviaqa-validation-2642", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-11382"], "SR": 0.578125, "CSR": 0.5675551470588236, "EFR": 1.0, "Overall": 0.7837775735294118}, {"timecode": 34, "before_eval_results": {"predictions": ["French forces destroyed the fort and large quantities of supplies, including 45,000 pounds of gunpowder", "business", "prairies", "bologna, Italy", "George Santayana", "marsupials", "Alice Cooper", "catheterization", "trumpet", "Marc Warren", "animal", "shildon", "Appalachian", "Herald of Free Enterprise", "ballet", "storm", "dupin", "lizards", "blackburn", "Frankie Laine,", "The Mystery of Edwin Drood", "pommel", "a scarlet tanager", "Dick Van Dyke", "egremont", "numb3rs", "spain", "phrixus", "spain", "Canada", "ink sac", "pears soap", "Some Like It Hot", "spain", "Ireland", "Mike Meyers", "animal", "plutonium", "igneous rocks", "Passepartout", "Thank you", "Iceland", "spain", "shrek", "26.22", "Cleveland Brown", "heston Blumenthal", "One Direction", "spain", "Saturn", "crime", "Charles Lindbergh", "November 1999", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "ballet", "Howard Carter"], "metric_results": {"EM": 0.5, "QA-F1": 0.5774305555555554}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, true, true, false, true, false, true], "QA-F1": [0.22222222222222224, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10251", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-508", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-3837", "mrqa_triviaqa-validation-535", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6449", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.5, "CSR": 0.565625, "EFR": 1.0, "Overall": 0.7828125}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "matlock", "American Civil War", "isle of shoa", "flies", "Arafura Sea", "passeiphae", "Tigris", "czech republic", "to make wrinkles in one's face", "Spain", "carousel", "bullfight", "charles brane bunch", "Tenor", "cat food", "flore", "Guys and Dolls", "Julian Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "black eyed peas", "pembrokeshire", "L. Pasteur", "jean fonda", "Tom Ewell", "Finland", "massive stars", "Mille Miglia", "in caves", "charles goya", "black", "muriel Spark", "happy birthday", "seven", "opossums", "pickwick", "presliced", "Saga Noren", "raven", "jean", "peter Creek", "nelsons Column", "Etruscans", "Ken Burns", "Hyde Park Corner", "Great Britain", "Pyotr Ilich Tchaikovsky", "Sheikh Mujib,", "Scorpio", "Donna", "season four", "sinoatrial node", "Lee Sunmi", "tomato", "November 5, 2002", "workers walked off the job January 28 to protest the hiring of hundreds of foreign workers for a construction project at the Lindsey oil refinery in eastern England.", "the Civil Protection Authority", "March 24,", "Duke of Edinburgh", "September", "Pocahontas"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5192036290322581}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.12903225806451613, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-3021", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3182", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228"], "SR": 0.453125, "CSR": 0.5625, "EFR": 0.9714285714285714, "Overall": 0.7669642857142858}, {"timecode": 36, "before_eval_results": {"predictions": ["the Iranian Islamic Revolution", "kim", "city of acacias", "branson", "Gordon Ramsay", "luton Town", "joan crawford", "sulfur dioxide and nitrogen oxides", "Margot Betti", "ringway airport", "Portuguese", "Travelocity", "Avengers", "city of isle of crawford", "is a fictional psychiatric hospital", "tom and Jerry", "a ghost", "rapeseed", "Tina Turner", "joanna Lumley", "duttlenheim", "Bolivia", "John Donne", "Uranus", "Rio Grande", "charles", "marty crawford", "30th", "joan Fontaine", "kings james i", "One Foot in the Grave", "Bronx Mowgli", "maurice crawford", "George Santayana", "stalls", "borowdale", "crackerjack", "maurice de torquemada", "maurice farenboim", "Canada", "rum", "seattlepi.", "ghee", "george", "maurice crawford", "hyperbole", "oldpatricktoe-end", "Saturday", "maurice island", "Ceylon", "screwdrivers", "Denver Broncos", "G minor", "My Summer Story", "1974", "The Outsiders", "Amberley Village", "lack of a cause of death", "Prime Minister Stephen Harper", "those who were locked in a basement,", "Tzu Hsi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4692708333333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9574", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5196", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-12", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.40625, "CSR": 0.558277027027027, "EFR": 1.0, "Overall": 0.7791385135135135}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "pH ( / pi\u02d0\u02c8 ( h ) e\u026a t\u0283 / ) ( potential of hydrogen )", "Durham Cathedral", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist Charles Lyell", "17.44667", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "London, England", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "1770 BC", "Niveditha, Diwakar, Shruti", "two", "John C. Reilly", "DNA", "Anakin", "Travis Tritt and Marty Stuart", "1976", "Bee Gees", "Emily VanCamp", "Pradyumna", "1902", "On the west", "Psychomachia", "the New Jersey Devils", "two", "4 in ( 10 cm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Lisa Stelly", "the Canadian Rockies", "France", "phineas duke of zweibr\u00fccken", "dumbo", "purple rain", "Charles Guiteau", "Gettysburg Address", "iTunes", "$273 million", "India", "Garacad, Somalia", "Desperate Housewives", "The Flying Dutchman", "Morelos", "Tuesday"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6429360079835622}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09523809523809523, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.25, 0.5454545454545454, 1.0, 0.6666666666666666, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-5082", "mrqa_triviaqa-validation-6008", "mrqa_newsqa-validation-2554", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-2335"], "SR": 0.53125, "CSR": 0.5575657894736843, "EFR": 0.9333333333333333, "Overall": 0.7454495614035088}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in positions Arg15 - Ile16", "Joseph M. Scriven", "Lady Gaga", "the Chicago metropolitan area", "the president", "Domhnall Gleeson", "eusebeia", "horticulture", "West Bromwich Albion", "a nobiliary particle indicating a noble patrilineality", "Stephen A. Douglas", "1984", "related to the Common Germanic word guma", "India", "21 February", "Tagalog or English", "Bryan Cranston", "thylakoid membranes", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "almost entirely in Wake County, it lies just north of the state capital, Raleigh", "January 1923", "18 Divisional Round", "602", "maximum energy of 687 keV", "between $10,000 and $30,000", "September 1980", "1931", "the `` Holy Club '' at the University of Oxford,", "Cherbourg in France and Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "soon after in most cases except for Parsis who still have jury Trials for their Matrimonial Disputes", "Southern Cause", "Randy", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan", "Joseph Stalin", "in the intermembrane space", "a divergent tectonic plate boundary", "North Dakota", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Sir John Major", "Roddy doddy diney", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below zero", "General Motors'", "David McCullough", "Rendezvous with Rama", "CERN", "saudade"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5979315476190477}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.28571428571428575, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.32, 1.0, 1.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4929", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1404", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1076", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.515625, "CSR": 0.5564903846153846, "EFR": 0.967741935483871, "Overall": 0.7621161600496278}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "active absorption", "Philippe Petit", "September 1980", "January 2004", "provinces along the Yangtze River and in provinces in the south", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "punk rock", "Set six months after Kratos killed his wife and child,", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "A 30 - something man ( XXXX )", "Gestalt", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Rachael Harris", "Richard Crispin Armitage", "Brooks & Dunn", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "diffuse nebulae", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Santiago Ram\u00f3n y Cajal", "1890", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Ariel Winter", "Mark Jackson", "Michael Buffer", "one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and through all and in all", "on location", "the Second Continental Congress", "1958", "Cody Fern", "questions about the name of the war, the tariff", "prophets and beloved religious leaders", "saliva", "jean Manuel de Ayala", "Prophet Joseph Smith, Jr.", "doyle", "1909", "John Duigan", "179", "Princess Diana", "Mikkel", "curfew", "\"Me and Bobby McGee\"", "shark", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6137932890230684}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.14545454545454545, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_searchqa-validation-10341"], "SR": 0.484375, "CSR": 0.5546875, "EFR": 1.0, "Overall": 0.77734375}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants,", "Piers Morgan,", "\"Grease\"", "glamour and hedonism", "2-0", "more than 15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "one American diplomat to a \"prostitute\"", "since 2004", "NATO", "Switzerland", "Monday", "second", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "he wants to spend $10 billion on childhood education, $150 billion over 10 years on developing alternative energy", "T.I.", "Ensenada, Mexico", "Robert Barnett", "a class A traffic violation", "41,", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "Sylt", "rural Tennessee", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "Section 60", "Ali Bongo", "Gloria Allred,", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "Brazilian supreme court judge", "Derek Mears", "Operation Pipeline Express", "help rebuild the nation's highways, bridges and other public-use facilities.", "East Java", "St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "Mexico", "Snickers bar", "monoceros", "roddy", "Anaheim, California", "uncle Juan Nepomuceno Guerra", "Bergen", "Anubis", "the lands in question", "a graphical user", "the American Kennel Club"], "metric_results": {"EM": 0.421875, "QA-F1": 0.6228256541727545}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 0.0, 0.0, 0.375, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.05405405405405406, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.5714285714285715, 1.0, 0.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 0.3333333333333333, 0.9411764705882353, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.421875, "CSR": 0.5514481707317074, "EFR": 1.0, "Overall": 0.7757240853658537}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1997", "displacement", "layered systems of sovereignty", "Megan Park", "the symbols of Europe", "Kate Walsh", "September 14, 2008", "Trace Adkins", "on Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000 or annual dues were estimated in 2009 to be less than $ 10,000 per year", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "In England, births were initially registered with churches, who maintained registers of births", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Malloy as Pierre, Phillipa Soo as Alexandra, Lucas Steele as Anatole, Amber Gray as H\u00e9l\u00e8ne, Brittain Ashford as Sonya, Shaina Taub as Mary", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Coalhouse Walker Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "along the Bundle of His and through bundle branches", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Intertropical Convergence Zone ( ITCZ )", "Missouri River", "the right to be served in facilities which are open to the public", "frontal lobe", "10 June 1940", "Tandi", "wagner", "ear", "brazil", "The Dressmaker", "$10.5 million (USD 8 million)", "Tim Whelan", "Kurdish Region of Iraq", "Denver, Colorado.", "two soldiers and two civilians from the Defense and State departments", "Christopher Henderson", "Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.5, "QA-F1": 0.6401425249587014}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.9523809523809523, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 0.8235294117647058, 0.16, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.15384615384615383, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-6700", "mrqa_hotpotqa-validation-157", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518", "mrqa_searchqa-validation-1237"], "SR": 0.5, "CSR": 0.5502232142857143, "EFR": 0.9375, "Overall": 0.7438616071428572}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "asphyxia", "within the towns of Lexington, Concord, Lincoln, Menotomy ( present - day Arlington ), and Cambridge", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "the composition and powers of the Senate", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring, and \u03bd\u03af\u03ba\u03b7, n\u00edk\u00ea, `` victory '', i.e. `` she who brings victory ''", "Wilhelm Groener", "Ceramic", "the Soviet Union", "Covington, Kentucky", "New Mexico", "to condense the steam coming out of the cylinders or turbines", "December 15, 2017", "on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive", "L.K. Advani", "differential erosion", "Glenn Close", "the long form in the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "The Puerto Rico Electric Power Authority ( PREPA )", "fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "the Northeast Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "by producing an egg through parthenogenesis", "1926", "South Korea", "starting in 1560s", "Frankie Muniz", "Leon Huff", "1765", "alberich", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "The entertainer, whose real name is Clifford Harris, was arrested just hours before he was scheduled to perform at the BET Hip Hop Awards.", "prostate cancer,", "a dragon", "Little Lord Fauntleroy", "a key ring", "yellow"], "metric_results": {"EM": 0.5, "QA-F1": 0.6456421986764729}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.7741935483870968, 0.2222222222222222, 1.0, 1.0, 0.1818181818181818, 1.0, 0.7272727272727272, 1.0, 0.9, 0.5333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.08, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-2518", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-1526", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.5, "CSR": 0.5490552325581395, "EFR": 0.875, "Overall": 0.7120276162790697}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "February 27, 2007", "\" pick yourself up and dust yourself off and keep going ', female - empowerment song ''", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "le Roi d'Irlande", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters, an ex - basketball player and amputee", "jean Antonin Merci\u00e9", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home", "Edward Kenway ( Matt Ryan ), a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "branch roots", "Alex Ryan", "a habitat", "2018", "Windows Media Video ( WMV ), Windows Media Audio ( WMA ), and Advanced Systems Format ( ASF )", "100 members", "Toledo", "embryo", "During the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "Alicia Vikander", "in late January or early February", "Kalinga Ashoka", "the compartments were intended to safeguard the King's Chamber from the possibility of a roof collapsing under the weight of stone above the Chamber", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority", "Bumblebee", "the Christian biblical canon", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "AMX - 13, light tank", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "2018", "New York City", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "in the southwestern part of the island", "is prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "winter", "Tethys Ocean", "Newcastle Brown Ale", "Western Australia", "v\u00e1clav Havel", "Mary Bon auto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "'peregruzka,' which means 'overcharged.'\"", "$60 billion", "North Atlantic Treaty Organization", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.4375, "QA-F1": 0.612087706656828}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.8387096774193548, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6250000000000001, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.962962962962963, 0.5714285714285715, 0.4705882352941177, 0.6666666666666666, 0.0909090909090909, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.9189189189189189, 0.0, 0.9767441860465117, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.09523809523809525, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-2425", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9390", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977", "mrqa_searchqa-validation-13337"], "SR": 0.4375, "CSR": 0.5465198863636364, "EFR": 1.0, "Overall": 0.7732599431818181}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Laurel, Mississippi", "about the outdoors, especially mountain-climbing", "Indianola", "Escorts Limited, an engineering company that manufacture agricultural machinery, machine construction and material handling equipment and railway equipment", "the British military", "1992", "the Goddess of Pop", "northwestern Georgia", "James Harrison", "Toronto", "Tomorrowland", "fennec", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Epicurus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop in Las Vegas", "Nationalism", "Bishop's Stortford F.C.", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "the Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer", "South America", "2006", "perjury and obstruction of justice", "\"The Major of St. Lo\"", "Mary Elizabeth Hartman", "over 9,000 employees", "John Nightingale", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "The Finger Tab", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Chapter 5", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6025240384615385}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.8, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-2340", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.484375, "CSR": 0.5451388888888888, "EFR": 1.0, "Overall": 0.7725694444444444}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1996", "navigation by river", "Naomi Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "AC/DC", "GmbH", "Mick Jackson", "Lalit", "his virtuoso playing techniques and compositions in orchestral fusion", "Tampa Bay Lightning", "Steven Selling", "Chesley Burnett \"Sully\"", "Manhattan Project", "Pacific War", "Romantic", "Hugh Dowding", "AMC Theatres", "New York Islanders", "Fennec fox", "1978", "the 1962 International Cup for Formula One Manufacturers", "Canadian", "Pacific Place", "ASEAN Football Federation (AFF)", "(2014)", "Rudebox", "about 5320 km", "Macbeth", "Engirundho Vandhaal", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faisal Qureshi", "the British Army", "over 80% of the vote", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Maroon 5", "Saudi Arabia", "Joseph Crowley", "two"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6643229166666667}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-4054", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327", "mrqa_searchqa-validation-2897"], "SR": 0.59375, "CSR": 0.5461956521739131, "EFR": 0.9615384615384616, "Overall": 0.7538670568561874}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland shark", "The Word", "President Abraham Lincoln's", "Saint Jude Thaddeus", "Anthoonij van Diemenslandt", "the death penalty", "xerophyte", "Jackie Robinson", "Manhattan", "Dian Fossey", "MI5", "Harrow", "cr\u00e8me anglaise", "onions", "pork", "curling", "Victoria Coren", "Pickett's Charge Gettysburg", "Chile\u2019s best wine producing region in the north of Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "President Barack Obama", "Canada's Liberal Party", "Bologna Song Lyrics - Daniel Bedingfield", "Dominican Republic", "David Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "Florida", "Mary Poppins", "glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Daily Herald", "(1812)", "\"permissible.\"", "beginning in 2016", "the Supreme Court of Canada", "2017", "Chief of Protocol", "Diamond White", "1944", "U.S. Open final defeat to Juan Martin Del Potro.", "Jeddah, Saudi Arabia,", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "Reader's Digest Association", "the living child"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6552083333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-6789", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1987", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.578125, "CSR": 0.546875, "EFR": 1.0, "Overall": 0.7734375}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "anaphylaxis", "bob Charlton", "Culloden", "Runic", "canada", "cricket", "alex kirchhoff", "rotherham United", "heat transfer", "misery", "Styal", "stately", "Blind beggar", "Mr. Brainwash", "Leroy Burrell", "parlophone", "Wild Atlantic Way", "john Denver", "an Unseen University football team", "hilitos", "lackawanna Six", "chile", "Scrabble", "muezzin", "a window", "a strake", "madame Bovary", "Apollo 11", "Cellophane", "s Tesla", "jockey", "Evita", "albino sperm whale", "roddy turner", "east fife", "St Pancras International Station", "the immediate physical and social setting in which people live or in which something happens or develops", "sliced bread", "dilbert", "casterbridge", "nunc dimittis", "French", "medea", "Burgundy", "cribbage", "The Beatles", "Johannesburg", "French", "muffin Man", "South Korea", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "the Greenbriar Boys", "Pansexuality", "Tony Ducks", "1754", "drugs", "Veracruz, Mexico,", "bankruptcy", "Robert Frost", "King Henry VIII", "Midwest Living", "Mitsubishi Eclipse - Shot at by Johnny Tran"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6127480158730159}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5914", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-2610", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.5625, "CSR": 0.5472005208333333, "EFR": 1.0, "Overall": 0.7736002604166666}, {"timecode": 48, "before_eval_results": {"predictions": ["jimmy highway", "sesame Street", "tomatoes", "cabbage", "t Tasmania", "jimmy magoo", "fleece", "Ash tree", "opossum", "New Zealand", "noddy", "60", "goldfinger", "1983", "pike", "mongols", "1875", "tax collector", "penny", "noddy", "spain", "bagram", "jimmy henderson", "Chrysler", "a winter fur hat", "dandy", "spain", "france", "france", "spain", "biathlon", "spain", "charles Chan", "Vienna", "white", "jaws", "paul henderson", "rabbit", "spain", "henpecked", "Orson Welles", "nikola", "menorah", "france", "texa", "Super Bowl Sunday", "a quant pole", "Little Tommy Stout", "jimmy smith", "azalea", "spain", "Chuck Noland", "the Colony of Virginia", "in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park, Kenya", "2010", "the ancient Greek site of Olympia", "10 below", "Nearly all of Britain's troops in Iraq", "silver", "the American Kennel Club", "Omaha", "Dick & Jane"], "metric_results": {"EM": 0.375, "QA-F1": 0.48436770541549956}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.7058823529411764, 1.0, 0.888888888888889, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-2446", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-3053", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-263", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-2158", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2352", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366"], "SR": 0.375, "CSR": 0.543686224489796, "EFR": 1.0, "Overall": 0.771843112244898}, {"timecode": 49, "before_eval_results": {"predictions": ["daniel stewart", "Iran", "tobacco", "francis", "dutch", "daniel Boone", "Thames Street", "Theodore roosevelt", "satyrs", "fish", "boheme", "IBM", "a wishbone", "garrick club", "Lackawanna 6", "bennaby roddy", "britten", "American Civil War", "a succession of bad events, repeated bad luck", "tommy lee Anderson", "jimmy Robertson", "Florence", "tsar Ivan IV", "veruca salt", "severn", "australia", "South Africa", "plants that have proteins like those in pollen", "Nicaraguan", "daniel chan", "war of roses", "chemnitz", "dutch", "trout", "ap\u00e9ritif", "kennon", "dutch", "folk music of the 20th century", "hair loss", "sprint", "charlie dane", "Robin Hood Men in Tights", "Chris Martin", "flinstone", "George gently", "rugby", "honda", "scotland", "11", "tobacco", "heifer", "free floating", "Tom Selleck", "United States", "a pinball machine designed by Steve Ritchie and manufactured by Stern Pinball", "Texas Tech University", "Loughborough Technical Institute", "Sharon Bialek", "United States", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "George Babbitt", "Oklahoma", "Company", "four"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4540938793995859}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true], "QA-F1": [0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.17391304347826086, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6840", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-3615"], "SR": 0.390625, "CSR": 0.540625, "EFR": 1.0, "Overall": 0.7703125}, {"timecode": 50, "UKR": 0.751953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.810546875, "KG": 0.46875, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "Angelo Bruno", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo", "Harold Lipshitz", "Spanish", "\"Ted\"", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Fiapre", "antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport", "Scotty Grainger Jr.", "9", "a subcompact automobile built by Honda of Japan", "New Scotland", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1902", "Nicolas Winding Refn", "devotional literature", "Fortunino Francesco Verdi", "Laban Movement Analysis", "Cecily Strong", "J. Robert Oppenheimer", "invoice, bill or tab", "seasonal television specials, particularly its work in stop motion animation", "4 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "playback singer", "1901", "Pope John X", "BAFTA Award", "Electronic Attack Squadron 135", "Doug Pruzan", "American country music group The Nitty Gritty Dirt Band", "English", "beta", "FBI", "a vessel", "EMI, owner of the recording studios", "UNICEF", "9 a.m.", "George Byron", "Van Helsing", "Aramaic", "a long-range missile"], "metric_results": {"EM": 0.5, "QA-F1": 0.6240451388888888}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.25, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-2110", "mrqa_hotpotqa-validation-4925", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-217", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.5, "CSR": 0.539828431372549, "EFR": 1.0, "Overall": 0.7142156862745098}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field in Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "a historic house museum", "\"Realty Bites\"", "24", "Razor Ramon", "Morita therapy", "Forbes", "St. George", "Kramer", "Lithuanian national team", "International Boxing Federation", "35", "Conservatorio Verdi", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "World Outgames", "Homebrewing", "Umberto II", "Presbyterian Church (USA),", "neuro-orthopaedic Irish veterinary surgeon", "Hookend Recording Studios in Checkendon, Oxfordshire", "North Sea", "17 October 2006", "67,575", "Oxford", "OSRIC", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "Italian English", "Eric Edward Whitacre", "Mission Inn Hotel & Spa", "180", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "Rahoneen", "Scunthorpe", "Canadian comedian", "Cook's Landing Place", "Summer Olympic Games", "1936", "1970", "Royal Albert Hall and The Kennedy Center", "Budget Rent a Car System, Inc.", "Japan", "lion", "1959", "Kristina Wagner", "a pop and R&B ballad, with Latin pop influences", "735 feet ( 224 m )", "state of america", "Blanche", "maxilla", "AMD (another American company and Intel's only competitor)", "4.6 million", "Iran,", "tea rose", "John J. Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.421875, "QA-F1": 0.6005219606782107}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.6666666666666666, 0.5, 0.5, 0.0, 1.0, 0.4, 1.0, 0.8, 0.0, 1.0, 0.8, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.16666666666666666, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.7499999999999999, 1.0, 1.0, 0.5, 0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-673", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653"], "SR": 0.421875, "CSR": 0.5375600961538461, "EFR": 1.0, "Overall": 0.7137620192307692}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "non-voters", "3", "up to 100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the American punk rock band the Ramones", "Jack Nicholson", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the Gospel of Luke", "30 years after Return of the Wars", "standard form contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1964", "the British", "1972", "Columbia River Gorge in the U.S. states of Oregon and Washington", "coercivity", "2006", "malicious software", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "mythical monsters like the Minotaur or a werewolf", "Terry Kath", "clay", "one person", "The Parlement de Bretagne", "password recovery tool for Microsoft Windows", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "late - September", "currency option", "1599", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "the medulla oblongata", "2018", "Gibraltar", "Howard Caine", "May 3, 2005", "Andy Cole", "war of passchendaele", "comedy playhouse", "paul Maskey", "teenage actor or teen actor", "Saoirse Ronan", "Revolution Studios", "The Kirchners", "north London rivals Tottenham", "Sovereign Wealth Funds", "Ways and Means Committee", "Yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.5, "QA-F1": 0.5830557489889602}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.8333333333333334, 0.046511627906976744, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.058823529411764705, 0.967741935483871, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-10706", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_triviaqa-validation-1896", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3162", "mrqa_newsqa-validation-318", "mrqa_newsqa-validation-577", "mrqa_searchqa-validation-1310", "mrqa_searchqa-validation-4527"], "SR": 0.5, "CSR": 0.5368514150943396, "EFR": 0.9375, "Overall": 0.701120283018868}, {"timecode": 53, "before_eval_results": {"predictions": ["Al Lenhardt", "a big bang", "James Bennett II", "Green Acres", "Life's Refinements", "a chocolate-covered blend of coconut, nuts, and fruit", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "Windsor", "the Pick A Brick Wall", "a blue mussel", "pudd'nhead Wilson", "Sydney", "the tapir", "France", "canned precooked meat", "Stephen Dedalus", "early", "Cheeses of France", "Friday", "The Golden Legend", "centaurs", "Mentor", "commander of the Lebanese armed forces", "Manifest Destiny", "William Jennings Bryan", "disabilities", "Singapore", "Bruce Springsteen", "(FRG/West Germany)", "Glucosamine", "Madagascar", "Encyclopedia of Philosophy", "celebration", "busby", "Susan Faludi", "Ice-T", "Al Lang Stadium", "Fidel Castro", "fudge", "heffalump", "Laborers' International Union", "goldfish", "hormones", "a dive", "yellowtail", "watermelon", "between the Mediterranean Sea to the north and the Red Sea in the south", "Beijing", "Zeus", "van Morrison", "antelopes", "bacardi", "the Rocky Mountain Institute", "21", "a \"stumbling block\" or a stone to \"stumble upon\", plural stolpersteine", "Three thousand", "a civilian caught in the crossfire", "3,000 kilometers (1,900 miles),", "Lambic"], "metric_results": {"EM": 0.5, "QA-F1": 0.5354166666666667}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-14168", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-7315", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-14085", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792"], "SR": 0.5, "CSR": 0.5361689814814814, "EFR": 0.96875, "Overall": 0.7072337962962962}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "a travelling circus", "the vascular cambium", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "elocution", "Isle of FERNANDO 'S!, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "45 %", "handheld subscriber equipment", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Will Champion", "the Ming dynasty", "a major river in the southern United States of America", "those colonists of the Thirteen Colonies", "The Intolerable Acts", "National Industrial Recovery Act ( NIRA )", "semi-autonomous organisational units within the National Health Service in England", "Scott Schwartz", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "the 1964 Republican National Convention in San Francisco", "the Finch family's African - American housekeeper", "( such as the muscles of the limbs, abdominal, and intercostal muscles )", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "driving miss boolie", "the Greek Goddess of Revenge", "Naval Air Station Kaneohe Bay", "PlayStation 4", "December 31, 2015", "Seminole Tribe", "Defense of Marriage Act", "Alinghi", "Eiffel tower", "barnacles", "animal", "ewan McGregor"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6689126212135847}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 0.5555555555555556, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.3448275862068966, 1.0, 0.888888888888889, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.7272727272727272, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-2067", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506"], "SR": 0.53125, "CSR": 0.5360795454545455, "EFR": 1.0, "Overall": 0.7134659090909091}, {"timecode": 55, "before_eval_results": {"predictions": ["king Edward III", "golf", "purple", "aeoline", "ascot", "Litas", "Loretta Lynn", "WrestleMania", "steppenwolf", "chop suey", "ken macManus", "baltimore", "baltimore", "India", "bakr", "New Zealand", "Tyrrhenian", "bacall", "mauritania", "han lippershey", "b Bolivia", "nick saxton", "Mozambique Channel", "ash", "bacall", "k Thomas Cranmer", "testicles", "quetzal", "muralitharan", "Caroline aherne", "Byron", "s\u00e8vres", "Mau Mau Revolution", "kipps: The Story of a Simple Soul", "frankincense", "Serena Williams", "capital of togo", "Pegida", "alberich", "Utrecht", "1709", "Mitford", "kansas", "alter-ego", "vitifoliae", "Skylab", "ostrich", "hugh quarshie", "a ship", "robin", "bator", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack Ridley", "Linux Format", "Stage Stores", "26", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Shanghai", "Kool- Aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.5, "QA-F1": 0.5588541666666667}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-1051", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-3596", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5554", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-6624", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.5, "CSR": 0.5354352678571428, "EFR": 1.0, "Overall": 0.7133370535714285}, {"timecode": 56, "before_eval_results": {"predictions": ["argentina", "bolivia", "The Telegraph", "liver", "portugal", "Drunk Crosswords", "gala", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "george eliot", "north-west corner of the central business district", "meatloaf", "benazir butto", "bowler", "Sam Mendes", "thorson", "scorcese", "ninth", "business", "lady Godiva", "scorcese", "Mexico", "river Towy", "poulenc", "1984", "scotland", "3", "shinto", "Sussex", "george iv", "mouse", "oxygen", "son", "toalavera de la reina", "Are you going to come quietly, or do I have", "dodoma", "radiohead", "Wilson", "Loch lomond", "Pyrenees", "South Korea", "gelatine", "new guinea", "gulf of aden", "Yorkshire", "austerlitz", "scotland", "French Revolution", "the Rockingham Arms", "into one of the Vikings nine realms", "an anion", "iron", "a President since creation of the office in 1789", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "off Somalia's coast.", "Shanghai", "a peacock skirt", "Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.453125, "QA-F1": 0.529362273755656}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 0.4615384615384615, 0.0, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-2319", "mrqa_triviaqa-validation-2943", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.453125, "CSR": 0.5339912280701755, "EFR": 1.0, "Overall": 0.7130482456140351}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "jimmy smith", "rennet", "river Lee", "Rudolf nureyev", "Jessica", "placebo", "weather", "Lake placid", "papal treaty", "braille", "William Boyd", "saint Cecilia", "Caroline Garcia", "morecambe and Wise", "tommy lee jones", "drummer", "cowpox", "fox hunting", "Stockholm", "france", "son in arms", "anosmia", "Lunar Prospector probe", "Chemnitz", "herbygrass", "yellow", "raven", "caracas", "ennio morricone", "British", "spain", "time team", "Turandot", "Algeria", "Mount Everest", "eat porridge", "Howard Keel", "marriage", "Boutros Ghali", "baltimore", "Sinclair Lewis", "southern", "garden of gethsemane", "decision tree", "3.762", "Sunday", "france", "Kristiania", "keirin", "selenium", "vehicles designed for off - road use are known as `` four - wheel drives '', `` 4WDs '', or `` 4 \u00d7 4s ''", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "Michael Jackson was in good health, contrary to media reports he was diagnosed with skin cancer.", "Shiza Shahid,", "Perseid meteor shower", "accordion", "bones", "Mark Wahlberg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7109375}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-1020", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-6704", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009"], "SR": 0.640625, "CSR": 0.5358297413793103, "EFR": 0.9565217391304348, "Overall": 0.704720296101949}, {"timecode": 58, "before_eval_results": {"predictions": ["Rubbing", "Jonah", "Hugh", "Constantinople", "Jacqueline Susann", "Brazil", "Hudson", "bones", "Paradise", "the Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "ruby", "scalpels", "Siberia", "William Pitt the Younger", "five", "The One Where Jason's Mom Did It", "Rotherham", "The Godfather", "cancer", "Nostradamus", "jihad", "harpoons", "Mandy", "financial services", "Conrad Hilton", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the Battle of Trafalgar", "the bison", "marty", "a dramma tragico", "hurricanes", "Home Improvement", "Kashmir", "Airport", "alpha", "new orleans", "a single death", "Under the Sea", "Grant", "lethal", "college grants", "beryl", "a dome", "19 July 1990", "Incudomalleolar joint", "Louis XV", "Zimbabwe", "mansion house", "lance-corporal", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Eden Park", "money"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5442708333333333}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-13207", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-12684", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-9863", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-5458", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225"], "SR": 0.484375, "CSR": 0.534957627118644, "EFR": 0.9696969696969697, "Overall": 0.7071809193631228}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "germany", "barrel aging", "Leonard Bernstein", "calcium", "Venice", "the Danube", "the albatross", "Se sitcom", "The Machines of God", "phrase", "Ohio State", "William Tecumseh Sherman", "Pakistan", "Theology of God", "Ireland", "Norma Rae", "Barbara Cartland", "Rum", "a Pringles can", "Paul Hamm", "a type of classical male singing voice", "East Siberia", "Nimble", "Tom Hanks", "Clue", "House Busters", "Wonder Woman", "alternating current", "(Walter) Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "the trade winds", "the United Nations", "silk", "w", "a Unicorn", "Scrabble", "humerus", "Saturday Night Fever", "Petruchio", "the Philippines", "fungus", "Ernesto \"Che\" Guevara", "Yale University", "Oscar Wilde", "Helen of Troy", "Dian Fossey", "a relief print", "an iron -- nickel alloy and some other elements", "ABC", "an opinion in a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court", "apple", "Melbourne", "The Big Bopper", "Ringo Starr", "Do Kyung-soo", "Hanna, Alberta", "Majid Movahedi,", "National Intelligence Service", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "Priam"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6180208333333334}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6, 0.0, 0.32, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-12007", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-217", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-8167", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-494", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-10144", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-4918", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-1726", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745"], "SR": 0.515625, "CSR": 0.5346354166666667, "EFR": 1.0, "Overall": 0.7131770833333333}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha", "four", "Sippin' on Some Syrup", "\"Diary of the Dead\"", "Maersk M\u00f8ller Centre for Continuing Education", "Cressida", "Karl-Anthony Towns", "five", "Gust Avrakotos", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1858", "Julie Taymor", "actor", "James Edward Kelly", "Spanish", "Purdue University", "Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "John Mills", "Erinsborough", "2015", "Moscow Does Not Believe in Tears", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "25 August 1949", "Savannah River Site", "\u00c6thelwald Moll", "God and the just cause", "Swiss", "Emperor Tiberius", "World War I", "at age 27", "Marktown", "five", "Rodney Crowell", "Mendel", "near major hotels", "scales", "d\u00fcsseldorf", "apollon", "Anil Kapoor", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "Arthur E. Morgan III,", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.578125, "QA-F1": 0.65390625}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-399", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-4752", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.578125, "CSR": 0.5353483606557377, "EFR": 0.9629629629629629, "Overall": 0.7059122647237401}, {"timecode": 61, "before_eval_results": {"predictions": ["Ivar", "Omaha Nighthawks", "girls aged 11 to 18", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Adult Swim", "1983", "Rio Ferdinand", "247,597", "2,664", "841", "Cher", "ABC1 and ABC2", "MG Cars", "Walt Disney and Ub Iwerks", "1979", "15", "January 23, 1898", "John W. Henry", "Bolton", "Argentinian American", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "Battle of White Plains", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "Dziga Vertov", "Friday", "Oklahoma Sooners", "2002\u201303", "7pm", "1866", "Gaahl", "Lega Serie B", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf for Best Actor", "Fast and Furious 7", "the final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer Bears", "1951", "35,124", "154 days", "September 30", "Jimmy Flynn", "the Soviet Union", "his finger", "Ronald Reagan", "Comfort", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "fuel economy and safety while boosting", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "James Watt", "T.S. Eliot", "Anastasia", "appearances"], "metric_results": {"EM": 0.5, "QA-F1": 0.6338172480567361}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 0.5, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 0.2666666666666667, 0.10526315789473684, 0.5217391304347826, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-3573", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1687", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-6998", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129", "mrqa_naturalquestions-validation-715"], "SR": 0.5, "CSR": 0.5347782258064516, "EFR": 1.0, "Overall": 0.7132056451612903}, {"timecode": 62, "before_eval_results": {"predictions": ["the \"Acad\u00e9mie royale d'architecture\"", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Babylon", "a card (or cards) during a card game", "water sprite", "Sean Yseult", "law firm", "October 5, 1937", "Hillsborough County", "Charles Nungesser,", "Burning Man", "Love Streams", "King George VI", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "San Francisco International Airport in California", "Simon Bolivar Buckner", "German", "Gareth Jones", "consulting", "April", "1978", "actor, producer, and director", "Connie", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "the German princely Battenberg family", "dice", "Kal Ho Naa Ho", "Dungeness", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "David Anthony O'Leary", "HackThis Site", "Reginald Engelbach", "American", "Black Friday", "Golden Valley, Minnesota", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard seddon", "the right atrium", "Sitka, Alaska", "to take the Rio Group to a new level by creating the organization.", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "Bob Bogle", "circumference", "The Hague", "a stationwagon", "in 2001"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6071969696969697}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4046", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-2535", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-12404", "mrqa_naturalquestions-validation-8299"], "SR": 0.515625, "CSR": 0.5344742063492063, "EFR": 0.967741935483871, "Overall": 0.7066932283666155}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"I'll have my bond\"", "the parsnip", "Beluga whale", "Nicholas II", "a tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "Argentina", "Thor", "Orange", "astride", "Borneo", "Mount Vernon", "cereal", "Raleigh", "whipped cream", "yellowfin", "Macbeth", "Jean-Michel Basquiat", "Led Zeppelin", "War and Peace", "Dutchman", "Cybill Shepherd", "the outskirts of a small Southern town", "Columbo", "John Tyler", "Milwaukee", "a mushroom", "Wall Street", "sake", "Notre Dame", "Portland", "Lafayette", "The Indianapolis 500", "Woody", "improv", "Carrie Bradshaw", "Eustace", "Nikolai Gogol", "Oscar Wilde", "Fletcher Christian", "weaving", "John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Phillip Schofield and Christine Bleakley", "the duodenum", "Reverend J. Long", "classical violin", "sexual imagination", "Mount Godwin Austen", "Garrett Morris", "1966", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "three thousand", "al-Maliki"], "metric_results": {"EM": 0.625, "QA-F1": 0.6854538690476191}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-4565", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.625, "CSR": 0.535888671875, "EFR": 1.0, "Overall": 0.713427734375}, {"timecode": 64, "before_eval_results": {"predictions": ["pumpkins", "Seminole", "billions of dollars in Chinese products each year,", "a German citizen", "228", "love and loss", "2005", "radioactive waste", "consumer confidence", "Fernando Gonzalez", "the southern port city of Karachi", "Rob Lehr", "Jason Chaffetz", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "India", "Barack Obama", "Sunday", "Bienvenido Latag", "France", "380,000", "be silent", "iTunes", "Yusuf Haji", "\"gotten the balance right\"", "a dozen", "10", "Quiet Nights", "his death cast a shadow over festivities", "Iran", "123 pounds of cocaine and 4.5 pounds of heroin", "an engineering and construction company", "was depressed over a recent breakup, grabbed the gun and took her own life.", "fractured pelvis and sacrum", "five", "to step up", "first-degree murder", "Moscow", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda", "Garth Brooks", "in Oxbow,", "Bahrami", "different women coping with breast cancer", "Michael Schumacher", "Lula da Silva", "release of the four men", "2006", "12.9 - kilometre", "Dennis Locorriere", "Theodosius I", "ted kennell", "Estonia", "is our children learning", "Anne", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Hipparchus", "Woodrow Wilson", "the middle"], "metric_results": {"EM": 0.5, "QA-F1": 0.6108268467643467}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, true, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.4, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3682", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-10515", "mrqa_searchqa-validation-709"], "SR": 0.5, "CSR": 0.5353365384615385, "EFR": 1.0, "Overall": 0.7133173076923077}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "\"I always kind of admired him, oddly.\"", "North Korea", "on February 12", "Mandi Hamlin", "United Nations", "falling space debris,\"", "Little Rock military recruiting center", "voluntary manslaughter", "Rainbow Babies and Children's Hospital in Cleveland,", "Chris Robinson", "Grease", "\"black box\"", "34", "E. coli bacteria", "15,000", "\"A good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "government", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "collapsed apartment building", "Cardinal Spellman High School,", "against using injectable vitamin supplements", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "President Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide", "Caylee Anthony,", "the Richmond students did nothing because of the \"bystander effect\"", "Wednesday.", "managing his time.", "not including co-pays or deductibles.", "bipartisan", "us to step up.\"", "he believed he was about to be attacked himself.", "education about rainforests.", "13 and 15", "Vicente Carrillo Leyva,", "state", "Trevor Rees,", "28 passengers,", "the leader of a drug cartel", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace.", "243 days", "Kirstjen Nielsen", "1937", "20", "Madison, Wisconsin", "he has been nicknamed \"Mr Loophole\"", "Arlo Looking Cloud", "Queenston Delta", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6441964285714286}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.4, 0.4, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-2527", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-3555", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2725", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-3469", "mrqa_triviaqa-validation-1217", "mrqa_triviaqa-validation-122", "mrqa_triviaqa-validation-5615", "mrqa_hotpotqa-validation-4692"], "SR": 0.515625, "CSR": 0.5350378787878788, "EFR": 1.0, "Overall": 0.7132575757575758}, {"timecode": 66, "before_eval_results": {"predictions": ["jeffery deaver", "sonar", "Pete Best", "Robert Taylor", "vincent van Gogh", "spain", "about a mile north of the village of Dunvegan", "ArcelorMittal Orbit", "lodges", "stilwell", "vatican Union", "the solar system", "coelacanth", "Belgium", "Dennis Potter", "calcium", "Eric coates", "Geoffrey Cox", "Mel Brooks", "The California condor", "wisconsin", "wind turbines", "harridan Grizelda pugh,", "woodentop", "0", "Hamlet", "kempton Park, Ekurhuleni, Gauteng,", "crackerjack", "charles Dickens", "carousel", "Spain", "minder", "sauce", "mr. babbage", "kansas city", "hard Times", "Tuscany (Tuscany) Region", "tallest building in the world", "Singapore", "Scooby-Doo", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "jennifer kennedy", "hk Kong", "Chuck Yeager", "lisping Violet- Elizabeth Bott", "northern France", "stamp collecting", "moby Dick", "Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "American philosophy of pragmatism", "21 July 2015", "Bern", "28 June 1945", "Mujahedeen Youth Movement,", "25", "Pakistan", "Yves Saint Laurent", "Rush", "Yogi Berra", "business dealings for possible securities violations"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6216021825396826}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 0.09523809523809525, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444444]}}, "before_error_ids": ["mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-6641", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-5331", "mrqa_triviaqa-validation-5006", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-7017", "mrqa_newsqa-validation-2682"], "SR": 0.546875, "CSR": 0.535214552238806, "EFR": 1.0, "Overall": 0.7132929104477612}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "United States Department of the Interior", "Christina Pickles", "August 9, 1945", "after obtaining the consent of the United Kingdom", "a cake", "Olivia Olson", "Tokyo", "Pyeongchang County, South Korea", "623", "March 11, 2018", "5.7 million customer accounts", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "Royal Air Force ( RAF )", "rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET", "1836", "Mariah Carey", "Spektor", "H CO", "seven", "as a single in September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Ukrainian Soviet Socialist Republic", "435", "sport utility vehicles", "Elk and Kanawha Rivers", "American country music duo The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand to New Guinea", "Frank Oz", "Flag Day in 1954", "2010", "Missouri River", "(Arthwyr) elizabeth", "lute", "Greece", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town", "Araceli Valencia,", "Eleven", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi", "hyperbole"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6608431590339485}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8421052631578948, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-5363", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025", "mrqa_searchqa-validation-12184"], "SR": 0.5625, "CSR": 0.5356158088235294, "EFR": 0.9642857142857143, "Overall": 0.7062303046218488}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "Roberta flack", "sesame", "Infante(noun)", "pirate day", "barnaby rudge", "Buddha", "ethiopia", "1963", "discus thrower", "tabloid", "royal festival hall", "chester racecourse", "wisconsin", "Jews", "Romanian", "saint basil", "Peru", "the keel", "Evander Holyfield", "a crosse or lacrosse stick", "dharmarajika", "New Orleans", "soda", "fat like oil or lard", "Richie McCaw", "brashy", "ken Burns", "paddy doherty", "yvonne", "phi", "Hungary", "So Solid Crew", "blues-rock", "Pennsylvania", "the kuma-Manych Depression", "scotland", "\" Morningtown Ride\"", "Jupiter", "The Woodentops", "a child", "8", "Queens Park Rangers", "Wide Area Augmentation System", "Cyclopes", "cotton", "b\u00e9la Bart\u00f3k", "hugh Dowding", "Montpelier", "February", "Arthur, Prince of Wales", "the poverty threshold for a single person under 65 was an annual income of US $11,770", "318", "Chris Rea", "Andrzej Go\u0142ota", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 30, 2025", "Amanda Knox's aunt Janet Huff", "the Gulf of Aden,", "a home in an upscale San Fernando Valley neighborhood,", "planted", "the United States of America", "mullet", "It is a year of concern and sober reassessment of our nation's character and purpose"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5348462301587302}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.2666666666666667, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-6027", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-638", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.484375, "CSR": 0.5348731884057971, "EFR": 1.0, "Overall": 0.7132246376811594}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey arthur", "Chicago", "oregon", "dar es salaam", "Sarah Keays", "miss marple", "elkie Brooks", "UPS", "Novak Djokovic", "piano", "c Cambridge", "graham", "The Beatles", "glycerol", "addams", "doubting castle", "insect", "germany", "england", "Harry Shearer", "9-13 years", "stanley", "farthings", "spice girls", "The Golden Child", "AFC Wimbledon", "dutch", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "bagram", "pygmalion", "English", "cassis", "Dieppe Raid", "Dengue fever", "left book club", "triathlon", "customs agent Dave Kujan", "the dividing of cells into additional cell bodies", "strictly Come Dancing", "sound and light", "Par", "jack Russell Terrier", "prairies", "fondue", "Mount McKinley", "Magic Circle", "the Potsdam Conference", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Cordelia", "London Luton Airport", "Sarah Winnemucca Hopkins", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Madagascar, Mauritius, Mayotte, R\u00e9union, Seychelles,", "Chaudhary's death was warning to management.", "that Misty Croslin-Cummings continues to hold important answers in the case,\"", "\"remained at the bottom of the hill surviving on leaves and water from a nearby creek,\"", "Vanilla Ice", "William Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5994647562582345}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.10000000000000002, 0.08695652173913043, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-1346", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627"], "SR": 0.53125, "CSR": 0.5348214285714286, "EFR": 1.0, "Overall": 0.7132142857142857}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew", "a sentence fragment", "New South Wales", "Ashrita Furman", "Lana Del Rey", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Vincent Price", "1931", "Edgar Lungu", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the city of Indianapolis", "Latitude", "blighted ovum or anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Van Halen", "$100", "the referee", "Bonhomme", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W \ufeff / \ufffdrous 26.617 \u00b0 N 81.886 \u00b0 W", "smacking a fly on her mirror", "around 2011", "New Jersey Devils", "ulnar nerve", "2018", "British Indian Association", "many forested parts of the world", "the majority coming from Western Australia", "Carol Worthington", "1830", "smoking", "thanksgiving for a good harvest", "28", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "Bangalore", "Anthony Hopkins", "Jesus Christ", "1996", "holographic method", "spain", "kevin vinterberg", "Gillian Anderson", "direct scattering and inverse scattering", "45th Infantry Division", "it should stay that way.", "2009", "an open window that fits neatly around him.", "Dutchman", "Coleridge", "Pygmalion", "yen"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7682033703632969}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, false, false, true, true], "QA-F1": [0.8571428571428571, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.8333333333333333, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.8888888888888888, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.7499999999999999, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-2577", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-706", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-3858", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.5625, "CSR": 0.5352112676056338, "EFR": 0.8928571428571429, "Overall": 0.6918636820925553}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "the inner core and growing bud of certain palm trees", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama World Tour", "on the table", "red", "on the reservation", "either in front or on top of the brainstem", "March 14, 1942", "Atreus, Agamemnon's father", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Peggy Lipton", "India", "Tessa Peake - Jones", "It is an expected or free or continuously changing behaviour and may have a given individual social status or social position", "United Nations Peacekeeping Operations", "part of the normal flora of the human colon and is generally commensal, but can cause infection if displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "a religious covenant that is described in the Bible", "Shirley Mae Jones", "Heat transfer by thermal radiation", "John 6 : 67 -- 71", "on August 19, 2016", "protects it from infections coming from other organs ( such as lungs )", "scrolls", "Terrell Suggs", "celebrity alumna Cecil Lockhart", "August 22, 1980", "the optic chiasma", "a large, high - performance luxury coupe", "September 25", "part of Virginia State Route 48, which also includes the Virginia portion of the Blue Ridge Parkway,", "the Confederacy", "1955", "electron donors", "2", "Montreal Canadiens", "2008", "On 3 September,", "three", "minimum viable product that addresses and solves a problem or need that exists", "George Strait", "accepted into the Christian biblical canon", "In the 1920s", "ice giants", "on September 19, 1977", "camellia sinensis", "European economic community", "mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "complicated and deeply flawed", "Crandon, Wisconsin,", "butterflies", "Rocky Mountain spotted fever", "$500", "Afghan forces"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5602162034987213}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.35294117647058826, 0.75, 0.0, 0.0, 1.0, 0.11428571428571428, 0.0, 0.13793103448275862, 0.22222222222222224, 1.0, 0.7692307692307693, 1.0, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.0, 0.07692307692307691, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-7012", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-8393", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.4375, "CSR": 0.5338541666666667, "EFR": 1.0, "Overall": 0.7130208333333334}, {"timecode": 72, "before_eval_results": {"predictions": ["a TEFL course", "Afghanistan", "a sauce or hot liquid", "the suffrage movement", "Gamgee", "Las Vegas", "a gourmet jelly bean", "a sunburned", "Daniel Berrigan", "bounty", "Carole King", "Iberia", "the Pro-Jig Clamp Set", "Christo and his wife, Jean-Claude", "Wichita", "Agriculture", "Gilligan's Island", "Penelope", "(Tom) Harkin", "Dukedom of Normandy", "Krackel", "Penelope", "me", "Bonobos", "(3)", "Veep", "a butterfly", "lullaby", "a ruby", "Pan's Labyrinth", "Barrie", "John Irving", "a Demonstrative pronouns", "the Who", "Europe and Asia", "Fuji Xerox", "Souvlaki", "Pierre Trudeau", "earned run average", "anxiety", "Vietnam war", "Beijing", "Abraham Zapruder", "the Boy General", "(Isaac) Newton's Second Law", "the breath", "Stockholm", "Alaska", "a puff", "Mausolus of Caria in Asia Minor", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "moses", "Saint Cecilia the Patron Saint of Musicians", "Germany", "1989", "Suzuki YZF-R6", "the nose, cheeks, upper jaw and facial tissue from a female cadaver", "Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5434484649122807}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.4, 0.0, 0.9473684210526316, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1459", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5219", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-202", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-5140", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-15118", "mrqa_searchqa-validation-14147", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_triviaqa-validation-4653", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681"], "SR": 0.4375, "CSR": 0.5325342465753424, "EFR": 1.0, "Overall": 0.7127568493150684}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "Happy Days", "Rita Mae Brown", "Bolivia", "Kansas", "a grasshopper", "the commander", "Sure", "1876", "brood", "a spectator", "The Big Sleep", "Maryland", "Lowenbrau", "the pen", "Herod", "the Lone Ranger", "Malaysia", "Xavier High School", "Bruce Rauner", "Goofy", "Walter Payton", "Mount Everest", "Winston Rodney", "odes", "Teal", "the Tom Thumb", "Prince Edward Island", "the Mad Hatter", "tryptophan", "Cincinnati", "a bicep tear", "the concert grand", "ketchup", "peanut butter", "soccer", "Tom Petty and the Heartbreakers", "Tuscany", "Tunisia", "Rosa Parks", "an inch", "Paris", "William Henry Harrison", "Corinthian", "carats", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "tipping point", "scotland", "dogger Bank", "James Harden", "ethereal wave", "Ronald Lyle \" Ron\" Goldman", "\"Mad Men\"", "\"fusion teams,\"", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.75, "QA-F1": 0.8015625}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410"], "SR": 0.75, "CSR": 0.535472972972973, "EFR": 1.0, "Overall": 0.7133445945945945}, {"timecode": 74, "before_eval_results": {"predictions": ["a wholesale division", "The Tyger", "\"Thunder Road\"", "the Last Supper", "Baccarat", "a bishop", "Harlem", "(Jheronimus) Bosch", "a monohull", "a Drug Rehab & Treatment Center", "a cricket", "India", "Children of Men", "Skagway", "a written request", "Hippolyta", "a species", "John Galt", "spinach", "milk", "1,000 watts", "a toadstool", "World War I", "a student loan", "the Gateway Arch", "Kobi Malkin", "( Wolfgang) Puck", "a dachshund", "the Monitor", "Cyprus", "Milwaukee", "a milkshake", "Kevin Costner", "the \"Hot Lips\" Houlihan", "Isadora Duncan", "Pig Latin", "Little Debbie", "Rumsfeld", "Speed Racer", "USA", "Aristotle", "an emergency room", "the Eagles", "An American Tail", "a bus tour", "an argyle", "Honda", "a Wallaby", "a leather feather", "Mark Twain", "Greg", "30 October 1918", "Mel Tillis", "Michael Moriarty", "james christopher bolam", "all pieces capture opponent's pieces by moving to the square that the opponent's piece occupies.", "India", "House of Habsburg-Lorraine", "the highest commissioned SS rank", "Kansas\u2013Nebraska Act of 1854", "the Orbiting Carbon Observatory", "South Africa", "Tuesday", "two"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6369791666666667}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12847", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-11529", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-2238", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-16543", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3359", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.578125, "CSR": 0.5360416666666667, "EFR": 1.0, "Overall": 0.7134583333333333}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "state", "1908", "at specific locations, or origins of replication, in the genome", "Yuzuru Hanyu", "Michael Crawford", "to protect people and domesticated animals from its prickles", "Hold On", "Germany", "November 2016", "Empiricism", "Identification of alternative plans / policies", "17 - year - old Augustus Waters", "North America", "Johnson", "Song of Songs", "Taron Egerton", "its vast territory was divided into several successor polities", "abbreviation", "Sheev Palpatine", "Divyanka Tripathi", "September 24, 2012", "Lex Luger and Rick Rude", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the homicidal thoughts of a troubled youth", "songwriters Dan Bern and Mike Viola ( of the Candy Butchers", "Daniel A. Dailey", "Mickey Mantle", "the +, -, *, and / keys", "December 15, 2016", "Kid Creole and the Coconuts", "year 1", "2010", "a microfilament", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna", "1773", "Buddhism", "By functions", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "to London st Pancras", "t.S. Eliot", "Russell Humphreys", "Hickam Air Force Base", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "debt to recoup any of his principal", "\" Blackbird\"", "Meredith Grey", "September 25, 2017"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6114300903774588}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.10526315789473684, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7142857142857143, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4308", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-5781", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.53125, "CSR": 0.5359786184210527, "EFR": 1.0, "Overall": 0.7134457236842106}, {"timecode": 76, "before_eval_results": {"predictions": ["a dress to wear to the neighborhood dance", "Walter Mondale", "a system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1928", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "28", "Theodore Roosevelt", "23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "Mockingjay -- Part 1 ( 2014 )", "the President of India", "fingers on either side of the mouth ( usually with the knuckles facing the observer )", "28 %", "American singer Elvis Presley", "a Native American nation from the Great Plains whose historic territory, known as Comancheria", "Jack Scanlon", "the eighth episode of Arrow's second season", "Elijah Wood", "head - up", "Doug Pruzan", "by October 1986", "Donna Reed", "inside the cell nucleus", "pathology", "the age of about 14", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Bali, Indonesia", "Panzerkampfwagen VIII Maus ( `` Mouse '' )", "a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England", "40 %", "Janie Crawford", "to the south coast of eastern New Guinea, thereby including the Gulf of Papua", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "Montreal Bruins", "around 1872", "Idaho's Snake River Valley", "starch", "carbon", "on the first Monday in September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Phelan Beale", "one", "Government Accountability Office report", "journalists and aid workers", "a suit", "Heroes", "a papyri", "since 1983."], "metric_results": {"EM": 0.390625, "QA-F1": 0.5440943605006104}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.7692307692307692, 0.5714285714285715, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.08333333333333334, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.390625, "CSR": 0.5340909090909092, "EFR": 0.9743589743589743, "Overall": 0.7079399766899768}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes zoster", "zork", "roddy doyle", "phoebus", "Prussia", "rudyard Kipling", "Spongebob", "Exile", "an enclave is a country which is entirely enclosed by the territorial waters of another nation.", "South Dakota", "Brian Close", "a caterpillar", "l Leeds", "Edinburgh", "meter maid", "cricketer", "pholet", "Neptune", "Vimto", "phosmphobia- Fear of being touched.", "leicestershire", "carry On Cleo", "afro-Asiatic", "sense of taste", "a rudiment", "phogeography", "sesame", "hurdles", "The Centaurs", "tallest building", "American Football", "Charlie Chaplin", "kitty in Boots", "Giglio", "dukkibet", "\"Upper Haight\"", "Geoffrey Rush", "Harry patch", "comedy Folks", "Sight & Sound", "inigo Jones", "sonar", "nelson Mandela", "Today", "love", "Utah", "Mark Darcy", "reptilian", "landmasses", "salyut 1", "dutch", "Hannah Fairlight as Calamity, Serenity, Charity, and Veracity", "62", "Matthew Gregory Wise", "1861", "voice actress", "Limbo", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$4.5 million"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6192708333333334}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-3484", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.578125, "CSR": 0.5346554487179487, "EFR": 1.0, "Overall": 0.7131810897435897}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "affray", "1964", "\"I was walking back through the crowd it was the word on everyone's lips,\"", "\"momentous discovery\"", "Al-Aqsa mosque", "closed on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "Middle East and North Africa,", "Najaf", "Sen. Barack Obama", "Arnoldo Rueda Medina,", "changed the world of music downloads.", "ketamine.", "Brian David Mitchell,", "Defense of Marriage Act", "Jacob,", "Brazil forward Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "neural devices become more complicated, and go wireless,", "1957", "start a dialogue of peace", "al Qaeda,", "Manmohan Singh's", "find calmness in a prison culture fertile with violence and chaos.", "J. Crew", "\"My gut started feeling like something just wasn't right,\"", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III", "million dollars", "bribing", "people", "not feel Misty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "more than 125 million", "the return of a fallen U.S. service member", "modeling", "Val Avery", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "well", "China", "Capture of the Five Boroughs", "Double Crossed", "pornographicstar", "the burning bush", "oil", "Fannie Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6376984126984127}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-168", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-1390", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-15636"], "SR": 0.578125, "CSR": 0.5352056962025317, "EFR": 1.0, "Overall": 0.7132911392405064}, {"timecode": 79, "before_eval_results": {"predictions": ["Togus", "Ulysses S. Grant", "Yangtze River", "Genesis", "Queen Anne", "The New York Times", "Scotland", "Oklahoma", "the Communist Party of China", "the Nuclear Age", "Humphry Davy", "peninsula", "1/2 hours", "smallpox", "the Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet", "Mickey Mouse", "Xerox", "a blitz", "Jamaica", "gossip", "an exothermic reaction", "Charlie and the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "U.S. federal tax laws", "reborns", "Marvell", "a vegetable", "Bollywood", "\"Titanic\"", "\"take me out to the ball game\"", "parapet", "Joe Lieberman", "a diary", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal Virgins", "The Lord of the Rings", "Fidel Castro", "H CO ( equivalently OC ( OH ) )", "In order to fight the Saiyans invading Earth", "the United States Navy", "clara", "Douglas Trendle", "Ricky Gervais and Stephen Merchant", "RickyRubio", "edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "John Demjanjuk,", "2,579"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6822916666666667}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, true], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13653", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-4613", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-4966", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118"], "SR": 0.578125, "CSR": 0.5357421875, "EFR": 0.9629629629629629, "Overall": 0.7059910300925927}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "Tim Whelan", "Waimea Bay", "the Virgin label", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "mother goddess", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Norwood", "Strange Interlude", "2004", "Hall & Oates", "Best Supporting Actor", "The More", "England, Scotland, and Ireland", "the Workers' Party", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "his exploration and settlement of what is now Kentucky,", "six", "Mauthausen-Gusen", "Ryan McLaren", "Distillery", "Ted Nugent", "New York", "Viscount Cranborne", "The Frog Prince", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "Boulder High School", "Dutch", "November of that year", "Boston, Massachusetts", "Kaley Cuoco", "Brendan O'Brien", "Delphine Software International", "University of Kentucky College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate", "September 15, 2012", "Andy Murray", "Vienna", "Malaysia", "I, the chief executive officer,", "nuclear program.", "alternative-energy", "the78rpm", "syllables", "The King's Fools", "M&M's"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6535511363636364}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.19999999999999998, 0.5, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-5694", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1830", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-1809", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999"], "SR": 0.5625, "CSR": 0.5360725308641976, "EFR": 1.0, "Overall": 0.7134645061728395}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies", "Acid house", "Esteban Ocon", "Sophie Lara Winkleman", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "half", "Adam Karpel", "rock and roll", "1991", "Windermere, Cumbria (town)", "Sir Frank P. Lowy,", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "Jenson buttons", "Ambroise Thomas", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "The English Electric Canberra", "1 September 1864", "Smithsonian", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "Roman \u00e0 clef", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1938", "British Columbia, Canada", "1925 novel", "willow grade selection", "The Sand Trap", "Kim Clijsters", "Mombasa, Kenya,", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "basic", "Chief", "voltage", "Willa Cather"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5120869996549344}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2608695652173913, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-4081", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-3513", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_naturalquestions-validation-2624", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-388", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.40625, "CSR": 0.5344893292682926, "EFR": 1.0, "Overall": 0.7131478658536585}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "Emmy and four", "July 23, 1971", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2007", "Norwegian", "The Late Late Show", "Ry\u016bky\u016ban sailors in Qing-era Taiwan", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "(IATA: VNO, ICAO: EYVI)", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "\"The Worm\"", "Herman's Hermits", "Nikhil Banerjee", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Daniel Espinosa", "novel", "Gabriel Jesus Iglesias", "3,384,569", "Gambaga", "2 March 1972", "Shenandoah National Park", "La Scala, Milan", "every aspect of public and private life", "Gary Ross", "Washington", "leading money winner among women in WSOP history", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "born 2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "ringo", "1883", "off the coast of Dubai", "Sunday evening", "not doing more", "tutorial", "polio", "the treble", "bond hearing Friday,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7237847222222222}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4717", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-1559", "mrqa_hotpotqa-validation-3668", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732", "mrqa_searchqa-validation-5174", "mrqa_newsqa-validation-1245"], "SR": 0.640625, "CSR": 0.5357680722891567, "EFR": 1.0, "Overall": 0.7134036144578314}, {"timecode": 83, "before_eval_results": {"predictions": ["May 29, 1917", "Metacomet", "Chicago", "Leon Trotsky", "a loaf", "a atlas", "the New York Times", "(Thomas) Beekman", "Ugly Betty", "a Winnie-the-Pooh bear", "Agnese Bonucci", "Alexander Graham Bell", "Vijay Singh", "clouds", "a modem", "China", "the Boston Red Sox", "Jon Stewart", "Hitler", "Man", "Jane's Electro-Optic Systems", "Christo", "Ted Danson", "Ichiro Suzuki", "Frank Sinatra", "the Horn of Africa", "a banjo", "Grant", "Belle Watling", "Mozart", "American alternative rock band", "Nellie Bly", "Lord Byron", "meningitis", "Douglas MacArthur", "3M", "the Rolling Stones", "Edie Falco", "America", "Oneonta College", "1936", "the CN Tower", "the King of Siam", "inheritance", "Maryland", "the cardinal", "Japan", "a cow", "Prince Edward", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "cliff thorburn", "total population", "daedalus", "Conservatorio Verdi", "close range combat", "Paul Manafort", "1959.", "The son of Gabon's former president", "United States", "in mid November"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6187872023809524}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.8, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3392", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-4619", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-4122", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3923", "mrqa_naturalquestions-validation-8884"], "SR": 0.515625, "CSR": 0.5355282738095238, "EFR": 1.0, "Overall": 0.7133556547619048}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Blackbeard", "Jabez Stone", "Taft", "olive", "pemmican", "Olivia Newton-John", "Oahu", "Joseph Smith", "arthropoda", "Roosevelt", "Capricorn", "Diane Arbus", "a blue corn chile relleno", "Thomas Jefferson", "the legislature", "tofu", "Old School", "the DEW Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "the American Economic Association", "Robert Bruce", "zirconium", "oxygen", "Gargantua", "Elke Sommer", "a horn", "Robin Williams", "Philadelphia", "Ivory soap", "Giuseppe Garibaldi", "The Five People You Meet in Heaven", "the eel", "the S-Type R", "Thomas Jefferson Family Cemetery", "Gandhi", "Brazil", "Jim Thorpe", "Michael", "Dustin Hoffman", "King Lear", "the parachute jump", "the Bicentennial Symphony", "the Haunted Mansion Holiday", "Rembrandt", "Gilligan\\'s Island", "your woman", "the National Postal Museum", "Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "a horizontal desire", "charlie drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Asashoryu", "because of what they had done to Muslims in the past,\"", "former U.S. secretary of state.", "Newcastle Falcons"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6166666666666667}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.26666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-14016", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293"], "SR": 0.5625, "CSR": 0.5358455882352942, "EFR": 1.0, "Overall": 0.7134191176470589}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play's the thing\"", "The Ugly Duckling", "a panic", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Ponzi", "Earhart", "Tippi", "object-oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthe", "Libros", "marsupial", "quid", "Lincoln", "Anthony Newley", "swimmer\\'s ear", "Henry", "2.4", "Cyrillic", "Jeff Probst", "\"Grease\"", "Nasser", "The Moment of Truth", "Laura", "Lupus", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "FDR", "the Black Sea", "Katharine Hepburn", "pennies", "Young Frankenstein", "Shout", "to form a higher alkane", "inability to comprehend and formulate language", "Hellenic Polytheism", "venezuela", "The Shootist", "segas", "the National Society of Daughters of the American Revolution", "Leonard", "44,300", "it has not", "At least 88", "1981 drowning death,", "Markoff allegedly robbed a 29-year-old woman at gunpoint"], "metric_results": {"EM": 0.5625, "QA-F1": 0.621875}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-10463", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-16963", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-2819", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_naturalquestions-validation-3840", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.5625, "CSR": 0.536155523255814, "EFR": 1.0, "Overall": 0.7134811046511628}, {"timecode": 86, "before_eval_results": {"predictions": ["Anthony Caruso as Johnny Rivers", "at a given temperature", "season ten", "October 28, 2007", "seven", "repel bullets and fly at sub-sonic speeds", "at the city of Suez", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the First Epistle of John", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the base of the right ventricle", "beer", "U.S. Bank Stadium", "Destiny's Child", "statistical", "Earle Hyman", "Husrev Pasha", "Will", "The Osmonds", "735 feet ( 224 m )", "polymerizing the first few glucose molecules", "meat ( particularly beef and pork ), beans, peppers and spices", "September 8, 2017", "SURFACE AREA OF ROOTS", "Oklahoma", "Matt Flinders", "1 October 2006", "spiritual ideas, virtues and the essence of scriptures", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the biblical Book of Exodus", "cartilage", "SIP ( Session Initiation Protocol )", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "in the eye", "Donna Mills", "Donna", "annette Crosbie", "bobby Kennedy", "Minder", "leopard", "Tim Burton", "University Grants Commission", "Symbionese Liberation Army", "102", "two", "\"Like a Rock\"", "a cat", "George III of Britain", "Norwegian"], "metric_results": {"EM": 0.5, "QA-F1": 0.61224567647265}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, false], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 1.0, 0.1, 0.30769230769230765, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7142857142857143, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-5113", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-3582", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-366", "mrqa_searchqa-validation-4175"], "SR": 0.5, "CSR": 0.5357399425287357, "EFR": 0.9375, "Overall": 0.7008979885057471}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "\"Deutsch-Franz\u00f6sischer Krieg\"", "Hirsch index rating", "Cody Miller", "1951", "Teen Titans Go!", "The Ramna Stacks", "Book of Judges", "new, small and fast vessels such as torpedo boats and later submarines", "9 February 1971", "San Francisco, California", "\"Three's Company\"", "9,984", "Diondre Cole", "Marktown, Clayton Mark's planned worker community in Northwest Indiana", "The Rose Theatre", "over 1 million acre", "Trey Parker and Matt Stone", "the Teatro Carlo Felice", "Fidenza", "237 square miles", "timeline of Shakespeare criticism", "balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden,", "Noel", "Michael Rispoli", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "The Austro-Hungarian Army", "St. George, Maine", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "his son Louis", "Vancouver", "Urijah Faber", "four", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "Franklin Roosevelt", "the 1920s", "on - and off - premises sales in one form or another on Sundays at some restricted time", "james hargreaves", "puff", "english", "Samoa", "flooding", "composer", "extravagant", "Bath", "Atlanta", "a greeting which is used by some on birthdays, and by others in response to `` Merry Christmas '' and `` Happy New Year ''"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6487441378066379}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.5, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.22222222222222224, 0.5, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12121212121212123]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-3147", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_naturalquestions-validation-9361"], "SR": 0.53125, "CSR": 0.5356889204545454, "EFR": 1.0, "Overall": 0.7133877840909091}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as", "Ameneh Bahrami", "40", "state senators", "2005", "by text messaging", "Hawaii.", "Haiti", "Brazil's", "she learnt from growing up in a communist country and how she keeps smiling", "\"Common Access Cards,\"", "James Whitehouse,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "\"inappropriate,\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "Carnival", "Jason Chaffetz", "2007,", "in the southern port city of Karachi,", "hired translators to eavesdrop on a series of conversations in Arabic, Russian and Mandarin", "that anything could have stopped Robert Hawkins from going on a murderous rampage at an Omaha, Nebraska, shopping mall", "Ricardo Valles de la Rosa,", "Islamabad", "Toffelmakaren.", "Wednesday", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra clan", "Nigeria", "201-262-2800", "South Africa", "very dark and very cold place.", "France", "President Obama", "late Tuesday", "to reach car owners who haven't complied fully with recalls.", "Mashhad", "Plymouth Rock", "Alina Cho", "Roger Federer", "last week", "a cardio and for that not to be wasted,\"", "Tukel", "10", "This will be the second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "axe", "portugal", "June 17, 2007", "England", "Black Elk", "hollandaise", "Kwanzaa", "\"Sorry, boss,\"", "leopard"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6423592032967034}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.09090909090909093, 0.0, 0.5, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.4, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-446", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-2641", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-2642", "mrqa_triviaqa-validation-6987", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749", "mrqa_hotpotqa-validation-855"], "SR": 0.53125, "CSR": 0.5356390449438202, "EFR": 0.9666666666666667, "Overall": 0.7067111423220973}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "Shemsu Sirgaga", "killing rampage.", "Eintracht Frankfurt", "they did not receive a fair trial.", "federal officers' bodies", "Bill Haas", "Larry Ellison", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "rising disposable income and an increasing interest in leisure pursuits, a growing number of courses, more television coverage and availability of EU funds,", "Piers Morgan,", "endorsed Romney in his bid for the Republican presidential nomination", "Phoenix, Arizona,", "KBR", "Copts", "Jeanne Tripplehorn", "two years", "the body of the aircraft", "North Korea", "chairman of the House Budget Committee", "pattern matching.", "\" Teen Patti\"", "almost 9 million", "U.S. senators", "public opinion in Turkey", "Buenos Aires", "she returned to Pakistan", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "bank", "two", "illegal immigrants", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States if provoked.", "Sunday,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris", "Alicia Keys", "ALS6,", "The EU naval force", "well over 1,000 pounds", "Iran's Green Movement of protesters", "help make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "new GI Bill", "Lindsey Vonn", "three levels", "postero - medially towards the optic chiasm", "Hugo Weaving", "aragonite", "Lester", "Olympia", "Bruce R. Cook", "Los Angeles, California", "86,112", "the Tweedledee", "a soap opera", "the CPI", "charles wllgwyngyll"], "metric_results": {"EM": 0.5, "QA-F1": 0.5972330229134665}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.19354838709677416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8571428571428571, 1.0, 0.2222222222222222, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-1586", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_hotpotqa-validation-2460", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.5, "CSR": 0.5352430555555556, "EFR": 1.0, "Overall": 0.7132986111111111}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon General", "Ebony", "Cook County", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "a shrewish woman", "lacrosse", "Naples", "a Dormouse", "the Galatians", "a cow pie", "The Paradise Lost", "beautiful", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "Oregon", "Earthquakes", "Lyric Wikia", "Best Supporting Actor", "The Bionic Woman", "the 5000", "a tan", "Narnia", "the comet Tempel 1", "Mount Sinai", "Kamehameha", "(Elbert) Gary", "an epitaph", "crowded", "\"Duke\"", "Orlans", "The Wall", "Pulp Fiction", "Hester Prynne", "pajamas", "Dynasty Class", "a bagpipe", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "the Philippines", "Sydney", "the Hudson Bay", "When the angel Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "The long - hair gene is recessive", "makaron nesoi", "Another Day in Paradise", "Danegeld", "Donald Wayne Johnson", "Robert Allen Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "The North could delay the launch if they experience problems with the weather, or within the leadership,", "financial gain,"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7496744791666667}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8125000000000001, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.13333333333333336, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-7563", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-4827", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_triviaqa-validation-1702", "mrqa_triviaqa-validation-1688", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.6875, "CSR": 0.5369162087912087, "EFR": 1.0, "Overall": 0.7136332417582418}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff, Wales", "keirin", "Light Middleweight", "christopher nolan", "Johann", "highball", "arthur conan doyle", "lady Godiva", "brain", "six", "Bashir", "dog sport", "\"the Double\"", "aluminium", "omega", "mickey mouse", "can be 108 or 126 gallons", "the Welcome Stranger", "the recorder", "Oman", "Genesis", "Ladysmith", "californium", "robert germany", "the Arizona Diamondbacks", "george Orwell", "Goldie Myerson", "Marc Brunel", "pasta", "William Shakespeare", "1960's", "Some Like It Hot", "Beaujolais", "injecting a 7 percent solution intravenously three times a day", "gingerbread", "Sarajevo", "Henry I", "st. Thomas \u00e0 Becket", "bullfighting", "leicestershire", "cycling", "Crimean Tatar", "bedding", "Switzerland", "yichang City", "duke", "Founder's Day", "the Swordfish", "France", "australian continent", "france", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1898", "early January 1923", "Colombo South Asian Games", "Rana Daggubati", "four", "1,500", "13-year-old boy", "38 feet", "the Marquis de Lafayette", "turquoise", "the Birds of America", "2010"], "metric_results": {"EM": 0.5, "QA-F1": 0.6309895833333332}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.8, 0.75, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-5466", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-3037", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-4071", "mrqa_hotpotqa-validation-369", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134", "mrqa_searchqa-validation-836"], "SR": 0.5, "CSR": 0.5365149456521738, "EFR": 0.9375, "Overall": 0.7010529891304348}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "1979\u20132013", "two", "2001", "Meghan Markle", "2006", "alcoholic drinks", "Seoul, South Korea", "Dutch", "41st President of the United States", "political correctness", "Russell Humphreys", "Wisconsin and the Upper Peninsula of Michigan", "November 23, 2011", "over 3 million", "Mazda", "Jack St. Clair Kilby", "\"Seducing Mr. Perfect\"", "water", "more than 70", "Black pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "The Emperor of Japan", "\"Apatosaurus\"", "TD Garden", "because of their cover of David Bowie's 1979 song \"Boys Keep Swinging\"", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"bamboo man\"", "2010", "Kent, Washington", "Prudence Jane Goward", "Vincent Anthony Guaraldi", "\"What's My Line?", "Kim So-hyun", "seasonal television specials", "Carol Ann Duffy", "Lauren Lane", "Charles II", "17 October 2006", "Kansas Joe McCoy", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman", "Canada", "defense against rain rather than sun", "the eurozone", "Jane Seymour", "Willie nelson", "1984", "Argentine", "15", "Ali Bongo", "Antietam", "your insurance", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6792849511599512}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-2770", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_hotpotqa-validation-294", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.546875, "CSR": 0.5366263440860215, "EFR": 1.0, "Overall": 0.7135752688172043}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "stand-up comedian", "Edward R. Murrow", "Liesl", "KB Toys Inc.", "Training Day", "1998", "World Famous Gold & Silver Pawn Shop in Las Vegas", "1972", "Argentina", "the Crab Orchard Mountains", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the Provisional Irish Republican Army", "Tel Aviv", "Chevy", "the tissues of the outer third of the vagina", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "Yolande Cornelia \" Nikki\" Giovanni, Jr.", "Love Letter", "2013", "Half Hollow Hills Central School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Fordyce", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow Airport (also known as London Heathrow) (IATA: LHR, ICAO: EGLL)", "George Martin", "Timo Hildebrand", "Adam Dawes", "Maasai phrase \"Enkare Nairobi\"", "Rockland", "2009", "Vietnam War", "Toto", "9 February 2018", "Todd Griffin", "martin spacey", "funchal", "British", "Champions League final", "it would", "a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Africa", "Agriculture"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6798231282606282}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.2857142857142857, 0.0, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-5586", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-4194", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_searchqa-validation-16694", "mrqa_searchqa-validation-15207"], "SR": 0.578125, "CSR": 0.5370678191489362, "EFR": 1.0, "Overall": 0.7136635638297872}, {"timecode": 94, "before_eval_results": {"predictions": ["\"If a man does not keep pace with his companions, perhaps it is because he hears a different drummer\"", "Hitler", "Mrs. Miniver", "Simon Cowell", "The Eagles", "a neon sign", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "The Diary of a Young Girl", "Tahiti", "My Name Is Earl", "Nassau", "a geisha", "France", "the Barbary corsairs", "the CIA", "yeast", "the BlackBerry", "the Temptations", "phonetics", "Crosby", "Frasier", "the sun", "a cannon", "the Court of Cassation", "Yucatan", "\"Jeopardy\"", "Afghanistan", "Australia", "a buffalo", "Seoul", "The Mortimer D. Sackler", "pitch", "Pete Rose", "Esther", "South Africa", "Bacall", "Goldeneye", "agriculture", "Dumbo", "Edith Wharton", "Aretha Franklin", "marsupials", "Spanish", "The Crow", "Lou Gehrig", "The Magnificent Ambersons", "a mongoose", "Captain Jack Aubrey", "Ecuador", "Koine Greek", "four", "elected or appointed by means of a commission", "Friends", "frankincense", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "the Runaways", "Pieter van Musschenbroek", "Seoul", "\" Fortunately, I've been feeling better every single day since surgery and this weekend my doctors gave me the green light to get back to work.\"", "Superman brought down the Ku Klux Klan,", "Krankies"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6303819444444445}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.1111111111111111, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-13172", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_searchqa-validation-1165", "mrqa_searchqa-validation-1101", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.578125, "CSR": 0.5375, "EFR": 1.0, "Overall": 0.71375}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "Ninette de Valois", "Dag Hammarskjld", "Latin", "King Henry VIII", "San Francisco", "\"The Secrets of a Fire King\"", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "the Dow Jones industrial average", "Aunt Jemima", "the fowls", "dynasties", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "middle-aged", "B.B. King", "Kennedy", "Donovan", "plankton", "Candlestick Park", "a jointer plane", "compensation", "vodka", "pastrami", "Adam", "heresy", "Ivy Dickens", "woozy", "thunder", "Ham", "calamine", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norma's brother", "1957", "Jurchen Aisin Gioro clan", "france ce que tu voudras", "little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "at the exit in question,\"", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7101934523809523}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-1558", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.640625, "CSR": 0.53857421875, "EFR": 0.9130434782608695, "Overall": 0.6965735394021739}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "\"Ozymandias\" poet", "Unbreakable", "Holy Week", "Tijuana", "the Codex Alera", "a kilobytes", "Planned Parenthood", "Jamie Lee Curtis", "Ellen DeGeneres", "an Abduction", "Alexander Graham Bell", "the North-East Frontier Tracts", "a baffle", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "a giant slalom", "Medusa", "zoology", "Lucia di Lammermoor", "a globes", "cricket", "Stephen Hawking", "St. Francis of Assisi", "light", "The Scarlet Letter", "2016", "a rehab facility", "pastries", "the Hundred Years' War", "the Met", "milk and honey", "3", "the lung", "The Beatles", "The Bronx", "a saccharide", "King Kong", "Cubism", "Umbria", "ken Burns", "M. C. Escher", "Oahu", "urine", "Scott Fitzgerald", "aria", "a Ghostbusters II", "Marquette University", "the monk", "Fall 1998", "infection", "Bart Howard", "france", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.625, "QA-F1": 0.7109375}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-3482", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16364", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-7573", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_triviaqa-validation-3952", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.625, "CSR": 0.539465206185567, "EFR": 1.0, "Overall": 0.7141430412371135}, {"timecode": 97, "before_eval_results": {"predictions": ["3", "three gold rings", "Gaston Leroux", "Concorde", "gold", "eec", "great Britain", "vietnam", "florens", "Wanderers", "emilia fox", "Amnesty International", "krak\u00f3w", "the Shaft", "a gal", "Ramadan", "Girard", "count Basie Orchestra", "Pegida", "plutonium", "sheree Murphy", "edward hopper", "Einstein", "faversham", "Justin Trudeau", "kevin kline", "time team", "Thom Yorke", "crawford & Hammerstein", "UNESCO", "brazil", "Christian wulff", "milk", "usk", "spider", "prime minister of australia", "Daily Herald", "nairobi", "netherlands", "bone", "the coronary sinus", "a \"puck\"", "Hula-Hoops", "dubonnet", "Lady Susan", "Ben Quick", "cashmere", "Today newspaper", "world news", "Gene Vincent", "sterngard", "a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus", "The Chesapeake", "Ben Faulks", "an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "the flotilla", "Art of Dying", "2nd Lt. John Auer,", "Apple's iconic music-players line", "Christopher Savoie", "Zeus", "an elegant girl", "WWI", "Joseph"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5732456140350877}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.6666666666666666, 1.0, 0.4210526315789474, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-2947", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4376", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-3391", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5210", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-2039", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-2098", "mrqa_hotpotqa-validation-1861", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947", "mrqa_searchqa-validation-6024", "mrqa_searchqa-validation-1427"], "SR": 0.53125, "CSR": 0.5393813775510203, "EFR": 0.9666666666666667, "Overall": 0.7074596088435374}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "edward", "Jerry Mouse", "cirrus uncinus", "procol harum", "alberta", "belfast", "st. Ives", "Uganda", "st pancras", "lactic acid", "Valais, Switzerland", "Robinson Crusoe", "once a week", "my Favorite Martian", "whist", "fear of snakes", "Madagascar", "Wyatt", "julia", "one Direction", "The West Wing", "Prince Harry", "1994", "titanium", "The Sausage Shop", "Pegasus", "alaskan", "Twain", "brazil", "horseradish", "rawhide", "eyes", "Ukrainian", "bowie knife", "Nile", "a rat", "Independence Day", "Tinie Tempah", "portugal", "Greek", "collapsible support assembly", "beard", "the Angel in the House", "oldham, in Greater Manchester, England", "Sunday Post", "bobby darin", "emirate", "jimmy armstrong", "mansfield park", "South Africa", "Ian Harrowell", "drivers", "Florida", "twenty-three", "Mexican War on Drugs", "her relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi and Hutu rivalry", "The Tempest", "Capri", "David", "heavier than a feather"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5589533730158729}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.4, 1.0, 0.4444444444444445, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_searchqa-validation-12012", "mrqa_searchqa-validation-6488", "mrqa_hotpotqa-validation-3713"], "SR": 0.46875, "CSR": 0.5386679292929293, "EFR": 0.9705882352941176, "Overall": 0.7081012329174093}, {"timecode": 99, "UKR": 0.767578125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.8515625, "KG": 0.51796875, "before_eval_results": {"predictions": ["\"The people kill him with the blocks,", "37", "dismissed all charges", "U.S. Defense Department", "11", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her;", "Red Lines", "The Kirchners", "an African-American woman", "Arsene Wenger", "Arnold Drummond", "in the Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "his business dealings", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "Alejandro Peralta Alvarez", "Kerstin Fritzl,", "Amnesty International", "The Tinkler.", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "overthrow the socialist government of Salvador Allende in Chile,", "lump in Henry's nether regions", "late Thursday to form a government of national reconciliation.", "snow,", "steamboat", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "students at the school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "three thousand", "burning of a church.", "The cause of the child's death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "about 2,000", "park bench", "Cirque du Soleil", "9", "for the rest of the year", "hydrogen", "Kevin Spacey", "foreign investors", "the back of the neck", "wrigley", "CBS", "round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "Arthur Miller", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6699261675824175}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.888888888888889, 1.0, 0.5, 0.25, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-4326", "mrqa_triviaqa-validation-7478", "mrqa_hotpotqa-validation-2793", "mrqa_searchqa-validation-6438"], "SR": 0.59375, "CSR": 0.5392187500000001, "EFR": 1.0, "Overall": 0.735265625}]}