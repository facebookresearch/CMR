{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4180, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "The Book of Discipline", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "teachers in publicly funded schools", "Stanford University Professor of Comparative Literature Richard Rorty", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8206106635237826}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "Smith and Jones", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "The Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "immediately north of Canaveral at Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay in Alaska", "120 m ( 390 ft ) at its widest part", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "26 January was chosen as the Republic day because it was on this day in 1930", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "the Atlantic Ocean, the Gulf of Mexico and the Straits of Florida"], "metric_results": {"EM": 0.671875, "QA-F1": 0.774016911907537}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.6153846153846154, 0.4444444444444445, 1.0, 0.4, 1.0, 0.4090909090909091, 1.0, 0.0, 0.5, 0.5, 0.16666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-3840", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.9047619047619048, "Overall": 0.8195684523809523}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "494,665", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "Yam route systems", "Stairs", "transplastomic", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "December 1971", "lord of the rings", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7833333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.5, 0.0, 0.28571428571428575, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.71875, "CSR": 0.73046875, "EFR": 0.9444444444444444, "Overall": 0.8374565972222222}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Coldplay", "the Yuan dynasty", "same-gender marriages", "red algae red", "after their second year", "1960s", "narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "sponges, both ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "remaining in jail, or by evading it", "the kettle and the Cricket", "Manilal", "Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "The first US-market Betamax video recorder, the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "Earth's orbital period is 365 & this fraction of a day", "The Story of Tiger Woods' 1996 U.S. Amateur Win", "the University of Arizona", "Marshal Dillon", "The Bosporus Bridge links", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "Light Amplification by Stimulated Emission by radiation", "Jean Dapra", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "The Phobia List", "American", "The Mexican military"], "metric_results": {"EM": 0.5, "QA-F1": 0.6123807905057905}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14814814814814814, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 0.7499999999999999, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.2666666666666667, 0.19999999999999998, 0.3076923076923077, 0.0, 0.4, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.25, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-4424", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.5, "CSR": 0.684375, "EFR": 0.875, "Overall": 0.7796875}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "The Jewish Star", "League of the Three Emperors", "the field of science", "143,007", "Bill Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawn the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Joel Chandler Harris", "corruption", "How long", "Dover Beach"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7971926510989011}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-6218", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.734375, "CSR": 0.6927083333333333, "EFR": 0.7647058823529411, "Overall": 0.7287071078431372}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "A vote clerk", "high growth rates", "destructive", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools", "the means to invest in new sources of creating wealth", "Spanish", "Structural geologists", "president and CEO", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac", "Rabat", "between 11 or 13 and 18", "Heather Elizabeth Langenkamp", "Henry Moseley", "paracyclist", "IATA: VNO, ICAO: EYVI", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "English former international footballer", "Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "romantic", "the Eastern part", "Polar Bear", "Atlantic City"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8167410714285714}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.5, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971"], "SR": 0.71875, "CSR": 0.6964285714285714, "EFR": 0.8888888888888888, "Overall": 0.7926587301587301}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "output", "already-wealthy individuals or entities", "center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "entire length", "computer programs", "General Conference", "1996", "dreams", "The Judiciary", "deterministic", "Bart Starr", "allotrope", "Karluk Kara-Khanid", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "the country's second largest city by population", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "Atat\u00fcrk Museum Mansion", "Bothtec", "Cody Miller", "219", "John Locke", "Christophe Lourdelet", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "PeopleMover", "8 December 1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Honey Nut Chex Gluten Free Cereal 12.5 oz. Box", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7140625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-7547", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-3413", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.6875, "CSR": 0.6953125, "EFR": 0.9, "Overall": 0.79765625}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "higher efficiency", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Ulli Lommel", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Adam Amin", "boxer", "Boston University", "Fulham", "A55", "Ranulf de Gernon, 4th Earl of Chester", "\u00c6thelstan", "Madras Export Processing Zone", "44", "Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Shirley Horn", "Israel", "Bigfoot", "Papua New Guinea", "Renoir\u00b4s", "Manchester"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7129734848484848}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.8, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_squad-validation-5972", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-524", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170", "mrqa_newsqa-validation-1268", "mrqa_triviaqa-validation-1423"], "SR": 0.640625, "CSR": 0.6892361111111112, "EFR": 0.9130434782608695, "Overall": 0.8011397946859904}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "unpaired electrons", "French", "Museum of the Moving Image in London", "sent missionaries", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "transgender teenage girl", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "Afroasiatic", "James Tinling", "Italy", "the 79th Masters Tournament", "Kristoffer Rygg", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscousCouscous", "22 million", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993 film)", "freshwater airbreathing"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6609139605255592}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.59375, "CSR": 0.6796875, "EFR": 0.6923076923076923, "Overall": 0.6859975961538461}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "rose to higher political office", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks in series 1", "to attend school at the Higher Real Gymnasium", "a Standard Model", "Tolui", "Rhine-Ruhr region", "a course of study", "Prevenient grace", "Kansas State", "the Queensland Heritage Register", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "World Health Organization", "Emmanuel Ofosu Yeboah", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "what", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "the Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "Dustbin"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7253484645199761}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-797", "mrqa_squad-validation-6927", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644"], "SR": 0.640625, "CSR": 0.6761363636363636, "EFR": 0.8695652173913043, "Overall": 0.772850790513834}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "Spanish", "100\u2013150", "Philo of Byzantium", "The climate is cooler in the savannah grasslands around the capital city, Nairobi, and especially closer to Mount Kenya", "in marine waters worldwide", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "It's helping consumers move beyond these hard times and has reignited a whole industry", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "does not involve MDC head Morgan Tsvangirai", "lack of a cause of death", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally", "opposition party members", "Missouri", "\"Racism and racist conversations have no place today in America.\"", "executive director of the Americas Division of Human Rights Watch", "Dominican Republic", "90", "KARK", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice Act", "Bush administration", "more than 200", "This is not a project for commercial gain. It is done with the parents' full consent", "best-of-three series", "Kaka", "Japanese ex-wife", "Dan Parris, 25, and Rob Lehr, 26", "apartment near Fort Bragg in North Carolina", "two", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000 unprotected civilians", "The singer's personal security guard, Andrew Morris", "Ark of the Covenant", "Jean F Kernel", "Thomas Hardy\u2019s novel", "Richmond", "1994", "The Conjuring", "The Gallipoli Campaign, also known as the Dardanelles Campaign", "The second-largest Great Lake, Lake Huron, has a surface area of 23,000 square miles", "Nowhere Boy"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6261357935145835}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 0.8571428571428571, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.38095238095238093, 0.0, 1.0, 0.0, 0.4444444444444445, 0.8333333333333333, 1.0, 0.2608695652173913, 1.0, 1.0, 0.2857142857142857, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8397", "mrqa_squad-validation-4524", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.515625, "CSR": 0.6627604166666667, "EFR": 0.6774193548387096, "Overall": 0.6700898857526882}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British", "wealth", "every good work designed to attract God's favor", "Napoleon", "mass production", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "587,000 square kilometres", "Private Bill Committees", "Bruno Mars", "the Catechism", "Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "\"Minnie\" Schoenberg", "Salvador Allende", "Marie Antoinette", "Redmond, United States", "Erik Thorvaldson", "Marsyas", "Pal Joey", "Mary Jane Grant", "green", "\"French Polynesia", "the supreme religious leader of all the subordinate priests", "Antonio", "European Economic Community (EEC)", "Christine Keeler", "Jesus", "Jack Nicholson Easy Rider", "four", "Netherlands", "\"Sugar Baby Love\"", "Rosa Parks Bus", "former lads\u2019 magazine pin-up", "Bill and Taffy Danoff", "the one-celled zygote", "Travis", "The Show", "Robert Kennedy", "Q", "lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "an author and philosopher", "barber", "Evonne Goolagong Cawley", "Murrah Federal Office Building", "Evita", "an old, unsavoury, and oily black clay pipe", "fortified complex", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "\"It is very easy for comments to be taken out of context and create unnecessary drama", "a delegation of American Muslim and Christian leaders", "Royal Wives", "the Greek Village", "Juan Martin Del Potro"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5970331101190476}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0625, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6696", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929"], "SR": 0.515625, "CSR": 0.6514423076923077, "EFR": 0.6129032258064516, "Overall": 0.6321727667493797}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "in order to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "dernell DUNKELD", "moles", "Democritus", "the Chagos Archipelago", "Anne Boleyn", "Ronald Reagan", "Steve McQueen", "Portugal", "piano", "one", "komando Pasukan Khusus", "the northwest of England", "liquid", "Chillicothe and Zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "one or both eyes don't form during pregnancy", "t.S. Eliot", "the River Forth", "woe", "NOW Magazine", "aligula Roman emperor Caligula", "Italy", "Canada", "typhoid fever", "alto mio> with Pavarotti", "Action Man", "al Bundy", "2010", "volume of a given mass of a gas increases or decreases by the same factor as its temperature (in kelvins)", "Venezuela", "stooge, or deadwood", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Regulus", "Chris Weidman", "Drillers Stadium", "one", "Virgin America", "John Grisham", "the World Bank", "Iran's parliament speaker", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5977430555555556}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.4, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.546875, "CSR": 0.6439732142857143, "EFR": 0.6896551724137931, "Overall": 0.6668141933497538}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow", "public official", "the most cost efficient bidder", "acorn", "Continent that spans 11 time zones", "tibia", "Olympia", "Ukrainian Soviet Socialist Republic", "shrew", "Clark Kent", "a hopeful miner, one of the many that rushed to the Yukon when gold was discovered there in", "amber", "high school football coach", "The executioner's Song", "oval", "bishkek Tajikistan", "anamosa", "Russell Lynes", "The Comedy of Errors", "asylum", "film", "knife", "glinding light", "Cologne", "Leadership Academy for Girls", "arch", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "cowboys", "a citizen, first in war, First in peace, and first in the hearts of his countrymen", "shrew", "Japan", "\"A Beer Can Named Desire\"", "Thant", "boys", "windjammer", "bona Living in the Shadows: A Biography of Oona O'Neill Chaplin", "stanoma State University", "Augusta", "counter clockwise", "2013", "Nick Hornby", "Coldplay", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "memories of his mother", "Israel"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4809659090909091}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1818181818181818, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.421875, "CSR": 0.6291666666666667, "EFR": 0.7837837837837838, "Overall": 0.7064752252252252}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "a violinist", "Jerry Maguire", "Strongsville, Ohio", "flemish", "Mastercard", "Henry Ford (36)", "Nashville", "cranial nerve (Olfactory nerve)", "Ivan the IV", "Nancy Astor", "Liver spot", "a gang of ex-cons rob a casino", "Toronto Maple Maple", "Zsa Zsa Gabor", "konstantin Stanislavski", "Utah", "liquor made from molasses or sugar cane", "Harry Angstrom", "Johann Strauss II", "joey", "pro bono", "Atena", "The Fun Factory", "ale", "Anthony Fokker", "Nacho Libre", "copper", "devils or demons", "carrots", "Jeffrey Wigand", "poetry", "a sesame seed bun", "meager", "Casablanca", "blimps", "Gustav Kirchhoff", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "a \"noir novel\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.515625, "QA-F1": 0.621875}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.5, 0.5, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.515625, "CSR": 0.6220703125, "EFR": 0.9354838709677419, "Overall": 0.778777091733871}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser River", "in an open casket", "Nguyen That Thanh", "circumference", "the Inuit", "Detroit Rock City", "Toronto Blue Jays", "President Lincoln", "Ray Bradbury", "crimes committed out of hatred for someone's race", "King Julien XIII", "Pl Srkzy de Nagy-Bcsa", "Rubicon River", "Sanjaya", "17.5 million", "Louisa May Alcott", "Modeling Compound", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary D. Rodham Clinton", "King Philip's", "Bellerophon", "Balaam", "the Wharton School of the University of Pennsylvania", "the caine mutiny", "the Allman Brothers Band", "the Clorox Company", "(John) Coltrane", "the peace sign", "oxygen", "the Sphinx", "John Huss", "USA Network's (The Sing-Off)", "Mavericks", "Onegin", "Macy's Department Store", "a hand-powered multiple spinning machine", "A1A 1A1", "Dennis Haysbert", "negligence", "the courts", "attached to another chromosome", "Broughton", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "prisoners", "his entire personal fortune", "punishment"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5537831959706959}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.5, 1.0, 0.2, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.5, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.3333333333333333, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-9172", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-8100", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-9150", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-1759"], "SR": 0.421875, "CSR": 0.6102941176470589, "EFR": 0.6216216216216216, "Overall": 0.6159578696343402}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Benjamin Vail", "telephone ring", "Party of National Unity", "22", "duke", "Phillip Marlowe", "piracy", "A.J. Burnett", "Kei", "Puerto Rico", "The Mausoleum", "Million Dollar Baby", "Switzerland", "Deutsche Lufthansa", "The Old Man and the Sea", "French", "Joe Louis", "lion", "d'Artagnan", "the Bayeux Tapestry", "a small front porch", "China", "Shia", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "quilt", "FRAM", "the House of Representatives", "Labatt", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "London", "Yellowstone National Park", "Ronald Reagan", "would have been so terrible if I had a small fortune", "Ethiopian", "six", "1992", "pH", "Bromley-By- Bow", "the Kree", "Cartoon Network", "Caylee Anthony", "know what is important in life", "\"face of the peace initiative has been attacked", "nuclear", "The Stooges"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6302083333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-6418", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-2709", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-9270", "mrqa_searchqa-validation-12814", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-3692", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-4110"], "SR": 0.59375, "CSR": 0.609375, "EFR": 0.7692307692307693, "Overall": 0.6893028846153846}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXXIII", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity measures", "same-gender marriages", "2006", "the mid-18th century", "aioli", "A Raisin in the Sun", "Sistine Chapel", "bielaruski", "a halfback", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "the Cliffs of Dover", "Genoa", "Fanchette", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "George Field Bros", "the Hampton Inn", "21", "John Janetzko", "Copeina arnoldi", "Paul McCartney", "omega-3", "paoletas", "Bachman Turner Overdrive", "FEARnet on Demand", "Caddy Shack", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "the Bear family", "a small earthquake", "arrest him", "elephants", "mazurka", "Sweden", "a covert operation", "Our Country", "May 2010", "the International Space Station", "Sugarloaf Mountain", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5863685344827586}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.8275862068965517]}}, "before_error_ids": ["mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.46875, "CSR": 0.6019736842105263, "EFR": 0.7352941176470589, "Overall": 0.6686339009287926}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "transplastomic", "Earth", "53,000", "one", "poet", "two", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "Arousal regulation", "Charlene Holt", "Ted '' Levine", "1991", "electron shells", "The Cornett family", "acid rain", "April 15, 2018", "inefficient", "he cheated", "2001", "flawed democracy", "400 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Necator americanus and Ancy lostoma duodenale", "February 28", "Furious 7", "the American Civil War", "an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "Hermia", "Jupiter", "east", "15", "John Robert Cocker", "Israel", "a simple puzzle video game", "a palace", "the olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.546875, "QA-F1": 0.626953125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.625, 1.0, 0.2, 0.8, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_triviaqa-validation-2227"], "SR": 0.546875, "CSR": 0.59921875, "EFR": 0.896551724137931, "Overall": 0.7478852370689655}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "choosing their own ministers", "1886", "Blue Harvest", "Jacob Zuma", "gang rape", "illegal crossings", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "well over 1,000 pounds", "Egyptian dead-end", "Mutassim", "Oklahoma", "Polo", "Joe Jackson", "in Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus shifts", "Brad Blauser", "September", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "behind the counter", "chief executive officer", "\"There's no chance of it being open on time. Work has basically stopped\"", "file papers shortly with an appeals court seeking an emergency stay", "non-European Union player in Frank Rijkaard's squad.Mexican forward Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "orphans", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter", "Whitsunday", "the Dee", "Dumb and Dumber", "Nokia Sugar Bowl", "Minton", "converging", "autu", "season five", "Revenge of the Sith"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6147367042679543}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 0.4, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.18181818181818182, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.2666666666666667, 0.72, 0.2, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.3333333333333333, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-7937", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-3226", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.46875, "CSR": 0.5930059523809523, "EFR": 0.7058823529411765, "Overall": 0.6494441526610644}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress", "Combined Statistical Area", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "the Kenyan forces crossing of the joint border as \"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "Wednesday", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday", "Kim Clijsters", "Mashhad", "Amanda Knox's aunt", "jazz", "$17,000", "\"Doogie Howser, M.D.\"", "Luiz Inacio Lula da Silva", "his father's parenting skills", "two", "Bill", "J.G. Ballard", "Dr. Conrad Murray", "Sarah Brown", "jumped full time into his company, Ripken Baseball, without taking any break, lessening the emotional jolt of retirement.", "1981", "17 Again", "Nigeria", "83,27014", "Republican", "EU naval force", "Chris Robinson", "Ali Bongo", "steamboat", "Hyundai Steel", "a bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5", "canceled the swimming privileges", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2008)", "Northumbrian", "\"Get Thee To A Nunnery\"", "a helicopter", "Argentinian", "Mercedes-Benz Superdome", "Otto Eduard Leopold"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5827457698551448}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.125, 0.5454545454545454, 0.0, 0.0, 0.9, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602"], "SR": 0.46875, "CSR": 0.5873579545454546, "EFR": 0.7058823529411765, "Overall": 0.6466201537433156}, {"timecode": 22, "before_eval_results": {"predictions": ["X-rays", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia, especially.", "two", "glowed even when turned off.", "five female pastors", "resources that could sustain future exploration of the moon and beyond.", "Falkland Islands", "1994", "Prague", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "a federal judge in Mississippi", "the department has been severely affected by the earthquake, with thousands of officers injured, killed or unaccounted for.", "22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide", "a president who understands the world today, the future we seek and the change we need. We need Barack Obama as the next president of the United States.", "military trials for some Guant Bay detainees.", "Kase Ng,", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain,", "women.", "ancient rituals in Olympia, where torch and relay races were popular festival events and where heralds traveled throughout Greece to announce the games.", "Zimbabwe's main opposition party", "No. 1 slot", "nine", "ash and rubble in place of their homes.", "Friday", "\"City of Silk' in Kuwait,", "Rima Fakih", "Tuesday night", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "only one", "Lee Myung-Bak", "Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Rima Fakih", "the Isthmus of Corinth", "Nalini Negi", "Keeping Up with the Kardashianians", "Runcorn", "collarbone", "\"to divide\"", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "hearth Menotti"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5668184114560433}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, false, true, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.20000000000000004, 1.0, 1.0, 0.0, 0.8235294117647058, 0.0, 1.0, 0.19999999999999998, 0.967741935483871, 1.0, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.6666666666666666, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.23529411764705882, 1.0, 0.875, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-1743", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.390625, "CSR": 0.5788043478260869, "EFR": 0.6410256410256411, "Overall": 0.6099149944258639}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Spain", "Jared Polis", "Janet and La Toya", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over", "threatening messages", "Noriko Savoie", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "martial arts", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani officials, India", "Zuma", "made out of either heavy flannel or wool", "five", "Iraqi Prime Minister Nouri al-Maliki", "September 11, 2001", "about 50", "a group of teenagers", "body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Jobs", "$81,88010", "provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "repudiation, change of mind, repentance, and atonement", "Jason Lee", "sleep is not one homogeneous state, but rather a progression through various states with extremely unique characteristics.", "attributive adjectives", "Kent", "beer and soft drinks.", "five aerial victories.", "Cherokee River", "\"Manor Farm\"", "NASA Astronaut", "Florida"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6550643112536886}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.08333333333333333, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.058823529411764705, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.0, 0.9787234042553191, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.5625, "CSR": 0.578125, "EFR": 0.75, "Overall": 0.6640625}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Lindsey Vonn", "Venus Williams", "him to step down as majority leader.", "EU naval force", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "The Louvre", "club", "shows the world that you love the environment and hate using fuel", "1979", "Heshmat Tehran Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector", "Bangladesh", "Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "behind the counter", "11 healthy eggs", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9", "racial intolerance.", "animal products.", "\"El Viceroy\" and \"El General,\"", "Symbionese Liberation Army", "$55.7 million", "work together to stabilize Somalia and cooperate in security and military operations.", "The BBC is refusing to broadcast a plea from leading British charities for aid to Gaza, saying the ad would compromise the public broadcaster's appearance of unbiasedity.", "it -- you know -- black is beautiful", "$104,327,006", "Picasso's muse and mistress, Marie-Therese Walter.", "Afghan forces in destroying drug labs, markets and convoys", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "near Takoma Park, Maryland.", "eight", "Mark Obama Ndesandjo", "Oxygen Channel's \"Dance Your Ass Off\"", "famous faces", "Raiders of the Lost Ark.", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "the division of Italy into independent states, the restoration of the Bourbon kings of Spain, and the enlargement of the Netherlands to include what in 1830 became modern Belgium", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5796996141113788}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.2857142857142857, 0.23529411764705882, 0.33333333333333337, 0.06666666666666667, 1.0, 0.0, 0.8, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.15384615384615385, 0.23076923076923078, 0.6666666666666666, 1.0, 1.0, 0.09999999999999999, 0.1142857142857143, 1.0, 0.0, 0.0, 0.0, 0.5, 0.2857142857142857, 0.0, 0.0, 0.6666666666666666, 0.0, 0.07999999999999999, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.453125, "CSR": 0.573125, "EFR": 0.7142857142857143, "Overall": 0.6437053571428571}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "beetle", "arthropoda", "Ub Iwerks", "St Pauls", "holography", "Pelias", "Barry White", "Northumbria", "Harvard", "cricket", "Ron Ridenhour", "quant pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "seborrheic dermatitis of the scalp.", "four", "a Rh\u00f4ne Grape Varietal Grown at Tablas Creek Vineyard", "Joseph Smith,", "Huntington Beach, California", "palladium", "moon", "13", "a palla", "The Virgin Spring", "Canada", "Churchill", "Stockholm", "Peter Parker", "Goldie Myerson,", "Giorgio Armani,", "bullfight", "Sparks", "Ginger Rogers", "Rock of Gibraltar", "Comedy Playhouse", "citric", "Charles Darwin", "John  Denver,", "Mr. Boddy", "Marie Van Brittan Brown", "Southern California Timing Association ( SCTA )", "2004 and 2007", "Bourbon", "Taylor Swift.", "Clarence Coffee Jr., Kiesza, Charli XCX, Jacob Plant, and Jennifer Lopez.", "two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "stripper pole photos", "Gopi Podila, chairman of the biological sciences department; Maria Davis, associate professor of biology; and Adriel Johnson,", "cactus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5213541666666667}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.6666666666666666, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-82", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-8908", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.4375, "CSR": 0.5679086538461539, "EFR": 0.6388888888888888, "Overall": 0.6033987713675213}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Space Museum\"", "number eight", "affordable housing", "Mao Zedong", "Verona", "Pontiac Silverdome", "elephants", "a charcoal powered grill, stove or hot plate", "Frank McCourt", "Charles A Raines", "j Judy Cassab", "Margo Leadbetter", "Schengen Area", "A", "city of Sheffield, England", "Famous Players", "the Beatles", "Gerald Durrell", "Jezebel", "Cork", "Pelias", "Arabian", "Halifax", "Noises Off", "england", "Stephen Potter", "Carlos the Jackal", "Edwina Currie", "Gillis Grafstr\u00f6m", "Robert Maxwell", "1768", "For gallantry", "Tuesday", "Caucasus", "Cahaba", "The Good Life", "Tahrir Square", "plutonium", "Count de la F\u00e8re", "27", "Jack Ruby", "tintoretto", "Eric Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "heart rate that exceeds the normal resting rate", "672", "\"Linda McCartney's Life in Photography\", \"Some Like It Hot\", \"Kubrick's Napoleon: The Greatest Movie Never Made\", \" Marc Newson: Works\", and \"Saturday Night Live: The Book\"", "The Frost Place Advanced Seminar", "@", "Juan Martin Del Potro.", "27", "german", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5534970238095238}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3571428571428571, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8026", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_searchqa-validation-12829"], "SR": 0.515625, "CSR": 0.5659722222222222, "EFR": 0.8387096774193549, "Overall": 0.7023409498207885}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "forced Tesla out leaving him penniless", "Zulfikar Ali Bhutto", "Iran's nuclear program.", "27 Awa", "(l-r)", "Daniel Cain", "acid attack by a spurned suitor.", "Wally", "2008", "after Wood went missing off Catalina Island, near the California coast,", "Behar", "Afghanistan", "The Everglades, known as the River of Grass,", "Dilshan made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27", "young self-styled anarchists", "$163 million (180 million Swiss francs)", "unwanted baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions", "Ensenada, Mexico", "Orbiting Carbon Observatory", "Switzerland", "Robert Redford", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "burned badly on the backs of his knees and every time he moves his knee, it pulls, and if it's healing, it starts to bleed.\"", "al-Shabaab", "posting a $1,725 bail", "sustain future exploration of the moon and beyond.", "his business dealings", "Opry Mills", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "j Stuart Gaffney, media director for Marriage Equality USA,", "\"gotten the balance right\"", "oceans", "sodomized him with a broomstick, a pair of scissors and a wooden dowel", "dr. Conrad Murray", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "1923 and 1925", "Gilda", "jeremy dryden", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Disraeli", "sun"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6149801936208299}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.4, 0.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.06896551724137931, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.11764705882352941, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19354838709677416, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-2976", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810"], "SR": 0.515625, "CSR": 0.5641741071428572, "EFR": 0.8709677419354839, "Overall": 0.7175709245391706}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot (7.6 m)", "manipulates symbols", "Hyundai Steel", "Monday night", "Bailey, Colorado", "Most of the 103 children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "40", "Illuminati", "in a public housing project,", "toxic smoke", "Lucky Dube,", "two Israeli soldiers, Ehud \"Udi\" Goldwasser and Eldad Regev.", "space shuttle Discovery", "Gavin de Becker", "building a nuclear weapon", "in Japan", "Arizona", "Southeast Asia and India.", "Tetris", "outside influences", "humanitarian issues", "flipped and landed on its right side", "suppress the memories and to live as normal a life as possible", "Tuesday in Los Angeles.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off, so they did not know casualty figures.", "knocking the World Cup off the front pages for the first time in days.", "Cash for Clunkers", "project work", "Oprah: A Biography", "80 percent", "London's 20,000-capacity O2 Arena.", "try to make life a little easier for these families", "Ozzy Osbourne", "$50", "Australian officials", "Hollywood headquarters of Capitol Records", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"State of Play\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off, so they did not know casualty figures.", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "mozart's finales", "Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5507620851370851}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.8571428571428571, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.19999999999999998, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.4444444444444445, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5100", "mrqa_squad-validation-1789", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-725", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1527", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.40625, "CSR": 0.5587284482758621, "EFR": 0.7105263157894737, "Overall": 0.6346273820326679}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "Russian army", "interstellar medium", "August 6 and 9, 1945", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "ancient Mesopotamia", "maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going", "Anthony Caruso as Johnny Rivers", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "singer and a co-worker", "Brenda", "who the better fighters are relative to their weight ( i.e., adjusted to compensate for weight class )", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "the first four caliphs ( successors )", "Lake Powell", "tree - topper or treetopper", "September 6, 2019", "population", "substitute good", "Veronica", "over 74", "1987", "cunnilingus", "1999", "New York City", "Mamata Banerjee", "the United States economy first went into an economic recession", "closing of the atrioventricular valves and semilunar valves", "Hermann Ebbinghaus", "Marvin Gaye", "people in the 20th century who used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Rome and Carthage", "43rd", "Gesellschaft mit beschr\u00e4nkter Haftung", "7.63\u00d725mm Mauser", "seven", "Muslim", "the two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Baikal", "the adventure park"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5298489313106249}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.9090909090909091, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0, 0.19999999999999998, 1.0, 0.7142857142857143, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.4444444444444444, 1.0, 0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.3333333333333333, 1.0, 0.1, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.4, 0.9333333333333333, 1.0, 0.0, 0.19354838709677422, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-10469", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.359375, "CSR": 0.5520833333333333, "EFR": 0.5365853658536586, "Overall": 0.5443343495934959}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "pioneers.", "a great warrior, call him by a new nickname  Hawkeye.", "shoes.", "nine", "Isaac Newton,", "acetylene", "an illegal substance", "fiber.", "gray deer", "a name that which we call a rose by any other name", "Winston Rodney", "sand", "Nanjing,", "Montana", "an ordinary rabbit", "Louis XIV of France", "GILBERT & SullIVAN.", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "1970 box office and critical disaster Song of Norway", "Frida Kahlo", "served as the sixth President of the United States from 1825 to 1829.", "Jeopary Questions page 831", "Fat man, you shoot a great game of pool", "Hair", "William Randolph Hearst", "basalt", "a pale ale", "Hominidae", "dogs", "a song performed by English pop punk band Busted.", "Luther", "\"The New Colossus\"", "yelped in pain when the bee stung.", "Richard Wagner", "Sarah, Duchess of York", "getting married tomorrow", "middleweight champion", "a drug that relaxes the smooth muscle around airways, causing the center", "Forty", "jedoublen/jeopardy", "Red Lake", "in 1923 Andre Lagache & Rene Leonard won the first \"24 Hours of\" here, averaging 57.21 mph", "Earl Long", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "three times", "Alberto juantorena", "R&B vocal group", "Awake", "Doctor of Philosophy", "Pakistan", "Seoul.", "an African-American woman for the job."], "metric_results": {"EM": 0.40625, "QA-F1": 0.45089285714285715}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.40625, "CSR": 0.5473790322580645, "EFR": 0.7105263157894737, "Overall": 0.6289526740237691}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the retina", "volume", "a crossword clue", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "August Wilson", "Juliet", "Notre Dame", "Tablecloth", "Tate", "Captain William Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "monosodium glutamate", "a card", "kozo", "Tenzing Norgay", "Samuel Beckett", "Rachel Carsons", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Prince William", "America Ferrera", "R", "a white dairy cattle", "New Jersey", "Lake Ontario", "Matt LeBlanc", "a beautiful city", "John Ford", "kismet", "Charlie and the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "an assemblage", "gravitational force", "Isis", "a quiver", "Heroes", "on the two tablets", "the source of the donor organ", "seven units", "Dr. A.G. Ekstrand,", "Duke Ellington", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years,", "Arsene Wenger", "in an interview Tuesday on CNN's \"Larry King Live.\""], "metric_results": {"EM": 0.5, "QA-F1": 0.590625}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10526", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-114", "mrqa_newsqa-validation-2123"], "SR": 0.5, "CSR": 0.5458984375, "EFR": 0.875, "Overall": 0.71044921875}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in.", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Emperor Norton", "CIA", "piano", "Rickey Henderson", "Jawaharlal Nehru", "World Carrot Museum", "John Grunsfeld", "a pavilion or a mandapa", "1976", "Galileo Descartes", "the quarks", "the Youth Bible Study", "Rudy Giuliani,", "the First Amendment", "Virginia", "Sif", "Hadrosaurus", "The Omega Man", "a walk-in pantry", "a barrel", "the 1984 Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Dirty Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Jenna Davenport", "Los Angeles", "the East Wind", "Richard III", "the policies", "The pen", "Croatia", "Douglas Adams", "Strindberg", "okina", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "the Thought Police", "a bust", "Central Park", "Alice", "Part 2", "The main character Roy Eberhardt moves to Florida and into the town of Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6337053571428571}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-5516", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-15655", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-13869", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.546875, "CSR": 0.5459280303030303, "EFR": 0.8620689655172413, "Overall": 0.7039984979101358}, {"timecode": 33, "before_eval_results": {"predictions": ["The BBC, in conjunction with animation studio Cosgrove Hall,", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him. Blood trickles down the road.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "the second she got back from Mexico,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "\"The station", "Hundreds of women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in five vignettes.", "a missile", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida", "over 1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "CNN", "no chance", "St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "a man wearing expensive costuming, including a very beautifully painted ruff of Italian lacework", "Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "in-cabin lighting system", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "Appathurai", "$40 and a bread.", "Kgalema Motlanthe,", "the Ming dynasty", "George II", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "M&M'S Plain Chocolate Candies", "The Star-Spangled Banner"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7052163573762837}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7058823529411765, 0.5, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.7499999999999999, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7682", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.609375, "CSR": 0.5477941176470589, "EFR": 0.52, "Overall": 0.5338970588235294}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "anti- strike", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcy going out of business for one reason or another, have a mental backup plan waiting in case you need to spring into action.", "nearly $2 billion in stimulus funds", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion, with further foreign direct investment exceeding $40 billion during the operations phase.", "hardship for terminally ill patients and their caregivers", "Honduras", "Brazil", "environmental", "strife in Somalia,", "Roy", "the WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.", "relatives of the five suspects,", "Meredith Kercher.", "defense lawyers trying to save their client from the death penalty", "Alicia Keys", "work together to stabilize Somalia and cooperate in security and military operations.", "Friday,", "cancerous tumors.", "20", "Matthew Fisher,", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "J. Crew", "Department of Homeland Security Secretary Janet Napolitano", "543 elected members, of which 58 are women.", "The patient, who prefers to be anonymous,", "Robert Gates", "Israel", "rural Tennessee.", "in critical condition", "Seoul,", "Nicole", "desperately wanted to make her mother proud.", "next week", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "Her husband and attorney, James Whitehouse,", "hopes the journalists and the flight crew will be freed, his chief of staff, Mahamat Hissene, said Thursday.", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1968", "Black Elk", "the Hogan Family", "the hippopotamus", "Peter"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5632323901455535}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.5, 0.15384615384615385, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.43478260869565216, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-3007", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.484375, "CSR": 0.5459821428571429, "EFR": 0.5757575757575758, "Overall": 0.5608698593073593}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "3 to 5 inches wide", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "mau fern", "the Aegean Sea", "Battle of the Little Bighorn", "Shakers", "a bellwether", "Time and Free Will", "chips", "Boxer", "The Spiderwick Chronicles", "Mabel Harding", "Las Vegas", "role play", "the Rose Bowl", "Norman Rockwell", "hair red.", "tunacanned light tunais", "Napa Valley", "Eurail France", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "Grease", "12 men", "Jeff Merkley", "blogging", "Jupiter", "Sadat", "a seven-day-a-week treat", "Grace Evans,", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Master of thunder,", "Lou Gehrig", "nine", "1949", "Aamir Khan", "My Gorgeous Life", "Argentine", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.484375, "QA-F1": 0.580514705882353}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true], "QA-F1": [0.35294117647058826, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-7041", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.484375, "CSR": 0.5442708333333333, "EFR": 0.7272727272727273, "Overall": 0.6357717803030303}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "if you never take risks or try anything, you will never gain the rewards of that risk.", "silver", "Supernanny", "Atlantic", "Cincinnati", "mosque", "Henry Hudson", "a gun blast tubes", "dry ice", "Elihu Root", "Entourage", "eel", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "John C. Frmont", "Russia", "(BRA STREISAND)", "Hermann Hesse", "the Taj Mittal", "English Monarchs", "the Toreador Song", "Margaret Mitchell", "Frollo", "Money for Nothing", "Pandarus", "(A gloomy landscape)", "Burt Reynolds", "the Sphinx", "Louis Satchmo Armstrong", "Saudi Arabia", "American new wave band", "Arby's", "coffee", "The Lgion", "Robert Burns", "The Incredible Hulk", "Atlanta", "Memphis Belle", "Burkina Faso", "Central Pacific", "Attorney General", "Icelandic", "a bison bull", "Sunday", "Edith Piaf", "Ivan I", "a prologue", "birch", "an investor couple", "Jack Gleeson", "Phil Hurtt", "animals", "Massachusetts", "the City of Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"17 Again\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.6906994047619048}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-14520", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_newsqa-validation-3951"], "SR": 0.640625, "CSR": 0.546875, "EFR": 0.7391304347826086, "Overall": 0.6430027173913043}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "Sanders", "oats", "Romney", "Ivan the Terrible", "Sally Field", "1927", "Egypt", "pi", "tin", "Lake Maurapas", "Cousin Eddie", "W", "Marriott", "the Principality of Monaco, French Principaut de Monaco,", "Canada", "The Secret", "the Australian population", "Collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "J. W. Scott,", "the axiomatic system", "Eva Peron", "Cain", "Edward Asner", "X-Men: The Last Stand", "the Louvre", "keta", "Prison Break", "Mars", "Maine", "a sheep's milk cheese", "Meg", "Sonnets", "deuce", "Hans", "Peter Bogdanovich", "a #3 hit song", "Pilate", "FATE", "the Quaternary Period", "nolo contendere", "Jr. Walker", "the Czech Republic", "the Albacore", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"Sausage Party\"", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again,\"", "Nelson"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6651041666666667}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-6998", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-5774"], "SR": 0.578125, "CSR": 0.5476973684210527, "EFR": 0.8888888888888888, "Overall": 0.7182931286549707}, {"timecode": 38, "before_eval_results": {"predictions": ["in whole by charging their students tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospirosis", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "M1 Abrams", "brushes", "a boat", "forgetting Sarah Marshall", "Witness", "Martha Tabram", "3800", "Rene Auberjonois", "taxonomy", "Spain", "the spinal cord", "Francesco Schettino", "Macbeth", "a comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "Second Marriage Ceremony", "Livin' On A Prayer", "Sherlock Holmes", "a lollipop", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "G", "German", "Katamari Damacy", "Bill Murray", "Margaret Thatcher", "the Queen of Spades", "tungsten", "forests", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Sydney Pollack", "pan rabbit", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "different levels of importance of human psychological and physical needs.", "eleven", "Norfolk Island", "The Wright brothers", "sexual activity", "Canada Goose", "Sandro Bondi refused to attend", "voluntary homicide", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5171875}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.4, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1, 0.5, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6983", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-5541", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_searchqa-validation-402", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_hotpotqa-validation-2005", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.453125, "CSR": 0.5452724358974359, "EFR": 0.7142857142857143, "Overall": 0.629779075091575}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the eight-year blockade of Constantinople", "Independence", "Jefferson", "Ford Madox Ford", "The Orinoco River", "a ready-to-use cotton swab", "Alaska", "Dixie's Land", "America's University of Imperialism", "Warren Harding", "engrave", "Elisabeth & Andrew", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "Westies, Scotties, schnauzers", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "a little over a mile", "Electric word life", "a bird's foot", "the endgame", "GIGO", "Johannes Brahms", "Florida State", "Italian", "The Grapes of Wrath", "a bicentennial exposition", "Byzantium", "William", "Led Zeppelin", "a Tesla coil", "Denmark", "Anna Murphy", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "Bollywood superstar", "managing his time"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5441220238095238}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-7830", "mrqa_searchqa-validation-14076", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11314", "mrqa_searchqa-validation-11250", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4073"], "SR": 0.46875, "CSR": 0.543359375, "EFR": 0.7352941176470589, "Overall": 0.6393267463235295}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "a 2003 South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000 people", "yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "\"Away In A Manger\"", "Tsavo East National Park", "New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the second tier of the English football league system,", "The Gettysburg Address", "most awarded female act of all-time.", "forwards", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas, Anne Bancroft, James Fox, Derek Jacobi, and Sean Penn.", "Mayor Ed Lee", "1958", "1993", "American burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the 2007 Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "a prototype of the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Golde", "Sir Tom Finney", "Baka hunter-gatherers", "obtaining and proper handling of human blood.", "toxic smoke from burn pits in Iraq and contaminated water.", "two", "Iggy Pop invented punk rock.", "a pound of flesh", "a man of Character", "Leonardo DiCaprio", "a destructive ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6708792892156863}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1786", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_naturalquestions-validation-6326"], "SR": 0.5625, "CSR": 0.5438262195121951, "EFR": 0.8571428571428571, "Overall": 0.7004845383275261}, {"timecode": 41, "before_eval_results": {"predictions": ["a touchdown", "10", "was \"in bad condition at the scene,\"", "Les Bleus", "2005", "more than 4,000", "Arlen Specter", "an angry mob.", "normal maritime traffic", "Sri Lanka, seeking a win to level the series at 1-1,", "death", "average of 25 percent", "he was led away in handcuffs after being sentenced in a New Jersey court for fatally shooting a limo driver", "Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "Brazil", "some three months before the crimes", "Bush", "Facebook and Google", "through a facility in Salt Lake City, Utah", "Manmohan Singh", "Haiti", "Tuesday afternoon", "Pakistan", "23 years.", "a head injury", "Tim Cahill", "an open window that fits neatly around him", "Leo Frank", "Paul McCartney and Ringo Starr", "Washington", "Wilbert Gwashavanhu, political consul at Zimbabwe's embassy in Washington.", "don't have to visit laundromats", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "His love for America is unwavering.", "Twilight", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died", "Cesar Laurean", "aircraft had a crew of 14 people and was carrying an additional 98 passengers,", "al Qaeda", "Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "the Consolidated B-24 Liberator", "Nut & Honey Crunch", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "1523-1560", "Department of Transportation"], "metric_results": {"EM": 0.484375, "QA-F1": 0.599464610654868}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 0.11764705882352942, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8, 0.3636363636363636, 1.0, 0.4, 0.3636363636363636, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.0, 1.0, 0.7272727272727273, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 0.625, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.21428571428571427, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-1549", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3857", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-2414", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-1519"], "SR": 0.484375, "CSR": 0.5424107142857143, "EFR": 0.6363636363636364, "Overall": 0.5893871753246753}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe", "Italian Serie A", "Darrel Mohler", "her dancing against a stripper's pole.", "Michoacan Family", "WTA Tour titles", "Welshman Ncube", "42", "takes on the swords of the Taliban.", "If huge hunks of ice -- such as parts of Greenland and the western shelf of Antarctica -- melt, then the rise is expected to be more dramatic.\"", "80 percent of a woman's face", "1979", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Elena Kagan", "CNN's Campbell Brown", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar's military", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Bienvenido Latag", "poems", "the program was made with the parents' full consent.", "Evan Bayh", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators", "31 meters (102 feet) long and 15 meters (49 feet) wide", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire,", "1940's", "March 22", "eco", "at a depth of about 1,300 meters in the Mediterranean Sea.", "Antichrist", "a major fall in stock prices", "John Adams and Benjamin Franklin", "Alexander Salkind", "Rigel", "reddish brown", "Selfie", "2002", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "El Aneto"], "metric_results": {"EM": 0.5, "QA-F1": 0.6259662340314913}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.4, 0.25, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-5989", "mrqa_triviaqa-validation-1492", "mrqa_triviaqa-validation-1225", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920", "mrqa_triviaqa-validation-4566"], "SR": 0.5, "CSR": 0.5414244186046512, "EFR": 0.8125, "Overall": 0.6769622093023255}, {"timecode": 43, "before_eval_results": {"predictions": ["north", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "American Civil Liberties Union", "33-year-old", "\"Well, about time.\"", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "nearly $2 billion", "The National Infrastructure Program, as he called it,", "1937,", "\"The station", "Krishna Rajaram,", "a man's lifeless, naked body", "Robert Mugabe", "first lady,", "Afghanistan's restive provinces", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "Iran could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Elena Kagan", "Hyundai Steel's", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "militants", "Seminole", "a Muslim with Lebanese heritage,", "South Africa", "Obama", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "a receptionist with a gunshot wound in her stomach", "$50 less", "$60 billion on America's infrastructure.", "ALS6", "Malayalam", "Hagrid", "1960 Summer Olympics in Rome", "Villa Park", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "pool", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "ruby slippers", "the occipital lobe"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6207050830200501}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.08333333333333333, 1.0, 0.9523809523809523, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5263157894736842, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.546875, "CSR": 0.5415482954545454, "EFR": 0.7931034482758621, "Overall": 0.6673258718652038}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf.", "Los Angeles", "Chris Eubank Jr.", "Duval County, Florida", "Benj Pasek and Justin Paul,", "Andes", "1952", "Soyo  Soyo (formerly known as Santo Ant\u00f3nio do Zaire)", "19th", "January 28, 2016", "Harriet Tubman", "Roger Staubach", "1944", "Highlands Course", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley Village", "What Are Little Boys Made Of?", "Berea College", "Omaha Nighthawks", "Call Me by Your Name", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown, Clayton Mark's", "jus sanguinis", "Radcliffe College", "Charles Guiteau", "Ford Motor Company", "If the citizen's heart was heavier than a feather they would face torment in a lake of fire.", "India", "Lutheranism", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "Believe", "central", "largest country comprising the mainland of the Australian continent, the island of Tasmania and numerous smaller islands", "the first to develop lethal injection as a method of execution", "Nicola Adams", "\"bay of geese,\"", "Russia", "dependable Camry", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "Riddles", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5892224049707603}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.53125, "CSR": 0.5413194444444445, "EFR": 0.8, "Overall": 0.6706597222222223}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder", "Indian Ocean waters", "30", "crocodile eggs", "A Colorado prosecutor", "Jared Polis", "Saturday,", "Carrefour", "in July for A Country Christmas, and the festivities run from mid-November until the holidays end.", "trail the illegal traffic.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "17 Again", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "police", "Sen. Joe Lieberman,", "the jaws of a crocodile", "a bronze medal in the women's figure skating final,", "more than 200", "Congress", "Susan Boyle", "military ID cards, known as \"Common Access Cards,\"", "Phillip A. Myers.", "Obama", "Gyanendra", "homicide", "Casey Anthony, 22,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "2004", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "I started my foundation in 2005, after the Beslan tragedy [the 2004 school siege in which at least 339 hostages were killed].", "Jacob Zuma", "Oaxacan countryside of southern Mexico", "Arsenal manager Arsene Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "Latin liberalia studia", "British", "Johnny Mathis", "Beverly Hills Cop,", "Champion Jockey", "Luca Guadagnino", "Freddie Jackson", "the caged bird", "timing shapes and supports brain function", "a bar jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.5, "QA-F1": 0.613119952963703}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.14285714285714288, 0.0, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.9090909090909091, 0.4, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.5, "CSR": 0.5404211956521738, "EFR": 0.6875, "Overall": 0.6139605978260869}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "phone calls or by text messaging", "Los Alamitos Joint Forces Training Base", "12.3 million", "Mexico", "Manchester United", "Michael Arrington,", "Brett", "eight Indian army troopers, including one officer, and 17 militants,", "Saturday", "Nicole", "legitimacy of that race.", "ceo Herbert Hainer", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry", "June 6, 1944,", "in almost all [Middle East and North Africa] countries, and censorship and self-censorship are prevalent throughout the region.", "twice", "October 19", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "VBS.TV", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "the area was sealed off, so they did not know casualty figures.", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "test scores and graduation rates", "two", "the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel ( 1497 -- 1558 )", "Discworld", "Japan", "fox hunting", "New York", "travel diary", "16,116", "the Jinx", "sukkar", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6986740256271506}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.45454545454545453, 0.0, 1.0, 0.625, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_naturalquestions-validation-5769", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.640625, "CSR": 0.5425531914893618, "EFR": 0.8260869565217391, "Overall": 0.6843200740055504}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Chicago", "\"The Ones Who Walk Away from Omelas\"", "child actor", "Dennis Kux", "drawing the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "Jack Richardson", "Lady Frederick Windsor", "point-coloration", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1946 and 1947", "5,112", "1992", "many artists' lofts and art galleries, but is now better known for its variety of shops ranging from stylish upscale boutiques to national and international chain store outlets.", "14,673", "6'5\" and 190 pounds", "Mickey Gilley's", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport.", "the Salzburg Festival", "McComb, Mississippi", "Afghanistan", "1991\u201392", "Imelda Marcos", "Randall Boggs", "Messiah Part II", "Charlestown, Massachusetts,", "lion", "Royal", "World War II", "Knoxville, Tennessee", "\"Three's Company\"", "P.O.S,", "Labour", "Linda McCartney's Life in Photography", "Australian", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy.", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "ante rooms", "Lehman Bros International"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7058741605616605}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 0.0, 0.4, 0.5, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.609375, "CSR": 0.5439453125, "EFR": 0.72, "Overall": 0.63197265625}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "sushi", "offensive", "god of fire", "the Pilgrims", "Fawn Hall", "lapiskel", "Shakespearean", "Barnum", "Johnny Weissmuller", "cathode", "torque screw", "gold", "Maria Schneider", "Middle Dutch", "\"Impressionists\"", "Kentucky Wildcats", "the ruddy", "Brussels", "Macbeth", "General Lee", "piracy", "the death vestments", "Martin Luther", "Clue", "Edgar Allan Poe", "German", "Andrew Johnson", "15:1", "Mike Connors", "Jungle Jim", "Jim Inhofe", "sancire", "Corpus Christi", "South Africa", "Ostriches", "The Constitution For The United States,", "the night shift", "mug", "Desperate Housewives", "Galileo Galilei", "Canada's", "Andy Sachs", "spare", "the Grail", "West Virginia", "James Madison", "movie house", "SeaWorld", "kritiks", "Khrushchev", "1904", "Everest creative Maganlal Daiya", "Bobby Tambling", "ambilevous", "chariots", "Humberside", "more than 265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "a head injury.", "Pope Benedict XVI", "Charles II"], "metric_results": {"EM": 0.375, "QA-F1": 0.4779671003016591}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6153846153846153, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-10470", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-14219", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-10801", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.375, "CSR": 0.5404974489795918, "EFR": 0.8, "Overall": 0.6702487244897959}, {"timecode": 49, "before_eval_results": {"predictions": ["National Security Agency", "Heisman Trophy", "Brandi Chastain", "the Androscoggin", "C.J. Parker", "colombo", "Treasure Island", "Pocahontas", "\"Whose Line Is It Rhythm?\"", "(Whizzer) White", "low", "a spray", "Great American Novel", "Ferris B Mueller's", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "Cold Blood", "Ernest Lawrence", "three Hills Rodeo", "fresco", "Nevil Shute", "\"If he's a poet, then I'm no poet.", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "a fly", "the mouthpiece", "Key West", "Lord of the Rings", "Have You Neverbeen Mellow", "Picaridin", "Manhattan", "February 2", "Leontyne Price", "Compost", "Lauren Hutton.", "Christopher Columbus", "Phil Mickelson", "Sarah Jessica Parker", "a little learning", "Bern", "akhnif", "Philadelphia", "peanut butter", "Edgar Allan Poe", "Diamond", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "Meadowbank Thistle", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The incident Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her;", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5329861111111112}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4616", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-7250", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.46875, "CSR": 0.5390625, "EFR": 0.7941176470588235, "Overall": 0.6665900735294117}, {"timecode": 50, "UKR": 0.78515625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.759765625, "KG": 0.50234375, "before_eval_results": {"predictions": ["Fatih Ozmen", "Volvo 850", "Skyscraper", "Cadillac Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Paul Bettany", "J\u00fcrgen M. Geissinger", "band director", "Visigoths", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "president of Guggenheim Partners", "19th", "Hillary Scott", "Jeremy Hammond", "vice president", "Tottenham Hotspur", "October 2016", "Vixen", "Forbidden Quest", "Rymill Park", "Balloon Street, Manchester", "May 1, 2011", "Santa Fe", "Jewish power", "Adelaide Lightning", "Landing Barge", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north.", "created the American Land-Grant universities and colleges.", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "American", "hamburgers", "Liverpool", "spaghetti", "Luigi Segre", "United States House of Representatives", "February 16, 2018", "the studies and developments department of the French firm R2E Micral", "Nacio Herb Brown ( music ) and Arthur Freed ( lyrics )", "Geoff Hurst", "Precambrian", "Mull", "Dube's death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "had a relationship with another person.", "a progressive neurological disease", "Paul Newman", "Puccini", "Steve Martin", "milk and honey"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5123511904761905}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.35714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-3352", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-13015"], "SR": 0.4375, "CSR": 0.5370710784313726, "EFR": 0.7222222222222222, "Overall": 0.661311785130719}, {"timecode": 51, "before_eval_results": {"predictions": ["1898", "an Indian", "What You Will", "1961", "Stacey Kent", "1970s", "Arthur Freed", "Elizabeth Kekaikuihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui Pratt", "Gothic Revival", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237", "11,163", "an album", "its air-cushioned sole", "Original Knights of Louisiana", "WikiLeaks", "Three card brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Films", "2001", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Dame Eunice Mary Kennedy Shriver, DSG", "35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Daniel Espinosa", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League group stage", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "Atlantic Ocean", "devotional", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "last week", "The Baldwin Project", "hunter sauce", "The Tolkien's", "carbon"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7084635416666667}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.3333333333333333, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-1263", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.65625, "CSR": 0.5393629807692308, "EFR": 0.9090909090909091, "Overall": 0.699143902972028}, {"timecode": 52, "before_eval_results": {"predictions": ["My Antonia", "King Henry VIII", "lead", "the Rose Bowl", "VC-25", "amber", "Denmark", "cute puppies", "Katrina & the Waves", "Jerusalem", "freestyle", "devonian", "Ustilaginales", "Stargate", "Lou Reed", "Chancellors", "Spmi", "Lucy Rigg", "canvas", "petticoat", "X-Files", "Frankie Muniz", "North American Mammals", "Hudson Bay", "Coupvray", "kinetic", "santera", "Starsky", "Statue of Liberty", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "Panama Canal", "cornucopia", "Bob Fosse's", "Ankara", "condensation", "be", "Winchester", "Chinese", "Larry Sanders Show", "The Virgin Spring", "Como agua para chocolate", "NigerCongo", "TGI Fridays", "John Tyler", "Daniel Craig", "humility", "programming", "Isle of Sheppey in England", "A footling breech", "concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bristol", "governor", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "Atlantic Ocean", "consistency, whose naturalness is part of their excitement.", "fake his own death", "the S&DR"], "metric_results": {"EM": 0.609375, "QA-F1": 0.63359375}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.5, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-13812", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-3189", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-2686", "mrqa_triviaqa-validation-5426"], "SR": 0.609375, "CSR": 0.5406839622641509, "EFR": 0.76, "Overall": 0.6695899174528301}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen and illustrated by Helen Oxenbury", "Neil Young", "After Shawn's kidnapping", "to manage the characteristics of the beer's head", "in early evenings to call ( in spring and summer ) and hunt for food", "an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "clay", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "in the sequence of pieces of DNA called genes", "to `` help bring creative projects to life ''", "Most of the rainfall occurs in the December to March period", "David Motl", "The Portuguese", "Madison, Wisconsin, United States", "September 1972", "2017", "Gustav Bauer", "the settlement of the sedimentation", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "John Barry", "1961", "111", "Brazil, Turkey and Uzbekistan", "an even - toed ungulate", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "A complex sentence", "Halliwell, French, Timomatic and Sandilands", "Coriolis effect", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "Cities", "Daya Jethalal Gada", "74", "omitted", "in various submucosal membrane sites", "noble gas", "Department of Health and Human Services, Office of Inspector General, as of 2000 there were more than 6,000 entities issuing birth certificates", "four distinct levels", "Janie Crawford", "Justin Timberlake", "The Tenth Planet", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Paul Gauguin", "USA Today serving as its megaphone.", "creeks, fringing the southwest mouth of Lagos Lagoon, while protected from the Atlantic Ocean by barrier islands and long sand spits such as Bar Beach,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "off the coast", "Northwest Territories", "Chayka", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5718974948662449}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, false, true], "QA-F1": [0.4444444444444445, 1.0, 0.0, 0.7692307692307692, 0.08, 0.9, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3571428571428571, 1.0, 0.42857142857142855, 0.5, 1.0, 1.0, 0.8, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 0.2857142857142857, 0.08333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-3243", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4748", "mrqa_hotpotqa-validation-3974", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.453125, "CSR": 0.5390625, "EFR": 0.7428571428571429, "Overall": 0.6658370535714286}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "Tex - Mex cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "George Harrison", "Kanawha Rivers", "1803", "Speaker of the House of Representatives, President pro tempore of the Senate, and then the heads of federal executive departments who form the Cabinet of the United States", "3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Frank Theodore `` Ted '' Levine", "May 3, 2005", "restored to life", "California, Utah and Arizona", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "1773", "John J. Flanagan", "1988", "elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "over seven years", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Beyonc\u00e9", "Arkansas", "Pandit Jawaharlal Nehru", "island owner `` U.N. Owen '' ( i.e., `` Unknown '' )", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "S\u00e9rgio Mendes", "Secretary of Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "Transvaginal ultrasonography", "741 weeks", "Zimbabwe", "London", "Hillary Clinton's", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison", "the ship", "beautiful", "Tater Tots", "Yemen", "QED", "Dalton Gang"], "metric_results": {"EM": 0.5, "QA-F1": 0.5847083492487904}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.56, 0.0, 1.0, 0.6666666666666666, 0.0, 0.08, 1.0, 0.058823529411764705, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-8575"], "SR": 0.5, "CSR": 0.5383522727272727, "EFR": 0.78125, "Overall": 0.6733735795454545}, {"timecode": 55, "before_eval_results": {"predictions": ["the spoiled, bedridden daughter of wealthy businessman James Cotterell ( Ed Begley )", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "U.S. states of Oregon and Washington", "Northeast Monsoon", "2005", "Nitty Gritty Dirt Band", "living and organic material", "annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves", "minimum viable product that addresses and solves a problem or need that exists", "London", "Incumbent Democratic mayor Marty J. Walsh", "Sir Edward Henry", "Ernest Rutherford", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "SI joint", "HTTP / 1.1", "the Mayflower", "1 mile ( 1.6 km ) in width in several places", "pop ballad", "8 December 1985", "during meiosis", "2005", "Arnold Schoenberg", "notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "Orographic lift", "Hebrew Bible", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outermost layer of human skin", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Niall Matter", "Sebastian Vettel", "San Antonio", "Jetfire", "biological taxonomy", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Tevin Campbell", "Celebrity Big Brother", "Sir Roger Casement", "James Garner", "Boston, Massachusetts", "Colonel Patrick John Mercer", "Robert Matthew Hurley", "urging more help for military members, especially for those returning from war.", "two", "Deputy Chief Brenda Johnson", "Charles the Bald", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5439201961661047}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.9333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.09523809523809522, 0.5, 0.0, 0.0, 0.6153846153846153, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25000000000000006, 0.0, 0.1290322580645161, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2296", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.421875, "CSR": 0.5362723214285714, "EFR": 0.8648648648648649, "Overall": 0.6896805622586872}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "Sumitra", "16", "1840", "1999", "Old Trafford", "Tami Lynn", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "metamorphic rock", "Theodore Roosevelt", "Nepal", "Dutch navy captain Jurriaen Aernoutsz", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "April 1st", "Brobee", "the claims process starts at noon Eastern Time and ends 24 hours later", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "mental disorder characterized by at least two weeks of low mood that is present across most situations", "1989", "Liam Cunningham", "Lorenzo Lamas", "Walter Pauk", "1979", "lateral nasal wall", "gentry Buddhism", "forex market", "`` Singing the Blues '' by Guy Mitchell in 1957", "Sir Ernest Rutherford", "Nigel Lythgoe", "December 2, 2013", "gastrocnemius", "Art Carney", "Thomas Hobbes in his Leviathan", "March 26, 1973", "1986", "a forest", "President Lyndon Johnson", "prenatal development of the human heart", "a Nativity scene", "1840", "2007", "About Branson", "first baseman", "South Plainfield, New Jersey-based manufacturer of suitcases and bags", "River Shiel", "Ozzy Osbourne", "Polo", "the music label that owns them said Sunday, after days of speculation that they were.", "\"surfing\"", "Nova Scotia", "Sir Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7104910714285715}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_triviaqa-validation-7674", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-15619", "mrqa_searchqa-validation-10569"], "SR": 0.609375, "CSR": 0.5375548245614035, "EFR": 0.92, "Overall": 0.7009640899122808}, {"timecode": 57, "before_eval_results": {"predictions": ["France", "Massachusetts", "the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "Casino promotions such as complimentary matchplay vouchers or 2 : 1 blackjack payouts allow the player to acquire an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Joe Young", "the original game release", "Ozzie Smith", "Mark Jackson", "2017", "two - year terms", "January 2018", "in soils", "September 30", "humans", "President Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "the nucleus", "1955", "Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music", "contestant", "Hebrew \u05de\u05b7\u05dc\u05b0\u05db\u05b8\u05bc\u05dd\u200e Malkam `` great king ''", "P.V. Sindhu", "Carpenter", "Asuka", "126", "Scorpions", "Brazil", "UNESCO / ILO", "issued upon a military service member's retirement", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "American country music duo Brooks & Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "Long Island", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "liver", "Heineken International", "Chekhov", "Gust Avrakotos", "Mark Sanford", "Lance Cpl. Maria Lauterbach", "step up", "1920", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5460180458542354}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.4, 0.375, 0.14285714285714288, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.5555555555555556, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-6103", "mrqa_searchqa-validation-5902"], "SR": 0.453125, "CSR": 0.5360991379310345, "EFR": 0.7714285714285715, "Overall": 0.6709586668719212}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "October 14, 2017", "the books of Exodus and Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979", "son of Edward", "iron", "Detective Eddie Thawne", "Los Angeles", "British Empire", "Jaffa Cakes", "the name of a work gang", "Jeremiah", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "( 27 January -- 16 April 1898 )", "Yosemite National Park", "Ewan McGregor", "LED illuminated display", "turkey", "1917", "January 2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "genome", "by each state's DMV, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "peace between two entities ( especially between man and God or between two countries )", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "13 February", "291 episodes", "early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "March 1995", "Zoe Zebra", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles", "crude oil", "peppermint oil, soluble fiber, and antispasmodic drugs", "FBI", "a ferry", "Leland Stanford", "Mexico", "Nepal"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6551945970695972}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.33333333333333337, 0.92, 0.5, 0.0, 0.0, 0.3333333333333333, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.33333333333333337, 0.0, 0.0, 0.2857142857142857, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7895", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-3940", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98"], "SR": 0.46875, "CSR": 0.534957627118644, "EFR": 0.6470588235294118, "Overall": 0.6458564151296111}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Abiotic", "IIII", "the ultimate exercise for the bored and lazy ''", "head coach", "July 2012", "`` Audrey II ''", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "January 2018", "George Strait", "Antarctica's lowest air temperature record was set on 21 July 1983, with \u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "Herman Hollerith", "94 by 50 feet ( 28.7 by 15.2 m )", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "October 1, 2014", "The Miracles", "required many hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients", "Roxette", "Long Island", "1988", "Egypt", "Rococo - era France", "Michael Crawford", "Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "September 2, 1945", "1950s", "Maximilien Robespierre", "XXXX", "by the early - to - mid fourth century", "to turn our will and our lives over to the care of God as we understood Him", "De pictura", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Joker Wild", "Chicago", "dijon", "Lucas Stephen Grabeel", "15,024", "model", "the results by a chaplain about 1:45 p.m., per jail policy.", "15-year-old", "Sunday", "Vietnam", "bass", "Richard", "Son of Sam"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7283854129046703}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5161290322580645, 1.0, 0.6666666666666666, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.9090909090909091, 0.27586206896551724, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-34", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465"], "SR": 0.640625, "CSR": 0.53671875, "EFR": 0.782608695652174, "Overall": 0.6733186141304348}, {"timecode": 60, "before_eval_results": {"predictions": ["a recognized group of people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "writ of certiorari", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "coffee, macadamia nuts, pineapple, livestock, sugarcane and honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Dennis C. Stewart", "Mahatma Gandhi", "people of the United States", "The eighth and final season of the fantasy drama television series Game of Throne", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil", "Nicklaus", "1957", "Clare Torry", "ummat al - Islamiyah", "Brazil, Turkey and Uzbekistan", "Parashara", "Domhnall Gleeson", "Brazil and Paraguay", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "on the alluvial plain", "\"The closest approach to the original sound\"", "Peter Sellers", "Colonel Tom Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain's", "\"Empire of the Sun,\"", "Stephen Dedalus", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6510940882034633}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.625, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.546875, "CSR": 0.5368852459016393, "EFR": 0.6206896551724138, "Overall": 0.6409681052148106}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "Dimitar Berbatov and Carlos Tevez", "Jason Marsden", "New Mexico", "In 1889", "Poems : Series 1", "William the Conqueror", "February 16, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "the world's sixth - largest country by total area", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Ewan McGregor", "Acts passed by the Congress of the United States and its predecessor, the Continental Congress, that were either signed into law by the President or passed by Congress after a presidential veto", "2018", "The first bull running is on 7 July, followed by one on each of the following mornings of the festival, beginning every day at 8 am", "the 2009 model year", "4.25 inches ( 108 mm )", "Judi Dench", "Japan by Crunchyroll", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson", "Ian McKellen", "Space is the Place   Jumping on the Moon   No Night Today   Planet Name Game   Top of the Sky   Tough Enough", "Brad Dourif", "counter clockwise direction", "Joanne Wheatley", "President pro tempore of the Senate", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "1994 season", "Matt Flinders", "parthenogenic", "the major contributor", "the efferent nerves that directly innervate muscles", "1773", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "Don Cook", "kautta", "South America", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "One of Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6277254869172972}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.24000000000000002, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 0.0, 0.06896551724137931, 1.0, 0.07692307692307691, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3, 1.0, 0.8, 1.0, 0.28571428571428575, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.515625, "CSR": 0.5365423387096775, "EFR": 0.8387096774193549, "Overall": 0.6845035282258065}, {"timecode": 62, "before_eval_results": {"predictions": ["1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Eastern Mediterranean", "toys or doorbell installations", "microfilament", "in positions Arg15 - Ile16", "northernmost point on the Earth", "`` A.D. ''", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1936", "Ringo Starr", "Djokovic", "Abraham Gottlob Werner", "1922", "2017", "scythe", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "Stephen Sondheim", "Toronto", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "the Americas", "10.5 %", "ecological regions", "White House Executive Chef", "Bangladesh -- India border", "Bart Millard", "a woman named Sarah Whitehead", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal drummer", "Selden", "Muslim Eid-ul-Adha", "the day before.", "due to a shortage of landing fields available for practice, an offer to land near the Middleton house on April 3 was readily accepted.", "Chastity", "Senegal", "Chief Oshkosh", "River Welland"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5978331244778613}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.28571428571428575, 0.21052631578947367, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-342", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_newsqa-validation-1285", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.515625, "CSR": 0.5362103174603174, "EFR": 0.967741935483871, "Overall": 0.7102435755888377}, {"timecode": 63, "before_eval_results": {"predictions": ["Robyn", "1998", "the closing of the atrioventricular valves and semilunar valves", "the Coppolas", "sacroiliac joint", "Identification of alternative plans / policies", "Mexico", "development of electronic computers", "the Internal Revenue Service", "Numbers 22 : 28", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "napkin", "Andrew Dice Clay", "Jakkur, Bangalore, India", "Five years later", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "a fortified complex at the heart of Moscow", "the court from its members for a three - year term", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "from a Czech word, robota", "Arthur `` The President '' Flanders", "Cameron Fraser ( who disappeared with \u00a3 60,000 of her savings )", "Austin and Pflugerville", "the history of the Philadelphia Eagles begins in 1933", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah", "Jack Barry", "Hugo Weaving", "from the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "American singer and songwriter Lana Del Rey", "The Matterhorn", "calypso", "JP Richardson", "The Pentagon", "Croatan, Nantahala, and Uwharrie", "Johnnie Ray", "Morgan Tsvangirai", "Capitol Hill", "increase the flow of water passing through its network of dams.", "impressionist", "the Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5277942237501061}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2222222222222222, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.16666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.11764705882352941, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.20000000000000004, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-3801", "mrqa_naturalquestions-validation-7669", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4240", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-198", "mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-8333"], "SR": 0.421875, "CSR": 0.534423828125, "EFR": 0.7297297297297297, "Overall": 0.662283836570946}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough, Massachusetts", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "Liga MX", "Amber Heard", "Peter Seamus O'Toole", "March 8, 1942", "\"Electron Blue\"", "January 30, 1930", "Doctor of Philosophy", "Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "Cher", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "Ionolyce", "\"For Love alone\" (1986)", "October 4, 1970", "King of the Polish-Lithuanian Commonwealth", "Sam Waterston", "Transporter 3", "March 14, 2000", "Gauteng province", "Vietnam War", "Bill Walton", "Darling River", "Brian Keith Bosworth", "over 140 million", "American", "Teri Garr", "the employer", "1965 -- 66 season", "Wyoming", "Wee Jimmy Krankie", "Apeirophobia", "announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Washington DC", "a long distance (6)", "Southport, North Carolina"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6053199404761904}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.25, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-5297", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474"], "SR": 0.484375, "CSR": 0.5336538461538461, "EFR": 0.6363636363636364, "Overall": 0.6434566215034965}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "\"Arrested Development\"", "Albert", "September 30, 2017", "322,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire in Atlanta that killed 119 people and the Dupont Plaza Hotel, San Juan, Puerto Rico fire on December 31, 1986, in which 97 perished", "Odense Boldklub", "Stephen of Blois", "Scott Eastwood", "Gweilo", "Tufts College", "Prince Amedeo, 5th Duke of Aosta", "1936", "The Wu-Tang Clan", "For Love Alone", "midtempo hip hop ballad with a pop refrain, sung by Rihanna,", "melodic hard rock", "G\u00e9rard Depardieu", "rural", "Summerlin, Clark County, Nevada", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "the first four James Bond films", "Syracuse", "Kings Point, New York", "Robert Paul \"Robbie\" Gould III", "\"The Gang\"", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "on the Australian coast", "Faith", "Marge agrees to stay with her old prom date, Artie Ziff, for one weekend (on the grounds that he try not to grope her like he did in \"The Way We Was\")", "the Cleveland Celtics", "Everybody Hates Chris", "CHO", "eight", "the regime of Emperor Napoleon III", "Sippin' on Some Syrup", "James Harrison", "the third Viscount", "Arabella Churchill", "Lester Ben \"Benny\" Binion", "two Grammy awards", "the S7 series", "2017", "Qutab Ud - Din - Aibak", "14 November 2001", "Thomas Jefferson", "Luxembourg", "\u0153\u043e\u043b\u0434\u0430 \u041c\u0430\u0431\u043e\u0432\u0438\u0447; May 3, 1898 \u2013 December 8, 1978", "The Muffin Man", "President George Bush", "250,000", "Vernon Forrest", "Claudette Colvin", "blown", "real", "Jamie Lee Curtis"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6420190381127882}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.16216216216216217, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-3263", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_naturalquestions-validation-10202", "mrqa_triviaqa-validation-2994", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.546875, "CSR": 0.5338541666666667, "EFR": 0.896551724137931, "Overall": 0.6955343031609196}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Hillsborough", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "strata", "a living architect or architects whose built work demonstrates a combination of those qualities of talent, vision, and commitment", "Guy Fawkes Night", "a cat in the infrared.", "Port Moresby", "orange", "kursk nuclear submarine (C)", "pyrotechnic", "South Korea", "Annie Lennox", "a goose", "a superhero", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "Thomas Jefferson", "Ellice Islands", "Meta", "the 'Flower of Scotland'", "about a mile north of the village of Dunvegan", "a clarinet", "Spice Girls", "\"Mr Loophole\"", "Istanbul", "drinking song", "Texas", "Pablo Picasso", "Yalta", "Rajasthan", "African violet", "bali", "MetroLyrics", "the 11th Light Dragoons", "notorious Welsh pirate Edward Kenway, grandfather and father of Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway respectively", "Djokovic", "1912", "fennec", "1950", "\u041d\u0438\u043a\u043e\u043b\u0430\u0301\u0439 \u0421\u0435\u0440\u0433\u0435\u0301\u0435\u0432\u0438\u0447 \u0422\u0440\u0443\u0431\u0435\u0446\u043a\u043e\u0301 \u0439", "Vernon Forrest", "Linda Hogan", "development of two courses on the Black Sea coast in Bulgaria.", "Andrew Wyeth", "virus", "Steve Wynn", "substitute good"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5901041666666667}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_triviaqa-validation-3214", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-4090", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-9098"], "SR": 0.546875, "CSR": 0.5340485074626866, "EFR": 0.8275862068965517, "Overall": 0.6817800678718478}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less", "Phay Siphan, secretary of the Cambodian Council of Ministers.", "France", "tranquil beaches", "flooding", "bremen", "Secretary of State", "Ali Larijani", "nearly three out of four", "Fernando Caceres", "an Italian and six Africans", "lack of a cause of death and the absence of any soft tissue on the toddler's skeletal remains", "best-of-three series.", "the 11th century Preah Vihear temple", "Uzbekistan", "voluntary manslaughter", "Jenny Sanford", "Nevaeh", "Miami Beach, Florida", "\"Percy Jackson & The Olympians,\"", "contraband", "two contestants.", "Tiffany MacKeown", "the Southern Baptist Convention", "Graeme Smith", "former U.S. secretary of state.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old", "two Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies,", "terrorize", "two tickets to Italy", "Oxbow", "\"a potential hazard may occur due to re-entry of satellite debris into the earth's atmosphere.\"", "21-year-old", "Jacob Zuma", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call", "poll published by academics at Bahcesehir University,", "can also taste a hamburger and pizza, and drink coffee from a cup, the \"things we take for granted every day,\"", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Twitter", "1983", "Carolyn Sue Jones", "Hold On", "in Koine Greek : apokalypsis", "Phil Mickelson", "Dumbo", "skiffle", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "julie taymor", "Frank McCartney", "director", "batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5703471483713419}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.1935483870967742, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-190", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.515625, "CSR": 0.5337775735294117, "EFR": 0.9032258064516129, "Overall": 0.696853800996205}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura this year.", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "Chrysler", "AS Roma beat Lecce 3-2", "President Barack Obama,", "the Southern Baptist Convention", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally", "2000", "at least 300", "Thursday", "always hot and humid and it rains almost every day of the year.", "Israeli", "drama that pulls in the crowds", "2008", "root out terrorists within its borders.", "25 years", "a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford,", "in a remote part of northwestern Montana", "genocide", "allegedly involved in forged credit cards and identity theft", "Bailey, Colorado,", "John Demjanjuk", "Venus Williams", "Black History Month", "Doogie Howser, M.D.", "British", "Six", "He is obviously very relieved and grateful that the pardon was granted.", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down", "his past and his future", "Mombasa, Kenya", "a loanword of the Visigothic word guma `` man ''", "Taron Egerton", "Italy", "Hard Times", "purpurea", "Nellie Melba", "Clark Gable", "1947", "the backside", "Sweden", "garcinia cambogia", "Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6078733766233766}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.8, 0.13333333333333333, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.22727272727272727, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-2994", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337"], "SR": 0.53125, "CSR": 0.5337409420289856, "EFR": 0.7666666666666667, "Overall": 0.6695346467391305}, {"timecode": 69, "before_eval_results": {"predictions": ["line the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise, Nevada", "the Reverse - Flash", "Hathi Jr", "LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "by October 1986", "http://www.example.com/index.HTML", "solids", "1997", "Carol Worthington", "September 6, 2019", "1973", "1902", "SURFACE HEREA of ROOTS IS ENORMous", "back", "Battle of Antietam", "National Park Service's Shenandoah National Park in the Blue Ridge Mountains of Virginia", "Clarence Anglin", "Andrew Garfield", "under normal conditions", "the 1980s", "Pasek & Paul", "in a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "The White House Executive chef", "place of trade, entertainment, and education", "25 years after the release of their first record", "the bank", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu ( `` Master Sun '', also spelled Sunzi )", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "Mallee trees", "inflation", "Peter Scudamore", "John M. Dowd", "December 17, 1974", "Northrop P-61 Black widow", "26", "The woman who received the first-ever near-total face transplant in the United States", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6671491033831187}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true], "QA-F1": [0.9523809523809523, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6, 0.19999999999999998, 1.0, 0.08, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9411764705882353, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.4, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-710", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-6308", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-6937", "mrqa_newsqa-validation-1092"], "SR": 0.546875, "CSR": 0.5339285714285714, "EFR": 0.7586206896551724, "Overall": 0.6679629772167488}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "Longline", "Sebastian Vettel", "Niles", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "investment bank Friedman Billings Ramsey", "the NFL", "N 17 \u00b0 26 \u2032 48 ''", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "Linda Hamilton's real - life son Dalton Abbot", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Donald Trump", "100,000 writes", "1967", "Rajasthan", "Sodor", "the eye", "44,300", "the 2008 presidential election", "Anglo-Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "Humpty Dumpty", "Thailand", "500-room"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6681872321578204}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.4615384615384615, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-5392", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-7551"], "SR": 0.578125, "CSR": 0.5345510563380282, "EFR": 0.7037037037037037, "Overall": 0.6571040770083465}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "north-south ridge", "photographer", "a clown", "the Titanic", "the port of Brundisium (Brindisi)", "Hadrian", "Madagascar", "Barbizon school", "Michel Denance", "Manet", "Gary Sparrow", "Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "Honda", "Greenock", "ABBA", "Sonja Henie", "12", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess", "the University of Sydney", "Stieg Larsson", "music Stories", "1957", "a manhir", "steel", "Rotherham United", "Joseph Priestley", "a greyhound, gazelle hound or tazi", "international team competition in sport,", "Periodic Table", "CameroonCameroon (; ), officially the Republic of Cameroon", "region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuba", "ab extra", "Patience", "Ernest Evans", "Quentin Tarantino", "to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 12th hole", "San Francisco", "90s", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "monthly", "one of Europe's most experienced providers of carbon offset,", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "6 counties in Ulster", "in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past", "a peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6171879440181869}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.08695652173913042, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6465", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.578125, "CSR": 0.53515625, "EFR": 0.7777777777777778, "Overall": 0.6720399305555556}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "Thames", "Altamont Speedway", "The Jetsons", "26.22", "ankle joint", "overprotective clownfish", "Samson", "Connecticut", "Daedalus", "a critically burned English accented Hungarian man, his Canadian nurse, a Canadian-Italian thief, and an Indian sapper in the British Army as they live out the end of World War II in an Italian villa.", "augusta", "a goad", "Freddie Highmore", "up to 14", "radars", "Queen Elizabeth II", "spaino", "hippocampus", "Frank Miller", "international team competition", "Orwell", "Atlantic Ocean", "treaty of Waitangi", "chatsworth house", "dirk bikembergs", "London", "on your dog's eyelid", "wolfman Speights", "augusta", "aug. 24, 1572", "a fatty hump on their shoulders, drooping ears and a large dewlap", "Augustus", "South America's northern coast", "Southwest Airlines", "SUNSET BOULEVARD", "hopper", "Derwill Water", "sesame seeds", "Laos", "Allardyce", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "pasta spirals", "1768", "Joan Rivers", "Athens", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett", "Diego Milito's", "Dick Grayson", "Dumbo the Flying elephant", "Casey at the Bat", "pythons"], "metric_results": {"EM": 0.390625, "QA-F1": 0.49431371719678174}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.06451612903225806, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-5614", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.390625, "CSR": 0.5331763698630136, "EFR": 0.8205128205128205, "Overall": 0.6801909630751669}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "racehorse breeder and owner", "SS", "Edward James Olmos", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "pastels", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Knowlton School", "143,007", "Philadelphia", "7", "American former model, actress and television host.", "1968", "mathematician, physicist, and spectroscopist", "king Duncan", "The St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "main east-west road", "schoolteacher", "People v. Turner", "Bill Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng", "Herman Hollerith", "6 -- 14 July", "parashah", "paramitas", "1881", "journalism", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Jobs", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6483658989518364}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-1002", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.5625, "CSR": 0.5335726351351351, "EFR": 0.8928571428571429, "Overall": 0.6947390805984556}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid", "ketchup", "igdlu", "compound eyes of flies", "Timberland", "Former Texas governor and two-time Republican presidential candidate", "meanma naing ngan", "Latvia", "spleen", "farewell", "rely", "ramesses", "wine coolers", "the esophagus", "Dallas Cowboys", "the Bible", "twist", "Marie Tussaud", "Biscay", "ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "kolkata's red light district Sonagachhi", "an oblate spheroid", "The Aviator", "gioachino Rossini", "Veracruz", "tail", "Nashville", "hanging garden", "the Last Starfighter", "Billy Crystal", "skin cancer", "(Henry Ford)Cadillac Motor Car Company-Packard Motor Company-Paige-Detroit", "kbec", "pontificio", "Mimi Bobeck", "Onagraceae", "Moonlighting", "Corpus Christi", "self", "Ruth Bader Ginsburg", "Edward R. Murrow", "shallow embayment", "in vitro fertilization", "Diogenes Laertius", "pastries", "chocolate milk drink", "the Electric Company", "the following day", "Roger Dean Stadium", "March 31, 2013", "Helen Reddy", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "making her comeback last year after giving birth to baby daughter Jada, who was watching her mum from the stands again on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5792444923371647}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 0.0, 0.4, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4827586206896552, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-6585", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-10018", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-976", "mrqa_newsqa-validation-801"], "SR": 0.46875, "CSR": 0.5327083333333333, "EFR": 1.0, "Overall": 0.7159947916666667}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "1765", "The Miracles", "1900", "provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2009", "1963", "The Satavahanas", "the Central Board of Artisans", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK", "28 July 1914", "Lager", "908 mbar", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on a sound stage in front of a live audience in Burbank, California", "Allsup", "American singer - songwriter - actress Debbie Gibson", "Lula's", "31 January 1934", "at the mayor's home", "the southeastern United States of unresolved taxonomic identity", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "fermenting dietary fiber into short - chain fatty acids ( SCFAs ), such as acetic acid and butyric acid, which are then absorbed by the host", "20 year - old Kyla Coleman", "Bill Patriots", "December 19, 1971", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Dr. Joel S. Engel of Bell Labs", "Neil Young", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "forested parts", "arithmetic", "Finger Tab", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "President Felipe Calderon", "low-calorie meals", "0-0 draw", "Hapsburg", "Mexico", "coyote", "Majid Movahedi"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6761421783625732}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6842105263157894, 0.9523809523809523, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.6, 1.0, 1.0, 0.0, 0.8, 0.0, 0.9777777777777777, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7133", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-5571", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-1646"], "SR": 0.515625, "CSR": 0.532483552631579, "EFR": 0.9032258064516129, "Overall": 0.6965949968166384}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries", "Total Drama World Tour", "Christopher Lloyd", "senators", "rape", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "layered systems of sovereignty", "Authority", "Jughead Jones", "Los Lonely Boys", "the Great Plains and U.S. Interior Highlands region", "cakes", "Kiss", "from 18 September to 31 October", "Julie Adams", "During World War II", "Kirk Douglas", "January 2004", "Ella Eyre", "Hank J. Deutschendorf II", "Derrick Henry", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Tiffany Vallejo", "an anembryonic gestation", "acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IIII", "Virginia", "Saphira", "September 2017", "an Irish feminine name", "Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "the Isthmus of Corinth", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "a Bristol Box Kite", "EMI", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million", "San Diego", "CNN.com", "jazz", "echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6462612801428591}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [0.15384615384615385, 1.0, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7999999999999999, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-14736"], "SR": 0.5625, "CSR": 0.5328733766233766, "EFR": 0.75, "Overall": 0.6660278003246753}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Il Botticello", "metal", "pulsar", "Seth", "Honda", "\"Erroneous\" Number One", "Adolf Hitler", "Merchant of Venice", "FIFA World Cup 2010", "Elizabeth I", "June", "Italy", "1960", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "gin", "apples", "parochie", "Roddy Doyle", "discus thrower", "Separate Tables", "a multiple telegraph, using Morse code to convey several messages simultaneously, each at a different pitch.", "Beatrix Potter", "magpie", "comets", "swimming", "Kansas City", "Ra\u00fal Castro", "Bowie\u2019s first ever UK #1 single.", "Scotland", "UK Butterflies", "Illinois", "red", "Splash", "South Africa", "menorah", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "Asia", "Liam Cunningham", "Brobee", "Madrid", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency, part of the lawless Federally Administered Tribal Areas where U.S. and Pakistani officials have reported a presence of militants.", "Mashhad, Iran.", "Saint Bernard", "France", "Columbia University", "the equator"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6197172619047618}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.09523809523809525, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-5774", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7254", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.5625, "CSR": 0.5332532051282051, "EFR": 0.7857142857142857, "Overall": 0.6732466231684981}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Verdi", "April", "Al Pacino", "Britain", "subtraction rule", "William Golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "Director General of the Security Service", "Hell Upside Down", "Funchal", "phy Mulligan", "BBC\u2019s pasta harvest", "Northern Ireland", "passport", "Marcel Duchamp", "The Quatermass Experiment", "Mumbai", "a great invetor", "1875", "raven", "hound", "Ernie", "Estimate", "$12$", "Jawaharlal Nehru", "Richard Wagner", "arpad \u2018Arki\u2019 Busson", "Argentina", "acronym", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "prairies", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "Casino Square", "Endora", "springtime for Hitler", "Holocaust", "Eva Herzigov\u00e1", "David Hockney", "Ireland", "zulu", "Carrie", "Colombia", "the free and the home of the brave", "1 - 2 spinal nerve segments above the point of entry", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "Tudor music and English folk-song", "Martin O'Malley", "1992", "sculptures", "when people gathered outside as the conference in the building ended.", "al-Shabaab", "The Old Man and the Sea", "Edward I", "the Cranberries", "there were no radar outages and said it had not lost contact with any planes during the computer glitch."], "metric_results": {"EM": 0.546875, "QA-F1": 0.623483455882353}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.35294117647058826, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5155", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-5712", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.546875, "CSR": 0.5334256329113924, "EFR": 0.7586206896551724, "Overall": 0.6678623895133129}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS amethyst", "Libya", "tomato", "Kyoto Protocol", "Fancy Dress Shop", "bull moose", "exam", "Jake La Motta", "resistance of an unknown resistor", "hobbit McDaniel", "South Africa", "indigestion", "discretion", "breaststroker", "The Apprentice", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "pearls", "Bruce Jenner", "mafia", "bitches", "Duncan", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "publis", "mi Mullen", "The IT Crowd", "\u00ef\u00bf\u00bd", "local police officer Rip Nix", "mi bobby barley", "Richard Curtis", "\"Terms of Endearment,\"", "China", "lothbrok", "1790", "bayock", "catnip", "driving Miss Daisy", "orchid", "Hilary Swank", "Aberdeen", "latitude 90 \u00b0 North", "the 18th century", "UTC \u2212 09 : 00", "just 18 minutes", "England", "Sri Lanka Freedom Party", "\" Steamboat Bill, Jr.\"", "Afghanistan's Helmand province,", "Rodong Sinmun", "theology", "Daddy Long Legs", "sancire", "February"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6436458333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-889", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7034", "mrqa_naturalquestions-validation-3505", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-2116"], "SR": 0.59375, "CSR": 0.5341796875, "EFR": 0.7692307692307693, "Overall": 0.6701352163461538}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2 total", "dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Los Angeles", "1969", "Tim Passmore", "1965 -- 66 season", "first appeared in the Vulgate manuscripts of the 9th century", "the Canadian Rockies continental divide east to central Saskatchewan", "carbon dioxide in water ( carbonated water )", "Miami Heat", "2018 Major League Baseball season began on March 29, 2018, and is scheduled to end on September 30", "four", "manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association was established on 31 October 1851", "autopistas", "set to 0.05 ( 5 % )", "Australian reality television talent show which premiered on 18 February 2007 on the Seven Network", "A stack of thin films is called a multilayer", "Tulsa, Oklahoma", "Kristy Swanson", "from before", "Charles R Ranch, County Road 24, Las Vegas, New Mexico, USA", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "FBI Director briefed the President on any issues that arose from within the FBI until the Intelligence Reform and Terrorism Prevention Act of 2004 was enacted following the September 11 attacks", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "American Broadcasting Company ( ABC ), and premiered on September 28, 2017 with a special two - hour premiere", "Staci Keanan", "Brooklyn, New York", "1837", "lagaan ( English : Taxation ; also called Lagaan : Once Upon a Time in India )", "1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market (FX )", "Coppolas and, technically, the Farrow / Previn / Allens", "Sunday Post", "Karl Pilkington", "pei Tang", "1860", "\"Back to December\"", "Buck Owens and the Buckaroos", "\"Up\" mixes allegory with adventure and dumb imaginative exuberance.", "boyhood experience in a World War II internment camp", "off east  Africa", "modify", "Anne Juergens", "petticoats", "the skull and crossbones"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6844561688311688}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.4, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.4, 0.0, 0.09523809523809523, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.09090909090909093, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-1373", "mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-8711", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-5915", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.578125, "CSR": 0.5347222222222222, "EFR": 0.8518518518518519, "Overall": 0.6867679398148148}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "CAI Containers", "berenice", "nuclear warheads", "capitals", "ham", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "fauvism", "Alzheimer's", "Christopher Darden", "jenny", "gestation", "ravens", "J.R. R. Tolkien", "Dale", "Blue Ridge Mountain range", "British Guiana", "a mixture of iron oxide and aluminum oxide", "belly button", "Apple", "Thomas R. Gray", "catfish", "A Chorus Line", "piazza del Campo", "Robbie Turner", "not speaking", "Chloe Lattanzi", "Virginia", "College of William", "small", "Louisiana", "Vassar", "Japan", "cutlery", "The Police", "Air France", "Scarlatti", "laserated two of the children of his", "trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "falsetto", "Indian Ocean", "a syringe with a needle fine enough to pierce the skin", "robespierre", "nanosecond", "a bat", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "on location", "2010", "a ride cymbal", "Madagascar", "Cassio", "Estadio Victoria", "Allerdale", "Mugabe's opponents", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.5, "QA-F1": 0.5792038690476191}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.2, 0.0, 1.0, 0.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-6250", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_triviaqa-validation-7122", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868"], "SR": 0.5, "CSR": 0.5342987804878049, "EFR": 0.90625, "Overall": 0.6975628810975609}, {"timecode": 82, "before_eval_results": {"predictions": ["the Nautilus", "Hopi", "Vatican City", "Pope John Paul II", "Yangtze", "Gnarls Barkley", "the Parthenon", "My Therapist", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the National Gallery of Art", "4,047 m2", "the Baha de Darwin, Spanish for \"Darwin Bay\"", "( Giulio) Cavendish", "the Black Sox Scandal", "lynx", "Grenadine", "Constantine", "Aleutian", "alchemy", "art nouveau", "Autobahn", "Anglo-Saxon", "the California quail", "curtsy", "lacrosse", "Toronto", "acute", "King David", "Riboflavin", "tassels", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The hobbit", "Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "lace", "Ossie Davis", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "On the east", "Austria", "acai berry", "the Benedictine Order", "Pansexuality", "co- authorship", "getaway driver", "Drew Kesse", "the pregnancy.", "eight-week", "1872"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6767361111111112}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-13920", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-5031", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.609375, "CSR": 0.5352033132530121, "EFR": 0.84, "Overall": 0.6844937876506024}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "vulture", "Nantucket", "Ebony", "Cambridge University", "Algeria", "Joseph Haydn", "Richard Cheney", "the black market", "a number", "Saturday Night Fever", "(USA)", "pizza al taglio", "a turtle", "Empire State Building", "white blood corpuscle", "a picayune", "dogwood", "Qubec", "Larry McMurtry", "Kellogg's", "Helen of Troy", "sweatshirt", "W=Fd", "Napoleon", "gold", "Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Henkel & Cie", "Pancho Gonzales", "Aleutians", "Latter-day Saints", "Jane Grey", "Tommy Tutone", "the crescent moon", "Iraq", "an old grasshopper", "Nicolaus Copernicus", "Stuffed Poblano Chiles", "William Safire", "Santa Maria delle Grazie, Milan", "to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "Theodore Roosevelt Mason", "Parlophone", "9:20 p.m. ET Wednesday.", "DBG", "1995", "four"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6296875}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-502", "mrqa_hotpotqa-validation-3182"], "SR": 0.53125, "CSR": 0.53515625, "EFR": 0.8666666666666667, "Overall": 0.6898177083333333}, {"timecode": 84, "before_eval_results": {"predictions": ["Russia", "Catherine of Aragon", "Judas Iscariot", "Windsor, Ontario", "Stephen Douglas", "Comrade", "the Great Gatsby", "a fox", "sexuality", "Salaries", "a king", "John McEnroe", "a bicycle", "Johnson County", "Jericho", "push", "Alexander Solzhenitsyn", "an unnecessary farce", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "Manila", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "a pirate ship", "engrave", "Daisy Miller", "the Isis Medal", "X", "a ship", "Kalanikupule", "an owl", "Virginia", "Jerry Maguire", "the north magnetic pole", "oyster", "an Italian-American", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "season two", "A complex sentence", "40", "Neptune", "Nowhere Boy", "August 1973", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Carrefour", "financial gain", "concentration camps", "agent Mark Steinberg"], "metric_results": {"EM": 0.625, "QA-F1": 0.6640625}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-6488", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-6178", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-10285", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-11433", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-10841", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-3759"], "SR": 0.625, "CSR": 0.5362132352941176, "EFR": 0.9583333333333334, "Overall": 0.7083624387254902}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "(George) Washington", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "\"Strawberry Fields Forever\"", "The Hague", "Geena Davis", "pharmacy", "the American Empire", "has no teams based", "Doolittle", "the heart", "Queen Elizabeth I", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the NIV", "The X-Files", "Babar the elephant", "Mensa", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a Booster seat", "the Church of Jesus Christ of Latter-day Saints", "Veneto", "an acorn squash", "the Warsaw Pact", "Sparta", "The New York Times", "anode", "boldly go where no man has gone before", "Covington", "the Bicentennial", "the Chickasaw", "the epidermis", "the Texas Rangers", "Fluoxetine", "H CO ( equivalently OC (OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine", "has to move out of her rental house because it is facing foreclosure", "\"He is more American than German.\"", "Charles Sherrington"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5916666666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-6063", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-11773", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-151"], "SR": 0.53125, "CSR": 0.536155523255814, "EFR": 0.7333333333333333, "Overall": 0.6633508963178294}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a short race", "a Himalayan Yeti", "Joseph", "Chicago", "Helen", "Cannery Row", "Palatine", "California", "Mississippi", "Alpha", "Quebec City", "nacre", "Texas Chainsaw Massacre", "the rotunda", "a Medal of Honor", "Manet", "Plutarch", "Mediolanum", "Orlando", "Shropshire", "kidney", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "Millard", "Coarse", "Finnegans Wake", "aleikum", "the black market", "professor of higher education", "an earthquake", "Maastricht", "Delilah", "synapses", "a croissant", "Rocky Down Mexico Way", "lungs", "fuchsia", "metacarpal", "a pool", "Bern", "a trowel", "Mercury", "Taiwan", "Gettysburg", "Ibtihaj Muhammad", "trout", "slow", "1959", "season two", "$75,000", "Zimbabwe", "15", "Stonemason's Yard", "Agent Carter", "Orson Welles", "Manhattan", "56", "Secretary of State", "Bright Automotive", "James Hogg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6677083333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.609375, "CSR": 0.5369971264367817, "EFR": 0.84, "Overall": 0.6848525502873564}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "$72", "the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "Darren McGavin", "Milan, Italy", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Francis Ford Coppola", "$2 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "secession", "Donny Osmond", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "island countries", "Anakin Skywalker", "Alexander Salkind", "one", "Ricardo Chavira", "Ed Roland", "Kevin Garnett", "a star", "Brazil", "Instagram's own account", "Washington", "the 2nd century", "Triple threat", "1998", "Nicolas Anelka", "foreign investors", "Napoleon", "the inverted - drop - shaped icon that marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Watson and Crick", "Aconcagua", "Bake Off", "1924", "Noah Levenstein", "the zona glomerulosa of the adrenal cortex", "Fionnula Flanagan", "last summer", "impact the realities of homelessness", "three-time road race world champion, as well as a double winner of the women's Tour de France, and the clear favorite for gold in Seoul.", "banker", "eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5779737862302471}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.7741935483870968, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-5753", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-5696", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-3468", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-995", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.453125, "CSR": 0.5360440340909092, "EFR": 0.8285714285714286, "Overall": 0.6823762175324676}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany", "Philip Markoff", "a bag", "Roger Federer", "Veracruz, Mexico", "Diego Milito's", "They might leave a residue that can be picked up on the X-rays, interfering with the results.", "militants were plotting to attack two Shiite mosques, police stations, and a Norwegian telecommunications company in Punjab,", "Salt Lake City, Utah", "normal maritime traffic", "hansa (Malmborgsgatan 6)", "protecting ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "Two suspects are in custody.", "\"We want to reset our relationship and so we will do it together.'\"", "club managers", "Long Island", "90", "FBI", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "At least 14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl", "the military's \"Don't Ask, Don't Tell\" policy", "Europe", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Greeley, Colorado", "Festival Foods", "Molotov cocktails, rocks and glass.", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million people worldwide", "Krishna Rajaram", "a rocket", "Patrick McGoohan", "saying Chaudhary's death should serve as a warning to management, according to CNN's sister network in India, CNN-IBN.", "Hamas", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "the Yemeni port city of Aden", "federal officers", "Carl", "central business district of Bangkok", "journalists and the flight crew will be freed,", "petition for a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "Hague Conventions", "Robert Downey, Jr.", "Viscount Cranborne", "England", "beef", "Sleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5674784693466759}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 0.8, 0.0, 0.14285714285714288, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.07407407407407407, 1.0, 1.0, 1.0, 0.875, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.17391304347826086, 0.0, 0.8, 0.0, 0.33333333333333337, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.125, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_naturalquestions-validation-7950", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.453125, "CSR": 0.5351123595505618, "EFR": 0.6571428571428571, "Overall": 0.6479041683386838}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Sun Woong", "president of Guggenheim Partners", "Comedy Film Nerds", "9\u201310 March 1945", "2011", "John D Rockefeller's", "early 1970s", "Asiana Town building", "American R&B", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks", "Fiat Group", "Chrysler", "Australian", "gorillas", "\"Traumnovelle\" (\"Dream Story\")", "The Royal Navy", "Robert Digges Wimberly Connor", "Brad Wilk", "the Beatles", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "\"Haunted R\" (2009)", "95 AD", "University of Groningen", "French", "\"The Manhunter from Mars\"", "Mondays", "Michael Jordan", "Snowball II is killed off,", "HSBC Main Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "1822", "\"Smile, Mom\" (2010)", "Suspiria", "The Independent", "Kansas\u2013Nebraska Act of 1854 (10 Stat.  277 ) created the territories of Kansas and Nebraska and was drafted by Democratic Senator Stephen A. Douglas of Illinois and President Franklin Pierce.", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "June 5, 2017", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "CNN's \"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "housing, business and infrastructure repairs, federal authorities said."], "metric_results": {"EM": 0.609375, "QA-F1": 0.6724180692391899}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.13793103448275862, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-3198", "mrqa_hotpotqa-validation-5440", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.609375, "CSR": 0.5359375, "EFR": 0.76, "Overall": 0.668640625}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2009", "singer", "Pakistan", "1754", "\"Confessions of a Teenage Drama Queen\"", "Bundesliga", "valkyries", "David Villa", "Adrian Peter McLaren", "from 2010 to 2013", "an early colonist of South Australia, remembered as a schoolmaster at J. L. Young's Adelaide Educational Institution and at Saint Peter's College.", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Fuli", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "Heathrow", "Binaural", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama", "Scandinavian design", "Donald Trump", "Thomas Perez", "Flexible-fuel", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian Church (USA)", "138,535", "Ry\u016bky\u016b minzoku", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravity", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert Barnett,", "Sally Ride doll", "Diane Cilento", "CO2", "Shout"], "metric_results": {"EM": 0.546875, "QA-F1": 0.642166201099625}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.787878787878788, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.30434782608695654, 1.0, 1.0, 1.0, 0.2564102564102564, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5509", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-4050", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743"], "SR": 0.546875, "CSR": 0.5360576923076923, "EFR": 0.7586206896551724, "Overall": 0.668388801392573}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Apple", "Jaguar S-Type", "the Gateway Arch", "Friday", "Sabino Canyon", "Depp", "Babe Ruth", "housewife", "Arkansas", "Vince Lombardi", "Libra", "Contemporary Art", "Steppenwolf", "bcolicus", "Tito Puente", "Hydrogen", "Johnny Cash", "Hodgkin's lymphoma", "Margaret", "Las Vegas", "San Francisco", "\"forever Amber\"", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "The Wright Brothers", "Badminton", "John Deere", "43", "Pontiac", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro's tomb", "Babylon", "Jean-Paul", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a spirit-lifting jingle", "Bobby Brown", "Bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "sailboat, namedthia Woods, was one of about two dozen boats heading from Galveston, Texas, to Veracruz, Mexico,", "Monday", "eight", "minister and biographer"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6597470238095238}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19047619047619047, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-16068", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_hotpotqa-validation-4539"], "SR": 0.546875, "CSR": 0.5361752717391304, "EFR": 0.8275862068965517, "Overall": 0.6822054207271364}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico Virginia", "the East River", "William Shakespeare", "William Shakespeare", "abscesses, ulcers and mucous membranes", "Alaska", "Sputnik", "Richmond, Virginia", "the period of program music", "Java", "Haydn", "Blanche DuBois", "inseparable", "room-temperature vulcanization", "Wuthering Heights", "Muhammad", "Sofia Scicolone", "the Curse of the Black Pearl", "Frederick Forsyth", "Chesterfield", "a chipmunk", "Josephine", "salt", "a disorderly Conduct", "Rossini", "Oman", "Spmi", "Tom Canty", "Andrzej Wajda", "Didion", "the frigate", "Baltimore", "the Bay of Bengal", "(1735-1777)", "Clinton", "Terrific", "time scale", "six sides", "Olympia", "the Ship of Fools", "Haunted", "tendang", "Color Splash", "Margaret Mitchell", "Frances", "Toorop", "cremation", "the French & Indian War", "a manic episode", "central Saskatchewan", "lighter", "a scuffle with the Beast Folk", "Judi Dench", "Germany", "Caernarfon", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.46875, "QA-F1": 0.564236111111111}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15084", "mrqa_searchqa-validation-11893", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.46875, "CSR": 0.5354502688172043, "EFR": 0.8529411764705882, "Overall": 0.6871314140575585}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Tony Orlando and Dawn", "Stephen Schwartz", "2017", "drivers who were 2016 Pole Award winners, former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "over the next seven years until the last coin, a gold sovereign, was struck in London in November 1975", "Pacific Grove", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Goku's body in red fur", "Audrey II", "January 2017", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmoker", "13 May 1787", "Prince James, Duke of York and of Albany ( later King James II & VII )", "to feel close to his son", "Seattle, Washington", "honey bees", "Article 1, Section 2, Clause 3", "McFerrin", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "ice giants", "hyperinflation", "1939", "Richard Masur", "Regina Hall", "Spanish", "Sauron", "Lana Del Rey", "statistical", "159", "The Third Five - year Plan", "Chemistry professor E.H.S. Bailey and his colleagues were returning by train to Lawrence after a conference", "a bridal shop", "increases the life of the pump, allows a smaller and lighter device to be used, and reduces electrical load", "limited period of time", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood", "nide", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "Da Vinci Code", "humiliate herself by standing next to a story,\"", "Khrushchev", "Julie Andrews", "Ichabod Crane", "Leo Frank, a northern Jew who'd moved to Atlanta to supervise the National Pencil Company factory."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6158944341688907}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9259259259259259, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.25, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.17391304347826086, 0.30769230769230765, 1.0, 0.2, 0.0909090909090909, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-105", "mrqa_newsqa-validation-3849"], "SR": 0.53125, "CSR": 0.535405585106383, "EFR": 0.7, "Overall": 0.6565342420212766}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "ThonMaker", "Battle of Chester", "youngest TV director ever", "1864", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away.", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League (NBDL)", "Neville Chamberlain,", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural", "8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "CMYK inks", "Las Vegas Boulevard", "The Bridge Between Science and Theology", "Anthony Herrera", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Uzumaki", "Kansas", "nearly 80 years", "Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music.", "The Wachowskis", "Pour le M\u00e9rite", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "chronicler, whose work, commonly known as \"Holinshed's Chronicles\", was one of the major sources used by William Shakespeare for a number of his plays.", "August 9, 2017", "Commonwealth Universities", "1 April 1985", "Australia", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "giant planet", "alveolar process", "Duisburg", "Hugh Quarshie", "Maria Feodorovna", "Tokyo", "Utah Valley Regional Medical Center", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "an average of 25 percent"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6978864261347815}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false], "QA-F1": [0.8333333333333333, 0.0, 1.0, 1.0, 0.5, 0.3157894736842105, 0.2857142857142857, 0.8, 1.0, 0.888888888888889, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.47619047619047616, 1.0, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-2928", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056", "mrqa_newsqa-validation-2361"], "SR": 0.546875, "CSR": 0.5355263157894736, "EFR": 0.7241379310344828, "Overall": 0.6613859743647913}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million", "Ben Ainslie", "1978", "Spoorloos", "Scott Mosier", "1945", "Roy Warren Spencer", "1964", "Shawnee Mission Parkway", "VH1", "London Review of Books", "Russian", "Harrison Ford", "July 25 to August 4", "Claude Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress, and radio and television presenting", "Northern Lights", "non-alcoholic", "Mach number", "Jordan Ridgeway", "Maine", "Encore Las Vegas", "Baa, Black sheep", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "Dame Eunice Mary Kennedy Shriver", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor at some institutions in the United Kingdom and Ireland, or a Deputy Vice-Chancellor (Academic) at most Australian universities", "Song Il-gon", "Teenitans Go!", "Mickey Mouse cup", "three", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "seal hunting", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers women's basketball team", "Metro-Goldwyn-Mayer", "P.O.S,", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La Fenice", "week", "Da Vinci Code", "Dog patch Labs", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.578125, "QA-F1": 0.709920634920635}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 0.4, 1.0, 0.22222222222222224, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-1151", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_triviaqa-validation-4831", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-191", "mrqa_searchqa-validation-14503"], "SR": 0.578125, "CSR": 0.5359700520833333, "EFR": 0.8518518518518519, "Overall": 0.687017505787037}, {"timecode": 96, "before_eval_results": {"predictions": ["Prince Sung-won", "1927", "16,116", "the 2012 Summer Olympics", "end of the 18th century", "1942", "Cash and Jennings", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "the Bears", "Gillian Leigh Anderson", "The Sun", "Ice Princess", "the Games of the Olympiad", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored Labrador Retriever", "Norman Graham Hill", "1952", "Neneh Mariann Karlsson", "Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "imp My Ride", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "an Indian", "Francis Kelly", "early Romantic period", "approximately $700 million", "the Sun", "Bhushan Patel", "24 December 1692", "interstate commerce", "The Wu-Tang Clan", "Kids", "Mortal Kombat X", "Kew Gardens", "third season", "May 2016", "Kristy Swanson", "manager", "Conan Doyle", "scalene", "put a lid on the marking of Ashura", "Pakistan", "homicide", "bread dessert", "leather", "cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7483022186147186}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.18181818181818182, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-619", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-5395", "mrqa_hotpotqa-validation-2482", "mrqa_hotpotqa-validation-4514", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-13280"], "SR": 0.578125, "CSR": 0.5364046391752577, "EFR": 0.8888888888888888, "Overall": 0.6945118306128293}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddy Redmayne", "Caucausus", "David Bowie", "John Spencer", "Granada", "Treaty of Brest-Litovsk", "Karl Marx", "Procol Harum", "Marilyn Monroe", "cyanoguttatus", "1957", "1876", "Transvestite/Cross dresser", "Roderick Astaire", "greece", "Scotland Yard", "Inverness-shire", "Friday's", "winnie Mae", "Rudyard Kipling", "1921", "Trainspotting", "Emilia", "avocat", "Frans Hals", "Syriza", "Ford", "soy", "Frank Sinatra", "1826", "w WJacobs", "the Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet", "elephant", "Tigran Petrosyan", "asthma", "Westminster Abbey", "Canada", "Seal", "eGBERT 827 - 839", "Tombstone", "s\u00e3o Miguel", "Mr. Tickle", "Worcester Cathedral", "Mercury", "December 7, 1941", "the stapes", "Nadia Comaneci", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "VAQ-135", "95 AD", "more than 170", "\"Gossip Girl\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.484375, "QA-F1": 0.559375}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, false, false, true, false, false, true, false], "QA-F1": [0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7127", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-3536", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-6624", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.484375, "CSR": 0.535873724489796, "EFR": 0.6666666666666666, "Overall": 0.6499612032312926}, {"timecode": 98, "before_eval_results": {"predictions": ["he'll send a text message and e-mail to his supporters to let them know who his sidekick will be.", "Afghanistan", "geologists have found evidence that soldiers from Hitler's Wehrmacht -- the German armed forces -- had been there: machine guns, parts of uniforms and explosives", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems telling of the pain and suffering of children just like her; girls banned from school, their books burned, as the hard-core Islamic militants spread their reign of terror across parts of Pakistan.", "then-Sen. Obama", "women", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Former Mobile County Circuit Judge Herman Thomas", "pastors", "Iraq's autonomous region of Kurdish.", "Phillip A. Myers.", "I started my theme song, \"Swingin' Down the Lane.\"", "to share personal information.", "Argentinean and 255 British", "in his 60s,", "al-Maliki", "France", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "dreamers", "WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.", "Austin, Texas,", "17-month", "to pay him a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party centered around Rush Limbaugh.", "for death squad killings carried out during his rule in the 1990s.", "in the design stage", "sniff out cell phones.", "Womack Army Hospital at Fort Bragg,", "American Bill Haas", "Used Acura", "28 states", "step up.\"", "42 years old", "since 1983", "improve health and beauty.", "almost 100", "Espinoza Barron's", "I heard they were doing a new \"Friday the 13th,\" and I've never tried to pursue a role before and I went, I really want to do this.", "\"We know this can be done,\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "18th", "prisoners story, including the name, where he is in jail and how long the term will be.", "Armenia", "Asuka", "Bart Millard", "Nissan", "stone arch bridges", "Jane Austen", "the Marx Brothers film", "Indian", "early 20th-century Europe.", "hold business' IT systems hostage", "Shakespeare in Love", "w. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4773648301276252}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, true, true], "QA-F1": [0.14285714285714285, 0.0, 0.0, 0.9210526315789475, 0.0, 0.0625, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.8333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.35294117647058826, 1.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.2105263157894737, 0.0, 1.0, 0.3636363636363636, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.4, 0.0, 0.3636363636363636, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-2182", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-3008", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-2610", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-3208", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2255", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191"], "SR": 0.328125, "CSR": 0.5337752525252526, "EFR": 0.7674418604651163, "Overall": 0.6696965475980738}, {"timecode": 99, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.705078125, "KG": 0.5109375, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "M or Ma", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota", "most performed song of all time", "Oregon Ducks", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "Pain Language", "Broadcasting House in London", "lexy Gold, a teenage high school student who investigates a mystery after one of her teachers goes missing.", "sitcom", "Lily Hampton", "President of the United States", "Big Machine Records.", "constant support from propaganda campaigns.", "The Heirs", "Saturday Night Live", "mother goddess", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle cities", "Suspiria", "Silvia Navarro", "22,500 acres", "Warsaw, Poland", "Nelson County", "Kang", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "the MC5", "James City County", "Tunisian", "Linda Ronstadt", "the United Kingdom", "21st birthday", "the Americas and the entire South American temperate zone", "Sister, Sister", "five", "Mark Radcliffe", "The club will participate in the Premier League, FA Cup, EFL Cup (as holders), UEFA Champions League and UEFA Super Cup.", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Frank Zappa", "1991", "apples", "Fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Fernando Torres", "Friday,", "Lifeboat", "a kilobyte", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6630408653846154}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_searchqa-validation-572"], "SR": 0.578125, "CSR": 0.53421875, "EFR": 0.9629629629629629, "Overall": 0.6957644675925925}]}