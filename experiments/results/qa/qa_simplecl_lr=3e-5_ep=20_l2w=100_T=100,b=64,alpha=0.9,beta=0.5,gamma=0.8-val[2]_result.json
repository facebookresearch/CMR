{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8580, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normans, Viking", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia, Belarus, and Moldova"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 0.6666666666666666, "Overall": 0.7669270833333333}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "civil disobedience", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "historical political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial and... Three major Spanish cities that are located on the Mediterranean coast are... on both the Atlantic Ocean and the Mediterranean Sea", "it is well written", "'Twas the Night Before Christmas", "guardian", "Constitution Day  Founding Father Roger Sherman from the State of Connecticut is a signer to the U.S. Constitution in September 17, 1787", "the first... a ticket from Panama to San Francisco in the steamer Oregon", "guardian", "time goes", "Reviews, discussion, Bookclubs, lists", "the division of the...   Department of Chemistry -UPMC - University Pierre and Marie...  Head of the Chemistry Department", "abolitionists", "5562"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7031520562770562}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.65625, "CSR": 0.796875, "EFR": 0.8636363636363636, "Overall": 0.8302556818181819}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double", "August 1967", "German", "27-30%", "four", "philanthropic initiative", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Warsaw", "time and space", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail and a carnivorous octopus", "Orestes", "Some grow to an immense size", "the term \"act of terror\"", "the process by which water changes from a liquid to a gas", "the Travel Detective: How to Get the Best Service and the Best deals from Airlin", "a really liquid cereal", "Inks, in which colour is imparted by... the replacement of many inorganic pigments such as chrome yellow,... alloy powder (gold bronze) are used in novel silver and gold inks", "the Mycenaean kingdoms, the Hittite Empire", "a biological process that displays an endogenous, entrainable", "the Belasco Theatre 111 W. 44th Street", "the Normandy Landings, a group of U.S. soldiers go behind enemy lines to", "Evelyn \"Billie\" Frechette", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6637919372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-397", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-1775", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.640625, "CSR": 0.7578125, "EFR": 0.8695652173913043, "Overall": 0.8136888586956521}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Latin Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "capturing prey", "C4", "pasture for cattle", "Victorian", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen", "eight", "A computational problem", "WZM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer", "50-yard line", "3D printing technology", "Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "Intel (or any company) based on 10% of global annual revenues", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block is next to his shoulder, with shattered pieces of it around him", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester United", "Noriko Savoie", "three", "change course", "Tsvangirai", "cowardly lion", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a 100% pure and natural sweetener made and stored in honeycombs by the honey bees", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.625, "QA-F1": 0.6866802647783251}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.06896551724137931, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.2666666666666667, 1.0, 0.0, 0.2, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.0, 0.14285714285714288, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-8874", "mrqa_squad-validation-2984", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-6092", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.625, "CSR": 0.73125, "EFR": 0.875, "Overall": 0.803125}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "King Ethelred II", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "British", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant", "Goa", "D, E or F", "the Louvre", "Leo Frank", "as he tried to throw a petrol bomb", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle", "the release of the four men", "putting a personal and human face on the issue", "Johnny Carson", "This will be the first time any version of the Magna Carta has ever gone up for auction, according to David Redden, vice chairman of Sotheby's.", "No. 2 man (or woman)", "end of a biology department faculty meeting at the University of Alabama in Huntsville", "Ali Larijani", "policing the world and Africa", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "supporting fuel economy and safety while boosted the economy", "heart rate that exceeds the normal resting rate", "a jolly, solid, nutritious character, which describes the Suffolk perfectly.", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6760374050936164}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.609375, "CSR": 0.7109375, "EFR": 0.6, "Overall": 0.65546875}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight line", "the autumn of 1991", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1.", "nerves", "1700", "the New Germany", "polyhydroxy aldehydes and ketones", "Howard Dean III (born November 17, 1948) is an American politician who served as the 79th Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "the heart, blood, and blood vessels.", "\"Wild Thing\", he played the ocarina as well", "six literal ordinary days", "Bratislava, this country's capital", "Diana, the Princess", "slave-trade", "pulmonary veins carry oxygenated blood from the lungs into the left atrium", "a fossil clam, now known as Chesapecten jeffersonius, which appeared in Lister's... to the fossil from Virginia", "Bullseye, or bull's-eye, is the centre of a shooting target,", "Tartarus", "\"cyc\" is short for this type of backdrop that suggests infinite space behind the performer.", "Nancy Reagan", "Bardiya, the king he killed & replaced, had been an impostor", "Fractional Ownership", "Count Ferdinand von Zeppelin", "huge", "Duke of Clarence, third son of George III and King of England", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas!", "Hurley", "The Walking Dead ( comic book ), a comic book series by Robert Kirkman, Tony Moore, and Charlie Adlard first published in 2003", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5327329048606623}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.125, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-8993", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.484375, "CSR": 0.6785714285714286, "EFR": 0.8181818181818182, "Overall": 0.7483766233766234}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "little support", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Eisenhower Freeway", "Thanksgiving", "86.66% (757.7 sq mi or 1,962 km2)", "Two thirds", "the Privy Council", "well into the nineteenth century", "capacity deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "The Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rodeo", "hog", "Barack Obama", "Kenny G", "a small, half size cup used for serving espresso", "puffalump", "Annapolis", "Spring Awakening", "klammeraffe", "Artificial female ones", "al- ilah", "child", "South American snake", "The Bible: In the Beginning", "Phillip", "Faith Hill & Tim McGraw", "Ben Affleck", "Sandy was not a hurricane when it made landfall.", "Germany", "geologic time", "Yardbird and Bird", "Sweden", "Thailand", "94 elements exist naturally, although some are found only in trace amounts and were synthesized in laboratories before being found in nature.", "destroyed", "Perfume: The Story of a Murderer", "the New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state,", "Georgetown", "Essex Eagles", "Alzheimer's"], "metric_results": {"EM": 0.5, "QA-F1": 0.5658717105263158}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.4, 0.3157894736842105, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-3893", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-15487", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_naturalquestions-validation-10073", "mrqa_triviaqa-validation-3911", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.5, "CSR": 0.65625, "EFR": 0.84375, "Overall": 0.75}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu in the north", "silent", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "Pierre Puget", "the Anti-Atlas", "Madrid", "the Danube", "Yahweh", "leather", "George Mortimer Pullman", "plums", "Jesus Christ", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "Frangipanis", "Dividing", "Hypnos", "Texas", "International House of Pancakes", "a white breed", "the Bill of Rights", "an optional writing test", "Brazil", "Walden", "Southern California", "Harry Whittington", "the Earth", "William Donald Scherzer", "Jack B Yeats", "the Central Intelligence Agency", "d'Artagnan", "Vnus impudique", "1985", "apples", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5147081500172532}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-13837", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-14640", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.4375, "CSR": 0.6319444444444444, "EFR": 0.7777777777777778, "Overall": 0.7048611111111112}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "Second World War", "integer factorization problem", "Scottish independence", "exploration", "prep schools", "soft power", "Islamist", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Alexei Kosygin", "Hera", "the vine", "Elton John", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Washington State", "Carmen", "Genoa", "15", "tarn", "972; 451; 100; or 25", "buffalo", "Ann Widdecombe", "scalene", "Old Kent Road", "Tuesday", "anhydrous copper sulfate (CuSO4)", "Ab Fab", "Massachusetts", "Barrow, Carlisle, Whitehaven and Workington", "California", "the Susquehanna River", "Kajagoogoo", "maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "What Price", "Grover"], "metric_results": {"EM": 0.609375, "QA-F1": 0.690922619047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.609375, "CSR": 0.6296875, "EFR": 0.84, "Overall": 0.73484375}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Lord's Enclosure", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult, if not impossible", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "eyes", "stone", "Ken Russell", "Dan Dare", "Sulla", "Smiths", "Mike Tyson", "Morocco", "Pesach", "Brian Deane", "oscope", "Uranus", "Apollo", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "pouk", "\"beyond violet\"", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "the New Haven Railroad", "The Marriage Contract", "Christian Dior", "a shaggy, candy-loving dog", "Mendip", "Wichita", "communion", "New Croton Reservoir in Westchester and Putnam counties", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "a \"independent jurist\" with a \"sharp and agile mind\" who would bring \"a wealth of unique experience\" to the high court.", "\"Ni!\"", "Roman Polanski"], "metric_results": {"EM": 0.640625, "QA-F1": 0.65625}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-2022", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.640625, "CSR": 0.6306818181818181, "EFR": 0.782608695652174, "Overall": 0.7066452569169961}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network headquartered in San Jose, CA that utilized virtual call packet switched technology", "public service", "Guy de Lusignan", "tiger team", "B cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hez-bah-lah", "five", "Whist", "Nile River", "Toscana", "vision loss, especially in bright light, to which they are extremely sensitive.", "choroid", "Pluto", "iron", "copper", "Hague", "Victoria", "Ironside", "John le Carr\u00e9", "g Gorky", "brown trout", "Beyonce Knowles", "Wordsworth", "Man V Food", "Queen Elizabeth II", "J. Dodsley", "Ed Chernoff", "Mary Poppins", "Bennett Cerf", "calcium, magnesium, phosphorus and potassium", "hudd", "Crimea", "Shrek", "Oslo", "horses", "rhododendron", "\"All That Jazz\"", "Franklin D. Roosevelt", "Shanghai", "gile de Becque", "boat lifts", "Billy Colman", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "tituchin", "Edgar Allan Poe", "titular"], "metric_results": {"EM": 0.5, "QA-F1": 0.6110639880952382}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.9166666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4510", "mrqa_squad-validation-8252", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-2059", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.5, "CSR": 0.6197916666666667, "EFR": 0.75, "Overall": 0.6848958333333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "a majority in Parliament, a minority in the Council, and a majority of the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "bonobo", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack Kilby", "Ryan Babel", "Ramzan Kadyrov", "July 16, 1971", "1933", "\"The Heirs\" (2013), \"Descendants of the Sun\" (2016) and \"Fight for My Way\" ( 2017)", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca Hopkins", "Daniel Hale Williams Preparatory School of Medicine", "England", "Paul W. S. Anderson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "opium poppies in Taliban-controlled Helmand province", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "dr. Dre", "little Miss Muffet", "pre-Columbian times, the American Bison, is difficult to domesticate and was never domesticated by Native Americans"], "metric_results": {"EM": 0.703125, "QA-F1": 0.724546568627451}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7200000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.11764705882352942, 0.04761904761904762, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_naturalquestions-validation-8227"], "SR": 0.703125, "CSR": 0.6262019230769231, "EFR": 0.8421052631578947, "Overall": 0.7341535931174089}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000 years", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "The Five Doctors", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "a psychophysical training or the method of physical action", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Firestorm\", \"The Spectre\", and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Gilbert du Motier", "Indian", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "6", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Johnny Cash", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "2015", "1982", "rod", "Chris Robinson", "g gossip Girl", "euler equations", "angno or Lorre", "Big Blue Woman", "London Festival Orchestra"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6367708333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.4, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7200000000000001, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5625, "CSR": 0.6216517857142857, "EFR": 0.7857142857142857, "Overall": 0.7036830357142857}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "2009 onwards", "religious freedom", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population.", "the kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "time and storage", "Vistula River", "100 to 150", "Apple's new iOS5 operating system, meaning its ability to run apps, surf the Web and the like will maintain its unofficial status as the iPhone-without-a-phone.", "a dormitory parent mistreated students at the school.", "March 8", "Democrats and Republicans", "Catholic League", "Half Moon Bay", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "\"We essentially closed the wheelhouse doors. I went to the port side, and I looked out up at the derrick.", "she also told FBI agents Lisa's parents never mentioned anyone wanting to harm them", "milk", "Lance Cpl. Maria Lauterbach", "South Korea's newest plant claims it is designed to go green.", "London", "400", "Val d'Isere, France earlier this year", "the results by a chaplain about 1:45 p.m., per jail policy.", "a municipal building in Baghdad's Sadr City", "21 percent", "1616", "Sky", "Chile", "Half Moon Bay", "Buddhism", "J. Crew", "Japanese", "mood-shifter", "British author J.G. Ballard, whose boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun,\"", "get on with his life", "4 meters (13 feet) high", "the Irish capital", "Democrat", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "roald Dahl", "mercury"], "metric_results": {"EM": 0.3125, "QA-F1": 0.38799507595363575}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08333333333333334, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 0.27272727272727276, 1.0, 0.6666666666666666, 0.8750000000000001, 0.7555555555555554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818181818181818, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2608695652173913, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.3125, "CSR": 0.6010416666666667, "EFR": 0.6818181818181818, "Overall": 0.6414299242424242}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "the Quaternary period", "1870", "water", "a prime number", "50 fund", "Camisards", "over $40 million", "GTE.", "1,100 tree species", "spinat", "Oligocene", "Melodie Rydalch,", "Charles Darwin", "at a Little Rock military recruiting center", "March 24", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"We are here to cooperate with anyone and everyone that will help us find the guilty party, and return Lisa home safely,\"", "56", "Fred Bright, the district attorney in Milledgeville, Georgia,", "\"The Da Vinci Code\"", "Heshmatullah Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Atlanta", "resources", "highest ranking former member of Saddam Hussein's regime still at large, salutes the \"People of Palestine\" and calls on them to fight back against Israel in Gaza.", "two", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"  - the central attraction of golf remains at all the film's core.", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing Friday, a federal magistrate said Monday.", "President Bush", "a hospital in Amstetten, where staff grew suspicious and called police, who opened an investigation and uncovered the abuse.", "African National Congress Deputy President Kgalema Motlanthe", "spiral into economic disaster.", "resigned as leader of the ruling political party Monday following a poor showing in Sunday's elections, the official news agency Telam reported.", "The security is less kinetic", "a strict interpretation of the law, which forbids girls from attending school, requires veils for women and beards for men, and bans music and television.", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit on TV shows filmed or produced in the state,", "July 23.", "70,000 or so", "The surveillance-camera video, shot May 11, shows a man wearing a baseball cap, dark jersey, blue jeans and running shoes entering a store, walking to the back and looking around, then walking out.", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a published campaign setting or a homebrew campaign setting", "Beno\u00eet Jacquot", "topaz", "Library of Congress", "The Left Book Club", "holography"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5902805224761504}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.07407407407407407, 1.0, 0.4444444444444445, 1.0, 0.5, 0.6428571428571429, 0.28571428571428575, 1.0, 1.0, 0.20689655172413793, 0.0, 0.13333333333333333, 0.24000000000000002, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.11764705882352941, 0.4444444444444445, 1.0, 0.06451612903225808, 0.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.3, 0.045454545454545456, 1.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-4349", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.484375, "CSR": 0.59375, "EFR": 0.696969696969697, "Overall": 0.6453598484848485}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "housing bubble", "137", "Adam Lambert and Kris Allen", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary misdemeanor", "foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "injuries,", "30 years ago", "murder", "next year", "Despite Gration's comments, the Obama administration has not yet articulated a Sudan policy.", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire, does that mean it would use it against Israel?", "brutal", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up", "\"Perfidia,\" \"Walk Don't Run '64\" and \"Diamond Head.\"", "tears of a Native American Indian", "1 million", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday", "women", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "in July she laid 11 healthy eggs and, this week, all 11 of them hatched", "have expressed concerns about the missile defense system. While Poland and the Czech Republic have agreed to host parts of the system, others in Europe share Russian concerns that the defensive shield could be used for offensive aims.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "Fullerton, California,", "World War I", "1950s", "U.S. troops", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "More than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "\"Three Colours\" Trilogy, themed on the French Revolutionary ideals of liberty, equality, and fraternity;", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6185201343795095}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6923076923076924, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.16, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.125, 0.3, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.06666666666666667, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.546875, "CSR": 0.5909926470588236, "EFR": 0.6896551724137931, "Overall": 0.6403239097363084}, {"timecode": 17, "before_eval_results": {"predictions": ["lower", "in hospitals", "questions and answers", "(sed vigilat)", "Captain Francis Fowke, Royal Engineers, who was appointed by Cole.", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "an initial report outlining its findings and recommendations", "\"Mad Men\"", "Windsor, Ontario,", "$50", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a visitor's visa and bus ticket to Johannesburg.", "killings of Indians", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher", "The exact cause of IBS remains unknown,", "in the north and west of the country,", "forcibly drugging", "introduce legislation Thursday, to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22", "Spain", "how health care can affect families.", "Appathurai", "U.S. Food and Drug Administration", "Dominican Republic", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "Lashkar-e-Tayyiba (LeT)", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "beat", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bky\u016b people", "surrealism", "C. S. Lewis", "281 8 1 2", "sake", "Halifax"], "metric_results": {"EM": 0.53125, "QA-F1": 0.597372153989801}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3529411764705882, 0.25, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.4, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-6359", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695"], "SR": 0.53125, "CSR": 0.5876736111111112, "EFR": 0.7666666666666667, "Overall": 0.6771701388888889}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "The European Court of Justice", "bronze", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "British", "\" Teen Patti\" (\"Card Game\")", "Argentina", "Congress", "28", "Frank Ricci", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "saying Tuesday the reality he has seen is \"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "requiring the label warnings and a medication guide for fluoroquinolone drugs, which include Cipro, Levaquin, Avelox, Noroxin and Floxin.", "political and religious", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "a violent and brutal extremist group with a number of individuals affiliated with al Qaeda.", "skull", "providing the basic securities that Turkey can be a great partner.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "because they were being discriminated against on the basis of nationality.", "Ben Roethlisberger", "Dr. Christina Romete,", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "Paul McCartney and Ringo Starr, to celebrate the anniversary of Cirque du Soleil's \"Love,\" which uses the Beatles' music.", "prisoners' rights and better conditions for inmates, like Amnesty International.", "President Obama's race in 2008.", "Brazil", "Saluhallen,", "burned genitals", "two people", "40", "Iranian consulate in Peshawar", "Casey Anthony, 22,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "Kirk Lazarus", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.484375, "QA-F1": 0.582054288930004}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.8571428571428571, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.45454545454545453, 0.33333333333333337, 0.10810810810810811, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-2165", "mrqa_newsqa-validation-1603", "mrqa_newsqa-validation-1000", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-9338"], "SR": 0.484375, "CSR": 0.5822368421052632, "EFR": 0.6060606060606061, "Overall": 0.5941487240829346}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid", "most of those who managed to survive the incident hid in a boiler room and storage closets", "that the Bainbridge would be getting backup shortly.\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones.", "a book", "reports he was diagnosed with skin cancer.", "stand down", "Ashley \"A.J.\" Jewell", "17", "Satsuma, Florida", "southern city of Naples", "Hugo Chavez", "London", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "Preah Vihear temple", "The Delta Queen will go out of service if Congress does not grant the ship another exemption from a 1960s federal law, the Safety at Seas Act, which bans boats made largely out of wood because of fire hazards.", "Haeftling range.", "Alaska or Hawaii.", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Blagojevich", "America's infrastructure.", "patrolling the pavement in protective shoes", "public-sector labor unions launching a general strike,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "discard beer bottles on pebbled walkways.", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International Airport", "GZA, \"Grandmasters\"", "Suffragette", "Cobblestone", "Brazil", "The Lone Ranger", "Bonnie and Clyde"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6090360318567556}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.27272727272727276, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.5, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.1081081081081081, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 1.0, 0.5714285714285715, 0.0, 1.0, 0.2857142857142857, 0.4, 0.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-14663"], "SR": 0.453125, "CSR": 0.57578125, "EFR": 0.7142857142857143, "Overall": 0.6450334821428572}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000 write / erase cycles", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50 feet", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956", "The first message was sent over the ARPANET in 1969 from computer science Professor Leonard Kleinrock's laboratory at University of California, Los Angeles ( UCLA ) to the second network node at Stanford Research Institute ( SRI )", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Yale University", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria", "Koine Greek : apokalypsis", "October 1941", "to refer to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "b\u0101gh, baug, bageecha or bagicha", "Cee - Lo", "after Shawn's kidnapping", "in consistency and content", "Labour", "1933", "November 25, 2002", "October 29, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "for a single particle in a plane two coordinates define its location so it has two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick,", "CEO of an engineering and construction company with a vast personal fortune.", "more than 1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6419506472290992}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8421052631578948, 1.0, 0.0, 1.0, 0.5365853658536585, 0.0, 0.0, 0.0, 0.1, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.4, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5736607142857143, "EFR": 0.7333333333333333, "Overall": 0.6534970238095238}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "bearers", "Washington metropolitan area", "molar concentration", "the breast or lower chest of beef or veal", "Samaria", "Tagalog or English", "The Edwin Smith Papyrus was written around 1600 BC", "By mid-1988, all 50 states and the District of Columbia had raised their purchase ages to 21", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Giancarlo Stanton", "Orangeville, Ontario, Canada", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "Janie Crawford, an African - American woman in her early forties,", "6th century AD", "in positions Arg15 - Ile16", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "Transvaginal ultrasonography", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Julie Gonzalo", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "batsman", "Rear-Admiral of the Navy", "Marktown, Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5114399948499213}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2222222222222222, 0.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.3333333333333333, 0.16666666666666666, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.8235294117647058, 0.0, 0.0, 0.5, 0.6666666666666666, 0.08333333333333333, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-5168", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.359375, "CSR": 0.5639204545454546, "EFR": 0.6341463414634146, "Overall": 0.5990333980044347}, {"timecode": 22, "before_eval_results": {"predictions": ["the mouth of the Monongahela River", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "Coldplay", "annual income of US $11,770", "al - khimar", "prenatal development", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Massachusetts", "two", "John Adams", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2009", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Kirk Douglas as Matt Morgan", "Jodie Foster", "February 27, 2007", "Malina Weissman", "8ft", "Owen Vaccaro", "detritus", "on the lateral side of the tibia", "Lynda Carter", "erosion", "90 \u00b0 N 0 \u00b0 W", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Queen Elizabeth II", "an insect in one part of the country and to a completely different insect", "Pearl Jam", "2005", "Dan Tyminski", "the oldest daughter of an incestuous relationship", "the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "at least nine", "Bashar al-Assad", "New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6738549933862434}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.28571428571428575, 0.14814814814814814, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.578125, "CSR": 0.5645380434782609, "EFR": 0.7037037037037037, "Overall": 0.6341208735909822}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 )", "Thaddeus Rowe Luckinbill", "by the early - to - mid fourth century", "2002", "China", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2, Clause 3", "Constitution of India", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "closing of the atrioventricular valves and semilunar valves", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Ireland", "1981", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "1922 to 1991", "Edward Hyde", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "the `` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five books, with a cumulative total of 528 aphoristic sutras, about rules of reason, logic, epistemology and metaphysics", "Mot\u00f6rhead", "Kingman Regional Medical Center", "Phillip A. Myers", "Osama", "Antarctic", "spinal cord", "chanterelle mushrooms, or Cantharellus"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6148593274415644}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.5714285714285715, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-13614", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.453125, "CSR": 0.5598958333333333, "EFR": 0.7142857142857143, "Overall": 0.6370907738095237}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff with Kentucky native Kenny Perry", "Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "Indian School of Business, American India Foundation, New Silk Route and Scandent Solutions.", "Radio City Music Hall", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin button\"", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Eilean Donan", "Fatih Ozmen", "U.S.", "Pacific Place", "writing for \"The New York Times\" and \"Popular Mechanics\", and is a regular contributor to various CNBC shows such as \"On the Money\"", "Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn, Bricusse and Cuden", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Operation Watchtower", "Bishop's Stortford", "Starvation Is Motivation", "Michael Burger", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "Lucky", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "The Tenth Planet ( 1966 )", "The Stig", "Jehan Mubarak", "Medellin", "Joe Jackson", "alternative-energy vehicles", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6576140873015872}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.4, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.578125, "CSR": 0.5606249999999999, "EFR": 0.7777777777777778, "Overall": 0.6692013888888888}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort.", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Jonghyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online.", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS", "second largest", "Citric acid", "1989", "Lola Dee", "\"The Five\"", "Walt Disney Feature Animation", "The club will participate in the Premier League, FA Cup, EFL Cup (as holders), UEFA Champions League and UEFA Super Cup.", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "Tax Reform Act of 1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "Homo erectus", "In honor of the man who made the generous gifts,", "green"], "metric_results": {"EM": 0.671875, "QA-F1": 0.70546875}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.671875, "CSR": 0.5649038461538461, "EFR": 0.7619047619047619, "Overall": 0.6634043040293041}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Sleeping Beauty\" (French: \"La Belle au bois dormant\" \"The Beauty Sleeping in the Wood\")", "Orchard Central", "Johnwyneth Paltrow", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cleveland", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Summerlin, Nevada", "1919", "Kevin Spacey", "Love Streams", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "Old Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music and English folk-song", "Hexachrome", "1600 BC", "Frank Oz", "1963", "a palla", "Car ferry", "A Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Japan", "postcards"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6095495650183149}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.2857142857142857, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-1617", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268"], "SR": 0.515625, "CSR": 0.5630787037037037, "EFR": 0.7741935483870968, "Overall": 0.6686361260454002}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "Fall 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "Whitney Houston", "Player's No 10, Skol, Leyland Cars,auntlet, Daily Mirror, TNT Sameday and Dunlop", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "40 Days and 40 Nights", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji Nugroho Notosusanto", "Don Bluth", "2007", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Double Crossed", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch Kiss M1914 machine gun", "Steve Kiley, M.D.", "Prussian army general, adjutant to Frederick William IV of Prussia", "January 2004", "co-founder and lead guitarist", "\"# HappyHolograms\"", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off the coast of Somalia", "trite remark", "nasal septum", "Barack Obama"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6365508851528588}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.5625, "CSR": 0.5630580357142857, "EFR": 0.8928571428571429, "Overall": 0.7279575892857143}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF) beginning in 1985 to promote advanced research and education networking in the United States", "London", "Henry Mancini", "eisha", "Gordon Ramsay", "Ronald Reagan", "Adrian Cronauer", "surreptitiously, discreetly, furtively, clandestinely,", "Rameses II (Yul Brynner)", "Anna (Julia Roberts)", "a scythe", "balsam fir (Abies balsamea)", "Paddy Doherty", "severest", "b.C.E.", "Libya", "Yeehaw", "WoO", "Iraq", "Daniel Peggotty", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "Count de La F\u00e8re", "April", "Eric Morley", "hypertension", "the Garrick Club", "Belle", "Fabio Capello", "Fort George", "Marc Norman", "The Greatest", "a singer and performer", "in the British charts", "a habanero", "tenor saxophonist", "Seattle", "The Union Inn", "Llanishen", "Baton Rouge", "bugeye", "Tahrir Square", "Romanian", "a bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a small species of foraging mammal", "Greek", "Passion fruit", "Grace Zabriskie", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941", "North America", "Florida's Everglades", "Michael Jackson", "consistent and accessible", "driving through a fast-food chain", "a set of steak knives", "Sebastian Stark"], "metric_results": {"EM": 0.296875, "QA-F1": 0.3693576388888889}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.28571428571428575, 0.21428571428571427, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-3804", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-1222", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-12186", "mrqa_searchqa-validation-15919"], "SR": 0.296875, "CSR": 0.5538793103448276, "EFR": 0.7555555555555555, "Overall": 0.6547174329501916}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Kyrie Irving", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson", "between 8.7 % and 9.1 %", "2018, the first day of the Lunar New Year was on Friday, 16 February, initiating the year of the Dog", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "status line", "retina", "fears", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar worth close to 5,770 guaranies", "the original Star Trek television series", "1936, when she was 10 years old", "Sam", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Matt Jones", "in 1995, California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s", "i want to be with you everywhere", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s, primarily in wind turbines and photovoltaics and increased use of hydroelectricity, presented some of the first sustainable alternatives to fossil fuel and nuclear energy generation", "Hebrew Bible", "Earl ( John Doe )", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "Marvin Gaye", "Eukarya", "elbow", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island", "Romney", "rock", "ulnar", "bronchitis"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5709910963488267}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.45454545454545453, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.125, 0.25, 0.4, 1.0, 0.0, 0.0, 0.0, 0.56, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10459", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.515625, "CSR": 0.5526041666666667, "EFR": 0.8387096774193549, "Overall": 0.6956569220430108}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "fern", "Marvel's Guardians of the Galaxy", "the Spanish Republic", "Taxicab", "coyote", "The Sun Also Rises", "Harry Reid", "Ray", "Axis", "forge", "Wolfgang", "j Javier Bardem", "Flowerbomb Viktor&Rolf", "Blackbird", "Footprints", "Caliban", "LA Kings", "Census Bureau", "Tommy Lee Jones", "Zacchaeus", "The Memory keeper's daughter", "George Eliot", "hubris", "Yahtzee", "Tony Micelli", "XML", "hives", "77.0", "William S. Hart", "Joshua", "Pride and Prejudice", "The Secret Family of Jesus", "Kosher Wines", "Munich", "Michael Jordan", "February 2nd", "Prospero", "Hikaru Sulu", "parrots", "this", "kyushu", "honey", "Boston", "Mattel", "Arctic Ocean", "the new Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1935", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "adidas", "Intel has systematically given PC makers and stores rebates to keep computers with AMD chips off the shelves"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6557291666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3915"], "SR": 0.578125, "CSR": 0.5534274193548387, "EFR": 0.7777777777777778, "Overall": 0.6656025985663083}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "June 26, 1970", "Bloomingdale Firehouse", "elise Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Mercury Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland County", "Slaughterhouse-Five", "Shohola Falls", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Oyster Bay", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "Royal Air Force", "Isabella Palmieri", "Hathi Jr", "1935", "geryon", "slow", "\"Cruisin'\"", "the Moffat Tunnel", "Microsoft", "Friday", "the high Plains area", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7086538461538461}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-2088", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_hotpotqa-validation-2554", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055"], "SR": 0.640625, "CSR": 0.55615234375, "EFR": 0.8695652173913043, "Overall": 0.7128587805706521}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\" was the first crewed vehicle to land on the Moon.", "jellyfish", "March", "a blank", "Fauntleroy", "the World Health Organization", "Eat porridge (it\u2019s a spoon)", "Kofi Annan", "chloroplasts", "pamphlets, posters, ballads", "Taggart", "Che Amanwe and Chi Eekway", "Florida", "Manfred Mann", "Frank Keogh", "Barry Taylor", "Jackson Street", "Brussels", "Flora MacDonald", "John Poulson", "A\u00e9roport de Paris-Beauvais-Till\u00e9", "the Treaty on European Union", "Superintendent Norman Mullet", "The Precambrian Shield", "Laurent Planchon", "the Solent", "vomiting", "Basketball Page 30", "Bristol Aeroplane Company", "Spinach", "Jason Rissman", "\u201cArgo\u201d", "Libra", "Surrey", "1969", "fosse Way", "In Budapest, a 2.5-mile (4-kilometre) electric subway was opened in 1896", "The Coquimbo Region", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units", "Miller Brewing", "northwestern Italian coast", "the Peninsula in Melbourne", "without loved ones, without homes, without life's belongings.", "her decades-long portrayal of Alice Horton on the soap opera \" Days of our Lives,\"", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver, says.", "Peter Bogdanovich", "the mourning dove", "the Federal Republic of Cyprus"], "metric_results": {"EM": 0.40625, "QA-F1": 0.48544168822370043}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.0975609756097561, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.40625, "CSR": 0.5516098484848485, "EFR": 0.7368421052631579, "Overall": 0.6442259768740032}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "the Arctic Ocean", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "a long line, called the main line, with baited hooks attached at intervals by means of branch lines called snoods ( or gangions )", "Jesus'birth", "a habitat", "irsten Simone Vangsness", "Central Germany ( German : Mitteldeutschland ) is an economic and cultural region in Germany", "Andrew Johnson", "Bart Cummings, regarded as the best Australian horse trainer of all time, went on to win 12 Melbourne Cups to 2008", "Aegisthus", "electors", "Julia Ormond", "Sauron", "1961", "Mike Mushok", "2013", "March 1", "novelization", "iron oxide, a usually red oxide formed by the redox reaction of iron and oxygen in the presence of water or air moisture", "Spain disputes the legality of the constitution and claims that it does not change the position of Gibraltar as a colony of the UK with only the UK empowered to discuss Gibraltar matters on the international scene", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918, and fled to exile in the Netherlands", "paid monument", "erosion", "March 2, 2016", "turkey", "1996", "Ray Charles", "16", "Ramones", "expanded chambers for the bicameral legislature, the House of Representatives in the south wing and the Senate in the north wing", "originally a part of the Hen Ogledd, its people speaking a Brythonic language distinct from Scottish Gaelic and the English derived from Lothian", "Ted '' Levine", "Kate lives in Los Angeles, Randall and his family are in New Jersey, and Kevin relocates from Los Angeles to New York City", "May 2010", "built in France, shipped overseas in crate, and assembled on the completed pedestal on what was then called Bedloe's Island", "Heath Ledger", "Wilson Pickett", "a centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "German authorities", "Islamabad", "Tunisia", "RAND Corporation", "alcaeus"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5294397639387824}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.125, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3076923076923077, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.06451612903225806, 0.0, 1.0, 0.8205128205128205, 0.0, 0.8, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809525, 0.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-3396", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.4375, "CSR": 0.5482536764705883, "EFR": 0.8055555555555556, "Overall": 0.676904616013072}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets and beloved religious leaders", "state legislators of Assam", "enzymes break down the long chains of amino acids", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "constant pressure", "Mind your Ps and Qs", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "Wednesday, 5 September 1666", "Pebble Beach", "management team", "in various submucosal membrane sites", "enterprise application development market", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F )", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "just before her", "Henry Ford", "Jaguar Land Rover", "a Senator from Maine", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5915721640667762}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.3333333333333333, 0.45714285714285713, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3571428571428571, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.2758620689655173, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-15783", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.46875, "CSR": 0.5459821428571429, "EFR": 0.6176470588235294, "Overall": 0.5818146008403362}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "pharmacological effect", "Grey Worm", "Venezuela", "Mexico", "Rocky Marciano", "Finding Neverland", "Andrea del Sarto", "Arctic Ocean", "egg in front of the opening, the flame going out causes a vacuum effect, so the egg is sucked in by the differential in this between the inside & outside of the bottle", "dams", "marquis de Lafayette", "Elijah Muhammad", "doldrums", "Village People", "Alexander Pushkin", "Australia", "Munich Crisis", "Mexico", "work from 10", "papacy", "the Delta", "a typical day", "Pierre-August Renoir", "language", "libretti", "Innsbruck", "Lance Ito", "Microsoft", "petticoat", "Alcoholics anonymous", "Norse seafarers", "Atlantic City", "Blackwater USA", "elephants", "American Airlines", "ibex", "Odysseus", "Quizlet", "Kensington Palace", "Butch Cassidy", "Netherlands", "Pocahontas", "a British novelist, poet, academic, medievalist, literary critic, essayist, lay theologian", "Dagny Taggart", "chalkboard scrape", "Chicago Mercantile Exchange", "Las Vegas", "danskins Are Not Just For Dancing", "wheat", "Pablo Casals", "ostrich or common ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn castle", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Eleanor of Aquitaine", "Senate Democrats", "63", "\"perezagruzka,\" which means 'overcharged.'\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.6318452380952381}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false], "QA-F1": [0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_squad-validation-3610", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-3348", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.53125, "CSR": 0.5455729166666667, "EFR": 0.7666666666666667, "Overall": 0.6561197916666668}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "the National September 11 Memorial plaza", "Southend Pier", "Santa Monica", "layered systems of sovereignty", "Will", "31 January 1934", "Filipino American", "1773", "RAM", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Sumitra", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean and Toby Gad", "never made", "Frankie Muniz", "stratum lucidum", "60 by West All - Stars", "Hasmukh Adhia", "four", "retinal ganglion cell axons and glial cells", "the 1980s", "in soils", "card verification data", "`` rebuke with all authority '' ( Titus 2 : 15 )", "bohrium", "Germany", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "As of July 2017, there were 103 national parks encompassing an area of 40,500 km ( 15,600 sq mi )", "Vienna", "Bajan", "Australia", "Churchill", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6455289502164502}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.5454545454545454, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.1, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.578125, "CSR": 0.5464527027027026, "EFR": 0.8148148148148148, "Overall": 0.6806337587587588}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "b\u00e2ton", "South Africa", "first among equals", "shine", "a cappella", "albinism", "st Peter's Field", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "equinoxes and solstices", "b beth", "(tetun and Portuguese)", "copper", "Dawn French", "Stars Gone Too Soon", "b Benedict", "Doris Lessing", "Scooby-Doo", "Swaziland", "the elephant House at London Zoo", "Kent", "Humber", "a points based scoring system", "automobile", "Kent", "b Baron Von Trapp", "brazil", "Galileo Galilei", "Mata Hari", "Scotland Yard detective", "Marilyn Manson", "Medellin", "The Tempest", "spark", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Iraq", "Belle de Jour", "bognor Regis", "(The Great Leap)", "change, process, deposit, or feature that is the result of the action or effects of rain", "white", "storied history", "France", "b Bruno Kirby and Jennifer Tilly", "kunsky", "psychology, sociology, anthropology, religious studies, medicine and forensic science", "Bryan Anderson", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "thunderstorms", "different women coping with breast cancer in five vignettes.", "baine", "stomacflower", "Madonna's", "March 24"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4706980519480519}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-3349", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6503", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291", "mrqa_searchqa-validation-7454"], "SR": 0.4375, "CSR": 0.5435855263157895, "EFR": 0.8055555555555556, "Overall": 0.6745705409356726}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "the liver", "40", "water", "get it near water and never ever feed it after midnight", "Bolivia", "ch.1, p. 49-50", "phil Redmond", "Stevie Wonder", "skull", "a hound", "hanover", "the earth", "Earl of Strafford", "worked", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "quetzalcoatl", "1937 Austin Seven Ruby Open Top Tourer", "Paul Anka", "Carthage", "Bristol, who have returned to the top flight after defeating Doncaster in the 2015-16 RFU Championship Play-Off Final.", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "cymbals", "\u201cSanta Buddies\u201d", "San Diego Opera", "Tory MP Andrew Mitchell", "Ticket Sarasota", "South Africa", "Christian Dior", "the A5 and A49 trunk roads", "killer whale", "Ukrainian", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "54-Marquesses", "lizard", "reboot", "frauds", "a sea horse", "7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "Traumnovelle", "Anthony Lynn", "piano", "paid tribute to pop legend Michael Jackson, who died Thursday afternoon in Los Angeles.", "the women", "French Guiana", "AOL", "coat of arms", "Tiger Woods"], "metric_results": {"EM": 0.453125, "QA-F1": 0.49695232259570493}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.5, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 0.5, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-1112", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.453125, "CSR": 0.5412660256410257, "EFR": 0.6285714285714286, "Overall": 0.584918727106227}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "warehouse & Logistics", "Midnight Cowboy", "alfa", "seborrheic dermatitis of the scalp", "amy bristol", "a burthen of about 60 tons", "Niger", "Stockholm", "Tangled", "dogs", "James Douglas", "Bulls Eye", "bar\u00e8re de Vieuzac", "lapajne", "Martin Clunes", "Charles Darwin", "pembrokeshire Coast National Park", "george couzens", "peppers", "cenozoic", "John Mellencamp", "isambard Kingdom Brunel", "Great Britain", "1957", "waten", "roun", "a sauce of lemon juice, parsley, salt, pepper, and drawn butter", "micelles", "Ralph Vaughan Williams", "musical scale", "animals", "heart", "e. T. A. Hoffmann", "city - largest city - is located south of the Yangtze mouth", "Spain", "grow", "Tuesday", "Guru Nanak", "ch.1, p. 49-50", "The Princess bride", "phosphorus", "little jack Horner", "Indianapolis", "humbert Humbert", "cuckoo", "Mr. Stringer", "Ford", "Alice Cooper", "Majorca (Mallorca)", "red blood cells", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "\"The Cycle of Life,\"", "forgery and flying without a valid license", "137", "the log cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4601934523809524}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.421875, "CSR": 0.53828125, "EFR": 0.8378378378378378, "Overall": 0.688059543918919}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players-Lasky", "Washington", "dutiful daughter", "the black death", "a small draught horse, around three-fourths of a ton, and is without feathered legs", "buffalo", "Cleopatra", "a dove", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "the value of unknown electrical resistance", "the Arabian Gulf", "secretary", "jane de valence", "nepoticide", "jack Nicholson", "\u201cTonight is another Day\u201d or \u201cTote the weary Load\u201d", "a linesider", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "Angola", "New Hampshire", "James I", "barry Copeland", "the Philippines", "purple", "one-thousand ones", "warblers", "a 965-foot ocean liner", "Rome", "10", "Southwest Airlines", "a person born within hearing distance of the sound of Bow bells", "Jeffery Deaver", "The Comedy of Errors", "charlie j. Kelly", "glyn Jones", "president Clinton at the White House on \"20/20,\" Sept. 20, 1996", "cheviles", "the norkney Islands", "an al-Qaeda\u2013inspired terrorist cell carried out a series of bombings against Madrid's commuter train system", "Frederic Robinson Ltd", "his friends, Humpty Dumpty and Kitty Softpaws", "August 18, 1998", "Tanvi Shah", "EN World web site", "the 100th anniversary of the first \" Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "boy Buddha", "seinfeld", "nibelung", "they were weaker when it came to training and tertiary education"], "metric_results": {"EM": 0.375, "QA-F1": 0.45257745726495724}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.5, 0.0, 0.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-5371", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7346", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.375, "CSR": 0.5342987804878049, "EFR": 0.7, "Overall": 0.6171493902439025}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "nippon car Works", "chobus", "Roddy Doyle", "a counting table", "Robin Hood Men in Tights", "Aeolus", "Diego Velazquez", "South African", "maracaibo", "Norway", "tchaikovsky", "oliver Twist", "Scotland", "nimian logue", "David Bowie", "Buzz Aldrin", "jean-Paul sartre", "moiksa", "dicks turpin", "rust", "jane aniston", "pembroke County, Wales", "tbilisi", "stranning tatum", "othello", "if you wait until late, things   will get worse, and it will take much longer to deal with them", "Glenn Close and Rade Serbedzija", "lacock Abbey", "Alan B'Stard", "cat", "Anita Brookner", "eusebius", "bunned grandmother of the Jewish people", "the Black Sea", "bagram Theater Internment Facility", "Susie Dent", "lights went out", "Vienna", "The Archers", "shylock", "s. ochs", "henry gee", "John Mellencamp", "shanosars", "Marx Brothers", "aire", "habsburg Monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "1993 to 1996", "James Gandolfini", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones", "tuba", "corral", "butternut squash", "a walled, high area containing fortifications, temples to the gods, and spaces"], "metric_results": {"EM": 0.375, "QA-F1": 0.4818530701754386}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.5, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-2625", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-14680", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.375, "CSR": 0.5305059523809523, "EFR": 0.9, "Overall": 0.7152529761904762}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "pension fund", "at Eintracht Frankfurt", "Comoros Islands", "a public-television show", "Jeddah, Saudi Arabia", "40", "cry", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "Fifteen years ago", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "through a facility in Salt Lake City, Utah", "Dancy-Power Automotive Group showroom", "Michoacan Family", "64", "in prison", "fastest circumnavigation of the globe in a powerboat", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007 and has been coaching at Independiente.", "\"E! News\"", "Washington", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits", "bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "Alan Graham", "her fianc\u00e9", "cal Ripken Jr.", "as he dropped his children off at a relative's house", "cancer", "acid attack", "Vernon Forrest", "NATO has a self-interest in supporting Afghan forces in destroying drug labs, markets and convoys,\"", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m. at Terminal C when a man walked through an exit on the public side to the secure \"sterile\" side for passengers who had cleared screening", "former Mobile County Circuit Judge Herman Thomas", "we say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well", "body", "\"release\" civilians", "Dodi Fayed", "one day we will have no more oil and we'll have to find another way to live", "there is a decline in population density", "Barcelona", "emperor Cuauhtemoc", "korea", "Misery", "purdy", "Antonio Lippi", "Thorgan", "River Clyde", "Canada", "june Jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.375, "QA-F1": 0.5019888563089406}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.8, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.8000000000000002, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.2857142857142857, 0.4444444444444445, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 0.4, 1.0, 0.3636363636363636, 0.08695652173913045, 0.11764705882352942, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-3948", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-5597", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.375, "CSR": 0.5268895348837209, "EFR": 0.75, "Overall": 0.6384447674418605}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.", "1943", "Volvo 850", "the Mountain West Conference", "the National Basketball Association (NBA)", "Western Europe", "political thriller", "Schaeffler Technologies AG & Co.  KG", "the Championship", "1989 until 1994", "Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Attack the Block", "Bhushan Patel and Tinu Suresh Desai", "1986", "1964", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs.", "1988", "coaxial", "Philip Pullman's", "three different covers", "Malayalam cinema", "the \"Cisleithanian\" half of Austria-Hungary (1867\u20131918)", "1946", "Vincent Landay", "September 6, 1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Brian A. Miller", "Nicolas Vanier", "1985", "Gal Gadot", "Meghan Markle", "Texas Raiders", "Erika Girardi", "Joe Scarborough", "Crimean War", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Sony Studio Liverpool", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "Trade Mark Registration Act 1875", "blue", "elbow", "citizens of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6903467908902692}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.20000000000000004, 0.5, 0.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5714285714285715, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-2081", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-2823", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1464", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.59375, "CSR": 0.5284090909090908, "EFR": 0.8846153846153846, "Overall": 0.7065122377622377}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "1954", "sexy Star", "Conservatorio Verdi in Milan", "President of the United States", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "January 11, 2016", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kiss", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool F.C.  Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Sun Tzu", "American singer Toni Braxton", "Hindi", "Michael Manasseri", "Irish Chekhov", "311", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "Super Bowl VII", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Variations", "last summer", "almost 100", "the Southeast", "the jeffersons tv show", "a stick to fish the filemot frith for treasures", "male attire", "One Direction"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6651348039215687}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.546875, "CSR": 0.5288194444444445, "EFR": 0.9655172413793104, "Overall": 0.7471683429118774}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "a proof reader", "Elizabeth II", "the Aquitani", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "putt-putt", "CNN", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "sea otter", "jedoublen/jeopardy", "a franchise", "rod", "the Nixon scandal", "dressage", "astronomer", "Mickey Mouse", "stigma", "Associate Professor", "the Foot", "Medusa", "a curve", "Prince Attab", "staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Troy", "Vegetarianism", "the Peace sign", "An Old Man, a Young Man", "English Monarchs These 2", "Rajasthan", "Ben Kingsley", "Henry Fountain's column", "NHL", "nadir", "White bread and butter", "the chairperson", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "Tornado", "\"Queen In-hyun's Man\"", "Oneida Limited", "James Ager W", "Libreville, Gabon", "tickets to Italy", "The station", "Cahaba"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6524553571428571}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.5625, "CSR": 0.5295516304347826, "EFR": 0.9285714285714286, "Overall": 0.7290615295031055}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\" to which they were entitled institutionally and legally,", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "faggots", "a skein, a team, or a wedge", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Arabian Sea", "Gemini", "Great Victoria Desert", "German", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "North Korea", "a pig", "sequel, maybe", "Holzi194", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "Shift", "Susquehanna", "Bolivia", "darth vader", "Frankfurt", "chipmunk", "Goldie Hawn", "pulsar", "Belgium", "horse stories", "maple", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11 healthy eggs", "Twilight", "Carrousel du Louvre", "Speed Racer", "The Time Machine", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6441964285714286}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true], "QA-F1": [0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-3654", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-4025", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.5625, "CSR": 0.5302526595744681, "EFR": 0.75, "Overall": 0.640126329787234}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "at Sunset", "Sinclair Lewis", "a bear", "The World is Not Enough", "pigments", "Jonathan Demme", "v\u00e1clav Havel", "Dick Van Dyke", "isabella", "Tina Turner", "2010", "Portrush", "glasses for reading things that are far away or for driving", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "Lord Sugar", "ship\u2019s waterline", "trajuan Gris", "sahari", "the Advisory Council of Science and Industry", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "call my Bluff", "star", "Argentina", "Frank McCourt", "salt or sugar", "Debbie McGee", "LDV", "starch", "Pears soap", "Donna Summer", "a balustrade", "nottingham", "Poland", "the Welcome Stranger", "taggart", "January", "Chechnya", "a police janitor", "a-team", "football", "801,200", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "1952 World Champion Jack Young", "beautiful", "Eleven", "Michelle Obama", "kbenhavn", "The Communist Manifesto", "saara", "Floxin"], "metric_results": {"EM": 0.453125, "QA-F1": 0.48982007575757575}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-15651"], "SR": 0.453125, "CSR": 0.5286458333333333, "EFR": 0.8857142857142857, "Overall": 0.7071800595238095}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "\u00c6lfgifu of York", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "All Nippon Airways", "Mineola", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "mash-Up", "1986", "early Romantic period", "The Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Ishtar Gate", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Edward James Olmos", "Suffolk", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "45th Infantry Division", "2009", "5", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers Band", "the 924", "371.6 days", "North Carolina", "Selinsgrove", "Countess of Lovelace", "first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Najmeddin Al Hadad", "Space Shuttle Challenger", "basil", "clio Awards", "The Rosie Show", "Current TV", "well over 1,000 pounds", "Antony", "a volcano's lava flow", "the Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7150154532967034}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.5, 1.0, 0.0, 0.0, 0.8571428571428571, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.640625, "CSR": 0.5309311224489797, "EFR": 0.8260869565217391, "Overall": 0.6785090394853595}, {"timecode": 49, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Sam Roberts Band, The Trews, someKinda Wonderful, and Saintseneca", "joined the utopian Ascona community", "John W. Henry", "James Woods", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "\"Power Rangers Turbo\"", "Odisha", "novelty songs, comedy, and strange or unusual recordings dating from the early days of phonograph records to the present.", "OutKast", "Albert Ball", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem (Evil)", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "Avoca Lodge", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec fox", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "the birth centenary of Pandit Jawaharlal Nehru", "Honda", "Adam Smith", "the Republic of Upper Volta", "56", "Nkepile M abuse", "Eintracht Frankfurt", "the fortress", "Hephaestus", "Amherst College", "six nice golf courses"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6257597117794487}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.21052631578947367, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.1, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.5625, "CSR": 0.5315624999999999, "EFR": 0.7142857142857143, "Overall": 0.6229241071428571}, {"timecode": 50, "UKR": 0.744140625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.7265625, "KG": 0.47890625, "before_eval_results": {"predictions": ["Sushant Singh Rajput", "\u00c6thelwald Moll", "Fife", "26,000", "Spain, Mexico and France", "1981", "Dragons", "February 26, 1948", "enshrined at Dayton, Ohio, in the National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "A1 Recordings, Freebandz and Epic Records", "IFFHS World's Best Goalkeeper", "shortest player ever to play in the National Basketball Association", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern", "Picric acid", "Las Vegas", "ESPN's \" SportsCenter\"", "a pioneering New Zealand food writer", "fantasy role-playing game", "feats of exploration", "Columbia Records", "Bergen County", "Marlon Vaxivi\u00e8re", "Newcastle United's Cheick Tiot\u00e9", "Monica Seles", "the superhero Birdman from the Hanna-Barbera show \" Birdman and the Galaxy Trio.\"", "Biloxi", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "ethereal wave", "IATA: VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "between 27 July and 7 August 2021", "1800", "season seven", "glycerol", "an umbrella", "sheep", "Amitabh Bachchan", "1.2 million", "84-year-old", "Jacob", "testimony", "the fourth son, Private First Class James Francis Ryan", "Mitch Murray"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6154513888888888}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5555555555555556, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.5, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4698", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770", "mrqa_searchqa-validation-1372"], "SR": 0.453125, "CSR": 0.5300245098039216, "EFR": 0.7428571428571429, "Overall": 0.6444982055322129}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County, New York", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Daniel Espinosa", "1942", "water", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "Logan International Airport", "Blackpool Football Club", "Marvel Comics", "100 million", "James Gregory", "Volvo 850", "1978", "July 25 to August 4", "Sela Ann", "\"'Tis the Fifteenth Season\"", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle Corporation", "Paris", "John Andr\u00e9", "Three card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Alexandrovich Morozov", "traditional music of pre-Hispanic and contemporary music of the Andes", "The Dragon", "two Grammy awards", "Outside", "Traumnovelle", "the Chechen Republic", "model", "from 1986 to 2013", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover", "Citgo Petroleum Corporation", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee, is widely considered to be its chief architect", "Presley Smith", "hydrological cycle or the hydrologic cycle", "Mungo Park", "Jet Harris", "Melissa in one, The Scarlet Pumpernickel, where she is voiced by Bea Benaderet", "in a tenement in the Mumbai suburb of Chembur, with eight people living together in a single room.", "due to a shortage of landing fields available for practice, an offer to land near the Middleton house on April 3 was readily accepted.", "China could continue to claim Tibet as part of its territory.", "Popular Science", "avoirdupois", "Latter-day Saints", "Gerwing"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6808165299612667}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.15999999999999998, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.5, 0.8, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.4, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.21052631578947367, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-823", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-5108", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.53125, "CSR": 0.5300480769230769, "EFR": 0.8666666666666667, "Overall": 0.6692648237179488}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "movie scripts", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Bandai", "St Augustine's Abbey", "The Indianapolis Times", "Ridley Scott", "Dizzy Dean", "UHF channel 44", "North Kesteven", "West African descendants", "The Beatles", "\"Menace II Society\"", "September", "March 30, 2025", "Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Easy", "CBS", "Brickyard", "2012", "Candice Susan Swanepoel", "G\u00f6ran Bror", "Peter, Paul and Mary", "Kathleen O'Brien", "Blackstone", "the north bank of the North Esk", "Paris", "Hard rock", "Yeeun and Hyerim", "Ecko Unlimited", "Joe Frazier", "University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "Sister, Sister", "David Dunn", "William Bradford", "FieldTurf", "My Beautiful Dark Twisted Fantasy", "Benj Pasek and Justin Paul", "a hand injury", "the \u01c3ke e : \u01c0xarra \u01c1ke", "Johnny Cash", "the pulmonary arteries", "Pope Benedict XVI", "France", "Taekwondo", "The Tinkler", "since 1983", "legitimacy of that race", "the Duke of Norfolk", "Italy", "chili pepper", "stars"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6444816468253968}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.8, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-3227", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5343", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.546875, "CSR": 0.5303655660377358, "EFR": 0.9310344827586207, "Overall": 0.6822018847592713}, {"timecode": 53, "before_eval_results": {"predictions": ["mummies", "Friedrich Nietzsche", "give up the ship", "Carnarvon", "the Nine Years' War", "Glaciers", "white", "Marie-Antoinette", "the Andy Griffith", "Great Smoky Mountains National Park", "grasshopper", "Ohiopyle", "Nostradamus", "Hodgkin's", "The Flying Dutchman", "turbinado", "Longfellow", "The Crow", "the plain of Marathon", "John Keats", "(Scott) Peterson", "the northern geographic border", "the Mayflower", "Senator Bob Kerrey", "Curly Lambeau", "St. Erasmus", "BackRub", "Bednye liudi", "Mike Rowe", "Resident Evil", "daughter", "the French national holiday", "the UAE", "Dramamine", "The W.C. Fields Comedy Collection", "thebrewer parade", "Dred Scott", "a girl of \"good breeding but no money\"", "President McKinley", "Staten Island", "The Transformers", "Crystal Light", "the American Civil War", "the declaration of saturated fat", "Oscar Wilde", "Columbus", "Doctor Dolittle", "William Randolph Hearst", "Inventors", "Indira Gandhi", "top secret", "the Director of National Intelligence", "This procedure can be performed at any level in the spine ( cervical, thoracic, or lumbar ) and prevents any movement between the fused vertebrae", "2018", "Peter Paul Rubens", "mink mink", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license", "Michoacan state,", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "Carpenter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5843394886363635}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.125, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-9452", "mrqa_searchqa-validation-16126", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-16955", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-10203", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-2661", "mrqa_searchqa-validation-15822", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-3486"], "SR": 0.46875, "CSR": 0.529224537037037, "EFR": 0.8235294117647058, "Overall": 0.6604726647603486}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "318/92", "Gary Havelock", "Britain", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "armoured", "Adrian Cronauer", "Copenhagen", "the Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googolplex", "the Canadian Horseshoe Falls", "$SPX", "Mrs Merton", "blues", "Alamo Rent A Car", "Brazil", "bologna", "Aries", "Michael Faraday", "George Herbert Walker", "a small fox terrier", "haddock", "Happy Ever After", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "Good Neighbors", "a non-speaking character", "Richard Briers", "Sinclair Lewis", "deer", "Australia", "Barry White", "Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "Fix You", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "The Worm", "\"Maude\" and the sardonic Dorothy on \"The Golden Girls,\"", "\"the most dangerous precedent in this country, violating all of our due process rights,\"", "comments he made after his new boss, golffer Adam Scott, defeated Woods at the Bridgestone Invitational in Ohio in August.", "Easy Rawlins", "William McKinley", "Scripps National Spelling Bee", "Prussia"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6083031400966183}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4444444444444445, 0.08695652173913043, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-1769", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187", "mrqa_searchqa-validation-14797"], "SR": 0.53125, "CSR": 0.5292613636363637, "EFR": 0.9333333333333333, "Overall": 0.6824408143939394}, {"timecode": 55, "before_eval_results": {"predictions": ["ensure that detainees are not drugged unless there is a medical reason to do so.", "the man was dead", "CNN's Larry King", "Gente Nueva", "customers", "the United States", "in Iraq", "the Iranian consulate", "parachuted to the ground", "documents belonging to Miguel Mejia Munera.", "CNN's Matthew Chance", "heroin", "Bright Automotive", "NASCAR", "Clifford Harris", "Muslim", "a Muslim and a Coptic family", "adult reality show", "bollywood", "Tens of thousands of new voters", "urged NATO to take a more active role in countering the spread", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament", "Hillary Clinton", "Iran", "Daniel Radcliffe", "publicly criticized his father's parenting skills.", "Ronald Reagan UCLA Medical Center", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Sixteen", "remains unknown,", "60 euros", "\"I'm walking back through the crowd it was the word on everyone's lips,\"", "pilgrims", "acid attack", "root out terrorists within its borders", "July 8", "he was released Friday and taken to the Australian embassy in Bangkok,", "Channel 4 said the program was made with the parents' full consent.", "Gustav's top winds weakened to 110 mph", "rwanda", "twice", "Bob Johnson", "the \"bystander effect\"", "dance with the Stars", "his club", "Microsoft", "two years", "Confederate forces", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Thom Yorke", "Charlie Sheen", "silversmith", "Joseph Ruttenberg", "First Family of Competitive eating", "Valley Falls", "Linen", "mount Kosciuszko", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6207259760788373}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true], "QA-F1": [0.6, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.25, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.33333333333333337, 0.2608695652173913, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.9, 0.8235294117647058, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2697", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_hotpotqa-validation-5224", "mrqa_searchqa-validation-1388", "mrqa_searchqa-validation-12033"], "SR": 0.46875, "CSR": 0.5281808035714286, "EFR": 0.6470588235294118, "Overall": 0.6249698004201681}, {"timecode": 56, "before_eval_results": {"predictions": ["Fortress", "peso", "Nucleus", "prednisone and prednisolone", "1960", "Stalin", "Groundwater", "ovulation", "pythons", "William Proxmire", "George Orwell", "the Takana", "turntable", "The Man", "herbivore", "one giant leap", "Psycho", "Believer", "Athens", "the most reasonable", "zoo", "V Vinyl", "Jimmy Swaggart", "Oral Roberts", "staff", "John VIII Palaiologos", "tin", "Ganges", "In Search of the Castaways", "Dave Brubeck", "The Arsenal", "Soul", "Danville, Virginia", "Jupiter", "spiders", "Apple", "winter Depression", "Mausolus", "Act One", "sapphire", "Rhapsody in Blue", "the spectacle", "odka", "Ronald Reagan", "Mount Kilimanjaro", "the right to bear arms", "Delaware", "Graceland", "the MiG-31 Foxhound", "Michael", "the oral stage (first year of life), the anus stage ( second year) and superego (\"It's wrong to take someone else's ice cream\")", "Ulbricht", "Anirudh Sinha", "in the pouring rain at a rest stop", "Munich", "the Circle line", "12th", "Margaret Groening", "Benedict of Nursia", "A Boltzmann machine", "Abbey Road", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.421875, "QA-F1": 0.46117424242424243}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-4802", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-10267", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-15974", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-5209", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-8353", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-4868", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-3559"], "SR": 0.421875, "CSR": 0.5263157894736843, "EFR": 0.8108108108108109, "Overall": 0.657347195056899}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "bamboo", "Merlin", "graphic design", "Alien", "live Large", "Mariachi", "checks", "painful", "Kilimanjaro", "an opinion", "Francis Ford", "6-letter", "the pope", "Calais", "number of cells", "New York", "a tortoise", "Thomas Paine", "Isaac Newton", "American Wedding", "John Hughes", "Tears for Fears", "Jamestown", "the Rhine", "a blacksmith", "mohs", "Katharine McPhee", "October 7, 1913", "life", "Sweynforkbeard", "spiral", "Clinton", "gravel", "(Vijay) Singh", "geometric", "Louisiana", "Daniel Boone", "Quest for Fire", "notophthalmus", "Sweden", "pink", "eyes", "Hong Kong", "The Addams Family", "a", "Joe Lieberman", "Bait-and-switch", "Winston Churchill", "New Year's", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson", "September 9, 2012", "Jupiter", "90%", "Timothy Dalton", "the University of Oxford", "1,467", "Vision of Love", "allegedly grabbed a pupil by the throat and threw her against a wall,", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5727678571428572}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-2637", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11647", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-7362", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-9919", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-9976", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-12380", "mrqa_searchqa-validation-7507", "mrqa_searchqa-validation-5688", "mrqa_naturalquestions-validation-5425", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.515625, "CSR": 0.5261314655172413, "EFR": 0.8387096774193549, "Overall": 0.6628901035873193}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle retained fourth place with a 3-1 victory", "a owners suite and six further double-king sized suites. In addition to this there are numerous rooms for entertaining guests.", "engaging with the Taliban in Pakistan and Afghanistan.", "tells stories of different women coping with breast cancer in five vignettes.", "emergency aid", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school in South Africa", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I'm just getting started.\"", "the chief executive officer, the one on the very top,", "longest domestic relay in Olympic history,", "man's lifeless, naked body", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "opposition leader Morgan Tsvangirai", "new Touch", "The woman who received the first-ever near-total face transplant in the United States", "International Polo Club Palm Beach in Florida.", "President Bush", "All three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "a full garden and pool, a tennis court, or several heli-pads.", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "Polo", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Eleven people died and 36 were wounded", "The Rev. Alberto Cutie", "Nairobi, Kenya", "magazine", "FBI Special Agent Daniel Cain,", "Alan Graham", "February 12", "Ensenada, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "women in Somalia's third-largest city, Baidoa, have been ordered to wear Islamic dress starting this week or face jail time.", "trading goods and services without exchanging money", "three people", "two more countries, Denmark and China, reported cases of the 2009 H1N1 \"swine flu\" virus on Friday,", "Some of them told CNN they couldn't afford to pay for cable or satellite TV service.", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Stefanie Scott", "In late - 2011, she announced plans for a clothing and jewelry line called House of Maryse, and later began working as a realtor", "motorway archive.ihtservices.co.uk", "Zaire", "a pasta \"al dente,\" which means \"to the tooth,\" meaning that it still has a little bite.", "DreamWorks Animation", "Debbie Harry", "2004", "a face cord", "Brian Slade", "Existentialism", "Efrem Zimbalist Jr."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5761816110117741}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.25, 0.0, 0.17391304347826086, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.56, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.4444444444444445, 0.8, 0.17391304347826086, 0.25, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.2222222222222222, 0.07407407407407408, 1.0, 0.6666666666666666, 0.0, 0.0, 0.41666666666666663, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-6426", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.46875, "CSR": 0.5251588983050848, "EFR": 0.5882352941176471, "Overall": 0.6126007134845464}, {"timecode": 59, "before_eval_results": {"predictions": ["Tulsa", "Pakistan", "DTM", "Vernon Kay", "Everglades", "ten episodes", "Tyler Posey", "Maxwell Atoms", "Scandinavian design", "Hugh Hefner's", "Benj Pasek and Justin Paul", "Toxics Release Inventory", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "southwest Denver, Colorado", "Edward M. Kennedy", "Growler", "21st Century Fox", "Pennsylvania's state capital, Harrisburg", "Danielle Fernandes Dominique Schuelein- Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "NATO", "sometimes I. A. K. Pataudi", "authoritarian tendencies", "AOL Inc.", "World War II", "coca wine", "Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "the 2002 Golden Globe for Best Supporting Actress", "New Jersey", "Ian Rush", "English", "Australian", "youngest TV director ever", "Arthur William Bell III", "Henry John Kaiser", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "the second", "If no team places a claim, the player can be sent to a minor league affiliate", "Will", "work a minimum number of hours defined as such by his / her employer", "Ceefax", "Dieppe Raid", "Herrenhausen", "Capitol Records", "228", "The son of Gabon's former president", "stocks", "Thomas Alva", "Han Solo", "Longo-Ciprelli"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5862980769230769}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4, 0.5, 0.0, 0.4, 0.6666666666666665, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.1111111111111111, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-4375", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3372", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6758", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636"], "SR": 0.46875, "CSR": 0.52421875, "EFR": 0.7352941176470589, "Overall": 0.6418244485294118}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "that NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff, and said Schrenker had checked into the hotel under a fictitious name.", "Rivers", "'We want to reset our relationship and so we will do it together.'\"", "Alison Sweeney, who plays Sami,", "the Carrousel du Louvre", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "Russell", "at least 25 dead", "269,000", "flooding was so fast that the thing flipped over", "he'll charm you all the while tucking away your secrets for use at a later date.", "Patrick McGoohan,", "ambassadors", "coalition troops", "man's lifeless, naked body", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell", "\"not generals but businessmen\"", "\"Slumdog Millionaire\" (No. 4)", "Noida, located in the outskirts of the capital New Delhi.", "body bags", "Afghanistan", "10 to 15 percent", "No reason", "Joan Rivers", "CEO of an engineering and construction company", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "illegal immigrants", "a one-of-a-kind navy dress with red lining", "a monthly allowance", "Too many glass shards left by beer drinkers in the city center,", "legitimacy of that race.", "Nigeria", "Andrew Morris,", "in every port, the catamaran and its message has been warmly received.", "Drottningtorget", "a senior at Stetson University studying computer science", "home from Carrefour", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "gold", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "Gerry and the Pacemakers", "Khartoum", "Stand by Me", "France"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5693083748856084}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.1395348837209302, 0.1935483870967742, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2608695652173913, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.4444444444444445, 0.2857142857142857, 1.0, 0.0, 0.0, 0.8, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352942, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409", "mrqa_hotpotqa-validation-2403"], "SR": 0.453125, "CSR": 0.5230532786885246, "EFR": 0.6, "Overall": 0.6145325307377049}, {"timecode": 61, "before_eval_results": {"predictions": ["peanuts, nuts, shellfish, peanuts, tree nuts, wheat and soy", "Flying a space shuttle is a little more challenging than what we did in the movie, although the flying was a lot of fun,\"", "Santaquin City, Utah,", "The U.S. Coast Guard said it has witnessed only normal maritime traffic around Haiti, and it has not intercepted any", "Ed McMahon", "Bob Bogle", "183", "Russia: Moving Forward where CNN's Moscow-based Senior International Correspondent Matthew Chance rides the train from the Arctic north of Murmansk down to the southern climes of Sochi", "on-loan David Beckham claimed his first goal in Italian football.", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon", "Henry Ford", "Four Americans", "Mark Fields", "Luiz Inacio Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "16 Indiana National Guard soldiers", "the body of the aircraft", "third seed Venus Williams", "college campus.", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "Bright Automotive,", "The planned Kingdom City project", "Europe", "$7.8 million", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "The discovery of millions of extra ballots", "Balotelli", "surgical anesthetic propofol", "she was humiliated by last month's incident, in which she was forced to inappropriately remove the piercings", "CNN", "school, their books burned,", "The eye of Hurricane Gustav made landfall near Cocodrie, Louisiana, about 9:30 a.m. CT,", "the HPV vaccine, approved in 2006, is recommended for girls around 11 or 12.", "two", "outfit from designer Britt Lintner", "the two bodies out of the plant, which makes Slim Jim food products.", "second-degree aggravated battery", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Thailand", "Arsene Wenger", "The local Republican Party", "the Gulf", "Gary Brooker", "27", "\"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "housing, business and infrastructure repairs", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "\"The Longest Yard\"", "Lucille Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6619267992284633}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.5714285714285714, 0.0, 0.8571428571428571, 0.1, 0.0, 1.0, 1.0, 0.5882352941176471, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 0.4, 0.2666666666666667, 0.125, 1.0, 0.7499999999999999, 0.625, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-1370", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-2306", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-2149", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881"], "SR": 0.515625, "CSR": 0.5229334677419355, "EFR": 0.8387096774193549, "Overall": 0.6622505040322582}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0 draw away to Saudi Arabia", "portrait of William Shakespeare", "Al Gore.", "200", "T.I.", "media", "Friday", "carving in the middle of our Mountain View, California, campus.", "Arizona", "is the U.N. nuclear watchdog agency's strongest warning yet that Iran could be aiming to build a nuclear bomb.", "\"a Taliban member who had come for the talks about peace and reconciliation, and detonated the explosives as he entered the home.", "56", "China, Taiwan, Hong Kong and Mongolia", "former Boca Juniors teammate and national coach", "Fernando Caceres", "BADBUL", "Nirvana frontman,", "its nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "a residential area in East Java", "Body Works", "the Nuclear Non-Proliferation Treaty in 2003.", "supermodel and philanthropist", "10 below", "1,073", "Zoe's Ark", "joined the estimated 4,000 Zimbabweans who head south to South Africa, most of them illegally, every day.", "girls around 11 or 12.", "passengers on the Miva Marmara assaulted them.", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee", "Bright Automotive,", "nuclear-armed", "changed the business of music, to offering the world its first completely full-length computer-generated animated film", "exploration traded in for the comforts of home and domestic Bliss.", "165-room", "\"Oprah is an angel, she is God-sent,\"", "al Qaeda", "people", "Sharon Tate", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "South Korean President Lee Myung-bak,", "United States", "Burj Dubai tower", "speaking out about a cause someone feels passionate about.", "25", "Anil Kapoor", "President Obama and Britain's Prince Charles", "first to Twickenham Stadium, London ( 2016 -- 18 )", "regulatory site", "9.0 -- 9.1 ( M )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Bob Mould", "331 episodes", "2006", "Ginsburg", "Chandler", "Seth", "peacock"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5111936523621307}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, false, true, true], "QA-F1": [0.5, 0.4, 0.0, 1.0, 0.25, 0.0, 1.0, 0.1818181818181818, 0.0, 0.25, 0.0, 1.0, 0.14285714285714288, 0.6, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5714285714285715, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0, 1.0, 1.0, 0.26666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-3409", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-12746"], "SR": 0.421875, "CSR": 0.5213293650793651, "EFR": 0.6216216216216216, "Overall": 0.6185120723401973}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the New York Philharmonic Orchestra in North Korea to Dharamsala, India.", "The fourth gunshot wound, Van Hollen said, struck Peterson in the left bicep and appeared to have been fired from a rifle \"at some distance.\"", "dancing against a stripper's pole.", "the German Foreign Ministry", "$89", "South African ministers and the deputy president", "Pakistan", "Japan's", "The United Nations is calling on NATO to do more to stop the Afghan opium trade", "poor.", "head for Italy.", "Sixteen", "poems", "Iowa,", "Monterrey,", "a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "to find a novel way to raise awareness of global warming.", "the Obama and McCain camps", "The Ministry of Defense", "part of the proceeds from sales go to organizations that support prisoners' rights", "The minister later apologized, telling CNN his comments had been taken out of context.", "Fernando Torres", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars.\"", "civilians,", "March 3, 2008,", "Because 2\u00bd-year-old Ava Zinna ended up in the emergency room  this summer after an allergic reaction to peanuts,", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "The problems with the military option remain what they've always been,", "Christianity and Judaism,", "The Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "'overcharged.'\"", "since 1983.", "break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "A turlough, or turlach", "1934", "Kirk Douglas", "Radio City Music Hall", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Captain", "Department of Homeland Security", "a French colony", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6911780024509804}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.07692307692307691, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.8750000000000001, 1.0, 0.0, 0.35294117647058826, 1.0, 0.0, 1.0, 1.0, 0.4, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.08, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29411764705882354, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.33333333333333337, 1.0, 0.25, 0.6666666666666666, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1117", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-7047", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-8244", "mrqa_naturalquestions-validation-10396"], "SR": 0.578125, "CSR": 0.522216796875, "EFR": 0.7777777777777778, "Overall": 0.6499207899305556}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser, center,", "sportswear", "15-year-old", "July 23.", "Alwin Landry", "Korean-American missionary", "Chester Arthur Stiles, 38,", "United States", "Pakistan's High Commission in India", "Wednesday", "Wigan Athletic", "Adriano", "poems", "David Russ", "Philip Markoff", "Prison officials in Arizona are training dogs to sniff out cell phones.", "Longo-Ciprelli", "\"The Screening Room\"", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I'm just getting started.\"", "transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "his entire five-year term.", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "laundromats", "rural California,", "Robert Park", "11th year in a row", "100,000", "future relations between the Middle East and Washington.", "school.", "a plaque at the home of his great-grandfather", "death squad killings", "a nuclear weapon", "Kitty Kelley", "\"It's viewed as an anti-Russian device. Well, it's not.\"", "Oregon", "at the Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "And he won it after facing various challenges and turning them to his advantage.", "$3 billion, with further foreign direct investment exceeding $40 billion during the operations phase.", "Crap E-mail From A Dude", "Bobbyindal", "acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs", "angular rotation", "in a geographical coordinate system at which longitude is defined to be 0 \u00b0", "Darlene Cates", "Colette", "crow", "Rhys Williams", "21 July 2015", "channel 11", "January 15, 2016", "piano", "King Abdullah", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6124174277709675}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5882352941176471, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.8181818181818181, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5581395348837208, 0.2666666666666667, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-690", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516", "mrqa_searchqa-validation-4278"], "SR": 0.484375, "CSR": 0.5216346153846154, "EFR": 0.45454545454545453, "Overall": 0.5851578889860141}, {"timecode": 65, "before_eval_results": {"predictions": ["taking a medicine that contained the banned substance cortisone.", "Larry Zeiger", "The Ski Train", "emergency aid", "Officer Joe Harn", "Port-au-Prince, Haiti", "Saudi Arabia", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "identity documents", "Denver, Colorado.", "Jeffrey Jamaleldine took a bullet to his chin that blew out much of his jaw and nearly killed him while deployed in Iraq last year.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "great. \"I think it's the simplest thing. It's actually hard work and punctuality,\"", "The meter reader who led authorities last week to remains believed to be those of Caylee Anthony", "could be secretly working on a nuclear weapon", "delivered three machine guns and two silencers to the hip-hop star,", "Karen Floyd", "GOP state senators", "people are going to look at the content.", "April 22.", "Colombian government", "outfit from designer", "two", "Ozzy Osbourne", "Sarah,", "Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator, and Nancy Sutley, the Los Angeles deputy mayor for energy and environment, to lead the White House Council on Environmental Quality.", "Molotov cocktails, rocks and glass.", "eight.", "Fullerton, California,", "Hawaii", "Bill Haas", "A Lion Among Men.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Karl Kr\u00f8yer", "Gyanendra,", "Arlington National Cemetery's", "Gadahn, also known as Azzam the American,", "Turkey", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "Texas and Oklahoma to points east,", "$41.1 million", "unwanted horses", "a million", "at her 8th-grade graduation,", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful.", "Arnold Schoenberg", "N\u0289m\u0289n\u0289\u0289 )", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia,", "pyrotechnic", "Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "cryptids", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4990284670631538}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.25, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.47619047619047616, 0.0, 0.2222222222222222, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.07407407407407407, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.2222222222222222, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.40625, "CSR": 0.5198863636363636, "EFR": 0.8421052631578947, "Overall": 0.6623202003588518}, {"timecode": 66, "before_eval_results": {"predictions": ["Spanish Davis Cup hero Fernando Verdasco,", "they would not be making any further comments, citing the investigation.", "Iowa's critical presidential caucuses", "Iran's nuclear program.", "green-card warriors", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Booches Billiard Hall,", "Both men were hospitalized and expected to survive,", "Harris, whose real name is Clifford Harris, was arrested Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Pfc. Bowe Bergdahl", "many different backgrounds and religions.", "President Bush", "$17,000", "Employee Free Choice act", "assassination of President Mohamed Anwar al-Sadat at the hands of four military officers during an annual parade celebrating the anniversary of Egypt's 1973 war with Israel.", "\"He was mentoring them. He was trying to get them to do right, to be productive citizens.\"", "The worst snowstorm to hit Britain", "Arnold Drummond", "Madonna", "\"I hope people look at the content of the speech, not just the delivery.", "the commissions", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000", "The U.S. Food and Drug Administration Tuesday ordered the makers of certain antibiotics to add a \"black box\" label warning", "managing his time.", "1980", "Omar", "Scotland", "Thabo Mbeki,", "one of the most brutal genocides in modern history.", "his business dealings for possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "9-week-old", "dental work", "future relations between the Middle East and Washington.", "fake his own death", "a pregnant soldier was found in a hotel near Fort Bragg.", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "Apple Inc.", "38", "terrorists operating within its borders.", "Henrik Stenson", "1995", "The minivan ran a red light and struck two vehicles at an intersection,", "fear of losing their licenses to fly.", "Anjuna beach in Goa a few days before her death.", "\"You can go from rags to riches there. People still believe in that. It is not something that has gotten lost,\"", "not doing more since taking office.", "Television demonstrations", "American Indian allies", "Naturalization Act of 1790", "Sigurd", "blancmengier", "apples", "Sandia National Laboratory", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "joplin", "Italy", "I.M. Pei", "Numbers 22 : 22"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5088018882025267}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.07692307692307691, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.16, 0.0, 0.33333333333333337, 0.0, 1.0, 0.8421052631578948, 0.0, 0.6666666666666666, 1.0, 0.0, 0.058823529411764705, 0.5, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 0.6, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.09999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9523809523809523, 0.18181818181818182, 0.19999999999999998, 0.5, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3390", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-571", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-3383", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.359375, "CSR": 0.5174906716417911, "EFR": 0.6341463414634146, "Overall": 0.6202492776210412}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "Autobahn", "a large branched candlestick", "Jaipur", "tea", "the Ordovician geological period", "Martin Pipe", "Wordsworth", "Ginger Rogers", "a bus window", "borax", "United States Dollars", "peregrines", "B diminished", "muscle tissue", "hurdle", "Derby Stakes", "Parade", "Basketball Page 30", "HMS Amethyst", "lion", "sergeant", "whistling tune, the Colonel Bogey March,", "Cyprus", "King George VI", "ankle joint", "Greyfriars", "man-made", "flea", "a burial cloak", "The Big Bopper", "NBA", "L. P. Hartley", "Leander", "Arsenal", "Entropy", "Wadsworth", "green", "elia Earhart", "James Hogg", "lacrimal fluid", "Laufeyi Larson", "The Apartment", "Manfred von Richthofen", "Cain", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "Boston Red Sox", "1967 onwards", "absolute zero", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "Atlantic Ocean.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "bumblebee", "36 months old"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6694568452380952}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-4883", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.5625, "CSR": 0.5181525735294117, "EFR": 0.7857142857142857, "Overall": 0.6506952468487395}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast", "smen", "near the city of Cairo, Illinois", "the Americans", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "The Redwood National and State Parks ( RNSP ) are a complex of several state and national parks located in the United States, along the coast of northern California", "Zoe Zebra", "257,083", "Puerto Rico ( Rich Port )", "Harold Godwinson", "Gustav Bauer", "Shawn", "if the concentration of a compound exceeds its solubility", "the United States", "1603", "the `` round '', the rear leg of the cow", "1957", "360 members", "electron shells", "into the gastrointestinal tract through a series of ducts", "Lori McKenna", "Wisconsin", "Tbilisi, Capital of Georgia", "named after the Swedish astronomer Anders Celsius ( 1701 -- 1744 )", "1799", "Paul to the Philippians", "his last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2014", "three", "Sweden's long - standing policy of neutrality was tested on many occasions during the 1930s", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "Steve Russell", "the most times in a row", "4 January 2011", "New Zealand to New Guinea", "Boston Celtics center Bill Russell", "Seattle, Washington", "the internal auditory canal of the temporal bone", "2010", "Buddhism", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units within the National Health Service in England", "Diego Tinoco", "Henry Selick", "substitutes", "to provide school districts with federal funds", "1956", "April", "fearful man, all in coarse gray with a great iron on his leg", "huff & puff: can You blow down the third pig\u2019s brick home?", "Brad Silberling.", "1941", "Nick on Sunset theater", "July in the Philippines", "iCloud service", "Thursday", "bonobo", "posterior", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6896412857602373}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.29629629629629634, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.888888888888889, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 0.8571428571428571, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.5555555555555556, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.5714285714285715, 0.3076923076923077, 0.25, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_searchqa-validation-12035"], "SR": 0.515625, "CSR": 0.5181159420289856, "EFR": 0.8709677419354839, "Overall": 0.6677386117928938}, {"timecode": 69, "before_eval_results": {"predictions": ["whitechapel", "Uganda", "definitely, maybe", "Brazil", "constellations", "pieces are used to attack and capture the opponent's pieces,", "Bristol", "Florida Panhandle", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "Daltonism", "Cambodia", "Prussian Landsturm", "Russia", "Moulin Rouge", "cooperative", "180", "blue", "Tommy Burns", "Judi Dench", "Andre Agassi", "hawk", "The Times of India", "le le Carr\u00e9", "New Guinea", "Albania", "animals", "Mata Hari", "different levels of importance of human psychological and physical needs.", "polo", "gulliver", "Rating Organization", "Saturday Night Live", "Bayern", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Octavian", "barrels, wooden casks, kegs, or tubs", "One Canada Square in Canary Wharf", "Charlie Brown", "corvidae", "Snarked", "general strike to support mine workers", "kanagawa", "sifton", "Walter Mondale", "fresh nuclear fuel", "the plane crash in 1959", "Scotty Grainger Jr.", "Harry Potter series, The Boy in the Striped Pyjamas", "3.9 mi", "$1.5 million", "buddhism", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "Space Shuttle orbiter", "Smithfield", "Ivan Denisovich", "10 Years"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5499526515151515}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.2, 1.0, 1.0, 1.0, 0.4, 0.8, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-608", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-9025", "mrqa_searchqa-validation-16464"], "SR": 0.453125, "CSR": 0.5171875, "EFR": 0.8, "Overall": 0.6533593750000001}, {"timecode": 70, "before_eval_results": {"predictions": ["leigh Ann Fetter", "three", "high-jumping", "physicist Stephen Hawking", "james p\u00e4rt", "watchmaking", "Edmund Cartwright", "vine plagues", "teaching evolution in violation of a Tennessee state law.", "Philip Larkin", "wythes", "bayford", "hedgehog", "jack Brabham", "Peterborough United", "Herrenhausen", "precalculus", "flarney", "pistol sampras", "Prussian 2nd Army", "the Red sea", "cats", "The French Connection", "george Orwell", "moaning Myrtle", "Milan", "Dubai", "CeeLo Green", "photographer", "Justin Bieber", "Ionian Seas", "m\u00e1ji\u00e0ng", "scar", "stars on 45 Medley", "sedgefield", "Bowie knife", "Istanbul", "meryl Streep", "Achille Lauro", "Ian Botham", "stop motion effects", "malmullet", "Ellis Island", "Melanesian", "trapezoid", "Dick Advocaat", "john Huston", "starry starry night", "thomas Harris", "Martin Vanuren", "Moscow", "it was purchased by Movie Gallery in 2005", "the governor of West Virginia, who is elected to a four - year term at the same time as presidential elections", "Payaya Indians", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition in a Provo, Utah, hospital,", "2010", "South Korea", "Jerry Rice", "leotard", "October 7, 1913", "hips"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5223980880230881}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.36363636363636365, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.2222222222222222, 0.38095238095238093, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-6183", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-6644", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-3914", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-3881", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-10001", "mrqa_naturalquestions-validation-4207", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-2817"], "SR": 0.46875, "CSR": 0.5165052816901409, "EFR": 0.8235294117647058, "Overall": 0.6579288136909693}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California (USC) Trojans", "1935", "James Worthy", "David Weissman", "Moon Shot", "Kim Sung-su", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "L\u00edneas A\u00e9reas", "October 15, 2013", "Neha Sharma", "Netherlands", "Quentin Coldwater", "1853", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "John Anderson", "11", "Tempo", "7 miles", "1942", "Lollywood and Pollywood", "Carver Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone (SEZ)", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "detained indefinitely without trial", "France", "Wordsworth", "Spain", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "freeview"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8068229166666667}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2059", "mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.734375, "CSR": 0.51953125, "EFR": 0.7647058823529411, "Overall": 0.6467693014705882}, {"timecode": 72, "before_eval_results": {"predictions": ["read therefore", "amount to a crime and deserve punishment", "100,000", "2004", "the NFL", "9th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range", "nearby objects show a larger parallax than farther objects", "Iraq", "1885", "the final episode of the series", "Wisconsin", "the magnetic stripe `` anomalies '' on the ocean floor", "stems and roots of certain vascular plants", "the Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "the Rock", "2010 World Series", "Massachusetts", "Mark Jackson", "burt Hammersmith", "the 180th meridian in a 360 \u00b0 - system )", "need to repent in time", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane, resulting in an electrical potential or ion concentration difference across the membrane", "Kida", "Instagram's own account, with over 234 million followers", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "federal government", "2013", "England", "the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "when the cell is undergoing the metaphase of cell division", "79", "the League of Communists of Yugoslavia party and a ruling elite", "interphase", "in England, births were initially registered with churches, who maintained registers of births", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "Virginia", "Dante Pastula", "Daya Jethalal Gada", "state ownership of the means of production", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "de Havilland Moth", "architecture", "Bermuda", "win world titles in four weight classes", "the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "Parodiable", "a prostitute", "Ashlee Simpson", "d'Ivoire"], "metric_results": {"EM": 0.484375, "QA-F1": 0.571275945996208}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, true, false], "QA-F1": [0.125, 0.3870967741935484, 0.07999999999999999, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.2857142857142857, 0.6, 0.2222222222222222, 0.0, 0.4, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7692307692307692, 0.2222222222222222, 1.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-15285", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.484375, "CSR": 0.5190496575342466, "EFR": 0.7272727272727273, "Overall": 0.6391863519613948}, {"timecode": 73, "before_eval_results": {"predictions": ["The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person", "Kirstjen Nielsen", "May 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code - breaking intelligence", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "John Smith", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "india", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning Thieves", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the Indian Civil Service", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius ( 1701 -- 1744 )", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1877", "to `` help bring creative projects to life ''", "Joan Baez", "Senator Joseph McCarthy", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Jurchen Aisin Gioro clan in Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Saturn", "rubber", "Reggie", "Tampa", "1874", "January 28, 2016", "Jaipur", "18th", "in July for A Country Christmas", "taro", "Match Game", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.609375, "QA-F1": 0.688764880952381}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [0.8666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-4104", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_newsqa-validation-270", "mrqa_searchqa-validation-2100"], "SR": 0.609375, "CSR": 0.5202702702702703, "EFR": 0.68, "Overall": 0.6299759290540541}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Bungalow Candies", "propeller", "Starbucks", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "labor unions", "greece", "a blitz", "new wave", "a commune", "a ring", "Thames", "mask", "power play", "fairy tales", "David", "The Color Purple", "whales", "Jane Addams", "Shakespeare", "Tanzania", "Biosphere 2", "2", "death", "Henry Wadsworth", "Jeb Bush", "Basel", "humility", "bdellium", "The Mamas", "diatomaceous", "the debt ceiling", "pig", "golfo", "Existentialism", "ashes", "palindromes", "jack London", "Isaac Newton", "Charles Stuart", "Kevin Costner", "Apocalypse Now", "clef", "uranium", "Louisiana", "The Hot Chick", "red Worm", "August 21", "1990", "four", "feshie", "Popeye", "Denmark", "Trappist beer", "5,656", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County, Wisconsin"], "metric_results": {"EM": 0.5, "QA-F1": 0.5755208333333333}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true], "QA-F1": [0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-10874", "mrqa_searchqa-validation-14913", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-6427", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15387", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-5958", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-7832", "mrqa_searchqa-validation-13598", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-8909", "mrqa_triviaqa-validation-6580", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-1307"], "SR": 0.5, "CSR": 0.52, "EFR": 0.9375, "Overall": 0.6814218750000001}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "Pebble Beach", "SUVs", "Turing", "John B. Watson", "hydrogen", "Great Britain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "9th century", "Asuka", "Jason Momoa", "Vinnie Jones", "the United States Congress", "Spanish missionaries, ranchers and troops", "Gustav Bauer", "art of the book and architecture ; and also including ceramics, metal, glass, and gardens", "white blood cell in a vertebrate's immune system", "around 2.45 billion years ago ( 2.15 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Tevye", "March 31, 2017", "incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "55 -- 69 %", "summer of 1979", "Charles Evans Hughes, Harlan Fiske Stone, and William Rehnquist", "Spanish / Basque origin", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "The Yankees", "studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units", "Rigg", "electron donors", "New England Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "ourselves alone", "Orrest Head", "2005", "Yubin, Yeeun", "100 metres", "sedative", "a missing sailor whose five Texas A&M University crew mates were hoisted out of the Gulf of Mexico earlier in the day after their sailboat capsized.", "'perezagruzka,' which means 'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Zero Mostel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.706138392857143}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.14285714285714288, 0.0, 0.9333333333333333, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.08333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-4180", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-3069"], "SR": 0.609375, "CSR": 0.5211759868421053, "EFR": 0.68, "Overall": 0.6301570723684211}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "scotch", "repechage", "the island narrows between Loch Resort (Reasort) (opposite Scarp) on the west and Loch Seaforth (Shiphoirt)", "Angela Anderson Lee", "Costa Brava", "Northumberland", "a dual purpose breed, docile, and colorful,", "Mrs. Lovett", "the Atlantic", "Bleak House", "52", "the Indus valley", "Selfie", "Jaws", "Charlie Cairoli", "Utrecht", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick Kielty", "8 minutes", "Tribbiani", "Red Crescent", "Schumann", "Margaret Thatcher", "Hooky Street", "Darius Danesh", "Andrew Lloyd Webber", "Bonn", "lieutenant-general", "snakes", "Coral Sea", "Constantine", "Madonna", "a hole-in-one", "Millerlite beer", "knee", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "Bernard Spilsbury", "fifty-six", "196 BC", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "fight outside of an Atlanta strip club", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6577838827838828}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-7046", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-157", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.59375, "CSR": 0.5221185064935066, "EFR": 0.7307692307692307, "Overall": 0.6404994224525475}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1884", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "lola Dee", "master builder", "UFC 50: The War of '04", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "\"O\", \"La Nouba\", \"Myst\u00e8re\", \"Alegr\u00eda\", and \"Quidam\"", "half of the Nobel Prize in Physics", "glee", "Paul Corbould", "Ontogenetic depth", "2 November 1902", "December 1993", "orisha", "2006", "Oberst-Gruppenf\u00fchrer", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "American", "Norway", "the Military Band of Hanover", "around 8000 BC", "2011", "Peter Seamus O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "a Rugby Sevens competition for the twelve Aviva Premiership clubs that will play the following season", "Biola University", "Eugene O'Neill", "Morita therapy", "Lola team", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "Bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Mary Berry", "Mel Gibson", "1987", "San Francisco", "john johnson johnson", "Vancouver", "onto the college campus.", "nearly $106.5 million", "15-year-old", "Cleopatra", "Arm & Hammer", "the Strait of Hormuz", "drumroll"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6941220238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.7499999999999999, 0.0, 1.0, 1.0, 0.25, 0.5, 1.0, 0.28571428571428575, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.8000000000000002, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-2982", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.59375, "CSR": 0.523036858974359, "EFR": 0.8076923076923077, "Overall": 0.6560677083333334}, {"timecode": 78, "before_eval_results": {"predictions": ["Forsyth Street at the foot of the Manhattan Bridge", "August 1991", "Nigel Lythgoe, Mia Michaels, and Adam Shankman", "necessary, but not sufficient, for normal electrical activity within the heart", "1956", "Atlanta, Georgia", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "1986", "Ali", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "the internal reproductive anatomy ( such as the uterus in females )", "May 2017", "mid-1980s", "the S - stage of interphase", "1956", "8.7 %", "Little G minor symphony '', No. 25", "Divyanka Tripathi", "Newfoundland", "Norway", "31 December 1960", "postgraduate training", "Jesus'birth", "1992", "George Strait", "Allhallowtide", "1964", "midpiece", "2004", "$6.2 trillion", "7000301604928199000", "James Martin Lafferty", "Cairo, Illinois", "Sylvester Stallone", "pop ballad", "eusebeia", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "military experts", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "twin-faced sheepskin with fleece on the inside, a tanned outer surface and a synthetic sole.", "5,922", "1866", "two", "2006", "eight or nine", "Georgian Bay", "the Thames", "Mefistofele", "red"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5702136405261404}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true], "QA-F1": [0.6363636363636364, 0.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.5, 0.5714285714285715, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7852", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-1534", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_hotpotqa-validation-1250", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.484375, "CSR": 0.5225474683544304, "EFR": 0.6060606060606061, "Overall": 0.6156434898830073}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "the Sugar Bowl", "1950s", "heavy metal", "Koon-hei Chen", "1875", "The The The satirical", "his most brilliant student", "Juilliard School", "The 1st World Outgames", "1812", "Peach", "1935", "the Philadelphia Eagles", "Victorian England", "UFC 50: The War of '04", "Australian", "superhuman abilities", "skiing and mountaineering", "Baudot code", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney ( ) is the state capital of New South Wales", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "Shameless", "1241 until his death in 1250", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "Max", "gollum", "Melbourne", "paddington bear", "54-year-old", "millions of Americans", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond, Virginia", "Venezuela", "the Stone Age", "rally at the State House next week"], "metric_results": {"EM": 0.59375, "QA-F1": 0.70390625}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, true, true, false], "QA-F1": [0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-5741", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-808", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-4714", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-4416", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_searchqa-validation-11106", "mrqa_newsqa-validation-4059"], "SR": 0.59375, "CSR": 0.5234375, "EFR": 0.8461538461538461, "Overall": 0.6638401442307693}, {"timecode": 80, "before_eval_results": {"predictions": ["Anthony", "Champagne", "\"The chief business of the American people is business\"", "beach volleyball", "\"Jack & Diane\"", "hot springs", "the Philosopher's Stone", "Dell", "pro bono", "Donald Trump", "epitaphic", "Glinda", "Yggdrasil", "rattus", "Department of Chemistry", "The Merry Wives of Windsor", "kowtow", "Mars", "Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "chemy", "Lon Chaney", "salato", "a katzenjammer", "Cuisinart", "travertine", "Bob Dole", "the Ross Ice Shelf", "director", "Taiwan", "California grizzly bear", "Pinocchio", "the Czech Republic", "the opera house", "bison", "journey", "Jodie Foster", "Cleopatra VII", "Rick O'Connell", "White Fang", "bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1937", "53", "The Lightning Thieves", "Brazil", "Edinburgh", "gennadiy Samokhin", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5616071428571429}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4389", "mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-8319", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9590", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-3111", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-4135", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.484375, "CSR": 0.5229552469135803, "EFR": 0.696969696969697, "Overall": 0.6339068637766554}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "albania", "The Generation Game", "The Firm", "red hair", "fourteen", "Spain", "Georgia", "wren", "sow", "communion", "Turkey", "Anastasia Dobromyslova", "every ten years", "the Matterhorn", "Lake Placid", "$100", "Liverpool", "the Count Basie Orchestra", "Manhattan", "arch", "Esmeralda's Barn night  club", "Ajman", "Bombay", "4468 Mallard", "Ambroz Bajec-Lapajne", "Apollo", "1963", "Bologna", "Dennis Weaver", "Coleraine", "jean", "Timothy", "Addis Ababa", "motorcycle", "kidney", "BMW", "salsa", "Mark Twain", "Doctor Who", "Yosemite National Park", "IBM", "seven", "the First World War", "passion fruit", "kursk", "7", "Aberdeen", "100 years", "Benedict XVI", "Jesse Triplett", "Orlando", "LED illuminated display", "41st", "Mel Blanc", "Mauthausen-Gusen", "two paintings by Pablo Picasso, Bjoern Quellenberg, a spokesman for the Kunsthaus,", "antihistamine and an epinephrine auto-injector", "cowardly lion", "Danny Elfman", "Bolivia", "an intercalary year", "Val Kilmer"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5070684523809523}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-3910", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-1118", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-2573", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_triviaqa-validation-6728", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-2103", "mrqa_searchqa-validation-14665"], "SR": 0.46875, "CSR": 0.5222942073170731, "EFR": 0.6764705882352942, "Overall": 0.6296748341104734}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Illinois", "1,693", "Melville, NY, USA", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "Regional Rural", "Tufts University", "Hammer", "Wiltshire, in the south west of England", "Isla de Xativa", "her gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Whoopi Goldberg", "5.3 million", "six", "ribosomal", "Brady Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Hallett Cove", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "antelope", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "American comedian and actor", "the Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association (NBA)", "Indian", "the Corps of Discovery", "pubs, bars and restaurants", "Andrew Johnson", "the US state of Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "illnesses", "Thomas Joseph", "drawn on the bank's own funds and signed by a cashier", "31 March 1909", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Juri Kibuishi", "the sins of the members of the church", "Superman", "Richard Nixon", "right", "Edward VIII"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6973247904234158}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.08695652173913043, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.609375, "CSR": 0.5233433734939759, "EFR": 0.8, "Overall": 0.6545905496987952}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys: Confessions of a Bad Girl", "Mickey Mantle", "the Titanic", "the Nobel Prize", "John Edwards", "Graceland", "the Cardamom Mountains", "a elevator", "Edward Murdstone", "Terminator For Governor", "a nonsense", "a vowel", "a goat", "Splash Down in the Pacific", "The Ghost of Tom Joad", "Dracula", "the West Africa", "a wind instrument", "Mrs. Miniver", "The Office", "Italy", "a keynote", "sheep", "Casey Jones", "Brady Hawkes", "Hope", "the navy", "Dresden", "a flippant", "Arkansas", "Duchamp", "a pillage", "toilet paper", "Sesame seeds", "Iceland", "a nocturnal mammal", "Monty Hall", "a bee", "Janet Reno", "a Connecticut Yankee", "Gianlorenzo Bernini", "Essen", "Appomattox", "Thailand", "a man who had died", "a cereal", "C.J. Parker", "Theodor Seuss", "Whitehorse", "Scott McClellan", "Edd Kimber", "six", "Phoebe ( MacKenzie Mauzy ) were born onscreen as the daughters of supercouple Ridge Forrester ( Ronn Moss, later Thorsten Kaye ) and Taylor Hayes ( Hunter Tylo )", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester Ben \"Benny\" Binion", "India", "1959", "two remaining crew members", "her abusive husband"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5642857142857143}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.7142857142857143, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7445", "mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-3958", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-7313", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-5144", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14643", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-3314", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-1331"], "SR": 0.484375, "CSR": 0.5228794642857143, "EFR": 0.7878787878787878, "Overall": 0.6520735254329004}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony of Padua", "roof", "Cuisinart", "glands", "the Boston Massacre", "Truthful or creditable", "Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America Corporation", "Cleopatra", "Colorado Springs", "diamond", "Picasso", "a mansion", "Pope John Paul II", "boot", "Herakles", "South Dakota", "natural selection", "Secretary of the Interior", "Cyrus the Younger", "Humpty Dumpty", "Bo Schembechler", "Gucci", "Vermont", "chimp", "icon", "the Man in the Iron Mask", "New Zealand", "Vladito Schnabel", "Phil of the Future", "Dean Fay", "Uruguay", "Doctor Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Harry Winston", "the Flag of the United States of America", "herb", "the stiletto", "cheese", "Kentucky Wildcats", "Bora Bora", "Titanic", "a physician", "Fisherman's ring", "RBIs", "the forex market", "Dorothy Gale", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Caledonian", "Rome", "lakes and rivers", "Disney California Adventure", "Lochaber, Highland, Scotland", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe and found his qualifications mean little as a refugee.", "Baku"], "metric_results": {"EM": 0.46875, "QA-F1": 0.597664835164835}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.9743589743589743, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-13797", "mrqa_searchqa-validation-1686", "mrqa_searchqa-validation-12427", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6001", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-11856", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-1219", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-2558", "mrqa_newsqa-validation-1793", "mrqa_newsqa-validation-2653", "mrqa_triviaqa-validation-5654"], "SR": 0.46875, "CSR": 0.5222426470588235, "EFR": 0.7941176470588235, "Overall": 0.6531939338235294}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "The Little Old Lady", "Cochise", "Langhorne Clemens", "Margaret Mitchell", "The Big Red One", "a liqueurs", "endodontist", "a desktop microcomputer", "South Dakota", "Hercule Poirot", "Frasier Crane", "Brinton McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "Flav", "I.M. Pei", "The Name of the Rose", "a weak executive", "Norway", "Meriwether Lewis", "\"Where there is hatred, let me sow love... where there is despair, hope\"", "Steve McQueen", "Firebird", "Sweet Home Alabama", "Vietnam", "Petroleum", "Mike Huckabee", "the principle of no taxation without... to play in securing what Section XV of the Virginia Declaration of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "Help Myself", "Manitoba", "Madonna", "turban", "Perseid", "Holstein Rood", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Jayne Torvill and Christopher Dean", "the Black Eyed Peas", "\"I think, therefore I am\"", "the Bulgarian 2nd Army", "prophets", "1987", "Toy Story", "Harriet Tubman", "Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Henry, the oldest tuatara to mate at Southland Museum, enjoys a cold shower in his home in New Zealand.", "london haerta Rios, also known as \"La Burra\" or \"El Junior,\" a top lieutenant of the Beltran Leyva cartel.", "jobs up and down the auto supply chain", "Kristy Swanson"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7057988365800865}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.07999999999999999, 0.6363636363636364, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-6557", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-625", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-2188", "mrqa_naturalquestions-validation-2819", "mrqa_triviaqa-validation-1386", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.5625, "CSR": 0.5227107558139534, "EFR": 0.8571428571428571, "Overall": 0.6658925975913621}, {"timecode": 86, "before_eval_results": {"predictions": ["the cob", "Barbara Walters", "the Bosphorus and the Ural Mountains", "Hoover", "\"Stopping by Woods on a Snowy Evening,\"", "Cheetah Rivera", "coffee milk", "the Northern Leopard Frog", "Knott's Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Piscis Austrinus", "Charles de Gaulle", "a cathode", "Bernini", "Augustus", "Manuel Noriega", "Abraham Lincoln", "Anne Boleyn", "modify", "Eyelids", "Bank of America", "copper", "push", "Kiss Me, Kate", "John L. Sullivan", "plutonium", "the atom", "fermented Garlic Butter Crescent Rolls", "Amistad", "A down-and-out golfer attempts to recover his game and his life with help from a mystical caddy.", "The Simpsons", "Ladies Pro Tour", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge family", "Jammu and Kashmir", "the Great Seal", "The Empire Strikes Back", "Admiral Lord Nelson", "Billy Bob Thornton", "Meriwether Lewis", "Lima beans", "Will & Grace", "the Octopus", "De Wayne Warren", "2017", "Trinidad", "Twitty", "golf", "Dialogues des Carm\u00e9lites", "England", "35,124", "between the ages of 14 to 17.", "software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6857514880952381}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5714285714285715, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-3046", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-15956", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-6903", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-783", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-1867"], "SR": 0.578125, "CSR": 0.5233477011494253, "EFR": 0.7407407407407407, "Overall": 0.6427395633780332}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "the zona glomerulosa (from and into the tubular fluids, respectively) of the kidney, thereby indirectly influencing water retention or loss, blood pressure and blood volume.", "the late 19th and early 20th centuries", "Tom Jones", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "\"Grimjack\" (from First Comics) and \"Firestorm\", \"The Spectre\", and \"Martian Manhunter\"", "Easy", "Dayton Memorial Hall", "Gareth Barry", "Robert John Day", "Bambi, a Life in the Woods", "1896", "The Apple iPod+HP", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedo boats", "Dante", "Glendale, Arizona", "Boston Red Sox (Korean: \uae40\uc120\uc6b0, Hanja: \u91d1\u5584\u5b87,]", "Netherlands", "Dallas/Fort Worth", "Althea Rae Janairo", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever", "Haryana", "1837", "Blackpool Football Club", "Nasim Pedrad", "DS Virgin Racing Formula E Team", "explores the lives of those that either own exotic animals or have been captured for illegally smuggling them,", "1943", "Paradise, Nevada", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "(29 September 1888 \u2013 20 May 1937)", "2015", "the Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Damian Green", "Gary Oldman", "Alanis Morissette", "Employee Free Choice act", "\"peregruzka,\" which means 'overcharged.'\"", "Port-au-Prince", "Martina Navratilova", "Brazil", "Rocky and Bullwinkle", "baseball"], "metric_results": {"EM": 0.5, "QA-F1": 0.5791294642857143}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, false, true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.4, 0.2, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809523, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-3946", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-14393", "mrqa_searchqa-validation-4094"], "SR": 0.5, "CSR": 0.5230823863636364, "EFR": 0.84375, "Overall": 0.6632883522727273}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "first to utilize Audio-Animatronics", "Continental Army", "1874", "(57 B.C. - A.D. 935)", "January 16, 2013", "Theodore Haynes", "Apple Lisa", "Veyyil", "Victoria, Duchess of Kent, along with her attendant, Sir John Conroy, concerning the upbringing of the Duchess's daughter, the future Queen Victoria.", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide Miethke", "Pensacola", "Consigliere", "Orson Welles", "7", "The Bologna Process", "Peoria, Illinois", "Iran", "Dick Ebersol", "Philip K. Dick", "University of Texas Longhorns football", "O", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German shepherd", "The Vaudevillains", "Mansoor Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "the Twist", "1,462", "Manchester City", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills and North Hollywood", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "diastema", "Thames Street", "stoppard", "brazil", "Dube, one of South Africa's most famous musicians, was killed in an attempted car-jacking as he dropped his children off at a relative's house,", "average of 25 percent", "super-yacht designers Wally", "meat of various species", "Livin' On A Prayer", "the electoral college", "joseph kipling"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6702327035886819}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.08695652173913045, 0.4, 1.0, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2784", "mrqa_hotpotqa-validation-1048", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-3009", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-5078", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1623", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.5625, "CSR": 0.5235252808988764, "EFR": 0.8571428571428571, "Overall": 0.6660555026083468}, {"timecode": 89, "before_eval_results": {"predictions": ["Michael Manasseri", "various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley", "Levi Weeks", "Durrani Empire", "Arvo P\u00e4rt", "\"The Itchy & Scratchy Show\"", "First Street", "5249", "the Dutch Empire", "Black Swan", "Ready to Die", "October 20, 2017", "antelope", "Lord's Resistance Movement", "1965", "1943", "the Big 12 Conference", "1959", "1932", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "University of Kentucky", "\"The Sun on Sunday\"", "Song Kang-ho, Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies.", "B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One coverage on TV, radio and online.", "11,163", "four", "Bernd Bertie", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "pardus", "Prudential Center", "ten", "Conservatorio Verdi", "north", "State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "Raymond Benson", "World War II", "George Santayana", "label products that contain any of the most common allergens", "an annual road trip", "101", "Oil and Vinegar Dispenser", "experimented with marijuana", "saliva", "Venus Williams"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7329579274891775}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-1550", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-1504", "mrqa_newsqa-validation-3736", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.65625, "CSR": 0.525, "EFR": 0.8181818181818182, "Overall": 0.6585582386363636}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeleton", "Joaquin Phoenix", "Whiskey", "the integument", "Harley-Davidson", "New Coke", "Mrs. Barbara Bush", "unions", "University of Hawai'i at Manoa", "the leg", "Cristina Yang", "The Omega Man", "van Gogh", "Sumbawa", "Winnipeg", "Best of the charts", "Paddington Bear", "Google", "skyscraper", "2016", "television news", "a rock star's brutal murder", "a Czechoslavak resistance leader", "seven", "Nike", "a buck", "Sweden", "Lamborghini", "a deter-", "John Philip Sousa", "oregano", "New South Wales", "Women's Christian Temperance Union", "Thanh", "Martha's Vineyard", "No. worn by Wayne Gretzky", "a sweet fall apple dessert", "Transformers: Earth Wars", "a jazz-influenced symphonic poem", "Taiwan", "The Parent Trap", "Aloha", "Gustave Eiffel", "Corbett", "Michael Jackson", "Firebird", "Sicily", "Harold Ford", "a dollar", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "a monthly allowance", "Aung San Suu Kyi", "75", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5224931318681318}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-7340", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-16072", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-4781", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.484375, "CSR": 0.5245535714285714, "EFR": 0.7878787878787878, "Overall": 0.6524083468614719}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Crayola", "giant", "lubricant", "Top Banana Bar", "the Chesapeake Bay", "the first word of the language", "AILD", "Macbeth", "Suez Canal", "Stephen Hawking", "Ecuador", "New York City", "Iowa Broadcasters Association", "acetylene", "scrapple", "Fred Thompson", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "St Lewis", "Obliqued", "Cracker Jack", "Ford", "the high jump", "the phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "France", "Orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes Mountains", "Ovid", "2012", "Grendel", "ROE", "Ascomycota", "Dolley Madison", "John Wilson Townsend", "Lost in America", "eyes", "the sound barrier", "Germany", "a jazz funeral without a body", "Nala", "Etienne de Mestre", "USA43SC6390", "subspecies", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse University", "Stuttgart", "a program to help people buy converter boxes that make old TVs work in the new era.", "legislation that would let prisons jam cell-phone signals within their walls.", "Bed and breakfast"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5528799019607843}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.19999999999999998, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-7773", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-10563", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-5611", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.515625, "CSR": 0.5244565217391304, "EFR": 0.8387096774193549, "Overall": 0.662555114831697}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "the Shar'ia penal code", "Yente", "Occlusion", "initiative process", "alfalfa", "Phaedra", "Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "Australian", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "\"to compare\"", "The Secret", "a perch", "overture", "Frederick Douglass", "William Conrad", "Denver", "the Burning Bush", "a gastropod", "Indian tribes", "Australia", "Freaks and Geeks", "Manet", "Finding Nemo", "Frdric Chopin", "a tangletechnik", "Donna Mills", "Amman", "Van Halen", "Permanent Select Committee on Intelligence", "amyotrophic lateral sclerosis", "grapes", "Nancy Lopez", "\"As a soldier, and a good one\"", "Hudson Bay", "Beguile", "Aboite- Commonly thought to be named for an Indian chief.", "money changers", "a bread", "a mead", "Mossad", "a menagerie", "aide-de-camp", "Judiththia Aline Keppel ( born 18 August 1942 ) was the first one - million - pound winner on the television game show Who Wants to Be a Millionaire? in the United Kingdom", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "de Goya", "Shut the *freak* up", "Panther", "paracyclist", "XXIV Summer Universiade", "Asashoryu's wrestling style,", "The planned Kingdom City project", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.515625, "QA-F1": 0.599997434318555}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.13793103448275865, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-4268", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-1688", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-1122", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.515625, "CSR": 0.524361559139785, "EFR": 0.8387096774193549, "Overall": 0.662536122311828}, {"timecode": 93, "before_eval_results": {"predictions": ["Department of Labor", "Standard Oil", "Kings", "English", "a Vicar Apostolic of New Mexico", "Clark", "Myanmar", "The Carpenters", "Wyoming", "Queen of Scots", "Crimean War", "british", "a thermostat", "Hasty", "sapphire", "a dogwood", "a MOVIE \"NIGHT\"", "grace", "a wagons", "the most recent Davis Cup Nations Ranking from Group III of its Zone", "Blackbeard", "William of Orange", "Dickinson", "the stikhos", "Simon Wiesenthal", "Mercury and Venus", "LODGE-PODGE", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "hallow", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "flautas", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a Bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "the Canongate", "War of the Worlds", "January 17, 1899", "in which there is a decline in population density", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan, or MAP,", "a lump in Henry's nether regions was a cancerous tumor.", "Stuttgart on Sunday.", "Charlie Murphy"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7309602130325814}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473685, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12822", "mrqa_searchqa-validation-2685", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14358", "mrqa_searchqa-validation-5053", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12174", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-10500", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3138"], "SR": 0.65625, "CSR": 0.5257646276595744, "EFR": 0.8636363636363636, "Overall": 0.6678020732591876}, {"timecode": 94, "before_eval_results": {"predictions": ["assassination", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "David Lynch", "Nazareth", "pine", "Wild Bill Hickok", "2D Focus", "stars", "vodka", "lava", "anthrax", "J Jamaica", "Sacher Torte", "Hillary Clinton", "coyote", "CVS/pharmacy", "hot springs", "the Confessions of Nat Turner", "Marquette", "overbite", "Hannibal", "cytokinesis", "Thomas Jefferson", "a millimeter", "Megan Fox", "Eurydice", "Unicef", "the Little Bighorn", "Marie Curie", "the Archangel Cat", "Dustin Hoffman", "Nebraska", "E-T", "vodka", "John", "LOUIS XIV", "vnus impudique", "Yellow pages", "Jaguar", "Scout Finch", "Liechtenstein", "The Dark Knight", "Pulp Fiction", "Mao Zedong", "Nereid", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson and Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle-distance runner", "HackThis Site", "Arthur Schnitzler's 1926 novella \"Traumnovelle\" (\"Dream Story\")", "1985", "one of the most sought-after fugitive outside the country's rebel leaders.", "seven", "Six", "has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\" leaving them \"vulnerable to disruption,\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.564693657635468}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.6, 1.0, 0.0, 1.0, 1.0, 0.06896551724137931]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-4064", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-4661", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.46875, "CSR": 0.5251644736842105, "EFR": 0.7352941176470589, "Overall": 0.6420135932662538}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "Genie", "the cassowary", "Robbie Turner", "a palette", "ice cream", "Cherry baby", "Tajikistan", "Theology of God", "Forrest Gump", "a piles of papers", "a hot dog", "Guy Ritchie", "Dixie", "Alfred Nobel", "Karen Blixen", "The Edge Bar", "Sindbad", "a temple tower", "the toe", "Pennsylvania", "\"War of the Worlds\"", "Peter Connolly", "Steve Jobs", "Jiles P. Richardson", "a manwich", "L.l", "Pompey", "Jane Grey", "Eugene V. Debs", "California", "Troy", "Antoinette Perry", "The Crucible", "rabbit", "The Twelve Colonies of Man", "Rugby School", "Pluto", "Francis", "Samuel", "Arthur Miller", "Billie Holiday", "Batman Forever", "improv", "Scrabble", "2016", "a palmetto", "the north", "the Barbary Coast", "Hippos & baboons", "Neal Dahlen", "a permanent, fast - drying painting medium consisting of colored pigments mixed with a water - soluble binder medium ( usually glutinous material such as egg yolk or some other size )", "Reverend J. Long", "Bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions, served in a three-part sesame seed bun.", "Cavalcade", "FIFA Women's World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "its new restaurant next to the home of Mona Lisa as something completely normal.\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5436501887340301}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.7317073170731707, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809525]}}, "before_error_ids": ["mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-4660", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-8999", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-7018", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_searchqa-validation-5472", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.484375, "CSR": 0.5247395833333333, "EFR": 0.7575757575757576, "Overall": 0.6463849431818182}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Melanie Martinez", "InterContinental Hotels Group", "Kaley Christine Cuoco", "1877", "Everywhere", "T.S. Eliot", "states had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "30 October 1918", "Florida", "Robyn", "Vincent Price", "Nicole Gale Anderson", "Tiffany Adams Coyne", "Scheria", "Eddie Murphy", "20 November 1989", "Ben Savage", "Manuel Pessanha ( Pesagno )", "The Star Spangled Banner", "Thomas Stone", "meaning `` save, rescue, savior ''", "the Hudson Bay", "March 11, 2018", "Khrushchev", "Ciara Brady", "International Border ( IB )", "Ancylostoma duodenale", "Toronto", "Wakanda and the Savage Land", "The player character is recruited into the Grey Wardens, an ancient order that stands against demonic forces known as `` Darkspawn ''", "1993", "the Intertropical Convergence Zone ( ITCZ )", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "Thomas Middleditch", "September 19, 2017", "a convergent plate boundary", "domestication of the wild mouflon in ancient Mesopotamia", "fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Krypton", "December 14, 2017", "1957", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower Peninsula", "11,163", "Jaguar Land Rover Limited", "his son", "propofol", "Courtney Love", "his Seattle home.", "(piano)", "Ethel", "Africa", "1919"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6211604420731707}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8292682926829269, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.125, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.5714285714285715, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5468", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_hotpotqa-validation-3348", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-8266", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.546875, "CSR": 0.5249677835051547, "EFR": 0.896551724137931, "Overall": 0.6742257765286171}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Rajendra Prasad", "2001 -- 2002 season", "New England", "2007", "New Croton Reservoir", "1960s to the mid-1970s", "Bart Cummings", "Maggie", "Arnold Schoenberg", "15,000 BC", "meditation", "wagen VIII Maus", "A status line", "Richard Bremmer", "contestant", "1898", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Hermia", "Hans Christian Andersen", "Procol Harum", "2018", "the world", "James Rodr\u00edguez", "Nucleotides", "Hathi Jr", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals ), blood plasma and lymph in the`` intravascular compartment ''", "1983", "Instagram's own account", "Revelation was the last book accepted into the Christian biblical canon", "when matching regions on matching chromosomes break and then reconnect to the other chromosome", "Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "Michael Phelps", "Kevin Zegers", "declared neutrality", "Isabela Moner", "April 29, 2009", "Laodicea, near Denizli", "Gibraltar", "red, white, and blue", "small orange collection boxes distributed to millions of trick - or - treaters", "Salt Lake City", "Schengen Area", "Greg Norman", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "a controversial theory about Mary Magdalene and Jesus.", "Diana Krall", "Brave New World", "phobia", "Cryogenics", "anxiety disorder"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5937276878768369}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.06451612903225806, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.43750000000000006, 1.0, 0.5714285714285715, 0.3636363636363636, 0.07142857142857144, 0.4, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-10182", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-786"], "SR": 0.46875, "CSR": 0.5243941326530612, "EFR": 0.7058823529411765, "Overall": 0.6359771721188475}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Michael Sheen", "Rockbridge County", "Mumbai, Maharashtra", "Hong Kong", "\"Perfect Strangers,\"", "public", "Nelson County", "survival horror", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons 138th Episode Spectacular\"", "Twin Pines/Lone Pine Mall", "neo-Nazi", "model", "Bisexuality", "Adam Dawes", "early 17th-century Colony of Virginia after serving his term of indenture", "Brian Bosworth", "Oberkommando der Wehrmacht", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Shamrock Rovers F.C.", "Dirk Werner Nowitzki", "highland regions of Scotland", "Kansas Jayhawks football team", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the local midnight", "John R. Leonetti", "2009", "Anthony Ray Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "from 1100 (Ranulf Flambard) until 1952 (Kray twins)", "start fires, hunt, and bury their dead", "In February 2011, while overseas, she discovered that she was pregnant", "Antoine - Laurent de Lavoisier and John Newlands", "Honda", "Utah", "Moby Dick", "two Metro transit trains that crashed the day before, killing nine,", "More than 22 million people in sub-Saharan Africa", "to host the Olympic Games in Rio de Janeiro. Rio deserves this because Rio is a city that has suffered.\"", "\"Sweet Home\"", "Great Expectations", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6157661782661783}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.6, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1503", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-961", "mrqa_hotpotqa-validation-5730", "mrqa_hotpotqa-validation-4504", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-7182", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-2545", "mrqa_searchqa-validation-3197"], "SR": 0.53125, "CSR": 0.5244633838383839, "EFR": 0.9, "Overall": 0.6748145517676768}, {"timecode": 99, "UKR": 0.74609375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.689453125, "KG": 0.478125, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "PBS", "The Bears", "1973", "Salisbury", "Kohlberg & Co.", "526", "Jean-Marie", "Cold Spring", "\"Hacksaw Ridge\"", "satirical erotic romantic comedy", "The Process", "Vikram", "1949", "BAFTA TV Award Best Actor", "Cameron Indoor Stadium", "defender", "Levi Weeks", "219", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "1853", "1948", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan HyperSport", "Richard Arthur", "mentalfloss.com", "May 4, 2004", "3", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "Trent Alexander-Arnold", "eleven", "2011", "current day Poole Harbour towards mid-Channel", "North Carolina", "wish FM", "John Galliano", "Ford", "to make an emotional connection to their lost loved ones.", "Seoul", "Circumnavigate", "the colon", "15", "mollusca"], "metric_results": {"EM": 0.640625, "QA-F1": 0.69765625}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false], "QA-F1": [0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-3155", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-1036", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2265", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-5045"], "SR": 0.640625, "CSR": 0.525625, "EFR": 0.9565217391304348, "Overall": 0.679163722826087}]}