{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8420, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end", "1894", "Rhenus", "the Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "Luther states that everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "outrage from child protection and parental rights groups", "the Masovian Primeval Forest", "in the days, weeks and months after it happened", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "the problem of squaring an integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "in the same way as prices for any other good", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "the U.S. ship that was hijacked off Somalia's coast.", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8056648212898213}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-7566", "mrqa_squad-validation-9243", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-2520", "mrqa_squad-validation-2035", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.734375, "CSR": 0.78125, "EFR": 1.0, "Overall": 0.890625}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "On Tesla's 75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "the destruction of Israel", "locomotion", "each six months", "Japanese", "the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "a multi-party system", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "more integral", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Robbie Williams and Liam Gallagher", "Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Annemarie Moody", "Florida Current", "six", "It always begins with the music", "music director", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.765625, "QA-F1": 0.7986877705627705}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1637", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-8316", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.765625, "CSR": 0.7760416666666666, "EFR": 1.0, "Overall": 0.8880208333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "an Eastern Bloc city", "Sakya", "christopher", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "best-known legend", "Upper Lake", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President", "2000", "oxygen", "increase local producer prices", "the Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster", "multiple revisions", "50 fund", "integer factorization problem", "economic inequality", "Isel", "adapted quickly and often married outside their immediate French communities", "Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned", "yellow fever", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "the Channel Islands", "charleston", "Alberich", "charleston", "Emeril Lagasse", "Churchill Downs", "charleston", "charleston", "ireland", "ireland", "travis", "ireland", "travis", "George Fox", "ireland", "charleston", "24 hours a day", "Sponsorship scandal", "charleston"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6740451388888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2597", "mrqa_squad-validation-8324", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-1189", "mrqa_squad-validation-1150", "mrqa_squad-validation-7230", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-1581", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-3821"], "SR": 0.609375, "CSR": 0.734375, "EFR": 0.96, "Overall": 0.8471875}, {"timecode": 4, "before_eval_results": {"predictions": ["in plants that contain them", "Parliament of Victoria", "Zaha Hadid", "Fort Edward and Fort William Henry", "Science and Discovery", "the Army", "pedagogy", "the red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "The Skirmish of the Brick Church", "the port city of Kaffa", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "michael andrew atherton", "22", "massive crackdown on terror groups that they say were planning numerous suicide attacks", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "necessity", "a Muslim background", "will be the first time any version of the Magna Carta has ever gone up for auction", "a unit of Time Warner", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "his phone calls", "a woman who may have been contacted", "one", "maryland", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "colombia"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6925914011437908}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.15999999999999998, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.671875, "CSR": 0.721875, "EFR": 1.0, "Overall": 0.8609375}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a data network based on this voice-phone network", "500,000", "Ofcom", "Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "a way of reminding their countrymen of injustice", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "the 1970s", "the spoils of the war", "German Te Deum", "1795", "Bermuda 419", "air could be liquefied, and its components isolated, by compressing and cooling it", "Infinity Broadcasting Corporation", "\"semi-legal\" and was the only opposition group in Egypt able to field candidates during elections", "1972", "a rudimentary immune system, in the form of enzymes that protect against bacteriophage infections", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "negotiates treaties with foreign nations", "changing display or audio settings quickly", "an Ohio newspaper on 8 February 1925", "Herbert Hoover", "angular rotation", "Panning", "Justin Timberlake", "the economic systems of the uk germany and russia have in common", "a peacekeeper volunteer was required to be over the age of 25 with no maximum age limit", "an expression of unknown origin", "omitted and an additional panel stating the type of hazard ahead", "three", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "the present ( 2016 -- 2018, contemporaneous with airing ) and a storyline taking place at a set time in the past ;", "Morgan Freeman", "David Gahan", "it includes a restaurant, spa, and bed - and - breakfast and provides guided tours which feature the history and alleged paranormal activity of the site", "a long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the long fast for the Lent period", "Jaipur", "Jonas Olsson", "torpedo boats", "River Usk"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6991323897980245}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.56, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.13333333333333333, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5833333333333334, 0.0, 1.0, 0.28571428571428575, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-9908", "mrqa_squad-validation-3473", "mrqa_squad-validation-9635", "mrqa_squad-validation-6450", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-9071", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.578125, "CSR": 0.6979166666666667, "EFR": 0.9629629629629629, "Overall": 0.8304398148148149}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "antigen from a pathogen", "their disastrous financial situation", "making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "\"social and political action,\"", "1936", "New Birth", "gold", "a deficit", "178 Vivienne Westwood", "reduction", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "\"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America", "1,548", "Joy", "members", "end of the season", "10", "Jonas", "African-Americans", "will not support the Stop Online Piracy Act", "Hank Moody", "hot and humid and it rains almost every day of the year", "an animal tranquilizer, can put users in a dazed stupor for about two hours", "1980", "Stuttgart on Sunday", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "more than 170", "North Korea", "first five Potter films", "their cars have chosen their rides based on what their cars say about them", "3 to 17", "two suicide bombers,", "a \"stressed and tired force\" made vulnerable by multiple deployments", "James Whitehouse", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "a former American football player and coach", "Church of Christ, Scientist", "fat or fatty acid in which there is at least one double bond within the fatty acid chain", "New Testament"], "metric_results": {"EM": 0.625, "QA-F1": 0.7090452516233766}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.5, 1.0, 0.5, 0.25, 1.0, 0.13333333333333333, 1.0, 0.5, 0.0, 0.5, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.45454545454545453, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1255", "mrqa_squad-validation-5441", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.625, "CSR": 0.6875, "EFR": 1.0, "Overall": 0.84375}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "PP \u2286 PSPACE", "July 1969", "assisting in fabricating evidence or committing perjury", "prolamellar body", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "Time Lord", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey", "\"Dance Your Ass Off\"", "videos and commentaries", "India", "Benazir Bhutto, who was assassinated Thursday in Rawalpindi,", "at the country's third-largest oil refinery", "April 24 through May 2", "Krishna Rajaram,", "early detection and helping other women cope with the disease", "as many as 250,000", "Timothy Masters,", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "Madeleine K. Albright", "\"Dancing With The Stars\"", "some Guant Bay detainees", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "seeking help", "Japanese officials", "len euros -- $89 -- for shoes that are also worn by dogs who walk on ice in Alaska", "boyhood experience in a World War II internment camp", "Norman given name Robert", "stronger with an unfair advantage", "Matthew Ward Winer", "Doc Holliday", "at the Strelasund,", "Mustique", "green"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6465788551726052}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6, 1.0, 0.08333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 1.0, 1.0, 0.3636363636363636, 0.4, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.05555555555555555, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-8883", "mrqa_squad-validation-7587", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_newsqa-validation-3281", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-2858"], "SR": 0.578125, "CSR": 0.673828125, "EFR": 0.9629629629629629, "Overall": 0.8183955439814814}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships with an agreement that they were not to serve again in the present war.", "Roman Catholic", "\"Professor Sherlockarty to the Doctor's Sherlock Holmes\"", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "\"Journey's End\"", "immediate", "Levi's Stadium", "decidedly Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Aristotle and Archimedes", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington", "autonomy", "Islamic", "\"17 Again\"", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic", "finance", "terminal brain cancer", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "The boy's mother took him to Brazil", "Animal Planet", "fake his own death", "there were no radar outages and said it had not lost contact with any planes", "54 bodies", "early detection", "Diversity", "$250,000", "break up ice jams", "Nazi Germany", "March 27", "Kirchners", "directly involved in an Internet broadband deal with a Chinese firm", "The son of Gabon's former president", "as soon as 2050", "Alfredo Astiz,", "Abdullah Gul,", "Carl Froch", "Everglades", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans, Louisiana", "Tulip mania", "MIBs", "olympics", "Hockey"], "metric_results": {"EM": 0.625, "QA-F1": 0.7011126026751027}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-9903", "mrqa_squad-validation-10341", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839"], "SR": 0.625, "CSR": 0.6684027777777778, "EFR": 1.0, "Overall": 0.8342013888888888}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "Book of Discipline", "His wife Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"coo\", \"hoos\" and \"strang\"\u2014which is how they were pronounced in the Anglo-Saxon language.", "30%\u201350% O2 by volume", "\"All I can say is that the Natives of these localities are very badly disposed towards the French, and are entirely devoted to the English.", "the top 15 most populous", "CRISPR", "six years", "300 km long and up to 40 km wide", "1962", "free radical production", "its Video On Demand service", "issues related to the substance of the statement", "Edict of Fontainebleau", "15", "\"The U.S. subcontracted out an assassination program against al Qaeda... in early 2006.\"", "Ronaldinho", "a Taliban -- either as part of NATO or bilaterally -- would have much worse long-term consequences.", "25", "a treadmill", "the couple's surrogate lost the pregnancy.", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "two and a half hours", "Elin Nordegren", "Europe, Asia, Africa and the Middle East", "6,000", "anaphylactic shock", "President Clinton.", "\"two sides to every story -- sometimes three\" and he was confident the legal system would work in Harris' favor.", "MDC head Morgan Tsvangirai", "rig next week's elections in his favor,", "future relations with Washington", "a canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail,", "school, their books burned,", "strife in Somalia,", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois,", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "that a UH-60 Blackhawk helicopters crashed in northeastern Baghdad as a result of clashes between U.S.-backed Iraqi forces and gunmen.", "London", "Abigail '' that he loved her", "immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "Andr\u00e9 3000", "Groundhog Day", "Cleopatra", "a singer who takes a job working with a struggling carnival."], "metric_results": {"EM": 0.5, "QA-F1": 0.6327134395424836}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.7058823529411764, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 0.0, 1.0, 0.16, 0.0, 0.25, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 0.1111111111111111, 1.0, 0.4, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-10185", "mrqa_squad-validation-2429", "mrqa_squad-validation-8471", "mrqa_squad-validation-9194", "mrqa_squad-validation-2972", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-11812"], "SR": 0.5, "CSR": 0.6515625, "EFR": 0.96875, "Overall": 0.81015625}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York,", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever outbreaks", "DC traction motor", "The Prince of P\u0142ock,", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "within the premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "a broken pelvis,", "issued his first military orders as leader of North Korea just before the death of his father was announced,", "heavy snow and ice", "Willem Dafoe", "\"Maude\"", "Phillip A. Myers.", "general astonishment", "Thursday night in the library,", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Lance Cpl. Maria Lauterbach", "Dangjin", "Sharp-witted. Direct. In control. Loyal.", "Hu Jintao", "magazine,", "(CNN)", "October 3,", "Amir Zaki", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next", "President Bush", "Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Lisa Irwin", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett - Wines", "Lionsgate.", "James Lofton", "is popularly known as becoming one with God or the Absolute,", "whip-like"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6537280701754387}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.10526315789473684, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-4180", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.609375, "CSR": 0.6477272727272727, "EFR": 1.0, "Overall": 0.8238636363636364}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism and early reproduction", "Victoria Department of Education", "seized", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching", "Elway", "Philo of Byzantium", "36", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "pink mice", "antelope", "nipples", "the Precambrian period", "cooperative", "Anastasia Dobromyslova", "gagapedia", "9", "Space Jam", "radish", "Robert Ludlum", "giant", "\"[25.3 megabytes in .asf movie", "the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "The London Underground Piccadilly Line", "United States", "orangutan", "Edouard Manet", "The Magic Finger", "Wyoming", "2005", "1971", "minivans", "bawdy", "Venice", "petticoat", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Antigua and Barbuda", "the 14th most common surname in Wales and 21st most common in England", "Can't Get You Out of My Head ''", "Ray Looze", "Bloomingdale Firehouse", "nuclear weapons", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "the country's", "Buddhism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6106011157872859}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6153846153846153, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444444, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-1018", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983", "mrqa_searchqa-validation-13120"], "SR": 0.53125, "CSR": 0.6380208333333333, "EFR": 1.0, "Overall": 0.8190104166666666}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "90-60's", "Panini", "Bills", "anti-colonial movements", "the Rhine Valley", "protein A", "suspicious of even the greatest thinkers and to test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "the case of an express wish of the people to withdraw from the EU", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "alfred hawthorne", "alfred hawthorne", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "alfred hawthorne", "alfred hawthorne", "Vladivostok", "Sheryl Crow", "alfred hawthorne", "Camellia", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "astronomy", "gin", "George Clooney", "alfred hawthorne", "James Chadwick", "\"Ah, look at all the lonely people.\"", "Monopoly", "champagne", "rain", "the United States", "Brigit Forsyth", "alfred hawthorne", "alfred hawthorne", "What's Up With the Title", "Thomas Edward Lawrence,", "Kent", "alfred hawthorne", "alfred hawthorne", "white", "Switzerland", "soda", "the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Jason Voorhees", "alfred hawthorne", "alfred hawthorne", "\"The Screening Room\""], "metric_results": {"EM": 0.578125, "QA-F1": 0.6075312456360844}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.8387096774193548, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_newsqa-validation-3207", "mrqa_searchqa-validation-8450", "mrqa_searchqa-validation-9647", "mrqa_newsqa-validation-3860"], "SR": 0.578125, "CSR": 0.6334134615384616, "EFR": 1.0, "Overall": 0.8167067307692308}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "the Black Death", "had their own militia", "months", "61", "the quality of a country's institutions and high levels of education", "comb rows", "friction", "Sky Digital", "2005", "force", "polecat", "John Connally", "saffron", "hymen", "renoir", "albinism", "the Straits of Tiran", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "cuddly new pet", "the Battle of the Three Emperors", "Velazquez", "althea Gibson", "lizards", "strong cold southwest wind", "table tennis", "the National Library of Medicine", "renoir", "Gandalf", "alibis", "Jinnah International", "Monday", "Caracas", "renoir", "soap", "Cocktail", "Avro", "Genesis", "Charlie Brooker", "tea", "Harrods", "2007", "renoir", "Scarface", "yellow", "aluminium", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Kindle Fire", "Steven Green", "renoir", "fortune", "emperor", "Synchronicity"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6416666666666666}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-2875", "mrqa_squad-validation-4436", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-3807", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-372", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.578125, "CSR": 0.6294642857142857, "EFR": 1.0, "Overall": 0.8147321428571428}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep after it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn", "radioisotope", "Cody Fern", "Nicklaus", "Jim Gaffigan", "Jumping on the Moon", "2028", "1974", "332", "1936", "Authority", "chief petty officer", "Spanish moss", "Chinese cooking", "Vienna", "the National September 11 Memorial plaza", "Kevin Spacey", "1 November", "2.5", "white blood cell", "Bangladesh -- India border", "the President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "Sedimentary rock", "January 12, 2017", "the United States", "Claims adjuster", "the nucleus", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "a vertebral column", "three", "everest", "new england", "kew Gardens", "Nikita Khrushchev", "$500,000", "Alexandros Grigoropoulos,", "reaper", "new York City Police Department", "the BBC building in Glasgow, Scotland", "\"Larry King Live\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6330488616154377}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.5, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.5, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_squad-validation-7670", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-9975", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_newsqa-validation-121", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.515625, "CSR": 0.621875, "EFR": 0.967741935483871, "Overall": 0.7948084677419355}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "The Late Late Show with James Corden", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law", "Famous musicians", "ESPN Deportes", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "88%", "Necessity-based", "950 pesos ( approximately $ 18 )", "the fourth C key from left on a standard 88 - key piano keyboard", "Seattle, Washington", "Battle of Antietam and Lincoln's Emancipation Proclamation", "Andy Cole and Shearer", "In Time", "the 2nd century", "Glenn Close", "four times", "Agostino Bassi", "five seasons", "One Direction spending time on a beach in Malibu, California", "the church at Philippi", "The territories were once again briefly captured by the Dutch", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "a warrior", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "September 1972", "Argentina, Uruguay, the United States and Yugoslavia", "Alex Skuby", "Matt Jones", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep", "1970s", "The Director of the Federal Bureau of Investigation", "D.A.D. a.", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "Harry Terwilliger", "Rachel Kelly Tucker", "Bohemia", "a garage beetle", "Code 02PrettyPretty", "Joe Dever", "The opposition group,", "the abduction of minors", "Nevada", "Chile", "Stage Stores, Inc.", "1881"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6090094367438117}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.3076923076923077, 0.6, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.7499999999999999, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6739", "mrqa_squad-validation-7141", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5271", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_newsqa-validation-2674", "mrqa_hotpotqa-validation-1852"], "SR": 0.453125, "CSR": 0.611328125, "EFR": 0.9428571428571428, "Overall": 0.7770926339285714}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "New England Patriots", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Microsoft Office", "SAVE", "Scandinavian Airlines System Aktiebolag", "1993 to 2001", "1951", "Southern Miss Golden Eagles", "Martin Lee Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award", "Jello Biafra drew on Nardwuar's face with a marker pen", "the Battle of Culloden", "Burny Mattinson", "Sir William McMahon", "the Cowie Water", "7.63\u00d725mm Mauser", "the Academy Award for Best Animated Feature", "Chengdu Aircraft Corporation (CAC) of China", "Delacorte Press", "shared values, socialise youth, and maintain effective social control", "Secretariat", "Wake Island", "hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "Thomas Harold Amer", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Amway", "Parlophone Records", "South Africa", "Surrey", "\"My Sassy Girl\"", "Charles Russell", "Boyd Gaming", "NBA 2K16", "1969", "Glenn Close", "Florence Welch", "Neighbours", "Ewan McGregor", "2011", "pippa passes", "a enslaved African American", "expanding U.S. sanctions against Zimbabwe", "Shelley Moore Capito"], "metric_results": {"EM": 0.5, "QA-F1": 0.6039333062770563}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.7499999999999999, 0.3636363636363636, 0.25, 0.2857142857142857, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-76", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-3189", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2409", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-3521"], "SR": 0.5, "CSR": 0.6047794117647058, "EFR": 1.0, "Overall": 0.8023897058823529}, {"timecode": 17, "before_eval_results": {"predictions": ["force of gravity", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "the inner chloroplast membrane", "Charlie Harper", "Steveland Hardaway Morris", "beaver", "La Boh\u00e8me Giacomo Puccini", "formic acid", "Toledo", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "gazelle", "Xenophon", "Fuller's", "Plimsoll", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "welch", "weight plates", "\"big house\"", "Hadrian", "Los Gatos, CA", "murine typhus", "Moonee Ponds, a suburb in Melbourne, Victoria.", "Cologne", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Prokofiev", "Jessica Simpson", "Boy George", "Finland", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "The Union's forces", "New Jewel Movement", "cetaceans", "north-south", "On Anjuna beach in Goa", "Marius Petipa", "Oshkosh", "two", "\"The World\"", "\"The Sunday Thing\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6270833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-3031", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.5625, "CSR": 0.6024305555555556, "EFR": 1.0, "Overall": 0.8012152777777778}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "high", "Manakintown", "northwest", "10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "a balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "The Hustons", "Matt L. Jones", "the Isthmus of Corinth", "comprehend and formulate language", "Splodgenessabounds", "charlie", "electron donors", "Meredith Quill", "( 1993 -- 1994 )", "775", "Solange Knowles", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Coton", "3 ( 55 -- 69 % ) & 4 ( 40 -- 54 % )", "Zoe Badwi", "1995", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "aortic valve", "July 21, 1861", "Dr. Addison Montgomery", "state or other organizational body", "png HTTP / 1.1", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "the Rime is a work of transhistorical", "September 2017", "moral", "Rising Sun Blues ''", "Part 2", "dumbo", "the \u201cBloody Assizes\u201d", "Christian", "Robert L. Stone", "2008", "Yemen", "olysses", "Robert Langdon", "ABC1 and ABC2", "\"NBA 2K16\"", "mistress of the Robes"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6193303634859741}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3193", "mrqa_squad-validation-6937", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.53125, "CSR": 0.5986842105263157, "EFR": 0.9666666666666667, "Overall": 0.7826754385964911}, {"timecode": 19, "before_eval_results": {"predictions": ["everything that is used to work sorrow over sin is called the law,", "black", "Louisiana, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "1965", "270,000 tonnes", "Long troop deployments", "Joe Pantoliano", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother, a key witness in the case, his attorneys told HLN's \"Nancy Grace.\"", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "nearly three out of four", "Argentina has always claimed sovereignty over them", "Tuesday in Los Angeles", "forgery and flying without a valid license", "Anil Kapoor", "19-year-old boy is sleeping in your bed, with your wife...", "President Obama's surge plan to head to Afghanistan's restive provinces to support Marines and soldiers fighting a dug-in Taliban force.", "the city's reputation for glamour and hedonism", "The Louvre", "snowstorm", "six exotic sports cars", "a lizard-like creature from New Zealand", "Mutassim", "Thursday and Friday", "\"Stunt double Terry Leonard performs a hazardous jump from horseback to a truck as Indiana Jones in \" Raiders of the Lost Ark.\"", "Russia", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a320 million ($41.1 million) fortune", "U.S. 93 in White Hills, Arizona, near Hoover Dam", "CNN", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Lousiana", "the Southeast", "his wife, Robert Fields,", "Carol Browner", "\"A Mother For All Seasons.\"", "The Maraachli case caught the attention of the group Priests for Life, which funded Joseph's transfer and treatment at the SSM Cardinal Glennon Children's Medical Center.", "back at work", "necropsy or animal autopsy", "teenager", "Derek Hough", "John Adams", "Borsht (Borsch)", "Zager and Evans", "Robert Matthew Hurley", "fourth term", "obscenity", "Cromwell", "Lapland", "1937", "Emad Hashim"], "metric_results": {"EM": 0.453125, "QA-F1": 0.598592364760843}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.22222222222222224, 0.6, 0.4, 1.0, 1.0, 0.0, 0.1904761904761905, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.923076923076923, 0.6666666666666666, 0.8333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_squad-validation-3028", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_newsqa-validation-1958", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_searchqa-validation-8011", "mrqa_hotpotqa-validation-2922"], "SR": 0.453125, "CSR": 0.59140625, "EFR": 1.0, "Overall": 0.795703125}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C),", "Greek \u1fec\u1fc6\u03bd\u03bf\u03c2 (Rh\u0113nos), Latin Rhenus", "1331", "Death wish Coffee", "L", "Cameroon,", "just after midday on a cold December Monday", "ballots", "new fabric technique", "alcohol toxicity", "Eikenberry sent private cables to Obama last week, urging the president not to rush to send more troops to Afghanistan", "Bobby Darin,", "Felipe Massa", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "she was humiliated by last month's incident,", "the composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony,", "Amanda Knox's aunt", "over 1,000 pounds", "Iran's development of a nuclear weapon is unacceptable.", "a welcoming, bright blue-purple", "using recreational drugs", "ceo Herbert Hainer", "his client, Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "on the set at \"E! News\" on Tuesday", "seven-member Spanish flight crew and one Belgian", "$750-$1,000 a year by jumping just 10 mpg in efficiency.", "has said one of his strongest statements to date on the sex abuse scandal sweeping the Roman Catholic Church, saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "A video purporting to be from a vigilante group whose goal is the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "Republicans", "will be known for his consecutive games played streak,", "An undated photo of Alexandros Grigoropoulos,", "a power-sharing deal with the opposition party's breakaway faction,", "a Ford F-150 work truck (a plain, regular-cab model),", "North Korea intends to launch a long-range missile in the near future,", "a Mass in Angola on Sunday,", "Gary Brooker", "the creation of an Islamic emirate in Gaza,", "The iconic boogeyman Jason Voorhees in the new \"Friday the 13th\" movie.", "judges in charge of determining which Guant detainees should be tried by a U.S. military commision,", "at Sea World in San Antonio,", "a job he liked at the U.S. Holocaust Memorial Museum,", "about 50", "the Ku Klux Klan", "1939", "Branford College", "Wigan", "stamens", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "clone", "Hodel", "access to US courts", "British rock group Coldplay"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4498947317243688}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9523809523809523, 0.6, 0.25, 0.23076923076923078, 1.0, 1.0, 0.8571428571428571, 0.22222222222222224, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.3870967741935484, 0.0, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.07142857142857144, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-3070", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-599", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_naturalquestions-validation-7987"], "SR": 0.34375, "CSR": 0.5796130952380952, "EFR": 0.9761904761904762, "Overall": 0.7779017857142857}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "\u201cUnder The Sea\u201d", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "shoulders", "Madonna's", "Glasgow", "\"radio\" or \"stereo.\"", "Australia", "roch", "Pearson PLC.", "Irish Setter", "American Civil War", "Loch Awe", "Roman Catholic Church,", "roch", "silvery blue", "China", "Harrisburg", "is about 16 in. (40 cm) long including the 5-in. (13-cm) tail", "glockenspiel", "Dr John Sentamu", "Cameroon", "Pongo", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "emperor charlemagne", "not to them but to the community.", "Russell Crowe", "roch", "roch", "Robin Goodfellow", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "SS Constitution", "Albert Square", "Newbury", "the Old Testament", "70 million people", "Target Corporation", "\"The Omega Man\"", "Michelle Rounds", "that doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "\"international NGO\"", "John Jackson Dickison", "Amnesty International", "talk show queen Oprah Winfrey.", "mother"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6084730691056911}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.975609756097561, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_newsqa-validation-2971", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-4003"], "SR": 0.5625, "CSR": 0.5788352272727273, "EFR": 1.0, "Overall": 0.7894176136363636}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials, and because they are a matter of having sufficient funds at a specific time,", "Vicodin,", "jesus", "Robert Peary", "pearls", "Utah Territory", "Carrie Underwood", "gin", "he made his horse a consul, his palace a brothel, and his", "Google Inc.", "Langston Hughes", "Pain tolerance", "equina Lukyanova", "puck", "lariat", "the company of his opera", "LST Ship", "equine", "David Beckham", "company of the jesus", "economics", "Miracle in the Andes", "proscenium", "Montenegro", "discus", "puck", "basidiomycota", "1998", "puck", "president of the Congo", "company", "a body, body part, or personal item associated with a saint or martyr", "hard clay", "plutarch", "Rudy Giuliani", "masa harina", "six", "the Vikings", "puck", "Bastille Day", "typhoid fever", "a coastal inlet", "capital of Bavaria", "Williamsburg", "19th Century Inventions", "Tualatin", "hydrogen peroxide", "jenkins", "sex hormones", "more than $1 billion worldwide", "study design, collection, and statistical analysis of data, amend interpretation and dissemination of results", "the Big Bopper", "Tesco", "london and North Eastern Railway Class A4 4-6-2 Pacific steam locomotive", "Graham Hill", "the Battelle Energy Alliance", "IT products and services,", "debris", "$10 billion", "Trenton, Florida"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4048609575409111}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 0.6842105263157895, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_squad-validation-6887", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-8325", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-12564", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_searchqa-validation-16854", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-1118", "mrqa_newsqa-validation-1997"], "SR": 0.34375, "CSR": 0.5686141304347826, "EFR": 0.9761904761904762, "Overall": 0.7724023033126294}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "the Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "domestic cat", "the daughter of Tony Richardson", "Basel, Switzerland", "the Argonauts", "prometheus", "the Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a fantasy world populated by fictional races and monsters", "Cyrenaica", "Khaki", "magma", "Miguel Indurain", "Velazquez", "the British Arts and Crafts movement", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama", "the Earth", "a painting by Paul Gauguin", "the number of phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the coast of Surinam", "Justin Trudeau", "Radars", "Denis Law", "\"Love Is All Around\"", "William Golding", "Susan Helms", "a cyclone", "Fife", "Money Saving", "Adidas", "\"The Hunting of the Snark\"", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "\"White\" and \"Black\"", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "Tennis Channel", "fox", "\"60 Minutes\"", "Jupiter"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7044730392156863}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-4882", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-4963", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-458"], "SR": 0.640625, "CSR": 0.5716145833333333, "EFR": 1.0, "Overall": 0.7858072916666666}, {"timecode": 24, "before_eval_results": {"predictions": ["illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "the chosen machine model", "Universal Studios and Walt Disney Studios", "1997", "a suite of network protocols", "Noriko Savoie", "15", "nine", "between Pyongyang and Seoul", "killing a limo driver", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Jason Chaffetz", "money or other discreet aid for the effort if it could be made available,", "Sarah Brown", "at least the past 30 years,", "environmental", "Costa Rica", "Afghan police", "Saturday", "38,", "70,000 or so", "Climate care", "\"E! News\"", "coach", "Steve Williams", "McDonald's", "is a slight girl of 11, living in a simple home in a suburb of Islamabad.", "five female pastors", "2008", "Diego Maradona", "Dog patch Labs", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "two", "Itawamba County School District", "the former Massachusetts governor", "EU naval force", "Plymouth Rock", "Liza Murphy", "the nomination of Sonia Sotomayor", "police", "former U.S. secretary of state", "At least 33", "five", "get better skin, burn fat and boost her energy.", "contraband", "depraved acts by a few kids have served to demonize an entire student community.", "Damon Bankston", "Krishna Rajaram", "Sunday", "death and destruction", "Sin\u00e9ad", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "italy", "radar", "art", "the point guard position", "the", "South America", "freestyle", "the Nightingale", "Dr. Irina Spalko"], "metric_results": {"EM": 0.375, "QA-F1": 0.5146082910145411}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.2857142857142857, 1.0, 0.6153846153846153, 0.5, 1.0, 0.0, 0.8571428571428571, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.5555555555555556, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.16, 0.5, 1.0, 1.0, 0.4, 0.3636363636363636, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.5, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6846", "mrqa_squad-validation-610", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.375, "CSR": 0.56375, "EFR": 1.0, "Overall": 0.781875}, {"timecode": 25, "before_eval_results": {"predictions": ["\"most successful\" science fiction series of all time", "Thomas Savery", "Vicodin,", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "a violent separatist campaign", "Eleven", "269,000", "The Swiss art heist follows the recent theft in Switzerland of two paintings by Pablo Picasso,", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers", "41,", "Los Alamitos Joint Forces Training Base", "super-yacht designers Wally", "137", "Kurdish militant group in Turkey", "3-2", "autonomy.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "the Russian air force", "34", "the eventual closure of Guant Bay prison and CIA \"black site\" prisons", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "a lightning strike was a possibility,", "ensuring that all prescription drugs on the market are FDA approved,", "In fashionable neighborhoods of Tokyo customers", "Tom Baer", "Pakistan", "the oceans are growing crowded, and governments are increasingly trying to plan their use.", "\"iKini\"", "Brian Mabry", "completely changed the business of music,", "gunned down four Lakewood, Washington, police officers Sunday.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "Some truly mind-blowing structures", "Crista", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego,", "five", "Bergdahl, 23, was captured June 30 from Paktika province in southeastern Afghanistan,", "Twitter, and Facebook", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "first line of law and order", "heart", "Hyderabad", "between the Mediterranean Sea to the north and the Red Sea", "spiritual", "Las Vegas", "Jackson Pollock", "wye", "Mississippi", "Janis Lyn Joplin", "King Duncan", "Georgia", "monopoly", "a stride"], "metric_results": {"EM": 0.5, "QA-F1": 0.5884749159325566}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.35294117647058826, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.5882352941176471, 1.0, 1.0, 0.0, 0.07407407407407408, 0.5, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2608695652173913, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837"], "SR": 0.5, "CSR": 0.5612980769230769, "EFR": 0.96875, "Overall": 0.7650240384615384}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "Six people were killed and at least 300 were injured", "Krishna Rajaram,", "at least 25", "Shakespeare's Pizza,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "six", "the legitimacy of that race.", "the sight of celebrity pontificating about the plight of the environment", "three", "Monday", "Scarlett Keeling", "two years,", "84-year-old", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "in July", "Akshay Kumar", "Graham's wife", "the guerrillas detained and \"executed\" eight people on February 6 in the town of Rio Bravo", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "James Newell Osterberg", "strangulation and asphyxiation and had two broken bones in his neck,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republican", "Afghanistan's restive provinces", "\"People of Palestine\"", "older than the industry average,", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "Mohammed Ali", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "Tuesday", "same-sex civil unions,", "military veterans", "barter -- trading goods and services without exchanging money", "semi-autonomous organisational units within the National Health Service in England", "6 - 6", "Bongos", "Jack\" Frost", "the innermost digit of the forelimb", "1969", "over 20 million", "Peoria, Illinois", "Hawaii", "KID-FRIendly 4- LETTER", "King Lear", "Ottoman Empire"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5643327896062271}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.06250000000000001, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.72, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3298", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-1329", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586"], "SR": 0.515625, "CSR": 0.5596064814814814, "EFR": 1.0, "Overall": 0.7798032407407407}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab,", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "the second missing person", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "a single mother with HIV in Brazil,", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Los Angeles Angels", "Indian army and separatist militants", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "\"BADBUL,\"", "98", "1993", "Gulf of Aden,", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "between government soldiers and Taliban militants", "South Dakota State Penitentiary", "Iran", "November 26,", "people have chosen their rides based on what their", "July", "Zoe's Ark", "two soldiers and two civilians", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "Scardia,", "a fractured pelvis and sacrum", "Wednesday", "the abduction of minors", "gun", "Aniston, Demi Moore and Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "1954", "11 p.m.", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "a mushroom", "a city on Lake Champlain", "metoprolol"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7184298340548341}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_naturalquestions-validation-6383", "mrqa_naturalquestions-validation-4505", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-14535", "mrqa_searchqa-validation-12398"], "SR": 0.640625, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "technological superiority", "1981.", "forgery and flying without a valid license,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "the Genocide Prevention Task Force.", "is actually preparing to test-fire a long-range missile under the guise of a satellite launch.", "European Commission", "Whitney Houston", "the lead plaintiff in perhaps the most controversial case involving Judge Sonia Sotomayor,", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has,\"", "Anil Kapoor.", "eradication of the Zetas cartel from the state of Veracruz, Mexico,", "\"The Rosie Show,\"", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "8 p.m. local time Thursday", "Passers-by", "\"My gut started feeling like something just wasn't right,\"", "executive director of the Americas Division of Human Rights Watch,", "750", "Six people", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "attracted some U.S. senators", "inconclusive", "about 5:20 p.m. at Terminal C", "fueled by environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5 percent", "700,000", "Sen. Arlen Specter", "Deutschneudorf,", "would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "bragging about his sex life on television", "a vertebral column ( spine )", "December 11, 2014", "Seton - Karr", "Goldtrail", "Spain", "the Sidgwick Avenue", "Douglas Hofstadter", "\"The Dark Tower\"", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain in the Civil War.", "Castle Rock", "a fish"], "metric_results": {"EM": 0.53125, "QA-F1": 0.637600668188304}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9565217391304348, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.8, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.972972972972973, 1.0, 0.1, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-229", "mrqa_newsqa-validation-3839", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-8099", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.53125, "CSR": 0.5614224137931034, "EFR": 1.0, "Overall": 0.7807112068965517}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure on wages", "El Tem\u00fcr", "438,000", "Marty Ingels,", "coaxial", "Pakistani first-class cricketer", "Everbank Field", "14", "the German Campaign of 1813", "Arabella Churchill,", "1965", "Paris at Charles de Gaulle Airport", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1986", "non-alcoholic", "puzzle video game", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos", "Tom Kartsotis,", "2017", "Wayman Tisdale", "Mexico,", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Digital Network", "Erinsborough", "Marine Corps", "Robert A. Iger", "the Lost Battalion", "Seminole and Miccosukee tribes", "Virginia", "NBA Slam Dunk Contest.", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "a field in Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two", "IB Primary Years Program", "Richard Parker", "southernmost tip of the South American mainland", "Cecil B. De Mille's", "allergic reaction", "King Edward VIII,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia,", "shrimp", "Australia"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5930660485347985}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, true, false, true, false, true, false, true, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.25, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4048", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-3895", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4356", "mrqa_naturalquestions-validation-9130", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585"], "SR": 0.515625, "CSR": 0.5598958333333333, "EFR": 1.0, "Overall": 0.7799479166666666}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "effects of deforestation", "Prussian statesman", "London", "Dave Thomas", "co-op of grape growers", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations", "ten years of probation", "In Pursuit", "Bolton", "\"The Frost Report\"", "Kansas City Crime Family", "Werner Nowitzki", "lifetime achievements", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200 Indians", "Theme Park World", "Formula E", "New Jersey", "various deities, beings, and heroes", "86,112", "Celtic", "Ouse and Foss", "Springfield, Massachusetts", "comedian", "\"Apatosaurus\"", "in 1885", "American", "Frank Edward Thomas Jr.", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "national and international media", "The Seduction of Hillary Rodham", "1919", "Lambic", "Massive Entertainment", "Argentina", "Larry Alphonso Johnson Jr.", "Michael Stipe", "veto power", "Joseph E. Grosberg", "\"Chelsea Lately\"", "276,170", "Kuwait", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "NY", "the U.S Olympic Trials", "Villa Park", "2005", "228 people", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post-Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6664393939393939}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4446", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-3926", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2368", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.546875, "CSR": 0.5594758064516129, "EFR": 1.0, "Overall": 0.7797379032258065}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno native", "79", "Iceland", "Wyoming", "short story", "Knott's Berry Farm", "Iowa", "Georgia", "Nassau", "nacreous inner shell", "HIV", "Thomas Beekman", "TGV", "Rigoletto", "aardwolf", "Beijing", "Sir Roger Gilbert Bannister", "New Jersey Devils", "San Jose, California", "Yves Saint Laurent", "reindeer", "King Fortinbras", "a schooner", "Anna Mary Robertson", "Sailor Moon", "georgia state", "georgia state", "Brown bear", "georgia", "Gilson Lavis", "Monty Python and the Holy Grail", "negative electrode", "(Milton) Berle", "George Herbert Walker Bush", "Congolese", "Dryden Flight Research Center", "central Chile", "Dan Marino", "Mars", "clownfish", "E/c^2", "Guru Pitka", "Las Vegas", "millet", "bees", "heavy drinking", "a chimpanzee", "Baja California", "Soothsayer", "Yitzhak Rabin", "Saul", "Gettysburg", "Jack Gleeson", "thirteen if Plank, a board of wood who acts as one character's imaginary friend", "Buddhist", "Jean Bernadotte", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic bogs", "20 March to 1 May 2003", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States.", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5115327380952381}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.42857142857142855, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4708", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-4159", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1602", "mrqa_naturalquestions-validation-5896", "mrqa_naturalquestions-validation-5808", "mrqa_triviaqa-validation-4765", "mrqa_hotpotqa-validation-187", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587"], "SR": 0.453125, "CSR": 0.55615234375, "EFR": 1.0, "Overall": 0.778076171875}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Henry Addington", "40", "Chad is bordered on the north by Libya, on the south by the Central African Republic", "Shania Twain", "Hillsborough", "glucagon", "The New York Yankees", "rapid eye movement", "green", "Ann Dunham", "Prime Minister", "French", "June Brown", "Ohio", "Francis Matthews", "photographic", "hematite", "Noah", "London", "New Years Day", "Sarah Ferguson", "Mercury", "watt", "Peter Butterworth", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Brasil", "his father, John Dickens,", "aged 75", "Jennifer Lopez", "1664", "Eurythmics", "Fred Perry", "Downton Abbey", "Martina Hingis", "sept", "a Cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "gulliver", "Pomona", "Italy", "The Streets", "Appalachian Trail", "a black Ferrari", "algebra", "bears", "Michael Moriarty", "June 1992", "24", "1994", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone.", "this administration recognizes the importance of Turkey and wants to engage with it from the start.", "Jennifer Cody", "Helvetica", "a network of blood"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5855654761904762}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-5228", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-16567"], "SR": 0.515625, "CSR": 0.5549242424242424, "EFR": 1.0, "Overall": 0.7774621212121212}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "charlton", "Hudson Bay", "florida", "Allergic", "stanley", "Ast\u00e9rix", "jon pertaine", "Belfast", "wind", "fire", "Robin Hood", "West Point", "Andy Warhol", "Spain", "clare", "rio de janeiro", "solar system", "potatoes", "Moldova", "Mitsubishi", "the Dartford Warblers", "jon perturnes", "st leger", "baroudeur", "clare", "janeiro", "Madness", "Buxton", "discretion", "Christian Dior", "rudyard Kipling", "Leeds", "Manila", "beaver", "mel Blanc", "a frog", "Moffitt", "stanley", "rochdale", "5000 meters", "racing", "clump", "Newfoundland", "crow", "Yellowstone", "St. Francis Xavier", "Manila", "Hugh Laurie", "Buddhism", "Will Champion", "Ohio", "Port Melbourne", "Osbald", "Scarface", "forgery", "Hertha Berlin", "Liza Murphy,", "Spock", "Astana", "Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain and Switzerland"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5357142857142857}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998]}}, "before_error_ids": ["mrqa_triviaqa-validation-3524", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-786", "mrqa_triviaqa-validation-7129", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-2126", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.484375, "CSR": 0.5528492647058824, "EFR": 1.0, "Overall": 0.7764246323529411}, {"timecode": 34, "before_eval_results": {"predictions": ["attack against the forts Shirley", "business districts", "prairies", "philippine", "george sandayana", "marsupials", "Alice Cooper", "Beta-blockers", "trumpet", "Marc Warren", "The Scream", "shildon", "appalachian mountain", "Herald of Free Enterprise", "ballet", "philippines", "george ababa", "reptiles", "Blackburn Lancashire", "man Without a Star", "The Mystery of Edwin Drood", "pommel horse", "a scarlet tanager", "Dick Van Dyke", "Egremont", "numb3rs", "george i", "phrixus", "philippines", "Canada", "ink", "pears soap", "Some Like It Hot", "manhattan", "ireland", "Mike Meyers", "dolphins", "plutonium", "igneous", "jules verne", "welcome", "george", "Denmark", "george i", "42.195 km", "Cleveland Brown", "george i", "One Direction", "george i", "Uranus", "george i", "george i", "November 1999", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "African-American", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "ballet", "Howard Carter"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4296875}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10251", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4535", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-535", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6449", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-5537", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4530", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.40625, "CSR": 0.5486607142857143, "EFR": 1.0, "Overall": 0.7743303571428571}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "John Forster II", "Matlock", "American Civil War", "amhara", "beetles", "Arafura Sea", "passecratis", "Tigris", "Bavarian Forest", "to make wrinkles in one's face, eyebrows", "Spain", "carousel", "bullfight", "charles", "countertenor", "alpo", "fidelio", "Guys and Dolls", "jean feldman", "Denmark", "Another Day in Paradise", "bird", "goya", "pembrokeshire", "l. Pasteur", "jorge agust\u00edn nicol\u00e1s ruiz de goya", "spach Zarathustra", "Finland", "giant stars", "Mille Miglia", "caves", "Bill Haley & His comets", "50p", "Muriel Spark", "happy birthday", "seven", "opossums", "pickwick", "a machine that cuts the bread finely while efficiently and securely wrapped the entire bread in wax paper", "The Bridge", "raven", "jane ababa", "agust\u00edn nicol\u00e1s ruiz de goya", "nelsons", "Etruscan", "Ken Burns", "Hyde Park Corner", "heston dorney", "Pyotr Ilich Tchaikovsky", "sheikh Mujib,", "saturn", "Donna", "season four", "sinoatrial node", "Lee Sunmi", "tomato", "2002", "a construction project at the Lindsey oil refinery in eastern England.", "L'Aquila earthquake", "March 24,", "Duke of Edinburgh", "Equinox Day", "Pocahontas"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5112132352941177}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5537", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-5366", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-3021", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.453125, "CSR": 0.5460069444444444, "EFR": 1.0, "Overall": 0.7730034722222222}, {"timecode": 36, "before_eval_results": {"predictions": ["the Iranian Islamic Revolution", "kansas", "city of acacias", "branson", "Gordon Ramsay", "maurice crawford", "Robert kansas", "sulfur dioxide", "Annelies Marie Frank", "maurice airport", "Portuguese", "Travelocity", "The Avengers", "park of ethiopia", "comets", "sounds of Silence", "a ghost does not have flesh and bones,", "canola", "Tina Turner", "comets", "AS Monaco", "Bolivia", "John Donne", "Uranus", "river Rio Grande", "baraboo", "maurice crawford", "30th anniversary", "comets", "king jordan I", "One Foot in the Grave", "Bronx Mowgli", "maurice crawford", "george santayana", "pliable leather", "Lakeland", "Krankies", "maurice de torquemada", "composer Gerald Finzi", "Canada", "rum and coke", "Lake Union", "ghee", "king George III", "Justin Bieber", "hyperbole", "oldpatrick", "June", "maurice island", "Ceylon", "screwdrivers", "Denver Broncos", "G minor", "A Christmas Story", "1974", "Nightmares", "Amberley Village", "lack of a cause of death and the absence of any soft tissue", "President Obama", "Elisabeth, 43, andElisabeth's father, Josef Fritzl, 73,", "Tzu Hsi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4769097222222223}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true], "QA-F1": [0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9574", "mrqa_triviaqa-validation-3858", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-3788", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5196", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_naturalquestions-validation-4108", "mrqa_hotpotqa-validation-5545", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.390625, "CSR": 0.5418074324324325, "EFR": 1.0, "Overall": 0.7709037162162162}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "an armature of piped masonry", "Tess", "Sakshi Malik", "Columbia River Gorge", "a physiological reaction", "49 cents", "1876", "geologist James Hutton", "14.69278", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "British Columbia, Canada", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "1770 BC", "Niveditha, Diwakar, Shruti", "two", "Joe Lo Truglio", "chromatin proteins", "Anakin", "Travis Tritt and Marty Stuart", "1976", "Bee Gees", "Matt Czuchry", "Pradyumna", "1902", "On the west", "Psychomachia", "the New Jersey Devils", "two", "4 in ( 10 cm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Gloria", "the Canadian Rockies", "The Maginot Line", "pussia", "dumbo", "purple", "Charles Guiteau", "The Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "Cannonball Run", "Guerrero", "Tuesday"], "metric_results": {"EM": 0.5, "QA-F1": 0.640159617707172}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.6153846153846153, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.09523809523809523, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.25, 0.5454545454545454, 1.0, 0.6666666666666666, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-9191", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-7642", "mrqa_hotpotqa-validation-5119", "mrqa_searchqa-validation-2335"], "SR": 0.5, "CSR": 0.5407072368421053, "EFR": 0.9375, "Overall": 0.7391036184210527}, {"timecode": 38, "before_eval_results": {"predictions": ["James Gamble & Reuben Townroe", "25 years after the release of their first record", "the Taft -- Katsura Agreement", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "positions Arg15 - Ile16", "Joseph M. Scriven", "Lady Gaga", "Chicago metropolitan area in 1982", "the president of the United States", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "West Bromwich Albion", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "Stephen A. Douglas", "1984", "related to the Common Germanic word guma `` man ''", "Pakistan", "23 February", "Tagalog or English", "Bryan Cranston", "thylakoid membrane", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County", "late 1922", "2017 / 18 Divisional Round game", "520", "maximum energy of 687 keV", "between $10,000 and $30,000", "R2E Micral CCMC", "1931", "John Wesley", "11 : 40 p.m. ship's time", "Norman Whitfield", "1959", "The `` Southern Cause ''", "Randy", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "Joseph Stalin", "into the intermembrane space", "divergent tectonic plate", "North Dakota", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "s Sir John Major", "roddy doddy rooddy diddle dennis", "Daniil Shafran", "TD Garden", "Venus", "\"It's a really dumb thing to say,\"", "10 below in Chicago, Illlinois.", "General Motors'", "David McCullough", "Rendezvous with Rama", "CERN", "saudade"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5832215180652681}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [0.0, 0.09523809523809525, 0.5, 1.0, 0.5, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.9743589743589743, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.2666666666666667, 0.0, 0.5714285714285715, 0.0, 0.0, 0.32, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5569", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1076", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.453125, "CSR": 0.5384615384615384, "EFR": 0.9714285714285714, "Overall": 0.7549450549450549}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "Diary of a Wimpy Kid", "Jenny Slate", "ATP", "Philippe Petit", "R2E Micral CCMC", "2010", "along the Yangtze River and in provinces in the south", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "rock music subgenres", "March 12, 2013", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "A 30 - something man ( XXXX )", "Gestalt psychology", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Skylar Astin", "John Porter", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "2018 or early 2019", "diffuse nebulae", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Charles Sherrington", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "September, 2016", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "a defense against rain rather than sun", "1940", "Sarah Lavrof", "Mark Jackson", "Michael Buffer", "God and Father of all, who is over all and through all and in all", "on location", "the Second Continental Congress", "1958", "Cody Fern", "the nature of Abraham Lincoln's war goals", "prophets and beloved religious leaders", "4.5", "Juan Manuel de Ayala", "Joseph Smith, Jr.", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Mikkel", "curfew", "Me and Bobby McGee", "shark", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6140770106777578}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 0.3076923076923077, 0.967741935483871, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.47058823529411764, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.20000000000000004, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_searchqa-validation-10341"], "SR": 0.484375, "CSR": 0.537109375, "EFR": 0.9696969696969697, "Overall": 0.7534031723484849}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants", "Joan Rivers", "early detection and helping other women cope with the disease.", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "U.S. Assistant Secretary of State for African Affairs Jendayi Frazer", "two weeks ago", "NATO", "Switzerland", "Monday", "500", "shows Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "he wants to spend $10 billion on childhood education, $150 billion over 10 years on developing alternative energy", "Clifford Harris,", "6 miles northeast of Eureka", "Robert Barnett", "a class A traffic violation that can command a fine of $627, Hastings said.", "41", "Adenhart", "a strict interpretation of the law,", "Derek Mears", "Nieb\u00fcll from Berlin (290 miles) or Hamburg", "on 112 acres about 30 miles southwest of Nashville", "Tuesday", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "Section 60", "Ali Bongo", "Allred", "\"We connected meaningfully about the important issues that have emerged over recent days, and I offered him my sincere apologies for any offense to our veterans caused by this report.", "Two pages", "A Brazilian supreme court judge", "Derek Mears", "\"Operation Pipeline Express.\"", "help rebuild the nation's highways, bridges and other public-use facilities.", "East Java", "St. Louis, Missouri", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2018 and 2019", "P.V. Sindhu", "on location in Mexico", "Snickers candy bars", "arctic whale whale", "capone", "Disneyland theme park in Anaheim, California", "his uncle Juan Nepomuceno Guerra", "Bergen", "embalming", "on November 11, we honor these", "a graphical user interface", "a two - layer coat"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5876370062950945}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.37500000000000006, 0.05405405405405406, 1.0, 0.1818181818181818, 1.0, 0.16666666666666669, 1.0, 0.6666666666666666, 0.29629629629629634, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.5714285714285715, 1.0, 0.0, 0.10256410256410257, 1.0, 0.4, 1.0, 0.3333333333333333, 0.9411764705882353, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 0.2857142857142857, 0.33333333333333337, 0.0, 1.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3794", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.40625, "CSR": 0.5339176829268293, "EFR": 1.0, "Overall": 0.7669588414634146}, {"timecode": 41, "before_eval_results": {"predictions": ["the Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1997", "displacement", "layered systems of sovereignty, especially within the Holy Roman Empire", "Megan Park", "the euro is the result of the European Union's project for economic and monetary union which came fully into being on 1 January 2002", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "international aid as one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million customer accounts", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "initially registered with churches, who maintained registers of births", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Blake DeLong as Andrey / Prince Bolkonsky", "collect menstrual flow.", "pigs", "General George Washington", "Spanish", "Virgil Tibbs", "an integral membrane protein that builds up a proton gradient across a biological membrane", "in the sinoatrial node travels through the right atrium to the atrioventricular node, along the Bundle of His and through bundle branches", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements ) episodes", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Jos Plateau", "Missouri River", "the right to be served in facilities which are open to the public", "spinal cord", "10 June 1940", "Tandi", "alberich", "ear canal", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "the Kurdish Region of Iraq thus far, we are making significant progress in spurring on economic growth and creating opportunity for our people.", "Denver", "the southern Sadr City residents.", "CTU", "Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.5, "QA-F1": 0.6476746383426294}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.06451612903225805, 1.0, 0.0909090909090909, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 0.8235294117647058, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518", "mrqa_searchqa-validation-1237"], "SR": 0.5, "CSR": 0.5331101190476191, "EFR": 0.9375, "Overall": 0.7353050595238095}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization", "in Middlesex County, Province of Massachusetts Bay, within the towns of Lexington, Concord, Lincoln, Menotomy ( present - day Arlington )", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "The Senate is composed of senators, each of whom represents a single state in its entirety, with each state being equally represented by two senators", "Zeus", "during Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "a female given name, the Latin transliteration of the Greek name Berenice, \u0392\u03b5\u03c1\u03b5\u03bd\u03af\u03ba\u03b7", "Field Marshal Paul von Hindenburg", "Ceramic art", "the Soviet Union", "Covington, Kentucky", "New Mexico", "to condense the steam coming out of the cylinders or turbines", "December 15, 2017", "Paradise, Nevada", "L.K. Advani", "differential erosion", "Glenn Close", "the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "electricity generation, power distribution, and power transmission on the island", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English p Parsons may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "a pair of compasses", "Charlotte Thornton", "the Northeast Monsoon", "March 16, 2018", "President Lyndon Johnson, himself a Southerner", "the European Renaissance, the Age of Discovery, and the Protestant Reformation", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "880,000 square kilometres ( 340,000 sq mi )", "by producing an egg through parthenogenesis", "1926", "East Asia", "31 December 1947", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Loki", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "not registered on the National Firearms Registration and Transfer Record as required by law.", "prostate cancer,", "wyvern", "Little Lord Fauntleroy", "white rabbit", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.625384874676078}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.9444444444444444, 0.2222222222222222, 1.0, 1.0, 0.06896551724137931, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.9767441860465117, 1.0, 0.7058823529411765, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.5316133720930232, "EFR": 0.9117647058823529, "Overall": 0.721689038987688}, {"timecode": 43, "before_eval_results": {"predictions": ["May 21, 2013", "2007", "she was `` sick of keeping all these feelings inside and not speaking up for myself ''", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "as the arms of the king of Ireland", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Brutus", "Pierre Mallet", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier,", "Edward Kenway", "Haliaeetus", "a thick bunch of rootlets ( branch roots )", "Alex Ryan", "habitat", "2018", "Windows Media Player 11", "100", "Toledo", "embryo", "During the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "Alicia Vikander", "late January or early February", "Ashoka", "the compartments known as Relieving Chambers", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority", "Devastator", "the Christian biblical canon", "New England", "AMX - 50, heavy tank", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "2008", "Florida", "the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "in the southwestern part of the island", "usually in a way considered to be unfair", "wintertime", "Pangaea", "Newcastle Brown Ale", "Western Australia", "vaclav Havel", "Mary Bon auto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"peregruzka\"", "$60 billion", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5739204867553082}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.5, 0.1818181818181818, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.9387755102040816, 0.5714285714285715, 0.5000000000000001, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.07142857142857142, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.09523809523809525, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-151", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.421875, "CSR": 0.5291193181818181, "EFR": 1.0, "Overall": 0.7645596590909091}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Mississippi", "about the outdoors, especially mountain-climbing", "Mississippi Delta", "Ritu Nanda Insurance Services", "jean Baptiste Point du Sable", "1992", "the Goddess of Pop", "Alabama", "James Harrison", "Toronto", "Tomorrowland", "fennec", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Democritus", "Caesars Entertainment Corporation", "Terrence \"Uncle Terry\" Richardson", "Reinhard Heydrich", "Karl Kraus", "Steve Howey", "Maria Brink", "Manitobaowoc County, Wisconsin", "North Korea", "Adelaide", "World Famous Gold & Silver Pawn Shop in Las Vegas", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Adventures of Huckleberry Finn", "French cuisine", "South America", "2006", "four months in jail", "\"The Major of St. Lo\"", "Mary Elizabeth Hartman", "over 9,000", "John Nightingale as Tom Seaton", "potential of hydrogen", "San Antonio, Texas", "Stephen King Biography", "Finger Tips", "Kent", "almost 9 million", "Kenya", "2008", "small", "baby Moses", "Chapter 5", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5501802884615384}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.8, 0.6666666666666666, 0.4, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-2340", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-3458", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-1449", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-2020", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.40625, "CSR": 0.5263888888888889, "EFR": 1.0, "Overall": 0.7631944444444445}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda's", "1858", "Australian", "1903", "interstate commerce", "Naomi Wallace", "Jenson button", "Tufts College", "Macau", "Azeroth", "Squam Lake", "The Livingston family", "Tayeb Salih", "King James II of England", "God Save the King", "526 people per square mile", "Scotland", "\"rock and roll\"", "GmbH", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Chesley Burnett \"Sully\" Sullenberger III", "VHF Global Lightning", "Asia-Pacific War", "Romantic", "Hugh Dowding", "AMC Entertainment Holdings, Inc.,", "New York Islanders", "Fennec fox", "1978", "John Surtees", "Canadian", "Pacific Place", "The Australian women's national soccer team", "\"Bad Blood\"", "Rudebox", "about 5320 km", "Andrea Maffei", "Khilona", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faysal Qureshi", "the British Army", "Democracy", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Maroon 5", "Saudi Arabia", "Sabo", "two"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6177083333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-614", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327", "mrqa_searchqa-validation-2897"], "SR": 0.546875, "CSR": 0.5268342391304348, "EFR": 1.0, "Overall": 0.7634171195652174}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland sharks", "The Word", "President Abraham Lincoln", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "the Death Penalty", "annual", "Jackie Robinson", "Manhattan", "Dian Fossey", "MI5", "Harrow", "cr\u00e8me anglaise", "onions", "pork", "curling", "Victoria Coren Mitchell", "Gettysburg", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara", "Mercury", "Venus", "Barack Obama", "Canada's Liberal Party", "mortadella", "Cuba", "David Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "Florida", "Mary Poppins", "Glyn Jones", "Port Moresby Harbour of the Gulf of Papua", "Connecticut", "Quentin Blake", "whooping cough", "The Daily Herald", "(1939\u20131945)", "\"permissible.\"", "2016", "the Supreme Court of Canada", "2017", "Chief of Protocol", "Diamond White", "1944", "umpire Louise Engzell.", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "How to Keep Young Mentally", "the other"], "metric_results": {"EM": 0.625, "QA-F1": 0.6829861111111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.625, "CSR": 0.5289228723404256, "EFR": 1.0, "Overall": 0.7644614361702128}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "anaphylaxis", "alex more penalty shoot-outs", "Culloden", "Runic", "portugal", "tennis", "alex planck", "rotherham United", "heat transfer", "Misery", "Styal", "olek", "blind beggar", "Brainwash", "london", "parlophone", "Wild Atlantic Way", "john Denver", "oscar", "noddy", "oscar", "canada", "a Tree Swing", "a muezzin", "a window", "a ship s keel", "alex", "Apollo 11", "Cellophane", "Nikola Tesla", "Nicky Henderson", "Evita", "albino sperm whale", "roddy", "east fife", "st Pancras", "social environment", "sliced bread", "Dilbert", "aristotelian Tragedy", "nunc dimittis", "French", "medea", "Burgundy", "cribbage", "oscar mores", "Johannesburg", "France", "the Muffin Man", "victoria", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "the Greenbriar Boys", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas, to Veracruz, Mexico,", "carrier based in Texas.", "Robert Frost", "Henry VIII", "oscar", "Mitsubishi Lancer OZ Rally"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6322668650793651}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.888888888888889]}}, "before_error_ids": ["mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-1258", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.546875, "CSR": 0.529296875, "EFR": 0.9655172413793104, "Overall": 0.7474070581896552}, {"timecode": 48, "before_eval_results": {"predictions": ["Route 66", "sesame street", "marcella Hazan", "cabbage", "south east of Australia", "mister magoo", "fleece", "Ash tree", "opossum", "new Zealand", "maurice ravel", "60", "goldfinger", "1983", "pike", "mongols", "1875", "tax collector", "penny", "Rod Stewart", "spain", "bagram", "jordan farfrae", "Chrysler", "ushanka", "mrigg", "maur\u00e9at", "spain", "Brazil", "pei Tang", "biathlon", "Idaho Falls", "jimmy Chan", "Vienna, Austria", "white", "spain fish", "Paul Rudd", "rabbit", "scottish", "jimmy Leadbetter", "Orson Welles", "prakrits", "menorah", "Dutch", "Texas", "marmole", "quant pole", "jimmy stout", "michael farfrae", "Rhododendron", "Ireland", "Chuck Noland", "the Colony of Virginia", "in Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park, Kenya", "2010", "Greece, the birthplace of the Olympics,", "10 below", "100 to 150", "silver", "the American Kennel Club", "Omaha", "George Glenn Jones"], "metric_results": {"EM": 0.375, "QA-F1": 0.5038345410628019}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 0.9565217391304348, 1.0, 0.888888888888889, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-2446", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-3053", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-5848", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2352", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.375, "CSR": 0.5261479591836735, "EFR": 1.0, "Overall": 0.7630739795918368}, {"timecode": 49, "before_eval_results": {"predictions": ["quan Ivy", "Iran", "tobacco", "francis", "jennifer", "Daniel Boone", "Thames Street", "jennifer roosevelt", "satyrs", "crabs", "lee boheme", "IBM", "bone", "Garrick club", "jaber elbaneh", "master Humphrey", "britten", "American Civil War", "\"black\"", "Cybill Shepherd", "jimmy Robertson", "Florence", "saint Basil", "veruca salt", "severn", "australia", "south Africa", "droughts", "Nicaragua", "Neville Chamberlain", "wars of roses", "leipzig and Dresden", "of america", "trout", "joseph Dubonnet", "kennon", "chile", "jennifer lomax", "alopecia", "track cycling", "charlie darlings", "king Arthur", "Chris Martin", "flinstone", "(Lee Ingleby)", "rugby", "hanghai", "deacon blue", "11", "tobacco", "cows", "free floating", "Harrison Ford", "New Orleans", "a pinball machine", "Texas Tech University", "leicestershire", "Sharon Bialek", "the United States", "that the National Guard reallocated reconnaissance helicopters and robotic surveillance craft to the \"border states\" to prevent illegal immigration.", "George F. Babbitt", "Oklahoma", "Company", "four"], "metric_results": {"EM": 0.296875, "QA-F1": 0.3710737179487179}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6153846153846153, 0.8, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-2670", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1810", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6840", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-13441", "mrqa_searchqa-validation-3615"], "SR": 0.296875, "CSR": 0.5215624999999999, "EFR": 1.0, "Overall": 0.76078125}, {"timecode": 50, "UKR": 0.66796875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.85546875, "KG": 0.45, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "\"The Gentle Don\"", "Walcha", "Belladonna", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland", "37", "Tufts University", "Owsley Stanley", "\"The Late Late Show\"", "Kongo", "Harold Lipshitz", "Spanish", "\"A Million Ways to Die in the West\"", "1945", "69.7 million", "Neneh Cherry", "Fiapre", "antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport", "Scotty Grainger Jr.", "9", "(George) Ballade", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional literature", "Fortunino Francesco Verdi", "modern dance", "Cecily Legler Strong", "J. Robert Oppenheimer", "invoicing the employees' work based on an hourly rate", "seasonal television specials, particularly its work in stop motion animation", "4 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "Pamela Chopra", "1901", "Pope John X", "Best Art Direction", "(VAQ-135)", "Doug Pruzan", "The Nitty Gritty Dirt Band", "( later King James II & VII", "'Q'", "U.S. Marshals", "a pitcher", "EMI", "UNICEF", "9 a.m.,", "(George) Byron", "Van Helsing", "Aramaic", "a long-range missile"], "metric_results": {"EM": 0.5, "QA-F1": 0.6360119047619048}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, true, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.8, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-3163", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4925", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-3499", "mrqa_hotpotqa-validation-4616", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-495", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.5, "CSR": 0.5211397058823529, "EFR": 1.0, "Overall": 0.6989154411764706}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field in Detroit, Michigan", "comedy", "Buena Vista Distribution", "143,007", "\u00c7ankaya St.", "\"Realty Bites\"", "24 NCAA sports", "Razor Ramon", "object relations theory", "Forbes", "St. George", "Kramer Guitars", "Lithuanian", "International Boxing Federation", "35", "Conservatorio Verdi", "Binion", "Smoothie King Center", "World Outgames", "Homebrewing", "Umberto II", "Presbyterian Church", "neuro-orthopaedic Irish veterinary surgeon", "Hookend Recording Studios", "North Sea", "17 October 2006", "67,575", "Oxford", "\"Advanced Dragons\"", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "Italian", "Eric Whitacre", "historic landmark hotel in downtown Riverside, California", "180", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "Ardfert in County Kerry, Ireland", "Scunthorpe", "Canadian comedian", "Captain Cook's Landing Place", "Summer Olympic Games", "1862", "1970", "Royal Albert Hall and The Kennedy Center", "Budget Rent a Car", "Ch\u014dfu, Tokyo, Japan", "lion", "1959", "Kristina Wagner", "is a pop and R&B ballad, with Latin pop influences", "735 feet", "ireland", "Bette Davis", "maxilla", "Intel", "4.6 million", "Iran,", "tea rose", "Pershing", "Keil", "Rear Window"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5633306751727805}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true], "QA-F1": [0.888888888888889, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1260", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-5556", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-3934"], "SR": 0.46875, "CSR": 0.5201322115384616, "EFR": 1.0, "Overall": 0.6987139423076923}, {"timecode": 52, "before_eval_results": {"predictions": ["September 24", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "the central voters list was kept or that citizens were given some form of voter identification", "3", "100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judith Aline Keppel", "Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Albert Finney", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the Gospel of Matthew", "30 years after Return of the Kenobi", "A standard form contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1963", "the Colony of Canada ( part of New France )", "The following year", "in the U.S. states of Oregon and Washington", "Magnetically soft ( low coercivity ) iron", "July 8, 1998", "Malware", "Cyndi Grecco", "ingredients", "From 1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "roofing material", "one person", "The Parlement de Bretagne ( Administrative and judicial centre of Brittany, Breton : Breujo\u00f9 Breizh )", "Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "late - September", "currency option", "1599", "enables access to the mini-game", "the medulla oblongata", "1998", "Gibraltar, a British Overseas Territory", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "Steptoe and Son", "Gerry Adams", "Child actor", "Saoirse Ronan", "Revolution Studios and Happy Madison Productions", "The Kirchners", "Croatia playmaker", "Gordon Brown", "veterans", "yellow fever epidemic", "Hemispheres", "Netflix"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6530518929955704}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [0.4, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.046511627906976744, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 0.125, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5446", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-10706", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-9142", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-3959", "mrqa_hotpotqa-validation-2688", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-1420", "mrqa_searchqa-validation-4527"], "SR": 0.546875, "CSR": 0.5206367924528301, "EFR": 0.9310344827586207, "Overall": 0.6850217550422901}, {"timecode": 53, "before_eval_results": {"predictions": ["Al Lenhardt", "Science and Faith", "Beethoven", "Green Acres", "Life's Refinements", "a chocolate-covered blend of coconut, nuts, and fruit", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "Calvin Coolidge", "the Institute of Cybernetics", "salmon", "Pudd'nhead Wilson", "Sydney", "the tapir", "France", "Spam", "Hector Berlioz 7", "early labour", "Camembert", "Sunday", "the Golden Legend", "Centaur", "Mentor", "Emile Lahoud", "Manifest Destiny", "William Jennings Bryan", "Americans with Disabilities", "China", "Streets of Philadelphia", "the Federal Republic of Germany", "Glucosamine", "Madagascar", "Wikipedia", "a celebration, stunt, spectacle", "astrachan (curly lambswool) formerly worn by rifle regiments", "Susan Faludi", "Dr. Dre", "Tampa Bay Rays", "Fidel Castro", "fudge", "a story of the Transcontinental Railroad", "Laborers' International Union", "goldfish", "hormones", "a dive in which the diver bends in midair to touch the feet", "yellowtail", "watermelon", "between the Mediterranean Sea to the north and the Red Sea in the south", "Beijing", "Zeus", "Van Morrison", "antelopes", "manufacturer, distributor, and marketer of non-alcoholic beverage", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube", "3 thousand", "a firefight Friday in Afghanistan", "about 3,000 kilometers (1,900 miles), possibly putting U.S. military bases in the Pacific Ocean territory of Guam within striking distance,", "Lambic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5575181159420289}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, true, false, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.34782608695652173, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-2596", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-14085", "mrqa_searchqa-validation-1108", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-3349"], "SR": 0.46875, "CSR": 0.5196759259259259, "EFR": 0.9705882352941176, "Overall": 0.6927403322440087}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "Assam", "a travelling circus", "the vascular cambium", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "teaching elocution", "Manchester", "seven", "1999", "Rashida Jones", "Hook", "Bush", "the merging of tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "Brooklyn Heights, New York", "Haji Sahib of Turangzai", "45 %", "handheld subscriber equipment", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "2017", "Jonny Buckland", "the Ming dynasty", "a major river in the southern United States of America", "those colonists of the Thirteen Colonies", "The Intolerable Acts", "National Industrial Recovery Act", "semi-autonomous", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "1964 Republican National Convention in San Francisco, California", "Cal", "( such as the muscles of the limbs, abdominal, and intercostal muscles )", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "driving jessica tandy", "the Greek Goddess of Revenge", "Kaneohe Bay", "PlayStation 4", "2015 Orange Bowl", "Seminole Tribe", "Defense of Marriage Act", "Alinghi", "the Eiffel Tower", "barnacles", "LOVE", "jimmy McGregor"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6311713694098329}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.0, 0.5882352941176471, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.3448275862068966, 1.0, 1.0, 0.19999999999999998, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-8386", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-2067", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.484375, "CSR": 0.5190340909090909, "EFR": 1.0, "Overall": 0.6984943181818182}, {"timecode": 55, "before_eval_results": {"predictions": ["Edward III", "golf", "purple", "aeoline", "ascot", "Litas", "Loretta Lynn", "WrestleMania", "born To be Wild", "chop suey", "crawford", "Coronation Street", "The Bill", "hanghai Gibbs", "Saddam Hussein", "New Zealand", "Tyrrhenian", "Bobby Sands", "MauritaniaMauritania", "Galileo Galilei", "Bolivia", "Nick saxton", "mad Madagascar", "ash", "Edward VII", "k Thomas Cranmer", "testicles", "quetzal", "bacall", "Caroline aherne", "Byron", "s\u00e8vres", "Mau-Mau", "kipps: The Story of a Simple Soul", "guggul", "Serena Williams", "Lome", "Pegida", "wagner", "Utrecht", "1709", "loveisspeed", "kansas", "Miles Morales", "nymphs", "Skylab", "cheetah", "Hugh Quarshie", "a stern tube", "Batman", "korea", "Michelle Stafford", "seven", "Kid Creole and the Coconuts", "Jack", "Linux Format", "Stage Stores", "26", "ordered the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guantanamo Bay, Cuba.", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5955965909090909}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.48484848484848486, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5554", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-6312", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-179", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.5625, "CSR": 0.5198102678571428, "EFR": 1.0, "Overall": 0.6986495535714285}, {"timecode": 56, "before_eval_results": {"predictions": ["ireland", "bolivia", "The Telegraph", "heart", "portugal", "Clue", "Galway Bay", "auguste sossi", "calcium carbonate", "Salman Rushdie", "george elosevelt", "along with the harbour, Te Papa and the hills", "koftas", "benazir butto", "all-handed", "Sam smith", "thorson", "scorcese", "ninth", "business", "godiva", "scorcese", "guatemala", "river Towy", "Lab\u00e8que", "1984", "scotland", "3\u201311", "shinto", "Sussex", "george iv", "Mickey Mouse", "phosphorus", "Prince albert", "monaco", "do I have to use earplugs", "Dodoma", "Radiohead", "Wilson", "loch ness", "el aneto", "south korea", "gelatine", "guinea", "gulf of Aden", "Yorkshire", "an Express Bus shuttle service that costs \u20ac17 and picks up passengers from parking Pershing, located near porte maillot M\u00e9tro stop three hours before RyanAir", "sankt torriani", "the French Revolution", "old kent Road", "on your way in one of two ways, cremation or inhumation", "anion", "iron", "Johnson", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Spurs", "Venus Williams", "off Somalia's coast.", "Shanghai", "katheryn Maloney and Brady Cullinan", "John Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5252757352941176}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-1001", "mrqa_triviaqa-validation-4984", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-2968", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1466", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-6753", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-4566", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_searchqa-validation-10653", "mrqa_hotpotqa-validation-4052"], "SR": 0.453125, "CSR": 0.518640350877193, "EFR": 1.0, "Overall": 0.6984155701754386}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "jessica smith", "rennet", "river lee", "Rudolf nureyev", "j Jessica", "placebo", "weather", "Lake placid", "papal", "braille", "charles boyd", "Saint Cecilia", "Caroline g Garcia", "ernie wiseman and cleman", "Maggie Gilkeson", "butcher", "cowpox", "deer hunting", "Stockholm", "France", "b Brothers in Arms", "olfactory", "to Pluto", "chemnitz", "rue", "yellow", "raven", "capital of caracas", "ennio morricone", "British", "mexico", "Time Team", "Turandot", "mexico", "tallest mountain in the world", "Dan Dare", "Howard Keel", "marriage", "Boutros Ghali", "Germany", "mcPherson", "mexico", "disciples", "a tree diagram worksheet", "3", "Bild", "France", "Kristiania", "keirin", "selene", "vehicles designed for off - road use are known as `` four - wheel drives '', `` 4WDs '', or `` 4 \u00d7 4s ''", "an American actor", "Tbilisi, Capital of Georgia", "Las Vegas", "2006", "number five", "natural gas", "he was diagnosed with skin cancer.", "Shiza Shahid,", "Perseid meteor shower", "accordion", "bones", "Marky Mark"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5772321428571427}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6109", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-5579", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-7431", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-2804", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-7177", "mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-4074", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_triviaqa-validation-6078", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-6769", "mrqa_naturalquestions-validation-8026", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-16209"], "SR": 0.46875, "CSR": 0.5177801724137931, "EFR": 1.0, "Overall": 0.6982435344827587}, {"timecode": 58, "before_eval_results": {"predictions": ["Frottage", "Jonah", "The Color Purple", "Constantinople", "Jacqueline Susann", "Bangladesh", "Hudson River", "bones", "New Years Day", "The Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "gemstones", "deep Woods", "Siberia", "William Pitt the Younger", "five", "Friday the 13th", "Rotherham", "The Godfather", "melanoma", "Nostradamus", "jihad", "harpoons", "Mandy", "finance", "Conrad Hilton", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "Battle of Trafalgar", "the bald eagle", "menudo", "Panax", "hurricanes", "Home Improvement", "Kashmir", "Airport", "alphabets", "Bourbon French Parfums", "a single death", "Little Mermaid", "identical twin brother", "injecton", "Pell grants", "emerald", "stained glass", "19 July 1990", "anvil", "Louis XV", "Zimbabwe", "Mansion House", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Eden Park", "money"], "metric_results": {"EM": 0.5625, "QA-F1": 0.609375}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-12017", "mrqa_searchqa-validation-1938", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225"], "SR": 0.5625, "CSR": 0.5185381355932204, "EFR": 0.9642857142857143, "Overall": 0.6912522699757869}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "italianmoneyguy.com", "whisky", "Leonard Bernstein", "magnesium", "Milan", "Danube", "the albatross", "Costanza", "The Smashing Pumpkins", "larger units", "Ohio State", "Sherman", "Pakistan", "Theology of God", "Ireland", "Sally Field", "Barbara Cartland", "Rum", "a Pringles can", "Paul Hamm", "profundo", "East Siberia", "Nimble", "Tom Hanks", "Clue", "a black magpies", "Hillary Clinton", "an alternating current system", "Walter Cronkite", "Robert Burns", "Bicentennial", "We Are Marshall", "General Motors", "the trade winds", "the 1964 New Hampshire Primary", "silk", "a vowel", "the Unicorn", "Scrabble", "humerus", "Saturday Night Fever", "Petruchio", "the Philippines", "mushrooms", "(Ernesto) Guevara", "Yale", "Oscar Wilde", "Nestor", "Dian Fossey", "a relief print", "an iron -- nickel alloy and some other elements", "ABC", "a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court", "pear", "Melbourne", "jape", "Ringo Starr", "D.O.", "Hanna, Alberta", "Majid Movahedi,", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "\"We take this issue seriously,\"", "king of Troy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6783514492753623}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6, 0.0, 0.34782608695652173, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-5632", "mrqa_searchqa-validation-6411", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-4918", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-1635", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_triviaqa-validation-6487"], "SR": 0.5625, "CSR": 0.5192708333333333, "EFR": 1.0, "Overall": 0.6985416666666667}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "close to 50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Nani", "four", "Sippin'", "Sergeant Purley Stebbins", "Maersk Mc- Kinney M\u00f8ller Centre for Continuing Education", "New Orleans", "the University of Kentucky", "five", "Charlie Wilson", "Sim Theme Park", "850 saloon", "riverside location", "1950s", "Julie Taymor", "actor", "James Edward Kelly", "Spanish", "Indiana University", "lower Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "Tom Courtenay", "Erinsborough", "2015", "Vladimir Valentinovich Menshov", "The Birds", "Derry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Lewis", "UFC Fight Pass", "25 August 1949", "Savannah River Site", "\u00c6thelwald Moll", "God and the just cause", "Dubai", "emperor tiberius", "World War I", "at age 27", "Marktown", "five", "Rodney Crowell", "pea plants", "near major hotels and in the parking areas of major Chinese supermarkets", "a major", "d\u00fcsseldorf", "apollon", "Anil Kapoor", "\" Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III", "quarantina", "Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6768830128205128}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.2, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3746", "mrqa_hotpotqa-validation-5741", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4752", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-5216", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.578125, "CSR": 0.5202356557377049, "EFR": 0.9629629629629629, "Overall": 0.6913272237401336}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaelic", "Chicago Bears", "girls", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Adult Swim", "2003\u20132008", "Rio Gavin Ferdinand", "264,152", "2,664", "841", "Cher", "Australian Broadcasting Corporation (ABC)", "MG Cars", "Mickey Mouse", "1979", "15", "January 23, 1898", "John W. Henry", "Winter Hill", "Argentinian", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "Battle of White Plains", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "Dziga Vertov", "Friday", "Oklahoma Sooners", "2002\u201303", "7pm", "1866", "Gaahl", "Serie B", "1887", "Sojourner Truth", "RAF Tangmere, West Sussex", "North Holland", "Charlie B. Barkin", "Golden Calf", "The Lykan Hypersport", "the final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer University", "1951", "35,124", "154 days", "September 30", "Jimmy Flynn", "the Western Bloc ( the United States, its NATO allies and others )", "his finger", "Ronald Wilson Reagan", "One Thousand and One", "Long troop deployments", "fuel economy and safety while boosting", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "James Watt", "T.S. Eliot", "Anastasia", "G -- Games"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5721379551274431}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.4, 0.3636363636363636, 0.6666666666666666, 1.0, 1.0, 0.0, 0.10526315789473684, 0.5217391304347826, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-3573", "mrqa_hotpotqa-validation-4916", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-4408", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129", "mrqa_naturalquestions-validation-715"], "SR": 0.453125, "CSR": 0.5191532258064516, "EFR": 1.0, "Overall": 0.6985181451612903}, {"timecode": 62, "before_eval_results": {"predictions": ["The Dayton Memorial Hall", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Ishtar Gate", "a card (or cards) during a card game", "water sprite", "Sean Yseult", "circuit courts", "1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "King George VI", "August 10, 1933", "Dallas", "the Lost Boys Foundation", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "Simon Bolivar Buckner", "German", "Gareth Jones", "consulting", "April", "1978", "actor, producer, and director", "Sarah Hadland", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "The Mountbatten family", "dice", "Kal Ho Naa Ho", "Dungeness crab", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "David O'Leary", "HackThis Site", "Reginald Engelbach", "American", "Black Friday", "Golden Valley, Minnesota", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard seddon", "the heart", "Sitka, Alaska", "to take the Rio Group to a new level by creating the organization.", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "Bob Bogle", "circum", "Austin", "a stationwagon", "2001"], "metric_results": {"EM": 0.53125, "QA-F1": 0.596780303030303}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-5811", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4046", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-7093", "mrqa_searchqa-validation-12404"], "SR": 0.53125, "CSR": 0.5193452380952381, "EFR": 0.9666666666666667, "Overall": 0.691889880952381}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"justice\"", "water hemlock", "Beluga whale", "Nicholas II", "a fish", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "salir", "Thor", "Orange", "astride", "Borneo", "Versailles", "a cereal", "located just outside of Dallas", "whipped cream", "a tuna", "Macbeth", "Jean Michel Basquiat", "Led Zeppelin", "War and Peace", "Dutchman", "Moonlighting", "a small Southern town", "Columbo", "John Tyler", "Milwaukee", "sin", "Greed", "shochu", "Notre Dame", "Portland", "Charles-Franois de Broglie", "the Indianapolis 500", "Toy Story", "a stand-up comedian", "Charles Askegardshe", "water", "Nikolai Gogol", "David Hare", "Fletcher Christian", "weaving", "John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Phillip Schofield", "enterocytes", "Reverend J. Long", "violin", "library", "the second peak", "Garrett Morris", "1966", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "Three thousand", "al-Maliki"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6411830357142857}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-3355", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-3642", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1825", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.59375, "CSR": 0.5205078125, "EFR": 1.0, "Overall": 0.6987890625000001}, {"timecode": 64, "before_eval_results": {"predictions": ["a pumpkin", "Seminole", "billions of dollars", "scout", "228", "a traditional form of lounge music that flourished in 1940's Japan.", "2005.", "radioactive sludge.", "consumer confidence", "Second seed Fernando Gonzalez", "in the southern port city of Karachi", "The pilot,", "Jason Chaffetz", "processing data", "India", "Iran", "Sunday", "Bienvenido Latag", "France", "380,000", "be silent.", "iTunes", "Kenyan", "\"gotten the balance right\"", "a dozen", "10", "\"Quiet Nights,\"", "his death cast a shadow over festivities", "North Africa", "the recovery of 123 pounds of cocaine and 4.5 pounds of heroin", "an engineering and construction company", "not testify", "pelvis and sacrum", "five", "to step up.", "first-degree murder", "Moscow", "Mashhad", "2007", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda,", "Garth Brooks", "Oxbow, a town of about 238", "Bahrami", "different women coping with breast cancer", "Michael Schumacher", "Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Dennis Locorriere", "Theodosius I", "czech", "Estonia", "is our children learning?", "Anne", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Ptolemy", "Woodrow Wilson", "the middle"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6376463813963813}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, false, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.2222222222222222, 1.0, 0.5454545454545454, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.9090909090909091, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.9, 0.8571428571428571, 0.0, 0.8571428571428571, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-1314", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1367", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-44", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-236", "mrqa_newsqa-validation-3682", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-446", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-709"], "SR": 0.453125, "CSR": 0.5194711538461538, "EFR": 1.0, "Overall": 0.6985817307692308}, {"timecode": 65, "before_eval_results": {"predictions": ["304,000", "\"I always kind of admired him, oddly.\"", "North Korea", "February 12", "Mandi Hamlin", "South African Judge Richard Goldstone", "\"falling space debris,\"", "Conway, Arkansas,", "voluntary manslaughter", "immediately put Morgan on a helicopter to Rainbow Babies and Children's Hospital in Cleveland,", "Chris Robinson", "Sandy Olssen", "Cipro and other fluoroquinolones,", "34", "E. coli bacteria", "More than 15,000", "\"A good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "government", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "against using injectable vitamin supplements because the quantities are not regulated.", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "President Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "Richmond students did nothing because of the \"bystander effect\"", "9:20 p.m. ET", "managing his time.", "ensure that government treats all its citizens equally, to fight injustice and intolerance in all its forms and to bring about that more perfect union,\"", "bipartisan", "us to step up.\"", "wanted to change the music on the CD player and the 34-year-old McGee said the football star had acted aggressively in trying to grab the device.", "education about rainforests.", "13 and 15", "Vicente Carrillo Leyva,", "state", "Trevor Rees-Jones,", "at least 28 passengers,", "the leader of a drug cartel", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "secretary of state", "243 days", "Kirstjen Nielsen", "August 5, 1937", "20", "Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "Queenston Delta", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6452984515484516}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.4, 0.8571428571428571, 0.5, 0.0, 1.0, 1.0, 0.06666666666666667, 1.0, 0.0, 0.0, 1.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2056", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2911", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-3555", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2725", "mrqa_naturalquestions-validation-9728", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692"], "SR": 0.53125, "CSR": 0.5196496212121212, "EFR": 1.0, "Overall": 0.6986174242424242}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "north west", "ArcelorMittal Orbit", "\"lodges\")", "Stilwell", "Tallinn", "solar system", "coelacanth", "Belgium", "Dennis Potter", "Calcium", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "California condor", "new york", "turbines", "Sid James", "The Bill", "0", "Hamlet", "Johannesburg", "crackerjack", "Bleak House", "\"You'll Never Walk Alone\"", "spain", "Minder", "mustard", "Les Dennis", "kansas city", "Gradgrind", "Toscana (Tuscany) Region", "18 meters", "Singapore", "Dinkley", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "Jack Kennedy", "george lee", "Chuck Yeager", "Melody Lysette", "northern France", "collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements", "Ishmael", "coral reefs or hard coral communities", "12.9 - kilometre ( 8 mi )", "a sociological perspective which developed around the middle of the twentieth century and that continues to be influential in some areas of the discipline", "21 July 2015", "Bern", "28 June 1945", "not", "25", "Pakistan's", "Yves Saint Laurent", "Eric Clapton", "\"If people don't want to come out to the ballpark,", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6534304511278196}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.10526315789473684, 0.5, 0.0, 1.0, 0.09523809523809523, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-6641", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_triviaqa-validation-7014", "mrqa_triviaqa-validation-1771", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.59375, "CSR": 0.5207555970149254, "EFR": 1.0, "Overall": 0.6988386194029851}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Alaska", "Christina Pickles", "August 9, 1945", "after obtaining the consent of the United Kingdom", "they were ranked the best selling cake or biscuit", "Olivia Olson", "Los Angeles", "Pyeongchang County, South Korea", "602", "April 7, 2016", "5.7 million", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "during the first week of April", "Tiger Woods", "Plank", "Executive Residence of the White House Complex", "the United Kingdom ( UK )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET", "1836", "Mariah Carey", "Spektor", "respiratory acid", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "northern Ukrainian Soviet Socialist Republic, Soviet Union", "435", "sport utility", "Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "plane crash", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand", "Frank Oz", "Flag Day in 1954", "2010", "Missouri River", "elvis elvis I", "lute", "phoibos", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town", "Jaime Andrade", "people", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi", "hyperbole"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6235350554695562}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.11764705882352941, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.8, 0.7368421052631579, 1.0, 0.8421052631578948, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-335", "mrqa_searchqa-validation-12184"], "SR": 0.484375, "CSR": 0.5202205882352942, "EFR": 0.9696969696969697, "Overall": 0.6926710115864528}, {"timecode": 68, "before_eval_results": {"predictions": ["North Rhine-Westphalia", "roba flack", "sesame seed", "Infante", "Tuesday", "barnaby rudge", "Buddha", "ethiopia", "1963", "discus thrower", "tabloid", "royal festival of england", "chester racecourse", "ohio", "Mizrahi Jews", "Romanian", "saint Basil's", "Peru", "the keel", "Evander Holyfield", "intercrosse", "Buddhism", "new Orleans", "sprite", "fat like oil or lard", "edward hanghai", "brashy", "ken Burns", "paddy doherty", "barry johnson", "khi", "Hungary", "so Solid Crew", "blind faith", "Pennsylvania", "caucausus", "malaysia italy", "rockin', rollin', ridin',", "jupiter", "watch with mother", "tiddler", "eight", "york park Rangers", "wiziwig", "Cyclopes polyphemus,", "flannel", "b\u00e9la bart\u00f3k", "Hugh Dowding's father, Arthur Dowding,", "Montpelier", "February", "aragon", "2015, in the United States, the poverty threshold for a single person under 65 was an annual income of US $11,770", "318", "Chris Rea", "Andrzej Go\u0142ota", "\"Forbidden Quest\" (2006)", "March 30, 2025", "Amanda Knox's aunt Janet Huff", "the Gulf of Aden,", "rabbit hole,", "deep-rooted", "the United States", "Mullet", "it can be a year of politics as usual"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4760573308270677}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.21052631578947367, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-3986", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-2964", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-3417", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-638", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.390625, "CSR": 0.5183423913043479, "EFR": 0.9743589743589743, "Overall": 0.6932277731326645}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey Archer", "Chicago", "filly/mare", "dar es salaam", "Gary Gibbon", "miss marple", "Elkie Brooks", "UPS", "robert nadalal", "piano", "Cambridge", "bennet", "spice girls", "syrupy", "addams", "Doubting Castle", "insect", "germany", "england", "Harry Shearer", "9-13 years", "pirate day", "farthings", "Spice Girls", "48 Hours", "AFC Wimbledon", "germany", "Tombstone", "Nietzsche", "Cambridge", "south african", "bagram", "pygmalion", "bajan", "cassis", "Dieppe Raid", "Dengue fever", "left book club", "triathletes", "barbershop quartet", "dividing of cells into additional cell bodies", "strictly Come Dancing", "\"sound and light\"), or a sound and light show,", "Par-4", "fox terrier", "Prairie region", "fondue", "kilimanjaro", "The Magic Circle", "potsdam Conference", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Cordelia", "London Luton Airport", "Sarah Winnemucca Hopkins", "Antigua & Barbuda", "Chaudhary's death was warning to management.", "they don't feelMisty Cummings,", "\"The deceased appeared to have been there for some time.\"", "Vanilla Ice", "William Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5713609307359307}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5454545454545454, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-6664", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-2520", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-1346", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627"], "SR": 0.515625, "CSR": 0.5183035714285714, "EFR": 1.0, "Overall": 0.6983482142857144}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew", "a sentence fragment", "New South Wales", "Ashrita Furman", "Lana Del Rey", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "2018", "the term originated in Missouri, during the Kirtland period of Latter Day Saint history, circa 1834", "Swedien and Jones", "1902", "Edgar Lungu", "4 January 2011", "Dougie MacLean", "12 '' x 12 '' attached giant - sized booklet", "1999", "the city of Indianapolis", "the topography and the dominant wind direction", "anembryonic gestation", "Michael Rosen", "to achieve independence from Spain", "103", "Van Halen", "$100", "the team that won the coin - toss", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "At the end of the episode, she is seen smacking a fly on her mirror and removes its corpse", "around 2011", "New Jersey Devils", "ulnar nerve", "November 2016", "19th - century", "0.3 to 1.0 in or 0.76 to 2.54 cm", "the majority coming from Western Australia", "Carol Worthington", "1830", "biological agents", "thanksgiving", "November 28, 1973", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "drive", "Bangalore", "Anthony Hopkins", "Jesus Christ", "1996", "holographic", "spain", "marty mulligan", "Gillian Leigh Anderson", "the theory of direct scattering and inverse scattering", "the 45th Infantry Division", "it should stay that way.", "2009", "an open window that fits neatly around him.", "the Hearth", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6674031824996899}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true], "QA-F1": [0.8571428571428571, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6153846153846154, 1.0, 0.7142857142857143, 0.0, 1.0, 0.5454545454545454, 1.0, 0.0, 0.0, 0.125, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 0.4444444444444445, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-2384", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-3858", "mrqa_searchqa-validation-2541"], "SR": 0.53125, "CSR": 0.5184859154929577, "EFR": 0.9, "Overall": 0.6783846830985916}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "the inner core and growing bud of certain palm trees ( notably the coconut ( Cocos nucifera ), palmito ju\u00e7ara ( Euterpe edulis )", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan ( / \u0261\u0251\u02d0n / ; born David Callcott", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama Action", "located on the table or, more formally, may be kept on a side table", "red", "Junior's struggles to find a path to break free of his seemingly doomed fate on the reservation", "either in front or on top of the brainstem", "1942", "Atreus, Agamemnon's father", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "connected behaviors, rights, obligations, beliefs, and norms as conceptualized by people in a social situation", "United Nations Peacekeeping Operations", "part of the normal flora of the human colon", "A biblical covenant", "Shirley Mae Jones", "Heat transfer by thermal radiation", "Luke 6 : 67 -- 71", "on August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "celebrity alumna Cecil Lockhart", "August 22, 1980", "the optic chiasma", "a large, high - performance luxury coupe sold in very limited numbers", "2016", "part of Virginia State Route 48, which also includes the Virginia portion of the Blue Ridge Parkway", "the Confederacy", "1955", "electron donors", "2", "Montreal Canadiens", "2004 and 2008", "On 1 September 1939", "three", "creating a so called minimum viable product that addresses and solves a problem or need that exists", "Wyatt `` Dusty '' Chandler ( George Strait )", "the last book accepted into the Christian biblical canon, and to the present day some `` Nestorian '' churches such as the Church of the East reject it", "In the 1920s", "ice giants", "on September 19, 1977", "camellia sinensis", "euratom", "mumbai", "Frank Fertitta, Jr.", "\"Coronation Street\"", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "complicated and deeply flawed", "Crandon, Wisconsin,", "The brown hairstreak", "Rocky Mountain spotted fever", "(Brett) Esely", "drug labs, markets and convoys,\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.6253018877762282}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 0.75, 1.0, 1.0, 1.0, 0.9333333333333333, 0.0, 0.4444444444444445, 0.5, 1.0, 0.7692307692307693, 0.75, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 0.07692307692307691, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.5714285714285715, 0.17391304347826084, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-8393", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.46875, "CSR": 0.5177951388888888, "EFR": 1.0, "Overall": 0.6982465277777778}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day Eve", "Afghanistan", "lecithin air", "the Suffragette", "Gamgee", "Christopher Darden", "salty", "a cloudy day", "(Philip) Berrigan", "wheat", "Carole King", "Spain", "The Pro-Jig Clamp Set", "Christo", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "(Tom) Harkin", "the Channel Islands", "Krackel", "Penelope", "Pronouns", "Bonobo", "Harry's Harbor Bizarre(2)", "Veep", "alex", "lullaby", "a rubies", "Pan's Labyrinth", "Barrie", "(John) Irving", "a Demonstrative Pronouns", "The Who", "Europe and Asia", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorders", "the Vietnam war", "Beijing", "(Lee) Oswald", "(George) Custer", "easier than pushing an adult", "the breath", "Orlando", "Alaska", "a puff", "The Mausoleum at Halicarnassus", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew 2:11", "Pentateuch", "Saint Cecilia the Patron Saint of Music", "Germany", "1989", "Suzuki YZF-R6", "nose, cheeks, upper jaw and facial tissue", "Donald Trump and Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5767671130952381}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, true, false, false, false, false, true, true], "QA-F1": [0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.4, 0.0, 0.8750000000000001, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1459", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-15118", "mrqa_searchqa-validation-14147", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-13584", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-6286", "mrqa_triviaqa-validation-4653", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1587"], "SR": 0.4375, "CSR": 0.516695205479452, "EFR": 1.0, "Overall": 0.6980265410958905}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "Happy Days", "Rita Mae Brown", "Bolivia and Paraguay", "Kansas", "a grasshopper", "the executive officer", "Sure", "1876", "brood", "the bystander", "(H Humphrey) Bogart", "Maryland", "a honeybru", "the pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Bruce Rauner", "Goofy", "the Chicago Bears", "Mount Everest", "( Winston) Rodney", "pindar poem", "the Black-winged Teal", "the Tom Thumb", "Prince Edward Island", "the Mad Hatter", "serotonin", "Cincinnati", "the Confederate flag", "the concert grand", "ketchup", "banana", "soccer", "Tom Petty and the Heartbreakers", "Tuscany", "Tunisia", "Rosa Parks", "the inch", "France", "William Henry Harrison", "Corinthian", "carats", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "tipping Point", "scotland", "epeiric (or \"shelf\") sea", "James Harden", "eworldly wave", "Ronald Lyle \" Ron\" Goldman", "mad Men", "\"fusion teams,\"", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.6875, "QA-F1": 0.746875}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-16213", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-11680", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_triviaqa-validation-4662", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410"], "SR": 0.6875, "CSR": 0.5190033783783784, "EFR": 1.0, "Overall": 0.6984881756756758}, {"timecode": 74, "before_eval_results": {"predictions": ["Wholesale", "The Tyger", "\"Thunder Road\"", "The Last Supper", "Baccarat", "a bishop", "Harlem", "(Den) Bosch", "hull", "Drug Rehab & Treatment Center", "a cricket", "India", "Children of Men", "Skagway", "a petition", "Hippolyta", "a species", "John Galt", "spinach", "milk", "an Electric meter", "a toadstool", "World War I", "a student loan", "the Gateway Arch", "Itzhak Perlman", "Wolfgang Puck", "a Dachshund", "the Monitor", "Cyprus", "Milwaukee", "Coffee Syrup", "Kevin Costner", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Gerald R. Ford", "Speed Racer", "John Mellencamp", "Aristotle", "Code Black", "the Eagles", "An American Tail", "a bus tour", "an argyle", "Honda", "a wallaby", "a leather feather", "Mark Twain", "Greg Montgomery", "30 October 1918", "Mel Tillis", "Michael Moriarty", "james christopher Bolam", "pawns", "brazil", "House of Habsburg-Lorraine", "highest commissioned SS rank", "Kansas\u2013Nebraska Act of 1854", "Orbiting Carbon Observatory,", "South Africa", "Tuesday.", "two"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6698660714285715}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12847", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-11529", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3779", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.59375, "CSR": 0.52, "EFR": 1.0, "Overall": 0.6986875}, {"timecode": 75, "before_eval_results": {"predictions": ["the Quraysh", "following the 2017 season", "to unification of China", "1900", "at the origin", "Yuzuru Hanyu", "Michael Crawford", "silk floss", "Hold On", "Gustav Bauer", "July 2017", "Empiricism", "Identification of alternative plans / policies", "underlings", "Greenland", "creation of the office in 1789", "The Song of Songs", "Taron Egerton", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Karan Patel", "September 24, 2012", "Rick Rude", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "American indie pop band Foster the People", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "addition, subtraction, multiplication, and division are represented by the +, -, *, and / keys, respectively", "February 3, 2017", "Kid Creole and the Coconuts", "before the start of the era", "2010", "muscle contraction", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Mahinda Rajapaksa", "1773", "Buddhism", "introverted Sensing ( Si ), Extroverted Thinking ( Te ), introverted Feeling ( Fi ) and Extrovert Intuition ( Ne ) )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "midland", "t.S. eliot", "robert hovind", "Hickam Air Force Base", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "to recoup any of his principal", "Blackbird", "Ellen Pompeo", "September 25, 2017"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6088584592490842}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4370", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-5781", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337"], "SR": 0.5625, "CSR": 0.5205592105263157, "EFR": 1.0, "Overall": 0.6987993421052632}, {"timecode": 76, "before_eval_results": {"predictions": ["works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "Walter Mondale", "a system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1942", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "28", "Theodore Roosevelt", "once every 23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "The Hunger Games : Mockingjay -- Part 2 ( 2015 )", "the President of India", "to signify cunnilingus and the gesture is often off - colour", "28 %", "Elvis Presley", "a Native American nation from the Great Plains whose historic territory, known as Comancheria", "Jack Scanlon", "the eighth episode of Arrow's second season", "Ian McKellen", "head - up", "Doug Pruzan ( season 2 -- 6 ; played by Anne Meara ) Spence's mother", "by October 1986", "Donna Reed", "in organelles, such as mitochondria or chloroplasts", "pathology", "1986", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Bali, Indonesia", "a German World War II super-heavy tank", "limited period of time", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "Pittsburgh Steelers ( 6 -- 2 )", "40 %", "Janie Crawford", "in the west by the east coast of Queensland, thereby including the Great Barrier Reef, in the east by Vanuatu ( formerly the New Hebrides ) and by New Caledonia", "2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "Montreal Canadiens ( 24 )", "around 1872", "Snake River Valley", "cellulose", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Phelan Beale", "one", "Government Accountability Office report", "journalists who were found guilty in Ethiopia of supporting terrorism were sentenced to 11 years in jail Tuesday,", "a suit", "Heroes", "a Book of the Dead", "since 1983."], "metric_results": {"EM": 0.40625, "QA-F1": 0.5637888847263848}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, false], "QA-F1": [0.6666666666666665, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 0.6666666666666666, 1.0, 0.7692307692307692, 0.0, 0.8, 0.3076923076923077, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.30769230769230765, 0.4615384615384615, 0.6666666666666666, 0.0, 1.0, 0.16, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.4, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-6137", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_newsqa-validation-377"], "SR": 0.40625, "CSR": 0.5190746753246753, "EFR": 0.9736842105263158, "Overall": 0.6932392771701983}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus", "zork", "roddy dogger", "miss Havisham", "prussia", "rudyard Kipling", "SpongeBob SquarePants", "Exile", "an enclave which is entirely enclosed by another nation.", "South Dakota", "Brian Close", "cabbage worm", "l Leeds", "Edinburgh", "meter maid", "cricket", "america", "Neptune", "Vimto", "phosmphobia", "alicestershire", "carry On quip", "afro-Asiatic region", "sense of taste", "snare drum", "phogeography", "sesame seed", "track & field", "The Centaurs", "tallest building", "football", "Charlie Chaplin", "Beatrix Potter", "Giglio Island", "dutch", "stanyan Street and Golden Gate Park Panhandle on the north, Baker Street and Buena Vista Park to the east", "Geoffrey Rush", "Harry patch", "eagle", "sight & sound", "inigo Jones", "sonar", "Nelson Mandela", "Today", "confetti", "Utah", "stanley fielding", "dragon", "a supercontinent", "salyut 1", "india", "Andy Allo, Venzella Joy Williams, and Hannah Fairlight as Calamity, Serenity, Charity, and Veracity", "62", "Matthew Gregory Wise", "1861", "Zola", "Limbo", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.5, "QA-F1": 0.5880208333333332}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-4651", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-1976", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7059", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-3484", "mrqa_triviaqa-validation-3613", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.5, "CSR": 0.5188301282051282, "EFR": 1.0, "Overall": 0.6984535256410257}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he believed he was about to be attacked himself.", "1964", "\"tributes appeared on YouTube and CNN's i report.\"", "\"momentous discovery\"", "Al-Aqsa", "Mathews and Dilshan put Sri Lanka back on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "Middle East and North Africa,", "Baghdad", "Barack Obama", "Arnoldo Rueda Medina.", "left his indelible fingerprints on the entertainment industry.", "pizza", "Brian David Mitchell,", "Defense of Marriage", "Jacob,", "Ronaldinho", "the Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "\"brain hacking\"", "1957,", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda,", "Manmohan Singh's", "help the convicts find calmness in a prison", "navy", "noticed a UPS delivery box where it shouldn't be.", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "Eleven", "not feel Misty Cummings has told them everything she knows.", "(3 degrees Fahrenheit),", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Barack Obama", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "No. 2", "the return of Myers' remains.", "model", "Val Avery", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "well", "christopher", "Capture of the Five Boroughs", "Jim Diamond", "pornographicstar", "the burning bush", "Custer", "Fannie Merritt Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6129658385093167}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.08695652173913043, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2679", "mrqa_newsqa-validation-1390", "mrqa_triviaqa-validation-744", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-7153"], "SR": 0.53125, "CSR": 0.5189873417721519, "EFR": 1.0, "Overall": 0.6984849683544304}, {"timecode": 79, "before_eval_results": {"predictions": ["Togus", "Ulysses S. Grant", "Yangtze River", "Jacob", "Anne", "The New York Times", "Scotland", "Oklahoma", "the communist revolution", "the Nuclear Age", "Humphry Davy", "seoul", "1/2 hours", "smallpox", "a salt lake", "the fairway", "Hill Street Blues", "sprained ankle", "Mao Zedong", "Harriet the Spy", "Mickey Mouse", "Xerox", "blitz", "Jamaica", "gossip", "exothermic reaction", "Willy Wonka and the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "tax law enforcement", "clothes off her", "John Donne", "fruits or vegetables", "Bollywood", "Celine Dion", "Take Me Out to the Ballgame", "parapet", "Joe Lieberman", "a dictionary", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal Virgins", "The Lord of the Rings: The Return of the King", "Fidel", "H CO", "in a thousand years", "W. Edwards Deming", "clara wieck", "darthur Trendle", "lewis", "Ricky Marco", "edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "John Demjanjuk,", "1,776"], "metric_results": {"EM": 0.5, "QA-F1": 0.6557088744588744}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.7272727272727272, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13653", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-3519", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-7308", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118", "mrqa_naturalquestions-validation-3561"], "SR": 0.5, "CSR": 0.51875, "EFR": 0.96875, "Overall": 0.6921875}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "Tim Whelan", "Waimea", "the Virgin label", "The Boeing EA-18G Growler", "George Harrison", "the white-tailed eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "sacred mountains", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "The More", "England, Scotland, and Ireland", "the Workers' Party", "those who work with animals", "his exploration and settlement of what is now Kentucky", "six-time", "Mauthausen-Gusen", "9 February 1983", "Distillery", "Ted Nugent", "New York", "Captain of the Yeomen of the Guard", "The Princess and the Frog", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "Boulder High School", "Dutch", "November of that year", "Boston", "Kaley Cuoco", "Brendan O'Brien", "Delphine Software International", "Sullivan University", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member", "September 15, 2012", "Queen Elizabeth II", "vienna", "Malaysia", "Akio Toyoda", "Iran's nuclear program.", "alternative-energy vehicles", "\"jazz's\"", "dike", "the judge", "M&M's"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6479910714285715}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.19999999999999998, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-237", "mrqa_hotpotqa-validation-5694", "mrqa_hotpotqa-validation-3078", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-1809", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-5371", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999"], "SR": 0.515625, "CSR": 0.5187114197530864, "EFR": 1.0, "Overall": 0.6984297839506173}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "Derek and the Dominos", "1853", "The Allies of World War I, or Entente Powers", "Acid house", "Esteban Ocon", "Sophie Lara Winkleman", "Perfume: The Story of a Murderer", "Barbara Feldon", "Razor Ramon", "Birmingham, Alabama", "half", "Adam Karpel", "rock and roll", "1991", "Windermere, Cumbria, England", "Sir Frank P. Lowy", "Hermione Baddeley", "Greater Manchester's Metrolink light rail system", "Australia", "1698", "Tulsa, Oklahoma", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "McLaren-Honda", "Alexandre Dumas, p\u00e8re, and Paul Meurice", "The Books", "The Washington Post", "Annales de chimie et de physique", "Nairobi, Kenya", "The English Electric Canberra", "1864", "Washington, D.C.", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoons", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow", "Cliff Thorburn", "Kim Clijsters", "Mombasa, Kenya,", "Zulfikar Ali Bhutto,", "basic", "New York City Ballet", "voltage", "Willa Cather"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5863495879120879}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-555", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-232", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-3696", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_triviaqa-validation-873", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.46875, "CSR": 0.5181021341463414, "EFR": 1.0, "Overall": 0.6983079268292683}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Helen Mirren", "Algernod Lanier Washington", "Conservative Party", "Emmy and four", "October 29, 1895", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2007", "Norwegian", "The Late Late Show", "The Ryukyuan people", "Commanding General", "\"50 best cities to live in.\"", "Mike\" Mills", "Parlophone", "January 15, 2016", "Vilniaus oro uostas", "George Clooney, Thekla Reuten", "\"The Worm\"", "Herman's Hermits", "Ustad Vilayat Khan", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Tom Rob Smith", "novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "Great Smoky Mountains National Park", "La Scala, Milan", "every aspect of public and private life", "Gary Ross", "The Hanford Site", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "born 2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelial tissues", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "ringo", "1882", "off the coast of Dubai", "Sunday evening", "not doing more since taking office.", "the AT bus", "polio", "the treble clef", "bond hearing Friday,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7338541666666667}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4717", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-2244", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-7459", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732", "mrqa_newsqa-validation-1245"], "SR": 0.65625, "CSR": 0.5197665662650602, "EFR": 1.0, "Overall": 0.6986408132530121}, {"timecode": 83, "before_eval_results": {"predictions": ["Brookline, Massachusetts", "Metacomet", "Chicago", "Leon Trotsky", "a loaf", "a family tree", "The New York Times", "(Martin) Van Buren", "Ugly Betty", "Winnie the Pooh", "Charles Gounod", "Alexander Graham Bell", "(Vijay) Singh", "clouds", "a modem", "China", "the Boston Red Sox", "Jon Stewart", "Hitler", "Man", "Jane's Electro-Optic Systems", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "africa", "the banjo", "Ulysses S. Grant", "Belle Watling", "Mozart", "American alternative rock band", "Nellie Bly", "Lord Byron", "meningitis", "(Douglas) MacArthur", "3M", "The Rolling Stones", "Edie Falco", "The U.S.A.", "Oneonta College", "the 1936 Summer", "the CN Tower", "Siam", "inheritance", "Maryland", "the cardinal", "Japan", "cattle", "New Brunswick", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "Cliff", "member of the Hui minority", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul Mueller", "horseback in 1959.", "Ali Bongo", "the United States", "in mid November"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6370163690476189}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, false, false, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-4619", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-16652", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-4122", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3419", "mrqa_naturalquestions-validation-8884"], "SR": 0.515625, "CSR": 0.5197172619047619, "EFR": 1.0, "Overall": 0.6986309523809524}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "J. M. Barrie", "Jabez Stone", "Stony Creek Granite", "olives", "pemmican", "Chloe Lattanzi", "Oahu", "Joseph Smith", "the phylum Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "poblano chiles", "Thomas Jefferson", "the legislature", "soy miso", "Old School", "the Distant Early Warning Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "the Australian Entomologist", "Robert Bruce", "zirconium", "oxygen", "gargantuan", "Elke Sommer", "an unguis", "Robin Williams", "Philadelphia", "Ivory soap", "Giuseppe Garibaldi", "The Five People You Meet in Heaven", "the anglerfish", "the Jaguar S-Type R", "Jefferson Family Cemetery", "Mahatma Gandhi", "Brazil", "Jim Thorpe", "9-to-5", "Jack Crabb", "Lear", "Kittinger", "the Bicentennial Symphony", "the Haunted Mansion", "Rembrandt", "Gilligan\\'s Island", "to take you out tonight", "the Colorado Rep11blican", "Manhattan", "Atticus Finch", "Andy Serkis", "spain", "a horizontal desire", "charlie drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Asashoryu", "over the treatment of Muslims,", "former U.S. secretary of state.", "Newcastle Falcons"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5399305555555556}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.888888888888889, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-16336", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-14016", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-7461", "mrqa_triviaqa-validation-5201", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293"], "SR": 0.453125, "CSR": 0.5189338235294118, "EFR": 1.0, "Overall": 0.6984742647058824}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play's the Thing\"", "\"Green Acres\"", "Wee", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi", "object oriented", "Nova Scotia", "cocoa", "the Solomon Islands", "Absinthe", "Zeus", "marsupials", "quid", "Lincoln", "Anthony Newley", "swimmer\\'s ear", "Henry", "the 2.4 GHz frequency", "Greek", "Jeff Probst", "\"Grease\"", "Nasser", "The Moment of Truth", "Laura", "the constellation of Ethiopia", "Charles Manson", "Jerusalem", "Xerox", "Crystal", "the thyroid", "Venus", "Hurricane Katrina", "pineapple", "Bill & George Clinton", "the Black Sea", "Katharine Hepburn", "pennies", "Young Frankenstein", "Shout", "to form a higher alkane", "language", "Hellenic Polytheism", "south americ's northern coast", "The Shootist", "Sega Saturn", "National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300", "it has", "88", "1981 drowning death,", "\"We would like to make one final pitch to those out there who may have been a victim of robbery at the hands of Philip Markoff,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6533617424242424}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-10836", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-15369", "mrqa_searchqa-validation-12141", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_naturalquestions-validation-3840", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.578125, "CSR": 0.5196220930232558, "EFR": 0.9629629629629629, "Overall": 0.6912045111972438}, {"timecode": 86, "before_eval_results": {"predictions": ["Anthony Caruso as Johnny Rivers", "at a given temperature", "season ten", "October 28, 2007", "seven", "absorbed the superhuman powers and the psyche of Carol Danvers", "the northern terminus of Port Said", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the 9th century", "between the stomach and the large intestine", "Gupta", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the base of the right ventricle", "Lager", "U.S. Bank Stadium in Minneapolis, Minnesota", "Destiny's Child", "statistical", "Earle Hyman", "Husrev Pasha", "Will", "The Osmonds", "The Drew Las Vegas", "enzymes take over", "meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "bh\u0101va", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Hebrew", "cartilage", "SIP ( Session Initiation Protocol )", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "the medial epicondyle of the humerus", "innermost in the eye while the photoreceptive cells lie beyond", "Donna Mills", "Donna", "annette Crosbie", "Bobby Kennedy", "minder", "The leopard", "Patricia Arquette", "University Grants Commission", "Symbionese Liberation Army", "102", "two", "\"Like a Rock\"", "a cat", "King George III", "Norway"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6698635794030531}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 1.0, 0.761904761904762, 0.14285714285714285, 0.0, 1.0, 0.4210526315789474, 1.0, 0.20000000000000004, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-5113", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-9814", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808"], "SR": 0.5625, "CSR": 0.5201149425287357, "EFR": 0.9285714285714286, "Overall": 0.6844247742200329}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "The Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teen Titans Go!", "The Ramna Stacks", "Book of Judges", "torpedo boats", "9 February 1971", "San Francisco, California", "\"Three's Company\"", "9,984", "Diondre Cole", "Marktown, Clayton Mark's planned worker community in Northwest Indiana", "the Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "615 square kilometers or 237 square miles", "timeline of Shakespeare criticism", "balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel Gallagher", "Michael Rispoli", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "the Austro-Hungarian Army", "St. George", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "Nova Planta Decree of Majorca and Ibiza", "Vancouver", "Urijah Faber", "four", "1958", "The Thomas Crown Affair", "Bharat Ratna", "November 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "the person compelled to pay for reformist programs", "the 1920s", "on - and off - premises sales in one form or another on Sundays at some restricted time", "James Hargreaves", "Puff the Magic Dragon", "Hindi", "Samoa", "flooding", "composer", "Thesaurus", "Bath", "Winnipeg", "a greeting"], "metric_results": {"EM": 0.578125, "QA-F1": 0.675607638888889}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.5, 0.8, 1.0, 1.0, 0.0, 0.25, 0.22222222222222224, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-1302", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_searchqa-validation-15272", "mrqa_naturalquestions-validation-9361"], "SR": 0.578125, "CSR": 0.5207741477272727, "EFR": 1.0, "Overall": 0.6988423295454546}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour", "as", "Ameneh Bahrami", "40", "state senators", "2005", "partner Katarina Smirnoff", "Hawaii.", "Haiti", "Brazil's", "she keeps smiling -- despite life's setbacks.", "\"Common Access cards,\"", "Her husband and attorney,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "billboards with an image of the burning World Trade Center", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "Carnival", "Jared Polis", "summer", "southern port city of Karachi,", "forged credit cards and identity theft", "If the people closest to him didn't see any indicators or signs that he was going to go off so drastically... how is some public safety officer supposed to recognize this person?\"", "Ricardo Valles de la Rosa,", "Islamabad", "clogs", "3 p.m. Wednesday", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra", "Nigeria", "201-262-2800.", "South Africa", "probably rivaled Neil Armstrong's first steps on the surface more than 40 years earlier: There's water on the moon.", "Chad", "President Obama", "late Tuesday night,", "to reach car owners who haven't complied fully with recalls.", "Mashhad, Iran.", "Plymouth Rock", "Alina Cho", "Federer", "last week,", "a gym or facing days of bad weather.", "Anthony Chambers", "10", "This will be the second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "axe", "portugal", "June 17, 2007", "England", "Black Elk Speaks", "Bchamel", "Kwanzaa", "toothy", "Javan leopard"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6908591561624651}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.8571428571428571, 1.0, 0.9411764705882353, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.3333333333333333, 0.16666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-2642", "mrqa_triviaqa-validation-6987", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749"], "SR": 0.578125, "CSR": 0.5214185393258427, "EFR": 1.0, "Overall": 0.6989712078651686}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "presiding judge Shemsu Sirgaga", "killing rampage.", "Eintracht Frankfurt", "they did not receive a fair trial.", "federal officers' bodies", "Bill Haas", "Larry Ellison,", "unable to pass significant restrictions on war funding", "development of two courses on the Black Sea coast in Bulgaria.", "Joan Rivers", "endorsed Romney in his bid for the Republican presidential nomination", "Phoenix, Arizona,", "KBR's", "Copts", "Alicia Keys", "two years,", "the body of the aircraft", "United States, Japan, Russia, South Korea and China,", "chairman of the House Budget Committee,", "pattern matching.\"", "\" Teen Patti\"", "almost 9 million", "some U.S. senators", "Turkey's foreign policy,\"", "London and Buenos Aires", "hanged in 1979", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "a bank", "two", "472,478 acres (738 square miles),", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States", "after they ambushed a convoy carrying supplies for NATO forces in southern Afghanistan,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris", "Alicia Keys", "ALS6,", "The EU naval force", "well over 1,000 pounds).", "Iran's Green Movement of protesters", "make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "provides nearly $162 billion in war funding without the restrictions congressional Democrats", "Lindsey Vonn", "three", "the optic chiasm", "Hugo Weaving", "aragonite", "charles", "Olympia", "Bruce R. Cook", "Los Angeles, California", "86,112", "Tweedledee", "a soap opera", "the CPI", "penrhyn castle"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6376969537815127}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8571428571428571, 1.0, 0.23529411764705882, 1.0, 0.7058823529411764, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-213", "mrqa_newsqa-validation-3267", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_hotpotqa-validation-2460", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.484375, "CSR": 0.5210069444444445, "EFR": 1.0, "Overall": 0.6988888888888889}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Pluto", "larynx", "the Surgeon General", "Ebony", "Cook County", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "the Hatter", "the Galatians", "a cow pie", "'Paradise Lost'", "\"Beautiful\"", "the White Sea", "Doctor Dolittle", "Memphis", "Mitch Albom", "the beaver", "earthquakes", "Donovan", "musicals", "The Bionic Woman", "5000", "a tan", "Narnia", "comet Tempel 1", "cedar park", "Kamehameha", "(Elbert) Gary", "the Epitaph", "crowded", "Duke", "Orlans", "\"The Wall\"", "Pulp Fiction", "Hester Prynne", "pajamas", "Dynasty Class", "a bagpipe", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "the Philippines", "Sydney", "the Hudson Bay", "the original timeline is eventually restored", "The long - hair gene", "the Canaries", "Another Day in Paradise", "danish", "Donald Wayne Johnson", "Bob Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "North Korea", "financial gain,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7106770833333333}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-4704", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-15409", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10975", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-4827", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-10583", "mrqa_triviaqa-validation-1702", "mrqa_triviaqa-validation-1688", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072"], "SR": 0.65625, "CSR": 0.5224931318681318, "EFR": 1.0, "Overall": 0.6991861263736264}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff", "keirin", "lightweight", "christopher nolan", "Johann", "highball", "arthur conan doyle", "lady Godiva", "the brain", "six", "Bashir", "dog sport", "The Double", "aluminium", "dan", "Mickey Mouse", "bushel", "the Welcome Stranger", "the recorder", "Oman", "Genesis", "Ladysmith", "calciumornium", "robert germany", "the Arizona Diamondbacks", "george Orwell", "Goldie Myerson", "Marc", "\"al dente,\"", "William Shakespeare", "1960's", "Some Like It Hot", "chardonnay", "morphine", "the National Council for the Unmarried Mother and her Child (and for the widowed or deserted Mother in Need)", "Sarajevo", "king thomas i", "saint thomas \u00e0 Becket", "bullfighting", "leicestershire", "cycling", "the Cimmerian or Scythican Swamps", "bedding", "Switzerland", "shanghai", "duke orsino", "Founder's Day", "the Swordfish", "france", "australia", "Great Britain", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1898", "January 1923", "South Asian Games", "Ramanaidu Daggubati", "four", "1,500", "a group of teenagers.\"", "38 feet", "the Marquis de Lafayette", "turquoise", "the birds of America", "2010"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5784970238095237}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-1651", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-4508", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-2527", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-369", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134", "mrqa_searchqa-validation-836"], "SR": 0.515625, "CSR": 0.5224184782608696, "EFR": 0.9032258064516129, "Overall": 0.6798163569424965}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "1998 NCAA Division I-A football season", "two", "1987", "Rachel Meghan Markle", "2006", "alcoholic drinks", "Seoul, South Korea", "Dutch", "Director of Central Intelligence", "political correctness", "Russell Humphreys", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "November 23, 2011", "more than 40 million", "Mazda", "Jack St. Clair Kilby", "\"Seducing Mr. Perfect\"", "water", "70", "blood pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko Takeshita", "\"Apatosaurus\"", "TD Garden", "the controversial and explicit nature of many of their songs", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"b bamboo man\"", "the 2007 Formula One season", "Kent, Washington", "Pru Goward", "Vince Guaraldi", "\"What's My Line?\"", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Mathew Sacks", "Archduke of Austria", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo language", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "defense against rain rather than sun", "the eurozone", "Jane Seymour", "willie nelson", "1984", "Argentine", "15 percent", "The son of Gabon's former president", "Antietam", "your premium", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6649181547619047}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-2770", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1662", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.5625, "CSR": 0.5228494623655914, "EFR": 1.0, "Overall": 0.6992573924731184}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "Edward R. Murrow", "Liesl", "Stage Stores", "\"Suicide Squad\"", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "the Crab Orchard Mountains", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the IRA's South Armagh Brigade", "Tel Aviv", "Chevy", "the nature of human sexual response", "Overijssel, Netherlands", "great-grandfather", "PEN America: A Journal for Writers and readers", "Love Letter", "2013", "Jericho Union Free School District", "January 15, 1975", "John R. Dilworth", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Scottish novelist and poet", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "the district of Sierre", "Buffalo", "Gatwick Airport", "George Martin", "Chelsea", "Adam Dawes", "Enkare Nairobi", "Rockland, Maine", "2009", "the Vietnam War", "Toto", "9 February 2018", "Cheap trick", "Kevin Spacey, Benicio Del Toro, Kevin Pollak, and Stephen Baldwin", "funchal", "British", "the Champions Lague final.", "it would", "a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7271825396825397}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4444444444444445, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-5586", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-2849", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_searchqa-validation-16694"], "SR": 0.640625, "CSR": 0.5241023936170213, "EFR": 1.0, "Overall": 0.6995079787234043}, {"timecode": 94, "before_eval_results": {"predictions": ["the drummer", "Hitler", "\"Mrs. Miniver\"", "Cowell", "the Eagles", "the neon sign", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "A Young Girl", "Bora Bora", "Cops", "the Jamaican capital", "a geisha", "France", "the Barbary pirates", "the CIA", "yeast", "Blackberry", "the Temptations", "Phonetics", "Neil Young", "Frasier", "the plants", "a balloon", "the court of Cassation", "Chiapas", "the second cat love song", "Afghanistan", "Australia", "a mozzarella", "lice", "the College of Dental Medicine", "pitch", "Pete Rose", "Esther", "South Africa", "Slim", "GoldenEye", "Anthropology", "Dumbo", "Edith Wharton", "Aretha Franklin", "marsupials", "swedish", "The Crow", "Lou Gehrig", "Orson Welles", "the mongoose", "Russell Crowe", "Ecuador", "Koine Greek", "four", "a judicial officer, of a lower or puisne court", "friends", "olibanum", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "the Runaways", "Musschenbroek", "Seoul", "\"I wasn't sure whether I was going to return to 'E! News' this week or after the new year.", "the Klan experienced a huge resurgence. Its membership was skyrocketing, and its political influence was increasing,", "Krankies"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6036858974358974}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.5, 1.0, 0.10256410256410256, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-579", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-13172", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-13645", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-11108", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2512", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.546875, "CSR": 0.5243421052631578, "EFR": 0.9655172413793104, "Overall": 0.6926593693284937}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Sadler", "Dag Hammarskjld", "Latin", "Charles I", "San Francisco", "\"The Secrets of a Fire King\"", "Nereid", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild gooso", "Joseph Haydn", "Willa Cather", "Dow Jones Industrial Average", "Aunt Jemima", "the fowls", "dynasties", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "middle-aged", "B.B. King", "JFK", "Donovan", "plankton", "Candlestick Park", "a carpenter", "just compensation", "Vodka", "pickled", "Adam", "martyrs", "Celia Humphrey", "woozy", "thunder", "Ham", "calamine", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norman's half - brother", "1 October 1939", "Hong Taiji", "order of the Friars of Wycombe", "little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty-eighth", "Newark, New Jersey", "more than 4,000", "Teresa Hairston", "india"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6398809523809523}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11613", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-12050", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278", "mrqa_triviaqa-validation-833"], "SR": 0.609375, "CSR": 0.5252278645833333, "EFR": 0.92, "Overall": 0.6837330729166667}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "\"Ozymandias\"", "Unbreakable", "Holy Week", "Tijuana", "a Wizard", "a kilobytes", "Planned Parenthood", "Jamie Lee Curtis", "King of the Hill", "Abduction", "Alexander Graham Bell", "the north-east", "a baffle plate", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "giant", "Medusa", "zoology", "Lucia di Lammermoor", "a map", "cricket", "Stephen Hawking", "St. Francis of Assisi", "the lumens", "The Scarlet Letter", "2016", "a rehab facility", "pastries", "The Hundred Years' War", "the Met", "milk and honey", "3", "Sternum", "The Beatles", "Brooklyn", "starch", "King Kong", "Cubism", "Umbria", "Cottage cheese", "(Oscar) Escher", "Oahu", "the ureter", "F. Scott Fitzgerald", "aria", "Sigourney Weaver", "Marquette University", "the monk", "Fall 1998", "poorly fitting dentures", "Bart Howard", "france", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7208333333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-12798", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_naturalquestions-validation-2666", "mrqa_triviaqa-validation-3952", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.65625, "CSR": 0.5265786082474226, "EFR": 0.9545454545454546, "Overall": 0.6909123125585754}, {"timecode": 97, "before_eval_results": {"predictions": ["4", "gold rings", "Gaston Leroux", "Concorde", "gold", "eec", "Canterbury and Lancaster", "vietnam", "florens", "Wanderers", "emilia fox", "Amnesty International", "mzawa", "Shaft", "gallon", "Ramadan", "bizet", "count Basie Orchestra", "Pegida", "osmium", "victoria strong", "edward hopper", "Einstein", "Faversham", "Justin Trudeau", "kevin kline", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "baltimore", "Christian wulff", "light brown", "usk", "spider", "Malcolm Turnbull", "Daily Herald", "nairobi", "alonzo Church", "tendon", "heart", "puck", "hula hoops", "ap\u00e9ritif", "Lady Susan", "Rocky Graziano", "cashmere", "Today", "warrington Messenger", "Gene Vincent", "midgard", "an aberrant, ligand - independent, non-regulated growth stimulus", "USS Chesapeake", "Ben Faulks", "an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "the right bank of the Gomti River", "Art of Dying", "John Auer,", "iPods", "Christopher Savoie", "Thessalian Thebes", "Ingenue", "World War I", "Joseph"], "metric_results": {"EM": 0.609375, "QA-F1": 0.625328947368421}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-4806", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-3391", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-2039", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947"], "SR": 0.609375, "CSR": 0.5274234693877551, "EFR": 0.92, "Overall": 0.684172193877551}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "edward", "hippopotamus", "cirrus uncinus", "Procol Harum", "olympics", "armagh", "newquay", "ugandan", "st pancras", "lactic acid", "vienne", "Robinson Crusoe", "told both news and rumours", "my Favorite martian", "bohemian bridge", "fear of snakes", "venezuelan", "Wyatt Earp", "belfast", "one Direction", "The West Wing", "Prince Harry", "1994", "titanium", "leicestershire", "Pegasus", "alaskan", "mark Twain", "brazil", "horseradish", "swimming pools", "eyes", "olympics", "Bowie knife", "darundi", "rat", "Independence Day", "Tinie Tempah", "portugal", "cleric", "a buggy", "beard", "little Dorrit", "oldham", "Sunday Post", "bobby darin", "sharjah", "phil Woolas", "Mansfield Park", "south africa", "Cam Clarke", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican Drug War", "relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi ethnic minority and the Hutu majority", "The Tempest", "Naples", "Solomon", "heavier than a feather"], "metric_results": {"EM": 0.453125, "QA-F1": 0.537251984126984}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 0.5714285714285715, 0.5, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-2636", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2107", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-2492", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-4579", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.453125, "CSR": 0.5266729797979798, "EFR": 0.9428571428571428, "Overall": 0.6885935245310246}, {"timecode": 99, "UKR": 0.759765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.87890625, "KG": 0.50703125, "before_eval_results": {"predictions": ["stoned to death by an angry mob.", "third", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her;", "Red Lines", "Kirchners", "an African-American woman", "Arsene Wenger", "Arnold Drummond", "in the Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "his business dealings", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "Amado Carrillo Leyva", "Dr. Albert Reiter,", "better conditions for inmates, like Amnesty International", "Saruman", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "overthrow the socialist government of Salvador Allende in Chile,", "lump in Henry's nether regions", "late Thursday to form a government of national reconciliation.", "if record flood levels on several rivers.", "\"Raiders of the Lost Ark.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "students at the school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "police patrol car", "al-Moayad", "\"It was a comment that shouldn't have been made and certainly one that he wished he didn't make.\"", "Three thousand", "attack on Christians in Egypt in some time -- but far from the only one.", "cause of the child's death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "about 2,000", "\"I miss your beautiful face and voice,\"", "Cirque du Soleil", "9 percent", "for the rest of the year", "hydrogen", "Kevin Spacey", "foreign investors", "neck", "wrigley", "CBS", "in round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6291255139876464}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.15384615384615383, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.25, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 0.15999999999999998, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2925", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3457", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-3835", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793"], "SR": 0.546875, "CSR": 0.526875, "EFR": 0.9655172413793104, "Overall": 0.7276190732758622}]}