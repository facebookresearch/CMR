{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 3980, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 0.875, "Overall": 0.875}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange Counties", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normans, Viking", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "No.1", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8708333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-71", "mrqa_naturalquestions-validation-646"], "SR": 0.84375, "CSR": 0.859375, "EFR": 0.7, "Overall": 0.7796875}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "civil disobedience", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "demographics and economic ties", "linear", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial", "It seemed to me I... She was Lo, plain Lo, in the morning, standing four feet ten in one sock", "'Twas the Night Before Christmas", "Eli Murray opposed the advancement of polygamy", "Constitution Day  Founding Father Roger Sherman from the State of Connecticut is a signer to the U.S. Constitution in September 17, 1787", "gold was found by...", "Like 1990, 2007 was a year when these noisy insects famously swarmed the Midwest", "time goes", "Reviews, discussion, Bookclubs, lists", "the division of the...   Department of Chemistry -UPMC - University Pierre and Marie", "abolitionists", "5562"], "metric_results": {"EM": 0.625, "QA-F1": 0.6763663419913419}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.625, "CSR": 0.78125, "EFR": 0.75, "Overall": 0.765625}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "ctenophores", "calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "Mollusca", "Orestes", "Some grow to an immense size", "gerrymandering", "the process by which water changes from a liquid to a gas", "the Travel Detective: How to Get the Best Service and the Best deals from Airlin", "Expanding water vapor makes grains balloon", "Inks, in which colour is imparted by... the replacement of many inorganic pigments such as chrome yellow,... alloy powder (gold bronze) are used in novel silver and gold inks", "the Mycenaean kingdoms, the Hittite Empire", "a biological process that displays an endogenous, entrainable", "the ghost of noted impresario David Belasco is said to no longer haunt it", "the Normandy Landings, a group of U.S. soldiers go behind enemy lines to", "Evelyn \"Billie\" Frechette", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7132711038961039}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.703125, "CSR": 0.76171875, "EFR": 0.8421052631578947, "Overall": 0.8019120065789473}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Latin Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "Torchwood", "capturing prey", "C4", "pasture for cattle", "Ford", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen", "eight", "A computational problem", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "New York City Mayor Michael Bloomberg", "The oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "World War II", "Intel", "Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block is next to his shoulder, with shattered pieces of it around him", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester United", "his son, Isaac, and daughter, Rebecca", "three", "change course", "Tsvangirai", "A Lion Among Men", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a 100% pure and natural sweetener made and stored in honeycombs by the honey bees", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6902922777653381}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.06896551724137931, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.2666666666666667, 1.0, 0.0, 0.5454545454545454, 0.0, 0.8333333333333333, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.640625, "CSR": 0.7375, "EFR": 0.9565217391304348, "Overall": 0.8470108695652174}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "British", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant", "Anjuna beach", "D, E or F", "France's famous Louvre museum", "Leo Frank", "Athens", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "the release of the four men", "putting a personal and human face on the issue... there's nothing more crucial", "Ed McMahon", "This will be the first time any version of the Magna Carta has ever gone up for auction, according to David Redden, vice chairman of Sotheby's.", "No. 2 man (or woman)", "Friday", "Ali Larijani", "policing the world and Africa", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium", "promoting fuel economy and safety while boosted the economy", "heart rate that exceeds the normal resting rate", "heavy breeds", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.609375, "QA-F1": 0.651042676686059}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-754", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.609375, "CSR": 0.7161458333333333, "EFR": 0.92, "Overall": 0.8180729166666667}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "if a person violates a law in order to create a test case as to the constitutionality of a law, and then wins his case, then that act did not constitute civil disobedience.", "University of Chicago Press", "$2 million", "2015", "1762", "unfairly biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight", "In the autumn of 1991, talks were held for the broadcast rights for Premier League for a five-year period, from the 1992 season.", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1.", "nerves", "1700", "wrapped the Reichstag in more than a million square feet", "a double sugar or a disaccharide (di = two)", "Howard Dean III (born November 17, 1948) is an American politician who served as the 79th Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "heart, blood, and blood vessels.", "\"Wild Thing\", he played the ocarina as well", "God took millions of years to make everything.", "Bratislava, this country's capital", "Diana", "slave trade", "pulmonary veins carry oxygenated blood from the lungs into the left atrium", "a scallop that lived during the Pliocene age", "bullseye, or bull's-eye, is the centre of a shooting target,", "Tartarus", "cyclorama - Search-ID.com", "Nancy Reagan", "Bardiya", "LAP", "Count Ferdinand von Zeppelin", "huge", "64", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas!", "Hurley", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5597683260367083}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6773", "mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-8993", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.484375, "CSR": 0.6830357142857143, "EFR": 0.9090909090909091, "Overall": 0.7960633116883117}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "K-9 and Company", "9.1 million", "little", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway/Eisenhower Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "Capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "basketball", "Earth", "tornado", "Rodeo", "hoo-hoo, the barn type", "Barack Obama", "Kenny G", "a small, half size cup used for serving espresso.", "a tutu", "the postal abbreviation of the state whose capital is Annapolis", "Spring Awakening", "klammeraffe", "pheromones", "a god", "Useless facts", "Python", "The Bible: In the Beginning", "Ada Monroe", "Faith Hill", "Ben Affleck", "a hurricane is a large-scale, low-pressure weather system.", "the letter V", "geologic time", "a jazz saxophonist and composer", "Sweden", "Vietnam", "nihonium, moscovium, tennessine, and oganesson", "Alexandria", "Perfume: The Story of a Murderer", "the New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5963776629072681}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.3157894736842105, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-3893", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-15487", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_naturalquestions-validation-10073", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.53125, "CSR": 0.6640625, "EFR": 0.8333333333333334, "Overall": 0.7486979166666667}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu", "silent", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Anti-Atlas", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "plums", "the Messiah", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "the tonka bean", "the divisor", "Hypnos", "Texas", "International House of Pancakes", "an eagles", "the Bill of Rights", "the SAT", "Rio de Janeiro", "Walden", "the Santa Ana winds", "Harry Whittington", "the Earth rotates", "Gustave Eiffel", "Jack B Yeats", "the Central Intelligence Agency", "D'Artagnan", "a green substance", "1985", "apples, blueberries, bananas", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5240831500172533}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-13837", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-14640", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.453125, "CSR": 0.640625, "EFR": 0.9428571428571428, "Overall": 0.7917410714285714}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "Second World War", "integer factorization problem", "Scottish independence", "exploration", "prep schools", "soft power", "strong Islamist", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Alexei Kosygin", "Rhea", "the nymphs", "Reginald Dwight", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Washington", "Carmen", "Giglio", "12", "tarn", "972", "buffalo", "Ann Widdecombe", "scalene", "the Old Kent Road", "Tuesday", "sodium pyroborate", "Ab Fab", "Massachusetts", "Workington Town", "California", "the Susquehanna River", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "What Price", "Orvon Grover"], "metric_results": {"EM": 0.625, "QA-F1": 0.6942708333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-5586", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.625, "CSR": 0.6390625, "EFR": 0.625, "Overall": 0.63203125}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "the faecal-oral route (turd to tongue transmission)", "a tree with fragrant spring flowers", "Ken Russell", "Dan Dare", "Sulla", "Smiths", "Mike Tyson", "Morocco", "Passover", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "Puck", "\"beyond violet\"", "passion fruit", "Portugal", "football", "Serena Williams", "63 to 144 inches", "the Titanic", "William Tell", "Christian Dior", "snail", "Mendip Hills", "Wichita", "the Passover", "New Croton Reservoir in Westchester and Putnam counties", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "\"Ni!\"", "Roman Polanski"], "metric_results": {"EM": 0.75, "QA-F1": 0.7614583333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4926", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.75, "CSR": 0.6491477272727273, "EFR": 0.75, "Overall": 0.6995738636363636}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network headquartered in San Jose, CA", "public service", "Guy de Lusignan", "tiger team", "Killer T cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hez-bah-lah", "six", "Whist", "Nile", "Tuscany", "achromatopsia", "aqueous humor", "Pluto", "chromium", "copper", "The Hague", "Victoria", "Ironside", "John le Carr\u00e9", "Nizhny Novgorod", "brown trout", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "Samuel Johnson", "Conrad Murray", "Pavement", "Bennett Cerf", "lettuce Seeds", "hudd", "Ukraine", "Shrek", "Oslo", "horses", "rhododendron", "Bob Fosse", "Franklin D. Roosevelt", "Shanghai", "eile de Becque", "Boat lifts are another type of counter-weighted elevator system approximating an Atwood machine.", "Billy Colman", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception, Rome, Italy", "Poe", "bobby"], "metric_results": {"EM": 0.625, "QA-F1": 0.6959077380952381}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1269", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.625, "CSR": 0.6471354166666667, "EFR": 0.7083333333333334, "Overall": 0.677734375}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units", "AD 14", "orogenic wedges", "explorer, woodsman, and frontiersman", "The Handmaid's Tale", "pygmy chimpanzee", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack Kilby", "Ryan Babel", "A\u1e8bmat-khant Ramzan", "July 16, 1971", "1933", "The Heirs", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Daniel Hale Williams", "England", "Paul W. S. Anderson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and therefore national initiatives have their limitations,", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "Dr. Dre", "Little Miss Muffet", "pre-Columbian times, the American Bison, is difficult to domesticate and was never domesticated by Native Americans"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7377232142857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_naturalquestions-validation-8227"], "SR": 0.703125, "CSR": 0.6514423076923077, "EFR": 0.8421052631578947, "Overall": 0.7467737854251012}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "partial funding", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "Mikhail Aleksandrovich \"Michael\" Chekhov", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Imperial War Museums", "Minnesota's 8th congressional district", "Johns Creek", "Hawaii", "liquidambar styraciflua", "Gilbert du Motier", "Gujarat", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "a few", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Larnelle Harris", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "2015, 2017", "1982", "rod", "Chris Robinson", "gossip Girl", "aerodynamics", "in", "a sky goddess", "Richie Unterberger"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6635069444444444}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7200000000000001, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-4359", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5625, "CSR": 0.6450892857142857, "EFR": 0.9285714285714286, "Overall": 0.7868303571428572}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular", "Inherited wealth", "December 1963", "1970", "religious freedom", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population", "the kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "time and storage", "Vistula River", "100 to 150", "Apple's new iOS5 operating system, meaning its ability to run apps, surf the Web and the like will maintain its unofficial status as the iPhone-without-a-phone", "at the school.", "March 8", "Meehan", "the Catholic League", "well over 1,000 pounds", "he was released Friday and taken to the Australian embassy in Bangkok, where he stayed until leaving for Australia at about midnight", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills -- began falling onto the stern of his ship", "depressed", "a quarter of bread", "Lance Cpl. Maria Lauterbach", "South Korea", "London", "400", "in Lienz on Monday.", "the test results by a chaplain about 1:45 p.m., per jail policy.", "two soldiers and two civilians", "tweener love", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "U.N. agencies", "\"I always kind of admired him, oddly.\"", "boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "Dublin", "Democrat", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "toe-line", "Sevens", "England", "Yemen", "peterikos Theotokopoulos", "giant", "mercury"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5177938988095239}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08333333333333334, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8571428571428571, 0.6, 1.0, 0.6666666666666666, 0.8750000000000001, 0.23999999999999996, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191"], "SR": 0.40625, "CSR": 0.6291666666666667, "EFR": 0.8421052631578947, "Overall": 0.7356359649122807}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "a prime number", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments.", "Camisards", "over $40 million", "Telenet was the first FCC-licensed public data network in the United States", "1,100", "spinat", "Oligocene", "Melodie Rydalch,", "Charles Darwin", "at a Little Rock military recruiting center", "March 24", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"We are here to cooperate with anyone and everyone that will help us find the guilty party and return Lisa home safely,\"", "56", "National Football League", "\"The Da Vinci Code\"", "Heshmat Tehran Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Seoul", "resources", "highest ranking former member of Saddam Hussein's regime still at large, salutes the \"People of Palestine\" and calls on them to fight back against Israel in Gaza.", "two Emmys for work on the 'Columbo' series starring Peter Falk.", "\"It's like having one of our own kids in this situation.\"", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing", "President Bush", "a hospital in Amstetten, where staff grew suspicious and called police, who opened an investigation and uncovered the abuse.", "African National Congress Deputy President Kgalema Motlanthe", "lost his job as the supermarket chain he worked for cut staff.", "resigned", "Ralph Cifaretto", "a strict interpretation of the law, which forbids girls from attending school, requires veils for women and beards for men, and bans music and television.", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit on TV shows filmed or produced in the state,", "July 23", "70,000 or so", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "campaign setting", "Beno\u00eet Jacquot", "topaz", "Library of Congress", "The Left Book Club", "holography"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5379761701491166}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16, 1.0, 1.0, 0.25806451612903225, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.07407407407407407, 1.0, 0.0, 1.0, 0.4, 0.6428571428571429, 0.28571428571428575, 0.0, 1.0, 0.20689655172413793, 0.0, 0.09090909090909091, 0.375, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.11764705882352941, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.3, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-397", "mrqa_squad-validation-4835", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.4375, "CSR": 0.6171875, "EFR": 0.7777777777777778, "Overall": 0.6974826388888888}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "housing bubble", "137", "Adam Lambert and Kris Allen", "Brian Smith", "\"Hillbilly Handfishin'\"", "President Robert Mugabe", "voluntary manslaughter", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "30 years ago", "murder", "next year", "the Obama administration has not yet articulated a Sudan policy.", "Christopher Savoie", "Anil Kapoor", "Afghanistan and India", "Kerstin", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire,", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "environmental", "1 million", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday", "women", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs and, this week, all 11 of them hatched", "expressed concerns about the missile defense system. While Poland and the Czech Republic have agreed to host parts of the system, others in Europe share Russian concerns that the defensive shield could be used for offensive aims.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "Fullerton, California,", "World War I", "1950s,", "U.S. troops", "Brazil, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran is the only artist to have 2 singles pass 1 billion streams on Spotify", "20", "Australia", "\"Three Colours\" Trilogy, themed on the French Revolutionary ideals of liberty, equality, and fraternity; it is followed by \"\" and \"\".", "2001", "parishes of Jersey are further divided into vingtaines (or, in St. Ouen, cueillettes),", "Between 1937 & 1942, he successfully defended his heavyweight title 21", "George Blake", "Bogota"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6218798817603965}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.27272727272727276, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.3076923076923077, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.05555555555555555, 0.5, 1.0, 0.0, 0.2857142857142857, 1.0, 0.23529411764705882, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_naturalquestions-validation-6883", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.53125, "CSR": 0.6121323529411764, "EFR": 0.7, "Overall": 0.6560661764705882}, {"timecode": 17, "before_eval_results": {"predictions": ["lower", "a pharmacy practice residency", "questions and answers", "bedchamber (sub noctem intrat in cubiculum suum)", "Captain Francis Fowke, Royal Engineers,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Illinois Reform Commission", "\"Sesame Street's\" Grover,", "St. Louis, Missouri.", "$50", "Afghanistan's restive provinces", "fled Zimbabwe and found his qualifications mean little as a refugee.", "suspected of collaborating with the Colombian government,", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Gary Brooker", "unclear, and that lack of knowledge has led to the use of a variety of treatments, including fiber supplements, probiotics, antidepressants, behavioral-based therapies, psychotherapy, food modification, acupuncture, and laxatives.", "in the north and west of the country,", "forcibly drugging", "introduce legislation Thursday, to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "in a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22", "the UNHCR", "how health care can affect families.", "U.N.", "U.S. Food and Drug Administration", "Dominican Republic", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "that the deadly attack on India's financial capital last month was planned inside Pakistan,", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "more than 20 times", "slapped and beaten with a baseball bat and the butt of a rifle.", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "quarter", "rice", "Halifax"], "metric_results": {"EM": 0.5, "QA-F1": 0.5705188857302828}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3529411764705882, 0.25, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.4, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.5, "CSR": 0.6059027777777778, "EFR": 0.8125, "Overall": 0.7092013888888888}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam movement", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "warned against outside influences in next month's run-off election,", "UK", "\"Gandhi,\"", "Argentina", "Congress", "28", "Frank Ricci,", "on the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "he made one of his strongest statements to date on the sex abuse scandal sweeping the Roman Catholic Church,", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.\"", "political and religious", "$4.5 million", "Afghan lawmakers", "Bahrain", "FBI and Homeland Security said in a joint threat advisory obtained by CNN.", "skull,", "he can play an important role in Afghanistan as a reliable NATO ally.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "workers walked off the job January 28 to protest the hiring of hundreds of foreign workers for a construction project at the Lindsey oil refinery in eastern England.", "Ben Roethlisberger", "Winehouse's personal security guard, Andrew Morris,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "(l-r) Paul McCartney, Yoko Ono Lennon, Olivia Harrison and Ringo Starr", "Amnesty International.", "Obama's race in 2008.", "Brazil", "Saluhallen,", "that AbdulMutallab, accused of trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "Iranian consulate in Peshawar", "Casey Anthony, 22,", "Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "finger", "\"Sunny After afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6675071008183244}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.08695652173913045, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.12903225806451613, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.625, 1.0, 0.1111111111111111, 1.0, 0.0, 0.27586206896551724, 1.0, 1.0, 0.5714285714285715, 0.8, 0.9090909090909091, 0.2702702702702703, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_newsqa-validation-1000", "mrqa_newsqa-validation-2847", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-254"], "SR": 0.53125, "CSR": 0.6019736842105263, "EFR": 0.7333333333333333, "Overall": 0.6676535087719297}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "if he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "that the Bainbridge would be getting backup shortly.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "reports he was diagnosed with skin cancer.", "stand down", "Ashley \"A.J.\" Jewell,", "17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London", "rural California,", "off the front pages for the first time in days.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "The Delta Queen will go out of service if Congress does not grant the ship another exemption from a 1960s federal law,", "the Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CBS, CNN, Fox and The Associated Press.", "America's infrastructure.", "protective shoes", "public-sector labor unions launching a general strike, a union official told CNN.", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "often discard beer bottles on pebbled walkways.", "Sedimentary rock", "3.45 billion years ago ( 2.45 Ga )", "London", "Colorado", "Bangor International Airport", "GZA, \"Grandmasters\"", "Suffragette", "Cobblestone", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6487329510767011}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.5, 0.28571428571428575, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 0.0, 1.0, 0.47619047619047616, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-7700"], "SR": 0.484375, "CSR": 0.59609375, "EFR": 0.7878787878787878, "Overall": 0.6919862689393939}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000 write / erase cycles", "they each supported major regional wars known as proxy wars", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956 ) and four since the advent of the Super Bowl ( Super Bowls XXI ( 1986 ), XXV ( 1990 ), XLII ( 2007 ), and XLVI ( 2011 ) )", "The first message was sent over the ARPANET in 1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria", "Koine Greek : apokalypsis", "October 1941", "peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "mughal garden of rashtrapati bhavan", "Cee - Lo", "after Shawn's kidnapping", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour", "three times", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "for a single particle in a plane two coordinates define its location so it has two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick, Rensselaer County,", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The third pig", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "Hanford Nuclear Site, Washington"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6555509079858336}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.08695652173913045, 0.2222222222222222, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 1.0, 0.0, 1.0, 0.5945945945945945, 0.0, 0.0, 0.0, 0.9696969696969697, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.4, 1.0, 0.8, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.515625, "CSR": 0.5922619047619048, "EFR": 0.8064516129032258, "Overall": 0.6993567588325653}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "bearers", "Washington metropolitan area", "10 logarithm of the molar concentration", "the breast or lower chest of beef or veal", "Sargon II", "Tagalog or English", "around 1600 BC", "By mid-1988,", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford, an African - American woman in her early forties,", "by the early 3rd century", "in positions Arg15 - Ile16", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "her boyfriend Lance", "a yolk sac ( protruding from its lower part )", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Tessa Virtue and Scott Moir", "Sophocles", "Tim Allen", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "Rear-Admiral of the Navy", "Marktown, Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "Pardon of Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.375, "QA-F1": 0.5331907624646595}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 0.3636363636363636, 0.28571428571428575, 0.16666666666666666, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.7692307692307693, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.7777777777777778, 1.0, 0.0, 0.5, 0.6666666666666666, 0.08333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_hotpotqa-validation-3984"], "SR": 0.375, "CSR": 0.5823863636363636, "EFR": 0.9, "Overall": 0.7411931818181818}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "Coldplay", "an annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the United States Congress", "Zachary John Quinto", "Tanvi Shah", "Manchester - by - the - Sea, Massachusetts", "two", "Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2009", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas as Matt Morgan", "Jodie Foster", "February 27, 2007", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side of the tibia", "Lynda Carter", "erosion", "90 \u00b0 N 0 \u00b0 W", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "King Elizabeth II", "an insect", "Brendan O'Brien", "2005", "Dan Tyminski", "the oldest daughter of an incestuous relationship", "southern port city of Karachi", "at least nine", "Bashar al-Assad", "New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6720692791005292}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.5625, "CSR": 0.5815217391304348, "EFR": 0.8214285714285714, "Overall": 0.7014751552795031}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Emperor", "Geoffrey Zakarian", "Christopher Allen Lloyd ( born October 22, 1938 )", "prenatal development in the central part of each developing bone", "Ali", "Tanvi Shah", "Article 1, Section 2, Clause 3", "the Constitution of India came into effect on 26 January 1950 replacing the Government of India Act ( 1935 ) as the governing document of India", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "heart sounds, often described as a lub and a dub ( or dup ), that occur in sequence with each heartbeat", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Ireland", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "the Colony of Virginia", "March 2016", "1922 to 1991", "Edward Hyde", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "molecules contain either two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "investment bank Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "the forces of Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid   Eleanor Parker as Ruth Hartley", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five books, with a cumulative total of 528 aphoristic sutras, about rules of reason, logic, epistemology and metaphysics.", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers", "Osama bin Laden", "Antarctica", "axon", "enoki"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6103689013130333}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 0.3636363636363636, 1.0, 1.0, 1.0, 0.6451612903225806, 1.0, 0.5714285714285715, 0.07999999999999999, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.1904761904761905, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.46875, "CSR": 0.5768229166666667, "EFR": 0.9117647058823529, "Overall": 0.7442938112745099}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff with Kentucky native Kenny Perry", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "American Airlines", "Radio City Music Hall", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin button\" (2008)", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Eilean Donan", "Fatih Ozmen", "U.S.", "Pacific Place", "campaign organizer on staff for Presidential candidate John Kerry", "Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Operation Watchtower", "Bishop's Stortford", "The Hungry Hustlerz: Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Tennessee", "Yoruba", "Lucky", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "The Stig", "Ryan Harris", "Medellin", "his father", "lawmakers actual production models of vehicles that may cut the nation's reliance on petroleum-based fuels.", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6762152777777777}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.5625, "CSR": 0.5762499999999999, "EFR": 0.8928571428571429, "Overall": 0.7345535714285714}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "in  time which was popular in Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS", "second largest", "Citric acid", "in 1989", "Lola Dee", "The Five", "Walt Disney Feature Animation", "The club will participate in the Premier League, FA Cup, EFL Cup (as holders), UEFA Champions League and UEFA Super Cup.", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Cleveland", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "Tax Reform Act of 1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "mahana", "\"Death, be not\" this \"though some have called thee mighty and dreadful, for thou art not so\"", "green"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7007339015151515}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.640625, "CSR": 0.5787259615384616, "EFR": 0.8260869565217391, "Overall": 0.7024064590301003}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Tom Hiddleston", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "2 May 2015", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cleveland", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Las Vegas", "1919", "Kevin Spacey", "Love Streams", "Eddie \"The Eagle\" Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building (EEOB)", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music and English folk-song", "Pantone Matching System (PMS)", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Ewan McGregor", "1963", "a peplos", "Herald of Free Enterprise", "A Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Japan", "postcards"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6676720848595848}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-1617", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268"], "SR": 0.59375, "CSR": 0.5792824074074074, "EFR": 0.8076923076923077, "Overall": 0.6934873575498576}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "particular skills", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Alistair Grant", "most awarded female act of all-time", "Sumitomo Rubber Industries", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji", "Don Bluth", "1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Jim Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "M1914 machine gun, rechambered for 7.92\u00d757mm Mauser ammunition", "James Brolin", "Prussian army general, adjutant to Frederick William IV of Prussia", "January 2004", "Michael Stipe", "ten", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "glycerol", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "c clef", "nasal septum", "stars"], "metric_results": {"EM": 0.625, "QA-F1": 0.6986273503543241}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.18181818181818182, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.625, "CSR": 0.5809151785714286, "EFR": 0.875, "Overall": 0.7279575892857143}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF) beginning in 1985 to promote advanced research and education networking in the United States", "Herrenhausen Palace, Hanover", "Henry Mancini", "Aiatic", "Gordon Ramsay", "Gorbachev", "Adrian Cronauer", "a rose", "Rameses II (Yul Brynner)", "Anna (Julia Roberts)", "a scythe", "balsam fir (Abies balsamea)", "Paddy Doherty", "a milder disease, which was fatal in less than one percent of cases", "the Hanging Gardens of Babylon", "Libya", "Yeehaw", "an Albumblatt", "Khomeini\u2019s Iran", "Daniel Peggotty", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "a father figure to the other musketeers", "mrs-campbell", "Eric Morley", "hypertension", "the Garrick Club", "Belle", "David Beckham", "Manhattan", "Marc Norman", "The Greatest", "a singer and performer", "in the British charts", "a Scotchman\u2019s bonnet (called a Tam o\u2019Shanter hat)", "tenor saxophonist", "Seattle", "The Cross Foxes Inn", "Cardiff", "Baton Rouge", "a 'Weber', or a 'Zenith", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a small species of foraging mammal", "Greek", "Passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941 \u2013 December 5, 1991", "North America", "Everglades, Florida", "Michael Jackson", "elegant, sexy and international", "drive", "Glengarry Glen Ross", "Sebastian Stark"], "metric_results": {"EM": 0.375, "QA-F1": 0.47687251984126977}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, false, false, true, true, false], "QA-F1": [0.0, 0.5, 0.21428571428571427, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-1670", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-15919"], "SR": 0.375, "CSR": 0.5738146551724138, "EFR": 0.85, "Overall": 0.7119073275862069}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "negotiates treaties with foreign nations", "Emma Watson and Dan Stevens", "between 8.7 % and 9.1", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "status line", "retina", "jimmy johnson", "Triple Entente", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar worth close to 5,770 guaranies", "the original Star Trek television series", "1960", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Donald Sutherland", "Allison Janney", "1995", "Fleetwood Mac", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Illinois", "in the 1970s and'80s", "Hebrew Bible, in the books of Exodus and Deuteronomy", "Earl ( John Doe )", "Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "Marvin Gaye", "Eukarya", "elbow", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island", "Romney", "rock", "julnar", "The Bachelor"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6180149711399712}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-10459", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.5625, "CSR": 0.5734375, "EFR": 0.8928571428571429, "Overall": 0.7331473214285715}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "parabola", "fern", "The Fairly Odd Parents", "Spanish Republic", "taximeter", "coyote", "pobdio ekonomin veikl. PVM", "Harry Reid", "Ray", "axis", "forge", "Wolfgang", "j Javier Bardem", "Flowerbomb", "Blackbird", "Footprints", "Caliban", "LA Kings", "probation and Correctional Alternatives", "Tommy Lee Jones", "Zacchaeus", "The Memory Keeper's daughter", "Daniel Deronda", "hubris", "Yahtzee", "Tony Danza", "markup language", "hives", "74.3", "William S. Hart", "bible", "Pride and Prejudice", "The Secret Family of Jesus", "kosher", "Munich", "Michael Jordan", "candlemas", "Prospero", "zefram Cochrane", "parrots", "dough", "kyushu", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1911", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "adidas", "anti-trust laws"], "metric_results": {"EM": 0.5625, "QA-F1": 0.621875}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4996", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391"], "SR": 0.5625, "CSR": 0.5730846774193548, "EFR": 0.9642857142857143, "Overall": 0.7686851958525345}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "January 21, 2016", "Bloomingdale Firehouse", "elise Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland County", "Slaughterhouse-Five", "Adventures of Huckleberry Finn", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Massapequa, New York", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Isabella Palmieri", "Hathi Jr. - The baby elephant who is the son of Hathi and Winifred and is a good friend of Mowgli", "1935", "serpent", "\"Slow\"", "\"Cruisin'\"", "the Moffat Tunnel", "the anti-trust unit", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6830370698380567}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-99", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.609375, "CSR": 0.57421875, "EFR": 0.84, "Overall": 0.7071093749999999}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\" was the first crewed vehicle to land on the Moon", "jellyfish", "March", "a blank", "Fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "oxygen", "\"the Daily Courant was the first daily newspaper in London.\"", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "Frank Keogh", "the BBC", "Route 66", "Brussels", "Flora MacDonald", "John Poulson", "Orly", "the Treaty on European Union", "Jack Frost", "Saskatchewan (Province)", "Ambroz Bajec-Lapajne", "the Solent", "vomiting", "Basketball Page 30", "Bristol Aeroplane Company", "Spinach", "Tony Meo", "Argo", "Libra", "Surrey", "1971", "the Fosse Way", "In Budapest, a 2.5-mile (4-kilometre) electric subway was opened in 1896, using a tunneling shield developed by J.H. Greathead.", "The Coquimbo Region", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units are a system of measurements commonly used in the United States", "Miller Brewing", "northwestern Italian coast", "Sydney, New South Wales, Australia", "people left without loved ones, without homes, without life's belongings.", "Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver, says.", "Peter Bogdanovich", "a bird", "the Federal Republic of Cyprus"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5496680511173427}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.5454545454545454, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.47058823529411764, 1.0, 0.0, 0.7499999999999999, 0.0, 0.4444444444444445, 0.0975609756097561, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.453125, "CSR": 0.5705492424242424, "EFR": 0.7428571428571429, "Overall": 0.6567031926406927}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "Arctic Ocean", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms, and the garden is the largest private garden in London", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "a long line, called the main line, with baited hooks attached at intervals by means of branch lines called snoods ( or gangions )", "Jesus'birth", "habitat", "irsten Simone Vangsness", "Central Germany ( German : Mitteldeutschland ) is an economic and cultural region in Germany", "Andrew Johnson", "Etienne de Mestre", "Agamemnon, with his brother's assistance, drove out Aegisthus and Thyestes to recover his father's kingdom", "electors", "Julia Ormond", "Sauron", "1961", "Aaron Lewis", "2013", "March 1", "novelization", "red oxide", "Spain disputes the legality of the constitution and claims that it does not change the position of Gibraltar as a colony of the UK with only the UK empowered to discuss Gibraltar matters on the international scene", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "entrance to the 1889 World's Fair", "erosion", "March 2, 2016", "turkey", "1996", "Ray Charles", "marriageable age was set at 16 for females and 18 for males", "Ramones", "The original building was completed in 1800 and was subsequently expanded, particularly with the addition of the massive dome, and expanded chambers for the bicameral legislature, the House of Representatives in the south wing", "Anglo - Norman French waleis", "Frank Theodore", "Kate lives in Los Angeles, Randall and his family are in New Jersey, and Kevin relocates from Los Angeles to New York City", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "German authorities", "Islamabad", "Tunisia", "RAND", "bios & Profiles - Faculty - CUNY"], "metric_results": {"EM": 0.4375, "QA-F1": 0.519215610492788}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.125, 1.0, 1.0, 1.0, 0.18181818181818182, 0.15384615384615385, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3076923076923077, 1.0, 0.0, 0.125, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.06451612903225806, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0689655172413793, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.4375, "CSR": 0.5666360294117647, "EFR": 0.8611111111111112, "Overall": 0.7138735702614379}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "a biblical title of respect applied to prophets and beloved religious leaders", "state legislators of Assam", "a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "constant pressure", "Mind your Ps and Qs", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "lead", "first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "in various submucosal membrane sites", "enterprise application development market", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "ice cap climate ( K\u00f6ppen EF )", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "a hard rock/blues rock band", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday", "this week", "Henry Ford", "Toyota", "vice president of the United States", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.453125, "QA-F1": 0.5942907456031643}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 0.5, 1.0, 1.0, 0.42857142857142855, 0.3333333333333333, 0.9811320754716981, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.3571428571428571, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.2758620689655173, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.453125, "CSR": 0.5633928571428571, "EFR": 0.8285714285714286, "Overall": 0.6959821428571429}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "mild euphoric", "The Mistmantle Chronicles", "Venezuela", "Croatia", "boxing", "Finding Neverland", "Andrea del Sarto", "Arctic Ocean", "in the egg-in-a-bottle experiment, the flame going out causes a vacuum effect, so the egg is sucked in by the differential in this between the inside & outside of the bottle", "obstructions", "Lafayette", "Elijah Muhammad", "equatorial belt of calms", "Village People", "Alexander Pushkin", "Australia", "Munich", "Puebla", "a night shift", "pope", "the Mississippi Alluvial Plain", "The AI Behind Watson", "Pierre-August Renoir", "mister", "operas", "Innsbruck", "Lance Ito", "Microsoft", "petticoat", "Sony", "Norse seafarers", "Atlantic City, New Jersey", "Blackwater USA", "elephants", "American Airlines", "ibex", "Odysseus", "Quizlet", "Kensington Palace", "$60,000", "Netherlands", "Pocahontas", "author of The Lion, the Witch, and the Wardrobe", "John Galt", "fingernails", "Chicago Mercantile Exchange", "Las Vegas", "dance.net", "bounty", "Pablo Casals", "ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "Sen. Debbie Stabenow", "63", "overcharged"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5448660714285714}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-5219", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546"], "SR": 0.453125, "CSR": 0.5603298611111112, "EFR": 0.9428571428571428, "Overall": 0.751593501984127}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "the Earth's axial tilt, which fluctuates within a margin of 2 \u00b0 over a 40,000 - year period, due to tidal forces resulting from the orbit of the Moon", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "the National September 11 Memorial plaza", "Southend Pier", "Santa Monica", "sovereign states", "Will", "31 January 1934", "Filipino", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Kusha", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean and Toby Gad", "never made", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "retinal ganglion cell axons and glial cells", "the 1980s", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "card verification value", "to exercise general oversight, telling him to `` rebuke with all authority '' ( Titus 2 : 15 )", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "As of July 2017, there were 103 national parks encompassing an area of 40,500 km ( 15,600 sq mi ), comprising 1.23 % of India's total surface area", "Vienna", "English", "Australia", "Stalin", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7280630882864542}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.12903225806451613, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.08333333333333334, 0.0, 0.5, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.21052631578947367, 0.1, 0.36363636363636365, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.07999999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-5295", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.640625, "CSR": 0.5625, "EFR": 0.7391304347826086, "Overall": 0.6508152173913043}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "United States", "South Africa", "first among equals", "Shanine", "a cappella", "albinism", "Peterloo", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "equinoxes", "Bonnie and Clyde", "English", "copper", "Dawn French", "David Bowie", "Florentius", "Doris Lessing", "Scooby-Doo", "Swaziland", "the boston House at London Zoo", "Kent", "Humber", "a points based scoring system", "automobile", "Kent", "Rodgers and Hammerstein", "Boy George", "Galileo Galilei", "Gertrud Margarete", "Scotland Yard detective", "Marilyn Manson", "Medellin", "The Tempest", "spark-ignition", "brazilia", "Boulder Dam", "long-term effects", "Saudi Arabia", "Belle de Jour", "Morecambe", "(The Great Leap)", "rain", "white", "Asaph Hall", "France", "Geena Davis", "Kunsky", "the reality of loss", "David Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "different women coping with breast cancer in five vignettes.", "&quot", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5595238095238095}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-3349", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.53125, "CSR": 0.5616776315789473, "EFR": 0.8666666666666667, "Overall": 0.714172149122807}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "liver", "40", "table salt", "wet,keep it away from bright light and no matter how much it begging never feed it after midnight", "Bolivia", "chicago", "Phil Redmond", "Stevie Wonder", "skull", "hound", "hanover", "moon", "the Earl of Strafford", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "quetzalcoatl", "1937 Austin Seven Ruby Open Top Tourer", "Paul Anka", "Carthage", "Bath", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "cymbals", "\u201cSanta Buddies\u201d", "San Diego Opera", "Tory MP Andrew Mitchell", "Ticket Sarasota", "South Africa", "Marie Trepanier", "scrobbesburh", "killer whale", "Ukrainian", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "baron", "lizard", "bridge", "frauds", "sea horse", "even numbers", "\u201cmorally justified\u201d to assassinate Tony Blair, but stressed he was not calling for his death.", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "Traumnovelle", "Anthony Lynn", "piano", "paid tribute to pop legend Michael Jackson,", "the United States", "French Guiana", "AOL", "arms", "Jean Van de Velde"], "metric_results": {"EM": 0.5, "QA-F1": 0.5465584150326797}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.23529411764705882, 0.5, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-1112", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-856", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_triviaqa-validation-3358", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_newsqa-validation-1352", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.5, "CSR": 0.5600961538461539, "EFR": 0.75, "Overall": 0.6550480769230769}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Olivo", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "nebrie hennson", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "James Douglas", "Bulls Eye", "Napoleon I", "bach", "Martin Clunes", "Charles Darwin", "pembrokeshire Coast National Park", "Kevin Macdonald", "hot peppers", "cenozoic", "John Mellencamp", "Isambard Kingdom Brunel", "georgia", "1957", "Devon", "villefranche", "white wine, green peppers and onions", "a miehei", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "Shanghai", "Spain", "grow", "Tuesday", "Guru Nanak", "ch.1, p. 49-50", "Harry Potter and the Half Blood Prince", "phosphorus", "Thomas Horner", "doha, Qatar", "humbert", "cuckoo", "Miss mple", "Ford", "Alice Cooper", "Majorca (Mallorca)", "a blood group", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "\"The Cycle of Life,\"", "forgery and flying without a valid license", "137", "log cabin", "St. Patrick's Day", "defensive backs", "Marshall"], "metric_results": {"EM": 0.4375, "QA-F1": 0.49069940476190477}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.4375, "CSR": 0.55703125, "EFR": 0.8333333333333334, "Overall": 0.6951822916666667}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "Washington", "Thomas De Quincey", "yersinia pestis", "horse", "bison", "Cleopatra", "dove", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor by passing current through it", "the Arabian Gulf", "writer", "jasper", "matricide", "jack Nicholson", "\u201cTonight Is Another Day\u201d or \u201cTote the weary Load\u201d", "linesider", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "indian", "New Hampshire", "James I", "Terry Bates", "the Philippines", "purple", "everyhit", "warblers", "hell Upside Down", "Rome", "10", "Southwest Airlines", "phone", "Jeffery Deaver", "The Comedy of Errors", "charlie jawn [John J] McKenna", "glyn Jones", "President Clinton at the White House on \"20/20,\" Sept. 20, 1996", "crossword clue", "the dogger bank", "radicalization", "Frederic Robinson Ltd", "Humpty Dumpty", "1998", "Tanvi Shah", "EN World web site", "100th anniversary of the first \" Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "neuroethicists", "the Matrix", "curb Your Enthusiasm", "nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.453125, "QA-F1": 0.54140625}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.19999999999999998, 0.5, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.453125, "CSR": 0.5544969512195121, "EFR": 0.8, "Overall": 0.6772484756097561}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "nippon", "golden fleece", "Roddy Doyle", "abacus", "Robin Hood Men in Tights", "aeolus", "Velazquez", "South African", "maracaibo", "Norwegian", "tchaikovsky", "olympian Twist", "Scotland", "pomposity or self-importance", "David Bowie", "Buzz Aldrin", "jane paul sartre", "jane", "jack Johnson", "rust", "jane krakowski", "wales", "tbilisi", "mad Max Beyond Thunderdome", "othello", "a sewed up of a small hole or tear in a piece of material", "Glenn Close", "lacock abbey", "alex b'Stard", "domestic cat", "Anita Brookner", "shomron", "bunned grandmother of the Jewish people", "Black Sea", "bagram", "Susie Dent", "a power outage Sunday", "Vienna", "The Archers", "shylock", "sousa ochs", "chicago", "jimmy boyd", "shakespears", "the Marx Brothers", "pershore", "habsburg monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "from 1993 to 1996", "James Gandolfini", "March 23, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones", "tuba", "the o.K. Corral", "butternut squash", "a Trojan War"], "metric_results": {"EM": 0.53125, "QA-F1": 0.59390664160401}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.53125, "CSR": 0.5539434523809523, "EFR": 0.8666666666666667, "Overall": 0.7103050595238095}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "work rule issues", "Eintracht Frankfurt", "Comoros Islands", "revolution of values", "Jeddah, Saudi Arabia", "40", "chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "Wednesday, at a house adjacent to the park", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group showroom", "Michoacan Family", "64", "Myanmar's military junta", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007 and has been coaching at Independiente.", "E! News", "Washington", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits", "benazir butto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "Cal Ripken Jr.", "a relative's house", "cancer", "acid attack", "Vernon Forrest", "if we can do more is certainly a live discussion for NATO, but at the moment this is a matter for the Afghan government.", "one", "comfort those in mourning", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "we say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well", "a man's lifeless, naked body", "\"release\" civilians", "Dodi Fayed", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has", "there is a decline in population density", "Real Madrid", "emperor Cuauhtemoc", "japan", "Misery", "kenn purdy", "Antonio Lippi", "Thorgan", "River Clyde", "chile", "japan jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5344041097198711}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.2, 0.8000000000000002, 1.0, 0.923076923076923, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.12903225806451613, 1.0, 1.0, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 1.0, 1.0, 0.3636363636363636, 0.0, 0.11764705882352942, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.4375, "CSR": 0.5512354651162791, "EFR": 0.8055555555555556, "Overall": 0.6783955103359174}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.", "1943", "Volvo 850", "Mountain West Conference", "the National Basketball Association", "Western Europe", "political thriller", "Schaeffler AG", "the Championship", "1989 until 1994", "Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs.", "1988", "coaxial", "Northern Lights", "three different covers", "Malayalam", "Regno di Dalmazia", "August 11, 1946", "Vincent Landay", "September 6, 1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Brian A. Miller", "Nicolas Vanier", "1985", "Gal Gadot", "Amy Jessicaup", "Texas Raiders", "in Bremen, Germany in a family of Portuguese descent.", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two occasions", "Trade Mark Registration Act 1875", "blue", "elbow", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.65625, "QA-F1": 0.719124147792626}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-7240", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.65625, "CSR": 0.5536221590909092, "EFR": 0.8181818181818182, "Overall": 0.6859019886363638}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "5.3 million", "sexy Star", "Conservatorio Verdi in Milan", "the 43rd Vice President of the United States from 1981 to 1989", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "January 11, 2016", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer Guitars", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool F.C.", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Sun Tzu", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "6,012,331", "Roscoe Lee Browne", "1972", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Variations", "last summer", "almost 100", "into the Southeast,", "the jeffersons tv show", "a stick to fish the filemot frith for treasures", "by... what differed for women was the status of their authority in the wider community.", "One Direction"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6658044467787114}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-2104", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.546875, "CSR": 0.5534722222222221, "EFR": 0.9655172413793104, "Overall": 0.7594947318007663}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "quod erat demonstrandum", "the Royal Standard of the United Kingdom", "the Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "miniature golf", "CNN Daybreak", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "sea otters", "the 13th letter of the alphabet", "franchise", "rod", "Nixon's", "dressage", "astronomer", "Mickey Mouse", "a bud", "Associate Professor", "a fruit snack", "Medusa", "a spiral", "tabby", "staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "King Priam of Troy", "Vegetarianism", "peace sign", "An Old Man, a Young Man", "English Monarchs These 2", "Rajasthan", "Ben Kingsley", "The New York Times", "NFL", "ar-rs road", "White bread and butter", "Robert's Rules of Order, Strategies for Individual Motions Illustrated", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "Peppercorn class A1", "Queen In-hyun's Man", "Oneida Limited", "Michael Jordan", "Libreville, Gabon", "two tickets to Italy", "The station", "Cahawba"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5807291666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_triviaqa-validation-888"], "SR": 0.515625, "CSR": 0.5526494565217391, "EFR": 0.967741935483871, "Overall": 0.7601956960028051}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\" to which they were entitled institutionally and legally,", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "the playhouse theatre", "Faggots", "a skein, a team, or a wedge", "California Chrome", "Pluto", "Route 66", "Ural and Zagros Mountains", "Sindh", "Astronaut", "Great Victoria Desert", "North Rhine-Westphalia", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "a tweed", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "South Korea", "a pig", "X-Men", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "a hundred", "the Susquehanna River", "Argentina", "Luke", "Frankfurt", "Mouse", "Goldie Hawn", "pulsar", "Belgium", "horses", "sugar", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11 healthy eggs", "Twilight", "the Carrousel du Louvre", "Speed Racer", "Henry Holt", "Queen Elizabeth II", "Sir Walter Scott"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6139880952380952}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, true], "QA-F1": [0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-4025", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788", "mrqa_searchqa-validation-14284"], "SR": 0.546875, "CSR": 0.5525265957446808, "EFR": 0.8275862068965517, "Overall": 0.6900564013206163}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "at Sunset", "Sinclair Lewis", "toms", "The World is Not Enough", "tempera", "Jonathan Demme", "V\u00e1clav Havel", "Dick Van Dyke", "millais", "Tina Turner", "2010", "Portrush", "glasses", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "The Apprentice", "ship\u2019s hull", "Cubism", "sahari desert", "the Advisory Council of Science and Industry", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "Call My Bluff", "A", "Argentina", "Frank McCourt", "salt or sugar", "Debbie McGee", "\"A\" Company", "starch", "soap", "Donna Summer", "a balustrade", "Nottingham", "Poland", "the Welcome Stranger", "Taggart", "February", "Chechnya", "Spot", "a-teamautos", "football", "1,281,900 servicemembers", "CV Raman", "Sun Tzu", "bioelectromagnetics", "Foxborough, Massachusetts", "Speedway World Championship", "beautiful", "Eleven", "Michelle Obama", "kbenhavn", "Communist Manifesto", "sara", "Floxin"], "metric_results": {"EM": 0.5, "QA-F1": 0.5494791666666667}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.16666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990"], "SR": 0.5, "CSR": 0.5514322916666667, "EFR": 0.875, "Overall": 0.7132161458333334}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "Thored, Earl of southern Northumbria", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dziga Vertov", "Strange Interlude", "Julia Compton Moore", "physical", "1986", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration", "Edward James Olmos", "Bury St Edmunds, Suffolk, England", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "mustard gas", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "the Cayenne", "371.6 days", "Piedmont", "Selinsgrove", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "first year at Harry Potter School of Witchcraft and Wizardry", "cake", "Anjana Om Kashyap", "Space Shuttle Challenger", "basil", "Clio Awards", "The Rosie Show", "Current TV", "well over 1,000 pounds", "Julius Caesar", "desert", "the Library of Congress", "thylakoid membranes"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7162878787878788}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.9090909090909091, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1399", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.640625, "CSR": 0.5532525510204082, "EFR": 0.8260869565217391, "Overall": 0.6896697537710736}, {"timecode": 49, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "the utopian Ascona community", "John W. Henry", "James Woods", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "Odisha", "novelty songs, comedy, and strange or unusual recordings dating from the early days of phonograph records to the present.", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "Musicology", "Dragon TV", "Appalachian chain", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million passengers", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem (Evil)", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "Kj\u00f8benhavns Boldklub", "Robert Jenrick", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "`` Everywhere ''", "to mark the birth centenary of Pandit Jawaharlal Nehru", "honda", "Adam Smith", "Republic of Upper Volta", "56", "Nkepile M abuse", "Eintracht Frankfurt", "Lt Presley O'Bannon", "Hephaestus", "Amherst College", "200 registered players"], "metric_results": {"EM": 0.5625, "QA-F1": 0.666607926065163}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 0.8571428571428571, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.21052631578947367, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-1476", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.5625, "CSR": 0.5534375, "EFR": 0.8928571428571429, "Overall": 0.7231473214285715}, {"timecode": 50, "UKR": 0.75390625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.767578125, "KG": 0.49609375, "before_eval_results": {"predictions": ["Sushant Singh Rajput", "\u00c6thelwald Moll", "Fife", "26,000", "Spain, Mexico and France", "1981", "Dragons", "February 26, 1948", "National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "A1 Recordings", "IFFHS World's Best Goalkeeper", "head coach", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern mockingbird", "Picric acid", "Las Vegas", "ESPN's \" SportsCenter\"", "pioneering New Zealand food writer", "fantasy role-playing game", "feats of exploration", "Columbia Records", "Bergen County", "Marlon St\u00f6ckinger", "Feyenoord's Sekou Ciss\u00e9", "the quarter finals", "the superhero Birdman", "Biloxi", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "ethereal darkwave", "VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould III", "The Games are expected to take place between 27 July and 7 August 2021", "1800", "season seven", "glycerol", "umbrella", "sheep", "the most high-profile amalgamation of Indian and western talent yet", "more than 1.2 million people", "84-year-old", "Jacob", "testimony", "Matt Damon", "Mitch Murray"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6426119887057387}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.6666666666666666, 1.0, 0.42857142857142855, 0.0, 0.25, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.3333333333333333, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4698", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770"], "SR": 0.484375, "CSR": 0.5520833333333333, "EFR": 0.8181818181818182, "Overall": 0.6775686553030302}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County, New York", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Tom Rob Smith", "1942", "water", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "General Edward Lawrence Logan International Airport", "Blackpool Football Club", "Marvel Comics", "100 million", "James Gregory", "The Volvo 850", "1978", "July 25 to August 4", "Sela Ann Ward", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle Corporation", "Paris", "John Andr\u00e9", "Three-card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Alexandrovich Morozov", "their evocative music on indigenous flutes, panpipes and drums, as well as stringed instruments introduced since the Spanish conquest", "The Dragon", "two", "Outside", "Traumnovelle", "Chechen Republic", "actress and model", "from 1986 to 2013", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover", "Citgo Petroleum Corporation", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee, is widely considered to be its chief architect", "Presley Smith", "hydrological cycle or the hydrologic cycle", "Mungo Park", "Joe Meek", "Daffy Duck", "in a tenement in the Mumbai suburb of Chembur, with eight people living together in a single room.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "China could continue to claim Tibet as part of its territory.", "Popular Science", "anoirdupois", "Latter-day Saints", "people who are growing more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6627069805194805}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 0.8, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.15999999999999998, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.5, 0.8, 0.09999999999999999, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.4, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-185", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-823", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-5002", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-5108", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.484375, "CSR": 0.55078125, "EFR": 0.9393939393939394, "Overall": 0.7015506628787879}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "\"Physical\"", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "National Society of Daughters of the American Revolution", "Timmy Sanders", "Bandai", "St Augustine's Abbey", "The Washington Post", "Dan O'Bannon", "Dizzy Dean", "UHF channel 44", "North Kesteven", "Spanish Empire among West African descendants", "The Beatles", "\"Menace II Society\"", "September 1901", "March 30, 2025", "Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Easy", "CBS", "Brickyard", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Mary Travers", "Kathleen O'Brien", "a New York-based global asset management firm", "the north bank of the North Esk", "Paris", "melodic hard rock", "Yeeun and Hyerim", "Ecko Unlimited", "Jimmy Ellis", "University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"General Hospital\"", "David Dunn", "William Bradford", "FieldTurf", "My Beautiful Dark Twisted Fantasy", "Benj Pasek and Justin Paul", "a hand injury", "the \u01c3ke e : \u01c0xarra \u01c1ke", "Johnny Cash", "the pulmonary arteries", "\"The Pope? How many divisions does he have?", "France", "Taekwondo", "The Tinkler", "since 1983", "the legitimacy of that race", "the Dukes of Norfolk", "Italy", "chili pepper", "a star"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7082465277777779}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5343", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.609375, "CSR": 0.5518867924528301, "EFR": 0.96, "Overall": 0.7058929834905661}, {"timecode": 53, "before_eval_results": {"predictions": ["a calendar", "Friedrich Nietzsche", "give up the ship", "Carnarvon", "Ireland", "Glaciers", "bdellium", "Marie-Antoinette", "Aunt Bee", "Great Smoky Mountains National Park", "grasshopper", "Ohiopyle", "Nostradamus", "Hodgkin's", "The Flying Dutchman", "brown sugar", "Longfellow", "The Crow", "the plain of Marathon", "John Keats", "(Scott) Peterson", "Central America", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "germany dostoyevsky", "Mike Rowe", "Person One", "daughter", "the French national holiday", "the United Arab Emirates", "Dramamine", "korbat", "the 18th Oktoberfest", "Dred Scott", "josephine de Beauharnais", "President McKinley", "Staten Island", "Transformers", "Crystal Light", "the Civil War", "the declaration of saturated fat", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "an ear", "Indira Gandhi", "top secret U.S. aircraft programs", "the Director of National Intelligence", "The procedure can be performed at any level in the spine ( cervical, thoracic, or lumbar ) and prevents any movement", "2018", "the Rubenshuis Museum", "mink mink", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license", "Michoacan state", "the administration is putting human rights issues to one side,\"", "Carpenter"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6453869047619047}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.07142857142857142, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-9523", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-3486"], "SR": 0.5625, "CSR": 0.5520833333333333, "EFR": 0.8928571428571429, "Overall": 0.6925037202380953}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "IRL", "Gary Havelock", "Anthony Joshua", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "Waffen SS", "Adrian Cronauer", "Copenhagen", "Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "the Canadian Horseshoe Falls", "$SPX", "Mrs Merton", "blues", "Alamo", "Brazil", "aperitivo", "Peter Crouch", "Michael Faraday", "George", "Montmorency", "haddock", "Happy Ever After", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "the Leadbetters", "Woody's horse", "Richard Briers", "Sinclair Lewis", "deer", "Argentina", "Barry White", "Batman's faithful sidekick Robin", "Parchman Farm", "Canada", "Hague Conventions", "Portugal", "silver", "Moby Dick", "`` Fix You ''", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "\"The Worm\"", "\"The Sid Caesar Show.\"", "\"the most dangerous precedent in this country, violating all of our due process rights.\"", "sex scandal", "the Easy Rawlins", "William McKinley", "Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.625, "QA-F1": 0.6899003623188406}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.08695652173913043, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187"], "SR": 0.625, "CSR": 0.553409090909091, "EFR": 0.5833333333333334, "Overall": 0.6308641098484848}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "CNN's Larry King", "a vigilante group whose goal is the eradication of the Zetas", "customers", "the United States", "in Iraq", "the Iranian consulate", "parachuted to the ground", "the twins on narcotics-trafficking charges.", "CNN's Moscow-based Senior International Correspondent Matthew Chance", "heroin labs in neighboring countries and along trafficking routes.", "Bright Automotive", "NASCAR", "Clifford Harris", "Muslim", "a Muslim and a Coptic family", "children as young as eight would cope without their parents for two weeks.", "bollywood", "tens of thousands of new voters became the key to his Iowa win", "urged NATO to take a more active role in countering the spread of the", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament", "Democrats", "Iran", "his son", "publicly criticized his father's parenting skills.", "Ronald Reagan UCLA Medical Center", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Six", "remains unknown,", "$89", "paid tribute to pop legend Michael Jackson,", "naturalist Charles Darwin", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy in Bangkok,", "It is done with the parents' full consent.", "top winds", "rwanda", "2-1", "Bob Johnson", "the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "U.S. President Abraham Lincoln", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Edward Yorke", "Charlie Sheen", "silversmith", "Joseph Ruttenberg", "First Family of Competitive eating", "Valley Falls", "the Provisional Irish Republican Army", "Mount Kosciuszko", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.5, "QA-F1": 0.6168422503324412}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.04878048780487805, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.33333333333333337, 0.2608695652173913, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.9, 0.5714285714285714, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-766", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_triviaqa-validation-1475", "mrqa_hotpotqa-validation-5224", "mrqa_searchqa-validation-1388", "mrqa_searchqa-validation-12033"], "SR": 0.5, "CSR": 0.5524553571428572, "EFR": 0.71875, "Overall": 0.6577566964285715}, {"timecode": 56, "before_eval_results": {"predictions": ["fortress", "peso", "nucleus", "steroids", "0:29", "Stalin", "a aquifer", "ovulation", "pythons", "William Proxmire", "George Orwell", "Takana", "wood", "Coach Carter", "herbivore", "one", "Psycho", "a believer", "Athens", "the most reasonable (or the most sensible) choice to make in the sense of the best possible one", "zoo", "Please Mr. Please", "Mickey Gilley", "Oral Granville Roberts", "staff", "John VIII Palaiologos", "tin", "Ganges", "Captain Nemo", "Dave Brubeck", "The Arsenal", "Soul", "Richmond, Virginia", "Jupiter", "spiders", "Apple", "depression", "the Mausoleum at Halicarnassus", "Act One", "diamonds", "Piano Concerto No. 4 (Rachmaninoff)", "the spectacle", "Vodka", "Ronald Reagan", "Mount Kilimanjaro", "militia", "Delaware", "Graceland", "Russian", "santino", "the id", "US President John F. Kennedy", "Siddharth Arora / Vibhav Roy", "in the pouring rain at a rest stop", "Munich", "the London Railway", "12th", "Margaret Groening", "Benedict of Nursia", "A Boltzmann machine", "Abbey Road", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5046875}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-4802", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-16424", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-15974", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-5209", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-3559"], "SR": 0.453125, "CSR": 0.5507127192982456, "EFR": 0.8857142857142857, "Overall": 0.6908010260025063}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "bamboo", "Merlin", "paper", "Alien", "talk", "the Mariachi", "a bottle", "painful", "Kilimanjaro", "a belief", "Joseph Campbell", "pardon", "the pope", "Calais", "9", "New York", "a tortuga terrestre", "Thomas Paine", "Isaac Newton", "American Wedding", "John Hughes", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "mohs", "Katharine McPhee", "October 7, 1913", "Prince", "Cnut the Great", "spiral", "Dan Eggen", "the yolk", "(Vijay) Singh", "geometric", "Louisiana", "Daniel Boone", "chariots of Fire", "notophthalmus", "Sweden", "pink", "eyes", "Hong Kong", "The Addams Family", "a", "Sanders", "Bait-and-switch", "Winston Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Timothy Dalton", "University of Oxford", "1,467", "Vision of Love", "grabbed a pupil by the throat and threw her against a wall,", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5958333333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11647", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-7362", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-9919", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-9976", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-12380", "mrqa_searchqa-validation-5688", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.546875, "CSR": 0.5506465517241379, "EFR": 0.8620689655172413, "Overall": 0.6860587284482758}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle retained fourth place with a 3-1 victory over Blackburn,", "a full tropical garden", "engaging with the Taliban in Pakistan and Afghanistan.", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs, federal authorities said.", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "the chief executive officer, the one on the very top,", "ancient rituals", "the corpse, whose head was lying behind the meteorologist's shoulder,", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "military trial system", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "Zimbabwe", "new Touch", "Dr. Maria Siemionow,", "International Polo Club Palm Beach in Florida.", "President Bush", "all three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "The Rev. Alberto Cutie", "Nairobi, Kenya", "magazine", "FBI Special Agent Daniel Cain", "Graham", "February 12", "Ensenada, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "strict interpretation of sharia forbids girls from attending school, requires veils for women and beards for men, and bans music and television.", "trading goods and services without exchanging money", "three people", "two more countries, Denmark and China, reported cases of the 2009 H1N1 \"swine flu\" virus on Friday, but they were still to be confirmed by the WHO.", "Some of them told CNN they couldn't afford to pay for cable or satellite TV service.", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Stefanie Scott", "November 2016", "Coventry to Leicester Motorway", "Zaire", "pasta", "DreamWorks Animation", "Debbie Harry", "2004", "a face cord", "Woody Guthrie", "Existentialism", "Efrem Zimbalist Jr."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5711990530604661}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.19999999999999998, 0.0, 0.17391304347826086, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.4444444444444445, 0.17391304347826086, 0.7000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.2222222222222222, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.41666666666666663, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-3948", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-6426", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.484375, "CSR": 0.5495233050847458, "EFR": 0.7878787878787878, "Overall": 0.6709960435927067}, {"timecode": 59, "before_eval_results": {"predictions": ["Pine", "Pakistan", "IndyCar Series", "Vernon Charles Kay", "Everglades", "ten episodes", "Dylan O'Brien", "Betty Cohen", "Scandinavian design", "Hugh Hefner", "Pasek and Paul", "publicly available", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "Denver, Colorado", "Edward M. Kennedy", "a specialized version of the two-seat F/A-18F Super Hornet", "21st Century Fox", "Pennsylvania's state capital, Harrisburg", "Danielle Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "NATO", "the Nawab of Pataudi Jr.", "extreme nationalist, and nativist ideologies, as well as authoritarian tendencies", "AOL Inc.", "World War II", "coca wine", "President Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australia", "youngest TV director ever", "Arthur William Bell III", "Henry J. Kaiser", "Delaware River", "Jean Acker", "Anheuser-Busch InBev", "MG Car Company Limited", "Boston Celtics", "May 2008", "the second in a set of 19 Hungarian Rhapsodies", "24 hours later", "Brian Steele", "35 to 40 hours per week", "Ceefax", "Dieppe Raid", "Herrenhausen Palace, Hanover", "the iconic Hollywood headquarters of Capitol Records,", "228", "The son of Gabon's former president", "stocks", "a vote-recording machine", "Han Solo", "Longo-Ciprelli"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6713304924242425}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.8, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.18181818181818182, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-4375", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-4248", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3372", "mrqa_naturalquestions-validation-215", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6758", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636"], "SR": 0.546875, "CSR": 0.5494791666666667, "EFR": 0.8620689655172413, "Overall": 0.6858252514367816}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "Russia announced it might hold joint naval maneuvers with Venezuela in the Caribbean.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "Joan Rivers", "\"We want to reset our relationship and so we will do it together.'\"", "Alison Sweeney", "the Carrousel du Louvre", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "\"Up\"", "43,000", "269,000", "flooding was so fast that the thing flipped over,\"", "\"Sesame Street's\" Grover, how to make gnocchi with Mario Batali, and the ins and outs of prettying up your home with any number of programs on HGTV.", "Patrick McGoohan,", "ambassadors", "NATO", "man's lifeless, naked body", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "\"perezagruzka,\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell,", "economic and political engagement", "\"Slumdog Millionaire\" (No. 4)", "Noida, located in the outskirts of the capital New Delhi.", "body bags", "Afghanistan", "10 to 15 percent", "The UNHCR recommended against granting asylum", "Annie Duke", "an engineering and construction company", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "illegal immigrants", "a one-of-a-kind navy dress with red lining", "monthly allowance", "too many glass shards left by beer drinkers in the city center,", "legitimacy of that race.", "Nigeria", "Andrew Morris,", "to dock back in Monaco in May next year.", "Drottningtorget", "a senior at Stetson University studying computer science", "the family's blog", "his cousin D\u00e1in", "the Mayor's son", "the American Civil War", "T.S. Eliot", "gold", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "Pacemakers", "Khartoum", "Stand by Me", "French"], "metric_results": {"EM": 0.5, "QA-F1": 0.5737240468182974}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 0.04761904761904762, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.4444444444444445, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-9604", "mrqa_naturalquestions-validation-7957", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409", "mrqa_hotpotqa-validation-2403"], "SR": 0.5, "CSR": 0.5486680327868853, "EFR": 0.65625, "Overall": 0.6444992315573771}, {"timecode": 61, "before_eval_results": {"predictions": ["peanuts, nuts, shellfish, peanuts, tree nuts, wheat and soy", "Space shuttle", "Santaquin City, Utah, home", "It has not intercepted any", "Johnny Carson", "Bob Bogle", "183", "Moscow-based Senior International Correspondent Matthew Chance rides the train from the Arctic north of Murmansk down to the southern climes of Sochi by way of St Petersburg and Moscow,", "in a 4-1 Serie A win at Bologna on Sunday", "Filippo Inzaghi", "Sunni Arab and Sunni tribal leaders", "Tuesday afternoon.", "Henry Ford", "Four Americans", "Ford", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "the soldiers", "the body of the aircraft", "Venus Williams", "the college campus.", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "Bright Automotive,", "Kingdom City", "Europe", "$7.8 million", "Polo because \"it was the sport of kings.", "rig next week's elections in his favor,", "United", "surgical anesthetic propofol", "she was humiliated by last month's incident, in which she was forced to inappropriately remove the piercings", "CNN", "school,", "Hurricane Gustav", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "two", "one-of-a-kind navy dress with red lining by the American-born Lintner,", "the two bodies out of the plant,", "misdemeanor assault charges after a fight at his Texas high school", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Thailand", "Arsene Wenger", "Mike Meehan", "Gulf this week in an attempt to secure more funds from the region.", "former Procol Harum bandmate Gary Brooker", "27", "\"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "housing, business and infrastructure repairs,", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "The Longest Yard", "Lucille Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6382142933927957}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.5714285714285714, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.5555555555555556, 0.2222222222222222, 1.0, 0.8333333333333334, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.8, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-2482", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-1370", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-575", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881"], "SR": 0.515625, "CSR": 0.5481350806451613, "EFR": 0.9032258064516129, "Overall": 0.6937878024193548}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0 draw", "portrait of William Shakespeare", "Charlie Moore", "200", "T.I.", "media", "Friday,", "carving in the middle of our Mountain View, California, campus.", "Arizona", "is the U.N. nuclear watchdog agency's strongest warning yet that Iran could be aiming to build a nuclear bomb.", "\"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "56,", "China, Taiwan, Hong Kong and Mongolia,", "former Boca Juniors teammate and national coach", "Fernando Caceres", "BADBUL", "Nirvana frontman,", "nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Indonesian military transport plane crashed into a residential area in East Java early Wednesday,", "Body Works", "Nuclear Non-Proliferation Treaty in 2003.", "supermodel", "10 below", "1,073", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a visitor's visa and bus ticket to Johannesburg.", "girls around 11 or 12.", "passengers on the Miva Marmara", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee", "Bright Automotive,", "nuclear", "changed the way the world consumed media", "Wilderness Explorer", "165-room", "her daughter and granddaughter attend Oprah Winfrey's school in South Africa considers the talk-show host heaven-sent,", "al Qaeda,", "the media", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "Chinese President Hu Jintao", "United States", "Burj Dubai tower", "speaking out about a cause someone feels passionate about.", "25", "Anil Kapoor.", "President Obama and Britain's Prince Charles", "The series began expanding to more stadiums, first to Twickenham Stadium, London ( 2016 -- 18 )", "a ligand - binding site on a receptor or enzyme", "up to 40.5 metres ( 133 ft )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Robert Arthur Mould", "331 episodes", "2006", "Ruth Bader Ginsburg", "Chandler's", "Seth", "hen"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5350333694083693}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 0.4, 0.0, 1.0, 0.25, 0.0, 1.0, 0.1818181818181818, 0.0, 0.25, 0.0, 1.0, 0.14285714285714288, 0.6, 1.0, 1.0, 0.0, 0.5, 1.0, 0.2666666666666667, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.26666666666666666, 0.2666666666666667, 0.22222222222222224, 0.8, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746", "mrqa_triviaqa-validation-3869"], "SR": 0.453125, "CSR": 0.5466269841269842, "EFR": 0.8285714285714286, "Overall": 0.6785553075396826}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the New York Philharmonic Orchestra in North Korea", "the shootings, handed over the AR-15 and two other rifles and left the cabin.", "dancing against a stripper's pole.", "the German Foreign Ministry,", "60 euros -- $89 -- for shoes that are also worn by dogs who walk on ice in Alaska.", "South African ministers and the deputy president", "militants from Pakistan's lawless tribal regions near the porous 1,500-mile border the two countries share.", "Japan's", "urged NATO to take a more active role in countering the spread of the", "poor.", "striker", "Sixteen", "poems", "Iowa,", "The Mexican government has apologized to the families of two students killed early Friday who officials initially said were drug gang members.", "a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents", "ballots", "leaving the Atlantic, the Panama Canal and is currently in the Pacific. Next stop is Singapore.It will then travel across the Indian Ocean and the Suez Canal before finally returning to the Mediterranean", "the Obama and McCain camps", "The Ministry of Defense", "part of the proceeds from sales go to organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "The minister later apologized, telling CNN his comments had been taken out of context.", "In a superb individual goal from midfielder Nani in the 27th minute as the Portugal international waltzed into the box and drilled in a low shot.", "eight-day", "Alexey Pajitnov,", "three", "Ozzy Osbourne", "\"Dancing With the Stars.\"", "civilians,", "March 3, 2008,", "peanuts, nuts, shellfish and fish tend to be lifelong, she said.", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Buddhism, a practice that originated in China, and meet weekly to focus their minds. Others practice Vipassana, a Buddhist practice founded in India,", "The Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "'overcharged.'\"", "since 1983.", "break through that wall often", "Total Drama Action", "Kimberlin Brown", "A turlough", "1934", "Kirk Douglas", "Radio City Music Hall", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Royal Navy rank of Captain", "Department of Homeland Security", "a French colony", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6752224679967205}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.15384615384615385, 0.0, 1.0, 0.21052631578947367, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.07407407407407408, 0.8750000000000001, 1.0, 0.0, 0.5454545454545454, 1.0, 0.06060606060606061, 1.0, 1.0, 0.2608695652173913, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29411764705882354, 0.5714285714285715, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.33333333333333337, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-2470", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3692", "mrqa_newsqa-validation-1117", "mrqa_naturalquestions-validation-7264", "mrqa_triviaqa-validation-7047", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-8244", "mrqa_naturalquestions-validation-10396"], "SR": 0.546875, "CSR": 0.546630859375, "EFR": 0.8620689655172413, "Overall": 0.6852555899784483}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear", "15-year-old", "July 23.", "Landry", "Korean-American missionary", "Chester Arthur Stiles, 38,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan Athletic", "Adriano", "poems", "Barbara Jones", "A 22-year-old college student in Boston, Massachusetts,", "sniff out cell phones.", "Longo-Ciprelli", "\"The Screening Room\"", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I'm just getting started.\"", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "his entire personal fortune of more than 30 billion won ($30.2 million) to the poor.", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "a free laundry service.", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "school.", "a plaque at the home of his great-grandfather", "death squad killings", "a nuclear weapon", "Kitty Kelley,", "\"The missile defense system is not aimed at Russia,\"", "Dayton, Oregon, in the Willamette Valley to the Pacific coast.", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "And he won it after facing various challenges and turning them to his advantage.", "$3 billion,", "a Facebook photo album full ofphotos of you looking smiley.", "Bobby Jindal", "he acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs up and down the auto supply chain: from dealers to assembly workers and parts markers.", "cannonball", "the 180th meridian in a 360 \u00b0 - system )", "Darlene Cates", "Colette", "crow", "Rhys Williams", "21 July 2015", "11", "January 15, 2016", "piano", "Palestine", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.5, "QA-F1": 0.6487733097791811}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.30769230769230765, 0.888888888888889, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.125, 0.8181818181818181, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.4, 0.18181818181818182, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.5581395348837208, 1.0, 0.7777777777777778, 1.0, 0.10526315789473685, 0.2857142857142857, 1.0, 0.09523809523809522, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-690", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516", "mrqa_searchqa-validation-4278"], "SR": 0.5, "CSR": 0.5459134615384615, "EFR": 0.625, "Overall": 0.6376983173076922}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry Zeiger", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Port-au-Prince", "Saudi Arabia", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "identity documents", "Denver, Colorado.", "Jeffrey Jamaleldine took a bullet to his chin that blew out much of his jaw and nearly killed him while deployed in Iraq last year.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "a strong work ethic", "The meter reader who led authorities last week to remains believed to be those of Caylee Anthony", "could be secretly working on a nuclear weapon", "delivered three machine guns and two silencers to the hip-hop star,", "Karen Floyd", "Republican state senators", "people are going to look at the content.", "April 22.", "Colombian police", "outfit from designer", "five", "Ozzy Osbourne", "Sarah", "Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator, and Nancy Sutley,", "people were throwing Molotov cocktails, rocks and glass.", "eight.", "Fullerton, California,", "Hawaii", "American Bill Haas", "A Lion Among Men.", "the guerrillas detained and \"executed\" eight people on February 6 in the town of Rio Bravo because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Karl Kr\u00f8yer", "Gyanendra,", "to show that a visitor had been to the grave.", "Gadahn, also known as Azzam the American,", "Turkey", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "Texas and Oklahoma to points east,", "\u00a320 million ($41.1 million)", "resources", "a million", "here at her 8th-grade graduation,", "Kerstin and the rest of the family were also able to move into an apartment at a regional clinic nearby.", "-- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "a novelty pet", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5256233831728725}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.5, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5263157894736842, 0.0, 0.2222222222222222, 1.0, 0.11764705882352941, 1.0, 0.2, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.06666666666666667, 1.0, 1.0, 1.0, 0.8, 1.0, 0.631578947368421, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.1111111111111111, 0.7499999999999999, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.421875, "CSR": 0.5440340909090908, "EFR": 0.8378378378378378, "Overall": 0.6798900107493857}, {"timecode": 66, "before_eval_results": {"predictions": ["former French Open champion Moya.", "\"still trying to absorb the impact of this week's stunning events,\"", "Iowa's critical presidential caucuses on January 3.", "Iran's nuclear program.", "green-card warriors", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Booches Billiard Hall,", "Both men were hospitalized and expected to survive,", "Harris won two awards.", "Pfc. Bowe Bergdahl", "many different backgrounds and religions.", "President Bush", "$17,000", "Employee Free Choice act", "assassination of President Mohamed Anwar al-Sadat at the hands of four military officers during an annual parade celebrating the anniversary of Egypt's 1973 war with Israel.", "The judge does not deny bringing the inmates into his office,", "The worst snowstorm to hit Britain in 18 years", "Arnold Drummond", "Madonna", "\"I'm certainly not nearly as good of a speaker as he is.\"", "military commissions", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000 unprotected civilians", "The U.S. Food and Drug Administration Tuesday ordered the makers of certain antibiotics to add a \"black box\" label warning", "managing his time.", "1980,", "Omar bin Laden", "Scotland", "Mugabe's opponents", "inferior, prompting resentment that was passed on through the generations.", "his business dealings for possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "9-week-old", "dental work done, including removal of his diamond-studded teeth.", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "was seven months pregnant at the time of her death,", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "Apple Inc.", "38,", "that the deadly attack on India's financial capital last month was planned inside Pakistan,", "Henrik Stenson", "1995", "a red minivan ran a red light and struck two vehicles at an intersection,", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "\"You can go from rags to riches there. People still believe in that. It is not something that has gotten lost,\"", "not doing more since taking office.", "Television demonstrations", "American Indian allies", "naturalization law for the United States, the Naturalization Act of 1790", "Sigurd the Dragonslayer", "blancmange", "apples", "Manhattan Project", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "the Angel of the Lord ( Numbers 22 : 22 )"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5867894160255809}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 0.7272727272727273, 0.8, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.8571428571428571, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.16, 0.0, 0.2222222222222222, 0.0, 1.0, 0.2105263157894737, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.058823529411764705, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.0, 1.0, 0.5714285714285714, 1.0, 1.0, 0.39999999999999997, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.5, 0.0, 0.6666666666666666, 0.0, 0.2105263157894737, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.4444444444444444]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-4019", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.4375, "CSR": 0.5424440298507462, "EFR": 0.8333333333333334, "Overall": 0.6786710976368159}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "Autobahn", "candlestick", "Thornbridge Jaipur", "tea", "the Ordovician geological period", "Martin Pipe", "Wordsworth", "Ginger Rogers", "apartment buildings", "sulfate decahydrate", "United States Dollar", "peregrines", "Dm", "muscle tissue", "400 meter hurdle", "Derby Stakes", "Easter Parade", "Basketball Page 30", "HMS Amethyst", "lion", "sergeant", "whistling tune, the Colonel Bogey March, became a massive hit.", "Cyprus", "King George VI", "ankle joint", "Greyfriars Bobby", "snowboards", "fleas", "a white robe", "The Big Bopper", "NBA", "Hartley", "Leander", "Arsenal", "Entropy", "Mrs. Peacock", "green", "elia Earhart", "James Hogg", "lacrimal fluid", "Loki Laufeyi", "The Apartment", "Manfred von Richthofen", "Cain,", "1879", "Los Angeles", "Loch Lomond", "an isosceles triangle", "black", "ballet", "Boston Red Sox", "1967 onwards", "absolute zero", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "between South America and Africa.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "bumblebee", "36 months old"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6706507034632034}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-1352", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.546875, "CSR": 0.5425091911764706, "EFR": 0.7241379310344828, "Overall": 0.6568450494421907}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast   Botel", "smen", "Cairo, Illinois", "the Americans", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "Del Norte and Humboldt Counties", "zebra", "257,083", "Puerto Rico", "Harold Godwinson", "Gustav Bauer", "Shawn", "if the concentration of a compound exceeds its solubility", "the Western Bloc ( the United States, its NATO allies and others )", "1603", "the `` round '', the rear leg of the cow", "1957", "360", "electron shells", "into the gastrointestinal tract", "Lori McKenna", "Wisconsin", "Tbilisi", "from the Latin centum", "1799", "Paul", "his last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2014", "Best Picture, Best Director for Fincher, Best Actor for Pitt and Best Supporting Actress for Taraji P. Henson", "Sweden's long - standing policy of neutrality was tested on many occasions during the 1930s", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "spacewar", "12", "4 January 2011", "New Zealand to New Guinea", "Bill Russell", "Seattle, Washington", "the internal auditory canal of the temporal bone", "In 2010", "Buddhism", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units within the National Health Service in England", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "april", "fearful man, all in coarse gray with a great iron on his leg", "huff & puff: Can You Blow Down the Houses of the Three", "Brad Silberling.", "1941", "Nick on Sunset theater", "July in the Philippines", "iCloud service will now be integrated into the iOS 5 operating system. It will work with apps and allow content to be stored", "Thursday", "bonobo", "side", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6690788909790926}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, true], "QA-F1": [0.8571428571428571, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.3636363636363636, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.09999999999999999, 0.5555555555555556, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.3076923076923077, 0.25, 0.6666666666666666, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 0.8571428571428571, 0.5, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-10704", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_newsqa-validation-2251", "mrqa_searchqa-validation-12035"], "SR": 0.515625, "CSR": 0.5421195652173914, "EFR": 0.8709677419354839, "Overall": 0.686133086430575}, {"timecode": 69, "before_eval_results": {"predictions": ["Whitechapel", "Uganda", "definitely, maybe", "Brazil", "constellation Taurus the Bull", "pieces are divided, by convention, into white and black sets.", "Bristol", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "deuteran anomaly", "Cambodia", "Prussian Landsturm", "Russia", "1925 novel", "ooperatiou", "180 degrees", "blue", "Tommy Burns", "Maggie Smith", "Andre Agassi", "hawk", "The Times", "le Carr\u00e9", "bismarck", "Albania", "animals", "Mata Hari", "the different levels of importance of human psychological and physical needs.", "polo", "gulliver", "Rating Organization", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Octavian", "silks", "One Canada Square", "Charlie Brown's", "corvidae", "Snark", "Union of Post Office Workers", "Narita", "Richmondshire", "Walter Mondale", "fresh nuclear fuel", "the plane crash in 1959", "Scotty Grainger Jr.", "The Kingkiller Chronicle series", "3.9 mi", "$1.5 million", "Buddhism", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "Space Shuttle orbiter", "Smithfield", "Aleksandro Solzhenitsyn", "10 Years"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5634943181818182}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.8, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1156", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-9025", "mrqa_searchqa-validation-16464"], "SR": 0.515625, "CSR": 0.5417410714285714, "EFR": 0.7419354838709677, "Overall": 0.6602509360599078}, {"timecode": 70, "before_eval_results": {"predictions": ["leigh Ann Fetter", "three", "high jump", "Stephen Hawking", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grapevines", "teaching evolution in violation of a Tennessee state law.", "Philip Larkin", "Northumbria", "Kent", "hedgehog", "two Australians, driver Jack Brabham", "Peterborough United", "hanover", "algebra precalculus", "york", "yimbo sampras", "ch\u00e2lons", "the Red sea", "cats", "The French Connection", "Eric Blair", "Moaning Myrtle", "lago di Como", "Dubai", "CeeLo Green", "photographer", "Taylor Swift", "the Ionian Sea", "m\u00e0hjeung", "scar", "stars on 45 Medley", "chiletenham & Gloucester", "Jim Bowie knife", "yok on Oct. 10.", "Margaret Thatcher", "Achille Lauro", "Botham", "visual effects", "lemullet", "Ellis Island", "island nation in the South Pacific Ocean", "tripezoid", "Dick Advocaat", "John Huston", "Van Gogh", "Ted Talley", "Martin Van Buren", "Moscow", "2005", "the governor of West Virginia, who is elected to a four - year term at the same time as presidential elections", "Payaya Indians", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "is in critical condition in a Provo, Utah, hospital,", "2010", "Uzbekistan.", "Jerry Rice", "leotard", "Ford", "place"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5747294372294373}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.36363636363636365, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.38095238095238093, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-6644", "mrqa_triviaqa-validation-2921", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-3914", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1928", "mrqa_naturalquestions-validation-4207", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.515625, "CSR": 0.5413732394366197, "EFR": 0.8709677419354839, "Overall": 0.6859838212744207}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "test pilot, and businessman.", "Kim Sung-su", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "L\u00edneas A\u00e9reas", "October 15, 2013", "Neha Sharma", "the Netherlands", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York.", "1853", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Julianne Moore", "11", "tempo", "7 miles", "1942", "Pollywood", "Carver Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "detained indefinitely without trial", "France", "Wordsworth", "Spain", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "freeview"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8378497023809524}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.25, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.78125, "CSR": 0.5447048611111112, "EFR": 0.7142857142857143, "Overall": 0.6553137400793652}, {"timecode": 72, "before_eval_results": {"predictions": ["sign", "showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "100,000", "2004", "the Super Bowl is chosen by the NFL well in advance, usually three to five years before the game", "9th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Tony Orlando", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range", "nearby objects show a larger parallax than farther objects when observed from different positions", "Iraq", "1885", "the final episode of the series", "Wisconsin", "the motion of the continents is linked to seafloor spreading by the theory of plate tectonics", "stems and roots of certain vascular plants", "the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "the Rock", "2010 World Series", "Massachusetts", "Mark Jackson", "burt Hammersmith", "the 180th meridian in a 360 \u00b0 - system )", "need to repent in time", "reduces chemical compounds such as NADH and FADH2 ( for example produced during glycolysis and the citric acid cycle ) to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Kida", "Selena Gomez", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "the federal government", "2005", "England", "the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "when the cell is undergoing the metaphase of cell division", "79 official PGA Tour events", "the League of Communists of Yugoslavia party and a ruling elite", "the cell copies its DNA in preparation for mitosis", "1853", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "Virginia", "Dante Pastula", "Daya Jethalal Gada", "centralized administrative planning", "Gunpei Yokoi", "the Alamodome", "Amy Johnson", "architecture", "Bermuda", "win world titles in four weight classes,", "their unusual behavior, such as the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "parody", "a prostitute", "Ashlee Simpson", "danish"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5470926250016322}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false], "QA-F1": [0.13333333333333333, 0.8095238095238095, 0.07999999999999999, 1.0, 0.11764705882352941, 1.0, 0.3076923076923077, 0.6666666666666666, 0.2857142857142857, 0.6, 0.14285714285714288, 0.0, 0.4, 1.0, 1.0, 0.0, 0.22222222222222224, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.060606060606060615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7692307692307692, 0.2222222222222222, 0.33333333333333337, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-3243", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.4375, "CSR": 0.543236301369863, "EFR": 0.8888888888888888, "Overall": 0.6899406630517504}, {"timecode": 73, "before_eval_results": {"predictions": ["The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Secretary of Homeland Security", "December 14, 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code - breaking intelligence", "Bart Millard", "Jesse Wesley Williams", "Lucius Verus", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "John Smith", "Joanne Wheatley", "`` Everywhere ''", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "india", "Taylor Michel Momsen", "Magnavox Odyssey", "Lightning thief", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the Indian Civil Service", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Vampire", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1878", "to `` help bring creative projects to life ''", "President Lyndon Johnson", "Senator Joseph McCarthy", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Saturn", "wooden clog", "Reggie", "Tampa", "1874", "January 28, 2016", "Jaipur", "18th", "July", "taro", "Match Game", "Dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7157894736842105}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [0.8666666666666666, 0.21052631578947367, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_newsqa-validation-270", "mrqa_searchqa-validation-2100"], "SR": 0.640625, "CSR": 0.5445523648648649, "EFR": 0.8260869565217391, "Overall": 0.6776434892773209}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Bungalow Candies", "center", "submarine", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "classes", "Togo", "blitz", "new wave", "a commune", "a ring", "Thames", "breath", "power play", "fairy tales", "David", "Vogue", "whales", "Jane Addams", "Shakespeare", "Tanzania", "Biosphere 2", "an inch", "death", "Henry Wadsworth", "Fred Thompson", "Geneva", "humility", "white", "California Dreamin", "Diatomaceous", "$8.2 trillion", "pig", "Lake Titicaca", "Existentialism", "ashes", "CASUAL JURIES", "George Freeth", "einstein", "Charles I", "Kevin Costner", "Antichrist", "treble clef", "uranium", "Louisiana", "The Hot Chick", "composting", "August 21", "1990", "four", "Spey", "Popeye", "Denmark", "Trappist beer", "5,656", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County, Wisconsin"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5911458333333333}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-10874", "mrqa_searchqa-validation-14913", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-6235", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-9751", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-15658", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-8909", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-1307"], "SR": 0.546875, "CSR": 0.5445833333333333, "EFR": 0.8620689655172413, "Overall": 0.684846084770115}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "Rosalind Bailey", "the main highway entrance at California State Route 1", "a marketing term for a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "John B. Watson", "hydrogen", "France's colonial presence north of the Caribbean was reduced to the islands of Saint Pierre and Miquelon, confirming Great Britain's position as the dominant colonial power in eastern North America", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "Alexandra Bynes", "the President", "Spanish missionaries", "Gustav Bauer", "art of the book and architecture ; and also including ceramics, metal, glass, and gardens", "the main type of cell found in lymph", "around 2.45 billion years ago ( 2.15 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Yente", "March 31, 2017", "Incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "the lower of the overall continuous assessment score (OCAS ) and overall examination score ( OES )", "summer of 1979", "John Roberts", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "The Yankees", "while studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units", "Rigg", "electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions, and couples this electron transfer with the transfer of protons ( H ions ) across a membrane", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "the underground organization of the Irish Republican Brotherhood", "Orrest Head", "1967", "Yubin", "The record now is 9.58 seconds which was run by Usain Bolt.", "a drug reportedly found after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "the keel", "\"It should be \"perezagruzka\" (the Russian word for reset,)", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Zero Mostel"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7246011181335323}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.14285714285714288, 0.25, 0.9333333333333333, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9859154929577464, 0.888888888888889, 1.0, 0.12903225806451613, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-2810", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-2232", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-3069"], "SR": 0.578125, "CSR": 0.5450246710526316, "EFR": 0.8888888888888888, "Overall": 0.690298336988304}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "drambuie", "repechage", "Lewis and Harris (Scottish Gaelic: Le\u00f2dhas agus na Hearadh) in the Outer Hebrides make up the largest island in Scotland.", "Angela Anderson Lee", "Costa Brava", "Northumberland", "chicken", "Benjamin Barker", "SS United States", "Bleak House", "four", "the Indus Valley", "Selfie", "Jaws", "Charlie Cairoli", "Utrecht", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick Kielty", "8 minutes", "Ross", "Red Crescent", "Simon Rattle", "Margaret Thatcher", "Hooky Street", "Darius Danesh", "Andrew Lloyd Webber", "Bonn", "lieutenant general", "snake", "Coral Sea", "Constantine III", "Madonna", "bogey", "Millerlite beer", "knee", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "Jackie Wilson", "Emilia", "Hawley Harvey Crippen", "fifty-six", "1822\u20131824", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "fight outside of an Atlanta strip club", "seasonal affective disorder", "timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6583047161172162}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.19999999999999998, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-157", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-460", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.59375, "CSR": 0.5456574675324675, "EFR": 0.6923076923076923, "Overall": 0.651108656968032}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "johnnie ray", "master builder", "UFC 50  UFC 50: The War of '04", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "\"O\", \"La Nouba\", \"Myst\u00e8re\", \"Alegr\u00eda\", and \"Quidam\"", "half of the Nobel Prize in Physics", "glee", "Paul Corbould", "his advocacy of young earth creationism and intelligent design.", "2 November 1902", "December 1993", "orisha", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British-American", "Norway", "followed his father into the Military Band of Hanover, before migrating to Great Britain in 1757 at the age of nineteen.", "around 8000 BC", "2011", "Peter Seamus O'Toole", "Australian women's national soccer team", "Leonarda Cianciulli", "a Rugby Sevens competition for the twelve Aviva Premiership clubs that will play the following season", "Talbot School of Theology at Biola University in La Mirada, California", "Eugene O'Neill", "Morita therapy", "the Surtees Racing Organisation team that competed as a constructor in Formula One, Formula 2 and Formula 5000 from 1970 to 1978.", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Mary Berry", "Mel Gibson", "1987", "San Francisco", "Peter Purves", "Vancouver, BC", "onto the college campus.", "nearly $106.5 million", "15-year-old's", "Cleopatra", "Chevron", "mary erythraeum", "tambourine"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6457234002410632}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 0.6, 0.0, 1.0, 1.0, 0.25, 0.5, 1.0, 0.28571428571428575, 0.3636363636363636, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.34782608695652173, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.3076923076923077, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-3101", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-16", "mrqa_newsqa-validation-900", "mrqa_searchqa-validation-4417", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.53125, "CSR": 0.5454727564102564, "EFR": 0.9333333333333333, "Overall": 0.699276842948718}, {"timecode": 78, "before_eval_results": {"predictions": ["Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "August 1991", "Nigel Lythgoe", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta, Georgia", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "1986", "Ali", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "internal reproductive anatomy ( such as the uterus in females )", "May 2017", "mid-1980s", "DNA at the origin", "1956", "between 8.7 % and 9.1 %", "minor key symphonies", "Divyanka Tripathi", "Newfoundland", "Ole Einar Bj\u00f8rndalen", "31 December 1960", "following graduation", "pre-Christian festivals that were celebrated around the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "member states", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "sheepskin", "5,922", "1866", "two", "2006", "eight or nine", "Lake Superior", "Thames", "Liceo", "red"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6654268205453551}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [0.896551724137931, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.5714285714285715, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.59375, "CSR": 0.5460838607594937, "EFR": 0.8076923076923077, "Overall": 0.6742708586903603}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "The Tigers won the BCS National Championship Game,", "1858", "indie and metal", "Edison Koon-hei Chen", "1875", "The The The Onion", "his most brilliant student", "Juilliard School", "The 1st World Outgames", "1812", "Peach", "1935", "The Ducks and Beavers", "Victorian England", "The War of '04", "American", "superhuman abilities after being bitten by radioactive/genetically-altered spiders.", "Alpine climate and landscapes, in particular for skiing and mountaineering", "Baudot code", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "New South Wales", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "\"Shameless\" (2014\u20132015)", "1241 until his death in 1250", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "American", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "Max", "gollum", "Melbourne", "paddington bear", "54-year-old", "American Muslims", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond", "Venezuela", "The Stone Age", "a rally at the State House next week because legislators are starting to come out strongly against Sanford."], "metric_results": {"EM": 0.65625, "QA-F1": 0.7396768162393162}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-4714", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4981", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-4416", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.65625, "CSR": 0.5474609375, "EFR": 0.9090909090909091, "Overall": 0.6948259943181818}, {"timecode": 80, "before_eval_results": {"predictions": ["Tribune", "chardonnay", "'Silent Cal'", "beach volleyball", "Jack & Diane", "hot springs", "the Philosopher's Stone", "Dell", "pro bono", "The New York Times", "epitaphic", "Glenda", "a dragon", "rattus norvegicus", "Department of Chemistry", "The Merry Wives of Windsor", "kowtow", "Mars", "Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "pasta", "a katzenjammer", "Cuisinart", "travertine", "Bob Dole", "Ross Ice Shelf", "director", "China", "coast redwood", "Pinocchio", "the Czech Republic", "the opera house", "bison", "Olympia", "Jodie Foster", "Cleopatra VII", "Mummy", "Buck", "bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1937", "53", "The Lightning thief", "Brazil", "Edinburgh", "gagra Range of the Western Caucasus, in the Gagra district of Abkhazia, a breakaway region of Georgia", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6105654761904762}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-11708", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.546875, "CSR": 0.5474537037037037, "EFR": 0.8275862068965517, "Overall": 0.6785236071200511}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "Indonesia", "The Generation Game", "The Firm", "red hair", "fourteen", "Spain", "Georgia", "Inigo Jones", "sow", "eucharist", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$10", "Liverpool", "the Count Basie Orchestra", "Manhattan", "arch", "Esmeralda's Barn night  club", "Ajman", "Bombay", "Mallard", "Ambroz Bajec-Lapajne", "Apollo", "1963", "Bologna", "bear", "Portrush", "La Toya Jackson", "Timothy", "Addis Ababa", "motorcycle", "kidney", "hanckley, Leicestershire", "salsa", "Mark Twain", "Doctor Who", "Yosemite National Park", "Microsoft", "40", "the First World War", "passion fruit", "H. L. Hunley", "7", "Southampton", "100 years", "Pope Benedict XVI", "Jesse Triplett", "Camping World Stadium in Orlando", "LED illuminated display", "43rd", "Mel Blanc", "Mauthausen-Gusen", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine auto-injector", "\"A Lion Among Men.\"", "Danny Elfman", "Bolivia", "an intercalary year", "Val Kilmer"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5764215225563909}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.10526315789473684, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-2103", "mrqa_searchqa-validation-14665"], "SR": 0.5625, "CSR": 0.5476371951219512, "EFR": 0.7142857142857143, "Overall": 0.655900206881533}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Fairfax County, Virginia", "1,693", "Melville, NY", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "Regional Rural", "Tufts University", "Hammer", "East Kn Boyle", "Isla de Xativa", "her gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Akosua Busia", "5.3 million", "six", "a polypeptide chain", "Brady Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Adelaide, South Australia", "Juan Manuel Mata Garc\u00eda (] ; born 28 April 1988) is a Spanish professional footballer who plays as a midfielder for English club Manchester United and the Spain national team.", "Malayalam", "Pittsburgh Steelers", "antelope", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "Durban International Convention Centre (ICC Arena)", "Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association (NBA)", "Indian", "the Corps of Discovery", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "illnesses", "Thomas Joseph", "the bank's own funds", "31 March 1909", "Joan Baez", "Celsius", "pertussis", "Johannesburg", "for admitting they learned of the death from TV news coverage,", "Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "Richard Nixon", "90", "Edward VIII"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6978933191169444}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.08695652173913043, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4368", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-6094", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.59375, "CSR": 0.5481927710843373, "EFR": 0.8846153846153846, "Overall": 0.6900772561399444}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys: Confessions of a Bad Girl Who makes Good", "Mantle & Maris", "the Titanic", "chemistry", "Bill Clinton", "Graceland Mansion", "Cambodia", "a elevator", "Edward Murdstone", "Arnold Schwarzenegger", "a nonsense", "W", "a goat", "\"Gump,\"", "the union", "Dracula", "the Horn of Africa", "a wind instrument", "Mrs. Miniver", "the chief monk of Tibetan Buddhism", "Italy", "a keynote", "sheep", "Casey Jones", "Coward", "Hope", "navy", "Dresden", "flippant", "Arkansas", "Marcel Duchamp", "a sloop", "toilet paper", "sesame seeds", "Iceland", "a nocturnal mammal", "the Monty Hall problem", "bees", "Janet Wood Reno", "Mark Twain", "Gianlorenzo Bernini", "Essen", "Appomattox", "Thailand", "Lazarus", "a DELICIous DISH", "Pamela Anderson", "Theodor Seuss Geisel Award", "Whitehorse", "Scott McClellan", "Edd Kimber", "six", "Phoebe ( MacKenzie Mauzy ) were born onscreen as the daughters of supercouple Ridge Forrester ( Ronn Moss, later Thorsten Kaye ) and Taylor Hayes ( Hunter Tylo )", "two twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester Ben \"Benny\" Binion", "India", "1959", "two remaining crew members", "her abusive husband"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6784620098039216}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.5882352941176471, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.16666666666666669, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7445", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-1463", "mrqa_searchqa-validation-7313", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-7801", "mrqa_searchqa-validation-15322", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-9734", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_triviaqa-validation-7594", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-1331"], "SR": 0.5625, "CSR": 0.5483630952380952, "EFR": 0.8214285714285714, "Overall": 0.6774739583333333}, {"timecode": 84, "before_eval_results": {"predictions": ["Saint Anthony of Assisi", "roof", "Cuisinart", "glands", "the Boston Massacre", "Truthful or creditable", "Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado", "Diamond", "Picasso", "the Custis-Lee Mansion", "Pope John Paul II", "hood", "Herakles", "South Dakota", "natural selection", "Secretary of the Interior", "Cyrus the Younger", "Humpty Dumpty", "Schembechler", "Gucci", "Vermont", "chimp", "a desktop extender", "The Man in the Iron Mask", "New Zealand", "fashion model", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Dr. Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the flag", "herb", "the stiletto", "cheese", "Kentucky", "Tahiti", "Titanic", "a physician", "Fisherman's ring", "bat", "the forex market", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "Rome", "a sphere", "Disney California Adventure", "Lochaber, Highland, Scotland", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe and found his qualifications mean little as a refugee.", "Baku"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6711023351648351}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, false], "QA-F1": [0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.9743589743589743, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-7797", "mrqa_searchqa-validation-13797", "mrqa_searchqa-validation-1686", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-2558", "mrqa_newsqa-validation-1793", "mrqa_newsqa-validation-2653", "mrqa_triviaqa-validation-5654"], "SR": 0.546875, "CSR": 0.5483455882352941, "EFR": 0.9310344827586207, "Overall": 0.6993916391987829}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "Old Lady", "Cochise", "Samuel", "Margaret Mitchell", "The Big Red One", "a liqueurs", "endodontist", "a microcomputer", "South Dakota", "Hercule Poirot", "Frasier Crane", "George B. McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "John Gotti", "I.M. Pei", "The Name of the Rose", "the Federal Convention of 1787", "Norway", "Lewis", "\"Where there is hatred, let me sow love... where there is hopeless, hope\"", "Steve McQueen", "Firebird", "Sweet Home Alabama", "Vietnam War", "Petroleum", "Mike Huckabee", "a Bill of Rights", "Peter Sellers", "St Mark", "Jon Stewart", "Howard Dean", "Pogo", "Help Myself", "Manitoba", "Madonna", "turban", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Churchill", "Torvill and Dean", "a will", "cogito", "the Bulgarian 2nd Army", "prophets", "1987", "Toy Story", "Harriet Tubman", "Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Lucy,", "in the city of San Pedro Garza Garcia in Nuevo Leon state, along Mexico's border with the United States.", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6601525297619047}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.31999999999999995, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-2188", "mrqa_searchqa-validation-14158", "mrqa_searchqa-validation-16360", "mrqa_naturalquestions-validation-2819", "mrqa_triviaqa-validation-1386", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.546875, "CSR": 0.548328488372093, "EFR": 0.8620689655172413, "Overall": 0.6855951157778668}, {"timecode": 86, "before_eval_results": {"predictions": ["a cob", "Barbara Walters", "the Bosphorus and the Ural Mountains", "hoover", "Frost", "Cheetah Rivera", "coffee", "a leopard", "Knott's Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Aries", "Michel Debr", "an electrolyte", "Bernini", "Augustus", "Pablo Escobar", "Abraham Lincoln", "Anne Boleyn", "modify", "Eyelids", "Bank of America", "copper", "push", "Kiss Me, Kate", "Errol Flynn", "plutonium", "bi", "paste", "Amistad", "a 2000 American sports drama film directed by Robert Redford, and stars Will Smith, Matt Damon and Charlize Theron.", "The Simpsons", "Ladies Pro Tour", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "an Achilles' heel", "classic red", "Sweden", "a member of the musical Partridge family", "Jammu & Kashmir", "the Seal", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Clark", "lima beans", "Will & Grace", "the Octopus", "De Wayne Warren", "2017", "Venezuela", "Conway Twitty", "golf", "Dialogues des Carm\u00e9lites", "England", "35,124", "between the ages of 14 to 17.", "software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6867187499999999}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-3046", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-15956", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_naturalquestions-validation-6903", "mrqa_naturalquestions-validation-9523", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-1867"], "SR": 0.609375, "CSR": 0.5490301724137931, "EFR": 0.76, "Overall": 0.6653216594827587}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "the adrenal cortex", "late 19th and early 20th centuries", "Tom Jones", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "\"Martian Manhunter\"", "Easy", "\"\u00c9cole des Beaux-Arts\" in Paris", "Gareth Barry", "Lucy Muringo Gichuhi (n\u00e9e Munyiri) ( ) (born 23 September 1962)", "Bambi, a Life in the Woods", "1896", "Apple iPod+HP", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedo boats", "Dante Bonfim Costa Santos (born 18 October 1983), commonly known as Dante (] ), is a Brazilian professional footballer who plays for French Ligue 1 club Nice.", "Glendale", "Boston Red Sox", "Netherlands", "Idaho", "Althea Rae Janairo", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever", "Haryana", "1837", "Blackpool Football Club", "Pippa", "DS Virgin Racing Formula E Team", "explores the lives of those that either own exotic animals or have been captured for illegally smuggling them,", "1943", "Paradise", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "(29 September 1888 \u2013 20 May 1937)", "2010", "Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Robert Devereux", "Gary Oldman", "Alanis Morissette", "Employee Free Choice act", "\"peregruzka\"", "Port-au-Prince, Haiti", "the French Open", "Brazil", "Rocky and Bullwinkle", "baseball"], "metric_results": {"EM": 0.5, "QA-F1": 0.5704836309523809}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.07999999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809523, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-1902", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-3946", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_newsqa-validation-2855", "mrqa_searchqa-validation-14393", "mrqa_searchqa-validation-4094"], "SR": 0.5, "CSR": 0.5484730113636364, "EFR": 0.8125, "Overall": 0.6757102272727272}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "first to utilize Audio-Animatronics", "Continental Army", "1874", "(57 B.C. - A.D. 935)", "January 16, 2013", "Theodore Haynes", "Apple Lisa", "Veyyil", "Victoria, Duchess of Kent, along with her attendant, Sir John Conroy", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide Miethke", "Pensacola", "Consigliere", "Orson Welles", "14", "the Bologna Process", "Peoria, Illinois", "Iran", "Dick Ebersol", "Philip K. Dick", "University of Texas Longhorns", "O", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German Shepherd", "The Vaudevillains", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "the Twist", "1,462", "Premier League", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills and North Hollywood", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "diastema ( plural diastemata )", "Thames Street", "Tom Stoppard", "brazil", "Dube was killed in an attempted car-jacking as he dropped his children off at a relative's house,", "an average of 25 percent", "super-yacht designers Wally", "charcuterie", "Livin' On A Prayer", "the electoral college", "kipling"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7043340773809523}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.125, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2784", "mrqa_hotpotqa-validation-1048", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-3009", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_searchqa-validation-6483"], "SR": 0.640625, "CSR": 0.5495084269662922, "EFR": 0.8260869565217391, "Overall": 0.6786347016976062}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "\"The Itchy & Scratchy Show\"", "First Street", "5249", "the Dutch Empire", "Black Swan", "Ready to Die", "October 20, 2017", "Antilocapra americana", "Lord's Resistance Army", "1965", "1943", "the Big 12 Conference in the National Collegiate Athletic Association (NCAA)", "1959", "1932", "Neighbourhoods are the spatial units in which face-to-face social interactions occur\u2014the personal settings and situations where residents seek to realise common values, socialise youth, and maintain effective social control.", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Seattle", "the University of Kentucky", "\"The Sun on Sunday\"", "Song Kang-ho, Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies.", "B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Bernd Bertie", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "clockwise from the north", "State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "Raymond Benson", "World War II", "George Santayana", "label products that contain any of the most common allergens", "speeding and passing in no-pass zones west of Grand Ronde,", "101", "vinegar", "hurt Tammy Wynette as a person", "saliva", "Venus Williams"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7654389880952381}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4040", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-3476", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.703125, "CSR": 0.5512152777777778, "EFR": 0.7894736842105263, "Overall": 0.6716534173976608}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeleton", "Joaquin Phoenix", "Pot", "the integument of the upper part of the head", "Harley-Davidson", "New Coke", "Abigail Adams", "United States Labor unions", "University of Hawai'i at Manoa", "the leg", "Cristina Yang", "The Omega Man", "van Gogh", "Sumbawa", "Winnipeg", "Alanis Morissette", "Paddington", "Google Doodles", "skyscraper", "1950", "television news broadcasting", "a rock star's brutal murder by ice", "Czech Resistance leader", "seven", "Nike", "bck", "Sweden", "Lamborghini", "notary", "John Philip Sousa", "oregano", "New South Wales", "\"faithful to the Cause of Prohibition, She Hath Done What She Could\"", "Ho Chi Minh", "Martha's Vineyard", "Wayne Gretzky", "apples", "Transformers: Earth Wars", "An American in Paris", "Taiwan", "The Parent Trap", "American Airlines", "William Donald Scherzer", "James J. Corbett", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "ringgit", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "to pay him a monthly allowance,", "Aung San Suu Kyi", "75", "schools"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5109510281385281}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-12132", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-11552", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-8040", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.46875, "CSR": 0.5503090659340659, "EFR": 0.8529411764705882, "Overall": 0.6841656734809308}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Harold Smith", "giant", "lubricant", "Top Banana Bar", "Chesapeake Bay", "the Devil's Dictionary", "Darl Bundren", "\"Macbeth\"", "Suez Canal", "Stephen Hawking", "Ecuador", "Missoula", "local broadcasters", "acetylene", "scrapple", "Florida", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "(Symphonie Fantastique) composer", "oblique", "Cracker Jacks", "Ford", "the Fosbury Flop", "the phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "France", "Orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes Mountains", "Ovid", "2012", "Grendel", "(CAVIAR) FISH", "Mogul", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "eyes", "sound barrier", "Cyprus", "the members of the actual club with the parading permit as well as the brass band", "Nala", "Lee Freedman", "USA43SC6390", "2.1", "kendo", "Rawlings", "Adam Levine", "Syracuse University", "Stuttgart", "a program to help people buy converter boxes that make old TVs work in the new era.", "legislation that would let prisons jam cell-phone signals within their walls.", "Bed and breakfast"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6091299019607843}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.1, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.19999999999999998, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-10784", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.578125, "CSR": 0.5506114130434783, "EFR": 0.7037037037037037, "Overall": 0.6543786483494364}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "the Shar'ia penal code", "Yente", "the", "initiative process", "alfalfa", "Phaedra", "Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "Australia", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "\"to compare\"", "The Secret", "1 furlong (66 by 660 feet)", "ancora", "Frederick Douglass", "William Conrad", "Jericho", "the Burning Bush", "a gastropod", "Indian tribes", "Australia", "Freaks and Geeks", "Edouard Manet", "Finding Nemo", "Frdric Franois", "a zippytechnik", "a American prime time television soap opera", "Amman", "Van Halen", "Permanent Select Committee on Intelligence", "Amyotrophic lateral sclerosis", "grapes", "Nancy Lopez", "Der Zauberberg", "Hudson Bay", "Beguile", "hoo'zher", "the money changers", "bread", "mead", "Mossad", "a mnagerie", "an aide-de-camp", "Judiththia Aline Keppel ( born 18 August 1942 ) was the first one - million - pound winner on the television game show Who Wants to Be a Millionaire? in the United Kingdom", "two - stroke engines and chain drive", "The Comanche / k\u0259\u02c8m\u00e6nt\u0283i\u02d0 / ( Comanche : N\u0289m\u0289n\u0289\u0289 ) are a Native American nation from the Great Plains", "plutocracy", "de Goya", "Shut the *freak* up", "The Panther", "paracyclist", "XXIV Summer Universiade", "Asashoryu", "tallest building,", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5954018460832609}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.5, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.13793103448275865, 0.0, 0.7058823529411764, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-4268", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-1688", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-129", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-574"], "SR": 0.5, "CSR": 0.5500672043010753, "EFR": 0.875, "Overall": 0.688529065860215}, {"timecode": 93, "before_eval_results": {"predictions": ["the United States Department of Labor", "Standard Oil", "Kings", "National Assembly for Wales", "archbishop", "Clark", "India", "The Carpenters", "Nebraska", "Mary", "the Crimean War", "the elbow", "a thermostat", "a good Puddin Theatricals", "a sapphire", "dogwood", "a wipers", "grace", "awagon", "the Davis Cup", "Blackbeard", "William of Orange", "Emily Dickinson", "stikhos", "Simon Wiesenthal", "Mercury and Venus", "Odom", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "hallow", "apples & oranges", "the Kuiper belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Sir Walter Scott", "War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan, or MAP,", "a lump in Henry's nether regions was a cancerous tumor.", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7486979166666667}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-5561", "mrqa_searchqa-validation-4055", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12174", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-4022", "mrqa_hotpotqa-validation-751"], "SR": 0.6875, "CSR": 0.5515292553191489, "EFR": 0.85, "Overall": 0.6838214760638298}, {"timecode": 94, "before_eval_results": {"predictions": ["commit", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "David Lynch", "Thomas G Nazareth", "spruce", "Wild Bill Hickok", "flash", "stars", "vodka", "lava", "anthrax", "Jamaica", "Sacher Torte", "Hillary Clinton", "coyote", "CVS/pharmacy", "Sulfur", "an enslaved African American", "Jacques Marquette", "malocclusion", "Hannibal", "cytokinesis", "Thomas Jefferson", "a millimeter", "Megan Fox", "Eurydice", "Speed Dating", "the Battle of the Little Bighorn", "Marie Curie", "the Russian Blue", "Dustin Hoffman", "Nebraska", "E-T", "vodka", "John", "LOUIS XIV", "painted Caves", "Yellow pages", "General Motors", "Scout Finch", "Liechtenstein", "The Dark Knight", "Pulp Fiction", "Mao Zedong", "Neptune", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson and Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle-distance runner", "Stratfor", "\"Traumnovelle\" (\"Dream Story\")", "1985", "Manuel Mejia Munera", "seven", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6171875}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-9813", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-4661", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.53125, "CSR": 0.5513157894736842, "EFR": 0.8, "Overall": 0.6737787828947368}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "John Lennon", "a genie", "the kagu", "Atonement", "palette", "ice cream", "Cherry baby", "Tajikistan", "Theology", "Forrest Gump", "a piles", "a hot dog", "Ritchie", "Dixie", "Alfred Nobel", "Karen Blixen", "New York", "Sindbad", "the Ziggurats", "the toe", "Pennsylvania", "The War of the Worlds", "Peter Connolly", "Steve Jobs", "Jiles P. Richardson", "a Manwich", "Salinity", "Pompey", "Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "rabbit", "the Cylons", "Marlborough", "Proteus", "Francis", "Judges", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "2016", "a palmetto", "Xinjiang-Uygur Autonomous Region", "the Barbary Coast", "an imaginary menagerie", "Neal Dahlen", "a permanent, fast - drying painting medium consisting of colored pigments mixed with a water - soluble binder medium ( usually glutinous material such as egg yolk or some other size )", "Reverend J. Long", "Bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions, served in a three-part sesame seed bun.", "BBC", "FIFA Women's World Cup", "Great Lakes and Midwestern", "Columbia, Illinois", "three out of four", "2002", "opening of its new restaurant next to the home of Mona Lisa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5880776636713736}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.7317073170731707, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473685]}}, "before_error_ids": ["mrqa_searchqa-validation-13433", "mrqa_searchqa-validation-14256", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-8999", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_searchqa-validation-5472", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-2950"], "SR": 0.546875, "CSR": 0.55126953125, "EFR": 0.7931034482758621, "Overall": 0.6723902209051724}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Donna Reed", "InterContinental Hotels & Resorts", "Kaley Christine Cuoco", "1877", "`` Everywhere ''", "T.S. Eliot", "based on sovereign states", "30 October 1918", "St. Augustine", "Mariah", "Peggy Lipton", "Nicole Gale Anderson", "Tiffany Adams Coyne", "Scheria", "Eddie Murphy", "2 September 1990", "Ben Savage", "Manuel Pessanha ( Pesagno )", "`` The Star Spangled Banner '' or the bugle call `` To the Colors ''", "Thomas Stone", "from Hebrew \u05d4\u05d5\u05e9\u05d9\u05e2 \u05e0\u05d0 h\u00f4\u0161\u00ee\u02bf\u00e2 - n\u0101 and related to Aramaic \u05d0\u05d5\u05e9\u05e2\u05e0\u05d0 ( \u02be\u014dsha\u02bfn\u0101 )", "the Canadian Rockies continental divide", "June 11, 2002", "Khrushchev", "Ciara Brady", "the International Border ( IB )", "Ancylostoma duodenale", "the road is travelled by funeral convoys for fallen Canadian Forces personnel from CFB Trenton to the coroner's office in Toronto", "Wakanda and the Savage Land", "a warrior, Mage, or rogue coming from an elven, human, or Dwarven background", "1992", "the southern part of Nigeria", "The Union's forces", "Majandra Delfino", "August 29, 2017", "a convergent plate boundary", "domestication of the wild mouflon in ancient Mesopotamia", "The show takes place on the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Krypton", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower Peninsula", "11,163", "Jaguar Land Rover", "His son", "propofol,", "Courtney Love,", "near his Seattle home.", "a score", "East of Eden", "Africa", "1919"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5934293609270631}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.2, 1.0, 0.0, 0.2, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.53125, "CSR": 0.5510631443298969, "EFR": 0.8333333333333334, "Overall": 0.680394920532646}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Rajendra Prasad", "2001 -- 2002 season", "New England", "2007", "New Croton Reservoir in Westchester and Putnam counties", "1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear '', a German ex-prostitute who has a reputation as a dirty fighter", "Arnold Schoenberg", "1000 BC", "meditation", "wagen VIII Maus", "A status line", "Richard Bremmer", "contestants'friends using web search engines and other Internet resources to assist them", "1898", "Massachusetts", "Rocinante", "Paul Hogan", "360 members", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Hermia", "Hans Christian Andersen", "Procol Harum", "2018", "William Shakespeare's As You Like It, spoken by the melancholy Jaques in Act II Scene VII", "James Rodr\u00edguez", "a nitrogenous base, a five - carbon sugar ( ribose or deoxyribose ), and at least one phosphate group", "Hathi Jr", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals ), blood plasma and lymph in the ` intravascular compartment ''", "1980", "Instagram's own account", "Revelation was the last book accepted into the Christian biblical canon, and to the present day some `` Nestorian '' churches such as the Church of the East reject it", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "a lightning strike", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Ernest Hemingway", "American swimmer Michael Phelps", "Kevin Zegers", "U.S. was not officially tied to the Allies by treaty", "U.S. Army Colonel and reluctant member of the Transformer Reaction Force ( TRF )", "April 29, 2009", "Laodicea", "Gibraltar", "red, white, and blue", "small orange collection boxes distributed to millions of trick - or - treaters", "Salt Lake City", "Schengen Area (which includes 22 EU and 4 non-EU states)", "Greg Norman", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "a controversial theory about Mary Magdalene and Jesus.", "Barbara Streisand", "Brave New World", "phobia", "Cryogenics", "anxiety disorder"], "metric_results": {"EM": 0.46875, "QA-F1": 0.585070578564924}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.42857142857142855, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.4545454545454545, 1.0, 0.0, 1.0, 0.43750000000000006, 0.0, 0.5714285714285715, 0.16, 0.9565217391304348, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-564", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-786"], "SR": 0.46875, "CSR": 0.5502232142857143, "EFR": 0.7352941176470589, "Overall": 0.6606190913865546}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "an American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Michael Sheen", "Rockbridge County", "Mumbai, Maharashtra", "Hong Kong", "Perfect Strangers", "public", "Nelson County", "video game", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall", "neo-Nazi", "model", "Bisexuality", "Adam Dawes", "in the early 17th-century Colony of Virginia after serving his term of indenture.", "Brian Bosworth", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Longford Town", "Dirk Nowitzki", "highland regions of Scotland", "Kansas Jayhawks football team", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Ray Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "start fires, hunt, and bury their dead", "`` Lauren ''", "Dmitri Mendeleev", "honda", "Utah", "Moby Dick", "two Metro transit trains that crashed the day before, killing nine,", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "Lula da Silva", "Free Bird", "Gone Home", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6575892857142858}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.4, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1503", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_hotpotqa-validation-5730", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-2545", "mrqa_searchqa-validation-15800"], "SR": 0.578125, "CSR": 0.5505050505050505, "EFR": 0.9259259259259259, "Overall": 0.6988018202861953}, {"timecode": 99, "UKR": 0.744140625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.775390625, "KG": 0.490625, "before_eval_results": {"predictions": ["2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "November 13, 2007", "The Bears", "1979", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point Foundry", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award Best Actor", "Duke University", "defender", "Levi Weeks", "219", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "1853", "1977", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "Richard Arthur", "mentalfloss.com", "May 4, 2004", "3", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "John Alexander-Arnold", "eleven", "2011", "last Ice Age", "North Carolina", "wish FM", "John Galliano", "Mark Fields", "to show that a visitor had been to the grave.", "Seoul", "Circumnavigate", "the colon", "a 15th anniversary", "molluscus"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7100074404761905}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, false], "QA-F1": [0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_newsqa-validation-2265", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.65625, "CSR": 0.5515625, "EFR": 0.8636363636363636, "Overall": 0.6850710227272727}]}