{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4340, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "Graph isomorphism", "Thomas Murphy", "the highest terrace", "major national and international patient information projects", "three", "net force", "12 January", "1976\u201377", "Cleveland, Phoenix, Detroit and Denver", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "confirmed", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30%", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "fossils in sedimentary rocks", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Mrs. Wolowitz", "Daenerys", "Raabta"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7716021825396826}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809525, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-5952", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.734375, "CSR": 0.75, "EFR": 0.9411764705882353, "Overall": 0.8455882352941176}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "acted in a 9 + 3 pattern, where the extra compact filament is suspected to have a supporting function", "7 West 66th Street", "patent archives", "all members of Parliament", "4-week period", "six", "Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "the journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025 housing units", "1898", "Lunar Module Pilot", "citizenship", "immediately north of Canaveral at Merritt Island", "physicians, lawyers, engineers, and accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "the head of Lituya Bay in Alaska", "120 m ( 390 ft )", "Game of Wester and A Dream of Spring", "100 members", "photo-electric", "Welch, West Virginia", "it was on this day in 1930", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "Merrimac", "Spain"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7946910294566545}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 0.8, 0.888888888888889, 0.0, 1.0, 0.4, 1.0, 0.3888888888888889, 0.38095238095238093, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-9559", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-4725", "mrqa_squad-validation-3840", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.7239583333333333, "EFR": 0.9047619047619048, "Overall": 0.8143601190476191}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive; therefore, the defects justifying rebellion must be much more serious than those justifying disobedience, and if one cannot justify a civil disobedients' use of force and violence and refusal to submit to arrest", "the principle of inclusions and components", "the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec, where they were accepted and allowed to worship freely", "12 December 2000", "six teams", "redistributive taxation", "a enzyme called rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "the economy", "Stairs", "genetically modified plants", "around 300,000", "three sites", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle which uses rubisco", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw), who may sign them into law", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "town of the Ubii", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown San Bernardino", "Capital Cities Communications", "the lamprey and hagfish", "physicians and other healthcare professionals", "the Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "December 1971", "the realm of the Valar in Aman", "the middle of the 15th century", "6 March 1983", "James G. Kiernan", "horror fiction", "26,000"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7334949515328719}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.46808510638297873, 1.0, 0.5161290322580645, 0.0, 0.6666666666666666, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.5714285714285715, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6798", "mrqa_squad-validation-3023", "mrqa_squad-validation-4108", "mrqa_squad-validation-180", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-126", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-8833", "mrqa_squad-validation-962", "mrqa_squad-validation-384", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433"], "SR": 0.609375, "CSR": 0.6953125, "EFR": 1.0, "Overall": 0.84765625}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle (near present-day Erie, Pennsylvania)", "wireless power transmission", "Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "the 1960s", "it was directly effective", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "BSkyB", "shipping toxic waste", "anarchists", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands", "religious beliefs according to the Scottish census", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "\"on the hearth is the luckiest thing in all the world!\"", "Gandhi in South Africa", "Vlad the Impaler", "The Little Foxes", "Samanyo, Beta-format video recorders", "Leonard Nimoy", "Yam + MP))1/3.", "1994", "1867 to 1877", "Marshall Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "Sam F. Kennedy", "LASER", "Marshall Flying Demi-Tasse", "Yahuah Reigns", "Samagaria radiata, the egret flower of the Far East - Botany Boy", "\"why\", perch", "Andrew Taggart, Emily Warren and Scott Harris", "Samaxophobia- Fear of riding in a car", "American", "Enrique Torres"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5326193164474415}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693, 0.5, 0.5714285714285715, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-1341", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-390", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2804", "mrqa_squad-validation-8068", "mrqa_squad-validation-5214", "mrqa_squad-validation-4315", "mrqa_squad-validation-9406", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.421875, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "the total number of state transitions, or steps, the machine makes before it halts and outputs the answer (\"yes\" or \"no\")", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV in 2010", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "the work of British bacteriologist J. F. D. Shrewsbury", "a mouth that can usually be closed by muscles", "inversely to member state size", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "lymphocytes-derived molecule", "the Edict of Fontainebleau", "Levi's Stadium in the San Francisco Bay Area", "ten million people", "the Lippe", "Video On Demand content", "time and storage", "the top 5 percent", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "the League of the Three Emperors", "science", "143,007", "Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.", "Thomas Christopher Ince", "American Chopper", "from 1972 with drummer Rob Hirst, bass guitarist Andrew James and keyboard player/lead guitarist Jim Moginie", "German", "Fort Valley, Georgia", "American", "Easy (TV series)", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "American President Theodore Roosevelt", "corruption", "a doctor", "Dover Beach"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7422427000774368}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 0.5161290322580645, 0.9090909090909091, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.8235294117647058, 0.8, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-159", "mrqa_squad-validation-6218", "mrqa_squad-validation-4919", "mrqa_squad-validation-4517", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-12", "mrqa_squad-validation-9753", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.609375, "CSR": 0.6354166666666667, "EFR": 1.0, "Overall": 0.8177083333333334}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "courts of member states", "around its circle logo", "three", "a negative long-term impact on the health of the city's residents", "to ensure that people aren\u2019t denied their functionings, capabilities, and agency and can thus work towards a better relevant income", "about 7.5% of primary enrollment, 32% of secondary enrollment and about 80% of tertiary enrollment", "1521", "Gibraltar and the \u00c5land islands", "The starch granules displace the thylakoids, but leave them intact", "exceeds any given number", "Hulagu Khan", "Israeli poet", "quality rental units", "Grover Cleveland", "to cause their repeal, or to exert pressure to get one's political wishes on some other issue", "entertainment", "A vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "Central Poland", "a program called the Council on Advanced Studies in the Social Sciences and Humanities", "to otherwise leverage the accumulation of wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB and Virgin Media", "a terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "Sinclair Oil Corporation", "Taylor Swift", "Eric Edward Whitacre", "Joint Chiefs of Staff", "Linux Format", "Jasenovac concentration camp", "Rabat", "11 or 13 and 18", "Heather Langenkamp (born July 17, 1964)", "Henry Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "The WB supernatural drama series \"Charmed\"", "Lily Hampton", "Liverpool and England international player", "The Ducks", "Ricky Skaggs", "48,982", "Obuasi Municipal district of the Ashanti Region of Ghana", "73", "Algeria", "a novel", "Biafra", "The School of Athens in the Vatican Stanza della Segnatura", "Atlantic City"], "metric_results": {"EM": 0.5, "QA-F1": 0.701613546338768}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.7692307692307693, 0.08695652173913043, 0.125, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8717948717948718, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 0.10526315789473685, 0.5454545454545454, 1.0, 1.0, 0.7499999999999999, 1.0, 0.4, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.9090909090909091, 0.5, 1.0, 1.0, 0.8, 0.7499999999999999, 0.33333333333333337, 1.0, 0.0, 0.5, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-5213", "mrqa_squad-validation-7598", "mrqa_squad-validation-7029", "mrqa_squad-validation-8914", "mrqa_squad-validation-880", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-913", "mrqa_squad-validation-7983", "mrqa_squad-validation-7543", "mrqa_squad-validation-5651", "mrqa_squad-validation-2840", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971"], "SR": 0.5, "CSR": 0.6160714285714286, "EFR": 0.96875, "Overall": 0.7924107142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "solution", "means to invest in new sources of creating wealth", "center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "a modern canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "along the entire length of the lake", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "Judiciary", "single-tape", "Bart Starr", "allotrope", "Karluk Kara-Khanid ruler", "Perth", "Ian Rush", "Gerry Adams", "New Orleans Saints of the National Football League", "1974", "four", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "Hanoi", "Sevens", "fennec fox", "Bart Conner", "fantasy role-playing game", "Martin McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140", "John Locke", "Garth Jennings", "Pablo Escobar", "Afro-Russian", "Mexico City", "Sleeping Beauty", "PeopleMover", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Omar Bongo", "Honey Nut Chex", "Ray Harroun", "Emily Blunt", "David Tennant"], "metric_results": {"EM": 0.625, "QA-F1": 0.7254960317460317}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8, 0.6, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-7547", "mrqa_squad-validation-3091", "mrqa_squad-validation-9287", "mrqa_hotpotqa-validation-1898", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-3510", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-3413", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.625, "CSR": 0.6171875, "EFR": 0.9583333333333334, "Overall": 0.7877604166666667}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "during the compression stage relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "5th Avenue laboratory fire", "the history of arms", "two independent mechanisms", "minor", "Fringe or splinter movements", "17", "lower", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "teachers are now selling their lesson plans to other teachers through the web in order to earn supplemental income", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Han Chinese and Khitans", "8 mm cine film", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "noddy", "Don Johnson", "The song, which appears as the fifth track on the album", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham F.C.", "A55", "Ranulf de Gernon, 4th Earl of Chester", "Olaf Guthfrithson", "Madras Export Processing Zone", "44", "I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Hardman Square"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7149621212121212}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.5, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-1501", "mrqa_squad-validation-3405", "mrqa_squad-validation-2238", "mrqa_squad-validation-9859", "mrqa_squad-validation-8356", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-4945"], "SR": 0.640625, "CSR": 0.6197916666666667, "EFR": 0.9565217391304348, "Overall": 0.7881567028985508}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "cotton spinning", "Orange County", "chloroplast peripheral reticulum", "1962", "not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "unpaired electrons", "French", "the Museum of the Moving Image in London", "he sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Kearney Park", "force", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "a pivotal event in the Arab Muslim world", "to become a national transgender figure", "Trent Alexander-Arnold", "David Michael Bautista Jr.", "Black Friday", "American actor, singer and a DJ", "Prince Amedeo", "Lambic and Oud bruin", "Baja California Peninsula", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "the Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marco Hietala", "Basauri, Biscay", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "4145 ft above mean sea level", "Central Park", "Robert John Day", "Ouargli", "James Tinling", "Italy", "PGA Tour", "Kristoffer Rygg", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "manchester", "1.5 million", "morphine sulfate", "man from an impoverished man out of law", "manchester"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6396144602946073}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3371", "mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1061", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.546875, "CSR": 0.6125, "EFR": 0.9655172413793104, "Overall": 0.7890086206896552}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "early vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "tight end Owen Daniels and a 22-yard throw to receiver Andre Caldwell", "Sanders", "civil instability", "Gamal Abdul Nasser", "immune responses beginning to decline at around 50 years of age due to immunosenescence", "counterflow", "John B. Goodenough", "his arrest was not covered in any newspapers", "machine gun", "the Autons with the Nestene Consciousness and Daleks", "to attend school at the Higher Real Gymnasium", "Standard Model", "Chagatai", "the Rhine-Ruhr region", "pedagogy", "Prevenient grace", "Kansas State 52\u201321", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki (English version)", "Tom Jones", "the RATE project", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European culture", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Central Europe", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the cat", "Sir Giles Gilbert Scott", "get his ship away", "Nine fewer than an earlier count", "Onomastic Sobriquets In The Food And Beverage Industry", "the cat"], "metric_results": {"EM": 0.625, "QA-F1": 0.7022168803418803}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6495", "mrqa_squad-validation-9815", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.625, "CSR": 0.6136363636363636, "EFR": 0.9583333333333334, "Overall": 0.7859848484848485}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "his mother", "shock", "cytotoxic natural killer cells and CDRs (cytotoxic T lymphocytes)", "violence", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "The Cash for Clunkers", "a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "a larger deal that has not been signed by anyone", "\"We could have an accidental death and a mother that panics,\"", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong", "The Zimbabwe Electoral Commission", "Missouri", "to step down as majority leader", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice", "Bush administration", "more than 200", "It is done with the parents' full consent", "best-of-three series", "Kaka", "Christopher Savoie", "U.S. filmmakers", "an apartment near Fort Bragg", "two", "nearly $2 billion", "Jacob", "Molotov cocktails, rocks and glass", "250,000", "Andrew Morris", "Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "The dusting Crowd", "The town of Selby", "1994", "The Conjuring", "The Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6801854395604396}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 0.1904761904761905, 0.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.8, 0.8571428571428571, 0.0, 1.0, 0.5714285714285714, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-6588", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-2344", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-373", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.5625, "CSR": 0.609375, "EFR": 1.0, "Overall": 0.8046875}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "to be greater than sin", "Napoleon", "new technology and machinery", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation", "1227", "lower lake", "three", "Elders", "587,000", "A further type of committee", "Bruno Mars", "Catechism", "beneath the university's Stagg Field.", "Ian Botham", "E. T. A. Hoffmann", "Vincent Motorcycle Company", "richmond", "Salvador Allende", "Harold Pinter", "Hawaii", "Erik Thorvaldson", "Apollon", "Rodgers & Hart", "Mary Seacole", "green", "richmond", "Moses", "Antonio", "European Monetary System", "Christine Keeler", "animal", "Nicholson", "four", "Germany", "Sugar Baby Love", "Rosa Parks Bus", "Sean", "John Denver", "Stage 1", "Travis", "Blue Peter", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "Rudyard Kipling", "barber", "richmond", "Murrah Federal Office Building", "Evita", "oldpatricktoe-end of a Persian slipper", "Russian citadels", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's Club", "\"Sex and the City's\"", "a delegation of American Muslim and Christian leaders", "The marriage to Henry VIII lasted less than a year", "University of South Carolina", "Del Potro."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5643836152882207}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.20000000000000004, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.4, 0.3157894736842105, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_newsqa-validation-1150"], "SR": 0.46875, "CSR": 0.5985576923076923, "EFR": 0.9705882352941176, "Overall": 0.7845729638009049}, {"timecode": 13, "before_eval_results": {"predictions": ["Cram\u00e9r's conjecture", "Bo'orchu", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees.", "Dublin, Cork, Youghal and Waterford", "Tangled", "jinn", "moles", "Democritus", "Diego Garc\u00eda", "Anne Boleyn", "Calvin", "Steve McQueen", "Portugal", "jinni", "two", "komando Pasukan Khusus", "in the northwest of England", "dry Ice", "zanesville", "Lucas McCain", "phoctique", "mercury gilding", "aniridia", "t.S. Eliot", "the river", "woe", "NOW Magazine", "jinn", "netminder", "one", "typhoid fever", "Tina Turner", "g.I. Joe", "al Bundy", "2010", "netherlands", "Venezuela", "Laurel", "netherlands", "40", "phrenology", "San Francisco", "Fall 1998", "Regulus", "Christopher James \" Chris\" Weidman", "Drillers Stadium", "one", "Virgin America", "John Grisham", "netherlands", "Iran's parliament speaker", "netherlands"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5802083333333334}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8994", "mrqa_squad-validation-6078", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.53125, "CSR": 0.59375, "EFR": 1.0, "Overall": 0.796875}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Michelle detroit", "Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public official", "the most cost efficient bidder", "ocular", "the one that spans 11 time zones", "the femur of Ardipithecus ramidus", "Olympia", "Ukraine", "toab", "andrew johnson", "to build a fire", "amber", "Princeton University", "The executioner's Song", "ocular", "bishkek Tajikistan", "Anamosa's Famous Artist", "andrew johnson", "The Comedy of Errors", "the asylum", "film", "shrews", "fiery light", "Cologne", "Oprah Winfrey", "fiery", "preevo", "James Jeffords", "detroit", "tennis", "ocular", "shrew", "andrew johnson", "odocoileus virginianus", "detroit", "andrew johnson", "the United Nations", "ocular", "accordion", "andrew johnson", "neurosis", "Augusta", "clockwise", "2013", "Nick Hornby", "oasis", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "goblin's Market", "Israel"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4692708333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.7000000000000001, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.390625, "CSR": 0.5802083333333333, "EFR": 1.0, "Overall": 0.7901041666666666}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)", "Deabolis", "April 20", "R\u0113nos", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM's", "crossword", "Cuba Gooding Jr.", "John D. Rockefeller", "Flemish", "MasterCard", "Grant Wood", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "lentigo", "Grant Russell", "Toronto Maple", "Zsa Zsa Gabor", "Vladimir Nemirovich-Danchenko", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "a deer", "pro bono", "Politecnico di Bari", "a candy store", "a beer", "manfred von Richthofen", "Nacho Libre", "copper", "a representation in words or pictures of black magic or of dealings with the devil.", "a hemlock", "Jeffrey Wigand", "poetry", "a supplementary sauce", "supplementary", "Casablanca", "blimps", "Grant Kirchhoff", "a geisha", "a mermaid", "Altruism", "Frederic Remington", "S.A. de C.V.", "Grant Jennings", "a Tin Star", "\"Noir\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6175347222222222}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6463", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-4490", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-7392", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.53125, "CSR": 0.5771484375, "EFR": 1.0, "Overall": 0.78857421875}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite tribe", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Rhine", "Eva Peron", "Ho Chi Minh", "circum", "an Inuit dwelling", "Detroit Rock City", "the (Montreal) Blue Jays", "Lilacs Last", "Ray Bradbury", "hate crimes", "King Julien XIII", "Nicolas Sarkozy", "Rubicon", "Steve Martin", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Thomas", "The Prince & Pauper", "cola", "Hillary Clinton", "King Philip", "Bellerophontes", "Balaam", "The Wharton School", "the Caine Mutiny", "(Robbie) Robertson", "(founded) Woolworth Company", "(John) Coltrane", "peace", "fire", "the Sphinx", "John Hus", "Nashville Star", "Mavericks", "Onegin", "Macy's", "a spinning jenny", "Santa Claus", "(Julius) Caesar", "Malpractice", "judges", "chromosome 21 attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "(Charlie) Blauser", "salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6353766025641026}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-15262", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-1759"], "SR": 0.53125, "CSR": 0.5744485294117647, "EFR": 0.9666666666666667, "Overall": 0.7705575980392156}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Tesla", "the telephone ring", "the Orange Democratic Movement", "22", "the dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "The Crystal Method", "Puerto Rico", "Mausoleum", "Million Dollar Baby", "Syria", "Western Airlines", "The Old Man", "French", "Joe Louis", "the Nemean lion", "The Three Musketeers", "the Bayeux Tapestry", "a joey Porch", "China", "Sunni", "notes", "Stephen Hawking", "Mrcus Tullius Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "Quilt", "FRAM", "the House of Representatives", "a beer company", "Michael Moore", "Oman", "Chevy", "an artless girl", "Pennsylvania", "Don Juan", "Ian Fleming", "The Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "a rich man", "Ethiopian", "six", "1992", "preston", "Bromley", "the Ruul", "Cartoon Network", "Caylee Anthony", "their rides based on what their cars say about them.", "the Taliban", "a nuclear weapon", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6799242424242424}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1659", "mrqa_squad-validation-8420", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1920", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-14588", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-6024", "mrqa_searchqa-validation-12814", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.640625, "CSR": 0.578125, "EFR": 0.9565217391304348, "Overall": 0.7673233695652174}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXII", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "Complexity", "same-gender marriages", "2006", "the mid-18th century", "orange", "A Raisin in the Sun", "Moses", "White Russia", "a flanker", "a trowel", "Big Bang", "The Sex Pistols", "endodontist", "a bathtub", "White Cliffs of Denmark", "Genoa", "John Galt", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Kansas", "Seattle", "\"Little. White Pet.\"", "The Hampton Inn", "21", "the Civil War", "alevin", "Paul McCartney", "omega-6", "cavender Chang,1,Laws of Attractor,", "BTO", "Halloween", "\"Be the ball\"", "Tokyo", "Panama", "Confession", "Narnia", "Finnegans Wake", "(William) Wordsworth", "Iceland", "Berenstain Bears", "an earthquake", "Judas", "an elephant", "Mazurka", "Finland", "clandestine", "\"All for our Country\"", "May 2010", "Camp David", "Guanabara", "Thailand", "gender queer", "Minister for Social Protection", "Germany", "the estate", "Robin Williams, and Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.5, "QA-F1": 0.5798751293995859}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.5, "CSR": 0.5740131578947368, "EFR": 0.96875, "Overall": 0.7713815789473684}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "Earth", "53,000", "one", "poet", "two", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Captain Leland Stottlemeyer", "1991", "electron shells", "The Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "democracy", "735", "1913", "Rick Rude", "Toledo, Bowling Green, and Mount Union", "board of trade", "a cladding of a different glass", "Abraham Gottlob Werner", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Necator americanus and Ancy Lostoma duodenale", "March 1", "Forza Horizon 3", "Abraham Lincoln's war goals", "oxygen", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "Hermia", "Jupiter", "east", "15", "John Robert Cocker", "Israel", "video", "a palace", "the olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5628720238095238}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.2857142857142857, 0.28571428571428575, 0.26666666666666666, 0.0, 0.2, 0.8, 0.5, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-2379", "mrqa_triviaqa-validation-2227"], "SR": 0.453125, "CSR": 0.56796875, "EFR": 0.9714285714285714, "Overall": 0.7696986607142857}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\"", "Jacob Zuma", "gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "\"safe housing\"", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "over 1,000 pounds", "Mubarak's", "Saadi", "Texas and Oklahoma", "Polo", "Joe Jackson", "uranus", "computer problems left travelers across the United States waiting in airports,", "Silvan Shalom", "Jonathan Breeze", "Steve Jobs", "12-hour", "prisoners", "September", "consumer confidence", "5:20 p.m.", "North vs. South,", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "uranus", "Akio Toyoda", "The museum has been halted over a budgetary dispute, delaying its opening,", "the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guantanus Bay, Cuba.", "Giovani dos Santos", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "children that a French charity attempted to take to France from Chad for adoption", "40", "\"Friday the 13th\"", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "Doctor Who", "winter festivals", "Pentecost", "Aberdeen", "\"Dumb and Dumber\"", "The 2003 LSU Tigers football team represented Louisiana State University (LSU)", "Earl Warren", "A converging lens", "autompne", "uranus", "The Force Fighters"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5397218233155734}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, true, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.923076923076923, 0.8571428571428571, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.05, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2466", "mrqa_squad-validation-7937", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7266", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.453125, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers.", "San Diego-Carlsbad-San Marcos", "chief electrician", "Newton", "the applied force is opposed by static friction, generated between the object and the table surface.", "the assassination of US President John F. Kennedy", "\"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Awearness Fund", "10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.\"", "Maude", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad, Iran.", "Amanda Knox's aunt", "jazz", "$17,000", "Barney Stinson,", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "nurse who tried to treat Jackson's insomnia with natural remedies", "Sarah", "saving and planning for retirement long before his career neared its end.", "1981", "17 Again", "Nigeria", "$81,8709.", "Republicans", "EU naval force", "Chris Robinson", "Omar Bongo,", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "skeletal dysplasia, a bone-growth disorder that causes dwarfism,", "London Heathrow's Terminal 5.", "\"I underestimated the number of swimmers who would come to swim at the club.\"", "February 12", "30 Latin American and Caribbean nations", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Tiger Woods", "military strike", "White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"Mortal Kombat X\"", "Northumbrian", "Ophelia", "the country's last Communist leader", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Duke of Lauenburg"], "metric_results": {"EM": 0.5, "QA-F1": 0.5972360972360973}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.2666666666666667, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 0.0, 0.4, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.1, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-2810", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.5, "CSR": 0.5596590909090908, "EFR": 0.96875, "Overall": 0.7642045454545454}, {"timecode": 22, "before_eval_results": {"predictions": ["\"instrument will... enable one to generate Roentgen rays of much greater power than obtainable with ordinary apparatus.\"", "WMO Executive Council and UNEP Governing Council resolutions", "Saxon chancellery", "New York and Virginia", "two", "glowed even when turned off.", "a number of celebrities and ministers,", "scientists know about Earth's closest neighbor.", "\"It's public knowledge that the United Kingdom has started the search for hydrocarbon resources in the Falkland Islands area,\"", "April 6, 1994", "Prague", "\"The work is the hardest and least rewarding work we have ever tried to do.", "a federal judge in Mississippi", "\"The mob scatters as the police officers in military style camouflage fire shots in the air and apprehend a few stragglers, some with a kick or a punch.", "$22 million", "the impact of severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "$55.7 million", "The Real Housewives of Atlanta", "18", "88", "\"I haven't seen any violence.", "a president who understands the world today, the future we seek and the change we need.", "the commissions", "Sachina Verma", "Larry King", "Barack Obama", "racially motivated.", "Michael Partain", "male veterans struggling with homelessness and addiction.", "the longest domestic relay in Olympic history", "Zimbabwe's main opposition party", "$27.5 million", "nine", "four bodies", "Friday", "'City of Silk' in Kuwait", "Rima Fakih", "Tuesday night", "\"It is believed to be the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "\"The new language will strengthen the existing warnings,\"", "84-year-old", "Robert Park", "Rima Fakih", "the Isthmus of Corinth", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "paris", "horizon", "UFC 50: The War of '04", "June 11, 1973", "The Del Mar Fairgrounds", "Toy Story", "paris", "\"The Cricket on the Hearth: A Fairy Tale of Home\""], "metric_results": {"EM": 0.34375, "QA-F1": 0.4878681545081801}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.9333333333333333, 0.0, 0.22222222222222224, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.5, 0.19999999999999998, 0.07142857142857144, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.9565217391304348, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-8587", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4449", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.34375, "CSR": 0.5502717391304348, "EFR": 1.0, "Overall": 0.7751358695652174}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "was lost in the 5th Avenue laboratory fire", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma.", "a former general secretary of the Communist Party,", "in Yemen", "2005", "Karen Floyd", "six Iraqis and wounded 10 others,", "those missing were slowed by ammonia leaks and a fire that was not extinguished until afternoon.", "Haiti", "Susan Boyle", "Saturday", "The Interior Ministry", "Jared Polis", "Janet and La Toya,", "Dangjin", "three", "Miriam Brown", "lightning strikes", "Evans", "Italian government", "the flooding was so fast that the thing flipped over,\"", "threatening messages", "\"I have never thought about taking children away from their father, never,\"", "drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "the charges \"in the interest of justice.\"", "martial arts", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "then-Sen. Obama", "Congress", "a curfew", "her account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "June,", "the government in Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.", "Zuma", "haute, bandeau-style little numbers", "nine", "Iraqi Prime Minister Nouri al-Maliki", "2000", "about 50", "15-year-old", "in body bags on the roadway near the bus,", "al Fayed's", "Desmond Tutu", "$1.4 million", "Jobs", "$81,880", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "`` a transformiation, change of mind, repentance, and atonement ''", "Jason Lee", "sleep", "noun", "Kent", "beer and soft drinks", "five aerial victories.", "Cherokee River", "Animal Farm", "Apollo 13", "Florida"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5828499194465235}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.125, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.07692307692307691, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15789473684210525, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1506", "mrqa_newsqa-validation-968", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-716", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-957", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458"], "SR": 0.53125, "CSR": 0.5494791666666667, "EFR": 1.0, "Overall": 0.7747395833333334}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Yuan dynasty", "manually suppress the fire.", "compound", "Nigeria", "U.S. team medical director Richard Quincy", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "him to step down as majority leader.", "United Nations World Food Program", "gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "ancient Egyptian antiquities in the world,", "his club", "would be at the front of the line, self-righteously driving under the speed limit on his or her way to save the world.", "1979", "one of its diplomats in northwest Pakistan", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh,", "Michael Arrington,", "17", "U.N. High Commissioner for Refugees", "HIV/AIDS fight", "\"Larry King Live,\"", "military personnel.", "behind the counter.", "11", "one", "40 former U.S. Marines or sons of Marines who lived at Camp Lejeune", "her fianc\u00e9,", "racial intolerance.", "dairy and eggs,", "Vicente Carrillo Leyva,", "two police cars", "$8.8 million", "to stabilize Somalia and cooperate in security and military operations.", "who is responsible for causing it and what should be done about it", "black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "opium poppies,", "$162 billion in war funding", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "Springfield, Virginia,", "27", "Mark Obama Ndesandjo", "Oxygen,", "Russian residents and worldwide viewers,", "\"Bill, Jr.", "fatally shooting a limo driver on February 14, 2002.", "nuclear matrix", "Vienna", "Sonja Percy ( Shalita Grant )", "President Woodrow Wilson", "Tom Watson", "Sandi Toksvig", "Etihad Aldar Spyker F1 Team", "Viscount Cranborne", "Lake Buena Vista, Florida", "Iceland", "wedlock", "catalytic converters"], "metric_results": {"EM": 0.359375, "QA-F1": 0.48449989306670344}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 0.0, 0.25, 0.18181818181818182, 0.0, 0.4, 0.06896551724137931, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.0, 1.0, 0.0, 0.9090909090909091, 1.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8428", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4128", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.359375, "CSR": 0.541875, "EFR": 1.0, "Overall": 0.7709375}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "jodie Foster", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "phylum", "phylum", "Ub Iwerks", "St Pauls", "holography", "Pelias", "Joshua Radin", "Northumbria", "Harvard", "cricket", "Ron Ridenhour", "quant pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "dermatitis", "four", "Rh\u00f4ne Grape Varietal", "Prophet Joseph Smith, Jr.", "Huntington Beach,", "gold", "moon", "a number", "jimmy", "The Virgin Spring", "Canada", "Winston Churchill", "Stockholm", "Peter Parker", "Golda Meir", "Salvatore Ferragamo,", "bullfight", "Sparks", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "John Denver", "Miss Scarlet", "Marie Van Brittan Brown", "California", "1995", "Bourbon", "Taylor Swift", "\"Home\"", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop Anderson,", "calathus", "the Louvre", "an American private, not-for-profit, coeducational research university"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5116397421037381}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.1764705882352941, 0.4827586206896552, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-82", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_naturalquestions-validation-1399", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.421875, "CSR": 0.5372596153846154, "EFR": 0.9459459459459459, "Overall": 0.7416027806652807}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "Pontiac Silverdome", "elephants", "charcoal", "Frank McCourt", "jules Verne", "joseph smith", "seymour hersh", "Schengen Area", "\u201cA\u201d", "city of city of the United Kingdom", "Famous Players-Lasky Corporation", "\"Lady Willpower\"", "Gerald Durrell", "Jezebel", "Cork", "jason", "Arabian", "Halifax", "\"mccartney frayn\"", "joseph smith", "Frank Wilson", "apartment", "Edwina Currie", "Tara Lipinski", "jonathan smith", "1768", "\u201cFor Gallantry;\u201d", "\"full of woe\"", "chicago", "Cahaba", "apartment", "Tahrir Square", "plutonium", "d'Artagnan", "27", "Jack Ruby", "Tintoretto", "Eric Coates", "Saudi Arabia", "arson", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "clement", "Tokyo", "Edgar Lungu", "49 cents", "over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\"", "Franconia, New Hampshire, United States", "Twitter,", "Juan Martin Del Potro.", "27,", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.5, "QA-F1": 0.54921875}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-1354", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.5, "CSR": 0.5358796296296297, "EFR": 0.96875, "Overall": 0.7523148148148149}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "lost control of the patents he had generated since he had assigned them to the company in lieu of stock.", "Benazir Bhutto,", "nuclear program.", "eight Indians whom the rebels accused of collaborating with the Colombian government,", "louis armstrong", "FBI Special Agent Daniel Cain", "acid attack", "Wally", "2008", "after Wood went missing off Catalina Island,", "she told Behar.", "Afghanistan.", "Florida's Everglades.", "closed on 366 for eight wickets on the opening day.", "the 1950s,", "64,", "Iran's parliament speaker", "27-year-old", "young self-styled anarchists", "about $163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "around 3.5 percent of global greenhouse emissions.", "oaxaca, Mexico", "Orbiting Carbon Observatory,", "Switzerland", "Kenneth Cole", "Janet and La Toya", "11.4 million orphans", "hours", "combat veterans", "get better skin, burn fat and boost her energy.", "U.S. Chamber of Commerce", "injuries,", "al-Shabaab", "booked on an outstanding arrest warrant relating to a domestic violence case,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "the outlet mall", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda,", "louis armstrong", "\"gotten the balance right\"", "The oceans", "cut off his ear and a finger.", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "between 1923 and 1925", "gilda", "jeremy ode", "table tennis", "Tamil", "stephen armson", "Indianola", "the Empire State Building", "Benjamin Disraeli", "sun"], "metric_results": {"EM": 0.5, "QA-F1": 0.5987076291763791}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.15384615384615383, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.15384615384615383, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.6, 0.0, 1.0, 0.8, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-14496"], "SR": 0.5, "CSR": 0.5345982142857143, "EFR": 1.0, "Overall": 0.7672991071428572}, {"timecode": 28, "before_eval_results": {"predictions": ["a hybrid Bermuda 419 turf", "25-foot", "symbols", "Hy Hyundai", "Monday night", "a salvage yard,", "some of the 103 children that a French charity attempted to take to France from Chad for adoption", "40", "\"The Da Vinci Code\"", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Colorado City, Arizona", "a belt of low pressure that wraps around the planet.", "simple puzzle video game,", "outside influences in next month's run-off election,", "aid to Gaza,", "rolled over Tuesday near Campbellton, Texas,", "suppress the memories and to live as normal a life", "Tuesday in Los Angeles.", "immediate release into the United States of 17 Chinese Muslims", "the helicopter went down in Talbiya,", "killed in an attempted car-jacking", "promotes fuel economy and safety", "Vice's", "\"Oprah: A Biography,\"", "80 percent of the woman's face", "in London", "try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$199", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "a UH-60 Blackhawk helicopters collided Saturday night while landing in northern Baghdad,", "Rima Fakih", "at Old Trafford", "help bring creative projects to life ''", "eight episodes of the first season of NCIS", "Mary Elizabeth Patterson", "Tonight Ensemble", "Fifth", "Nepal", "Merck & Co", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.421875, "QA-F1": 0.564945211038961}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.25, 1.0, 0.5, 0.0, 0.4, 0.3636363636363636, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.6666666666666666, 0.0, 0.0, 0.22222222222222224, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-778", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-2380", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.421875, "CSR": 0.5307112068965517, "EFR": 0.972972972972973, "Overall": 0.7518420899347624}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "oxygen", "Betty Meggers", "priests and virgins", "primarily in Polk County, Florida", "ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis", "Russian army", "near the end of their main sequence lifetime", "August 6", "Doug Diemoz", "Virginia", "Monk's Caf\u00e9", "in the central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "a computer maintenance utility included in Microsoft Windows designed to free up disk space", "July 4", "pick yourself up and dust yourself off and keep going ', female - empowerment song ''", "Ann E. Todd as Loretta Merchant", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "October 12, 1979", "Lorazepam", "2013 non-fiction book of the same name by David Finkel", "`` steal '' a Cadillac by way of using their assembly line jobs", "Brenda ''", "a ranking used in combat sports,", "Husrev Pasha", "Jodie Sweetin", "ulnar collateral ligament of elbow joint", "Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "al - Khulaf\u0101\u02beu ar - R\u0101shid\u016bn", "Kanab, Utah", "a decorative ornament", "September 6, 2019", "single state", "a substitute good", "Veronica", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh", "the United States economy first went into an economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "Berry Gordy", "used obscure languages as a means of secret communication during wartime", "YouTube", "Carthage", "Bush 41", "GmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday", "Rickey Henderson", "Lake Baikal", "White Castle"], "metric_results": {"EM": 0.328125, "QA-F1": 0.5120052186836461}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.1111111111111111, 0.5, 0.0, 1.0, 0.4, 0.8, 0.0, 1.0, 1.0, 0.8387096774193548, 0.8, 0.8387096774193548, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 0.18181818181818182, 0.0, 0.3846153846153846, 1.0, 1.0, 0.25, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.4, 0.0, 1.0, 0.0, 0.15384615384615385, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10678", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.328125, "CSR": 0.5239583333333333, "EFR": 0.9302325581395349, "Overall": 0.727095445736434}, {"timecode": 30, "before_eval_results": {"predictions": ["a setup phase in each involved node before any packet is transferred to establish the parameters of communication", "Pleurobrachia, Beroe and Mnemiopsis", "1953", "AT&T", "North Carolina", "Hutter and Hurry Harry", "shoes", "nine", "romeid Akmaev,", "oxygen", "'Archer' Jokes", "cereal", "a deer", "a rose by any other name", "Winston Rodney", "\"shovel\"", "Nanjing", "Montana", "ry Python", "rome in the Metropolitan Museum of Versailles", "GILBERT & SullIVAN", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "Song of Norway", "carolinemuniz", "walker", "\"Y\" 2 \"K\": An Eskimo", "The Hustler", "Hair", "William Randolph Hearst", "pumice", "ale", "shrews", "a dingy", "a song performed by English pop punk band Busted", "jones", "The New Colossus", "a short, sharp bark or cry: excited dogs yelping", "Richard Wagner", "Princess Eugenie of York", "walker Elaine", "\"Tom Terrific\"", "bronchoconstriction", "four", "Neon and Argon Glow Lamps", "romeau", "Le Mans", "jedoublen/jeopardy", "Neil Patrick Harris", "Greg and Rodrick's younger brother", "1999", "vitamin D", "three", "albert juantorena", "R&B vocal group", "Awake", "Doctor of Philosophy", "Pakistan", "in Atlanta in 1996.", "Sonia Sotomayor"], "metric_results": {"EM": 0.3125, "QA-F1": 0.381749947786132}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false], "QA-F1": [0.052631578947368425, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, 0.5, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-4455", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-16969", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-8514", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-11550", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-7231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-8480", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_triviaqa-validation-6657", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.3125, "CSR": 0.5171370967741935, "EFR": 1.0, "Overall": 0.7585685483870968}, {"timecode": 31, "before_eval_results": {"predictions": ["traditional Mongol shamans", "Prospect Park", "the eye", "the volume", "a squint", "Joseph Conrad", "Credit Corporation", "Christian Dior", "August Wilson", "Romeo", "Notre Dame", "Tablecloth", "Peter Piper", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania", "Mike Huckabee", "Queen", "a headache", "a stubbly question mark", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Prince William", "Betty Suarez", "an R", "a crossword puzzle", "New Jersey", "Lake Ontario", "Matthew Perry", "Tracy Turnblad", "John Ford", "kismet", "Willy Wonka", "a subunit", "aluminum", "Matthew Brady", "Ned Kelly", "a piles of papers", "gravitational", "Isis", "a quiver", "Sylar", "on the two tablets", "a patient with end - stage renal disease", "seven", "Planck", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Keith Hackett", "the early Beatles knew they were a good band and were pretty sure of themselves,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6244791666666667}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8204", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-16666", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-313", "mrqa_newsqa-validation-2123"], "SR": 0.546875, "CSR": 0.51806640625, "EFR": 1.0, "Overall": 0.759033203125}, {"timecode": 32, "before_eval_results": {"predictions": ["in weight", "Fresno Street and Thorne Ave", "Black Death", "Elton", "John Stuart Mill", "Oblivion", "CIA", "pianissimo", "Rickey Henderson", "Sirimavo Bandaranaike", "the parsnip", "John Grunsfeld", "a pavilion", "1976", "Galileo Descartes", "a clark", "Cloth", "Rudy Giuliani", "the Constitution", "Virginia", "Thor", "New Jersey", "The Omega Man", "a mudroom", "the chest", "the Summer Olympics", "Chvez", "Jewel", "Hinduism", "tin", "Jermaine", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Aidan Quinn", "Tatum Gretzky Johnson", "Los Angeles", "Auster", "Richard III", "the Labour Party", "the pen", "Mexico", "Douglas Adams", "Celso Santebanes", "Hawaii", "Hilda", "Prussia", "Sophocles", "Mark Cuban", "the FBI", "a chest", "Central Park", "Lewis Carroll", "Part 2", "Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5864281400966184}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.08695652173913042, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-5449", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-15655", "mrqa_searchqa-validation-8063", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-5756", "mrqa_searchqa-validation-11157", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-3926"], "SR": 0.515625, "CSR": 0.5179924242424243, "EFR": 1.0, "Overall": 0.7589962121212122}, {"timecode": 33, "before_eval_results": {"predictions": ["The BBC,", "immunity and the self/nonself vocabulary", "the man facing up, with his arms out to the side.", "the closure of a terminal for hours", "28", "back at work", "Oxbow,", "the Emerson Police Department\\'s", "opium", "\"I just think the case speaks for itself.\"", "the annual White House Correspondents' Association dinner", "Hussein\\'s Revolutionary Command Council", "NATO", "the Dalai Lama", "Myanmar,", "the station", "the journalists and the flight crew will be freed,", "forgery and flying without a valid license,", "Arkansas,", "fuel economy", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in", "the North Korean regime intends to fire a missile", "Police", "the chemical at the Qarmat Ali water pumping plant in southern Iraq", "Roger Federer", "Brooklyn, New York,", "over 1000 square meters in forward deck space", "CNN", "no chance", "St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "in the past year", "two", "William Shakespeare", "Symbionese Liberation Army", "an incident which was described by judge Henry Globe as an \"explosion of violence.\"", "two tickets to Italy on Expedia", "Colombia", "12 shades of violet,", "her resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "India", "NATO forces", "$40", "(Mbeki) Mbeki", "the Ming dynasty", "George II ( George Augustus )", "2014 -- 15", "in the years of 1919 and 1930", "Javier Bardem", "Scotland", "in a family of Portuguese descent", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "M&M'S Peanuts Chocolate Candies", "the free and the home of the brave"], "metric_results": {"EM": 0.484375, "QA-F1": 0.586902854090354}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.4, 1.0, 0.15384615384615383, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-6585", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-2192", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.484375, "CSR": 0.5170036764705883, "EFR": 1.0, "Overall": 0.7585018382352942}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "the strike means all buses, subways and trolleys in Philadelphia and on the Frontier line in Bucks and Montgomery counties stopped running at 3 a.m.", "Washington State's decommissioned Hanford nuclear site,", "Yemen,", "bankruptcy", "$2 billion in", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spanish Davis Cup hero Fernando Verdasco,", "South African", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion", "hardship for terminally ill patients and their caregivers", "Honduran", "Brazil", "three different videos", "strife in Somalia,", "Roy", "the WBO welterweight title", "six", "Meredith Kercher.", "trying to save their client from the death penalty", "Alicia Keys", "soldiers crossed into Somalia to pursue Al-Shabaab fighters", "on gun charges,", "a lump in Henry's nether regions", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "J. Crew.", "returning combat veterans", "543", "The patient,", "Robert Gates", "Israel", "rural Tennessee.", "confirmed that Coleman, 42, was being treated there after being admitted on Wednesday.", "Seoul,", "Nicole", "she was a pain in the ass.", "next week.", "Adam Lambert", "inspector general's", "early detection and helping other women cope with the disease.", "The Board of Parole Hearings", "journalists and the flight crew will be freed,", "gentry Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noregi", "wine", "Revenger's Tragedy", "1754", "Black Elk", "Rye, New York", "the hippopotamus", "caravaggio"], "metric_results": {"EM": 0.5, "QA-F1": 0.5593834550865802}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19047619047619047, 1.0, 1.0, 0.3333333333333333, 0.3636363636363636, 0.0, 0.5714285714285714, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2628", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-1239", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_searchqa-validation-16463", "mrqa_searchqa-validation-7879"], "SR": 0.5, "CSR": 0.5165178571428571, "EFR": 1.0, "Overall": 0.7582589285714285}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Ahab", "Tabatabae", "a common forest tree in Kentucky", "Malibu", "Sisyphus", "sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "Purple", "the Aegean Sea", "the Battle of the Little Bighorn", "the Shakers", "a bellwether", "determinism", "potato chips", "Boxer", "The Spiderwick Chronicles", "Florence Harding", "Las Vegas", "the process of choosing actors", "the Rose Bowl", "Norman Rockwell", "Jackie Kennedy", "light tunais", "Napa", "Eurail France", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "Saturday Night Fever", "12 young people", "Nancy Pelosi", "blog", "Jupiter", "Sadat", "a sundae", "Mary Shelley", "50 million", "Volitan Lionfish", "Charlie Sheen", "The Brothers Karamazov", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "meaning and origin", "1949", "Aamir Khan", "My Gorgeous Life", "London and Buenos Aires", "High Court Judge Justice Davis", "fluoroquinolone"], "metric_results": {"EM": 0.578125, "QA-F1": 0.684375}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-1807"], "SR": 0.578125, "CSR": 0.5182291666666667, "EFR": 0.9629629629629629, "Overall": 0.7405960648148149}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "risk", "bullion", "Supernanny", "the Atlantic", "CINCINNATI", "the mosque", "(Mary) Hudson", "the Peashooter", "carbon dioxide", "(Island) Roosevelt", "Entourage", "the lionfish", "Philadelphia", "the Museum of Modern Art", "the unicorns", "(John) C. Frmont", "Russia", "(Mary) StREISAND", "(Hilda) Rosner", "the Taj Mahal", "(Island)", "Carmen", "Margaret Mitchell", "Frollo", "Sultans of Swing", "(Mary) Pynchon", "(secondary)", "(Burt) Reynolds", "the Sphinx", "Louis Armstrong", "Mecca", "(Mary) Harrison", "Arby\\'s", "coffee", "(Island)", "(Robert) Burns", "the Hulk", "Winnipeg", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "(EG) Bacon", "Icelandic", "a buffalo", "Monday Night Football", "Piaf", "Ivan", "a prologue", "clay", "an investor couple", "Jack Gleeson", "(Mary) Mason", "animals phobia", "Massachusetts", "Star 20", "(Charles) Laughton", "2009", "Democratic", "meteorologist", "$104,327,006", "\"State of Play\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5401785714285714}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-10272", "mrqa_searchqa-validation-11899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-4018", "mrqa_searchqa-validation-11595", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-9131", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-1409", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_triviaqa-validation-1125", "mrqa_hotpotqa-validation-2162", "mrqa_hotpotqa-validation-2000", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-1525"], "SR": 0.46875, "CSR": 0.5168918918918919, "EFR": 1.0, "Overall": 0.7584459459459459}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "Impressionists", "KFC", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "1927", "Eritrea", "pi", "tin", "the Mississippi River", "a turtleneck", "\"w\"", "Marriott", "France", "Canada", "The Secret", "goldfields", "collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Colorado River", "Stephen F.", "Euclid\\'s", "Eva Peron", "Cain", "Lou Grant", "X-Men", "the Louvre", "chinook", "Prison Break", "Earth", "Maine", "cheese", "Meg", "Sonnet", "deuce", "Hans Christian Andersen", "Bogdanovich", "Billy Joel", "Jesus Christ", "CANOE", "the Huronian Ice Age", "nolo contendere", "Junior Walker", "Czech Republic", "Chicken of the Sea", "the WPA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Little Prince\"", "Australian", "the sins of the members of the church,", "$30.6 million", "\"17 Again,\"", "Nelson County"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6859375}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-6358", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_naturalquestions-validation-2918", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_newsqa-validation-3646"], "SR": 0.609375, "CSR": 0.5193256578947368, "EFR": 1.0, "Overall": 0.7596628289473684}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Wild Bill Hickok", "leptospira", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "brushes", "a bear", "Pineapple Marshall", "Witness", "Jack the Ripper", "3800", "Ralph Bellamy", "non-celled", "Spain", "a cerebral hemispheres", "non-EJ Smith", "Macbeth", "comedy", "Mary Poppins", "animal Collective", "The Fresh Prince of Bel-Air", "Land of Nod", "watermelon", "bathwater", "a wedding of a widow", "Livin", "non-Hijja", "a strawberry", "Marie Antoinette", "Ford", "non-IC axis", "Roger Brooke Taney", "a diagonals", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "a cauldron", "Manganese", "a boreal forest", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Platoon", "a scrapple", "Oona Castilla Chaplin", "September 24, 2017", "John Cooper Clarke", "the different levels of human psychological and physical needs", "one", "Tasmania", "American brothers", "sexual activity", "Sam tick,", "the film was shown as part of the festival's special screening program.", "voluntary homicide", "the need for reconciliation in a country that endured a brutal civil war lasting nearly three decades.", "Pygmalion"], "metric_results": {"EM": 0.5, "QA-F1": 0.5872222222222222}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.16, 0.5, 0.05555555555555555, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-5541", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-7477", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_naturalquestions-validation-6347", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_hotpotqa-validation-1783", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.5, "CSR": 0.5188301282051282, "EFR": 1.0, "Overall": 0.7594150641025641}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "\"Boogie Woogie Bugle Boy\"", "Europe", "Charlton Heston", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the Fall of Constantinople", "Havisham", "President Jefferson", "Ford Madox Ford", "the Orinoco River", "a toothpick", "California", "Dixie", "RAND", "Warren Harding", "a pattern", "William", "Francis Crick", "Jay and Silent Bob", "Heath", "South Ossetia", "Twelfth Night", "Hawaii", "a key", "Tito", "the Westminster Kennel Club", "Ratatouille", "circadian rhythms", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube River", "Andrew Johnson", "26.2", "life", "a herb", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Schleswig - Holstein", "Tara / Ghost of Christmas Past", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "\"It\\'s a Small World", "the Kalahari Desert", "women. Graham", "Bob Dole,", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6071428571428571}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-16349", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.546875, "CSR": 0.51953125, "EFR": 1.0, "Overall": 0.759765625}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Germany", "James", "South Korean horror film", "Bohemia", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "yellow fever", "a cappella singing group", "1934", "a record of 13\u20133,", "We Need a Little Christmas", "Tsavo lion", "the New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "the Championship, the second tier of the English football league system,", "the Gettysburg Address", "most awarded female act of all-time", "Mbapp\u00e9", "Stravinsky\\'s \"Daphnis et Chlo\u00e9\"", "15", "26,000", "Kristin Scott Thomas", "Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1994\u201395", "11", "the XXIV Summer Universiade", "2012", "( Byron) De La Beckwith", "Kansas City", "The Second City", "Pinellas County", "beer", "London", "the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Golde", "Sir Tom Finney", "Cameroon", "its own safety as well as all others that may be exposed to the fluid samples they draw", "by military personnel to hazardous materials", "two", "Iggy Pop formed a blues band called the Prime Movers.", "a pound of flesh", "The Mayor of Casterbridge", "DiCaprio", "a destructive ex-lover"], "metric_results": {"EM": 0.5, "QA-F1": 0.624921947945845}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, false, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.25, 0.3333333333333333, 1.0, 0.8571428571428571, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-2004", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-2352", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-3874", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4749", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-13997", "mrqa_naturalquestions-validation-6326"], "SR": 0.5, "CSR": 0.5190548780487805, "EFR": 1.0, "Overall": 0.7595274390243902}, {"timecode": 41, "before_eval_results": {"predictions": ["a touchdown", "10", "a red minivan ran a red light and struck two vehicles at an intersection,", "Les Bleus", "2005", "4,000", "Alethea Wright", "an angry mob.", "normal maritime", "Sri Lanka", "took into custody after he walked up to a roadblock set up by a local anti-kidnapping task force investigating another case.", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as", "piano", "$250,000", "\"prostitute\"", "Zed", "tax", "Los Ticos", "some three months before the crimes", "Russia and China", "Facebook and Google,", "Salt Lake City, Utah,", "Manmohan Singh", "Haiti", "on God's time.", "Pakistan", "23 years.", "her fatal injury.", "North Korea", "an open window", "Leo Frank", "McCartney", "it has witnessed only normal maritime traffic around Haiti,", "President Robert Mugabe", "don't have to visit laundromats", "13", "United Kingdom Dance Championships.", "in a 4-1 Serie A win at Bologna", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "\"Twilight\"", "forgery and flying without a valid license,", "11,", "A third beluga whale belonging to the world's largest aquarium has died,", "Authorities in Fayetteville, North Carolina,", "that 19 people were brought to the hospital -- several with serious injuries, including multiple fracture.", "the Taliban", "Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s, plus error correction code", "Janet Royall", "the B-24 Bomber Crash Landings", "most famous breakfast cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "FMCSA"], "metric_results": {"EM": 0.53125, "QA-F1": 0.617607435966811}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.33333333333333337, 0.19999999999999998, 1.0, 0.625, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 0.06666666666666667, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 0.6, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-2263", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-6603", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.53125, "CSR": 0.5193452380952381, "EFR": 1.0, "Overall": 0.7596726190476191}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona", "in and entities connected to the Mugabe regime,\"", "In Milan have won the Italian Serie A title", "Darrel Mohler", "showing her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "Mugabe's", "42 years old", "\"I want to give peace to my nation,\"", "either stay home (which might be less depressing and won't add more airline emissions) or get a move on it and see the hot spots you just can't miss.", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "in the second day of the impeachment trial,", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar", "in Haiti,", "his business dealings", "in July while she was vacationing with her family on the island of Tictabon,", "poems telling of the pain and suffering of children", "the program was made with the parents' full consent.", "the Democratic VP candidate", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "not guilty of affray", "\"wanton reckless conduct\"", "Basel", "17", "Daytime Emmy Lifetime Achievement Award.", "state senators who will decide whether to remove him from office", "31 meters (102 feet)", "its nude beaches.", "\"This was something different,\"", "Florida girl", "in shark River Park in Monmouth County", "three out of four", "Islamabad", "partying your face off", "Capitol Hill,", "\"The IAEA has inspected the known nuclear sites", "the 21st century", "March 22,", "think are the best.", "in the Mediterranean Sea.", "\"Antichrist\"", "World War II", "Thomas Jefferson", "Jeff East", "Saturn", "brown", "Selfie", "23 March 1991", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "the Pyrenees"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5866095276251526}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.6, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.3076923076923077, 0.5333333333333333, 0.4, 0.0, 1.0, 0.8750000000000001, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-2290", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1891", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-800", "mrqa_naturalquestions-validation-1799", "mrqa_triviaqa-validation-1492", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.46875, "CSR": 0.5181686046511628, "EFR": 1.0, "Overall": 0.7590843023255813}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "the legitimacy of that race.", "At least 88", "does not believe North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "The U.S. subcontracted out an assassination program against al Qaeda... in early 2006.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "in finance but appeared to have been unemployed for several months and had worked for major accounting firms,", "$2 billion", "1.2 billion", "In 1937,", "Brett Cummins,", "Krishna Rajaram", "Arkansas weatherman", "Robert Mugabe", "Gov. Mark Sanford,", "Camp Lejeune, North Carolina,", "Saturday.", "$1.5 million", "have offered many people access to information and the outside world that would have been unthinkable a few years ago,\"", "the report should spur U.S. diplomacy to prevent Iran from developing nuclear weapons", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Hyundai", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "the Seminole Tribe", "Rima Fakih", "Robert Mugabe's", "Barack Obama", "helicopter requested helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "Hillary Clinton,", "display its 10-foot-tall, black, rat-shaped balloon at a rally held outside a fitness center.", "165-room", "500", "Jund Ansar Allah", "54 bodies", "most of those who managed to survive the incident hid in a boiler room and storage closets", "$50 less,", "$60 billion", "amyotrophic Lateral Sclerosis", "Malayalam", "Death Eaters", "1960 Summer Olympics", "Aston Villa", "peasants", "a cue ball", "1822", "The Dressmaker", "Anandapala", "garlic", "the buffalo", "red olives", "the occipital lobes"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5059310981257492}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 0.8695652173913044, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473684, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.09523809523809525, 0.07142857142857144, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.47619047619047616, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-3602", "mrqa_newsqa-validation-2642", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-228", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.390625, "CSR": 0.5152698863636364, "EFR": 1.0, "Overall": 0.7576349431818181}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Florida", "Benj Pasek and Justin Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley", "popular nursery rhyme dating from the early 19th century", "Berea College", "Omaha Nighthawks", "Call Me by Your Name", "Charmian Carr", "Germany and other parts of Central Europe", "New York Islanders", "Amy Smart", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "James A. Garfield", "Ford", "heavier than a feather", "India", "Lutheranism", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men: God Loves, Man Kills", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "the most influential private citizen in the America of his day", "I'm Shipping Up to Boston", "American", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "central", "capital", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnake", "Riddles", "early"], "metric_results": {"EM": 0.5, "QA-F1": 0.555501383667502}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.5, "CSR": 0.5149305555555556, "EFR": 1.0, "Overall": 0.7574652777777777}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "the Indian Ocean waters near the Gulf of Aden,", "30", "crocodile eggs", "\"in the interest of justice.\"", "Polis", "on Saturday.", "Haiti", "in July", "sniff out cell phones", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "aerobic", "Heshmatollah Attarzadeh near his home in Peshawar", "women at ecosolutions@cnn.com.", "women", "Nine out of 10 children", "police", "Raymond Soeoth of Indonesia and Amadou Diouf of Senegal in West Africa,", "the jaws of a crocodile", "bronze medal", "wounded more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "Phillip A. Myers.", "Obama's", "Gyanendra,", "\"The cause of the child's death will be listed as homicide by undetermined means,", "22,", "women", "12 off-duty federal agents in southwestern Mexico,", "UNICEF", "the pregnancy", "228", "Kerstin and two of her brothers,", "2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside", "Wenger", "slavery", "Kacey Ainsworth", "liberales", "Enid Blyton", "Johnny Mathis", "The Golden Child (1986)", "Champion Jockey", "Luca Guadagnino", "Sleepy Brown", "the caged bird", "the shortest", "1.5 fl oz", "women"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6269645467836258}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.47619047619047616, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.8571428571428571, 1.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.484375, "CSR": 0.5142663043478262, "EFR": 1.0, "Overall": 0.7571331521739131}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "\"We need a president who understands the world today, the future we seek and the change we need.", "Nirvana", "\"Dancing With the Stars\"", "without bail and will be arraigned June 25,", "12.3 million", "Mexico", "\"Lyon are said to be willing to cash in at the right price with Spanish giants Barcelona and Real Madrid also monitoring the situation.", "\"Arrington", "\"The station was getting continuing inquiries, and Brett thought it would be best if he resigned,\"", "Indian Army", "Saturday,", "Nicole", "the legitimacy of that race.", "ceo Herbert Hainer", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money --", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets,", "June 6, 1944,", "the Middle East and North Africa,", "2-1", "October 19,", "\"I sincerely apologize to Tiger and anyone else I have offended.", "in Seoul,", "fuel economy and safety while boosted the economy", "ALS6,", "eight", "Siri.", "\"I don't plan to gamble in a casino, buy a drink in a pub or see the horror film \" Hostel: Part II,\"", "246", "Grayback Forestry in Medford, Oregon,", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38,", "Her husband and attorney, James Whitehouse,", "\"Black and Hispanic students", "five Lebanese", "a time-lapse video showing some of the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "foxhunting", "New York", "travel", "16,116", "\"A Catered Affair\"", "a sap", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.625, "QA-F1": 0.6953021423760204}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.11764705882352941, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.12500000000000003, 0.6666666666666666, 0.1, 1.0, 1.0, 1.0, 0.27272727272727276, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-428", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.625, "CSR": 0.5166223404255319, "EFR": 1.0, "Overall": 0.758311170212766}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "a Rush of Blood to the Head", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Dennis Kux", "drawing the name out of a hat.", "Chris DeStefano", "Hero Indian Super League", "two or three", "Badfinger", "Juno Lara Winkleman", "animal", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1916 \u2013 July 2, 1973", "5,112", "1992", "retail, office and residential", "14,652", "6'5\" and 190 pounds", "Mickey Gilley", "a series of bilateral treaties whereby the Swiss Confederation has adopted various provisions of European Union law in order to participate in the Union's single market", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Ulver and the Troms\u00f8 Chamber Orchestra", "1733\u20131811", "London", "the Salzburg Festival", "McComb, Mississippi", "India", "1959", "Jane Ryan", "Randall Boggs", "a Passion", "Boston", "lion", "Royal", "World War II", "Knoxville", "Three's Company", "Doomtree", "Labour", "Linda McCartney's Life in Photography", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "the James Gang", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "cloakroom", "Salans'"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6342980295566503}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, true, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 1.0, 0.13793103448275862, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-1466", "mrqa_hotpotqa-validation-2847", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5172526041666667, "EFR": 1.0, "Overall": 0.7586263020833334}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "gari", "offensive", "Vulcan", "mating rituals", "Fawn Hall", "Citation", "Wanda", "Barnum", "Johnny Weissmuller", "negative electrode", "Torque Wrench", "gold", "Maria Schneider", "kenya", "best independent group show of Impressionist art", "Kentucky Wildcats", "ruddy liar", "Brussels", "13", "General Lee", "piracy", "Dostoevsky", "Martin Luther", "Clue", "Sir Arthur Conan Doyle", "northern kenya", "Abraham Lincoln", "seven years", "Mike Connors", "Juno Jim", "Jim Inhofe", "sancire", "Corpus Christi", "Algeria", "ostrich", "\"rigid\" constitution", "a night shift", "keller", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a diagonal line", "the Grail", "West Virginia", "James Madison", "home theater", "Citation", "kritiks", "Khrushchev", "1904", "young girl ( an illustration by Everest creative Maganlal Daiya back in the 1960s )", "Jimmy Robertson", "ambidextrous", "chariot", "Humberside Airport", "more than 265 million business records worldwide", "100 million", "freezing gasoline prices for the rest of the year and lowering natural gas prices by 10 percent.", "head injury.", "Pope Benedict XVI refused Wednesday to soften the Vatican's ban on condom use", "Charles I"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5114281400966183}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.08695652173913045, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-14219", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-3474", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663", "mrqa_triviaqa-validation-1959"], "SR": 0.40625, "CSR": 0.5149872448979591, "EFR": 0.9736842105263158, "Overall": 0.7443357277121374}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "Heisman Trophy", "Brandi Chastain", "the Colorado", "(P.J.) Parker", "carioca", "Treasure Island", "Pocahontas", "improv", "(Whizzer) White", "an octave", "a push-button valve", "a magnum opus", "Ferris B Mueller", "Joseph Campbell", "Margaret Mitchell", "(Charlie) Busch", "a draft horse", "Ernest Lawrence", "a rodeo", "fresco", "the war", "Grant", "Detroit", "the House of Saxe-Coburg-Gotha", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "the large intestine", "a mouthpiece", "Cuba", "a hobbit", "Olivia Newton-John", "a bug spray", "Manhattan", "February 1", "Leontyne Price", "compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "(Stephen) Bradshaw", "a dang'rous thing", "Hungary", "a burnus", "Philadelphia", "peanut butter", "Invisible Man", "cork", "Lex Luthor", "food and clothing", "Queen Taramis", "Master Christopher Jones", "Hebrew", "\"Meadowbank", "St. Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "an exit on the public side to the secure \"sterile\" side", "three", "poems", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5359375}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.13333333333333333, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-7250", "mrqa_searchqa-validation-8984", "mrqa_searchqa-validation-13674", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.46875, "CSR": 0.5140625, "EFR": 1.0, "Overall": 0.75703125}, {"timecode": 50, "UKR": 0.66015625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.818359375, "KG": 0.46484375, "before_eval_results": {"predictions": ["Fatih Ozmen", "the 850", "Skyscraper", "Cadillac", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "one", "Hilo", "Robert Downey", "J\u00fcrgen M. Geissinger", "band director", "Visigoths", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "president", "19th-century", "Lady Antebellum", "( Jeremy) Hammond", "vice president", "Dele Alli", "1958", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "political commentator", "Adelaide Lightning", "a kitchen", "Walter R\u00f6hrl", "\"Lonely\"", "ten", "Diamond White", "north-northeast of Bologna", "college", "Indooroopilly Shopping Centre", "2006", "Matt Flynn", "Indian", "hamburgers", "England", "pasta", "Luigi Segre", "the Senate", "February 16, 2018", "1980", "Nacio Herb Brown", "Michael Hart", "the Precambrian", "Mull", "his death cast a shadow over festivities", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin,", "(John) Fedor", "Paul Newman", "Puccini", "(John) Candy", "the Hittites"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5328124999999999}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.4, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4200", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3352", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-7101", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-13015"], "SR": 0.46875, "CSR": 0.5131740196078431, "EFR": 1.0, "Overall": 0.6913066789215686}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "devonian", "What You Will", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Betty Comden", "Elizabeth Kekaikuihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui Pratt", "Gothic Revival mansion", "Rochester", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237", "11,163", "an album", "its air-cushioned sole", "White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "American rock band Tool", "the Wikimedia Foundation", "Flashback: The Quest for Identity in the United States", "ARY Digital Network", "1987", "dementia", "two Grammy awards in 2001 for Best Traditional Pop Vocal Album and Best Instrumental Arrangement Accompanying Vocalist(s)", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "the Israeli Declaration of Independence", "2016", "Blue Origin", "Target Corporation", "small forward position", "2012", "United States", "Eunice Kennedy Shriver", "No. 60", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force", "devonian", "devonian", "devonian", "the Gulf of Aden,", "Daytime Emmy Lifetime Achievement Award.", "R.J. Jewell,", "(Joseph) Ingraham", "hunter sauce", "The Quest of Erebor", "carbon"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6048312364718615}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 1.0, 0.3, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-5302", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-5442", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-2654", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-2467", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-1452", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-2803", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.53125, "CSR": 0.5135216346153846, "EFR": 1.0, "Overall": 0.6913762019230769}, {"timecode": 52, "before_eval_results": {"predictions": ["To Carrie and Irene Miner", "King Henry VIII", "lead", "the Rose Bowl", "a Boeing 747", "amber", "Denmark", "terriers", "The Waves", "Nazareth", "freestyle", "duke", "cancer", "Stargate", "Lou Reed", "General Robert E. Lee", "Norway", "Emma Peel", "canvas", "fig", "The X-Files", "Frankie Muniz", "a dinosaur", "celtic bay", "the braille writing system", "kinetic", "Santera", "Starsky and Hutch", "a statue", "quicksand", "The Return of the Native", "AOL &T", "Kellie Kellie's", "Minnesota", "a river", "Zeus", "All That Jazz", "Ankara", "water vapor", "a poem", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Like Water for Chocolate", "the Niger-Congo", "Applebee's", "John Tyler", "Daniel Craig", "humility", "computer programming", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "when mixing solvents or changing their temperature", "Doctor Zhivago", "Bishopston", "governments", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1960s", "the equator between South America and Africa.", "its own individuality", "fake his own death by crashing his private plane into a Florida swamp.", "the Stockton & Darlington Railway"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5393043154761904}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.625, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-13812", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-6128", "mrqa_searchqa-validation-13915", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-16018", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-316", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.453125, "CSR": 0.5123820754716981, "EFR": 1.0, "Overall": 0.6911482900943395}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "a hollow plastic sphere, approximately 3 cm in diameter ( similar in appearance to table tennis ball, but smaller ) with at least one small hole and a seam", "cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "birch", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Bruno Berbatov and Carlos Tevez", "In his first appearance, he flirts with Meredith Grey, and Derek punches him in the face", "DNA", "global crowdfunding platform focused on creativity and merchandising", "warm and short with an average high of 23 \u00b0 C ( 73 \u00b0 F ) and overnight lows of 14 \u00b0 C", "David Motl", "the Catholic Monarchs of Castile and Aragon", "Wisconsin", "Beginning in September 1972", "2017", "the Allies", "bacteria", "magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "the Bactrian", "13", "the five - year time jump", "a compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson", "Coriolis force", "the five - year time jump", "James Rodr\u00edguez", "Donald Sutherland", "James Madison", "the NFL", "Jethalal Gada", "74", "warning signs", "the gastrointestinal tract, oral passage, breast, lung, salivary glands, eye, and skin", "noble gas", "the Immigration and Naturalization Service", "four distinct levels of protein structure", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "2017", "Hercule Poirot", "Charles Strickland", "Islamophobia", "creeks", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "the creation of a long-term plan to help Haiti recover from the devastating effects of the earthquake and Argentina's conflict with Great Britain over oil drilling offshore from the Falkland Islands.", "United Arab Emirates", "the Northwest Territories", "Chekhov", "a white robe", "the death of a pregnant soldier whose body was found Saturday morning in a motel,"], "metric_results": {"EM": 0.375, "QA-F1": 0.5416347809155713}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0625, 0.8571428571428571, 0.08333333333333334, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.25, 1.0, 0.0, 0.5, 0.7499999999999999, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3076923076923077, 0.6470588235294118, 1.0, 0.2, 0.2857142857142857, 1.0, 1.0, 0.5, 0.3076923076923077, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.8, 1.0, 0.6666666666666666, 0.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459", "mrqa_newsqa-validation-2516"], "SR": 0.375, "CSR": 0.509837962962963, "EFR": 0.95, "Overall": 0.6806394675925926}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "Psychomachia, '' an epic poem written in the fifth century", "its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "George Harrison", "Kanawha Rivers", "1803", "Speaker of the House of Representatives", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Frank Theodore `` Ted '' Levine", "May 3, 2005", "supernatural how do ellen and jo come back", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Ron Hicklin", "Michael Phelps", "Taron Egerton", "S\u00e9rgio Mendes", "Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "Transvaginal ultrasonography", "741 weeks", "Zimbabwe", "bristol", "Hillary Clinton", "Tampa", "Battle of Prome", "kitty Hawk", "John Lennon and Olivia Harrison", "\"increasingly aggressive\" Chinese ships harassed the Impeccable,", "Prague is a former Victoria\\'s Secret supermodel-turned-philanthropist.", "Tater Tots", "Yemen", "Q.E.D.", "Daltons"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5812187659154571}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8, 0.058823529411764705, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8000000000000002, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-370", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-940", "mrqa_triviaqa-validation-3099", "mrqa_newsqa-validation-2127", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833"], "SR": 0.484375, "CSR": 0.509375, "EFR": 0.9090909090909091, "Overall": 0.6723650568181818}, {"timecode": 55, "before_eval_results": {"predictions": ["Manhattan", "John Barry", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "Celtic", "Columbia River Gorge in the U.S. states of Oregon and Washington", "the Northeast Monsoon", "2013", "Hold On", "land, fresh water, air", "2015", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "Mark Andreessen", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "depolarization of the cardiac muscle begins at the sinus node", "the sacroiliac joint", "png HTTP / 1.1", "the Brewster family", "1 mile", "pop ballad", "8 December 1985", "during prophase I of meiosis", "21 June 2007", "Arnold Schoenberg", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "Orographic lift", "Hittite and Mesopotamian laws and treaties", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outermost layer of human skin", "2007", "Vanessa received an SMS which reveals that Dan was `` G gossip Girl ''", "10,605", "Tom Thornton", "Ferrari", "San Antonio, Texas", "Jetfire", "biological taxonomy", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Jefferson Alyse Smith", "Celebrity Big Brother", "(Roger) Casement", "James Garner", "Boston, Massachusetts", "Robert Jenrick", "Robert Matthew Hurley", "improve the military's suicide-prevention programs.", "five", "\"I love being with a group where there's not a power struggle,\"", "sarah I", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6551488952224246}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25000000000000006, 0.0, 0.9, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.09523809523809522, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8719", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.546875, "CSR": 0.5100446428571428, "EFR": 0.9655172413793104, "Overall": 0.6837842518472906}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "anti- anti-German", "Harishchandra", "16", "anti- rampant repudiation of signatures", "anti-recorded", "Old Trafford", "Tami Lynn", "U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Lucius Verus", "Sedimentary rock", "John Findley Wallace", "Nepal", "Jurriaen Aernoutsz", "4 September 1936", "fuel ( the reductant ) and an oxidant, usually atmospheric oxygen, that produces oxidized, often gaseous products", "anti- anti-American relations", "Authority", "April 1st", "Muno", "24 hours later", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "can negatively affect a person's personal", "anti National University", "Liam Cunningham", "Dody Goodman", "Walter Pauk", "Margaret Thatcher became Prime Minister in May 1979", "the septum", "Daoism", "the forex market", "Frankie Laine's `` I Believe ''", "Sir Ernest Rutherford", "Nigel Lythgoe", "the third season concluded on October 1, 2017", "gastrocnemius", "Al Pacino", "from 1651 by Thomas Hobbes in his Leviathan, though with a somewhat different meaning ( similar to the meaning used by the British associationists )", "March 26, 1973", "anti- anti-Bubbly", "a great deal", "President Lyndon Johnson", "the formation of two endocardial tubes which merge to form the tubular heart", "a Christmas Tree", "1839", "2007", "Branson", "broadcaster", "Tumi", "River Shiel", "Ozzy Osbourne", "Polo because \"it was the sport of kings.", "the music label that owns them said Sunday,", "ego", "Nova Scotia", "Sir Isaac Newton", "\"Love Letter\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5836364233193277}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.19047619047619047, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.47058823529411764, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.6666666666666665, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.12500000000000003, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-8290", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-4219", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-7991", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_triviaqa-validation-5377", "mrqa_hotpotqa-validation-1439", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.5, "CSR": 0.5098684210526316, "EFR": 0.96875, "Overall": 0.6843955592105264}, {"timecode": 57, "before_eval_results": {"predictions": ["England", "on the North Shore", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "Casino promotions such as complimentary matchplay vouchers or 2 : 1 blackjack payouts allow the player to acquire an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "coffee shop Monk's", "Fred E. Ahlert", "January 2017 patch", "Ozzie Smith", "Mark Jackson", "2017", "two - year terms", "January 2018", "all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "the ancestral virus, of avian origin, crossed the species boundaries and infected humans as human H1N1", "President Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "a focal point", "Cell nuclei", "1973", "May 17, 2018", "Henry Haller", "the scale used for a composition is usually indicated by a key signature at the beginning to designate the pitches that make up that scale", "the contestant", "a theonym based on the root `` king ''", "P.V. Sindhu", "Carpenter", "Asuka", "1961", "Herman Rarebell", "Turkey", "the UNESCO / ILO Recommendation concerning the Status of Teachers", "the United States Department of Defense", "a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "to eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "during prenatal development", "skeletal muscle", "American country music duo Brooks & Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "\"Irish Chekhov\"", "Charlie Wilson", "Gov. Mark Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "the Prohibition era", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.569479391649141}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.7499999999999999, 0.14285714285714288, 0.07692307692307693, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.2222222222222222, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.2608695652173913, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.3, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-6103", "mrqa_searchqa-validation-5902"], "SR": 0.4375, "CSR": 0.5086206896551724, "EFR": 0.9166666666666666, "Overall": 0.6737293462643679}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "October 14, 2017", "Exodus", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "a patronymic surname, which arose separately in England and Wales", "lithium", "the Reverse - Flash", "Los Angeles, California", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "a Genoise sponge base", "Lady Arbuthnot's Chamber", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "1923", "brain and spinal cord", "Seattle, Washington", "October 1898", "on the slopes of Mt. Hood in Oregon", "Ewan McGregor", "LED illuminated", "a large roasted turkey", "1917", "2003", "Ashley Faris", "smen", "the Israelites were encamped at the foot of biblical Mount Sinai", "Macon Blair", "genome", "a nearly - identical `` non-drivers identification card '' to identify persons who are unable or don't want to drive", "Convention's first act", "four", "mid-Atlantic Ridge", "Steve Russell", "peace between two entities ( especially between man and God or between two countries )", "Columbia University", "mitochondria", "Northeast Monsoon or Retreating Monsoon", "2017 -- 18 UEFA Champions League knockout phase began on 13 February", "291", "the early 1960s", "Yahya Khan", "Thespis", "Madison Square Park in Manhattan", "Wednesday, 5 September 1666", "2003", "Zoe", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "Christopher McCoy", "attacks on pipelines and hostage-taking", "fiber supplements, probiotics, antidepressants, behavioral-based therapies, psychotherapy, food modification, acupuncture, and laxatives", "U.S. Navy", "a ferry", "Leland Stanford", "Mexico", "Nepal"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6280478115634366}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.92, 1.0, 0.8, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.6666666666666666, 0.8750000000000001, 0.0, 0.19999999999999998, 1.0, 0.5, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.3076923076923077, 1.0, 0.4, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9600000000000001, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-3396", "mrqa_naturalquestions-validation-10561", "mrqa_naturalquestions-validation-8847", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_newsqa-validation-2428"], "SR": 0.484375, "CSR": 0.5082097457627119, "EFR": 0.9090909090909091, "Overall": 0.6721320059707242}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "9 ( VIIII )", "thumb twiddling is frequently used as an example of a useless, time - wasting activity", "quarterback", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "George Strait", "Antarctica's lowest air temperature record was set on 21 July 1983, with \u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "Herman Hollerith", "94 by 50 feet", "in the differential, which contains the final drive to provide further speed reduction at the wheels", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "many hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson", "Long Island", "1988", "German", "Rococo - era France", "Michael Crawford", "the Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 9, 1945", "1969", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century the Western Christian Church had placed Christmas on December 25, a date that was later adopted in the East", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "Leon Battista Alberti", "1970", "John William Mauchly's ENIAC", "A diastema ( plural diastemata ) is a space or gap between two teeth", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Pink Floyd", "Chicago", "duchy", "Toby Kennish", "Boulder City", "model", "the test results by the medical examiner's office, Garavaglia said.", "teenage", "Sunday", "Vietnam", "bass", "Richard", "John Leguizamo"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7007715184470779}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5161290322580645, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.9859154929577464, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.37037037037037035, 0.2580645161290323, 0.5454545454545454, 0.0, 0.28571428571428575, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-4764", "mrqa_hotpotqa-validation-329", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.578125, "CSR": 0.509375, "EFR": 0.9629629629629629, "Overall": 0.6831394675925926}, {"timecode": 60, "before_eval_results": {"predictions": ["people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "early early season", "used their knowledge of Native American languages as a basis to transmit coded messages", "Anna gives Jeremy a vial of her blood, telling him that if he drinks it he will die and become a Dracula", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "a writ of certiorari", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "macadamia nuts", "79", "dienine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi", "the eighth season", "Erica Rivera", "John Young", "Russia", "2020 National Football League ( NFL ) season", "Charles Perrault", "January 15, 2010", "James `` Jamie '' Dornan ( born 1 May 1982 )", "a branch of the left coronary artery", "son of Frankie '' Bergstein ( n\u00e9e Mengela ), a hippie art teacher", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Turkey", "V\u1e5bksayurveda", "General Armitage Hux", "plants Stevia rebaudiana has been used for more than 1,500 years by the Guaran\u00ed peoples of South America, who called it ka'a he'\u00ea ( `` sweet herb '' ).", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", ", `` Mirror Image ''", "Brooklyn Heights, New York, at 10 Stigwood Avenue", "1902", "early known non-nomadic agrarian societies", "\"digital switchover\"", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker (Born Andreas Cornelis van Kuyk)", "Atlantic Ocean", "mistress of the Robes", "Division of Fawkner", "Adam Lambert", "Kurt Cobain's", "\"Empire of the Sun,\"", "Hector Berlioz", "The Killing Fields", "Endeavour", "News of the World tabloid"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6242211649700873}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [0.48275862068965514, 0.0, 0.06666666666666667, 0.0, 0.0, 1.0, 0.9142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.6, 0.7499999999999999, 0.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-5378", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-160", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-1282"], "SR": 0.515625, "CSR": 0.5094774590163935, "EFR": 0.8709677419354839, "Overall": 0.6647609151903755}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "Dimitar Berbatov and Carlos Tevez", "Jason Marsden", "New Mexico", "In 1889", "under the title `` The Chariot ''", "William the Conqueror", "March 2, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Emma Watson", "Acts passed by the United States and its predecessor, the Continental Congress", "In 2018", "7 July", "the 2009 model year", "4.25 inches ( 108 mm )", "Judi Dench", "outside Japan by Crunchyroll", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "the 18th century", "Thomas Jefferson's", "Ian McKellen", "Space is the Place", "Brad Dourif", "counter clockwise", "Joanne Wheatley", "vice president", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Michael Easton", "the 1994 season", "Matt Flinders", "parthenogenic", "Richard Stallman", "the efferent nerves that directly innervate muscles", "1773", "the Union forces", "Ronnie Dunn and Don Cook", "\"Maljanne\"", "Brazil", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6804396645021645}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.4, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.1818181818181818, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.578125, "CSR": 0.5105846774193548, "EFR": 0.9259259259259259, "Overall": 0.6759739956690561}, {"timecode": 62, "before_eval_results": {"predictions": ["December 13, 1917 -- September 20, 2009", "the pear - shaped gallbladder lies beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "the Roman Empire", "toys or doorbell installations", "muscle contraction", "in positions 14 - 15, 146 - 147 and 148 - 149", "the northernmost point on the Earth", "the second `` A '', Red Coat, and the leader of the `` A- Team '' was revealed to be CeCe Drake", "Eduardo", "1868 war veterans", "1971", "Leo Arnaud ( / \u02c8le\u026a. o\u028a \u0251\u02d0r \u02c8no\u028a / ; July 24, 1904 -- April 26, 1991 )", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )", "Carlos Alan Autry Jr.", "12 : 00 CET", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "The courts", "1912", "Eric Clapton", "Djokovic", "James Hutton", "January 1923", "2017", "scythe", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "Stephen Sondheim", "the Toronto Islands in Toronto, Ontario, Canada", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Japanese light novel series written by Patora Fuyuhara and illustrated by Eiji Usatsuka", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "from New Orleans going north through Chicago and to New York", "the port of Veracruz", "10.5 %", "ecosystems", "the individual responsible for managing the kitchens", "the International Border ( IB )", "Bart Millard", "the Bank of England", "Rolihlahla Mandela", "Midnight Cowboy", "Austrian", "American heavy metal drummer", "Brookhaven", "American Seung-Hui Cho who killed 32 students and himself at Virginia Tech and American John John Wayne Gacy, Jr.", "Tuesday", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Queen Elizabeth", "French West Africa", "Chief Oshkosh Monument", "River Welland"], "metric_results": {"EM": 0.515625, "QA-F1": 0.618601986249045}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.9411764705882353, 0.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.2857142857142857, 0.3636363636363636, 1.0, 0.0, 1.0, 0.5, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-2892", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-4584", "mrqa_triviaqa-validation-5245", "mrqa_hotpotqa-validation-529", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.515625, "CSR": 0.5106646825396826, "EFR": 1.0, "Overall": 0.6908048115079366}, {"timecode": 63, "before_eval_results": {"predictions": ["Robyn", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "Coppolas", "the sacroiliac joint", "Identification of alternative plans / policies", "Cuernavaca, Durango, and Tepoztl\u00e1n", "the development of electronic computers in the 1950s", "the Internal Revenue Service", "Balaam", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "at luncheon", "Gina Gershon", "Jakkur, Bangalore, India", "in a thousand years", "2001", "much of the European industrial infrastructure had been destroyed", "brothers Henry", "Ben Findon", "articulatio incudomallearis", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "members", "Alicia Vikander", "over 300,000", "February 27, 2015", "prejudice in favour of or against one thing, person, or group compared with another", "115", "ten times", "Holly Marie Combs", "from a Czech word, robota, meaning `` forced labor ''", "Arthur `` The President '' Flanders", "Cameron Fraser", "Austin and Pflugerville", "1933", "the misuse or `` taking in vain '' of the name of the God of Israel", "four", "Geothermal gradient", "Utah", "Dan Enright", "Hugo Weaving", "from whom Loyola derives its name, which depicts two wolves standing over a kettle", "Lana Del Rey", "The Matterhorn", "Trinidadian and Tobagonian British", "the Big Bopper", "the United States Department of Defense", "Pisgah National Forest", "Lola Dee", "Robert Mugabe", "Capitol Hill,", "discuss water shortages in the major Tigris and Euphrates rivers,", "impressionism", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5200965942597134}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.13333333333333333, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7492", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8341", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-6825", "mrqa_hotpotqa-validation-3482", "mrqa_hotpotqa-validation-3339", "mrqa_newsqa-validation-198", "mrqa_searchqa-validation-8333"], "SR": 0.421875, "CSR": 0.50927734375, "EFR": 0.8918918918918919, "Overall": 0.6689057221283784}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "The Saga of an American Family", "St. Louis Cardinals", "Pittsburgh", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Benjamin Burwell Johnston, Jr.", "Nia Sanchez", "Vanessa Anne Hudgens", "top division of Mexican football, Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "American alternative rock band R.E.M.", "January 30, 1930", "Doctor", "Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "The Pogues", "Westminster system", "I. helicon", "Ellie Parker", "January 19, 1943", "King of the Polish-Lithuanian Commonwealth", "Sam Waterston", "Transporter 3 (French: Le Transporteur 3)", "March 14, 2000", "Midrand, Gauteng province, South Africa", "Vietnam War", "William Theodore Walton III", "the Darling River", "Brian Keith Bosworth (born March 9, 1965), nicknamed \"The Boz,\"", "140 million", "American", "Teri Garr", "the employer", "1965 -- 66 season ( including a record 27 straight NCAA Tournament appearances )", "Wyoming", "The Krankies", "the fear of cholera", "announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white, and women in the impoverished city are concerned that they will not be able to purchase clothing that conforms to the order,", "defense Minister Kim Kwan Jim", "Billy Corgan", "Washington", "a crossword clue", "Southport, North Carolina"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6177748466810966}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.4444444444444445, 0.0, 0.8, 0.5, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.5, 0.5, 0.5714285714285715, 1.0, 0.3333333333333333, 1.0, 0.19999999999999998, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.06060606060606061, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-4198", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-5596", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1066", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-3275", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474"], "SR": 0.46875, "CSR": 0.5086538461538461, "EFR": 1.0, "Overall": 0.6904026442307692}, {"timecode": 65, "before_eval_results": {"predictions": ["T. D. Lee", "The Man from Jupiter", "Albert", "September 30, 2017", "339,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the Dupont Plaza Hotel", "Odense Boldklub", "Stephen", "Jared Leto", "Gweilo", "Tufts College", "Amedeo", "1942", "The Wu-Tang Clan", "For Love Alone", "a demo", "blues rock", "G\u00e9rard Depardieu", "rural areas", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "Thunderball", "Syracuse University", "Kings Point, New York", "Robbie Gould", "The Gang", "Baldwin", "Port Clinton", "1969", "Wayne Conley", "Adelaide Steamship Company", "Hurricane Faith", "turns out to be a terrible date", "the Celtics", "Good Luck Charlie", "Citrus \u00d7 clementina", "eight", "from 1848 to 1852", "Sippin' on Some Syrup", "Jim Harrison", "the first Viscount", "Arabella Churchill", "Benny Binion", "two Grammy awards", "S7", "2017", "a lightning strike destroyed the top storey", "September 2000", "Thomas Jefferson", "Luxembourg", "Golda Meyerson", "The Muffin Man", "President George Bush", "250,000 unprotected civilians", "WBC light welterweight champion", "a Yonkers", "blown", "our own unhappy experience", "Tim Allen"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5178084935897436}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.25, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1941", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-3263", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2978", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.421875, "CSR": 0.5073390151515151, "EFR": 1.0, "Overall": 0.6901396780303031}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Hillsborough", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "Prince of Wales", "Zsa Zsa Gabor", "ambidevous", "Ibn al-Haytham", "Stephen Hawking", "a series of rock strata", "international prize", "Pipaluk (Inuit for little one)", "Satellites like NOWleta, CA", "Kimbe", "green, red, blue, yellow and white", "K-141 Kursk", "pyrotechnics Guild International", "Chinese", "Eurythmics", "a goose", "The Sundial", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Anouk Aim\u00e9e", "Scotland", "24", "George Washington John Adams", "Ellice Islands", "Meta", "a seaport", "the South West", "a bassoon", "Spice Girls", "Mr Loophole", "Istanbul", "drinking song", "Texas", "Pablo Picasso", "reparations", "Rajasthan", "African violet", "bali", "Glee", "Cardigan", "Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway respectively", "Djokovic", "1912", "The fennec fox", "1927", "Nikolai Trubetzkoy", "Vernon Forrest,", "Linda Hogan,", "from the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "Andrew Wyeth", "many pathogens,", "Steve Wynn", "A substitute good"], "metric_results": {"EM": 0.5, "QA-F1": 0.5362580128205128}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.15384615384615385, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-315", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-5982", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_newsqa-validation-2391", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-9098"], "SR": 0.5, "CSR": 0.5072294776119404, "EFR": 1.0, "Overall": 0.6901177705223881}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less,", "Thailand", "lievremont", "island's best-kept summer secret.", "took on water", "skye", "Secretary of State", "Ali Larijani", "21 percent", "Fernando Caceres", "500", "from Anthony's parents' house and identified through DNA testing.", "America's Cup", "Cambodian territory", "Iran", "voluntary manslaughter", "Jenny Sanford", "travis", "Miami Beach, Florida,", "romantic comedy,", "hundreds of contraband cell phones were found behind bars or in transit to Texas inmates in 2008.", "two contestants.", "travis", "Roland S. Martin", "Graeme Smith", "former U.S. secretary of state", "timothy financial manager who authorities say tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old judge,", "Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies,", "hanging a noose in a campus library,", "two tickets to Italy", "Oxbow, a town of about 238 people,", "the FAA received no reports from pilots in the air of any sightings", "21-year-old driver.", "Jacob Zuma,", "travis", "former Procol Harum bandmate Gary Brooker", "from a domestic violence incident last year,", "from a State Department spokesman", "from the Institutional Review Board in 2004 to conduct a full facial transplant.", "Kenyan and Somali", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "American country music group The Nitty Gritty Dirt Band", "New Testament", "Phil Mickelson", "Dumbo", "Yardbirds", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "jurassic", "ubersetzer", "director", "women and children are vulnerable to violence because of their unequal social, economic, and political status in society"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5407738095238095}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.19047619047619047, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.33333333333333337, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1711", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-833", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.484375, "CSR": 0.5068933823529411, "EFR": 1.0, "Overall": 0.6900505514705882}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "son of Gabon's former president", "put a lid on the marking of Ashura", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "Flint, Michigan", "AS Roma went second in Serie A with a 5-1 win over Torino in the San Siro on Sunday.", "President Barack Obama,", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday", "The family of a Korean-American missionary", "after nine years.", "at least 300", "Thursday,", "volatile and dangerous.", "Israeli Navy", "The drama of the action in-and-around the golf course", "2008", "root out terrorists within its borders.", "25", "\"Zed,\" a Columbian mammoth", "Ciudad Juarez,", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "in a remote part of northwestern Montana", "killing massacre.", "identity theft", "Bailey, Colorado,", "U.S. Justice Department", "Unseeded Frenchwoman Aravane Rezai", "two weeks", "\"Doogie Howser, M.D.\"", "Argentine President Cristina Fernandez de Kirchner", "Six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "President Bush of a failure of leadership at a critical moment in the nation's history.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "impose Islamic law, or sharia, in an effort to halt fighting between Somali forces and Islamic insurgents.", "his past and his future", "on a lifeboat off the coast of Somalia,", "man", "Taron Egerton", "Italy", "\"Book 1: Sowing\"", "purple coneflower", "Nellie Melba", "Clark Gable", "1979", "the backside", "Sweden", "a garcinia cambogia", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5391646241830065}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 0.0, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3, 1.0, 0.0909090909090909, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-430", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-2426", "mrqa_triviaqa-validation-4401", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.46875, "CSR": 0.5063405797101449, "EFR": 1.0, "Overall": 0.689939990942029}, {"timecode": 69, "before_eval_results": {"predictions": ["cavities", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Coach Steve", "April 1917", "Australia's Sir Donald Bradman", "use two - stroke engines and chain drive", "revenge and karma", "Texas A&M University", "Paradise, Nevada", "Professor Eobard Thawne", "Hathi Jr", "a partially reflecting mirror", "Spektor", "Star Spangled Banner", "Bill Russell", "The Parable of the Unjust Judge", "July 2010", "http://www.example.com/index.HTML", "343 m / s in water", "1996", "Carol Worthington", "September 6, 2019", "1972", "as far back as 1853", "rootlets", "terminal velocities much lower than their muzzle velocity", "Battle of Antietam", "Rockfish Gap", "Clarence Anglin", "Andrew Garfield", "normal conditions", "1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "piety", "Daniel Suarez", "White House Executive Chef", "a place of trade", "performers must receive the highest number of votes, and also greater than 50 % of the votes", "the bank's own funds", "The Naughty Nineties", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "eucalyptus", "inflation", "\"Taffy\" Salaman", "John M. Dowd", "December 17, 1974", "the F-15's aerial photographs of the Korean Peninsula", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6581045966915533}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.18181818181818182, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.962962962962963, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-5976", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993"], "SR": 0.5625, "CSR": 0.5071428571428571, "EFR": 0.9642857142857143, "Overall": 0.6829575892857143}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat", "the White Sox", "Bonhomme Carnaval", "1792", "Longliners", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "investment bank Friedman Billings Ramsey", "the NFL", "14 \u00b0 41 \u2032 34 '' N 17 \u00b0 26 \u2032 48 '' W \ufeff / \ufef7 / 14.69278", "1 January 1904", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methodssuch as dictionary attacks, brute force and cryptanalysis attacks", "35 to 40 hours per week", "by week 4 of development", "the sudden appearance of a worldwide storm causes 98 % of the world's population to disappear, and zombie - like creatures rise to attack the remainder", "a laboratory strategy for creating a viable embryo from a body cell and an egg cell", "UN General Assembly", "a premedication", "two", "David Ben - Gurion", "primarily concentrated in the Southern United States, and has been sold as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "September 15, 2012", "Nick Stahl in Terminator 3 : Rise of the Machines ( 2003 ), Christian Bale in Terminator Salvation ( 2009 ) and Jason Clarke in Terminator Genisys ( 2015 )", "Malware", "ex as a noun", "Beorn", "South Dakota", "John F. Kennedy", "around 100,000", "1967", "Rajasthan", "Sodor", "the eye", "44,300", "2008", "Anglo-Frisian", "Long Island", "Mugabe went on to say that U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "11", "bones", "LEWIS CARROLL", "Southeast Asia", "500-room"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6439944580750986}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.8, 0.35294117647058826, 0.9454545454545454, 1.0, 1.0, 0.07142857142857144, 0.125, 1.0, 0.0, 1.0, 1.0, 0.37837837837837834, 0.8, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.10526315789473684, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-4442", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.5625, "CSR": 0.5079225352112676, "EFR": 0.9285714285714286, "Overall": 0.6759706677565392}, {"timecode": 71, "before_eval_results": {"predictions": ["David O. Dykes", "Jon O'Brien", "Tina Turner", "William Howard Taft", "Helvellyn Lower Man, White Side, Stybarrow Dodd, Great Dodd and Clough Head, and in the south leads to Nethermost Pike and Dollywaggon Pike", "photographer", "a clown", "the Titanic", "Campania", "Hadrian", "Madagascar", "Huet, Constant Troyon", "louis Piano", "Manet", "Gary Carney", "shuttle Columbia", "Edinburgh City", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "cariones", "Glasgow", "ABBA", "sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess", "University of Tasmania", "Stieg Larsson", "The \u2018Music Stories\u2019 service", "1957", "\"Cromlechs\"", "steel", "Rotherham United", "Joseph Priestley", "German greyhound", "international team competition in sport,", "German chemistry periodical of the time, Zeitschrift f\u03cbr Chemie", "equatorial guinea, Gabon, and the Republic of the Congo to the south", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Martin Clunes", "Cuba", "armio", "Patience", "Chubby Checker", "Tarantino", "for smartphones and similar devices to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "The par five 13th and 15", "on the Stage Landing", "after 5 years, it was earning $300,000,000 a year", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues.", "July", "Jet Republic, one of Europe's most experienced providers of carbon offsets,", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "the Virginian secession convention", "by asking how do we know when irrational exuberance has unduly escalated asset values", "the Peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4962834498055031}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.24000000000000002, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.3636363636363636, 0.23529411764705882, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0689655172413793, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.4444444444444445, 0.08695652173913042, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-1226", "mrqa_triviaqa-validation-1282", "mrqa_triviaqa-validation-6465", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-990", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-10030", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.421875, "CSR": 0.5067274305555556, "EFR": 1.0, "Overall": 0.6900173611111111}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby darin", "Thames", "Altamont Speedway", "The Jetsons", "26 miles", "tibia", "jellyfish", "manoah\u2019s wife", "Connecticut", "daedalus", "gary clifton", "gaius", "goad", "peter parker", "14", "radars", "Queen Elizabeth II", "Tonto", "hippocampus", "Frank Miller", "lawn tennis", "gollancz", "Atlantic Ocean", "new Zealand history", "Chatsworth House", "giorgio armani", "Budapest", "eyes", "Husqvarna", "garyth", "Aug. 24, 1572", "taurine cattle", "Augustus Caesar", "Venezuela", "Southwest Airlines", "Andrew Lloyd Webber", "gary colla", "renish water lake", "sesame seeds", "Laos", "louis van Gaal", "General Henri-Philippe Petain", "Ali MacGraw", "Miami", "Bill Haley", "sparrow corkscrew", "1768", "Joan Rivers", "london", "barbator", "Ghana", "around 4500 BC in the Near East", "the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Evan Jonigkeit", "seven", "Karl Johan Schuster", "Berga an der Elster", "Robert Barnett", "Diego Milito", "dont Wanna leave Ft. Dutchboy", "Dumbo the Flying elephant", "1580s North Carolina", "pythons"], "metric_results": {"EM": 0.40625, "QA-F1": 0.475}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5655", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2420", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.40625, "CSR": 0.5053510273972603, "EFR": 1.0, "Overall": 0.6897420804794521}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Greek Revival", "The Ansonia Hotel", "Washington", "Helen Mirren", "a striker", "Schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "\"Wragby Road\"", "Indianapolis", "comets", "Premier League club Manchester City", "Sleepy Hollow", "Jane Mayer", "Obafemi Akinwunmi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "33", "hostess of \" Wheel of Fortune\"", "king of Norway", "Carl David Tolm\u00e9 Runge", "king Duncan", "st Andrew's Greeance", "Royal College of Music", "4145 ft", "comets", "Lake County, Illinois", "Netflix", "2013", "American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "suburb of Adelaide", "schoolteacher", "People v. Turner", "Bill Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "parashiyot", "paramitas", "1881", "secretary", "the largest and perhaps most sophisticated ring of its kind in U.S. history.", "comets", "buddhism", "blintze", "comets", "comets", "Caster Semenya"], "metric_results": {"EM": 0.515625, "QA-F1": 0.588942631660792}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.8, 0.25, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.11320754716981131, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-1623", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-3128", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-3692", "mrqa_searchqa-validation-13349", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-10465"], "SR": 0.515625, "CSR": 0.5054898648648649, "EFR": 0.967741935483871, "Overall": 0.6833182350697472}, {"timecode": 74, "before_eval_results": {"predictions": ["the Jesuits", "ribonucleic acid", "ketchup", "a igloo", "The compound eyes of flies", "a Timberland boot", "\"Dancing with the Stars\"", "Republic of the Union of Myanmar", "Latvia", "the spleen", "auf Wiedersehen", "rely", "The Great Temple at Abu Simbel,", "wine", "The esophagus", "Super Bowl", "The King Jesus Gospel:", "a disco group", "Marie Tussaud", "Bay of Biscay", "The Ziz", "February", "Ferdinand Magellan", "Kevin Spacey", "a brothel", "an equatorial diameter", "The Aviator", "Gioachino Rossini", "city", "a tail", "Nashville", "The Hanging Gardens of Babylon", "a robot", "Billy Crystal", "UVA rays", "Gerard", "Qubec", "pope", "On the scene, Mimi Bobeck (played by Kathy Kinney) inflicted no end of torment as Drew's clownlike, cackling nemesis", "Fiji Islands", "\"Moonlighting\"", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "port of chittagong", "In vitro fertilisation", "Diogenes of Sinope", "pastry", "Whatchamacallit", "The Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "\"The Night the Lights Went Out in Georgia.\"", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "demolishing American third seed Venus Williams in the final of the Sony Ericsson Open in Miami on Saturday.", "more than 4,000", "Princess Diana", "Melbourne, Victoria, Australia"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5109375}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-10877", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801", "mrqa_newsqa-validation-3527", "mrqa_hotpotqa-validation-403"], "SR": 0.40625, "CSR": 0.5041666666666667, "EFR": 1.0, "Overall": 0.6895052083333333}, {"timecode": 75, "before_eval_results": {"predictions": ["18", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "AD 1600", "2010", "Gautamiputra Satakarni", "Jos\u00e9 Mart\u00ed", "it violated their rights as Englishmen to `` No taxation without representation ''", "16 August 1975", "MFSK and Olivia", "28 July 1914", "Lager", "905 mbar", "North Atlantic Ocean", "February 7, 2018", "October 2000", "Lutheran Church of Sweden", "commemorating fealty and filial piety", "the fictional Iron River Ranch, Colorado", "Valens", "Debbie Gibson", "Lula", "31 January 1934", "Camp Green Lake", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "fermenting dietary fiber into short - chain fatty acids ( SCFAs ), such as acetic acid and butyric acid", "Kyla Coleman", "Bill Belichick", "September 1972", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish", "Lilian Bellamy", "13,000 astronomical units ( 0.21 ly )", "Shirley Partridge", "handheld", "Neil Young", "a marked ( `` - s '' ) or unmarked plural, as in : `` 1 lakh of people ''", "Chuck Noland", "many forested parts of the world", "arithmetic", "archery", "red squirrels", "Robert Curley", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw away to Saudi Arabia", "the Romanov Dynasty", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6248605104073854}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.7027027027027027, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4583333333333333, 1.0, 0.5, 0.6, 1.0, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.8205128205128205, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.4, 0.0, 1.0, 0.16666666666666669, 1.0, 0.8333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_hotpotqa-validation-543", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-3229", "mrqa_searchqa-validation-12989", "mrqa_newsqa-validation-1646"], "SR": 0.484375, "CSR": 0.50390625, "EFR": 0.9696969696969697, "Overall": 0.6833925189393939}, {"timecode": 76, "before_eval_results": {"predictions": ["$199.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "the Peace of Westphalia of 1648, a stepping stone in the development of the modern state system", "Authority", "Jughead Jones", "American rock band Los Lonely Boys", "ecological regions", "cakes", "Kiss", "18 September to 31 October", "Julie Adams", "After a visit by Adolf Hitler, Bruno's father is promoted to Commandant, and the family has to move to `` Out - With '' because of the orders of `` The Fury ''", "Michael G. Hutton as Lee Smithers", "2004", "The Vamps", "William T. Deutschendorf", "Derrick Henry", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins, and the lyrics to most of the suite's sections consist of his thoughts about her and their imminent breakup", "along a curve from Lake E\u011firdir in the west to the upper reaches of the Euphrates and Tigris rivers in the east", "to encounter antigens passing through the mucosal epithelium", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Megyn Price", "an anembryonic gestation", "by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IV", "Virginia", "Saphira hatches", "September 2017", "English as either Jane or Jennifer, or as the female version of the Scottish name Jean", "1974", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "peninsula", "Jason Flemyng", "peninsula", "Norman Mailer", "Vickers Vimy", "EMI", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million", "San Diego,", "CNN.com", "a jazz funeral", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6750284920946263}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444444, 0.6666666666666666, 1.0, 1.0, 0.0, 0.375, 0.1935483870967742, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4850", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170"], "SR": 0.59375, "CSR": 0.505073051948052, "EFR": 0.9230769230769231, "Overall": 0.674301870004995}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Giuliano Bugiardini", "palladium", "Pulsars", "Seth", "Honda", "\"When You're In Love With A Beautiful Woman\"", "Hitler", "\"Bard of Avon\"", "for soldiers, in this case the soldiers of the football battlefield, asking them to not let their energy come down, and to keep up with the people's expectations by just believing in themselves", "Elizabeth I", "June 14th", "Italy", "1960", "Mel Brooks", "France", "chloroplasts", "Paul Dukas", "Italy", "Uranus", "rum", "apples", "Arbroath", "Roddy Doyle", "discus thrower", "Separate tables", "telephone", "Beatrix Potter", "Magpie", "comets", "normines of Aquatics", "the Kansas City Royals", "Raul Castro", "Space Oddity", "Scotland", "butterflies", "Illinois", "red", "\u201c Splash\u201d", "Britain", "menorah", "A Beautiful Mind", "Gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "norm", "a member of the family Sturnidae ( starlings and mynas ) native to Asia", "Liam Cunningham", "Brobee", "Fuenlabrada", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency, part of the lawless Federally Administered Tribal Areas where U.S. and Pakistani officials have reported a presence of militants.", "in the northeastern Iranian city of Mashhad", "saint Bernard", "France", "Barnard College", "on average 94 kilowatts of power -- the equivalent to 127 horsepower."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5415685876623376}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-1265", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-693", "mrqa_triviaqa-validation-149", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-101", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.46875, "CSR": 0.5046073717948718, "EFR": 0.9705882352941176, "Overall": 0.6837109964177979}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Daniel Fran\u00e7ois Esprit Auber.", "May", "Al Pacino", "vatican Savarkar", "I", "Mr. Golding", "a group of nuclei interconnected with the cerebral cortex, thalamus and brainstem, associated with a variety of functions: motor control, cognition, emotions, and learning", "vitamin B3", "Director General of the Security Service", "hobbits", "Funchal", "woman-based stereotypes", "spaghetti harvest", "Northern Ireland", "woman", "Duchamp", "The Quatermass Experiment", "Mumbai", "a statue", "1875", "the raven", "dogs", "woman", "Tudor", "$-12$", "Modi", "Richard Wagner", "quentin tarantino", "Argentina", "a stand-alone text", "Kitzb\u00fchel", "Tunisia", "Barbara Ann Mandrell", "tundras tundra", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "hard lock left hand 2nd gear 20mph bend, before the sharp right at Portier", "Darrin", "bialystock", "Bethlehem", "Eva Herzigov\u00e1", "David Hockney", "south of Ireland", "'Zulu'", "hobbits", "Colombia", "Ireland as a whole consists of about 32 counties, six of which belonging to a secluded group called Northern Ireland", "the anterolateral corner of the spinal cord", "observing the magnetic stripe `` anomalies", "the ruling city of the Northern Kingdom of Israel, Samaria", "Tudor music", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's strike", "Al-Shabaab", "The Old Man and the Sea", "Edward I", "the Cranberries", "there were no radar outages and said it had not lost contact with any planes during the computer glitches."], "metric_results": {"EM": 0.421875, "QA-F1": 0.5486607142857143}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.14285714285714288, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.25000000000000006, 0.6, 1.0, 0.5714285714285715, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5712", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-3903", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.421875, "CSR": 0.5035601265822784, "EFR": 1.0, "Overall": 0.6893839003164557}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "francish", "HMS Amethyst", "Chad", "tomato", "Kyoto Protocol", "Fancy Dress Shop", "Bull Moose Party", "european", "Jake La Motta", "resistance of an unknown resistor", "ethan Randolph", "south african", "indigestion", "discretion", "Ye Shiwen", "will be assessing their performance in the process, individually and within their teams", "charlie pyle", "Corinth", "human rights lawyer", "Iceland", "ascot", "pear", "Bruce Jenner", "gangsters", "doe", "charlie", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "riverbo", "Julian WikiLeaks", "IT Crowd", "b Bucharest Buffoon", "carters", "charlie croker", "Richard Curtis", "Terms of endearment", "China", "noddy", "1790", "greenock", "charamomile", "charlie tandy", "bog adder's", "Hilary Swank", "Aberdeen", "latitude 90 \u00b0 North", "1800 to 1850", "noon solar time at the 135th meridian west of the Greenwich Observatory", "just 18 minutes", "England", "nationalism", "\"Steamboat Bill, Jr.\"", "hostile war zones,", "Rodong Sinmun", "theology", "Cyd Charisse", "sanctions", "February"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5822516025641025}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.23076923076923078, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1338", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-2216", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_hotpotqa-validation-5333", "mrqa_newsqa-validation-3862", "mrqa_searchqa-validation-2116"], "SR": 0.53125, "CSR": 0.50390625, "EFR": 1.0, "Overall": 0.689453125}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Eleanor Roosevelt", "senators", "2", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Bruce Willis as Steve Ford, a Los Angeles private detective whose dog is stolen by a gang", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "H CO ( equivalently OC (OH )", "Miami Heat", "March 29, 2018, and is scheduled to end on September 30", "four", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "19th - century", "bypasses, to cross major bridges, and to provide direct intercity connections", "set to 0.05 ( 5 % ), implying that it is acceptable to have a 5 % probability of incorrectly rejecting the null hypothesis", "Tom Burlinson, Red Symons and Dannii Minogue", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma, in 1965, but this is never explicitly stated in the book", "Kristy Swanson", "Joanna Moskawa", "Bonanza Creek Ranch, 15Bonanza Creek Lane, Santa Fe, New Mexico, USA", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria, consisted of present - day eastern New Mexico, southeastern Kansas, western Oklahoma, and most of northwest Texas and northern Chihuahua", "United Nations Convention on the Rights of the Child ( commonly abbreviated as the CRC or UNCRC )", "October 1, 2015, when the green class A was retired", "2026", "318", "the President of the United States", "Michael Crawford", "onoma tou Patros kai tou Huiou kai Tou Hagiou Pneumatos, or in Latin in nomine Patris et Filii et Spiritus Sancti", "kida", "February 10, 2017, by American Broadcasting Company ( ABC ), and premiered on September 28, 2017 with a special two - hour premiere", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan ( English : Taxation ; also called \u20b9 700 million or US $11 million in 2016 )", "1996", "American rock band Los Lonely Boys", "number of times a pitcher pitches in a season", "the foreign exchange market ( FX )", "The Hustons", "The Broons", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Buck Owens and the Buckaroos", "\"Up,\"", "\"Empire of the Sun,\"", "Africa", "modifiability", "percy ringwald", "assange", "the skull and crossbones"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6307771755821207}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.7058823529411764, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.10526315789473684, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 0.3243243243243243, 0.2666666666666667, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.2727272727272727, 1.0, 1.0, 1.0, 0.4799999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-1373", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-2241", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-592", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-257", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.515625, "CSR": 0.5040509259259259, "EFR": 0.9354838709677419, "Overall": 0.6765788343787336}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Berenice", "nuclear warheads", "a pentacle", "pizza", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "Marcia Clark", "Jenny", "gestation", "ravens", "Tolkien", "James Franco", "Blue Ridge Mountain Range", "shanghai", "a mixture of iron oxide and aluminum oxide", "buddha", "iTunes", "Thomas R. Gray", "fish", "Marvin Hamlisch", "shanghai", "Atonement", "a regret", "Olivia Newton", "Virginia", "College of William & Mary", "Podengo", "the catfish", "Matthew Vassar", "Japan", "cutlery", "the Police", "Air France", "Scarlatti", "Heracles", "trudge", "Violent Femmes", "albert camus", "Volvo", "Rhode Island", "yodeling", "the Indian Ocean", "a syringe", "Charlotte Corday", "a nanosecond", "a bat", "Mason Alan Dinehart", "a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "on location", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "the city of Aguascalientes", "Borough of Allerdale", "Robert Mugabe", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5897073412698413}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.888888888888889, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-14468", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-15178", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-16540", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-3615", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390"], "SR": 0.484375, "CSR": 0.5038109756097561, "EFR": 1.0, "Overall": 0.6894340701219512}, {"timecode": 82, "before_eval_results": {"predictions": ["the USS Nautilus", "the Cherokee", "China", "the Pope John Paul II", "Yangtze", "Gnarls", "the Parthenon", "the Therapist", "Marilyn Monroe", "Souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,840 square yards", "Galapagos", "Frans", "the Black Sox", "lynx", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "nouveau", "autobahn", "Anglo-Saxon", "the California quail", "curtsy", "Lacrosse", "Toronto", "fo", "King David", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "\"Blue\"", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "lace", "Ossie Davis", "Prince Edward Island", "Westminster Abbey", "Superbad", "granite", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W \ufeff /\ufeff 48.63972 \u00b0 N 4.57028 ) to Lands End", "Austria", "the acai", "the Benedictine Order", "the sexual, romantic or emotional attraction towards people regardless of their sex or gender identity", "linguistic analysis", "getaway driver", "Drew Kesse,", "an embryo to their surrogate,", "eight-week", "2001"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6917489035087719}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.6052631578947368, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12190", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-5031", "mrqa_searchqa-validation-4406", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1388", "mrqa_hotpotqa-validation-943"], "SR": 0.578125, "CSR": 0.5047063253012047, "EFR": 0.9629629629629629, "Overall": 0.6822057326528335}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus Christ", "penguins", "vrai", "Napoleon", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "Trinity", "Algeria", "Joseph Haydn", "Dick Cheney", "the black market", "an", "Saturday Night Fever", "the China", "a pizza (Neapolitan-American)", "a turtles", "a Skyscraper", "White blood cells", "a (Louisiana French picaillon)", "a dogwood", "Qubec", "Larry McMurtry", "Kellogg", "Helen of Troy", "a sweats sweatshirt", "a pound", "Napoleon", "dentures", "the Kola Peninsula of Russia", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "the Standard Oil Co", "Pancho Gonzales", "the Aleutians", "the Mormon", "Lady Jane Grey", "Tommy Tutone", "the crescent moon", "Iraq", "a grasshopper", "Copernicus", "an enchiladas", "William Safire", "Santa Maria delle Grazie, Milan", "London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Edward G. Robinson", "Andrea Brooks", "a Fallopian tube", "Some Like It Hot", "Barbara Eden", "\"Casablanca\" (1969)", "T. R. M. Howard", "the English rock band Radiohead", "9:20 p.m. ET Wednesday.", "the U.N.", "1995.", "four"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6037946428571428}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-9848", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-10095", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-6397", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-5196", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-537"], "SR": 0.53125, "CSR": 0.5050223214285714, "EFR": 1.0, "Overall": 0.6896763392857143}, {"timecode": 84, "before_eval_results": {"predictions": ["Syria", "Henry VIII", "Judas Iscariot", "Windsor", "Douglas", "Comrade", "The Great Gatsby", "a fox", "Sexuality", "Spalding", "the king", "McEnroe", "a bicycle", "Johnson County", "Jericho", "blackjack", "Solzhenitsyn", "work", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the Iroquoian", "the Philippines", "Festa di San Marco", "Eragon", "Strawberry Fields", "Louisiana", "Mexico", "Jolly Roger", "engrave", "daisy Miller", "(Landseer)", "a Y chromosome", "a ship", "Kamehameha", "a fox", "Jamestown, Virginia", "Jerry Maguire", "north magnetic pole", "Oyster Bar", "Reitherman", "Candlestick Park", "Zimbabwe", "a work", "Samwise Gamgee", "I", "Hoffmann", "a calico", "Frankie Muniz", "during season two", "a complex sentence", "40", "Neptune", "Nowhere Boy", "August", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Haiti.", "for financial gain,", "in a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6682291666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.3333333333333333, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-109", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-6488", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-3112", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-10841", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-10445", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_hotpotqa-validation-5599", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.546875, "CSR": 0.5055147058823529, "EFR": 1.0, "Overall": 0.6897748161764705}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "(W. A. Kangaroos)", "Italian", "Eggs Benedict", "the Taj Mahal", "The Fountainhead", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "(F.O.J.) Cornell", "The Beatles", "The Hague", "Geena Davis", "pharmacy", "Henry VIII", "(FIVB)", "Doolittle", "gaseous air", "Shakespeare in Love", "Oscar De La Hoya", "ABBA", "the League of Nations", "Marlee Matlin", "a house of prayer", "The X-Files", "Babar", "Mensa", "Edward Hopper", "oratorios", "a steak", "the voodoo cults", "high chairs", "The Salt Lake Choir", "Venetian", "watermelon", "The Warsaw Pact", "Sparta", "13,", "a battery", "(Star Trek)", "The National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "the epidermis", "the Texas Rangers", "Prozac", "H CO ( equivalently OC (OH )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Charles Sherrington"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6484375}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-10138", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-6063", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-2458", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-11773", "mrqa_searchqa-validation-10056", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692"], "SR": 0.59375, "CSR": 0.5065406976744187, "EFR": 1.0, "Overall": 0.6899800145348838}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy feet", "a sprint", "a Himalayan Yeti", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "Palatine Hill", "California", "the Mississippi", "Alpha", "Quebec", "abalone", "The Texas Chainsaw Massacre", "a rotunda", "a bronze oak leaf cluster", "Manet", "Plutarch", "Milan", "William Shakespeare", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "Dame Ninette de Valois", "Vasco da Gama", "Millard", "Coarse", "Finnegans Wake", "e Selamu", "the black market", "a cockroach", "earthquakes", "Maastricht", "Delilah", "synapses", "croissant", "Mexico", "the lungs", "lavender", "a metacarpal", "grade & grave", "Warsaw", "parsnips", "the Mercury Seven", "Taiwan", "Gettysburg", "Ibtihaj Muhammad", "trout", "\"I'd Like to Get You on a) Slow Boat to China\"", "1959", "season two", "$75,000", "Zimbabwe", "15", "Stonemason\\'s Palace", "Agent Carter", "Cotten", "Manhattan, New York City", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6959212662337662}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-24"], "SR": 0.640625, "CSR": 0.5080818965517242, "EFR": 1.0, "Overall": 0.6902882543103448}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Abonsists", "Michael Crawford", "Alka Yagnik", "Pat McCormick", "Louis Mountbatten", "Cress Warhaftig", "April 6, 1917", "A virion must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "5,770", "Geoffrey Zakarian", "2.04 kg", "Mary Elizabeth", "Scott Schwartz", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Cressida Weissman", "Alan Shearer", "Robert Duvall", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "the expansion of slavery into the western territories", "The Osmonds", "Chto delat", "Australia", "Anakin Abrams", "Jeff East", "one", "Ca Wolf", "Ed Roland", "Kevin Garnett", "a star", "Turkey", "Selena Gomez", "Washington", "the 2nd century", "a player facing a defender receives a pass", "1997", "Dimitar Berbatov and Carlos Tevez", "foreign investors", "Louis XVIII", "marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Crick", "Aconcagua", "Bake Off", "Innsbruck", "Eugene Levy", "zona glomerulosa", "Fionnula Flanagan", "last summer.", "fashion designer", "three-time road race world champion, as well as a double winner of the women's Tour de France,", "a banker", "a eyelid", "the Cubs", "a pickpocket"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5640986999638564}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.72, 0.2222222222222222, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7741935483870968, 0.2857142857142857, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-6424", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-7190", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-995", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.453125, "CSR": 0.5074573863636364, "EFR": 0.9714285714285714, "Overall": 0.6844490665584415}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "known to be uncomfortable,\"", "\"The suspects were plotting to attack two Shiite mosques, police stations, and a Norwegian telecommunications company in Punjab,", "Atlanta's Hartsfield-Jackson International Airport", "normal maritime", "west Harbor neighborhood", "to make space for two ocean wind farms -- taking up 2 percent of the state's waters -- without angering fishing industries, killing whales or harming ecosystems.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "In the last four weeks, authorities arrested three men with suicide vests who were plotting to carry out the attacks,", "'We want to reset our relationship and so we will do it together.'\"", "club managers,", "Long Island", "90", "the crew of the Bainbridge,", "Reggae legend Lucky Dube,", "the Kurdish militant group", "14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin", "Justice Department motion filed last week in support of the Defense of Marriage Act -- which effectively bars the federal government from recognizing same-sex unions.", "Europe,", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guantanamo Bay, Cuba.", "Greeley, Colorado,", "Kansas City, Missouri.", "\"It all started when the military arrested one man, and then an hour later he emerged from building barely able to walk from the beating,\"", "drugs", "Daniel Radcliffe", "1.2 million", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million", "Krishna Rajaram,", "a long-range missile", "Patrick McGoohan,", "he said Chaudhary's death should serve as a warning to management,", "Hamas", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "the Obama administration needs to think of \"victory\" not only in the short term and from a purely anti-terrorism perspective, but also in consideration of the people who have lived and will continue to live in those lands.", "Yemen,", "high-ranking drug cartel member Arnoldo Rueda Medina.", "Pixar", "central business district of Bangkok", "hopes the journalists and the flight crew", "writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "Hague Conventions", "Chris Hemsworth", "prime minister", "England", "beef", "Suleiman", "woods", "Ramadan"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5569511339460924}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 0.16666666666666666, 0.0, 1.0, 0.0, 0.07407407407407407, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.24000000000000002, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.08695652173913045, 1.0, 0.0, 0.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.125, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-6846"], "SR": 0.484375, "CSR": 0.5071980337078652, "EFR": 1.0, "Overall": 0.690111481741573}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron (133 ARS)", "Kim So-hyun", "president of Guggenheim Partners", "\"The Walking Dead\"", "9\u201310 March 1945", "2011", "John D Rockefeller", "during the early 1970s", "Asiana Town", "guitarists", "Rockland County", "Manitowoc County, Wisconsin", "south-east of Adelaide, in the Adelaide Hills", "1967", "alcoholic drinks", "Ferrari", "Chrysler", "Australia", "chimpanzee", "\"Traumnovelle\" (\"Dream Story\")", "Joshua Rowley", "Robert Digges Wimberly Connor", "Edward Asner", "the Beatles and the Rolling Stones", "Baden-W\u00fcrttemberg,", "2001 NBA All-Star Game", "\" rated R\" (2009)", "95 AD", "1614", "French", "\" asleep\"", "Mondays", "Michael Jordan", "\"Mona Leaves-a\"", "JPMorgan Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "Irish Parliamentary Party", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "BBC Focus", "The Kansas\u2013Nebraska Act of 1854 (10 Stat.  277 )", "Scandinavian design", "Buck Owens", "Big Machine Records", "couriers", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "arm", "Tigris", "Kgalema Motlanthe,", "\"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "Partridge Family", "Mickey Spillane", "housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6407490079365079}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false], "QA-F1": [0.8, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4444444444444444, 0.8, 0.8, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-3752", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.546875, "CSR": 0.5076388888888889, "EFR": 1.0, "Overall": 0.6901996527777777}, {"timecode": 90, "before_eval_results": {"predictions": ["The Searchers", "Ardeth Bay", "2009", "actress and singer", "Pakistan", "1754", "Confessions of a Teenage Drama Queen", "VfL Wolfsburg", "d\u00eds", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia, remembered as a schoolmaster at J. L. Young's Adelaide Educational Institution and at Saint Peter's College", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Fineas", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664 rooms", "Tamil", "Objectivism", "Chicago", "London Heathrow", "Binaural", "Helensvale", "January 30, 1930", "22 September 2015", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Goitsebeng Maphiri Khama", "Scandinavian design", "Donald Trump", "President Barack Obama's Cabinet", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "the Presbyterian Church", "138,535 people", "Ryukyuan people", "1972", "Stern-Plaza in Potsdam", "Life Is a Minestrone", "April 19, 1994,", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "maintains and enforces style to improve communication", "Mexico", "Ann Widdecombe", "Graham Nash", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert", "dolls", "James Bond", "CO2", "Walgreens"], "metric_results": {"EM": 0.5, "QA-F1": 0.5928671155233655}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.787878787878788, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.0, 0.2564102564102564, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4945", "mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-4282", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-2969", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5509", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-1363", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_triviaqa-validation-4655", "mrqa_triviaqa-validation-4881", "mrqa_newsqa-validation-386", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.5, "CSR": 0.507554945054945, "EFR": 1.0, "Overall": 0.690182864010989}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "the iTunes Store", "the Jaguar", "his reputation", "Friday", "south of the U.S. - Mexico border.", "Orlando Bloom", "Babe Ruth", "Blondie Abbey", "Arkansas", "Mike Tyson", "Iustitia, Justitia or Lady Justice", "modern art", "the prairie Wolf", "bcolicus", "Tito Puente", "hydrogen", "1960s", "the malignant disease", "Margaret II", "Salt Lake City", "San Francisco", "the 1940s", "the Church of Christ, Scientist", "Bank One", "the College of William & Mary", "the Wright Brothers", "tennis", "John Deere", "depth and height", "Pontiac", "Reptiles", "Georgia", "Key lime", "Lettuce", "Haroun and the Sea of Stories", "a bumblebee", "Savannah, Georgia", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln & I approved this message", "Eva Pern", "Kingston", "a key", "Ghost", "the Basilica Cathedral of Lima", "Mesopotamia", "Marat", "Sir Henry Bartle Frere", "the Bay of Montevideo", "a bank, drawn on the bank's own funds and signed by a cashier", "pickles", "Pat Houston", "Aquae Sulis", "1.5 million", "Macomb County", "Kristoffer Rygg", "five Texas A&M University crew mates were hoisted out of the Gulf of Mexico earlier in the day after their sailboat capsized.", "Monday night.", "eight.", "American Wesleyan minister and biographer"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5942471590909091}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.08333333333333334, 0.6666666666666666, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-10498", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-13521", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-3350", "mrqa_searchqa-validation-7246", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-16068", "mrqa_searchqa-validation-12942", "mrqa_naturalquestions-validation-6211", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-3665", "mrqa_hotpotqa-validation-2255", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.484375, "CSR": 0.5073029891304348, "EFR": 1.0, "Overall": 0.6901324728260869}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Constantin Brancusi", "Quantico, Virginia", "the East River", "William Shakespeare", "William Shakespeare", "(disease)", "Alaska", "Sputnik I", "Richmond", "(disease)", "Java", "the bass", "Marius Petipa", "Indivisible", "(disease)", "(Francisco) Earnshaw", "Muhammad", "September 20, 1934", "Pirates of the Caribbean: Dead Man\\'s Chest", "Charles de Gaulle", "Chesterfield", "the wolf", "Josephine", "salt", "a conviction", "Rossini", "Texas", "Lapland", "Tom Canty", "Roman Polanski", "Joan Didion", "a frigate", "Baltimore", "the Bay of Bengal", "button Gwinnett", "Hillary Clinton", "Terrific", "geology", "six", "Olympia", "Ship of Fools", "(disease)", "(Francisco) Tom", "fluid", "( Margaret) Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "manic", "central Saskatchewan", "lighter fluid", "he has also destroyed the only boats on the island", "Judi Dench", "Germany", "Caernarfon", "Nairobi, Kenya", "Love Streams", "My Beautiful Dark Twisted Fantasy", "June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6392045454545454}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-14332", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6867", "mrqa_newsqa-validation-1870"], "SR": 0.59375, "CSR": 0.5082325268817205, "EFR": 1.0, "Overall": 0.6903183803763441}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Alice Cooper", "Telma Hopkins", "Maria Gabriel", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners,, former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "Pebble Beach", "Dragon Ball GT", "Audrey II", "January 2017", "NIRA", "1922", "Julie Debbie Kavner", "Justin Timberlake", "The Chainsmokers", "1787", "The Province", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3", "Bill Irwin", "Napoleon", "Hem Chandra Bose", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Uranus", "hyperinflation", "1939", "Sam Huntington", "Maria Hall", "Tagalog", "Sauron", "Lana Del Rey", "statistical", "159", "The Third", "the university's science club", "works in a bridal shop", "increases the life of the pump, allows a smaller and lighter device to be used, and reduces electrical load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "a traditional holiday originating in China, occurring near the summer solstice", "inwards towards the pith, and secondary phloem growth outwards to the bark", "during segregation", "euro", "Robin Hood", "a Snowshoe Hare", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "\"The Da Vinci Code\"", "reporters.", "Khrushchev", "Julie Andrews", "Headless Horseman", "Leo Frank,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6343382010501576}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.4444444444444444, 0.7272727272727273, 0.17391304347826086, 0.4615384615384615, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-94", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374"], "SR": 0.53125, "CSR": 0.5084773936170213, "EFR": 0.9333333333333333, "Overall": 0.6770340203900709}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "Thon Maker", "Battle of Chester", "youngest TV director ever", "19 February 1927, Halifax", "the Cedar Forest, a forest of ten thousand leagues span", "playback singer, director, writer and producer", "Aerol\u00edneas Argentinas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado", "Revengers Tragedy", "Japan", "rural", "6", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "six-color printing process", "Las Vegas Boulevard", "intelligent design", "Barbara Ryan Coleman", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevrolet Corvette", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "Pour le M\u00e9rite", "In the UK, he was awarded nine platinum album certifications, eleven gold and eight silver, releasing eleven number-one albums", "Drowning Pool", "in most casinos", "the Food and Agriculture Organization", "dance hold in the improvisational disco dance scene dominated by solo dancing, approximately at the same time when the hustle emerged in the United States", "Bharat Ratna", "Cesar Millan", "Hong Kong", "Beauty and the Beast", "Bardney", "Holinshed\\'s Chronicles", "November 6, 2018", "Bangalore University", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "the densest giant planet", "The alveolar process", "Dortmund - Ems Canal", "Hugh Quarshie", "William II", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "The International Atomic Energy Agency", "Easter Island", "Whitney", "Today", "25"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7017248376623377}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, true], "QA-F1": [0.8333333333333333, 0.8, 1.0, 1.0, 0.0, 0.18181818181818182, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.47619047619047616, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5362", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-514", "mrqa_newsqa-validation-726", "mrqa_searchqa-validation-9249", "mrqa_searchqa-validation-2056"], "SR": 0.578125, "CSR": 0.5092105263157894, "EFR": 1.0, "Overall": 0.6905139802631579}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies worldwide", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1945", "Roy Warren Spencer", "1484\u20131564", "U.S. Route 71", "constantine", "March", "Russia", "Harrison Ford", "July 25", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "Northern Lights", "coca wine", "dimensionless quantity", "Terrina Stause", "Maine", "Encore Las Vegas", "baa, Baa, Black sheep", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Lester Burnham", "Deputy Vice-Chancellor", "Deepak Tijori", "Teen Titans Go!", "Mickey Mouser", "Grammy Award", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "seal hunting", "the Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "professional boxer", "Forever Living Products", "creeks", "1992", "the United States of America", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "The Da Vinci Code", "Polaris Venture Partners,", "iceberg", "The battery", "Victoria", "Venus Williams"], "metric_results": {"EM": 0.5, "QA-F1": 0.6167410714285715}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-1059", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-167", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-2622", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4470", "mrqa_naturalquestions-validation-360", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-191", "mrqa_searchqa-validation-14503", "mrqa_searchqa-validation-9695"], "SR": 0.5, "CSR": 0.5091145833333333, "EFR": 1.0, "Overall": 0.6904947916666666}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "2012 Summer Olympics", "at the end of the 18th century", "1942", "Johnny Cash and Jennings", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "the Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "(Jeux) olympiques d'\u00e9t\u00e9", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Mariann Karlsson", "Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "Pimp My Ride", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "Francis", "early Romantic", "$700 million", "the Sun", "Bhushan Patel", "1692", "the power to regulate interstate commerce", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat X", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "right", "to put a lid on the marking of Ashura", "Pakistan's", "homicide", "breadcake", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.625, "QA-F1": 0.8247912677600178}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.75, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.8, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.18181818181818182, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.923076923076923, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-619", "mrqa_hotpotqa-validation-5290", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_hotpotqa-validation-4514", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1058", "mrqa_searchqa-validation-13280"], "SR": 0.625, "CSR": 0.5103092783505154, "EFR": 0.9583333333333334, "Overall": 0.6824003973367698}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "the main Caucasus range", "David Bowie", "John Spencer", "Granada", "Treaty of Brest-Litovsk", "Karl Marx", "Procol Harum", "Marilyn Monroe", "cyanoguttatus", "1957", "1876", "Transvestite/Cross dresser", "Godfather", "south africa", "Scotland Yard", "The island does not have a common name in either English or Scottish Gaelic", "good and gay", "winnie Mae", "Rudyard Kipling", "1921", "Trainspotting", "Desdemona", "avocado", "Rembrandt", "Syriza", "Ford", "garbanzo", "Cole Porter", "1830", "William WymarkJacobs", "Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "an elephant", "Tigran Petrosyan", "end \u2013 10", "Westminster Abbey", "Canada", "Flavio Briatore", "Edward VII", "Tombstone", "south africa", "Mr. Tickle", "Cathedral Church of Worcester", "Venus", "December 7, 1941", "the endocrine gland", "Kerri Strug", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "EA-18G Growler carrier-based electronic warfare jet aircraft", "95 AD", "170", "\"Sesame Street's\" Grover,", "Carol McFall,", "free lance", "Caspian Sea", "Christ Auxilio Chapel", "1922 to 1991"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5151041666666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-6762", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-229", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_newsqa-validation-4053", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_searchqa-validation-16068", "mrqa_naturalquestions-validation-7080"], "SR": 0.453125, "CSR": 0.5097257653061225, "EFR": 0.9714285714285714, "Overall": 0.6849027423469388}, {"timecode": 98, "before_eval_results": {"predictions": ["he first kicked off his presidential run.", "Afghanistan's", "digging at the site", "suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and", "his health and about a comeback.", "poems", "then-Sen. Obama,", "Gloria Allred,", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-2 victory.", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Mobile County Circuit Judge Herman Thomas", "e-mail.", "for nearly 200,000 Iraqi citizens in infrastructure, industrial projects, support services and other business activities.", "Phillip Myers,", "I showed up at WAHR with the record that would play my theme song, \"Swingin' Down the Lane.\"", "share personal information.\"", "British", "Mohammed Mohsen Zayed,", "al-Maliki", "France", "\"It was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\"", "henry ford", "over Oscar de la Hoya, Britain's Ricky Hatton and Cotto.", "Austin, Texas,", "17-month", "pay him a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party centered around Rush Limbaugh.", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983.", "improve health and beauty.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Derek Mears", "\"we take this issue seriously,\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "five", "Haeftling,", "on the side table", "Asuka", "Bart Millard", "nanz", "stone arch", "jMW Turner", "the Marx Brothers film", "Indian drama television series", "early 20th-century", "a hostage", "Shakespeare in Love", "w. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5396406708616461}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, false, true, true], "QA-F1": [0.11764705882352941, 1.0, 0.0, 0.9210526315789475, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 0.0, 0.38095238095238093, 0.7272727272727272, 0.0, 0.11764705882352941, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2284", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-3008", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-2610", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2749", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3049", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.421875, "CSR": 0.5088383838383839, "EFR": 0.972972972972973, "Overall": 0.6850341463622713}, {"timecode": 99, "UKR": 0.64453125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.791015625, "KG": 0.46484375, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "more motion picture musical song scores", "Oregon Ducks", "Arkansas", "2011 Pulitzer Prize", "Golden Gate", "GZA, \"Grandmasters\"", "Broadcasting House in London", "a teenage high school student", "detective Stan \" Wojo\" Wojciehowicz", "Lily Hampton", "President of the United States", "American singer-songwriter Taylor Swift", "constant support from propaganda campaigns", "What's Up", "Saturday Night Live", "strongly associated with Gaia and Cybele", "Tumi Holdings, Inc.", "Black Ravens", "smith", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Bardstown", "Abraham \"Grampa\" Simpson", "25 million", "Athenion", "James G. Kiernan", "smith", "Naval Weapons Station Yorktown", "North African Arab", "Linda Ronstadt", "English", "August 2013", "the Neotropical realm", "Irene Cara", "five-time", "Stephen John Coogan", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "a competitor or team in a sport or other tournament who is given a preliminary ranking for the purposes of the draw", "Frank Zappa", "1989", "red apples", "fred Trueman", "Scotland", "Capt. Chesley \"Sully\" Sullenberger", "smner", "Friday,", "Lifeboat", "a yottabyte", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6623214285714285}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666666, 0.8, 1.0, 0.8, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2031", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-882", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-5774", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-5160", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2083", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.53125, "CSR": 0.5090625, "EFR": 1.0, "Overall": 0.681890625}]}