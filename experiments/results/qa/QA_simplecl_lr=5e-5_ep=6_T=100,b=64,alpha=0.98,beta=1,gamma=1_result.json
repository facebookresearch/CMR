{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/QA_simplecl_lr=5e-5_ep=6_T=100,b=64,alpha=0.98,beta=1,gamma=1', gradient_accumulation_steps=1, kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=5, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=6.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=10, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/QA_simplecl_lr=5e-5_ep=6_T=100,b=64,alpha=0.98,beta=1,gamma=1_result.json', submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.98,beta=1,gamma=1.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 1968, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Earth ocean landing", "as soon as they enter into force", "Warszowa", "1966", "270,000", "planning,[citation needed] design, and financing", "The Master is the Doctor's archenemy", "William Morris", "30%", "civilize the inferior", "automatically assigned addresses, updated the distributed namespace, and configured any required inter-network routing", "up to 2,500", "Sierra Freeway", "if they could kill us all, they would gladly do so", "outdated or only approproriate", "numeracy", "chorale cantatas", "respiration", "Gottfried Semper", "individual states and territories", "large differences in household income", "it pledged allegiance to al-Qaeda", "Cologne", "small islands", "Gottfried Fritschel", "semi-legal", "The force, therefore, is related directly to the difference in potential energy between two different locations in space", "1500 \u00b0C", "a freshwater lake", "Justin Tucker", "factories", "Adolf Galland", "gradient of potentials", "6000 Da", "Six", "Merkits", "Pittsburgh Steelers", "Richard Leakey", "Iran", "San Francisco Bay Area's Levi's Stadium", "The Secret Life of Pets", "Prussia", "two", "Sky+HD Box", "Super Bowl LI", "Mongolian patrimonial feudalism and the traditional Chinese autocratic-bureaucratic system", "shipping", "C\u00e9vennes mountain region", "Sun Life Stadium", "a small Dagger", "Santa Clara University", "15%\u201316%", "experience, ideology, and weapons", "two", "Herodotus", "13th", "A probabilistic Turing machine", "Donald Davies", "45,000 pounds", "stereoscopic", "the Great and General Court of the Massachusetts Bay Colony", "highly diversified", "the trial and rehabilitation of Joan of Arc", "preached eight sermons"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7762517507002801}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.14285714285714288, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3879", "mrqa_squad-validation-7698", "mrqa_squad-validation-5603", "mrqa_squad-validation-4789", "mrqa_squad-validation-4817", "mrqa_squad-validation-2368", "mrqa_squad-validation-6210", "mrqa_squad-validation-7571", "mrqa_squad-validation-9715", "mrqa_squad-validation-10472", "mrqa_squad-validation-6696", "mrqa_squad-validation-495", "mrqa_squad-validation-133", "mrqa_squad-validation-600", "mrqa_squad-validation-8410", "mrqa_squad-validation-164", "mrqa_squad-validation-6219", "mrqa_squad-validation-9274"], "SR": 0.71875, "CSR": 0.71875, "EFR": 1.0, "Overall": 0.859375}, {"timecode": 1, "before_eval_results": {"predictions": ["England", "> 45\u201360 nanometers across", "representatives elected to either house of parliament", "counterflow", "field trips", "the founding of new Protestant churches", "7 January 1943", "Behind the Sofa", "iTunes", "non-Mongol physicians", "1916", "Samarkand", "Super Bowl XXXIII", "Muslim Iberia", "peacekeeping", "Kurt H. Debus", "effective planning", "18%", "GPS", "25", "15 February 1763", "Percy Shelley", "Guglielmo Marconi", "ozone", "3:08", "1,000 m3/s (35,000 cu ft/s)", "one-eighth", "solid economic growth", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "Ticonderoga", "dealing with patients' prescriptions and patient safety issues", "1802", "old oil was withdrawn from the market", "justice and prosperity", "$1.2 billion", "ash tree", "Central business districts", "Colorado River", "Cam Newton", "\"The Waters of Mars\"", "1830", "\"Bricks for Warsaw\"", "any professional", "in the parts of the internal canal network under the comb rows", "Allston Science Complex", "changed the host interface to X.25", "cyclic photophosphorylation", "without", "University of Chicago Laboratory Schools", "4.95 mL", "Mike Carey", "yellow fever", "8 mm cine film", "notNP-complete", "2009", "divergent boundaries", "longitudinal waves", "bad air", "7,000", "tractors, motorcycle (without much success) and even automobiles", "Hashimoto's thyroiditis, rheumatoid arthritis, diabetes mellitus type 1, and systemic lupus erythematosus", "Anabaptists", "a political focus", "Isla Grande de Tierra del Fuego"], "metric_results": {"EM": 0.75, "QA-F1": 0.7982413419913419}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285714, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8787", "mrqa_squad-validation-1877", "mrqa_squad-validation-4311", "mrqa_squad-validation-2976", "mrqa_squad-validation-6345", "mrqa_squad-validation-3704", "mrqa_squad-validation-2192", "mrqa_squad-validation-4834", "mrqa_squad-validation-4029", "mrqa_squad-validation-3555", "mrqa_squad-validation-7230", "mrqa_squad-validation-1790", "mrqa_squad-validation-4875", "mrqa_squad-validation-3275", "mrqa_squad-validation-6444", "mrqa_naturalquestions-validation-8450"], "SR": 0.75, "CSR": 0.734375, "EFR": 0.9375, "Overall": 0.8359375}, {"timecode": 2, "before_eval_results": {"predictions": ["Orthogonal components", "porcelain, cloth and wallpaper", "21 to 11", "Several D&B contractors", "the forts Shirley had erected at the Oneida carry", "the Peace of Westphalia", "colonies", "the Decalogue (the Ten Commandments) and the Lord's Prayer", "combustion", "since the 1950s", "St. George's United Methodist Church", "through sponsors", "reminding their countrymen of injustice", "1698", "1936", "The Premier of Victoria is the leader of the political party or coalition with the most seats in the Legislative Assembly", "Mediterranean geography", "four", "Brandon Marshall", "motivated students", "the Scottish Government", "2020", "AvtoZ AZ", "student-teacher relationships", "theory of general relativity", "Yinchuan", "tiger team", "Queen Elizabeth", "latent heat", "northwest", "Mohawk Chief Hendrick", "Emperor Chengzong", "1413", "Paul Rand", "the Romantic Rhine", "rapid proliferationosis", "the rediscovery of \"Christ and His salvation\"", "$2.50 per AC horsepower royalty", "recant his writings", "emotional contagion", "the Shoushi Li", "Shiphrah and Puah", "Lutheran and Reformed", "the 16th and 17th centuries", "Jin", "James Hutton", "Warsaw Uprising Museum", "defensins", "Thomas Edison and Nikola Tesla", "an H+ or hydrogen ion gradient", "several", "trial division", "Ernest Gimson", "2", "the Golden Horde", "The Presiding Officer", "Lord's Enclosure", "the city council", "relationship contracting", "39", "1968", "Bachendri Pal", "Roman Reigns", "Saphira hatches from the stone"], "metric_results": {"EM": 0.75, "QA-F1": 0.7808458751393534}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913043, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-982", "mrqa_squad-validation-10251", "mrqa_squad-validation-2391", "mrqa_squad-validation-3477", "mrqa_squad-validation-2854", "mrqa_squad-validation-189", "mrqa_squad-validation-1960", "mrqa_squad-validation-1007", "mrqa_squad-validation-6545", "mrqa_squad-validation-8234", "mrqa_squad-validation-1535", "mrqa_squad-validation-8906", "mrqa_squad-validation-5599", "mrqa_squad-validation-6285", "mrqa_squad-validation-639", "mrqa_naturalquestions-validation-2873"], "SR": 0.75, "CSR": 0.7395833333333333, "EFR": 0.9375, "Overall": 0.8385416666666666}, {"timecode": 3, "before_eval_results": {"predictions": ["ozone", "1936", "Vistula River", "craftsmanship", "CFTO-TV", "The Reconstruction of Religious Thought in Islam", "2009", "Metropolitan Police Authority", "80 million", "British Gas plc", "Frederick II the Great", "several years", "Wars of Religion", "thylakoid network", "John Fox", "about 45\u201360 nanometers", "the Privy Council", "break off the cathode, pass out of the tube, and physically strike him", "1933", "Christian", "killer T cells", "Book of Exodus", "five", "Thomson", "the owner", "Scottish law", "David Wilkie", "fossil animal shells", "eukaryotes", "Japan", "the usual counterflow cycle", "US$1,000,000", "Sierra Sky Park Airport", "second", "Recognized Student Organizations", "June 6, 1951", "case law by the Court of Justice, international law and general principles", "The Earth's mantle", "early vertebrates", "as part of a rule connected with civil disobedience", "fear of their lives", "APCs", "Arley D. Cathey", "90\u00b0", "cytokine TTF-\u03b2", "coal", "the political party or coalition with the most seats", "1964\u20131965", "Lagos and Quiberon Bay", "66\u201334 Mya", "random noise", "\u00a341,004", "allocution", "Millingen aan de Rijn", "double", "western European", "Archbishop of Westminster", "general relativity", "Western", "late 19th century", "Joanne Wheatley", "The term is now usually associated with the United States soldiers during the world wars who used their knowledge of Native American languages", "Membership is believed to cost between $10,000 and $30,000", "a judicial officer"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8332133472758473}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333336, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.846153846153846, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.16216216216216214, 0.4666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8789", "mrqa_squad-validation-1388", "mrqa_squad-validation-9640", "mrqa_squad-validation-5519", "mrqa_squad-validation-3310", "mrqa_squad-validation-4698", "mrqa_squad-validation-3950", "mrqa_squad-validation-6719", "mrqa_squad-validation-7974", "mrqa_squad-validation-6523", "mrqa_squad-validation-2852", "mrqa_squad-validation-7622", "mrqa_squad-validation-6737", "mrqa_squad-validation-3296", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2476"], "SR": 0.734375, "CSR": 0.73828125, "EFR": 0.8823529411764706, "Overall": 0.8103170955882353}, {"timecode": 4, "before_eval_results": {"predictions": ["Marie de' Medici", "illegal boycotts", "exothermic reaction", "1735", "reflects the structure and substance of his questions and answers concerning baptism in the Small Catechism", "tidal currents", "silver", "mad dogs", "E. W. Scripps Company", "fermionic nature of electrons", "LeGrande", "Mexico\u2013United States border", "90-60's", "1720", "Battle of Hastings", "circuit switching", "nucleomorph", "WatchESPN", "sexual misconduct", "1220", "article 30", "Seine", "gain support from China", "2001", "type III secretion system", "Great Exhibition of 1851", "produce both eggs and sperm at the same time", "Mark I Type 40 T", "The Scottish Parliament", "one of his wife's ladies-in-waiting", "rotary", "Ancient Greeks", "were able to fund travelers who would come back with tales of their discoveries", "Peninsular Ranges", "missing self", "Queen Victoria", "Small Catechism", "layered basaltic lava flows", "four", "Theatre Royal", "an electric lighting company in Tesla's name", "His Biblical ideal of congregations' choosing their own ministers", "December 28, 2015", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "BankAmericard", "WTRF-TV", "a board of trustees", "between the 1960s and 1990s", "1967", "Beyonc\u00e9 and Bruno Mars", "beroids", "(trunnion", "William the Conqueror", "24 March 1879", "New York hotels", "1521", "1882", "Michael Heckenberger and colleagues of the University of Florida", "Jacksonville", "Gene MacLellan", "Pashto and Persian", "1991", "Spanish explorers", "CBS"], "metric_results": {"EM": 0.796875, "QA-F1": 0.8496926695616212}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.88, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3101", "mrqa_squad-validation-6848", "mrqa_squad-validation-3602", "mrqa_squad-validation-2448", "mrqa_squad-validation-479", "mrqa_squad-validation-6058", "mrqa_squad-validation-2657", "mrqa_squad-validation-8452", "mrqa_squad-validation-7370", "mrqa_squad-validation-9750", "mrqa_squad-validation-2466", "mrqa_squad-validation-4147", "mrqa_naturalquestions-validation-8947"], "SR": 0.796875, "CSR": 0.75, "EFR": 0.9230769230769231, "Overall": 0.8365384615384616}, {"timecode": 5, "UKR": 0.787109375, "before_eval_results": {"predictions": ["England", "Asia", "pathogen attack", "def a direct order of Pharaoh but misrepresented how they did it", "up to 3 pence in the pound", "one out of every six produced", "30 to 50 thousand inhabitants", "Von Miller", "Ryan Kalil", "Indianapolis Colts", "banded iron", "the problem of multiplying two integers", "1975", "11 million", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "the courts of member states", "13", "John Hurt", "William Booth", "July", "$38,000", "circular", "Queen Victoria and Prince Albert", "Tesla", "a Western Union superintendent", "Lower doses of anti-inflammatory drugs", "protein structure prediction", "1937", "high", "Santer Commission", "phagocytes", "Tate Britain", "necessity rather than opportunity", "hundreds", "a painting", "Larger Catechism", "over 200", "telecommunications", "John B. Goodenough", "Walt Disney Presents", "Turing machines", "alleged complicity and to Odinga declaring himself the \"people's president\" and calling for a recount", "Numerical models", "proposed to build a nationwide network in the UK", "Lombardi Trophy", "R\u0113nos", "socially owned", "oldest street in the United States of America", "president of NBC's entertainment division", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "Saxon Garden", "Anglo-Saxon", "Duke Kent- Brown", "seven", "arranged marriages", "assassination of US President John F. Kennedy", "two", "the original message/data is reassembled in the correct order, based on the packet sequence number", "Justice A.K Mathur will be heading the Seventh Pay Commission", "the ultimate exercise for the bored and lazy ''", "Sherwood Forest were filmed on location in the United Kingdom", "By 1912, major motion - picture companies had set up production near or in Los Angeles", "Old Trafford", "Guy Carawan"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7875680856971976}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809525, 1.0, 0.2, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.3636363636363636, 0.125, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6992", "mrqa_squad-validation-8888", "mrqa_squad-validation-337", "mrqa_squad-validation-1766", "mrqa_squad-validation-7430", "mrqa_squad-validation-8816", "mrqa_squad-validation-6513", "mrqa_squad-validation-8422", "mrqa_squad-validation-4629", "mrqa_squad-validation-404", "mrqa_squad-validation-9243", "mrqa_squad-validation-7516", "mrqa_squad-validation-8811", "mrqa_squad-validation-1108", "mrqa_squad-validation-6945", "mrqa_naturalquestions-validation-10372", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-1015", "mrqa_naturalquestions-validation-444"], "SR": 0.703125, "CSR": 0.7421875, "EFR": 0.9473684210526315, "Overall": 0.8447779605263157}, {"timecode": 6, "before_eval_results": {"predictions": ["8 November 2010", "Lek", "behind the foot of the mast", "Business Connect", "Red Turban rebels", "Arizona Cardinals", "Maxwell", "independence from the Duke of Savoy through an alliance between the city-state of Geneva and the Swiss Confederation", "Mongol and Turkic tribes", "San Jose", "sequential hermaphrodites", "a protest that blocked heavy traffic passing over the A13, Brenner Autobahn, en route to Italy", "Pittsburgh", "Solim\u00f5es Basin", "married outside their immediate French communities", "protect their tribal lands from commercial interests", "Destiny of the Doctor", "the Lunar Roving Vehicle", "buildings, infrastructure and industrial", "1,600 miles", "various disciplines of pharmacy", "a plastid that lacks chlorophyll", "Tyne and wear Metro", "the power of the Papacy", "fifteen", "black", "baptism", "6 December 1989", "Vietnam", "congresses and presidents", "town of the Ubii", "\"an important game for us as a league\"", "Christmas Day specials", "Innate immune systems", "two or more teachers", "Golden Gate Bridge", "they contain striated muscle", "HD", "phosphate", "$5,000,000", "\u00d6gedei Khan", "38\u201341 \u00b0C (100\u2013106 \u00b0F)", "phowa and siddhi", "if the head of government of a country were to refuse to enforce a decision of that country's highest court", "accrediting teacher education programs", "Transpac", "in school at a given time in the school day (such as lunch, recess or after school); or even to attend school on a non-school day", "Cyanobacteria", "the Quaternary period", "shamanist, Buddhist or Christian", "filaments", "Boomer Esiason and Dan Fouts", "he did not want disloyal men in his army", "a \"world classic of epoch-making oratory.\"", "18 February 1546", "terminating Tesla's relationship with Morgan", "Al-Biruni", "it was hosted by the most recent Super Bowl champions", "11 : 15 p.m., when a passing train will hide any sounds", "Hirschman", "USCS or USC", "Zeus and Bailey both watch Charlie doing what he was meant to do, and are touched by seeing him literally fighting for his son", "1987", "a gestational age of approximately 7 weeks and 5 days"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7899796365914787}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.38095238095238093, 0.0, 1.0, 0.08333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7142857142857143, 0.0, 1.0, 0.0, 0.07999999999999999, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3044", "mrqa_squad-validation-4332", "mrqa_squad-validation-2253", "mrqa_squad-validation-1912", "mrqa_squad-validation-3624", "mrqa_squad-validation-4811", "mrqa_squad-validation-6806", "mrqa_squad-validation-1909", "mrqa_squad-validation-1941", "mrqa_squad-validation-8899", "mrqa_squad-validation-1467", "mrqa_squad-validation-6465", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-10562", "mrqa_naturalquestions-validation-8116"], "SR": 0.734375, "CSR": 0.7410714285714286, "EFR": 0.8235294117647058, "Overall": 0.7823004201680672}, {"timecode": 7, "before_eval_results": {"predictions": ["Bell Northern Research", "Pole Mokotowskie", "Alfred Stevens", "National Football League", "English", "Levi's Stadium", "Auckland", "every five years", "use in chloroplast division", "an 8\u20134\u20134 system", "Kenyan Coast", "Economist Intelligence Unit", "to clean them of plants and sediments", "comedies and family-oriented", "1011", "October 2006", "Federica Mogherini", "three", "October 12, 1943", "Guo Shoujing", "Science and Discovery", "Kevin Harlan", "in school", "the tangential force", "Warszawa", "Non Governmental and Intergovernmental Organizations", "demolished", "Political geographers", "5 nanometers across", "alone", "Terry Nation", "Charly", "God's wrath to Christians", "human rights violations", "Jonathan Stewart", "John the Steadfast", "automobiles", "another problem", "petroleum and aircraft manufacturing", "Galileo", "Divine Right of Kings", "NL and NC", "EXPTIME", "Japan", "greenhouse gas", "\"Doctorin' the Tardis\"", "a religious basis", "interacting and working directly with students", "Jingshi Dadian", "the \"grey literature\"", "the incentive for the democratic changes", "pathogen", "Paris", "the Jews", "woodblocks", "savanna or desert", "the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "Mandy", "infection, irritation, or allergies", "on the inner edge of the Nebula Arm, one of the spiral - shaped concentrations of gas and dust", "13 June 1990", "the leaves of the plant species Stevia rebaudiana", "Reuben Kincaid", "Jerry Ekandjo"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7960700757575758}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.1818181818181818, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 1.0, 0.4, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9", "mrqa_squad-validation-132", "mrqa_squad-validation-8649", "mrqa_squad-validation-4182", "mrqa_squad-validation-5168", "mrqa_squad-validation-1941", "mrqa_squad-validation-8526", "mrqa_squad-validation-9748", "mrqa_squad-validation-7614", "mrqa_squad-validation-2704", "mrqa_squad-validation-9597", "mrqa_squad-validation-8514", "mrqa_naturalquestions-validation-2578", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-7754", "mrqa_naturalquestions-validation-6445"], "SR": 0.71875, "CSR": 0.73828125, "EFR": 0.8888888888888888, "Overall": 0.8135850694444444}, {"timecode": 8, "before_eval_results": {"predictions": ["Hospitality Business/financial Centre", "natural grass stadiums", "socially owned", "steam turbines", "in protest against the occupation of Prussia by Napoleon", "10 years", "one of the toughest rallies in the world", "Lowry Digital", "greatest common divisor is one", "Super Bowl Opening Night", "Nairobi's Harambee House", "1906", "Book of Exodus", "nearly three hundred years", "a fee per unit of information transmitted, such as characters, packets, or messages", "highly-paid", "$105 billion", "66 million years ago", "Unemployment", "1941", "over-fishing and long-term environmental changes that promoted the growth of the Mnemiopsis population", "General Hospital", "Wang Zhen's", "William III of Orange", "two \"coordinating lead authors\", ten to fifteen \"lead authors\", and a somewhat larger number of \"contributing authors\"", "1,160,000 square miles", "teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting", "Oriental Institute", "teacher's colleges", "Lippe", "majority of the seats", "an integral part of Aristotelian cosmology", "the Arabs and much of the rest of the Third World", "Mark Twain's", "1636", "TEU articles 4 and 5", "North America", "homicides", "technologies and ideas", "5", "Skaro", "Lunar Module Pilot", "the mouth of the Monongahela River", "1529", "since 2001", "487", "Big Ten Conference", "Z-ring", "American Broadcasting-Paramount Theatres, Inc.", "prayed", "1875", "The Standard Industrial Classification and the newer North American Industry Classification System", "129", "steam turbine plant", "CBS Television City, studios 41 and 43 in Hollywood", "William Strauss and Neil Howe", "commercial at", "first was from 1916 to 1920, the second from 1939 to 1960, with the last conscripted soldiers leaving the service in 1963", "Justin Timberlake", "Emma Watson and Dan Stevens", "hydrogen and oxygen", "point that lies either on the production possibilities curve or to the left of it is said to be an attainable point", "in humans", "Australia"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7525511893988368}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9600000000000001, 0.0, 1.0, 1.0, 1.0, 1.0, 0.625, 0.0, 0.5, 1.0, 0.5454545454545454, 0.5, 0.17391304347826084, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.5, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9473684210526316, 0.0, 1.0, 0.1, 1.0, 0.2702702702702703, 0.28571428571428575, 0.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-448", "mrqa_squad-validation-7517", "mrqa_squad-validation-4750", "mrqa_squad-validation-7357", "mrqa_squad-validation-4318", "mrqa_squad-validation-5940", "mrqa_squad-validation-8107", "mrqa_squad-validation-8552", "mrqa_squad-validation-4383", "mrqa_squad-validation-1863", "mrqa_squad-validation-10350", "mrqa_squad-validation-1235", "mrqa_squad-validation-10136", "mrqa_squad-validation-883", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-1988", "mrqa_naturalquestions-validation-8582", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-4286", "mrqa_naturalquestions-validation-8356"], "SR": 0.640625, "CSR": 0.7274305555555556, "EFR": 0.9130434782608695, "Overall": 0.8202370169082125}, {"timecode": 9, "before_eval_results": {"predictions": ["Fran\u00e7ois, Duc d'Alen\u00e7on", "Karl von Miltitz", "at elevated partial pressures", "creating a comprehensive drug therapy plan for patient-specific problems", "Judiciary", "performance", "1986", "their own militia", "chromalveolate lineages", "Business Connect", "Henry Young Darracott Scott", "stratigraphers", "God", "Writers Guild of America", "30", "Kenyan athletes (particularly Kalenjin)", "superoxide ion (O\u22122) and hydrogen peroxide (H2O2)", "104 \u00b0F", "protein structure prediction", "green", "at various locations throughout the world", "non-Catholics", "boudins", "Presbyterian Church", "radial", "geochemical evolution of rock units", "1973\u20131974", "political innovations", "TFEU article 294", "peripheral immune system", "cancers", "Wisdom, Compassion, Justice and Integrity", "intracellular pathogenesis", "modern hatred of the Jews", "pay-per-view services", "tutor", "Van de Graaff generator", "Jason Bourne", "two", "Roger Goodell", "Brough Park in Byker", "friendly and supportive", "Official Report", "remote sensing", "on the 50-yard line", "the election of the UK Labour Party to government in 1997", "higher school fees", "L'Eglise du Saint-Esprit", "never", "Cameron", "Danny Lane", "Samuel Phillips", "1985", "pigs", "McKim Marriott", "East Asia", "China", "after 1925, the date of the widely publicized Scopes Trial in the United States, where the term first appears", "parthenogenesis", "T'Pau", "1901", "The Province then took a new name, New York", "state", "the Italian Campaign, which culminated in the downfall of the fascist government in Italy and the elimination of Germany's main European ally"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8137479114452799}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 0.0, 0.2857142857142857, 0.10526315789473684]}}, "before_error_ids": ["mrqa_squad-validation-8756", "mrqa_squad-validation-3543", "mrqa_squad-validation-6489", "mrqa_squad-validation-2741", "mrqa_squad-validation-602", "mrqa_squad-validation-5456", "mrqa_squad-validation-7131", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-734"], "SR": 0.765625, "CSR": 0.73125, "EFR": 0.9333333333333333, "Overall": 0.8322916666666667}, {"timecode": 10, "UKR": 0.759765625, "OKR_sampled_ids": ["mrqa_squad-validation-5513", "mrqa_squad-validation-8012", "mrqa_squad-validation-8204", "mrqa_naturalquestions-validation-444", "mrqa_squad-validation-4960", "mrqa_squad-validation-9447", "mrqa_squad-validation-9785", "mrqa_squad-validation-4561", "mrqa_squad-validation-3695", "mrqa_squad-validation-571", "mrqa_squad-validation-9274", "mrqa_naturalquestions-validation-10268", "mrqa_squad-validation-7608", "mrqa_squad-validation-5480", "mrqa_squad-validation-9708", "mrqa_squad-validation-7517", "mrqa_naturalquestions-validation-6469", "mrqa_squad-validation-1295", "mrqa_squad-validation-7131", "mrqa_squad-validation-1998", "mrqa_squad-validation-7430", "mrqa_squad-validation-3339", "mrqa_squad-validation-8127", "mrqa_squad-validation-5084", "mrqa_squad-validation-9664", "mrqa_squad-validation-146", "mrqa_squad-validation-1287", "mrqa_squad-validation-4808", "mrqa_squad-validation-3394", "mrqa_naturalquestions-validation-9765", "mrqa_squad-validation-1912", "mrqa_squad-validation-1954", "mrqa_squad-validation-8313", "mrqa_squad-validation-872", "mrqa_squad-validation-3545", "mrqa_squad-validation-9895", "mrqa_squad-validation-479", "mrqa_squad-validation-297", "mrqa_squad-validation-6367", "mrqa_squad-validation-189", "mrqa_squad-validation-702", "mrqa_squad-validation-83", "mrqa_squad-validation-7654", "mrqa_squad-validation-8899", "mrqa_naturalquestions-validation-2476", "mrqa_squad-validation-8209", "mrqa_squad-validation-9671", "mrqa_squad-validation-9326", "mrqa_squad-validation-6907", "mrqa_squad-validation-9956", "mrqa_squad-validation-424", "mrqa_squad-validation-9490", "mrqa_squad-validation-3727", "mrqa_squad-validation-10465", "mrqa_squad-validation-3698", "mrqa_squad-validation-5140", "mrqa_squad-validation-9442", "mrqa_squad-validation-9901", "mrqa_squad-validation-5599", "mrqa_squad-validation-164", "mrqa_naturalquestions-validation-1500", "mrqa_squad-validation-10442", "mrqa_squad-validation-2854", "mrqa_squad-validation-9322", "mrqa_squad-validation-4934", "mrqa_squad-validation-3062", "mrqa_squad-validation-4078", "mrqa_squad-validation-7646", "mrqa_squad-validation-6576", "mrqa_squad-validation-6105", "mrqa_squad-validation-4076", "mrqa_squad-validation-7150", "mrqa_squad-validation-2949", "mrqa_squad-validation-3950", "mrqa_squad-validation-8003", "mrqa_squad-validation-9587", "mrqa_squad-validation-6621", "mrqa_squad-validation-1663", "mrqa_squad-validation-6945", "mrqa_squad-validation-416", "mrqa_squad-validation-4472", "mrqa_squad-validation-417", "mrqa_squad-validation-5023", "mrqa_squad-validation-5132", "mrqa_squad-validation-8991", "mrqa_squad-validation-10356", "mrqa_squad-validation-2448", "mrqa_squad-validation-4099", "mrqa_squad-validation-5902", "mrqa_squad-validation-6688", "mrqa_squad-validation-8816", "mrqa_squad-validation-5536", "mrqa_squad-validation-1955", "mrqa_squad-validation-2250", "mrqa_naturalquestions-validation-851", "mrqa_squad-validation-2645", "mrqa_squad-validation-5701", "mrqa_squad-validation-94", "mrqa_squad-validation-9705", "mrqa_squad-validation-132", "mrqa_squad-validation-2018", "mrqa_squad-validation-6770", "mrqa_squad-validation-8906", "mrqa_squad-validation-1123", "mrqa_squad-validation-6993", "mrqa_squad-validation-6465", "mrqa_squad-validation-1467", "mrqa_squad-validation-9430", "mrqa_squad-validation-1981", "mrqa_squad-validation-1323", "mrqa_squad-validation-5498", "mrqa_squad-validation-9243", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-4295", "mrqa_squad-validation-3736", "mrqa_squad-validation-5350", "mrqa_squad-validation-7370", "mrqa_squad-validation-8811", "mrqa_squad-validation-8952", "mrqa_squad-validation-2482", "mrqa_squad-validation-8756", "mrqa_squad-validation-404", "mrqa_squad-validation-9298", "mrqa_squad-validation-6345", "mrqa_squad-validation-5296", "mrqa_squad-validation-8969", "mrqa_squad-validation-8226", "mrqa_squad-validation-2741", "mrqa_squad-validation-9537", "mrqa_squad-validation-7584", "mrqa_squad-validation-3270", "mrqa_squad-validation-9750", "mrqa_squad-validation-6366", "mrqa_squad-validation-6696", "mrqa_squad-validation-3477", "mrqa_squad-validation-10228", "mrqa_squad-validation-3044", "mrqa_squad-validation-887", "mrqa_squad-validation-3925", "mrqa_squad-validation-6651", "mrqa_squad-validation-6868", "mrqa_naturalquestions-validation-7754", "mrqa_squad-validation-4230", "mrqa_squad-validation-9799", "mrqa_naturalquestions-validation-1491", "mrqa_squad-validation-426", "mrqa_squad-validation-9276", "mrqa_squad-validation-3236", "mrqa_naturalquestions-validation-934", "mrqa_squad-validation-557", "mrqa_squad-validation-6999", "mrqa_squad-validation-2382", "mrqa_squad-validation-6217", "mrqa_squad-validation-5334", "mrqa_naturalquestions-validation-2578", "mrqa_squad-validation-9009", "mrqa_squad-validation-7859", "mrqa_squad-validation-8514", "mrqa_squad-validation-7980", "mrqa_naturalquestions-validation-8450", "mrqa_squad-validation-8789", "mrqa_squad-validation-10056", "mrqa_squad-validation-2466", "mrqa_squad-validation-2647", "mrqa_squad-validation-8355", "mrqa_squad-validation-4337", "mrqa_squad-validation-1960", "mrqa_squad-validation-1042", "mrqa_squad-validation-8042", "mrqa_squad-validation-3070", "mrqa_squad-validation-4085", "mrqa_squad-validation-8197", "mrqa_squad-validation-4274", "mrqa_squad-validation-3310", "mrqa_squad-validation-5973", "mrqa_squad-validation-883", "mrqa_squad-validation-7251", "mrqa_squad-validation-244", "mrqa_squad-validation-5051", "mrqa_squad-validation-2192", "mrqa_squad-validation-8948", "mrqa_squad-validation-8868", "mrqa_squad-validation-9748", "mrqa_squad-validation-7321", "mrqa_squad-validation-8072", "mrqa_squad-validation-8186", "mrqa_squad-validation-8787", "mrqa_squad-validation-10418", "mrqa_squad-validation-9641", "mrqa_squad-validation-3774", "mrqa_squad-validation-5456", "mrqa_squad-validation-4639", "mrqa_squad-validation-648", "mrqa_naturalquestions-validation-2280", "mrqa_squad-validation-6040", "mrqa_squad-validation-8353", "mrqa_squad-validation-9453", "mrqa_squad-validation-3397", "mrqa_squad-validation-5092", "mrqa_squad-validation-3683", "mrqa_squad-validation-7846", "mrqa_naturalquestions-validation-8215", "mrqa_squad-validation-4734", "mrqa_naturalquestions-validation-2890", "mrqa_squad-validation-10369", "mrqa_squad-validation-9645", "mrqa_squad-validation-9597", "mrqa_squad-validation-2070", "mrqa_squad-validation-3133", "mrqa_squad-validation-861", "mrqa_squad-validation-337", "mrqa_squad-validation-7974", "mrqa_squad-validation-3550", "mrqa_squad-validation-8649", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-2633", "mrqa_squad-validation-5057", "mrqa_squad-validation-5098", "mrqa_squad-validation-6569", "mrqa_squad-validation-773", "mrqa_squad-validation-1329", "mrqa_squad-validation-1609", "mrqa_squad-validation-7175", "mrqa_squad-validation-7692", "mrqa_squad-validation-291", "mrqa_squad-validation-1752", "mrqa_squad-validation-4945", "mrqa_squad-validation-8234", "mrqa_squad-validation-3101", "mrqa_naturalquestions-validation-6095", "mrqa_squad-validation-9771", "mrqa_squad-validation-2097", "mrqa_squad-validation-7149", "mrqa_squad-validation-4844", "mrqa_squad-validation-2368", "mrqa_squad-validation-8455", "mrqa_squad-validation-4023", "mrqa_squad-validation-5987", "mrqa_squad-validation-5649", "mrqa_squad-validation-6054", "mrqa_squad-validation-6295", "mrqa_squad-validation-6127", "mrqa_squad-validation-1872", "mrqa_squad-validation-2790", "mrqa_squad-validation-10296", "mrqa_squad-validation-7906", "mrqa_squad-validation-7915", "mrqa_squad-validation-4875", "mrqa_naturalquestions-validation-3477", "mrqa_squad-validation-7107", "mrqa_squad-validation-9208", "mrqa_squad-validation-8598", "mrqa_squad-validation-646", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-10406", "mrqa_squad-validation-6219", "mrqa_squad-validation-448", "mrqa_squad-validation-462", "mrqa_squad-validation-1218", "mrqa_squad-validation-2448", "mrqa_squad-validation-1132", "mrqa_squad-validation-6714", "mrqa_squad-validation-820", "mrqa_squad-validation-2321", "mrqa_squad-validation-3948", "mrqa_squad-validation-742", "mrqa_squad-validation-2390", "mrqa_squad-validation-6523", "mrqa_squad-validation-8410", "mrqa_squad-validation-6210", "mrqa_squad-validation-2332", "mrqa_squad-validation-4817", "mrqa_naturalquestions-validation-4768", "mrqa_squad-validation-2508", "mrqa_squad-validation-4031", "mrqa_squad-validation-2854", "mrqa_squad-validation-955", "mrqa_squad-validation-3278", "mrqa_squad-validation-4204", "mrqa_squad-validation-2673", "mrqa_squad-validation-6861", "mrqa_squad-validation-804", "mrqa_squad-validation-8320", "mrqa_squad-validation-6720", "mrqa_squad-validation-7162", "mrqa_naturalquestions-validation-1144", "mrqa_squad-validation-6876", "mrqa_squad-validation-1119", "mrqa_squad-validation-8384", "mrqa_squad-validation-9788", "mrqa_squad-validation-2309", "mrqa_squad-validation-7674", "mrqa_squad-validation-4318", "mrqa_squad-validation-2113", "mrqa_squad-validation-5230", "mrqa_squad-validation-7389", "mrqa_squad-validation-7108", "mrqa_squad-validation-3265", "mrqa_squad-validation-5347", "mrqa_squad-validation-3091", "mrqa_squad-validation-7491", "mrqa_squad-validation-36", "mrqa_squad-validation-6116", "mrqa_squad-validation-7614", "mrqa_squad-validation-1941", "mrqa_squad-validation-10032", "mrqa_squad-validation-3280", "mrqa_squad-validation-2609", "mrqa_squad-validation-1909", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-495", "mrqa_squad-validation-602", "mrqa_squad-validation-5421", "mrqa_squad-validation-10500", "mrqa_squad-validation-7890", "mrqa_squad-validation-1316", "mrqa_squad-validation-1535", "mrqa_squad-validation-7735", "mrqa_squad-validation-6521", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-4710", "mrqa_squad-validation-8899", "mrqa_squad-validation-3259", "mrqa_squad-validation-1541", "mrqa_squad-validation-4147", "mrqa_squad-validation-5995", "mrqa_squad-validation-2704", "mrqa_squad-validation-1863", "mrqa_squad-validation-8877", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-1015", "mrqa_squad-validation-9928", "mrqa_squad-validation-3602", "mrqa_squad-validation-600", "mrqa_squad-validation-1824", "mrqa_squad-validation-10244", "mrqa_squad-validation-8159", "mrqa_squad-validation-5932", "mrqa_squad-validation-7857", "mrqa_squad-validation-9745", "mrqa_naturalquestions-validation-8947", "mrqa_squad-validation-835", "mrqa_squad-validation-1388", "mrqa_squad-validation-6719", "mrqa_squad-validation-6360", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-5255", "mrqa_squad-validation-3624", "mrqa_squad-validation-4029", "mrqa_squad-validation-3076", "mrqa_squad-validation-2471", "mrqa_squad-validation-7948", "mrqa_squad-validation-2419", "mrqa_squad-validation-1747", "mrqa_squad-validation-2994", "mrqa_squad-validation-1685", "mrqa_squad-validation-1477", "mrqa_squad-validation-9002", "mrqa_squad-validation-460", "mrqa_squad-validation-10252", "mrqa_squad-validation-8768", "mrqa_squad-validation-2253", "mrqa_squad-validation-5881", "mrqa_squad-validation-3416", "mrqa_squad-validation-1941", "mrqa_squad-validation-4632", "mrqa_squad-validation-7230", "mrqa_squad-validation-205", "mrqa_squad-validation-4166", "mrqa_squad-validation-8552", "mrqa_squad-validation-1247", "mrqa_squad-validation-8776", "mrqa_squad-validation-6237", "mrqa_squad-validation-5550", "mrqa_squad-validation-3347", "mrqa_squad-validation-6513", "mrqa_squad-validation-4680", "mrqa_squad-validation-3543", "mrqa_squad-validation-9189", "mrqa_squad-validation-2391", "mrqa_squad-validation-8572", "mrqa_squad-validation-6379", "mrqa_squad-validation-495", "mrqa_squad-validation-299", "mrqa_squad-validation-7917", "mrqa_squad-validation-1236", "mrqa_squad-validation-6612", "mrqa_squad-validation-4146", "mrqa_squad-validation-5259", "mrqa_squad-validation-4902", "mrqa_squad-validation-7598", "mrqa_naturalquestions-validation-8161", "mrqa_squad-validation-4072", "mrqa_squad-validation-10472", "mrqa_squad-validation-64", "mrqa_squad-validation-4811", "mrqa_squad-validation-5876", "mrqa_squad-validation-3067", "mrqa_squad-validation-2147", "mrqa_naturalquestions-validation-10562", "mrqa_squad-validation-6992", "mrqa_squad-validation-6994", "mrqa_squad-validation-4332", "mrqa_squad-validation-9715", "mrqa_squad-validation-1752", "mrqa_squad-validation-7698", "mrqa_naturalquestions-validation-642", "mrqa_squad-validation-9640", "mrqa_squad-validation-3841", "mrqa_squad-validation-4640", "mrqa_squad-validation-5322", "mrqa_squad-validation-3296", "mrqa_squad-validation-5018", "mrqa_squad-validation-9861", "mrqa_squad-validation-2247", "mrqa_squad-validation-7765", "mrqa_squad-validation-7777", "mrqa_squad-validation-5519", "mrqa_squad-validation-1040", "mrqa_squad-validation-8422", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-5584", "mrqa_squad-validation-8442", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-6019", "mrqa_squad-validation-10175", "mrqa_squad-validation-3926", "mrqa_squad-validation-4789", "mrqa_squad-validation-2281", "mrqa_squad-validation-878", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-6848", "mrqa_squad-validation-6806", "mrqa_naturalquestions-validation-6620", "mrqa_squad-validation-4629", "mrqa_squad-validation-10397", "mrqa_squad-validation-1235", "mrqa_squad-validation-8888", "mrqa_squad-validation-567", "mrqa_squad-validation-9412", "mrqa_squad-validation-3142", "mrqa_squad-validation-8242", "mrqa_squad-validation-1800", "mrqa_squad-validation-2589", "mrqa_squad-validation-8526", "mrqa_squad-validation-406", "mrqa_squad-validation-7019", "mrqa_naturalquestions-validation-9172", "mrqa_squad-validation-4236", "mrqa_squad-validation-7352", "mrqa_squad-validation-8483", "mrqa_squad-validation-4354", "mrqa_squad-validation-9913", "mrqa_squad-validation-2411", "mrqa_squad-validation-6444", "mrqa_squad-validation-2852", "mrqa_squad-validation-9635", "mrqa_naturalquestions-validation-2666", "mrqa_squad-validation-8881", "mrqa_naturalquestions-validation-6298", "mrqa_squad-validation-1343", "mrqa_squad-validation-7571", "mrqa_squad-validation-4311", "mrqa_squad-validation-3275", "mrqa_squad-validation-6245", "mrqa_squad-validation-9170", "mrqa_squad-validation-7516", "mrqa_squad-validation-447", "mrqa_squad-validation-7622", "mrqa_naturalquestions-validation-9410", "mrqa_squad-validation-708", "mrqa_squad-validation-4595", "mrqa_squad-validation-6685", "mrqa_squad-validation-3028", "mrqa_squad-validation-8630", "mrqa_naturalquestions-validation-6665", "mrqa_squad-validation-4744", "mrqa_squad-validation-4176", "mrqa_naturalquestions-validation-1988", "mrqa_squad-validation-2875", "mrqa_squad-validation-613", "mrqa_squad-validation-5072", "mrqa_squad-validation-10403", "mrqa_squad-validation-10392", "mrqa_squad-validation-7921", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-2999", "mrqa_squad-validation-1790", "mrqa_squad-validation-499", "mrqa_squad-validation-8107", "mrqa_squad-validation-2133", "mrqa_squad-validation-6285", "mrqa_squad-validation-3495", "mrqa_naturalquestions-validation-3494", "mrqa_squad-validation-5854", "mrqa_squad-validation-8199", "mrqa_squad-validation-982", "mrqa_squad-validation-9566", "mrqa_squad-validation-10340", "mrqa_squad-validation-2415", "mrqa_squad-validation-4290", "mrqa_squad-validation-4834", "mrqa_squad-validation-8000", "mrqa_squad-validation-6810", "mrqa_squad-validation-2955", "mrqa_squad-validation-4383", "mrqa_squad-validation-5715", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-6545", "mrqa_squad-validation-5491", "mrqa_squad-validation-3611"], "OKR": 0.89453125, "KG": 0.2828125, "before_eval_results": {"predictions": ["Von Miller", "defensins and zinc", "Genghis Khan and his family", "practice areas of pharmacy", "T", "early 1938", "12 December 2007", "Paramount Building at 1501 Broadway in Manhattan", "World War I", "Cow Counties", "1 October 1998", "Super Bowl XLVII", "MF Global", "second", "Sun Life Stadium", "61%", "The Time of the Doctor", "11.4 million", "Queen Victoria and Prince Albert", "20\u201318", "a form of anthrax", "1698", "Fresno", "British progressive folk-rock band Gryphon", "Sonderungsverbot", "an inauspicious typhoon", "to \u201cwid[en] people\u2019s choices and the level of their achieved well-being\u201d", "Steymann v Staatssecretaris van Justitie", "194", "internet", "time complexity", "floor function", "proportionally to the number of votes received in the second vote of the ballot using the d'Hondt method", "1500 \u00b0C", "internal combustion engines", "Kurt Vonnegut", "The Book of Discipline", "139th out of 176 total countries in the CPI", "Super Bowl XIX", "regularly since 1979", "VA, the Indian Health Service, and NIH", "Westminster (and where Ministerial functions usually lie with UK Government ministers)", "2012", "kinetic friction force", "agriculture and silviculture", "Co-teaching", "The Arrow", "\u20ac25,000 per year", "The lab was torn down in 1904", "Lake \u00dcberlingen", "Time magazine", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "Dmitri Mendeleev", "derivative financial instrument that gives the right but not the obligation to exchange money denominated in one currency into another currency at a specified date", "April 2010", "Heliocentric model of Copernicus, Galileo and Kepler", "Curtis Armstrong", "United States", "1975", "after World War II", "Geoffrey Zakarian", "in the fascia surrounding skeletal muscle", "57", "George Harrison"], "metric_results": {"EM": 0.703125, "QA-F1": 0.786983543417367}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.8, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.1764705882352941, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6388", "mrqa_squad-validation-6511", "mrqa_squad-validation-4108", "mrqa_squad-validation-7973", "mrqa_squad-validation-5360", "mrqa_squad-validation-1701", "mrqa_squad-validation-8034", "mrqa_squad-validation-8216", "mrqa_squad-validation-168", "mrqa_squad-validation-7832", "mrqa_squad-validation-9491", "mrqa_squad-validation-1404", "mrqa_squad-validation-1637", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-6149", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-4814"], "SR": 0.703125, "CSR": 0.7286931818181819, "EFR": 1.0, "Overall": 0.7331605113636364}, {"timecode": 11, "before_eval_results": {"predictions": ["\"One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "inertia", "indigenous", "a University of North Florida team", "Matthew 16:18", "Tem\u00fclen", "1957", "secular powers", "Dorothy Skerrit", "Miller", "pulmonary fibrosis", "a social networking support that allows them to reach their full cognitive potential", "a liquid in specially insulated tankers", "more than 20", "a diatom (heterokontophyte) derived chloroplast", "higher", "patents issued to Tesla in the US", "commutative ring R", "$155 million", "the Seattle Seahawks", "Stephen Greenblatt", "11", "Teenage Mutant Ninja Turtles: Out of the Shadows", "an upper bound T(n) on the time complexity of a problem", "more equality in the income distribution", "Wide World of Sports", "a Islamic state in Palestine", "publicly announced", "oxyacetylene welding", "project structures", "dangerous enemies", "Edinburgh", "five", "Roone Arledge", "two", "2009", "between the modern Baden and W\u00fcrttemberg", "General Electric", "installed electrical arc light based illumination systems designed by Tesla and also had designs for dynamo electric machine commutators", "Greenland", "lifeforms", "Jean-Claude Juncker", "Industry and manufacturing", "Budapest Telephone Exchange", "the Uighurs surrendered to the Mongols first", "Shakespeare", "11", "1390", "Netherlands", "higher economic inequality", "a renewed attack on Archbishop Albrecht of Mainz", "Klaus Meine and Herman Rarebell", "D \u00d7 4", "Major General Clarence L. Tinker", "Kristy Swanson", "2026", "2015", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "at the fictional elite conservative Vermont boarding school Welton Academy", "Highlands County, Florida", "Matt Monro", "cutting surfaces of a milling cutter are generally made of a hard and temperature - resistant material, so that they wear slowly", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "September 27, 2017"], "metric_results": {"EM": 0.625, "QA-F1": 0.7177076259796848}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.7499999999999999, 1.0, 0.4444444444444445, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.07407407407407407, 0.9411764705882353, 0.7499999999999999, 1.0, 0.1, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2611", "mrqa_squad-validation-3639", "mrqa_squad-validation-1915", "mrqa_squad-validation-3689", "mrqa_squad-validation-8713", "mrqa_squad-validation-1289", "mrqa_squad-validation-239", "mrqa_squad-validation-606", "mrqa_squad-validation-1784", "mrqa_squad-validation-9600", "mrqa_squad-validation-6711", "mrqa_squad-validation-174", "mrqa_squad-validation-3516", "mrqa_squad-validation-4297", "mrqa_squad-validation-8247", "mrqa_squad-validation-2273", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-7627", "mrqa_naturalquestions-validation-9944", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-5791", "mrqa_naturalquestions-validation-10098", "mrqa_naturalquestions-validation-1214"], "SR": 0.625, "CSR": 0.7200520833333333, "EFR": 1.0, "Overall": 0.7314322916666666}, {"timecode": 12, "before_eval_results": {"predictions": ["eight-year", "1474", "water-cooled undergarment", "ABC-DuMont", "Hasar, Hachiun, and Tem\u00fcge", "green chloroplast", "demographics and economic ties", "a double membrane from their cyanobacterial ancestor", "Tehachapi Mountains", "Edison Medal", "Thomson", "Battle of B\u1ea1ch \u0110\u1eb1ng (1288)", "the instance", "BBC Radio 5 Live", "86.66%", "within a few hundred feet of each other", "Malaria", "Roger NFL", "Landgrave of Hesse", "ideological", "crust and lithosphere", "February 8, 1974", "$2 million", "the Carolina Panthers", "forming a 'A National Gallery of British Art'", "154", "tidal currents", "carbon related emissions", "wage or salary", "Santa Clara University", "Puente Hills Fault", "Milutin Tesla", "Gandhi", "Mork & Mindy", "three", "Wernher von Braun", "become more integral within the health care system", "more positive", "8,477", "confirmed", "before Kublai in 1285", "34%", "experience and higher education", "fully consistent with the conceptual definition of force offered by Newtonian mechanics", "Russia", "oxygen-16", "10", "weakness in school discipline", "Grundschule", "International Crops Research Institute for the Semi-Arid Tropics (ICRISAT)", "Matt Rollings", "Poems : Series 1", "seven", "October 2012", "cytokinesis", "Montreal Canadiens ( 24 )", "Abanindranath Tagore CIE", "grades 1 ( threshold 85 %, a distinction )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Garfield Sobers", "Jules Shear", "Spanish / Basque origin", "Garbi\u00f1e Muguruza", "summer of 1979"], "metric_results": {"EM": 0.6875, "QA-F1": 0.8061051717836257}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8750000000000001, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.24000000000000002, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4070", "mrqa_squad-validation-8645", "mrqa_squad-validation-8636", "mrqa_squad-validation-8222", "mrqa_squad-validation-484", "mrqa_squad-validation-7473", "mrqa_squad-validation-4184", "mrqa_squad-validation-80", "mrqa_squad-validation-4952", "mrqa_squad-validation-6403", "mrqa_squad-validation-3876", "mrqa_squad-validation-2236", "mrqa_squad-validation-10284", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-9204", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-6763"], "SR": 0.6875, "CSR": 0.7175480769230769, "EFR": 0.95, "Overall": 0.7209314903846153}, {"timecode": 13, "before_eval_results": {"predictions": ["None", "in collenchyma tissue", "Lorentz's Law", "factories", "DuMont Television Network", "$32 billion", "in early Lutheran hymnals", "misguided", "at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "electrified", "early 1990s", "the Rh\u00f4ne", "the separate condenser", "chemical", "canals", "Industry and manufacturing", "Aaron Spelling", "NBC Blue and NBC Red", "native tribes", "UNESCO World Heritage Site", "Cardinals", "people who give services \"for remuneration\" especially commercial or professional activity", "11.1%", "Demaryius Thomas", "Ferenc De\u00e1k", "X-ray-producing devices", "May through September", "fashion, architecture, product design, graphic arts and photography", "the Sovereign", "1978", "a setup phase in each involved node before any packet is transferred to establish the parameters of communication", "1892 to 1894", "The outcome of most votes", "dam turbine", "1702 and 1709", "the phycobilin phycoerytherin", "intracellular pathogenesis", "Surveyor 3 unmanned lunar probe", "250,000 feet", "Downtown San Diego", "10th and 11th centuries", "Fermilab", "collective bargaining, political influence, or corruption", "Defensive ends", "Europe", "his grandson", "the Bible", "1960s", "sculptures, friezes and tombs", "January 11, 2014", "Panic! at the Disco", "Turner Layton", "1972 Cannes Film Festival", "Super Bowl LII, their fourth NFL title, after winning in 1948, 1949, and 1960", "cadmium", "the name of a work gang", "an example of a useless, time - wasting activity", "Stephen Curry", "David Madden as the Ram, one of the first animals Wilbur meets at Homer's farm", "the delta basin", "the Fox Ranch in Malibu Creek State Park, northwest of Los Angeles", "Eddie Murphy", "Rajendra Prasad", "the following 15 countries or regions have reached an economy of at least US $2 trillion by GDP in nominal or PPP terms"], "metric_results": {"EM": 0.6875, "QA-F1": 0.8120341614906832}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.9565217391304348, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.9565217391304348, 1.0, 1.0, 0.8333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-10216", "mrqa_squad-validation-2384", "mrqa_squad-validation-2", "mrqa_squad-validation-9103", "mrqa_squad-validation-4517", "mrqa_squad-validation-60", "mrqa_squad-validation-1429", "mrqa_squad-validation-3999", "mrqa_squad-validation-2888", "mrqa_squad-validation-7410", "mrqa_squad-validation-6267", "mrqa_squad-validation-9381", "mrqa_naturalquestions-validation-4594", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-1930", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-2255", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-6764"], "SR": 0.6875, "CSR": 0.7154017857142857, "EFR": 0.95, "Overall": 0.7205022321428571}, {"timecode": 14, "before_eval_results": {"predictions": ["his mother's genetics and influence", "May", "journalism", "Richard Dean Adams", "free-to-view", "2003", "aggressiveness", "1806-07", "Life", "Sophocles", "27-30%", "ships where their compactness is valued", "7,000,000", "on the south side of the garden", "The Dornbirner Ach", "steal the invention", "the European Court of Justice", "the Kenya National Dialogue and Reconciliation process", "James Dewar", "reaffirmed Catholicism as the state religion of France, but granted the Protestants equality with Catholics under the throne and a degree of religious and political freedom within their domains", "Anderson", "Charly", "declared martial law and sent the state militia to maintain order", "Cornell", "1936", "vote", "Eastern Europe", "disease", "teachers are now selling their lesson plans to other teachers through the web in order to earn supplemental income", "about 63,523", "enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible", "Unfair Commercial Practices Directive", "Rose", "1992", "the south-east of Australia", "anointing with oil", "average teacher salaries", "Samarkand", "from 1910 to 1940", "spring reaction force", "one of the most common forms of school discipline throughout much of the world", "The Hay Wain", "1893", "colonialismism", "paramagnetic", "clerical marriage", "1654", "electric eels", "Scarlett Johansson", "in a geographical coordinate system at which longitude is defined to be 0 \u00b0", "Kristy Swanson", "Central Germany", "1966", "plant food, mainly grass and sedges, which were supplemented with herbaceous plants, flowering plants, shrubs, mosses, and tree matter", "to collect menstrual flow", "1975", "semi-autonomous organisational units within the National Health Service in England", "De Wayne Warren", "nominally a civil service post, but the appointment tends to be from within the Bank, with the incumbent grooming his or her successor", "The Satavahanas", "Bed and breakfast   Botel", "one", "honey bees", "the United States declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7853562352128467}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8095238095238095, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.8571428571428571, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.6896551724137931, 0.0, 0.8571428571428571, 0.6666666666666666, 0.0, 0.25806451612903225]}}, "before_error_ids": ["mrqa_squad-validation-1257", "mrqa_squad-validation-2742", "mrqa_squad-validation-3223", "mrqa_squad-validation-4402", "mrqa_squad-validation-5525", "mrqa_squad-validation-3163", "mrqa_squad-validation-7235", "mrqa_squad-validation-2238", "mrqa_squad-validation-2919", "mrqa_squad-validation-6248", "mrqa_squad-validation-7374", "mrqa_squad-validation-2085", "mrqa_squad-validation-9798", "mrqa_squad-validation-2754", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9571", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-9809"], "SR": 0.640625, "CSR": 0.7104166666666667, "EFR": 0.9130434782608695, "Overall": 0.7121139039855072}, {"timecode": 15, "UKR": 0.705078125, "OKR_sampled_ids": ["mrqa_squad-validation-8310", "mrqa_squad-validation-4834", "mrqa_squad-validation-10284", "mrqa_squad-validation-8794", "mrqa_squad-validation-452", "mrqa_squad-validation-8422", "mrqa_squad-validation-8952", "mrqa_naturalquestions-validation-998", "mrqa_squad-validation-3394", "mrqa_naturalquestions-validation-444", "mrqa_squad-validation-2955", "mrqa_naturalquestions-validation-6620", "mrqa_squad-validation-8068", "mrqa_squad-validation-1434", "mrqa_squad-validation-3486", "mrqa_squad-validation-6367", "mrqa_squad-validation-7692", "mrqa_squad-validation-5456", "mrqa_squad-validation-9189", "mrqa_naturalquestions-validation-3477", "mrqa_squad-validation-1119", "mrqa_squad-validation-4029", "mrqa_squad-validation-1752", "mrqa_squad-validation-9170", "mrqa_squad-validation-1042", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-7211", "mrqa_squad-validation-3702", "mrqa_squad-validation-5876", "mrqa_squad-validation-9276", "mrqa_naturalquestions-validation-9172", "mrqa_squad-validation-479", "mrqa_squad-validation-10012", "mrqa_squad-validation-5694", "mrqa_naturalquestions-validation-2437", "mrqa_naturalquestions-validation-7097", "mrqa_squad-validation-5255", "mrqa_squad-validation-4354", "mrqa_naturalquestions-validation-5719", "mrqa_squad-validation-2097", "mrqa_squad-validation-6267", "mrqa_squad-validation-4184", "mrqa_squad-validation-7846", "mrqa_squad-validation-8216", "mrqa_squad-validation-1316", "mrqa_squad-validation-1365", "mrqa_squad-validation-1815", "mrqa_squad-validation-2384", "mrqa_squad-validation-4952", "mrqa_squad-validation-4459", "mrqa_squad-validation-10365", "mrqa_squad-validation-8003", "mrqa_squad-validation-297", "mrqa_squad-validation-600", "mrqa_squad-validation-7268", "mrqa_squad-validation-7974", "mrqa_squad-validation-4506", "mrqa_squad-validation-4094", "mrqa_squad-validation-895", "mrqa_squad-validation-5576", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-6444", "mrqa_squad-validation-3076", "mrqa_squad-validation-557", "mrqa_squad-validation-7654", "mrqa_squad-validation-2482", "mrqa_squad-validation-710", "mrqa_squad-validation-2221", "mrqa_squad-validation-835", "mrqa_squad-validation-7150", "mrqa_squad-validation-7765", "mrqa_squad-validation-64", "mrqa_squad-validation-742", "mrqa_squad-validation-8384", "mrqa_squad-validation-2448", "mrqa_squad-validation-4147", "mrqa_squad-validation-9490", "mrqa_squad-validation-8242", "mrqa_squad-validation-9626", "mrqa_squad-validation-2781", "mrqa_squad-validation-2790", "mrqa_squad-validation-6054", "mrqa_squad-validation-8222", "mrqa_squad-validation-257", "mrqa_squad-validation-3773", "mrqa_squad-validation-4099", "mrqa_squad-validation-1490", "mrqa_squad-validation-6285", "mrqa_squad-validation-6848", "mrqa_naturalquestions-validation-6800", "mrqa_squad-validation-3500", "mrqa_squad-validation-1477", "mrqa_squad-validation-6358", "mrqa_squad-validation-883", "mrqa_squad-validation-6621", "mrqa_naturalquestions-validation-10268", "mrqa_squad-validation-8969", "mrqa_squad-validation-212", "mrqa_squad-validation-1877", "mrqa_squad-validation-2976", "mrqa_naturalquestions-validation-10081", "mrqa_squad-validation-167", "mrqa_squad-validation-5584", "mrqa_squad-validation-7044", "mrqa_squad-validation-7134", "mrqa_squad-validation-982", "mrqa_squad-validation-8452", "mrqa_naturalquestions-validation-10098", "mrqa_squad-validation-2235", "mrqa_naturalquestions-validation-373", "mrqa_squad-validation-2589", "mrqa_squad-validation-80", "mrqa_naturalquestions-validation-2578", "mrqa_squad-validation-6068", "mrqa_squad-validation-2609", "mrqa_squad-validation-5670", "mrqa_squad-validation-1784", "mrqa_squad-validation-9651", "mrqa_squad-validation-1259", "mrqa_squad-validation-3543", "mrqa_squad-validation-1609", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-9643", "mrqa_squad-validation-9566", "mrqa_squad-validation-2309", "mrqa_squad-validation-6345", "mrqa_squad-validation-7173", "mrqa_squad-validation-8691", "mrqa_squad-validation-4710", "mrqa_squad-validation-9705", "mrqa_squad-validation-5881", "mrqa_squad-validation-4236", "mrqa_squad-validation-7571", "mrqa_squad-validation-6770", "mrqa_squad-validation-3278", "mrqa_squad-validation-10116", "mrqa_naturalquestions-validation-8947", "mrqa_naturalquestions-validation-6234", "mrqa_squad-validation-1541", "mrqa_squad-validation-5169", "mrqa_squad-validation-244", "mrqa_squad-validation-9276", "mrqa_squad-validation-9298", "mrqa_squad-validation-10296", "mrqa_squad-validation-6248", "mrqa_squad-validation-7162", "mrqa_squad-validation-10175", "mrqa_squad-validation-9816", "mrqa_squad-validation-4134", "mrqa_squad-validation-1287", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-9944", "mrqa_squad-validation-3280", "mrqa_naturalquestions-validation-2666", "mrqa_squad-validation-683", "mrqa_squad-validation-5259", "mrqa_squad-validation-4990", "mrqa_squad-validation-2382", "mrqa_squad-validation-5330", "mrqa_squad-validation-10356", "mrqa_squad-validation-1779", "mrqa_squad-validation-5304", "mrqa_squad-validation-9953", "mrqa_squad-validation-2956", "mrqa_squad-validation-9285", "mrqa_squad-validation-3910", "mrqa_squad-validation-1909", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-426", "mrqa_squad-validation-8355", "mrqa_squad-validation-8209", "mrqa_squad-validation-5168", "mrqa_squad-validation-10350", "mrqa_squad-validation-3262", "mrqa_squad-validation-613", "mrqa_naturalquestions-validation-4768", "mrqa_squad-validation-6569", "mrqa_squad-validation-1872", "mrqa_squad-validation-5854", "mrqa_squad-validation-773", "mrqa_squad-validation-5491", "mrqa_squad-validation-7374", "mrqa_squad-validation-9745", "mrqa_squad-validation-299", "mrqa_squad-validation-2332", "mrqa_squad-validation-6366", "mrqa_squad-validation-5536", "mrqa_squad-validation-3347", "mrqa_squad-validation-4799", "mrqa_squad-validation-8572", "mrqa_naturalquestions-validation-6041", "mrqa_squad-validation-6980", "mrqa_naturalquestions-validation-10562", "mrqa_squad-validation-2243", "mrqa_naturalquestions-validation-6469", "mrqa_squad-validation-567", "mrqa_squad-validation-6951", "mrqa_squad-validation-5701", "mrqa_squad-validation-10252", "mrqa_squad-validation-2232", "mrqa_squad-validation-9537", "mrqa_squad-validation-4251", "mrqa_squad-validation-3698", "mrqa_squad-validation-3275", "mrqa_squad-validation-83", "mrqa_squad-validation-955", "mrqa_squad-validation-36", "mrqa_squad-validation-2147", "mrqa_squad-validation-76", "mrqa_squad-validation-9861", "mrqa_squad-validation-8645", "mrqa_squad-validation-6612", "mrqa_squad-validation-4085", "mrqa_naturalquestions-validation-9422", "mrqa_squad-validation-7135", "mrqa_squad-validation-8168", "mrqa_squad-validation-5169", "mrqa_squad-validation-7230", "mrqa_squad-validation-887", "mrqa_naturalquestions-validation-2658", "mrqa_squad-validation-1951", "mrqa_naturalquestions-validation-10496", "mrqa_squad-validation-1800", "mrqa_squad-validation-9628", "mrqa_squad-validation-4629", "mrqa_squad-validation-1941", "mrqa_squad-validation-8335", "mrqa_squad-validation-4916", "mrqa_naturalquestions-validation-1039", "mrqa_squad-validation-5023", "mrqa_squad-validation-10472", "mrqa_squad-validation-6388", "mrqa_naturalquestions-validation-6095", "mrqa_squad-validation-972", "mrqa_naturalquestions-validation-1491", "mrqa_squad-validation-9640", "mrqa_squad-validation-6489", "mrqa_squad-validation-4434", "mrqa_squad-validation-7039", "mrqa_squad-validation-4811", "mrqa_squad-validation-8159", "mrqa_squad-validation-3062", "mrqa_squad-validation-939", "mrqa_squad-validation-1247", "mrqa_naturalquestions-validation-9094", "mrqa_squad-validation-8649", "mrqa_squad-validation-2877", "mrqa_squad-validation-9941", "mrqa_squad-validation-3555", "mrqa_squad-validation-9240", "mrqa_squad-validation-571", "mrqa_squad-validation-9329", "mrqa_squad-validation-6034", "mrqa_squad-validation-6040", "mrqa_squad-validation-1824", "mrqa_squad-validation-9956", "mrqa_squad-validation-7320", "mrqa_squad-validation-6403", "mrqa_squad-validation-3495", "mrqa_squad-validation-5973", "mrqa_squad-validation-4680", "mrqa_squad-validation-9750", "mrqa_squad-validation-7580", "mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-495", "mrqa_squad-validation-8415", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-495", "mrqa_squad-validation-6086", "mrqa_squad-validation-337", "mrqa_squad-validation-1257", "mrqa_squad-validation-1766", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-3070", "mrqa_squad-validation-1626", "mrqa_squad-validation-1955", "mrqa_squad-validation-8197", "mrqa_squad-validation-6058", "mrqa_squad-validation-6097", "mrqa_squad-validation-1323", "mrqa_squad-validation-6295", "mrqa_squad-validation-9243", "mrqa_squad-validation-1218", "mrqa_squad-validation-8034", "mrqa_squad-validation-1701", "mrqa_squad-validation-3736", "mrqa_squad-validation-4315", "mrqa_squad-validation-462", "mrqa_squad-validation-4140", "mrqa_squad-validation-1429", "mrqa_squad-validation-5641", "mrqa_squad-validation-60", "mrqa_squad-validation-9901", "mrqa_squad-validation-3965", "mrqa_squad-validation-8816", "mrqa_squad-validation-3394", "mrqa_squad-validation-3683", "mrqa_squad-validation-4146", "mrqa_squad-validation-6451", "mrqa_squad-validation-4789", "mrqa_squad-validation-648", "mrqa_squad-validation-2133", "mrqa_squad-validation-415", "mrqa_naturalquestions-validation-8414", "mrqa_squad-validation-9442", "mrqa_squad-validation-1910", "mrqa_squad-validation-3223", "mrqa_squad-validation-291", "mrqa_squad-validation-2704", "mrqa_squad-validation-4238", "mrqa_squad-validation-5836", "mrqa_squad-validation-7430", "mrqa_squad-validation-4031", "mrqa_naturalquestions-validation-10188", "mrqa_squad-validation-9666", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-1144", "mrqa_squad-validation-1040", "mrqa_squad-validation-8598", "mrqa_squad-validation-5790", "mrqa_squad-validation-6116", "mrqa_squad-validation-9945", "mrqa_squad-validation-2754", "mrqa_squad-validation-2044", "mrqa_squad-validation-8403", "mrqa_squad-validation-2576", "mrqa_squad-validation-7149", "mrqa_squad-validation-4072", "mrqa_squad-validation-3236", "mrqa_naturalquestions-validation-2873", "mrqa_squad-validation-9748", "mrqa_squad-validation-9372", "mrqa_squad-validation-5967", "mrqa_squad-validation-1123", "mrqa_naturalquestions-validation-9410", "mrqa_squad-validation-1535", "mrqa_squad-validation-1018", "mrqa_squad-validation-2415", "mrqa_squad-validation-4274", "mrqa_squad-validation-8811", "mrqa_squad-validation-8713", "mrqa_squad-validation-4826", "mrqa_squad-validation-7915", "mrqa_squad-validation-2253", "mrqa_squad-validation-872", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-340", "mrqa_squad-validation-3506", "mrqa_squad-validation-1517", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-7735", "mrqa_squad-validation-1863", "mrqa_squad-validation-10149", "mrqa_squad-validation-1815", "mrqa_squad-validation-1915", "mrqa_squad-validation-9491", "mrqa_squad-validation-7175", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-9542", "mrqa_squad-validation-2247", "mrqa_squad-validation-2854", "mrqa_squad-validation-1742", "mrqa_squad-validation-9846", "mrqa_squad-validation-9587", "mrqa_squad-validation-2018", "mrqa_squad-validation-5360", "mrqa_squad-validation-2085", "mrqa_squad-validation-820", "mrqa_squad-validation-8906", "mrqa_squad-validation-5550", "mrqa_squad-validation-5599", "mrqa_squad-validation-7321", "mrqa_naturalquestions-validation-2169", "mrqa_squad-validation-2689", "mrqa_squad-validation-4290", "mrqa_squad-validation-6127", "mrqa_squad-validation-2647", "mrqa_squad-validation-2050", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-7886", "mrqa_squad-validation-2281", "mrqa_squad-validation-1954", "mrqa_squad-validation-460", "mrqa_squad-validation-189", "mrqa_squad-validation-6999", "mrqa_squad-validation-9274", "mrqa_squad-validation-3602", "mrqa_squad-validation-2095", "mrqa_squad-validation-9715", "mrqa_squad-validation-8552", "mrqa_squad-validation-4902", "mrqa_squad-validation-4311", "mrqa_squad-validation-3888", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-4814", "mrqa_squad-validation-9326", "mrqa_squad-validation-7324", "mrqa_squad-validation-7160", "mrqa_naturalquestions-validation-6763", "mrqa_squad-validation-5140", "mrqa_squad-validation-6245", "mrqa_squad-validation-1522", "mrqa_squad-validation-9002", "mrqa_squad-validation-5606", "mrqa_naturalquestions-validation-6149", "mrqa_squad-validation-2633", "mrqa_squad-validation-4297", "mrqa_squad-validation-10244", "mrqa_naturalquestions-validation-7415", "mrqa_squad-validation-1814", "mrqa_naturalquestions-validation-8216", "mrqa_squad-validation-4076", "mrqa_squad-validation-1663", "mrqa_squad-validation-3221", "mrqa_squad-validation-10402", "mrqa_squad-validation-4960", "mrqa_squad-validation-3349", "mrqa_squad-validation-3453", "mrqa_squad-validation-3164", "mrqa_naturalquestions-validation-8186", "mrqa_squad-validation-8169", "mrqa_squad-validation-8526", "mrqa_squad-validation-3704", "mrqa_squad-validation-3425", "mrqa_squad-validation-5498", "mrqa_naturalquestions-validation-6009", "mrqa_squad-validation-3611", "mrqa_squad-validation-146", "mrqa_squad-validation-10500", "mrqa_squad-validation-9453", "mrqa_squad-validation-9322", "mrqa_naturalquestions-validation-9809", "mrqa_squad-validation-6523", "mrqa_squad-validation-7108", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-4640", "mrqa_squad-validation-9771", "mrqa_squad-validation-2919", "mrqa_squad-validation-978", "mrqa_squad-validation-4808", "mrqa_squad-validation-3310", "mrqa_squad-validation-2466", "mrqa_squad-validation-4750", "mrqa_squad-validation-6576", "mrqa_naturalquestions-validation-8275", "mrqa_squad-validation-4318", "mrqa_squad-validation-5230", "mrqa_squad-validation-132", "mrqa_squad-validation-4337", "mrqa_squad-validation-4744", "mrqa_squad-validation-3101", "mrqa_squad-validation-6217", "mrqa_squad-validation-1752", "mrqa_squad-validation-9675", "mrqa_squad-validation-9009", "mrqa_squad-validation-2238", "mrqa_squad-validation-9076", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-3432", "mrqa_squad-validation-2940", "mrqa_squad-validation-6481", "mrqa_squad-validation-3545", "mrqa_squad-validation-112", "mrqa_naturalquestions-validation-468", "mrqa_squad-validation-4708", "mrqa_squad-validation-7203", "mrqa_squad-validation-8403", "mrqa_squad-validation-3028", "mrqa_squad-validation-6681", "mrqa_squad-validation-2353", "mrqa_squad-validation-715", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-2741", "mrqa_squad-validation-2070", "mrqa_squad-validation-6360", "mrqa_squad-validation-7890", "mrqa_squad-validation-8247", "mrqa_squad-validation-8881", "mrqa_squad-validation-9311", "mrqa_squad-validation-7598", "mrqa_squad-validation-7019", "mrqa_squad-validation-9875", "mrqa_squad-validation-7584", "mrqa_squad-validation-3727", "mrqa_squad-validation-8768", "mrqa_squad-validation-7492", "mrqa_squad-validation-9447", "mrqa_naturalquestions-validation-7182", "mrqa_squad-validation-34", "mrqa_squad-validation-8234", "mrqa_squad-validation-5018", "mrqa_squad-validation-8756", "mrqa_squad-validation-6868", "mrqa_squad-validation-7196", "mrqa_squad-validation-5715", "mrqa_squad-validation-9281", "mrqa_squad-validation-3689", "mrqa_squad-validation-878", "mrqa_squad-validation-4078", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-8776", "mrqa_squad-validation-3948", "mrqa_squad-validation-9641", "mrqa_squad-validation-6379", "mrqa_squad-validation-6513", "mrqa_squad-validation-3163", "mrqa_squad-validation-484", "mrqa_squad-validation-5386", "mrqa_squad-validation-8636", "mrqa_squad-validation-2673"], "OKR": 0.853515625, "before_eval_results": {"predictions": ["Fredericia (Denmark), Berlin, Stockholm, Hamburg, Frankfurt, Helsinki, and Emden", "monophyletic", "five", "number eight", "July 2015", "ABC Sports", "boom-and-bust cycles", "November 2006", "Wahhabism", "teacher's colleges", "the Maling company", "electric lighting company in Tesla's name, Tesla Electric Light & Manufacturing", "in the Red Sea", "1830", "Hamas", "The Muslims in the semu class", "occupational stress", "1.6 kilometres", "c1600", "18\u201349", "Gandhi", "1895", "two men", "40,000", "two", "Those involved with the design and execution of the infrastructure in question", "granted Vaudreuil's request that any French residents who chose to remain in the colony would be given freedom to continue worshiping in their Roman Catholic tradition", "Peter Howell", "illiberal Islamic regimes", "its inequality-associated effects", "King George III", "algae", "non-deterministic time", "Broncos", "four public charter schools on the South Side of Chicago administered by the university's Urban Education Institute", "their belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "Germany", "Maxwell", "8\u20134\u20134 system", "the youngest and in the Mongol culture, youngest sons were not given much responsibility due to their age", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "Acute oxygen toxicity to the lungs and central nervous system can also occur in deep scuba diving and surface supplied diving", "Tuesday", "Confucianism and promoting Chinese cultural values", "Radio Lollipop", "Onggirat tribe", "neither conscientious nor of social benefit", "Lead and lead dioxide", "Morgan Freeman", "the Western Bloc ( the United States, its NATO allies and others )", "Qutab - ud - din Aibak", "the local, municipal level", "Daytona 500 pole winners", "2018", "Frank Langella", "Universal Pictures", "Dr. Rajendra Prasad", "16,801", "winter", "Dr. Hartwell Carver", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential", "President Yahya Khan", "Bryan Cranston", "northern terminus is at an intersection with U.S. Route 340 ( US 340 ) near Front Royal,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7731413880258988}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6486486486486487, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.6956521739130436, 0.16216216216216214, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.2608695652173913, 0.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.2424242424242424, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.88]}}, "before_error_ids": ["mrqa_squad-validation-8026", "mrqa_squad-validation-1287", "mrqa_squad-validation-4608", "mrqa_squad-validation-6402", "mrqa_squad-validation-10258", "mrqa_squad-validation-7487", "mrqa_squad-validation-1729", "mrqa_squad-validation-7983", "mrqa_squad-validation-6708", "mrqa_squad-validation-864", "mrqa_squad-validation-6167", "mrqa_squad-validation-7088", "mrqa_squad-validation-3642", "mrqa_squad-validation-455", "mrqa_squad-validation-8160", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4520", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-1813"], "SR": 0.65625, "CSR": 0.70703125, "EFR": 0.7727272727272727, "Overall": 0.6642329545454545}, {"timecode": 16, "before_eval_results": {"predictions": ["the Jadaran", "Warsaw Uprising Museum", "a system of many biological structures and processes within an organism that protects against disease", "Individual-level interventions", "Paul Whiteman", "Egypt", "720p high definition", "eight", "nearly three hundred years", "Grumman", "Daily Mail", "freedom of ceremony", "Rijn", "Apollo 13", "property owner", "accessory pigments that override the chlorophylls' green colors", "arrows", "applied force", "DeMarcus Ware", "sell prescription drugs without requiring a prescription", "divergence problem", "eidetic memory and creative abilities to his mother's genetics and influence", "Orthogonal components", "300 km long and up to 40 km wide", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "Americans", "Newton", "by over 100% as no census was undertaken between the time of publication of the Domesday Book and the year 1377", "John C. Messenger", "labor inputs (workers) under competitive pressure to reduce costs and maximize profits", "July 11, 1962", "2,400", "Mediterranean geography", "2009", "boudins", "stronger, tech-oriented economy in the Bay Area and an emerging Greater Sacramento region", "printing press", "18-karat gold", "Aboriginal inhabitants", "\u00a341,004", "North", "nine", "some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution", "Chicago", "reactive oxygen species", "Mark Twain", "horticulture", "December 1349", "Mandy", "Carol Ann Susi", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula,", "ideology", "the nucleus", "Bailey Graffman", "strange, circus - themed wedding played by the Lucent Dossier Vaudeville Cirque", "Frank Theodore", "an anembryonic gestation", "the seventh episodes of each series, but was pushed back due to the large amount of work needed to accomplish it", "Saul, the Jewish barbershop customer, as well as Clarence, the owner of the barber shop", "in moist temperate climates, with much of the world's production occurring near the 48th parallel north", "Canadian West series,", "Javier Fern\u00e1ndez", "79 official PGA Tour events, second only to Sam Snead, and six ahead of Jack Nicklaus with 73 wins", "Khrushchev"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6976372585747586}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.16666666666666669, 1.0, 0.5, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 0.09523809523809523, 0.0, 0.0, 0.1, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-6108", "mrqa_squad-validation-298", "mrqa_squad-validation-6343", "mrqa_squad-validation-1261", "mrqa_squad-validation-9194", "mrqa_squad-validation-4898", "mrqa_squad-validation-7186", "mrqa_squad-validation-2835", "mrqa_squad-validation-2072", "mrqa_squad-validation-6736", "mrqa_naturalquestions-validation-4929", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-1009", "mrqa_naturalquestions-validation-2857", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-5792", "mrqa_naturalquestions-validation-2256", "mrqa_naturalquestions-validation-4594", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-3735"], "SR": 0.640625, "CSR": 0.703125, "EFR": 0.9565217391304348, "Overall": 0.7002105978260869}, {"timecode": 17, "before_eval_results": {"predictions": ["an ignition event, such as heat or a spark,", "the San Jose Marriott", "Jean Ribault", "4,097.9 people per square mile", "as soon as they enter into force, unless stated otherwise, and are generally concluded for an unlimited period", "private schools and schools which are privately governed[clarification needed]", "reducing poverty", "partial funding", "Thank Goodness It's Funny", "the Caspian Sea", "separate admission and exhaust valves driven by trip mechanisms or cams profiled", "fighting horsemen", "7.9%", "Rhine Gutter", "their disastrous financial situation", "13\u20137", "over a hundred of them", "Roger Goodell", "fifty percent", "World War II", "San Jose Marriott", "ARPANET", "computational complexity theory", "Baltimore-Washington Conference of the UMC", "Labor", "Pick TV", "the sealing of the hatch", "preventable diseases like malaria, HIV/AIDS, pneumonia, diarrhoea and malnutrition", "lens-shaped, 5\u20138 \u03bcm in diameter and 1\u20133 \u03bcm thick", "1960", "Harrods", "increased blood flow into tissue", "Grand Canal d'Alsace", "the deaths of many Filipinos", "pseudorandom number generators", "vector quantities", "S.W.A.T", "John F. Kennedy", "Kublai Khan", "receptions, gatherings or exhibition purposes", "$5 million", "Saudi Arabia and Iran", "the common coastal \"sea gooseberry,\"", "Genghis Khan", "Rumford medal", "1955", "regulate the employment and working conditions of civil servants, oversee hiring and promotions, and promote the values of the public service", "the left atrium and ventricle of the heart", "Michael Schumacher", "1960", "a hollow plastic sphere, approximately 3 cm in diameter ( similar in appearance to table tennis ball, but smaller ) with at least one small hole and a seam", "Marty Stuart", "federal republic", "Canada", "JulieDeb Kavner", "transform agricultural productivity, particularly with irrigated rather than dry - land cultivation in its northwest, to solve its problem of lack of food self - sufficiency", "the cast members", "Mel Tillis", "the Ming dynasty", "Sapporo / Garmisch - Partenkirchen", "Russia", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Justin Bieber", "a revolution or orbital revolution, typically when it is produced by gravity"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7337753387198288}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9444444444444444, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.972972972972973, 0.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.4, 0.15789473684210525, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-4176", "mrqa_squad-validation-6825", "mrqa_squad-validation-3249", "mrqa_squad-validation-7272", "mrqa_squad-validation-625", "mrqa_squad-validation-8001", "mrqa_squad-validation-4778", "mrqa_squad-validation-3935", "mrqa_squad-validation-8749", "mrqa_squad-validation-5769", "mrqa_squad-validation-10007", "mrqa_squad-validation-9161", "mrqa_squad-validation-4470", "mrqa_naturalquestions-validation-1084", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-3199", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-3214", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-4192"], "SR": 0.640625, "CSR": 0.6996527777777778, "EFR": 0.9130434782608695, "Overall": 0.6908205012077294}, {"timecode": 18, "before_eval_results": {"predictions": ["liquid", "Del\u00fc\u00fcn Boldog", "merchant Marco Polo", "Mnemiopsis", "Tesco", "1962", "three-fourths", "Broncos", "2005", "one", "the Meiji Restoration", "photosynthesis", "inputs", "science", "1957", "1883\u201384", "a mouse was more active and lived longer while breathing it", "Marion Dorn", "1989", "a wedding present from the new elector John the Steadfast", "100", "Neumes rythmiques", "Electrical Experimenter Tesla", "the NP-complete Boolean satisfiability problem", "Grey Street", "tracks, signalling and overhead wires", "Japan", "U.S. Supreme Court", "two", "two", "highly brecciated", "polynomial-time reduction", "Doritos", "quantum mechanics", "Warsaw University of Technology building", "17th", "Tethys", "1560", "Wesleyan", "preparation and approval process", "1893", "1712", "lower incomes", "Upper Rhine region", "Jeff Bezos", "amphetamines", "7000301604928199000", "Tom\u00e1s de Torquemada", "a simple ketonic monosaccharide found in many plants", "12.65 m", "18th", "Irene Bedard and Mel Gibson", "Zilphia Horton", "17th Century", "2009", "England", "Moscazzano", "35 to 40 hours per week", "Russia", "The Winds of Winter and A Dream of Spring", "while in a Saiyan's \u014czaru ( \u5927 \u733f, lit. '' Great Ape '' ) form", "'' United States Ship ''", "Keeping Up with the Kardashianians", "a secluded cove on the far eastern end of Westward Beach, between Zuma Beach and Point Dume in Malibu"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6927083333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.9714285714285714]}}, "before_error_ids": ["mrqa_squad-validation-8105", "mrqa_squad-validation-796", "mrqa_squad-validation-6327", "mrqa_squad-validation-9855", "mrqa_squad-validation-3575", "mrqa_squad-validation-2514", "mrqa_squad-validation-9051", "mrqa_squad-validation-1491", "mrqa_squad-validation-4067", "mrqa_squad-validation-1764", "mrqa_squad-validation-10388", "mrqa_squad-validation-967", "mrqa_squad-validation-8496", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-4185", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-6091", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-6586", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-468"], "SR": 0.609375, "CSR": 0.6949013157894737, "EFR": 0.96, "Overall": 0.6992615131578946}, {"timecode": 19, "before_eval_results": {"predictions": ["Regenstein Library", "combustion", "Indianapolis Colts", "Thomas Edison", "unit-dose", "ABC-DuMont", "eicosanoids and cytokines", "the Eleventh Doctor", "the river Aare", "high growth rates", "player slipping during plays all throughout the game.", "J. S. Bach", "union government", "1505", "Christ's message and teachings", "100\u20135,000 hp", "epoch-making oratory", "1879", "biologist", "Tomingaj, near Gra\u010dac", "the Industrial Revolution", "modern radar", "three", "the Brompton district of the Royal Borough of Kensington and Chelsea", "Honorary freemen", "22,000\u201314,000 yr BP", "Professional and labor organizations", "D\u00fcrer", "a luncheon", "2007", "15,100", "Theatre Royal on Grey Street", "Marshall", "capital punishment", "1985", "WOTV", "the Upper Rhine Graben, in southwest Germany and eastern France and the Lower Rhine Embayment, in northwest Germany and the southeastern Netherlands", "the sixteenth century", "vaccination", "solvability of quadratic equations", "1995", "Pleurobrachia", "Newton's Second Law of Motion", "Thomas Edison", "Matt Flinders", "first Sunday after Easter", "adrenal medulla", "Maggie", "Ryan Pinkston", "Mirabilis", "negligence was gross, that is, it showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "Texhoma", "his brother, who died in action in the United States Army", "23 September 1889", "Senator Joseph McCarthy", "the third season", "New England Patriots", "Super Bowl LII", "3 lines of reflection and rotational symmetry of order 3 about its center", "1986", "two degrees of freedom", "Crepuscular animals", "Television demonstrations are held at the 1939 New York World's Fair on Long Island and the Golden Gate International Exhibition in San Francisco", "Akshay Kumar"], "metric_results": {"EM": 0.625, "QA-F1": 0.7305597267316017}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 0.2727272727272727, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.9583333333333334, 1.0, 0.33333333333333337, 1.0, 0.3333333333333333, 0.5, 1.0, 0.8571428571428571, 0.14285714285714288, 1.0, 0.4, 0.6666666666666666, 0.32, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3416", "mrqa_squad-validation-1427", "mrqa_squad-validation-435", "mrqa_squad-validation-1441", "mrqa_squad-validation-1227", "mrqa_squad-validation-5158", "mrqa_squad-validation-1542", "mrqa_squad-validation-5084", "mrqa_squad-validation-943", "mrqa_squad-validation-6092", "mrqa_squad-validation-9150", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6844", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-9848", "mrqa_naturalquestions-validation-4064"], "SR": 0.625, "CSR": 0.69140625, "EFR": 1.0, "Overall": 0.7065625}, {"timecode": 20, "UKR": 0.693359375, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-4768", "mrqa_squad-validation-10017", "mrqa_squad-validation-10362", "mrqa_squad-validation-9664", "mrqa_squad-validation-9194", "mrqa_squad-validation-9913", "mrqa_squad-validation-4898", "mrqa_squad-validation-3455", "mrqa_squad-validation-867", "mrqa_squad-validation-5072", "mrqa_squad-validation-7175", "mrqa_squad-validation-10252", "mrqa_squad-validation-4629", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-8645", "mrqa_squad-validation-1779", "mrqa_squad-validation-9490", "mrqa_squad-validation-10352", "mrqa_squad-validation-7745", "mrqa_squad-validation-7138", "mrqa_squad-validation-742", "mrqa_naturalquestions-validation-8326", "mrqa_squad-validation-7044", "mrqa_squad-validation-7891", "mrqa_squad-validation-9034", "mrqa_squad-validation-5360", "mrqa_squad-validation-4875", "mrqa_squad-validation-8552", "mrqa_squad-validation-4811", "mrqa_squad-validation-4147", "mrqa_squad-validation-415", "mrqa_squad-validation-715", "mrqa_squad-validation-7832", "mrqa_naturalquestions-validation-2182", "mrqa_squad-validation-146", "mrqa_squad-validation-5940", "mrqa_naturalquestions-validation-2406", "mrqa_squad-validation-7735", "mrqa_squad-validation-9600", "mrqa_squad-validation-8776", "mrqa_squad-validation-1701", "mrqa_squad-validation-9750", "mrqa_squad-validation-646", "mrqa_squad-validation-6783", "mrqa_squad-validation-5530", "mrqa_squad-validation-4318", "mrqa_naturalquestions-validation-8603", "mrqa_squad-validation-5902", "mrqa_squad-validation-4539", "mrqa_squad-validation-2611", "mrqa_squad-validation-1909", "mrqa_squad-validation-6156", "mrqa_naturalquestions-validation-8186", "mrqa_squad-validation-8242", "mrqa_squad-validation-9537", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-9587", "mrqa_squad-validation-3070", "mrqa_squad-validation-6951", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-1930", "mrqa_squad-validation-6521", "mrqa_squad-validation-2466", "mrqa_squad-validation-204", "mrqa_squad-validation-9718", "mrqa_squad-validation-1490", "mrqa_squad-validation-9799", "mrqa_squad-validation-9645", "mrqa_naturalquestions-validation-6913", "mrqa_squad-validation-1194", "mrqa_squad-validation-5098", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-8384", "mrqa_squad-validation-9170", "mrqa_squad-validation-6388", "mrqa_squad-validation-9447", "mrqa_squad-validation-4472", "mrqa_squad-validation-8159", "mrqa_squad-validation-7974", "mrqa_squad-validation-5640", "mrqa_squad-validation-1040", "mrqa_squad-validation-6777", "mrqa_squad-validation-3339", "mrqa_squad-validation-6245", "mrqa_squad-validation-5701", "mrqa_squad-validation-1427", "mrqa_squad-validation-841", "mrqa_squad-validation-5386", "mrqa_naturalquestions-validation-8161", "mrqa_squad-validation-2689", "mrqa_naturalquestions-validation-8673", "mrqa_squad-validation-174", "mrqa_squad-validation-4085", "mrqa_squad-validation-5322", "mrqa_squad-validation-9816", "mrqa_squad-validation-4251", "mrqa_squad-validation-1477", "mrqa_squad-validation-3602", "mrqa_squad-validation-2448", "mrqa_squad-validation-85", "mrqa_squad-validation-5425", "mrqa_naturalquestions-validation-1989", "mrqa_squad-validation-5296", "mrqa_squad-validation-417", "mrqa_squad-validation-6736", "mrqa_squad-validation-9671", "mrqa_squad-validation-6681", "mrqa_squad-validation-5846", "mrqa_naturalquestions-validation-8625", "mrqa_squad-validation-7765", "mrqa_squad-validation-9292", "mrqa_squad-validation-2956", "mrqa_squad-validation-83", "mrqa_squad-validation-6420", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-8766", "mrqa_squad-validation-5742", "mrqa_naturalquestions-validation-379", "mrqa_squad-validation-4434", "mrqa_squad-validation-982", "mrqa_squad-validation-9521", "mrqa_naturalquestions-validation-6620", "mrqa_squad-validation-6708", "mrqa_squad-validation-257", "mrqa_squad-validation-1814", "mrqa_squad-validation-10228", "mrqa_squad-validation-1509", "mrqa_naturalquestions-validation-7594", "mrqa_squad-validation-1784", "mrqa_squad-validation-1951", "mrqa_squad-validation-978", "mrqa_squad-validation-6511", "mrqa_squad-validation-1388", "mrqa_squad-validation-9566", "mrqa_squad-validation-3873", "mrqa_squad-validation-10496", "mrqa_squad-validation-9953", "mrqa_naturalquestions-validation-468", "mrqa_squad-validation-3695", "mrqa_squad-validation-6236", "mrqa_squad-validation-9208", "mrqa_squad-validation-10388", "mrqa_squad-validation-5411", "mrqa_squad-validation-3278", "mrqa_squad-validation-8595", "mrqa_squad-validation-5836", "mrqa_squad-validation-9666", "mrqa_squad-validation-5023", "mrqa_squad-validation-1941", "mrqa_squad-validation-2133", "mrqa_squad-validation-7698", "mrqa_squad-validation-895", "mrqa_squad-validation-1295", "mrqa_squad-validation-9276", "mrqa_squad-validation-291", "mrqa_squad-validation-8197", "mrqa_squad-validation-887", "mrqa_squad-validation-9326", "mrqa_naturalquestions-validation-1694", "mrqa_squad-validation-6068", "mrqa_squad-validation-6240", "mrqa_squad-validation-9150", "mrqa_squad-validation-9243", "mrqa_squad-validation-1007", "mrqa_squad-validation-2095", "mrqa_squad-validation-2309", "mrqa_naturalquestions-validation-10294", "mrqa_squad-validation-1467", "mrqa_squad-validation-7039", "mrqa_squad-validation-967", "mrqa_squad-validation-5084", "mrqa_naturalquestions-validation-2682", "mrqa_squad-validation-1704", "mrqa_squad-validation-3806", "mrqa_naturalquestions-validation-2857", "mrqa_squad-validation-8526", "mrqa_squad-validation-3702", "mrqa_squad-validation-539", "mrqa_squad-validation-2448", "mrqa_squad-validation-1132", "mrqa_squad-validation-1427", "mrqa_squad-validation-1073", "mrqa_naturalquestions-validation-6452", "mrqa_squad-validation-5270", "mrqa_squad-validation-6465", "mrqa_squad-validation-8204", "mrqa_squad-validation-452", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-9172", "mrqa_naturalquestions-validation-6149", "mrqa_squad-validation-930", "mrqa_squad-validation-6907", "mrqa_squad-validation-1289", "mrqa_squad-validation-5536", "mrqa_squad-validation-8160", "mrqa_squad-validation-7859", "mrqa_squad-validation-6002", "mrqa_naturalquestions-validation-53", "mrqa_squad-validation-9562", "mrqa_squad-validation-2716", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-1247", "mrqa_squad-validation-7203", "mrqa_squad-validation-8026", "mrqa_squad-validation-8186", "mrqa_squad-validation-6711", "mrqa_squad-validation-9703", "mrqa_squad-validation-10133", "mrqa_squad-validation-10149", "mrqa_squad-validation-5169", "mrqa_squad-validation-6112", "mrqa_squad-validation-3333", "mrqa_squad-validation-4808", "mrqa_squad-validation-3841", "mrqa_squad-validation-6116", "mrqa_squad-validation-3133", "mrqa_naturalquestions-validation-7930", "mrqa_squad-validation-3057", "mrqa_squad-validation-8209", "mrqa_squad-validation-3253", "mrqa_squad-validation-2781", "mrqa_naturalquestions-validation-7182", "mrqa_squad-validation-3516", "mrqa_squad-validation-5519", "mrqa_squad-validation-7516", "mrqa_squad-validation-7877", "mrqa_squad-validation-278", "mrqa_squad-validation-8068", "mrqa_squad-validation-10317", "mrqa_squad-validation-8598", "mrqa_squad-validation-3044", "mrqa_squad-validation-4236", "mrqa_squad-validation-1661", "mrqa_squad-validation-1491", "mrqa_squad-validation-5513", "mrqa_squad-validation-5472", "mrqa_squad-validation-9861", "mrqa_squad-validation-1493", "mrqa_squad-validation-2384", "mrqa_naturalquestions-validation-8317", "mrqa_squad-validation-8691", "mrqa_squad-validation-3430", "mrqa_squad-validation-8049", "mrqa_squad-validation-6621", "mrqa_squad-validation-4078", "mrqa_squad-validation-1910", "mrqa_squad-validation-118", "mrqa_squad-validation-88", "mrqa_squad-validation-4608", "mrqa_squad-validation-9640", "mrqa_squad-validation-1404", "mrqa_squad-validation-878", "mrqa_squad-validation-7107", "mrqa_squad-validation-5011", "mrqa_naturalquestions-validation-2476", "mrqa_squad-validation-6403", "mrqa_squad-validation-7088", "mrqa_squad-validation-9771", "mrqa_naturalquestions-validation-7415", "mrqa_squad-validation-9", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-6765", "mrqa_squad-validation-2645", "mrqa_naturalquestions-validation-7124", "mrqa_squad-validation-6696", "mrqa_squad-validation-4184", "mrqa_squad-validation-5606", "mrqa_squad-validation-2727", "mrqa_squad-validation-6868", "mrqa_squad-validation-7205", "mrqa_naturalquestions-validation-8450", "mrqa_squad-validation-3919", "mrqa_squad-validation-8422", "mrqa_squad-validation-8222", "mrqa_squad-validation-702", "mrqa_squad-validation-64", "mrqa_squad-validation-6999", "mrqa_naturalquestions-validation-1866", "mrqa_naturalquestions-validation-9160", "mrqa_squad-validation-7251", "mrqa_squad-validation-94", "mrqa_naturalquestions-validation-851", "mrqa_squad-validation-9785", "mrqa_squad-validation-7580", "mrqa_squad-validation-9002", "mrqa_squad-validation-239", "mrqa_naturalquestions-validation-4814", "mrqa_squad-validation-6714", "mrqa_squad-validation-955", "mrqa_squad-validation-6513", "mrqa_naturalquestions-validation-8931", "mrqa_squad-validation-4990", "mrqa_squad-validation-6295", "mrqa_squad-validation-6237", "mrqa_squad-validation-2833", "mrqa_naturalquestions-validation-6624", "mrqa_squad-validation-9198", "mrqa_squad-validation-6576", "mrqa_squad-validation-5932", "mrqa_squad-validation-9643", "mrqa_squad-validation-1316", "mrqa_squad-validation-4094", "mrqa_squad-validation-7320", "mrqa_squad-validation-5491", "mrqa_squad-validation-5703", "mrqa_squad-validation-3495", "mrqa_squad-validation-851", "mrqa_squad-validation-1508", "mrqa_squad-validation-9569", "mrqa_squad-validation-1365", "mrqa_squad-validation-57", "mrqa_squad-validation-4146", "mrqa_squad-validation-4543", "mrqa_squad-validation-10500", "mrqa_squad-validation-3611", "mrqa_squad-validation-299", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-5599", "mrqa_squad-validation-8768", "mrqa_naturalquestions-validation-3735", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-5092", "mrqa_squad-validation-4595", "mrqa_squad-validation-7414", "mrqa_squad-validation-1752", "mrqa_squad-validation-6720", "mrqa_squad-validation-4295", "mrqa_naturalquestions-validation-8075", "mrqa_squad-validation-1283", "mrqa_squad-validation-2471", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-7151", "mrqa_squad-validation-7515", "mrqa_squad-validation-1329", "mrqa_squad-validation-1626", "mrqa_squad-validation-10418", "mrqa_squad-validation-3862", "mrqa_squad-validation-2742", "mrqa_squad-validation-3849", "mrqa_squad-validation-5156", "mrqa_squad-validation-6451", "mrqa_squad-validation-7692", "mrqa_squad-validation-2882", "mrqa_squad-validation-5242", "mrqa_naturalquestions-validation-6586", "mrqa_squad-validation-4934", "mrqa_squad-validation-3076", "mrqa_squad-validation-2852", "mrqa_squad-validation-6210", "mrqa_naturalquestions-validation-495", "mrqa_squad-validation-5498", "mrqa_squad-validation-5169", "mrqa_naturalquestions-validation-9410", "mrqa_squad-validation-2058", "mrqa_naturalquestions-validation-2437", "mrqa_squad-validation-460", "mrqa_squad-validation-4099", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-1018", "mrqa_squad-validation-1024", "mrqa_naturalquestions-validation-2280", "mrqa_squad-validation-4561", "mrqa_squad-validation-7915", "mrqa_squad-validation-1644", "mrqa_naturalquestions-validation-4286", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-4143", "mrqa_squad-validation-4023", "mrqa_squad-validation-2875", "mrqa_squad-validation-426", "mrqa_squad-validation-9941", "mrqa_squad-validation-6367", "mrqa_squad-validation-3310", "mrqa_squad-validation-10306", "mrqa_squad-validation-4383", "mrqa_squad-validation-8877", "mrqa_squad-validation-5525", "mrqa_squad-validation-3425", "mrqa_naturalquestions-validation-7473", "mrqa_squad-validation-6352", "mrqa_squad-validation-5847", "mrqa_squad-validation-3416", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-7173", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-9755", "mrqa_squad-validation-6518", "mrqa_squad-validation-1434", "mrqa_squad-validation-8906", "mrqa_squad-validation-10296", "mrqa_squad-validation-8034", "mrqa_squad-validation-6861", "mrqa_squad-validation-1522", "mrqa_squad-validation-3163", "mrqa_squad-validation-168", "mrqa_squad-validation-8442", "mrqa_squad-validation-495", "mrqa_squad-validation-189", "mrqa_squad-validation-1287", "mrqa_squad-validation-10234", "mrqa_squad-validation-835", "mrqa_squad-validation-1218", "mrqa_squad-validation-7230", "mrqa_naturalquestions-validation-2666", "mrqa_squad-validation-6651", "mrqa_squad-validation-7430", "mrqa_squad-validation-8486", "mrqa_squad-validation-4245", "mrqa_squad-validation-8881", "mrqa_squad-validation-6639", "mrqa_squad-validation-5168", "mrqa_naturalquestions-validation-4929", "mrqa_squad-validation-8816", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-8789", "mrqa_squad-validation-6994", "mrqa_squad-validation-3736", "mrqa_squad-validation-7261", "mrqa_squad-validation-9442", "mrqa_squad-validation-3091", "mrqa_squad-validation-5613", "mrqa_squad-validation-10365", "mrqa_squad-validation-9626", "mrqa_squad-validation-4311", "mrqa_squad-validation-7654", "mrqa_squad-validation-1912", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-448", "mrqa_squad-validation-2238", "mrqa_naturalquestions-validation-6041", "mrqa_squad-validation-1235", "mrqa_squad-validation-4680", "mrqa_squad-validation-10216", "mrqa_squad-validation-7777", "mrqa_naturalquestions-validation-10098", "mrqa_squad-validation-7712", "mrqa_squad-validation-5891", "mrqa_squad-validation-7674", "mrqa_squad-validation-943", "mrqa_squad-validation-4640", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-1877", "mrqa_squad-validation-7108", "mrqa_squad-validation-9260", "mrqa_squad-validation-10023", "mrqa_naturalquestions-validation-1084", "mrqa_squad-validation-9298", "mrqa_squad-validation-7487", "mrqa_squad-validation-6086", "mrqa_squad-validation-1764", "mrqa_squad-validation-1236", "mrqa_squad-validation-5576", "mrqa_squad-validation-7134", "mrqa_squad-validation-6343", "mrqa_squad-validation-6214", "mrqa_squad-validation-8455", "mrqa_squad-validation-7324", "mrqa_squad-validation-9708", "mrqa_squad-validation-9945", "mrqa_squad-validation-3340", "mrqa_squad-validation-6945", "mrqa_naturalquestions-validation-7097", "mrqa_squad-validation-683", "mrqa_squad-validation-1257", "mrqa_naturalquestions-validation-2658", "mrqa_squad-validation-4478", "mrqa_squad-validation-9281", "mrqa_squad-validation-5259", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-8383", "mrqa_squad-validation-1042", "mrqa_squad-validation-4134", "mrqa_squad-validation-3265", "mrqa_naturalquestions-validation-3485", "mrqa_squad-validation-3262", "mrqa_squad-validation-1270", "mrqa_squad-validation-7953", "mrqa_squad-validation-1824", "mrqa_squad-validation-8216", "mrqa_squad-validation-212", "mrqa_squad-validation-1960", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-10032", "mrqa_squad-validation-5018", "mrqa_squad-validation-10258", "mrqa_squad-validation-1132", "mrqa_squad-validation-6250", "mrqa_naturalquestions-validation-3214", "mrqa_squad-validation-7967", "mrqa_squad-validation-3543", "mrqa_squad-validation-484", "mrqa_squad-validation-9276", "mrqa_naturalquestions-validation-9809", "mrqa_squad-validation-8226", "mrqa_squad-validation-7149", "mrqa_squad-validation-4182", "mrqa_squad-validation-7131", "mrqa_squad-validation-1815", "mrqa_squad-validation-4806", "mrqa_squad-validation-1542", "mrqa_squad-validation-4710", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-7132", "mrqa_squad-validation-4470", "mrqa_naturalquestions-validation-4775", "mrqa_squad-validation-2451", "mrqa_squad-validation-2657", "mrqa_squad-validation-8320", "mrqa_squad-validation-7370"], "OKR": 0.8671875, "KG": 0.34296875, "before_eval_results": {"predictions": ["external combustion engines", "four", "1961 to 1972", "Associate Administrator D. Brainerd Holmes", "Louis Paul Cailletet", "Philip Webb and William Morris", "Enthusiastic teachers", "the large and small interior valleys", "at least six", "Turing machines", "the spring of 1329", "8.5", "Lutheran and Reformed states", "5,111 m2 (55,014.35 sq ft)", "the Jews", "Annual Conference Order of Deacons", "expelled from their parties outright", "the late 1870s", "Shiphrah and Puah", "1939", "2009", "Mercedes-Benz Superdome", "48 hours", "the Halo video game series", "rotational inertia", "the Golden Gate Bridge.", "the Western Cape province", "the south-east of Australia", "Mount Wilson", "law", "ABC Sports", "A growing cause of concern", "Mark Twain", "the European Court of Justice", "the Tyne and wear Passenger Transport Executive.", "1953", "ten million", "Chinggis Khaan International Airport", "the Museum of Manufactures", "Super Bowl 50", "specific immune receptors", "ABC", "eastwards", "March 6, 2018", "The terrestrial biosphere", "May 2010", "`` Young and Beautiful ''", "25 September 2007", "the winter solstice", "1975", "the pachytene stage of prophase I of meiosis", "Norway", "a federal republic in which the president, Congress, and federal courts share powers reserved to the national government according to its Constitution", "in Pyeongchang County, Gangwon Province, South Korea", "Marty Robbins", "James Cameron", "Omar Khayyam", "Orographic lift", "the upper legislative house in the future bicameral Congress", "democratic government system", "the Greenbriar Boys", "Sophia Akuffo", "shared pairs or bonding pairs", "1998"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7129225808913309}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.28571428571428575, 1.0, 0.8000000000000002, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.7777777777777778, 1.0, 0.1904761904761905, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8472", "mrqa_squad-validation-3838", "mrqa_squad-validation-3474", "mrqa_squad-validation-5422", "mrqa_squad-validation-2145", "mrqa_squad-validation-2791", "mrqa_squad-validation-6101", "mrqa_squad-validation-5047", "mrqa_squad-validation-3270", "mrqa_squad-validation-675", "mrqa_squad-validation-10092", "mrqa_squad-validation-9426", "mrqa_squad-validation-118", "mrqa_squad-validation-8009", "mrqa_squad-validation-3922", "mrqa_squad-validation-5860", "mrqa_squad-validation-186", "mrqa_naturalquestions-validation-2989", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-832", "mrqa_naturalquestions-validation-9760", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-6307", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-5014", "mrqa_naturalquestions-validation-8763"], "SR": 0.578125, "CSR": 0.6860119047619048, "EFR": 1.0, "Overall": 0.7179055059523809}, {"timecode": 21, "before_eval_results": {"predictions": ["fund travelers who would come back with tales of their discoveries", "Sports Night", "William and Judith Bollinger", "South Kensington", "trust God's word rather than violence", "the Huguenot rebellions", "Albert C. Outler", "FuturePlan", "\u00d6gedei Khan", "$5 million", "French", "Kawann Short", "many known complexity classes are suspected to be unequal, but this has not been proved.", "Mao Zedong", "Palm Springs", "New York City", "1930", "help transfer and dissipate excess energy", "24%", "a maze of semantical problems and grammatical niceties", "Apollo TV", "\u00a3250,000", "Carl Sagan", "higher oil prices and lower prices for their own export commodities", "Tucker", "420,000", "Polignac's conjecture", "Stromatoveris", "increasing emphasis on entertainment and leisure", "the \"Mongol dynasty\"", "military action", "the Atlanta Falcons", "HgO", "the move from the manufacturing sector to the service sector", "Arthur H. Compton", "the greatest antisemite of his time, the warner of his people against the Jews", "improved firearms", "1696", "to catalog everything", "in an unmarked grave somewhere in Mongolia at an unknown location.", "WABC-TV and WPVI-TV", "internal strife", "the American Kennel Club", "Ian Hart", "President of the United States", "the Kansas City Chiefs", "September 19, 2017", "Beijing", "May 2017", "to help batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship", "Upstate New York", "the date on which the Constitution of India came into effect on 26 January 1950 replacing the Government of India Act ( 1935 ) as the governing document of India", "John Smith", "the internal reproductive anatomy ( such as the uterus in females )", "Joseph Stalin", "Michelangelo", "the team can either select a player or trade their position to another team for other draft positions, a player and players, or any combination thereof", "Julia Roberts", "Database - Protocol driver", "Sesel Zvidzai", "1773", "President pro tempore", "Sebastian Lund", "on a sound stage in front of a live audience in Burbank, California"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7439625885076253}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8148148148148148, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.625, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.5882352941176471, 1.0, 0.2222222222222222, 1.0, 1.0, 0.08, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5324", "mrqa_squad-validation-2283", "mrqa_squad-validation-1795", "mrqa_squad-validation-3756", "mrqa_squad-validation-8084", "mrqa_squad-validation-488", "mrqa_squad-validation-7382", "mrqa_squad-validation-7880", "mrqa_squad-validation-2562", "mrqa_squad-validation-9812", "mrqa_squad-validation-5937", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-3710", "mrqa_naturalquestions-validation-4029", "mrqa_naturalquestions-validation-10631", "mrqa_naturalquestions-validation-1282"], "SR": 0.65625, "CSR": 0.6846590909090908, "EFR": 1.0, "Overall": 0.7176349431818181}, {"timecode": 22, "before_eval_results": {"predictions": ["double or triple non-French linguistic origins", "fragmentation", "the immune system", "four", "the Song dynasty", "December 12", "the defense of the St. Lawrence", "rare and desired", "James Hutton", "Oligocene", "over 100 billion dollars", "Parliament of the United Kingdom", "God's wrath to Christians", "after its 1977 merger with Radcliffe College.", "Sociologist", "the eighteenth century", "the BBC National Orchestra of Wales", "gas turbines", "1930", "Sullivan Bay", "Highly", "a thylakoid", "Philip Glass", "the most cost efficient bidder", "CBS", "Bermuda 419 turf", "HD channels and Video On Demand", "The Hoppings", "Gateshead", "10", "Watt", "inertia", "Red Guards", "after their second year", "the fight against apartheid", "high inequality", "Robert Boyle", "torque variability", "bounding", "1969", "one day", "the first, second and third day collection of the film was \u20b9 39.97 lakh", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "in a non-exhibition game until 2004", "Pittsburgh", "18", "Lee Baldwin", "Patrick Walshe", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen", "At the professional level", "Buddhism", "a blend of ground beef and other ingredients and is usually served with gravy or brown sauce", "Missouri", "1603", "April 29, 2009", "low coercivity", "during a preseason exhibition game held in Sassari, Italy", "1986", "Aalika Sheikh as Vinati Amar Pethawala", "Database - Protocol driver ( Pure Java driver )", "94", "1917", "2002", "Ireland"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7650502989657402}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.4615384615384615, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.11764705882352941, 0.5, 1.0, 0.0, 0.0, 0.9411764705882353, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-6483", "mrqa_squad-validation-6986", "mrqa_squad-validation-3031", "mrqa_squad-validation-3491", "mrqa_squad-validation-2862", "mrqa_naturalquestions-validation-1552", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-6140", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2119", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-4829", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-1971"], "SR": 0.6875, "CSR": 0.6847826086956521, "EFR": 0.95, "Overall": 0.7076596467391304}, {"timecode": 23, "before_eval_results": {"predictions": ["three", "1226", "rationing", "the law\u2019s engagement in a moral dialogue with the offenders as a rational person", "$125 per month", "more", "2100", "Proteomics", "The Commission's President", "he did not want disloyal men in his army", "since 2001", "1914", "Spearhead from Space", "IgE", "fee per unit of connection time", "20,000", "Philip Roth", "Edict of Fontainebleau", "ITV Digital's free-to-air replacement, Freeview", "two", "to aid the Mongol cavalry in capturing cities", "Spanish", "January 30", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF) beginning in 1985 to promote advanced research and education networking in the United States", "ten minutes", "bioluminescence", "the Midlands and the South West", "NewcastleGateshead", "more than 1 million", "Pittsburgh", "Newcastle has a population of 282,442", "with the help of the military", "100", "a number of qualifications", "Kenyan athletes (particularly Kalenjin)", "Shing-Tung Yau", "small islands by precipitating sediments", "medicine use reviews", "the island of Mainau", "Drogo, as \"dux et magister Italiae comesque Normannorum totius Apuliae et Calabriae\"", "Ledger", "the Imperial Family and the traditional head of state of Japan", "Gibraltar", "more than 160 high - rises", "Ed Roland", "The law enabled those who had resided in the country for two years and had kept their current state of residence for a year to apply for citizenship", "the foreign exchange market ( FX )", "6 January 793", "at Camping World Stadium in Orlando, Florida", "Tandi, in Lahaul", "Dadra and Nagar Haveli", "the 1820s", "vasoepididymostomy", "it violated their rights as Englishmen to `` No taxation without representation ''", "self - closing flood barrier", "Cell nuclei", "Carrieen Simone Vangsness", "11 p.m. to 3 a.m", "Symphony No. 40 in G minor", "in a liquid solution", "1946 interview, Capra described the film's theme as `` the individual's belief in himself '' and that he made it `` to combat a modern trend toward atheism", "Robert Andrews Millikan", "March 27, 2017", "New Jersey, United States"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6922391400470445}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.08, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.21428571428571427, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.15384615384615385, 1.0, 0.47058823529411764, 1.0, 0.0, 1.0, 0.11428571428571428, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.4583333333333333, 0.888888888888889, 1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-6872", "mrqa_squad-validation-1463", "mrqa_squad-validation-10158", "mrqa_squad-validation-6698", "mrqa_squad-validation-2651", "mrqa_squad-validation-6253", "mrqa_squad-validation-4846", "mrqa_squad-validation-5288", "mrqa_squad-validation-5151", "mrqa_squad-validation-9290", "mrqa_squad-validation-1026", "mrqa_naturalquestions-validation-8429", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-6116", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-5558", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-2972", "mrqa_naturalquestions-validation-4558", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-805"], "SR": 0.59375, "CSR": 0.6809895833333333, "EFR": 0.9615384615384616, "Overall": 0.7092087339743589}, {"timecode": 24, "before_eval_results": {"predictions": ["the fort San Mateo", "1903", "an ignition event, such as heat or a spark", "2.666 million", "Presburger", "integer factorization problem", "M\u00e9ni\u00e8re's disease, vertigo, fainting, tinnitus, and a cataract in one eye", "The Turing machine is a mathematical model of a general computing machine.", "1550 to 1900", "constitutional impasse in which two public agencies, especially two equally sovereign branches of government, conflict", "Due to its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "fast forwarding of accessed content", "151 votes", "friezes and tombs", "seven", "Westinghouse Electric & Manufacturing Company", "Old Meuse", "President Mahmoud Ahmadinejad", "six years", "Mueller", "Northern Rail", "the Pauli exclusion principle", "nonviolent", "rare and desired", "Thomas Edison", "homeschooling", "taught a large class of students in his old school, Higher Real Gymnasium", "more than 70,000", "nine", "Prussia", "Diocles of Carystus", "Khentii Aimag", "his son and successor, \u00d6gedei", "minimality or indecomposability", "1881", "Because course [the price of oil] is going to rise", "Marlee Matlin", "University Athletic Association (UAA)", "1963", "Ernest Rutherford", "florida", "at CBS Television City, studios 41 and 43 in Hollywood", "Donald Gets Drafted", "New Boar -- c. 1400 ( Reintroduced )", "24", "Ram - He is considered the seventh Avatar of the god Vishnu", "an expression of unknown origin", "January 2017 patch", "1989", "Peter Andrew Beardsley MBE", "the 1980s", "Los Lonely Boys", "Ku - Klip", "Jason Marsden", "1997", "New Island", "joy", "1881", "Wisconsin", "the buttock and down the lower limb", "31 January 1934", "November 27, 2013", "`` Midnight Mass in Rome ''", "1987 American romantic comedy fantasy adventure film directed and co-produced by Rob Reiner"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7458738140263876}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.14814814814814817, 0.0, 1.0, 0.846153846153846, 0.5882352941176471, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5882352941176471, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.1818181818181818, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.14285714285714288]}}, "before_error_ids": ["mrqa_squad-validation-7201", "mrqa_squad-validation-2506", "mrqa_squad-validation-1789", "mrqa_squad-validation-6806", "mrqa_squad-validation-885", "mrqa_squad-validation-5633", "mrqa_squad-validation-8471", "mrqa_squad-validation-1346", "mrqa_squad-validation-6150", "mrqa_squad-validation-3730", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-8478", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-9071", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-2698", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1884", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-4571", "mrqa_naturalquestions-validation-4871"], "SR": 0.640625, "CSR": 0.6793750000000001, "EFR": 0.9130434782608695, "Overall": 0.6991868206521739}, {"timecode": 25, "UKR": 0.68359375, "OKR_sampled_ids": ["mrqa_squad-validation-6455", "mrqa_squad-validation-6101", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3735", "mrqa_squad-validation-1324", "mrqa_squad-validation-10299", "mrqa_naturalquestions-validation-6149", "mrqa_squad-validation-1701", "mrqa_naturalquestions-validation-2972", "mrqa_squad-validation-7261", "mrqa_squad-validation-9956", "mrqa_squad-validation-6367", "mrqa_squad-validation-2835", "mrqa_squad-validation-3249", "mrqa_squad-validation-2411", "mrqa_squad-validation-4708", "mrqa_squad-validation-1243", "mrqa_squad-validation-4238", "mrqa_squad-validation-3477", "mrqa_squad-validation-3689", "mrqa_naturalquestions-validation-7097", "mrqa_squad-validation-2", "mrqa_squad-validation-6167", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-9908", "mrqa_squad-validation-5456", "mrqa_squad-validation-6097", "mrqa_squad-validation-6054", "mrqa_naturalquestions-validation-8625", "mrqa_squad-validation-2253", "mrqa_squad-validation-4539", "mrqa_squad-validation-499", "mrqa_squad-validation-10149", "mrqa_squad-validation-1685", "mrqa_squad-validation-5967", "mrqa_squad-validation-10402", "mrqa_naturalquestions-validation-7162", "mrqa_squad-validation-8353", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-4775", "mrqa_squad-validation-6865", "mrqa_squad-validation-8483", "mrqa_squad-validation-5057", "mrqa_squad-validation-8948", "mrqa_naturalquestions-validation-2124", "mrqa_squad-validation-3778", "mrqa_squad-validation-715", "mrqa_squad-validation-883", "mrqa_squad-validation-435", "mrqa_squad-validation-7259", "mrqa_squad-validation-943", "mrqa_squad-validation-3310", "mrqa_squad-validation-5158", "mrqa_squad-validation-9750", "mrqa_naturalquestions-validation-9160", "mrqa_squad-validation-3076", "mrqa_squad-validation-1814", "mrqa_squad-validation-4072", "mrqa_squad-validation-3223", "mrqa_squad-validation-9422", "mrqa_squad-validation-1467", "mrqa_squad-validation-7859", "mrqa_squad-validation-118", "mrqa_squad-validation-2283", "mrqa_squad-validation-2235", "mrqa_squad-validation-7088", "mrqa_naturalquestions-validation-10378", "mrqa_squad-validation-833", "mrqa_squad-validation-6313", "mrqa_squad-validation-1261", "mrqa_squad-validation-3727", "mrqa_squad-validation-8969", "mrqa_squad-validation-7235", "mrqa_squad-validation-4251", "mrqa_squad-validation-7598", "mrqa_squad-validation-6379", "mrqa_squad-validation-5259", "mrqa_squad-validation-1282", "mrqa_squad-validation-9666", "mrqa_squad-validation-5633", "mrqa_squad-validation-9170", "mrqa_squad-validation-2506", "mrqa_naturalquestions-validation-1801", "mrqa_squad-validation-9550", "mrqa_naturalquestions-validation-4185", "mrqa_squad-validation-9785", "mrqa_squad-validation-9290", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-613", "mrqa_squad-validation-8766", "mrqa_naturalquestions-validation-8186", "mrqa_squad-validation-2716", "mrqa_squad-validation-7832", "mrqa_naturalquestions-validation-805", "mrqa_squad-validation-930", "mrqa_squad-validation-3083", "mrqa_squad-validation-6040", "mrqa_naturalquestions-validation-2437", "mrqa_squad-validation-3142", "mrqa_squad-validation-3133", "mrqa_squad-validation-10340", "mrqa_squad-validation-2192", "mrqa_squad-validation-5322", "mrqa_naturalquestions-validation-1988", "mrqa_squad-validation-1815", "mrqa_squad-validation-8199", "mrqa_squad-validation-1858", "mrqa_squad-validation-7138", "mrqa_squad-validation-6945", "mrqa_squad-validation-2857", "mrqa_squad-validation-6420", "mrqa_squad-validation-6708", "mrqa_squad-validation-539", "mrqa_squad-validation-3683", "mrqa_squad-validation-1960", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-7754", "mrqa_squad-validation-7948", "mrqa_squad-validation-479", "mrqa_squad-validation-1981", "mrqa_squad-validation-1872", "mrqa_squad-validation-7622", "mrqa_squad-validation-9", "mrqa_squad-validation-3491", "mrqa_squad-validation-6958", "mrqa_squad-validation-6214", "mrqa_squad-validation-7891", "mrqa_naturalquestions-validation-1611", "mrqa_squad-validation-1228", "mrqa_squad-validation-424", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-10439", "mrqa_squad-validation-2955", "mrqa_squad-validation-7686", "mrqa_squad-validation-447", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-9765", "mrqa_squad-validation-6545", "mrqa_squad-validation-7480", "mrqa_squad-validation-8496", "mrqa_squad-validation-257", "mrqa_naturalquestions-validation-6182", "mrqa_squad-validation-4916", "mrqa_squad-validation-3773", "mrqa_squad-validation-8952", "mrqa_squad-validation-1517", "mrqa_naturalquestions-validation-4855", "mrqa_naturalquestions-validation-998", "mrqa_squad-validation-8647", "mrqa_squad-validation-97", "mrqa_squad-validation-10377", "mrqa_squad-validation-6993", "mrqa_squad-validation-5576", "mrqa_squad-validation-8767", "mrqa_squad-validation-6806", "mrqa_squad-validation-2799", "mrqa_squad-validation-7800", "mrqa_squad-validation-10315", "mrqa_squad-validation-3789", "mrqa_squad-validation-4355", "mrqa_squad-validation-8472", "mrqa_squad-validation-3841", "mrqa_squad-validation-1915", "mrqa_squad-validation-7921", "mrqa_naturalquestions-validation-6665", "mrqa_squad-validation-1998", "mrqa_squad-validation-3516", "mrqa_squad-validation-7044", "mrqa_squad-validation-10438", "mrqa_naturalquestions-validation-3427", "mrqa_squad-validation-426", "mrqa_squad-validation-9855", "mrqa_squad-validation-579", "mrqa_squad-validation-1886", "mrqa_squad-validation-8899", "mrqa_squad-validation-6861", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-85", "mrqa_squad-validation-2391", "mrqa_squad-validation-64", "mrqa_squad-validation-8329", "mrqa_naturalquestions-validation-49", "mrqa_squad-validation-7338", "mrqa_squad-validation-9748", "mrqa_naturalquestions-validation-3236", "mrqa_squad-validation-7294", "mrqa_naturalquestions-validation-6763", "mrqa_squad-validation-3456", "mrqa_squad-validation-291", "mrqa_squad-validation-887", "mrqa_naturalquestions-validation-8603", "mrqa_squad-validation-4037", "mrqa_squad-validation-9274", "mrqa_squad-validation-4478", "mrqa_squad-validation-8069", "mrqa_squad-validation-6513", "mrqa_squad-validation-4506", "mrqa_squad-validation-10012", "mrqa_squad-validation-83", "mrqa_squad-validation-1555", "mrqa_squad-validation-5028", "mrqa_squad-validation-9771", "mrqa_squad-validation-6034", "mrqa_naturalquestions-validation-1770", "mrqa_squad-validation-10054", "mrqa_squad-validation-4960", "mrqa_squad-validation-2737", "mrqa_squad-validation-1862", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-8429", "mrqa_squad-validation-895", "mrqa_squad-validation-9809", "mrqa_squad-validation-8049", "mrqa_squad-validation-7108", "mrqa_naturalquestions-validation-6307", "mrqa_squad-validation-36", "mrqa_squad-validation-7953", "mrqa_squad-validation-4274", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-1015", "mrqa_squad-validation-9490", "mrqa_squad-validation-7134", "mrqa_squad-validation-2471", "mrqa_squad-validation-10258", "mrqa_squad-validation-3550", "mrqa_squad-validation-2589", "mrqa_squad-validation-8403", "mrqa_squad-validation-2862", "mrqa_naturalquestions-validation-9330", "mrqa_squad-validation-9306", "mrqa_squad-validation-3950", "mrqa_squad-validation-6432", "mrqa_squad-validation-2956", "mrqa_squad-validation-5169", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-5536", "mrqa_squad-validation-4640", "mrqa_squad-validation-10317", "mrqa_squad-validation-8242", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-366", "mrqa_squad-validation-6576", "mrqa_naturalquestions-validation-7151", "mrqa_squad-validation-3707", "mrqa_squad-validation-955", "mrqa_squad-validation-710", "mrqa_squad-validation-9329", "mrqa_squad-validation-7150", "mrqa_squad-validation-2741", "mrqa_squad-validation-5257", "mrqa_squad-validation-7690", "mrqa_squad-validation-9635", "mrqa_squad-validation-7765", "mrqa_squad-validation-6388", "mrqa_naturalquestions-validation-6887", "mrqa_squad-validation-6241", "mrqa_squad-validation-6002", "mrqa_squad-validation-6366", "mrqa_squad-validation-978", "mrqa_naturalquestions-validation-1500", "mrqa_squad-validation-404", "mrqa_squad-validation-6160", "mrqa_squad-validation-2852", "mrqa_squad-validation-5701", "mrqa_squad-validation-8158", "mrqa_naturalquestions-validation-7182", "mrqa_squad-validation-1910", "mrqa_naturalquestions-validation-1694", "mrqa_squad-validation-8168", "mrqa_squad-validation-639", "mrqa_naturalquestions-validation-1222", "mrqa_squad-validation-8552", "mrqa_squad-validation-9626", "mrqa_squad-validation-3062", "mrqa_squad-validation-3275", "mrqa_squad-validation-3394", "mrqa_squad-validation-5641", "mrqa_naturalquestions-validation-1866", "mrqa_squad-validation-1661", "mrqa_squad-validation-8572", "mrqa_squad-validation-5329", "mrqa_squad-validation-3329", "mrqa_squad-validation-702", "mrqa_squad-validation-1463", "mrqa_squad-validation-6994", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-5550", "mrqa_squad-validation-10107", "mrqa_squad-validation-32", "mrqa_naturalquestions-validation-2552", "mrqa_squad-validation-8127", "mrqa_squad-validation-5624", "mrqa_squad-validation-10472", "mrqa_naturalquestions-validation-9571", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-6151", "mrqa_squad-validation-8713", "mrqa_naturalquestions-validation-4435", "mrqa_squad-validation-4311", "mrqa_squad-validation-2385", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-3736", "mrqa_squad-validation-91", "mrqa_squad-validation-3057", "mrqa_squad-validation-2368", "mrqa_squad-validation-9645", "mrqa_squad-validation-8595", "mrqa_squad-validation-7272", "mrqa_naturalquestions-validation-3710", "mrqa_squad-validation-6951", "mrqa_squad-validation-5847", "mrqa_squad-validation-10442", "mrqa_squad-validation-5098", "mrqa_squad-validation-8003", "mrqa_squad-validation-4099", "mrqa_squad-validation-8452", "mrqa_squad-validation-8410", "mrqa_squad-validation-8544", "mrqa_squad-validation-297", "mrqa_squad-validation-4734", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-373", "mrqa_squad-validation-10092", "mrqa_squad-validation-2999", "mrqa_squad-validation-5422", "mrqa_squad-validation-8857", "mrqa_squad-validation-6521", "mrqa_squad-validation-6480", "mrqa_squad-validation-5694", "mrqa_squad-validation-4632", "mrqa_squad-validation-3926", "mrqa_squad-validation-7654", "mrqa_naturalquestions-validation-10446", "mrqa_squad-validation-9521", "mrqa_squad-validation-4639", "mrqa_squad-validation-6489", "mrqa_squad-validation-1404", "mrqa_squad-validation-600", "mrqa_naturalquestions-validation-3214", "mrqa_squad-validation-1747", "mrqa_squad-validation-885", "mrqa_squad-validation-4834", "mrqa_squad-validation-330", "mrqa_squad-validation-1020", "mrqa_squad-validation-2562", "mrqa_squad-validation-9969", "mrqa_squad-validation-3349", "mrqa_squad-validation-3425", "mrqa_squad-validation-1287", "mrqa_squad-validation-10251", "mrqa_squad-validation-5860", "mrqa_squad-validation-5168", "mrqa_naturalquestions-validation-1537", "mrqa_squad-validation-4184", "mrqa_squad-validation-9141", "mrqa_squad-validation-2609", "mrqa_naturalquestions-validation-1988", "mrqa_naturalquestions-validation-9387", "mrqa_squad-validation-3925", "mrqa_squad-validation-1042", "mrqa_squad-validation-5513", "mrqa_naturalquestions-validation-8466", "mrqa_squad-validation-6848", "mrqa_naturalquestions-validation-4563", "mrqa_squad-validation-5140", "mrqa_squad-validation-6295", "mrqa_squad-validation-5480", "mrqa_squad-validation-4325", "mrqa_squad-validation-455", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-6800", "mrqa_squad-validation-9198", "mrqa_squad-validation-2018", "mrqa_squad-validation-5573", "mrqa_naturalquestions-validation-6093", "mrqa_squad-validation-6621", "mrqa_squad-validation-283", "mrqa_squad-validation-1395", "mrqa_squad-validation-5047", "mrqa_squad-validation-8471", "mrqa_squad-validation-466", "mrqa_squad-validation-6736", "mrqa_squad-validation-7321", "mrqa_squad-validation-2085", "mrqa_squad-validation-10388", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-452", "mrqa_squad-validation-448", "mrqa_naturalquestions-validation-10081", "mrqa_squad-validation-6116", "mrqa_squad-validation-8000", "mrqa_squad-validation-3329", "mrqa_squad-validation-3091", "mrqa_squad-validation-435", "mrqa_squad-validation-6696", "mrqa_squad-validation-222", "mrqa_squad-validation-10350", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-5719", "mrqa_squad-validation-9726", "mrqa_squad-validation-5578", "mrqa_squad-validation-6737", "mrqa_squad-validation-939", "mrqa_squad-validation-9045", "mrqa_squad-validation-6444", "mrqa_squad-validation-1801", "mrqa_squad-validation-4059", "mrqa_squad-validation-5390", "mrqa_squad-validation-847", "mrqa_naturalquestions-validation-1144", "mrqa_squad-validation-2238", "mrqa_squad-validation-1644", "mrqa_squad-validation-2854", "mrqa_squad-validation-5317", "mrqa_squad-validation-9720", "mrqa_squad-validation-6783", "mrqa_squad-validation-3873", "mrqa_squad-validation-8012", "mrqa_squad-validation-6483", "mrqa_squad-validation-5688", "mrqa_squad-validation-3044", "mrqa_squad-validation-295", "mrqa_squad-validation-6267", "mrqa_naturalquestions-validation-495", "mrqa_squad-validation-9322", "mrqa_squad-validation-6964", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-675", "mrqa_naturalquestions-validation-8662", "mrqa_squad-validation-5854", "mrqa_squad-validation-5334", "mrqa_naturalquestions-validation-4505", "mrqa_squad-validation-1941", "mrqa_squad-validation-796", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-4074", "mrqa_squad-validation-10356", "mrqa_squad-validation-4183", "mrqa_squad-validation-1790", "mrqa_naturalquestions-validation-3494", "mrqa_squad-validation-1603", "mrqa_squad-validation-6994", "mrqa_naturalquestions-validation-8414", "mrqa_squad-validation-6358", "mrqa_naturalquestions-validation-9972", "mrqa_squad-validation-3147", "mrqa_squad-validation-9895", "mrqa_naturalquestions-validation-9755", "mrqa_squad-validation-7132", "mrqa_naturalquestions-validation-9311", "mrqa_squad-validation-708", "mrqa_squad-validation-6048", "mrqa_naturalquestions-validation-4863", "mrqa_squad-validation-4230", "mrqa_squad-validation-5411", "mrqa_squad-validation-9566", "mrqa_naturalquestions-validation-13", "mrqa_squad-validation-462", "mrqa_squad-validation-1441", "mrqa_squad-validation-9708", "mrqa_squad-validation-9901", "mrqa_squad-validation-571", "mrqa_naturalquestions-validation-8873", "mrqa_squad-validation-1836", "mrqa_squad-validation-4744", "mrqa_squad-validation-3278", "mrqa_squad-validation-6112", "mrqa_squad-validation-2875", "mrqa_squad-validation-5386", "mrqa_squad-validation-2940", "mrqa_squad-validation-773", "mrqa_naturalquestions-validation-9756", "mrqa_naturalquestions-validation-1706", "mrqa_squad-validation-8009", "mrqa_squad-validation-1764", "mrqa_squad-validation-7382", "mrqa_squad-validation-1295", "mrqa_squad-validation-1296", "mrqa_naturalquestions-validation-8782", "mrqa_squad-validation-3133", "mrqa_squad-validation-867", "mrqa_squad-validation-3392", "mrqa_naturalquestions-validation-4667", "mrqa_squad-validation-8036", "mrqa_squad-validation-204", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-2415", "mrqa_squad-validation-3343", "mrqa_squad-validation-4293", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-9732", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-4814", "mrqa_squad-validation-5491", "mrqa_naturalquestions-validation-2509", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-2781", "mrqa_squad-validation-6612", "mrqa_squad-validation-6068", "mrqa_squad-validation-7567", "mrqa_naturalquestions-validation-7336", "mrqa_squad-validation-7196", "mrqa_squad-validation-297", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-2256", "mrqa_squad-validation-557", "mrqa_squad-validation-1288", "mrqa_squad-validation-2281", "mrqa_squad-validation-6950"], "OKR": 0.828125, "before_eval_results": {"predictions": ["19th Century", "cabin depressurization", "Royal Ujazd\u00f3w Castle", "the late 19th century", "Spike Milligan", "1874", "1954", "1914", "western Serbia, near Montenegro", "Lutheran and Reformed", "on the surface at the northern (German) shore of the lake", "5,500,000", "infrastructure", "1910\u20131940", "continued application of a force", "March 2011", "August 15, 1971", "vaccination", "integral calculus", "Luther's anti-Jewish works", "KRFX", "entirely religious and in no respect racial", "Gateshead Council", "general and complete disarmament", "Maciot de Bethencourt", "Canada", "200", "Mount Kenya", "1975", "lion, leopard, buffalo, rhinoceros, and elephant", "orientalism", "1970s and sometimes later", "southern Suriname", "a restaurant situated at a Grade I-listed 16th century merchant's house at 28\u201330 Close.", "many complexity classes", "Richard the Lion-hearted", "high-frequency power experiments in New York and Colorado Springs", "10 years, from age 18 to 28", "tertiary education (universities and/or TAFE colleges)", "Nicole Gale Anderson", "James Watson and Francis Crick", "New Orleans v. The Crescent City Live - Stock Landing and Slaughter - House Company", "the state in which both reactants and products are present in concentrations which have no further tendency to change with time", "74", "Sasha Banks", "Dan Rooney and Art Rooney II", "fiat money", "more frequent are 512 GB and 1 TB units", "left coronary artery ( LAD )", "the thylakoid membranes", "1800", "Foreign Account Tax Compliance Act ( FATCA )", "Abigail Hawk", "in Narnia - much to the Witch's horror after she had banished him", "Woody Paige", "1991", "Nepal", "the medulla oblongata", "Gwen West", "the financial statement showing a firm's assets, liabilities and equity ( capital ) at a set point in time, usually the end of the fiscal year reported on the accompanying income statement", "Neeraj Goswani", "New England Patriots, 41 -- 33, to win their first Super Bowl and their first NFL title since 1960", "Tom Burlinson, Red Symons and Dannii Minogue", "http://www.example.com/index.HTML"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6602750721500721}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 0.3636363636363636, 0.4444444444444445, 0.5, 1.0, 1.0, 0.2857142857142857, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.04, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1262", "mrqa_squad-validation-9286", "mrqa_squad-validation-1443", "mrqa_squad-validation-8278", "mrqa_squad-validation-9644", "mrqa_squad-validation-5137", "mrqa_squad-validation-1777", "mrqa_squad-validation-1142", "mrqa_squad-validation-1196", "mrqa_squad-validation-4273", "mrqa_squad-validation-2000", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-7059", "mrqa_naturalquestions-validation-3016", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-3074", "mrqa_naturalquestions-validation-6466", "mrqa_naturalquestions-validation-5674", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8229"], "SR": 0.59375, "CSR": 0.6760817307692308, "EFR": 0.8461538461538461, "Overall": 0.6753846153846154}, {"timecode": 26, "before_eval_results": {"predictions": ["SyFy", "the North Sea", "health care", "Economist", "New England Patriots", "Treaty of Logstown", "35", "Energiprojekt AB", "more financial assets than the lowest 48 nations combined", "1206", "Beating the Odds: The Untold Story Behind the Rise of ABC", "that contemporary accounts were exaggerations", "representatives appointed by governments and organizations", "American Football Conference", "Chinese", "Tracy Wolfson and Evan Washburn", "1954", "in many countries, there is a Gender pay gap in favor of males in the labor market.", "Sony", "400 m", "the public", "Polish Academy of Sciences", "Matthew 16:18", "1949", "the middle of the continent", "occupancy permit", "alcohol and nightclubs", "the Mongol Empire", "Irish", "the Romantic Rhine", "lectured", "lower", "imperialist", "the Great Yuan", "four", "Infrastructure", "1969", "Evita and The Wiz", "Orangeville, Ontario, Canada", "the churches of Galatia '' ( Galatians 1 : 2 )", "Andrew Lloyd Webber", "Marty Robbins", "Speaker of the House of Representatives", "judicial discretion", "Frederick County", "in the United Kingdom ( with the exception of Scotland since August 1, 2016 )", "Michael Christopher McDowell", "increased productivity, trade, and secular economic trends", "AD 95 -- 110", "Thomas Mundy Peterson", "American comedy - drama film directed by Fred Schepisi", "Austria - Hungary", "1895", "January 1, 1976", "Kylie Minogue", "2003", "victimology", "her abusive husband", "in the south", "Karen Gillan", "at CBS Television City, studios 41 and 43 in Hollywood", "April 6, 1917", "in human physiology", "the total size of the peacekeeping force is 98,200 police"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7565972222222221}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-259", "mrqa_squad-validation-7558", "mrqa_squad-validation-4921", "mrqa_squad-validation-584", "mrqa_squad-validation-7446", "mrqa_squad-validation-4287", "mrqa_squad-validation-5935", "mrqa_naturalquestions-validation-2990", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-6912", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-3086", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-5656", "mrqa_naturalquestions-validation-10495"], "SR": 0.703125, "CSR": 0.6770833333333333, "EFR": 0.8947368421052632, "Overall": 0.6853015350877192}, {"timecode": 27, "before_eval_results": {"predictions": ["1978", "the chao", "Marburg Colloquy", "Khanbaliq", "Wahhabism", "48.8 \u00b0C", "south of Harvard Yard along or near the Charles River", "authors Richard Wilkinson and Kate Pickett", "insulated tankers", "about three hours", "asocial", "The individual is the final judge", "Ma Jianlong", "six", "New York hotels", "Murrieta", "DVB-compliant MPEG-2", "traditional Mongol shamans", "D", "American composer John Debney", "six", "proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin", "pharmacists", "public", "two", "two", "15", "Graham Twigg", "Scottish", "leptin, pituitary growth hormone, and prolactin", "Institute for Policy Studies", "specific catechism questions", "oxygen", "The United Methodist Church", "their cleats", "IgE", "University Athletic Association", "Ed Sheeran", "Jackie Robinson", "erosion", "Ian `` Dicko '' Dickson", "British pop band T'Pau", "January 12, 2017", "more than 80 tank\u014dbon volumes", "Thomas Edison", "Pop", "Andrew Garfield", "restored to life", "The ulnar collateral ligament", "Atlanta", "The Geography of Oklahoma", "`` full '' sexual intercourse", "Brooks & Dunn", "`` Wellington", "1997", "The genome", "E-2s and E-3s", "1895", "Beijing", "on a sound stage in front of a live audience in Burbank, California", "herd maintenance", "Melanie Walters", "NFL", "March 16, 2018"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7270331231268731}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.23076923076923078, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7145", "mrqa_squad-validation-3690", "mrqa_squad-validation-5285", "mrqa_squad-validation-6967", "mrqa_squad-validation-2848", "mrqa_squad-validation-8204", "mrqa_squad-validation-3991", "mrqa_squad-validation-7713", "mrqa_squad-validation-4390", "mrqa_squad-validation-6327", "mrqa_squad-validation-4919", "mrqa_naturalquestions-validation-5049", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-8599"], "SR": 0.671875, "CSR": 0.6768973214285714, "EFR": 1.0, "Overall": 0.7063169642857142}, {"timecode": 28, "before_eval_results": {"predictions": ["encoding", "Kevin Harlan", "the carotenoid pigment peridinin", "1830", "1972", "special efforts", "survival needs", "Santa Clara Marriott", "construction manager, design engineer, construction engineer or project manager", "over 3 days", "BSkyB", "John Madejski Garden", "1985", "10th", "oxygen isotope ratio cycle", "the form 4k + 1 are not", "two-page", "June 4, 2014", "double or triple non-French linguistic origins", "colonies, in combination with assuming political control by military and political means", "Neil Shubin and Paul Sereno", "two remaining ambassadors", "extracurricular activities", "the fact (Fermat's little theorem) for any n if p is a prime number", "the renewed life of Christians accorded to them by the sacrament of baptism", "Pleistocene (~11,600 BP)", "the original force", "Abercrombie", "infrastructure", "reason", "Hassan al-Turabi", "the Mughal Empire and the Marathas", "poorly drafted contracts", "WABC-TV and WPVI-TV", "domestic legislation of the Scottish Parliament", "Vince Lombardi Trophy", "eusebeia", "chain elongation", "the coffee shop Monk's", "Roger Nichols and Paul Williams", "Michael Harney", "October 2012", "Matthew Gregory Wise", "issue # 7", "electrocuted and then suffer a seizure", "13,000 astronomical units ( 0.21 ly )", "2018", "the Kansas City Chiefs", "Coconut Cove", "American rock band Portugal", "the player character is recruited into the Grey Wardens, an ancient order that stands against demonic forces known as `` Darkspawn ''", "Empire of Japan and the Korean Empire", "May 30, 2017", "June 1992", "the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position )", "Eddie Murphy", "Kent and Edgar", "Canterbury Cathedral", "the Chicago metropolitan area", "near Camarillo, California", "season four", "in the traditional '' markets of Maine and Buffalo, where there were well over 180 locations as of 2011", "in London ( 2018 -- 27 )", "an upright triangle"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6517477314352313}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.8571428571428571, 0.18181818181818182, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 1.0, 0.7222222222222222, 1.0, 0.5, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8661", "mrqa_squad-validation-7317", "mrqa_squad-validation-315", "mrqa_squad-validation-3592", "mrqa_squad-validation-9082", "mrqa_squad-validation-7949", "mrqa_squad-validation-9928", "mrqa_squad-validation-6204", "mrqa_squad-validation-1870", "mrqa_squad-validation-9023", "mrqa_squad-validation-2455", "mrqa_squad-validation-9145", "mrqa_squad-validation-5437", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-3802", "mrqa_naturalquestions-validation-2674", "mrqa_naturalquestions-validation-9028", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-9019", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-9011", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7489", "mrqa_naturalquestions-validation-4124", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-6556"], "SR": 0.53125, "CSR": 0.671875, "EFR": 0.9333333333333333, "Overall": 0.6919791666666667}, {"timecode": 29, "before_eval_results": {"predictions": ["valve", "Niagara Falls Cataract Construction Company", "opportunity", "Euler's totient function", "accepted and allowed to worship freely", "World Meteorological Organization (WMO) and the United Nations Environment Programme (UNEP)", "Thailand", "only individuals", "1966", "Africa", "1991", "flour mill", "17th century", "A reduction is a transformation of one problem into another problem", "carve out a state for himself from Moorish lands", "high risk of a conflict of interest and/or the avoidance of absolute powers", "Muqali", "1999", "though the 21st century", "ctenophores", "April 2008", "Woods Hole Research Center", "the assassination of US President John F. Kennedy", "Edgar", "received only as a free gift of God's grace through faith in Jesus Christ as redeemer from sin", "respect", "government and the National Assembly and the Senate", "Ahmadine Mahmoud Ahmadine Ahmad's", "Sydney", "lower lake", "Design Event festival", "approximately 51,300", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "Johann Gerhard", "older", "attacked the British column, killing and capturing several hundred men, women, children, and slaves", "Michael Glass", "Richard Crispin Armitage", "Audrey II", "Montreal Canadiens", "1992", "Mickey Rourke", "Gayla Peevey", "2001", "stray wandering the streets of Moscow", "Otis Timson", "Richard Masur", "Gametes", "Richard Newman and Captain John Pulling", "commemorating fealty and filial piety", "February 9, 2018", "merengue", "`` What a Useful World ''", "a good harvest. It lasts for a night and a day, starting on the evening of the Purnima ( Full Moon day ) falling in the Vikram Samvat Hindu Calendar month of Phalguna", "May 31, 2012", "Edgar Lungu", "Frank Oz", "New Orleans", "Italy", "Skat", "`` Robber baron ''", "1983", "LED illuminated display", "flawed democracy"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7496888528138528}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true], "QA-F1": [0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.38095238095238093, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.0, 0.2181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3406", "mrqa_squad-validation-1366", "mrqa_squad-validation-7316", "mrqa_squad-validation-3023", "mrqa_squad-validation-6972", "mrqa_squad-validation-1750", "mrqa_squad-validation-1127", "mrqa_squad-validation-7744", "mrqa_squad-validation-2099", "mrqa_squad-validation-9658", "mrqa_squad-validation-3886", "mrqa_squad-validation-2406", "mrqa_squad-validation-4971", "mrqa_naturalquestions-validation-5440", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-8911", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-3008", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-754"], "SR": 0.65625, "CSR": 0.6713541666666667, "EFR": 0.7727272727272727, "Overall": 0.6597537878787879}, {"timecode": 30, "UKR": 0.712890625, "OKR_sampled_ids": ["mrqa_squad-validation-7480", "mrqa_squad-validation-7162", "mrqa_squad-validation-7949", "mrqa_squad-validation-9895", "mrqa_squad-validation-2576", "mrqa_naturalquestions-validation-1500", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-6466", "mrqa_squad-validation-10227", "mrqa_squad-validation-6345", "mrqa_squad-validation-7205", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-4134", "mrqa_squad-validation-1877", "mrqa_squad-validation-8384", "mrqa_squad-validation-1040", "mrqa_squad-validation-833", "mrqa_squad-validation-2147", "mrqa_squad-validation-5688", "mrqa_squad-validation-8794", "mrqa_squad-validation-8797", "mrqa_squad-validation-3062", "mrqa_squad-validation-7712", "mrqa_squad-validation-330", "mrqa_squad-validation-10418", "mrqa_squad-validation-6112", "mrqa_naturalquestions-validation-4845", "mrqa_squad-validation-1073", "mrqa_squad-validation-3455", "mrqa_squad-validation-3329", "mrqa_squad-validation-6143", "mrqa_squad-validation-1288", "mrqa_squad-validation-5317", "mrqa_squad-validation-4728", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-7855", "mrqa_squad-validation-10340", "mrqa_squad-validation-713", "mrqa_squad-validation-3044", "mrqa_squad-validation-6867", "mrqa_squad-validation-2415", "mrqa_naturalquestions-validation-4863", "mrqa_squad-validation-9715", "mrqa_squad-validation-6711", "mrqa_squad-validation-3333", "mrqa_squad-validation-5347", "mrqa_squad-validation-3841", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-8417", "mrqa_squad-validation-8153", "mrqa_squad-validation-686", "mrqa_squad-validation-8303", "mrqa_squad-validation-7107", "mrqa_squad-validation-5429", "mrqa_naturalquestions-validation-10562", "mrqa_squad-validation-406", "mrqa_squad-validation-1404", "mrqa_squad-validation-7877", "mrqa_squad-validation-6267", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-3965", "mrqa_squad-validation-7344", "mrqa_squad-validation-8180", "mrqa_squad-validation-3642", "mrqa_squad-validation-1637", "mrqa_naturalquestions-validation-10406", "mrqa_squad-validation-5578", "mrqa_squad-validation-6952", "mrqa_naturalquestions-validation-2299", "mrqa_squad-validation-4338", "mrqa_squad-validation-7890", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-2280", "mrqa_squad-validation-2390", "mrqa_squad-validation-6366", "mrqa_squad-validation-8899", "mrqa_squad-validation-9784", "mrqa_naturalquestions-validation-6764", "mrqa_squad-validation-3416", "mrqa_squad-validation-4459", "mrqa_squad-validation-1282", "mrqa_squad-validation-91", "mrqa_naturalquestions-validation-7473", "mrqa_squad-validation-2645", "mrqa_squad-validation-4640", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-2609", "mrqa_squad-validation-4402", "mrqa_squad-validation-1981", "mrqa_naturalquestions-validation-4422", "mrqa_squad-validation-9969", "mrqa_squad-validation-7410", "mrqa_squad-validation-930", "mrqa_squad-validation-3190", "mrqa_squad-validation-222", "mrqa_squad-validation-4844", "mrqa_squad-validation-3545", "mrqa_squad-validation-6576", "mrqa_naturalquestions-validation-5049", "mrqa_squad-validation-8034", "mrqa_squad-validation-10392", "mrqa_squad-validation-1862", "mrqa_squad-validation-3303", "mrqa_squad-validation-744", "mrqa_squad-validation-174", "mrqa_squad-validation-1491", "mrqa_naturalquestions-validation-2842", "mrqa_squad-validation-10284", "mrqa_squad-validation-5790", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-10159", "mrqa_squad-validation-2238", "mrqa_squad-validation-3778", "mrqa_squad-validation-5876", "mrqa_squad-validation-10315", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-9643", "mrqa_squad-validation-259", "mrqa_squad-validation-10136", "mrqa_squad-validation-2882", "mrqa_squad-validation-8544", "mrqa_naturalquestions-validation-7819", "mrqa_squad-validation-6685", "mrqa_naturalquestions-validation-7930", "mrqa_squad-validation-10397", "mrqa_squad-validation-7370", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-3373", "mrqa_squad-validation-5158", "mrqa_squad-validation-2000", "mrqa_squad-validation-97", "mrqa_squad-validation-5269", "mrqa_squad-validation-5047", "mrqa_naturalquestions-validation-9880", "mrqa_squad-validation-447", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-8603", "mrqa_squad-validation-448", "mrqa_squad-validation-8127", "mrqa_squad-validation-10376", "mrqa_squad-validation-7745", "mrqa_naturalquestions-validation-9944", "mrqa_naturalquestions-validation-3494", "mrqa_squad-validation-10254", "mrqa_squad-validation-9490", "mrqa_squad-validation-2741", "mrqa_squad-validation-3702", "mrqa_squad-validation-6681", "mrqa_squad-validation-2018", "mrqa_naturalquestions-validation-2080", "mrqa_squad-validation-8471", "mrqa_squad-validation-4230", "mrqa_squad-validation-4311", "mrqa_naturalquestions-validation-6149", "mrqa_squad-validation-736", "mrqa_squad-validation-9391", "mrqa_squad-validation-6253", "mrqa_squad-validation-8756", "mrqa_naturalquestions-validation-2990", "mrqa_squad-validation-8442", "mrqa_squad-validation-2998", "mrqa_squad-validation-5324", "mrqa_squad-validation-1026", "mrqa_squad-validation-6765", "mrqa_squad-validation-8226", "mrqa_squad-validation-6861", "mrqa_squad-validation-3806", "mrqa_squad-validation-3575", "mrqa_squad-validation-9626", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-5847", "mrqa_naturalquestions-validation-4558", "mrqa_naturalquestions-validation-468", "mrqa_squad-validation-1517", "mrqa_squad-validation-9562", "mrqa_naturalquestions-validation-5516", "mrqa_squad-validation-6521", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-7382", "mrqa_squad-validation-4121", "mrqa_squad-validation-9491", "mrqa_naturalquestions-validation-1222", "mrqa_naturalquestions-validation-8115", "mrqa_squad-validation-3757", "mrqa_squad-validation-7608", "mrqa_squad-validation-1548", "mrqa_squad-validation-967", "mrqa_squad-validation-5603", "mrqa_squad-validation-8321", "mrqa_squad-validation-4204", "mrqa_squad-validation-648", "mrqa_squad-validation-7208", "mrqa_squad-validation-7480", "mrqa_naturalquestions-validation-9387", "mrqa_squad-validation-7880", "mrqa_naturalquestions-validation-8037", "mrqa_squad-validation-9467", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-3545", "mrqa_squad-validation-5836", "mrqa_squad-validation-1870", "mrqa_squad-validation-7953", "mrqa_squad-validation-6883", "mrqa_squad-validation-9875", "mrqa_squad-validation-5847", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-8649", "mrqa_squad-validation-3727", "mrqa_naturalquestions-validation-366", "mrqa_squad-validation-9726", "mrqa_squad-validation-710", "mrqa_naturalquestions-validation-8947", "mrqa_squad-validation-3103", "mrqa_naturalquestions-validation-8782", "mrqa_squad-validation-171", "mrqa_squad-validation-6865", "mrqa_naturalquestions-validation-3735", "mrqa_squad-validation-8415", "mrqa_squad-validation-4916", "mrqa_naturalquestions-validation-10509", "mrqa_squad-validation-6986", "mrqa_squad-validation-6097", "mrqa_squad-validation-9771", "mrqa_naturalquestions-validation-8270", "mrqa_naturalquestions-validation-3048", "mrqa_squad-validation-2281", "mrqa_squad-validation-60", "mrqa_squad-validation-4325", "mrqa_squad-validation-8068", "mrqa_squad-validation-6062", "mrqa_naturalquestions-validation-7626", "mrqa_naturalquestions-validation-5905", "mrqa_squad-validation-1007", "mrqa_naturalquestions-validation-9757", "mrqa_squad-validation-2133", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-2476", "mrqa_squad-validation-5584", "mrqa_naturalquestions-validation-1084", "mrqa_squad-validation-6343", "mrqa_squad-validation-9276", "mrqa_squad-validation-1113", "mrqa_squad-validation-10175", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-9076", "mrqa_naturalquestions-validation-2127", "mrqa_squad-validation-2466", "mrqa_squad-validation-9375", "mrqa_squad-validation-10054", "mrqa_squad-validation-4293", "mrqa_squad-validation-2854", "mrqa_squad-validation-1912", "mrqa_squad-validation-6848", "mrqa_naturalquestions-validation-2989", "mrqa_naturalquestions-validation-7991", "mrqa_squad-validation-885", "mrqa_squad-validation-8534", "mrqa_naturalquestions-validation-6924", "mrqa_squad-validation-2716", "mrqa_squad-validation-10234", "mrqa_squad-validation-7304", "mrqa_squad-validation-2949", "mrqa_squad-validation-6950", "mrqa_squad-validation-4238", "mrqa_squad-validation-4108", "mrqa_squad-validation-1522", "mrqa_squad-validation-2346", "mrqa_squad-validation-8857", "mrqa_squad-validation-2877", "mrqa_naturalquestions-validation-5656", "mrqa_squad-validation-5156", "mrqa_squad-validation-3773", "mrqa_naturalquestions-validation-8317", "mrqa_squad-validation-606", "mrqa_squad-validation-4356", "mrqa_naturalquestions-validation-1491", "mrqa_squad-validation-7584", "mrqa_squad-validation-8969", "mrqa_squad-validation-3602", "mrqa_squad-validation-6146", "mrqa_naturalquestions-validation-5958", "mrqa_squad-validation-7320", "mrqa_squad-validation-9798", "mrqa_squad-validation-7160", "mrqa_squad-validation-9945", "mrqa_squad-validation-6403", "mrqa_squad-validation-2921", "mrqa_squad-validation-3630", "mrqa_squad-validation-5832", "mrqa_squad-validation-6367", "mrqa_squad-validation-3275", "mrqa_squad-validation-8072", "mrqa_naturalquestions-validation-7211", "mrqa_squad-validation-9276", "mrqa_squad-validation-1493", "mrqa_squad-validation-847", "mrqa_squad-validation-3999", "mrqa_squad-validation-5854", "mrqa_squad-validation-3023", "mrqa_squad-validation-9788", "mrqa_naturalquestions-validation-1537", "mrqa_squad-validation-9771", "mrqa_squad-validation-584", "mrqa_squad-validation-4143", "mrqa_squad-validation-7417", "mrqa_squad-validation-1228", "mrqa_squad-validation-3888", "mrqa_squad-validation-6545", "mrqa_squad-validation-7586", "mrqa_squad-validation-9306", "mrqa_naturalquestions-validation-4855", "mrqa_squad-validation-773", "mrqa_squad-validation-7948", "mrqa_naturalquestions-validation-3008", "mrqa_squad-validation-1261", "mrqa_squad-validation-5804", "mrqa_squad-validation-8266", "mrqa_squad-validation-6156", "mrqa_squad-validation-2058", "mrqa_squad-validation-8001", "mrqa_naturalquestions-validation-3074", "mrqa_squad-validation-4934", "mrqa_squad-validation-4332", "mrqa_squad-validation-9875", "mrqa_squad-validation-4478", "mrqa_squad-validation-3101", "mrqa_squad-validation-2462", "mrqa_squad-validation-2232", "mrqa_squad-validation-9194", "mrqa_squad-validation-7316", "mrqa_squad-validation-2508", "mrqa_squad-validation-9371", "mrqa_squad-validation-3850", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-2471", "mrqa_naturalquestions-validation-6560", "mrqa_squad-validation-708", "mrqa_naturalquestions-validation-3628", "mrqa_squad-validation-10258", "mrqa_squad-validation-6459", "mrqa_naturalquestions-validation-6307", "mrqa_squad-validation-7915", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-5330", "mrqa_squad-validation-5860", "mrqa_squad-validation-3515", "mrqa_squad-validation-4806", "mrqa_naturalquestions-validation-4029", "mrqa_squad-validation-495", "mrqa_squad-validation-4472", "mrqa_squad-validation-6108", "mrqa_squad-validation-3789", "mrqa_naturalquestions-validation-7124", "mrqa_squad-validation-7965", "mrqa_squad-validation-9785", "mrqa_squad-validation-9161", "mrqa_squad-validation-9982", "mrqa_squad-validation-4834", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-189", "mrqa_naturalquestions-validation-9692", "mrqa_squad-validation-6526", "mrqa_squad-validation-7194", "mrqa_naturalquestions-validation-673", "mrqa_squad-validation-10116", "mrqa_squad-validation-4311", "mrqa_squad-validation-10149", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-6999", "mrqa_squad-validation-6417", "mrqa_squad-validation-2704", "mrqa_squad-validation-404", "mrqa_squad-validation-982", "mrqa_squad-validation-7203", "mrqa_squad-validation-2455", "mrqa_squad-validation-5633", "mrqa_squad-validation-3368", "mrqa_squad-validation-9430", "mrqa_squad-validation-8247", "mrqa_naturalquestions-validation-100", "mrqa_squad-validation-2791", "mrqa_squad-validation-5386", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-3199", "mrqa_squad-validation-7435", "mrqa_squad-validation-9422", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-8234", "mrqa_naturalquestions-validation-6665", "mrqa_squad-validation-2384", "mrqa_naturalquestions-validation-4776", "mrqa_squad-validation-6167", "mrqa_squad-validation-4561", "mrqa_squad-validation-3397", "mrqa_naturalquestions-validation-6116", "mrqa_squad-validation-895", "mrqa_squad-validation-7145", "mrqa_squad-validation-3516", "mrqa_squad-validation-7446", "mrqa_squad-validation-7211", "mrqa_squad-validation-3343", "mrqa_squad-validation-1429", "mrqa_squad-validation-9256", "mrqa_naturalquestions-validation-7182", "mrqa_squad-validation-6352", "mrqa_squad-validation-2253", "mrqa_squad-validation-10017", "mrqa_squad-validation-8452", "mrqa_squad-validation-6573", "mrqa_squad-validation-6002", "mrqa_squad-validation-5513", "mrqa_naturalquestions-validation-4685", "mrqa_squad-validation-1955", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-4166", "mrqa_squad-validation-5881", "mrqa_squad-validation-5137", "mrqa_naturalquestions-validation-10439", "mrqa_squad-validation-5951", "mrqa_naturalquestions-validation-4929", "mrqa_squad-validation-10155", "mrqa_squad-validation-5364", "mrqa_squad-validation-3704", "mrqa_squad-validation-9281", "mrqa_squad-validation-625", "mrqa_squad-validation-7272", "mrqa_naturalquestions-validation-3061", "mrqa_naturalquestions-validation-4064", "mrqa_squad-validation-64", "mrqa_naturalquestions-validation-9756", "mrqa_squad-validation-1839", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-7151", "mrqa_squad-validation-2471", "mrqa_squad-validation-480", "mrqa_squad-validation-1764", "mrqa_naturalquestions-validation-6913", "mrqa_squad-validation-9550", "mrqa_naturalquestions-validation-8931", "mrqa_squad-validation-7138", "mrqa_squad-validation-4629", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-2857", "mrqa_squad-validation-7558", "mrqa_squad-validation-1750", "mrqa_squad-validation-7582", "mrqa_squad-validation-2368", "mrqa_squad-validation-4639", "mrqa_squad-validation-10296", "mrqa_squad-validation-5576", "mrqa_squad-validation-3221", "mrqa_squad-validation-4023", "mrqa_squad-validation-3347", "mrqa_squad-validation-3690", "mrqa_squad-validation-1233", "mrqa_squad-validation-7149", "mrqa_squad-validation-8012", "mrqa_squad-validation-5641", "mrqa_naturalquestions-validation-6140", "mrqa_squad-validation-6289", "mrqa_squad-validation-1753", "mrqa_squad-validation-796", "mrqa_squad-validation-2482", "mrqa_squad-validation-6818", "mrqa_squad-validation-10107", "mrqa_squad-validation-168", "mrqa_squad-validation-939", "mrqa_squad-validation-416", "mrqa_squad-validation-1365", "mrqa_squad-validation-4245", "mrqa_squad-validation-446", "mrqa_naturalquestions-validation-851", "mrqa_squad-validation-3873", "mrqa_naturalquestions-validation-3093", "mrqa_squad-validation-3495", "mrqa_naturalquestions-validation-10081", "mrqa_squad-validation-3925", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-1127", "mrqa_squad-validation-10012", "mrqa_squad-validation-2506", "mrqa_naturalquestions-validation-9850", "mrqa_squad-validation-6034", "mrqa_squad-validation-2692", "mrqa_squad-validation-6219", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-683", "mrqa_squad-validation-9635", "mrqa_squad-validation-3846", "mrqa_squad-validation-7622", "mrqa_naturalquestions-validation-4874", "mrqa_squad-validation-9023", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-9666", "mrqa_naturalquestions-validation-5674", "mrqa_naturalquestions-validation-5900", "mrqa_squad-validation-7134", "mrqa_naturalquestions-validation-4594", "mrqa_squad-validation-9311", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-8009", "mrqa_squad-validation-10216", "mrqa_squad-validation-3329", "mrqa_naturalquestions-validation-9571", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-10583", "mrqa_squad-validation-1467", "mrqa_squad-validation-9009", "mrqa_squad-validation-3683"], "OKR": 0.875, "KG": 0.35703125, "before_eval_results": {"predictions": ["main hymn", "2003", "When some species, including Bathyctena chuni, Euplokamis stationis and Eurhamphaea vexilligera, are disturbed", "two main classes", "\"Journey's End\"", "the Golden Gate Bridge", "91.3", "a civil disobedients' refraining from violence", "salvation", "Grand Canal d'Alsace", "Sky Digital", "MHC I", "negative long-term impact", "seven times", "a base for the global car industry", "Shimer College", "the type of reduction being used", "Tracy Wolfson", "24-year", "Mueller", "1422", "720p high definition", "the situation is ambiguous", "Muhammad ibn Zakar\u012bya R\u0101zi", "During the 16th and 17th centuries", "receiver", "more than doubles", "new converts", "Zwickau prophets", "Cam Newton", "behind the foot of the mast of a moving ship", "those who refuse vet vet \"cannot be appointed or engaged by the school in any capacity including in a voluntary role\"", "1285", "Newcastle Beer Festival", "meaning \"belonging to Warsz\"", "in the dress shop", "response to a perceived harmful event, attack, or threat to survival", "1560s", "across a membrane", "the utopian novels of H.G. Wells", "Gerald Ford", "September 1947", "160km / hour", "March 16, 2018", "Lalo Schifrin", "The Cornett family", "Baaghi ( English : Rebel )", "the Old Testament", "March 11, 2016", "The Third Five - year Plan", "New Delhi", "Oscar", "a Malibu, California beach intercut with scenes of them driving an orange campervan", "1998", "from within the Bank, with the incumbent grooming his or her successor.", "1994", "Splodgenessabounds", "2018", "Uralic languages", "a unique species capable of reproduction", "a writ of certiorari", "microfilament", "senators", "David Tennant"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7357190967245315}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.33333333333333337, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 0.8571428571428571, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.5714285714285715, 0.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4511", "mrqa_squad-validation-6794", "mrqa_squad-validation-2011", "mrqa_squad-validation-5213", "mrqa_squad-validation-51", "mrqa_squad-validation-2980", "mrqa_squad-validation-8056", "mrqa_squad-validation-6197", "mrqa_squad-validation-10320", "mrqa_squad-validation-336", "mrqa_squad-validation-9263", "mrqa_squad-validation-1994", "mrqa_squad-validation-868", "mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-1611", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-1340", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-9609"], "SR": 0.640625, "CSR": 0.6703629032258065, "EFR": 1.0, "Overall": 0.7230569556451613}, {"timecode": 31, "before_eval_results": {"predictions": ["major national and international patient information projects and health system interoperability goals", "Coldplay", "2004", "Cosgrove Hall", "the Moon", "1975", "The Small Catechism", "63", "the American Revolution", "show globe", "October 16, 1973", "a great deal of utility", "liquid", "the communications between Yuan dynasty and its ally and subordinate in Persia, the Ilkhanate", "lipids and proteins", "Miasma theory", "thick atmosphere", "very low", "eight years in primary school and four years in high school or secondary school", "Mission to the Unknown", "information technology departments or for healthcare information technology vendor companies", "ring theory", "4,222,000", "a proprietary suite of networking protocols developed by Apple Inc. in 1985 for Apple Macintosh computers", "who is not always a bishop", "counterprogramming", "1990s", "Chinese", "1986", "the catechism", "mustered local militia companies, generally ill trained and available only for short periods, to deal with native threats, but did not have any standing forces", "Zhenjin", "to avoid being targeted by the boycott", "Queen Victoria", "eight hours", "1973", "Monk's Caf\u00e9", "bicameral Congress", "H.L. Hunley", "Human fertilization", "3D computer graphics, 3D modeling ( or three - dimensional modeling )", "the March of Dimes for Franklin D. Roosevelt", "Germany", "- ase", "Andreas Vesalius", "Mary Elizabeth Patterson", "the fictional town of West Egg on prosperous Long Island", "Clarence Darrow", "Minneapolis, Minnesota", "Fa Ze YouTubers", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "Etienne de Mestre", "79", "qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government", "July 25, 1898", "Bart Howard", "Tami Lynn", "1871", "parthenogenesis", "Jimmy Matthews", "Charles Habib Malik, Lebanon", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )", "Ethiopia ( Abyssinia ), the Dervish state ( a portion of present - day Somalia ) and Liberia still being independent", "2007"], "metric_results": {"EM": 0.625, "QA-F1": 0.760425955623324}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.846153846153846, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.16, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.8571428571428571, 0.3636363636363636, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7685", "mrqa_squad-validation-3994", "mrqa_squad-validation-8066", "mrqa_squad-validation-4065", "mrqa_squad-validation-4788", "mrqa_squad-validation-2227", "mrqa_squad-validation-8169", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-10618", "mrqa_naturalquestions-validation-4879", "mrqa_naturalquestions-validation-4145", "mrqa_naturalquestions-validation-681", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-993", "mrqa_naturalquestions-validation-3820", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-7152", "mrqa_naturalquestions-validation-3860", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-5928"], "SR": 0.625, "CSR": 0.6689453125, "EFR": 0.9166666666666666, "Overall": 0.7061067708333333}, {"timecode": 32, "before_eval_results": {"predictions": ["because \"prosecutors have reasoned (correctly) that if they arrest fully informed jury leafleters, the leaflets will have to be given to the leafleter's own jury as evidence.\"", "imperialism", "valleys", "1 August 1944", "earn as much as a healthy young man; gender roles and customs may prevent a woman from receiving an education or working outside the home", "1883", "William E. Simon", "Bart Starr", "closed (\"dammed\")", "cheating", "electron microscopy", "1500 and 1850", "Africa", "4 weeks", "eight", "Ti\u011bm\u00f9zh\u0113n", "the second-busiest airport in the United States by passenger volume (see World's busiest airports by passenger traffic)", "wooden paddle", "GTE", "a result of the American Revolution", "highways", "five climate scientists \u2013 all contributing or lead", "Northern Europe and the Mid-Atlantic", "Stromules", "independent", "since the 1960s", "books, films, radio, TV, music, live theater, comics and video games", "investigating complaints involving members, conducting hearings into allegations of professional misconduct and taking appropriate disciplinary action and accrediting teacher education programs", "Trioxygen", "35", "adaptive and innate immune responses", "The French Protestant Church of London", "12 December 1963", "Abu al-Rayhan al-Biruni", "Nodar Kumaritashvili", "lead vocalist and rhythm guitarist Aaron Lewis, lead guitarist Mike Mushok, bassist and backing vocalist Johnny April, and drummer Jon Wysocki", "the Soviet Union and its satellite states", "Havana Harbor", "The song on Zane Lowe's show on BBC Radio 1 in June 2010, at the Rockstar offices in New York in July 2010, and at the Spike Video Game Awards in December 2010", "the fifth studio album by English rock band the Beatles", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s, with its coastal areas north from the Columbia River frequented by ships from all nations engaged in the maritime fur trade", "Georgia", "1997", "Michigan and surrounding states and provinces", "Mary Elizabeth Patterson", "William T. Deutschendorf", "Richard Stallman", "Virginia Dare", "unattainable", "Carol Worthington", "2014", "October 1976", "the fourth season", "virtual reality simulator", "1995 Mitsubishi Eclipse - Shot at by Johnny Tran and later destroyed after ruptured nitrous tanks explode", "Roger Federer", "two - year terms", "2012", "compasses", "a crust of potatoes", "a narcissistic ex-lover who did the protagonist wrong", "Presley Smith", "1824", "the SAP Center at San Jose"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6871805965642619}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.8636363636363636, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.17391304347826084, 0.5, 1.0, 0.0, 0.0, 0.1142857142857143, 1.0, 1.0, 0.1739130434782609, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.35294117647058826, 0.3157894736842105, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_squad-validation-6832", "mrqa_squad-validation-9904", "mrqa_squad-validation-7596", "mrqa_squad-validation-633", "mrqa_squad-validation-9029", "mrqa_squad-validation-6304", "mrqa_squad-validation-2751", "mrqa_squad-validation-8607", "mrqa_squad-validation-10398", "mrqa_squad-validation-1907", "mrqa_squad-validation-5131", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-2870", "mrqa_naturalquestions-validation-4741", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-9564", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-1629", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-6326", "mrqa_naturalquestions-validation-872", "mrqa_naturalquestions-validation-878"], "SR": 0.5625, "CSR": 0.665719696969697, "EFR": 1.0, "Overall": 0.7221283143939394}, {"timecode": 33, "before_eval_results": {"predictions": ["1650", "the lack of reliable statistics", "2006", "inferior", "duty", "1979", "the beauty that surrounds us", "8 mm cine", "Muhammad ibn Zakar\u012bya R\u0101zi", "over 900,000", "the Xingu tribe", "Dan Fouts", "Mount Bogong", "Nairobi's Harambee House", "Thomas Commerford Martin", "$500,000", "1986", "the Saxon chancellery", "integer factorization", "Omnicare, Kindred Healthcare and PharMerica", "June 6, 1951", "mersenne primes", "one", "Sarah Jane Smith", "four", "Frank Burnet", "Kong Duancao", "$216,000", "the demand for higher quality housing increased", "18%", "the university and military academy", "ash tree", "MHC class I", "the money come from to pay these bills", "2007", "Davos", "Bemis Heights", "Emma Swan", "Brooklyn, New York", "Bob Dylan", "T - Bone Walker", "novella", "1943", "Menorca", "Avalon Sunset", "Gary Mitchell", "the winter solstice", "Ledger", "an illustration by Everest creative Maganlal Daiya back in the 1960s", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "July 1, 1923", "Christopher Columbus", "Icona Pop", "San Francisco", "2002 Mitsubishi Lancer OZ Rally", "Vicente Fox", "J. Presper Eckert and John William Mauchly", "the medulla oblongata", "Botel", "The Lutheran Church of Sweden", "July 21, 1861", "the most surrounding area, in the Georgia counties of Newton ( where Covington is located ), Rockdale, Walton, Morgan, and Jasper", "Buddhism", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7589937689122472}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.9523809523809523, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 0.8666666666666666, 1.0, 0.08695652173913043]}}, "before_error_ids": ["mrqa_squad-validation-10058", "mrqa_squad-validation-6914", "mrqa_squad-validation-7646", "mrqa_squad-validation-567", "mrqa_squad-validation-8983", "mrqa_squad-validation-221", "mrqa_squad-validation-4634", "mrqa_naturalquestions-validation-8612", "mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-2889", "mrqa_naturalquestions-validation-3965", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-8470", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-10271"], "SR": 0.671875, "CSR": 0.6659007352941176, "EFR": 1.0, "Overall": 0.7221645220588235}, {"timecode": 34, "before_eval_results": {"predictions": ["Mike Tolbert", "a set-up that uses movable pulleys", "help transfer and dissipate excess energy", "more than half", "1937", "counties or powiats", "nitrogen/oxygen", "Zorro", "structural collapse, cost overruns, and/or litigation", "Turkey", "clapping their lobes", "yellow fever outbreaks", "1526", "Mnemiopsis", "Big Finish Productions", "Commission v France", "1884", "20%", "encourage growth", "forces as being due to gradient of potentials", "the San Jose State practice facility", "four", "the High Rhine ends", "the Society of St Pius X", "Christopher Eccleston", "$230 million (out of $400 million)", "$216,000", "1905", "The Talons of Weng-Chiang", "Catholic", "1606", "Bermuda 419 turf", "2", "1979", "Ren\u00e9 Georges Hermann - Paul", "9 February 2018", "the 1970s", "his friends, Humpty Dumpty and Kitty Softpaws", "to address the historic oppression, inequality and discrimination faced by those communities and to give these communities a place", "erosion", "The virion must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "depending on the gender of the reigning monarch", "1923", "weekly", "Major General Clarence L. Tinker, the first Native American Major General", "Daren Maxwell Kagasoff", "the federal government, the territories under its authority, and the provincial governments", "16", "Beorn", "January 15, 2007", "human", "1881", "Kevin Garnett", "1960 and 1980", "the United States", "Ali", "2017", "Ole Einar Bj\u00f8rndalen", "the illegitimate son of Ned Stark", "735 feet ( 224 m )", "March 31 to April 8, 2018", "99.57 %", "six 50 minute ( one - hour with advertisements ) episodes", "a password recovery tool for Microsoft Windows"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7938903478057889}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.72, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705]}}, "before_error_ids": ["mrqa_squad-validation-10479", "mrqa_squad-validation-9199", "mrqa_squad-validation-6946", "mrqa_squad-validation-448", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-6092", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-4236", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-4572"], "SR": 0.734375, "CSR": 0.6678571428571429, "EFR": 0.9411764705882353, "Overall": 0.7107910976890757}, {"timecode": 35, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_squad-validation-4629", "mrqa_squad-validation-5578", "mrqa_squad-validation-10023", "mrqa_naturalquestions-validation-2934", "mrqa_squad-validation-4062", "mrqa_squad-validation-3922", "mrqa_squad-validation-9756", "mrqa_naturalquestions-validation-10439", "mrqa_squad-validation-8899", "mrqa_squad-validation-5257", "mrqa_squad-validation-5364", "mrqa_squad-validation-6870", "mrqa_naturalquestions-validation-9059", "mrqa_squad-validation-1164", "mrqa_squad-validation-7446", "mrqa_naturalquestions-validation-3734", "mrqa_squad-validation-2018", "mrqa_squad-validation-9257", "mrqa_squad-validation-1815", "mrqa_squad-validation-4898", "mrqa_squad-validation-6010", "mrqa_naturalquestions-validation-3016", "mrqa_squad-validation-4295", "mrqa_squad-validation-5028", "mrqa_squad-validation-8455", "mrqa_squad-validation-4919", "mrqa_squad-validation-3103", "mrqa_squad-validation-3289", "mrqa_squad-validation-9600", "mrqa_squad-validation-174", "mrqa_squad-validation-887", "mrqa_squad-validation-6360", "mrqa_squad-validation-4402", "mrqa_squad-validation-3413", "mrqa_squad-validation-2508", "mrqa_squad-validation-9644", "mrqa_squad-validation-8776", "mrqa_squad-validation-5613", "mrqa_naturalquestions-validation-6466", "mrqa_squad-validation-4201", "mrqa_squad-validation-6386", "mrqa_squad-validation-2281", "mrqa_squad-validation-9371", "mrqa_squad-validation-967", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-9491", "mrqa_squad-validation-4634", "mrqa_squad-validation-10496", "mrqa_squad-validation-1366", "mrqa_squad-validation-4506", "mrqa_naturalquestions-validation-6285", "mrqa_squad-validation-8313", "mrqa_squad-validation-8487", "mrqa_squad-validation-5564", "mrqa_squad-validation-4245", "mrqa_squad-validation-7487", "mrqa_naturalquestions-validation-6041", "mrqa_naturalquestions-validation-6947", "mrqa_squad-validation-88", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-9901", "mrqa_squad-validation-9658", "mrqa_squad-validation-7846", "mrqa_naturalquestions-validation-8270", "mrqa_squad-validation-2909", "mrqa_naturalquestions-validation-7101", "mrqa_squad-validation-8948", "mrqa_squad-validation-9467", "mrqa_squad-validation-8899", "mrqa_squad-validation-1814", "mrqa_naturalquestions-validation-7058", "mrqa_squad-validation-3925", "mrqa_squad-validation-5844", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-3637", "mrqa_squad-validation-5902", "mrqa_naturalquestions-validation-473", "mrqa_squad-validation-9290", "mrqa_squad-validation-9066", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-1000", "mrqa_squad-validation-9263", "mrqa_squad-validation-4934", "mrqa_squad-validation-4915", "mrqa_squad-validation-4318", "mrqa_naturalquestions-validation-1084", "mrqa_squad-validation-7559", "mrqa_squad-validation-2113", "mrqa_squad-validation-1029", "mrqa_squad-validation-6907", "mrqa_squad-validation-7692", "mrqa_squad-validation-8713", "mrqa_squad-validation-1742", "mrqa_naturalquestions-validation-2080", "mrqa_squad-validation-955", "mrqa_squad-validation-5456", "mrqa_naturalquestions-validation-8179", "mrqa_squad-validation-722", "mrqa_squad-validation-1909", "mrqa_squad-validation-867", "mrqa_squad-validation-7744", "mrqa_squad-validation-6419", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-4871", "mrqa_naturalquestions-validation-9387", "mrqa_squad-validation-2737", "mrqa_squad-validation-4640", "mrqa_squad-validation-5606", "mrqa_naturalquestions-validation-9332", "mrqa_squad-validation-6483", "mrqa_squad-validation-8415", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-278", "mrqa_squad-validation-1427", "mrqa_squad-validation-2243", "mrqa_squad-validation-8303", "mrqa_squad-validation-7103", "mrqa_squad-validation-3806", "mrqa_squad-validation-4337", "mrqa_squad-validation-4808", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-3190", "mrqa_squad-validation-10438", "mrqa_squad-validation-4236", "mrqa_squad-validation-7880", "mrqa_squad-validation-1907", "mrqa_squad-validation-708", "mrqa_squad-validation-4183", "mrqa_naturalquestions-validation-8972", "mrqa_squad-validation-2471", "mrqa_squad-validation-10362", "mrqa_squad-validation-3101", "mrqa_squad-validation-2751", "mrqa_squad-validation-5018", "mrqa_naturalquestions-validation-4563", "mrqa_squad-validation-1517", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-664", "mrqa_naturalquestions-validation-5905", "mrqa_naturalquestions-validation-2672", "mrqa_squad-validation-9002", "mrqa_naturalquestions-validation-1706", "mrqa_squad-validation-4287", "mrqa_squad-validation-6388", "mrqa_squad-validation-9953", "mrqa_squad-validation-4878", "mrqa_naturalquestions-validation-2299", "mrqa_squad-validation-5550", "mrqa_naturalquestions-validation-8161", "mrqa_squad-validation-2050", "mrqa_squad-validation-2716", "mrqa_squad-validation-168", "mrqa_squad-validation-7608", "mrqa_squad-validation-8472", "mrqa_squad-validation-3849", "mrqa_squad-validation-455", "mrqa_squad-validation-8630", "mrqa_squad-validation-3057", "mrqa_squad-validation-5715", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-673", "mrqa_squad-validation-10397", "mrqa_squad-validation-2704", "mrqa_squad-validation-1870", "mrqa_squad-validation-2781", "mrqa_squad-validation-1777", "mrqa_squad-validation-4176", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-3935", "mrqa_squad-validation-9903", "mrqa_squad-validation-3736", "mrqa_squad-validation-9208", "mrqa_squad-validation-3456", "mrqa_squad-validation-4897", "mrqa_squad-validation-2790", "mrqa_naturalquestions-validation-2674", "mrqa_squad-validation-9381", "mrqa_naturalquestions-validation-6999", "mrqa_squad-validation-1541", "mrqa_squad-validation-6009", "mrqa_naturalquestions-validation-9371", "mrqa_squad-validation-4875", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-426", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-939", "mrqa_squad-validation-6237", "mrqa_squad-validation-8159", "mrqa_naturalquestions-validation-9692", "mrqa_naturalquestions-validation-4459", "mrqa_squad-validation-7019", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-6924", "mrqa_squad-validation-1283", "mrqa_squad-validation-516", "mrqa_naturalquestions-validation-1552", "mrqa_squad-validation-1227", "mrqa_naturalquestions-validation-7152", "mrqa_naturalquestions-validation-6140", "mrqa_squad-validation-4290", "mrqa_squad-validation-6156", "mrqa_squad-validation-4146", "mrqa_naturalquestions-validation-8763", "mrqa_squad-validation-7414", "mrqa_squad-validation-7980", "mrqa_squad-validation-3159", "mrqa_squad-validation-773", "mrqa_naturalquestions-validation-681", "mrqa_squad-validation-6034", "mrqa_squad-validation-1766", "mrqa_squad-validation-3690", "mrqa_naturalquestions-validation-1988", "mrqa_naturalquestions-validation-8450", "mrqa_squad-validation-1026", "mrqa_squad-validation-1824", "mrqa_squad-validation-7134", "mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-4029", "mrqa_squad-validation-10138", "mrqa_squad-validation-8471", "mrqa_squad-validation-6817", "mrqa_squad-validation-6451", "mrqa_squad-validation-8691", "mrqa_squad-validation-1388", "mrqa_squad-validation-403", "mrqa_squad-validation-1127", "mrqa_squad-validation-2238", "mrqa_squad-validation-3826", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-7167", "mrqa_naturalquestions-validation-7819", "mrqa_squad-validation-4065", "mrqa_squad-validation-5637", "mrqa_squad-validation-5293", "mrqa_squad-validation-3076", "mrqa_squad-validation-3268", "mrqa_squad-validation-8000", "mrqa_squad-validation-5916", "mrqa_squad-validation-804", "mrqa_squad-validation-5854", "mrqa_squad-validation-480", "mrqa_naturalquestions-validation-6586", "mrqa_squad-validation-5861", "mrqa_squad-validation-51", "mrqa_squad-validation-8047", "mrqa_squad-validation-602", "mrqa_squad-validation-7135", "mrqa_naturalquestions-validation-7097", "mrqa_squad-validation-7580", "mrqa_squad-validation-5131", "mrqa_squad-validation-3491", "mrqa_squad-validation-3999", "mrqa_squad-validation-4230", "mrqa_squad-validation-1716", "mrqa_naturalquestions-validation-1694", "mrqa_squad-validation-3267", "mrqa_naturalquestions-validation-9564", "mrqa_squad-validation-1132", "mrqa_squad-validation-5483", "mrqa_naturalquestions-validation-1340", "mrqa_squad-validation-10056", "mrqa_squad-validation-1346", "mrqa_squad-validation-9597", "mrqa_squad-validation-6872", "mrqa_squad-validation-5168", "mrqa_squad-validation-6719", "mrqa_squad-validation-7382", "mrqa_squad-validation-2888", "mrqa_naturalquestions-validation-591", "mrqa_squad-validation-2466", "mrqa_squad-validation-4826", "mrqa_squad-validation-2085", "mrqa_squad-validation-9809", "mrqa_squad-validation-1508", "mrqa_squad-validation-2273", "mrqa_squad-validation-646", "mrqa_squad-validation-2000", "mrqa_squad-validation-9941", "mrqa_squad-validation-6358", "mrqa_naturalquestions-validation-9172", "mrqa_squad-validation-1981", "mrqa_naturalquestions-validation-6887", "mrqa_squad-validation-499", "mrqa_squad-validation-3910", "mrqa_squad-validation-5860", "mrqa_squad-validation-7491", "mrqa_squad-validation-5935", "mrqa_squad-validation-4315", "mrqa_squad-validation-1522", "mrqa_naturalquestions-validation-8037", "mrqa_squad-validation-1119", "mrqa_squad-validation-5759", "mrqa_squad-validation-1383", "mrqa_squad-validation-5174", "mrqa_naturalquestions-validation-3395", "mrqa_squad-validation-7417", "mrqa_squad-validation-5641", "mrqa_squad-validation-1955", "mrqa_squad-validation-3044", "mrqa_squad-validation-9", "mrqa_squad-validation-796", "mrqa_squad-validation-9666", "mrqa_squad-validation-222", "mrqa_squad-validation-9671", "mrqa_naturalquestions-validation-9880", "mrqa_squad-validation-7721", "mrqa_squad-validation-8787", "mrqa_squad-validation-9566", "mrqa_squad-validation-4204", "mrqa_naturalquestions-validation-10433", "mrqa_squad-validation-7162", "mrqa_squad-validation-5846", "mrqa_squad-validation-9923", "mrqa_squad-validation-5519", "mrqa_squad-validation-416", "mrqa_naturalquestions-validation-7293", "mrqa_squad-validation-6327", "mrqa_squad-validation-5156", "mrqa_squad-validation-6651", "mrqa_squad-validation-57", "mrqa_squad-validation-8329", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-2877", "mrqa_naturalquestions-validation-2255", "mrqa_squad-validation-1548", "mrqa_squad-validation-6160", "mrqa_squad-validation-3150", "mrqa_squad-validation-10149", "mrqa_squad-validation-6367", "mrqa_squad-validation-2253", "mrqa_squad-validation-9718", "mrqa_squad-validation-5169", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-4829", "mrqa_naturalquestions-validation-9692", "mrqa_squad-validation-9326", "mrqa_squad-validation-5881", "mrqa_squad-validation-978", "mrqa_squad-validation-1637", "mrqa_squad-validation-3555", "mrqa_squad-validation-6950", "mrqa_naturalquestions-validation-3651", "mrqa_squad-validation-6459", "mrqa_naturalquestions-validation-2870", "mrqa_squad-validation-402", "mrqa_squad-validation-7698", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-9375", "mrqa_squad-validation-9692", "mrqa_naturalquestions-validation-7065", "mrqa_squad-validation-847", "mrqa_squad-validation-3926", "mrqa_squad-validation-7906", "mrqa_squad-validation-3392", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-2552", "mrqa_squad-validation-10133", "mrqa_squad-validation-1647", "mrqa_squad-validation-7259", "mrqa_squad-validation-2075", "mrqa_squad-validation-7686", "mrqa_squad-validation-3333", "mrqa_squad-validation-7410", "mrqa_naturalquestions-validation-6624", "mrqa_squad-validation-7321", "mrqa_naturalquestions-validation-7415", "mrqa_squad-validation-1328", "mrqa_squad-validation-2576", "mrqa_squad-validation-9904", "mrqa_squad-validation-1541", "mrqa_squad-validation-4680", "mrqa_squad-validation-3223", "mrqa_squad-validation-7967", "mrqa_squad-validation-5092", "mrqa_squad-validation-7370", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-1626", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3405", "mrqa_squad-validation-60", "mrqa_naturalquestions-validation-1339", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-6800", "mrqa_squad-validation-9645", "mrqa_naturalquestions-validation-379", "mrqa_naturalquestions-validation-5674", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-4074", "mrqa_squad-validation-4331", "mrqa_naturalquestions-validation-1901", "mrqa_squad-validation-4235", "mrqa_squad-validation-9767", "mrqa_squad-validation-5213", "mrqa_squad-validation-8034", "mrqa_squad-validation-3846", "mrqa_squad-validation-8194", "mrqa_squad-validation-3028", "mrqa_squad-validation-5047", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-10396", "mrqa_squad-validation-5429", "mrqa_squad-validation-8310", "mrqa_squad-validation-3767", "mrqa_squad-validation-1863", "mrqa_naturalquestions-validation-10618", "mrqa_squad-validation-9103", "mrqa_squad-validation-1881", "mrqa_squad-validation-8782", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-2044", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-1750", "mrqa_squad-validation-4320", "mrqa_squad-validation-5769", "mrqa_squad-validation-7503", "mrqa_squad-validation-2980", "mrqa_squad-validation-3695", "mrqa_squad-validation-9641", "mrqa_squad-validation-5693", "mrqa_squad-validation-6865", "mrqa_naturalquestions-validation-10091", "mrqa_squad-validation-1228", "mrqa_squad-validation-1443", "mrqa_squad-validation-9422", "mrqa_squad-validation-9055", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-1500", "mrqa_naturalquestions-validation-1429", "mrqa_squad-validation-7890", "mrqa_squad-validation-6980", "mrqa_squad-validation-10397", "mrqa_squad-validation-1042", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-6452", "mrqa_squad-validation-5334", "mrqa_squad-validation-10365", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-8725", "mrqa_naturalquestions-validation-1310", "mrqa_squad-validation-5594", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-4078", "mrqa_squad-validation-2562", "mrqa_squad-validation-3773", "mrqa_squad-validation-6651", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-8994", "mrqa_squad-validation-7965", "mrqa_squad-validation-5891", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-7235", "mrqa_squad-validation-3397", "mrqa_squad-validation-9141", "mrqa_squad-validation-1800", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-488", "mrqa_squad-validation-8219", "mrqa_squad-validation-31", "mrqa_squad-validation-4108", "mrqa_squad-validation-9145", "mrqa_squad-validation-6455", "mrqa_naturalquestions-validation-6453", "mrqa_squad-validation-2882", "mrqa_squad-validation-4561", "mrqa_squad-validation-1815", "mrqa_squad-validation-639", "mrqa_squad-validation-7088", "mrqa_naturalquestions-validation-9160", "mrqa_squad-validation-9928", "mrqa_squad-validation-10320", "mrqa_squad-validation-1427", "mrqa_squad-validation-462", "mrqa_squad-validation-835", "mrqa_naturalquestions-validation-6461", "mrqa_squad-validation-9569", "mrqa_squad-validation-5847", "mrqa_squad-validation-10336", "mrqa_naturalquestions-validation-8603", "mrqa_squad-validation-3259", "mrqa_squad-validation-6197", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-1233", "mrqa_squad-validation-3757", "mrqa_naturalquestions-validation-2989", "mrqa_squad-validation-5472", "mrqa_squad-validation-8794", "mrqa_naturalquestions-validation-2297", "mrqa_squad-validation-6213", "mrqa_squad-validation-8084", "mrqa_squad-validation-8544", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-4645", "mrqa_squad-validation-5051", "mrqa_naturalquestions-validation-4435", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-956", "mrqa_squad-validation-6584", "mrqa_squad-validation-2663", "mrqa_naturalquestions-validation-6093", "mrqa_squad-validation-7567", "mrqa_naturalquestions-validation-156", "mrqa_squad-validation-1795", "mrqa_squad-validation-1176", "mrqa_squad-validation-4456", "mrqa_squad-validation-3601"], "OKR": 0.89453125, "before_eval_results": {"predictions": ["Jonathan Stewart", "Ed Lee", "the Chancel Chapel from Santa Chiara Florence", "they are judged \" wrong\" by an individual conscience", "New South Wales", "the day after their original broadcast", "Levi's Stadium", "British", "Skaro", "Muslim medicine", "Nobel Prize", "a modified version of the sieve that considers 1 as prime would eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "Te Deum", "allegations of professional misconduct", "Gateshead Council", "pharmacists are expected to become more integral within the health care system", "William the Lion", "Graham Gano", "a 700 megawatt coal-fired power plant may use about 3600 cubic metres of make-up water every hour", "the MetroCentre", "between June and September", "1973\u201374", "surnames", "their violence", "Pakistan", "lower", "the south-east of Australia", "an area of science where our scientific understanding is rapidly changing", "materia medica", "mineral deposits", "4,530", "pastor", "In Time", "Johannes Gutenberg", "Governor Al Smith", "Elizabeth Dean Lail", "Phil Simms", "pathology", "Cheryl Campbell", "mashed potato", "Thomas Jefferson", "Donald Fauntleroy Duck", "September 21, 2016", "mashed potato", "Matthew Gregory Wise", "Magnavox Odyssey", "St. Pauli Girl Lager", "Taron Egerton", "Mankombu Sambasivan Swaminathan", "Western Australia", "2015", "Thomas Alva Edison", "April 3, 1973", "1985", "Mercedes -Benz G - Class", "4.09", "Amybeth McNulty", "Most days are sunny throughout the year", "Number 4, Privet Drive, Little Whinging in Surrey, England", "Selena Gomez", "Hellenismos", "1912", "George Harrison", "The Annunciation"], "metric_results": {"EM": 0.703125, "QA-F1": 0.77949016563147}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.782608695652174, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5723", "mrqa_squad-validation-9064", "mrqa_squad-validation-2460", "mrqa_squad-validation-1906", "mrqa_squad-validation-3403", "mrqa_squad-validation-2493", "mrqa_squad-validation-8470", "mrqa_naturalquestions-validation-8541", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-4432", "mrqa_naturalquestions-validation-2644", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-10381", "mrqa_naturalquestions-validation-4903"], "SR": 0.703125, "CSR": 0.6688368055555556, "EFR": 0.9473684210526315, "Overall": 0.7266785453216374}, {"timecode": 36, "before_eval_results": {"predictions": ["V", "1622", "six", "1852", "Yuri Gagarin", "case law by the Court of Justice", "Brownlee", "gurus", "The Brain of Morbius", "ozone", "the city council", "Camp Pendleton", "5 Live Sports Extra", "defensins", "shortening the cutoff", "1814", "Los Angeles International Airport", "nonverbal expressions of enthusiasm, such as demonstrative gesturing, dramatic movements which are varied, and emotional facial expressions, result in college students reporting higher levels of intrinsic motivation to learn", "Kabaty Forest", "the sixteenth century", "Visa Inc", "Pacific", "more than 48 hours", "New Holland", "Christopher Gist", "plug-n-play system", "the 6th century", "pre-allocation of network bandwidth", "17,000", "the Muslim Brotherhood", "Kearney Mansion", "over 300,000", "DeWayne Warren", "Warren Hastings", "Billy Colman", "Dougie MacLean", "Saint Alphonsa", "1948", "Carroll O'Connor", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "a simple majority vote", "Jenny slate", "western Cuba", "Pakistan", "Filipino American", "Darlene Cates", "1980", "the central plains", "The long - hair gene is recessive", "Brooks & Dunn", "four", "Gayla Peevey", "the New Testament canon", "2015", "the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "Madison", "Lady Gaga", "Olivia O'Brien", "the nucleotide uracil", "Robert Downey Jr.", "the nation's capital in Washington, D.C.", "$2 million", "1889", "Austria - Hungary"], "metric_results": {"EM": 0.625, "QA-F1": 0.7452380952380953}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.9166666666666666, 0.8, 1.0, 0.2666666666666667, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 0.09523809523809523, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1849", "mrqa_squad-validation-9445", "mrqa_squad-validation-1986", "mrqa_squad-validation-4822", "mrqa_squad-validation-9599", "mrqa_squad-validation-4573", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-6435", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-3562", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-3440", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-4263", "mrqa_naturalquestions-validation-2558", "mrqa_naturalquestions-validation-171", "mrqa_naturalquestions-validation-10537", "mrqa_naturalquestions-validation-6278"], "SR": 0.625, "CSR": 0.667652027027027, "EFR": 0.9583333333333334, "Overall": 0.728634572072072}, {"timecode": 37, "before_eval_results": {"predictions": ["The fundamental theorem of arithmetic", "October 1948", "Children's Memorial Health Institute", "Several University of Chicago professors", "1948", "nine", "the Sunday Service of the Methodists in North America", "Monte Gargano", "stagnant wages for the working class amidst rising levels of property income for the capitalist class", "an ignition event, such as heat or a spark,", "Thomas Sowell", "Besan\u00e7on Hugues", "March 2011", "1964", "rebellion", "in commerce, schooling and government", "a two-membraned chloroplast", "the Hostmen", "Innate immune systems", "Euclid", "railroad", "boarding schools and day schools", "permanent pulmonary fibrosis", "New Paltz", "Tiffany & Co.", "not having a residence permit", "a German Nazi colonial administration", "the Apollo astronauts were chosen from the Project Mercury and Gemini veterans, plus from two later astronaut groups", "George Westinghouse", "disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac, including caches of supplies destined for New France's western forts and furs destined for Europe", "to describe the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Taylor Michel Momsen", "Cal", "around 2011", "November 26, 1956", "counter clockwise", "2018", "Olivia Olson", "mid-March", "tropical subtropical climate, with hot summers and mild winters", "agriculture", "18 UEFA Champions League knockout phase", "eleven", "Meri", "pre-Christian festivals that were celebrated around the winter solstice", "Kyla Pratt", "Cee - Lo", "Donald Sutherland", "A remittance", "Wembley Stadium", "Pac - 12 Conference Champions Stanford Cardinal", "22 \u00b0 00 \u2032 N 80 \u00b0 00", "Computer simulation", "2004", "`` Sacrifice ''", "March 2, 2016", "March 29, 2018", "T.J. Miller", "Aaron Lewis", "an Arabic masculine given name and occasional surname with the meaning `` beloved ''", "Marcus Atilius Regulus", "April 26, 2005", "Noel Kahn", "Ferm\u00edn Francisco de Lasu\u00e9n"], "metric_results": {"EM": 0.703125, "QA-F1": 0.776913181174123}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 0.06451612903225806, 0.6086956521739131, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9977", "mrqa_squad-validation-7189", "mrqa_squad-validation-6683", "mrqa_squad-validation-6918", "mrqa_squad-validation-3057", "mrqa_squad-validation-3899", "mrqa_squad-validation-10293", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-204", "mrqa_naturalquestions-validation-9961", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-5451", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-7741", "mrqa_naturalquestions-validation-5675"], "SR": 0.703125, "CSR": 0.6685855263157895, "EFR": 0.8421052631578947, "Overall": 0.7055756578947368}, {"timecode": 38, "before_eval_results": {"predictions": ["pH or available iron", "the gastrodermis", "1943", "the Prophet Mohammad", "whether he stood by their contents", "high wages", "Doctor Who (The Infinite Quest)", "1534", "triploblastic", "Encoded Archival description (EAD)", "Geneva", "James Hutton", "General Electric", "luxurious parks and royal gardens", "March", "impact process effects", "Basel, leaving Switzerland", "Diarmaid MacCulloch, Professor of the History of the Church in the University of Oxford", "more than 28 days in national law", "Buddhism and Christianity", "Hans Hillerbrand", "in his hotel room", "illiberal Islamic regimes", "kteis 'comb' and \u03c6\u03ad\u03c1\u03c9 pher\u014d 'carry'; commonly known as comb jellies", "that he dropped out of school", "Dignity Health", "effective planning", "a wide glacial alpine valley known as the Rhine Valley (German: Rheintal)", "the Twelfth Doctor", "Excellent job opportunities are expected as retirements, especially among secondary school teachers, outweigh slowing enrollment growth", "in Africa", "Peter Andrew Beardsley MBE", "energy loss", "rootlets ( branch roots )", "the player", "a Midwestern theater owner named Glen W. Dickson", "James Corden", "defense against rain", "four", "Hellenic polytheist", "1878", "Randy Newman", "2007", "Pangaea or Pangea", "the early 1800s", "the last Xterra would be sold in the fall of 2015", "gastrocnemius", "eight years after an amendment increased the tenure length by two years", "1963", "Scarlett Johansson", "71 -- 74 \u00b0 C ( 160 -- 165 \u00b0 F )", "the downfall of the fascist government in Italy and the elimination of Germany's main European ally", "Castleford", "in the Chicago metropolitan area in 1982", "March 16, 2018", "energy moves from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "Dalveer Bhandari", "31 March 2018", "2.5 %", "eleven", "March 2016", "Thomas Edison", "the attack on the task force", "the Corinthian and Saronic Gulfs, but joined by the Isthmus of Corinth"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6740992366766361}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.7272727272727273, 1.0, 1.0, 0.8571428571428571, 1.0, 0.7058823529411764, 1.0, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.3157894736842105, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.6, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.19999999999999998, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4516", "mrqa_squad-validation-7767", "mrqa_squad-validation-4441", "mrqa_squad-validation-3240", "mrqa_squad-validation-2560", "mrqa_squad-validation-4093", "mrqa_squad-validation-1632", "mrqa_squad-validation-4534", "mrqa_squad-validation-9126", "mrqa_squad-validation-7874", "mrqa_squad-validation-2054", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-4200", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-5396", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-2064"], "SR": 0.5625, "CSR": 0.6658653846153846, "EFR": 1.0, "Overall": 0.7366105769230769}, {"timecode": 39, "before_eval_results": {"predictions": ["a system of many biological structures and processes within an organism that protects against disease", "(rise and fall according to market demand)", "the time or space used by the algorithm", "the Migration period", "even ranked above", "6.04 milliliters", "City Road", "1 and less than or equal to the square root of n", "T\u00f6regene Khatun", "a former monastery, \"The Black Cloister,\"", "Shiphrah and Puah", "the difference between a problem and an instance", "132 million tons", "State Route 99", "about 75,000", "Sea of Japan", "Downtown San Bernardino", "Annual Conference Cabinet", "Jebe", "medication management system development, deployment and optimization", "downward pressure on wages", "this was part of the Seven Years' War", "anaerobic bacteria", "sea gooseberry", "hymnals", "the mountains", "the best teachers", "the ability to pursue valued goals", "\u00d6gedei Khan", "between 3.9 and 5.5 glyc / L ( 70 to 100 mg / dL )", "the nine original departments of Uruguay", "Phosphorus pentoxide", "1937", "May 1, 2018", "Tyke", "RAF Bovingdon", "the organ transplant", "an interchange with US 250 near Interstate 64 ( I - 64 ) in Rockfish Gap", "Hugo Weaving", "to prevent further offense", "up to 100,000", "the end of the Coming Out show on 15 December 2017", "the temporal lobes", "2005", "the angel Balthazar changes history in the sixth season episode `` My Heart Will Go On '' so that the Titanic never sank", "Gorakhpur Junction", "Panama Canal Authority", "by a hydrolysis reaction", "The vascular cambium", "Coton in the Elms", "Australia's Sir Donald Bradman", "the episode `` Killer Within ''", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "Profit maximization", "Nalini Negi", "The Hunger Games : Mockingjay -- Part 1 ( 2014 )", "Vasoepididymostomy", "John Goodman", "Eddie Murphy", "transceivers, each with an antenna, and a source of energy ( such as a battery, a portable generator, or the electrical grid )", "December 1800", "Frankie Muniz", "Number 4, Privet Drive, Little Whinging in Surrey, England", "Alicia Keys, Jhen\u00e9 Aiko, India Arie, and Solange Knowles & Destiny's Child"], "metric_results": {"EM": 0.625, "QA-F1": 0.7647613655969634}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.88, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6086956521739131, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 0.22222222222222224, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.9600000000000001, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.8571428571428571, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288]}}, "before_error_ids": ["mrqa_squad-validation-1687", "mrqa_squad-validation-6329", "mrqa_squad-validation-9004", "mrqa_squad-validation-2513", "mrqa_squad-validation-1670", "mrqa_squad-validation-2644", "mrqa_squad-validation-10165", "mrqa_naturalquestions-validation-9076", "mrqa_naturalquestions-validation-6765", "mrqa_naturalquestions-validation-3469", "mrqa_naturalquestions-validation-2269", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-3341", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1735", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-2264"], "SR": 0.625, "CSR": 0.66484375, "EFR": 0.8333333333333334, "Overall": 0.7030729166666666}, {"timecode": 40, "UKR": 0.697265625, "OKR_sampled_ids": ["mrqa_squad-validation-3259", "mrqa_naturalquestions-validation-6093", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-9248", "mrqa_squad-validation-6327", "mrqa_naturalquestions-validation-7250", "mrqa_squad-validation-8012", "mrqa_squad-validation-2999", "mrqa_naturalquestions-validation-8662", "mrqa_squad-validation-317", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-3263", "mrqa_squad-validation-1849", "mrqa_squad-validation-4511", "mrqa_squad-validation-3340", "mrqa_naturalquestions-validation-8599", "mrqa_squad-validation-7516", "mrqa_naturalquestions-validation-1427", "mrqa_squad-validation-1886", "mrqa_naturalquestions-validation-9422", "mrqa_squad-validation-1870", "mrqa_naturalquestions-validation-7881", "mrqa_squad-validation-2382", "mrqa_squad-validation-2070", "mrqa_naturalquestions-validation-6678", "mrqa_squad-validation-6696", "mrqa_squad-validation-7915", "mrqa_squad-validation-4332", "mrqa_naturalquestions-validation-3545", "mrqa_squad-validation-7582", "mrqa_squad-validation-1184", "mrqa_naturalquestions-validation-7387", "mrqa_squad-validation-83", "mrqa_squad-validation-6367", "mrqa_naturalquestions-validation-2928", "mrqa_squad-validation-1123", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-8270", "mrqa_squad-validation-6160", "mrqa_squad-validation-8788", "mrqa_squad-validation-7989", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-6009", "mrqa_squad-validation-97", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-3236", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-7059", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-7473", "mrqa_squad-validation-3432", "mrqa_squad-validation-7469", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-2909", "mrqa_squad-validation-9846", "mrqa_squad-validation-9798", "mrqa_squad-validation-6345", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-6143", "mrqa_squad-validation-2647", "mrqa_squad-validation-10317", "mrqa_squad-validation-10418", "mrqa_squad-validation-2018", "mrqa_squad-validation-9928", "mrqa_squad-validation-9720", "mrqa_naturalquestions-validation-10078", "mrqa_squad-validation-883", "mrqa_squad-validation-9412", "mrqa_squad-validation-6240", "mrqa_squad-validation-8118", "mrqa_squad-validation-2192", "mrqa_squad-validation-2611", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-444", "mrqa_squad-validation-841", "mrqa_squad-validation-9977", "mrqa_squad-validation-4235", "mrqa_squad-validation-64", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-6517", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8765", "mrqa_squad-validation-8888", "mrqa_squad-validation-2882", "mrqa_naturalquestions-validation-4776", "mrqa_naturalquestions-validation-9129", "mrqa_squad-validation-1909", "mrqa_naturalquestions-validation-10546", "mrqa_squad-validation-4095", "mrqa_squad-validation-2562", "mrqa_squad-validation-3991", "mrqa_squad-validation-9348", "mrqa_naturalquestions-validation-1988", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-3623", "mrqa_squad-validation-4023", "mrqa_squad-validation-5703", "mrqa_naturalquestions-validation-1989", "mrqa_squad-validation-539", "mrqa_squad-validation-833", "mrqa_naturalquestions-validation-6234", "mrqa_squad-validation-3163", "mrqa_naturalquestions-validation-8298", "mrqa_squad-validation-7107", "mrqa_naturalquestions-validation-4459", "mrqa_squad-validation-6388", "mrqa_squad-validation-8105", "mrqa_squad-validation-2651", "mrqa_squad-validation-509", "mrqa_naturalquestions-validation-5396", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-8781", "mrqa_squad-validation-94", "mrqa_squad-validation-7880", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6665", "mrqa_squad-validation-7793", "mrqa_squad-validation-1609", "mrqa_squad-validation-8811", "mrqa_squad-validation-8983", "mrqa_squad-validation-7420", "mrqa_squad-validation-146", "mrqa_naturalquestions-validation-10098", "mrqa_squad-validation-7044", "mrqa_naturalquestions-validation-4925", "mrqa_naturalquestions-validation-10618", "mrqa_squad-validation-9009", "mrqa_squad-validation-7134", "mrqa_squad-validation-9640", "mrqa_squad-validation-3031", "mrqa_squad-validation-7507", "mrqa_squad-validation-5687", "mrqa_squad-validation-5013", "mrqa_naturalquestions-validation-1735", "mrqa_squad-validation-2514", "mrqa_squad-validation-4902", "mrqa_squad-validation-1777", "mrqa_squad-validation-5425", "mrqa_naturalquestions-validation-4558", "mrqa_naturalquestions-validation-2578", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3630", "mrqa_squad-validation-1941", "mrqa_squad-validation-9991", "mrqa_squad-validation-4325", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-403", "mrqa_squad-validation-6105", "mrqa_squad-validation-7492", "mrqa_squad-validation-7491", "mrqa_naturalquestions-validation-4903", "mrqa_squad-validation-5860", "mrqa_squad-validation-4337", "mrqa_squad-validation-3849", "mrqa_squad-validation-3965", "mrqa_naturalquestions-validation-8216", "mrqa_squad-validation-6810", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-9499", "mrqa_squad-validation-3690", "mrqa_squad-validation-9286", "mrqa_squad-validation-5694", "mrqa_squad-validation-3397", "mrqa_squad-validation-7186", "mrqa_squad-validation-3491", "mrqa_squad-validation-3133", "mrqa_squad-validation-8281", "mrqa_squad-validation-6009", "mrqa_naturalquestions-validation-2890", "mrqa_squad-validation-7859", "mrqa_squad-validation-2689", "mrqa_squad-validation-3150", "mrqa_squad-validation-8725", "mrqa_squad-validation-8003", "mrqa_squad-validation-3392", "mrqa_squad-validation-315", "mrqa_squad-validation-7596", "mrqa_squad-validation-10362", "mrqa_squad-validation-4952", "mrqa_squad-validation-9329", "mrqa_squad-validation-924", "mrqa_squad-validation-5836", "mrqa_squad-validation-9311", "mrqa_squad-validation-8679", "mrqa_squad-validation-5324", "mrqa_squad-validation-8310", "mrqa_naturalquestions-validation-1248", "mrqa_squad-validation-5891", "mrqa_squad-validation-447", "mrqa_naturalquestions-validation-2255", "mrqa_naturalquestions-validation-930", "mrqa_squad-validation-8158", "mrqa_squad-validation-5334", "mrqa_squad-validation-3406", "mrqa_naturalquestions-validation-3319", "mrqa_squad-validation-9528", "mrqa_squad-validation-7645", "mrqa_squad-validation-406", "mrqa_naturalquestions-validation-1400", "mrqa_squad-validation-3712", "mrqa_squad-validation-3070", "mrqa_squad-validation-4826", "mrqa_naturalquestions-validation-2190", "mrqa_squad-validation-8899", "mrqa_squad-validation-8526", "mrqa_squad-validation-7452", "mrqa_naturalquestions-validation-3074", "mrqa_squad-validation-4750", "mrqa_naturalquestions-validation-8417", "mrqa_squad-validation-7953", "mrqa_squad-validation-10442", "mrqa_naturalquestions-validation-5371", "mrqa_naturalquestions-validation-8727", "mrqa_squad-validation-133", "mrqa_squad-validation-6545", "mrqa_squad-validation-417", "mrqa_squad-validation-7108", "mrqa_squad-validation-3486", "mrqa_naturalquestions-validation-10529", "mrqa_squad-validation-878", "mrqa_squad-validation-4665", "mrqa_squad-validation-1170", "mrqa_squad-validation-3255", "mrqa_naturalquestions-validation-6307", "mrqa_squad-validation-5421", "mrqa_squad-validation-3846", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-1670", "mrqa_squad-validation-7567", "mrqa_naturalquestions-validation-681", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-8534", "mrqa_squad-validation-1863", "mrqa_naturalquestions-validation-6088", "mrqa_squad-validation-1395", "mrqa_squad-validation-5508", "mrqa_naturalquestions-validation-2256", "mrqa_squad-validation-8403", "mrqa_squad-validation-1017", "mrqa_squad-validation-6250", "mrqa_squad-validation-6197", "mrqa_naturalquestions-validation-10135", "mrqa_squad-validation-9956", "mrqa_squad-validation-9679", "mrqa_naturalquestions-validation-4572", "mrqa_squad-validation-3253", "mrqa_squad-validation-3133", "mrqa_squad-validation-3142", "mrqa_squad-validation-1245", "mrqa_squad-validation-3690", "mrqa_squad-validation-1229", "mrqa_squad-validation-1427", "mrqa_squad-validation-9550", "mrqa_naturalquestions-validation-2406", "mrqa_naturalquestions-validation-2380", "mrqa_squad-validation-3873", "mrqa_squad-validation-7414", "mrqa_squad-validation-7558", "mrqa_squad-validation-584", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-3486", "mrqa_squad-validation-3862", "mrqa_squad-validation-939", "mrqa_naturalquestions-validation-3061", "mrqa_squad-validation-925", "mrqa_squad-validation-9", "mrqa_naturalquestions-validation-7359", "mrqa_naturalquestions-validation-5674", "mrqa_naturalquestions-validation-3637", "mrqa_squad-validation-571", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-1611", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-4204", "mrqa_squad-validation-9641", "mrqa_naturalquestions-validation-3651", "mrqa_squad-validation-6360", "mrqa_squad-validation-5530", "mrqa_squad-validation-2238", "mrqa_squad-validation-4176", "mrqa_squad-validation-1227", "mrqa_squad-validation-10165", "mrqa_squad-validation-7232", "mrqa_squad-validation-5624", "mrqa_squad-validation-8691", "mrqa_naturalquestions-validation-134", "mrqa_squad-validation-9718", "mrqa_naturalquestions-validation-3267", "mrqa_squad-validation-9913", "mrqa_squad-validation-7692", "mrqa_squad-validation-8782", "mrqa_squad-validation-3555", "mrqa_squad-validation-7316", "mrqa_squad-validation-8398", "mrqa_naturalquestions-validation-6931", "mrqa_squad-validation-4273", "mrqa_squad-validation-5213", "mrqa_squad-validation-6373", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-4976", "mrqa_squad-validation-3925", "mrqa_naturalquestions-validation-9756", "mrqa_squad-validation-648", "mrqa_squad-validation-5861", "mrqa_squad-validation-7208", "mrqa_squad-validation-6366", "mrqa_squad-validation-8452", "mrqa_squad-validation-6481", "mrqa_squad-validation-9569", "mrqa_naturalquestions-validation-4288", "mrqa_squad-validation-4320", "mrqa_squad-validation-9034", "mrqa_naturalquestions-validation-3926", "mrqa_squad-validation-4402", "mrqa_naturalquestions-validation-1310", "mrqa_squad-validation-6719", "mrqa_squad-validation-2147", "mrqa_squad-validation-2654", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-2254", "mrqa_squad-validation-10023", "mrqa_squad-validation-10418", "mrqa_squad-validation-7559", "mrqa_naturalquestions-validation-5236", "mrqa_naturalquestions-validation-9564", "mrqa_squad-validation-2790", "mrqa_squad-validation-6116", "mrqa_squad-validation-9035", "mrqa_naturalquestions-validation-49", "mrqa_squad-validation-3757", "mrqa_squad-validation-1637", "mrqa_squad-validation-4315", "mrqa_naturalquestions-validation-8728", "mrqa_squad-validation-6420", "mrqa_squad-validation-7584", "mrqa_squad-validation-484", "mrqa_squad-validation-3942", "mrqa_squad-validation-5584", "mrqa_squad-validation-1042", "mrqa_squad-validation-6576", "mrqa_naturalquestions-validation-1770", "mrqa_squad-validation-8472", "mrqa_naturalquestions-validation-5449", "mrqa_squad-validation-7328", "mrqa_squad-validation-1789", "mrqa_squad-validation-537", "mrqa_squad-validation-1388", "mrqa_naturalquestions-validation-6763", "mrqa_squad-validation-804", "mrqa_squad-validation-9263", "mrqa_squad-validation-442", "mrqa_naturalquestions-validation-8577", "mrqa_naturalquestions-validation-7754", "mrqa_squad-validation-6054", "mrqa_squad-validation-9675", "mrqa_squad-validation-2199", "mrqa_squad-validation-6994", "mrqa_squad-validation-9718", "mrqa_squad-validation-10296", "mrqa_squad-validation-6952", "mrqa_squad-validation-10056", "mrqa_naturalquestions-validation-4645", "mrqa_squad-validation-4878", "mrqa_squad-validation-5329", "mrqa_squad-validation-5098", "mrqa_squad-validation-8180", "mrqa_naturalquestions-validation-4855", "mrqa_squad-validation-6883", "mrqa_squad-validation-5257", "mrqa_squad-validation-1132", "mrqa_squad-validation-7125", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-297", "mrqa_squad-validation-9969", "mrqa_naturalquestions-validation-7266", "mrqa_squad-validation-1057", "mrqa_squad-validation-1548", "mrqa_squad-validation-9410", "mrqa_squad-validation-8219", "mrqa_squad-validation-3343", "mrqa_naturalquestions-validation-4741", "mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-5633", "mrqa_squad-validation-5640", "mrqa_squad-validation-4062", "mrqa_squad-validation-7261", "mrqa_naturalquestions-validation-5049", "mrqa_naturalquestions-validation-9295", "mrqa_squad-validation-4290", "mrqa_squad-validation-7622", "mrqa_squad-validation-2235", "mrqa_squad-validation-1018", "mrqa_squad-validation-7646", "mrqa_naturalquestions-validation-6140", "mrqa_squad-validation-9381", "mrqa_squad-validation-5932", "mrqa_squad-validation-3730", "mrqa_squad-validation-57", "mrqa_squad-validation-5536", "mrqa_squad-validation-4822", "mrqa_naturalquestions-validation-4029", "mrqa_squad-validation-9866", "mrqa_squad-validation-4121", "mrqa_squad-validation-2835", "mrqa_squad-validation-36", "mrqa_squad-validation-5836", "mrqa_squad-validation-8368", "mrqa_naturalquestions-validation-6193", "mrqa_squad-validation-1434", "mrqa_squad-validation-4897", "mrqa_naturalquestions-validation-7415", "mrqa_squad-validation-2332", "mrqa_squad-validation-1176", "mrqa_squad-validation-4778", "mrqa_squad-validation-1113", "mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-9311", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-8757", "mrqa_squad-validation-1541", "mrqa_squad-validation-4183", "mrqa_squad-validation-1881", "mrqa_squad-validation-3636", "mrqa_squad-validation-3137", "mrqa_squad-validation-10365", "mrqa_squad-validation-1257", "mrqa_squad-validation-7713", "mrqa_squad-validation-4447", "mrqa_squad-validation-3345", "mrqa_squad-validation-3190", "mrqa_squad-validation-1656", "mrqa_squad-validation-4311", "mrqa_naturalquestions-validation-6278", "mrqa_squad-validation-2448", "mrqa_squad-validation-3545", "mrqa_naturalquestions-validation-3395", "mrqa_squad-validation-9023", "mrqa_naturalquestions-validation-4973", "mrqa_naturalquestions-validation-10319", "mrqa_squad-validation-7175", "mrqa_squad-validation-118", "mrqa_naturalquestions-validation-7627", "mrqa_squad-validation-7184", "mrqa_naturalquestions-validation-3094", "mrqa_squad-validation-1289", "mrqa_naturalquestions-validation-7892", "mrqa_squad-validation-7410", "mrqa_squad-validation-164", "mrqa_squad-validation-259", "mrqa_squad-validation-8544", "mrqa_squad-validation-6945", "mrqa_naturalquestions-validation-5719", "mrqa_squad-validation-835", "mrqa_squad-validation-8572", "mrqa_squad-validation-8422", "mrqa_squad-validation-4088", "mrqa_squad-validation-826", "mrqa_squad-validation-9078", "mrqa_squad-validation-2050", "mrqa_squad-validation-7408", "mrqa_naturalquestions-validation-1756", "mrqa_squad-validation-4245", "mrqa_naturalquestions-validation-1491", "mrqa_squad-validation-710", "mrqa_squad-validation-9895", "mrqa_squad-validation-8068", "mrqa_naturalquestions-validation-4871", "mrqa_squad-validation-6463", "mrqa_naturalquestions-validation-8277", "mrqa_squad-validation-6101", "mrqa_naturalquestions-validation-3376", "mrqa_squad-validation-10397", "mrqa_squad-validation-132", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-7626", "mrqa_squad-validation-6964", "mrqa_squad-validation-1766", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-9467", "mrqa_squad-validation-5084", "mrqa_squad-validation-8168", "mrqa_squad-validation-3270", "mrqa_squad-validation-3296", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-8964", "mrqa_squad-validation-8868", "mrqa_naturalquestions-validation-3860", "mrqa_squad-validation-7410", "mrqa_squad-validation-4283", "mrqa_squad-validation-1329", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-9671", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-6214", "mrqa_squad-validation-5688", "mrqa_naturalquestions-validation-1015", "mrqa_squad-validation-5051", "mrqa_squad-validation-1656", "mrqa_squad-validation-2830", "mrqa_squad-validation-6993", "mrqa_squad-validation-3753", "mrqa_squad-validation-7205", "mrqa_squad-validation-8486", "mrqa_squad-validation-4634"], "OKR": 0.8125, "KG": 0.35703125, "before_eval_results": {"predictions": ["Battle of Kalka River", "Huguenots", "Greenland", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states", "Six soundtrack releases", "Cobham", "1849", "W. E. B. Du Bois", "otter, beaver and hundreds of bird species", "2,000", "fungi", "rookie", "Ma Jianlong", "eight", "Telepad", "1987", "Catholic", "Khanbaliq", "Texas", "sediment deposits", "2004", "west of Kashgar", "oceanic (K\u00f6ppen Cfb) and significantly milder than some other locations in the world at a similar latitude", "Jamukha", "oxidant", "won several medals", "glaucophyte", "four events", "US$10 a week", "Ren\u00e9 Georges Hermann - Paul", "Around 1200", "President Friedrich Ebert", "Saturn", "July 21, 1861", "Newfoundland", "Manhattan", "above the light source and under the sample in an upright microscope", "ancient Greece", "Cadillac", "John von Neumann", "At about 8 : 20 p.m. on 25 September 2007", "Sophocles", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Edy '' Proctor", "around 10 : 30am", "Hanssen", "The Statue of Freedom", "the reality - illusion dichotomy that fascinated James", "September 19 - 22, 2017", "`` It Ain't Over'til It's Over ''", "March 5, 2014", "Rhiannon Holt", "Oklahoma", "The baby elephant who is the son of Hathi and Winifred and is a good friend of Mowgli", "ambassadors, other public ministers and consuls, and those in which a state shall be party", "leg spinner Jimmy Matthews", "March 18, 2005", "The Hustons", "James Madison", "when the car comes to a halt", "Catherine Tramell", "in capillaries, alveoli, glomeruli, outer layer of skin and other tissues", "RAF", "absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6958300507703081}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false], "QA-F1": [0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6428571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.4, 0.8, 1.0, 0.11764705882352941, 0.8750000000000001, 1.0, 0.5, 1.0, 1.0, 0.20000000000000004, 1.0, 0.5333333333333333, 0.0, 0.9166666666666666]}}, "before_error_ids": ["mrqa_squad-validation-6298", "mrqa_squad-validation-3156", "mrqa_squad-validation-7761", "mrqa_squad-validation-4019", "mrqa_squad-validation-4829", "mrqa_squad-validation-5160", "mrqa_squad-validation-8538", "mrqa_squad-validation-3268", "mrqa_squad-validation-1273", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-9782", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-1328", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-7098", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-9895", "mrqa_naturalquestions-validation-8493", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-8092", "mrqa_naturalquestions-validation-6040", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-2133", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-2309"], "SR": 0.546875, "CSR": 0.6619664634146342, "EFR": 0.9310344827586207, "Overall": 0.691959564234651}, {"timecode": 41, "before_eval_results": {"predictions": ["28 days", "the Ilkhanate", "because it has survived many wars, conflicts and invasions throughout its long history", "Pathogens", "\"stream\" and \"gan\"", "The Times newspaper", "Jurassic Period", "Richard I of Normandy", "the Compromise of 1850", "Decision problems", "the most common", "glaucophyte", "ABC Modern", "The Malkin Athletic Center", "Westinghouse Electric", "John Fox", "Germany and Switzerland", "lymphokines", "American Baptist Education Society", "wages", "Thomas Edison", "We Love TV", "a Committee of Independent Experts", "occupational burnout", "twice", "an all-time high between 2005 and 2010", "a nucleomorph", "Earth", "a coherent system of ideas", "Charles Lyell", "IIII", "two of whom were his sons, not to back down", "Peking", "Pyeongchang, South Korea", "Aniene", "a thicker consistency and a deeper flavour than sauce", "Pink Floyd", "Joanne Wheatley", "Cheryl Campbell", "John Young", "a single, very long DNA helix on which thousands of genes are encoded", "Rice Records ( Rice 5028 b / w `` Stagger Lee ''", "March 23, 2013, 23 days before the April 15 deadline set by the No Budget, No Pay Act of 2013", "Terry Reid", "an adopted daughter of Thanos, and she is augmented and converted into a cyborg", "Aaron Lewis", "a special marker called a `` dabber '' or `` dauber '', or simply cross it off with a pen or pencil, depending on the venue", "a better father figure than he is in love with Hayley", "49 cents", "the sinoatrial node travels through the right atrium to the atrioventricular node, along the Bundle of His and through bundle branches", "Jane Fonda", "Speaker of the House of Representatives", "warmth", "copper ( Cu ), silver ( Ag ), and gold ( Au )", "Inequality of opportunity was higher in the transition economies of Central and Eastern Europe and Central Asia than in some other developed economies in Western Europe", "at 11 : 40 p.m. ship's time", "British R&B girl group Eternal", "in 1999 the canal was taken over by the Panamanian government and is now managed and operated by the government - owned Panama Canal Authority", "beloved", "1 - 2 spinal nerve segments above the point of entry", "Majandra Delfino", "Weston - super-Mare", "Ed Roland", "the ocean or from guano, and over time, geologic processes bring ocean sediments to land"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6101471125730994}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.21052631578947367, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.21428571428571425, 0.0, 0.0, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 0.11111111111111112]}}, "before_error_ids": ["mrqa_squad-validation-6456", "mrqa_squad-validation-5279", "mrqa_squad-validation-1074", "mrqa_squad-validation-7285", "mrqa_squad-validation-1884", "mrqa_naturalquestions-validation-9581", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-955", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-9368", "mrqa_naturalquestions-validation-10037", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-4728", "mrqa_naturalquestions-validation-8896", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3818", "mrqa_naturalquestions-validation-243", "mrqa_naturalquestions-validation-3969", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-3548", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1003"], "SR": 0.53125, "CSR": 0.6588541666666667, "EFR": 0.9666666666666667, "Overall": 0.6984635416666667}, {"timecode": 42, "before_eval_results": {"predictions": ["usually given privately in the principal's office", "tens of thousands", "CBS", "25 percent", "Ralph Nelson", "interacting and working directly with students", "1969", "often just a harassment and, at least to the bystander, somewhat inane", "Ming-Tan", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "a free state", "50 fund", "Thomas de Maizi\u00e8re", "Gaspard Dughet", "insulated tankers", "Tolui", "a Tatar chieftain, Tem\u00fcjin-\u00fcge", "John D. Rockefeller", "the Marquis de Vaudreuil", "never ratified by the colonial legislatures nor approved of by the crown", "color confinement", "Article 106 and 107", "a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts", "electronic music", "wage or salary", "BSkyB", "most seats", "Mahatma Gandhi", "late September", "Billy Idol", "Scott Schwartz", "round, bottom round, and top round, with or without the `` round '' bone ( femur ), and may include the knuckle ( sirloin tip ), depending on how the round is separated from the loin", "The Chainsmokers", "a key beer - drinking male demographic", "623", "prenatal development", "a major victory of the Civil Rights Movement, and a model for many future impact litigation cases", "Abid Ali Neemuchwala", "food and clothing", "2018", "southwestern Colorado and northwestern New Mexico", "September 15, 2012", "Darren McGavin", "24 hours later", "18", "a loop ( also called a self - loop or a `` buckle '' )", "1.2 billion", "a region in Greek mythology, first mentioned in Homer's Odyssey as the home of the Phaeacians and the last destination of Odysseus in his 10 - year journey before returning home to Ithaca", "Menelaus", "2010", "Adam Mitchell", "Tim McGraw", "near the city of Cairo, Illinois", "Branford College", "Bob Gaudio and his future wife Judy Parker", "more than a million members", "a series of prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "Thomas Jefferson", "Elena Anaya", "semi-autonomous organisational units within the National Health Service in England", "James Chadwick", "2016", "Andrea Brooks", "the early 19th century"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5978770546981754}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.1379310344827586, 1.0, 0.0, 0.5, 0.6666666666666666, 0.3333333333333333, 1.0, 0.8, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.16, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1935", "mrqa_squad-validation-7014", "mrqa_squad-validation-1459", "mrqa_squad-validation-3237", "mrqa_squad-validation-5489", "mrqa_squad-validation-8027", "mrqa_squad-validation-10213", "mrqa_squad-validation-4132", "mrqa_naturalquestions-validation-10258", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-1163", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-8420", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-7681", "mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-104", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-9273", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-4026"], "SR": 0.484375, "CSR": 0.654796511627907, "EFR": 0.8484848484848485, "Overall": 0.6740156470225511}, {"timecode": 43, "before_eval_results": {"predictions": ["an ICSI report \" Variations of Snow and Ice in the past and at present on a Global and Regional Scale\"", "his 1523 adaptation of the Latin Mass", "842 pounds", "4:51", "University President Robert Maynard Hutchins de-emphasized varsity athletics", "rapidly", "NFL Mobile", "a sequence of mission types which had to be successfully accomplished in order to achieve the manned lunar landing", "Standard Model", "1550", "Doctor Who \u2013 The Ultimate Adventure", "around 20 hours", "Golden Gate Bridge", "the Rip", "Dr. George E. Mueller", "The Knowledge School", "Deformational", "vocational schools", "ten million people", "Trotsky, and others, believed that the revolution could only succeed in Russia as part of a world revolution", "the year 2011", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "BBC Television", "BAFTA TV Awards", "Litton's Weekend Aventure", "the intractability associated with the breadth of sizes", "single-tape Turing machines", "8 December 1985", "775", "the Four Seasons", "Phillip Paley", "the Columbia River Gorge", "William Wyler", "Gettysburg College", "1960", "fresh water", "3 ) 1976", "1967", "March 2003", "Eda Reiss Merin", "Andrea Brooks", "1952", "1996", "Ram Nath Kovind of the Bharatiya Janata Party", "Gibraltar", "H CO", "Effy", "the Korean Republic Won", "Ali", "Richard Stallman", "Speaker of the House of Representatives", "1975", "Kenny", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "to collect menstrual flow", "March 31, 2013", "Chilliwack", "Walter Brennan", "mongrel female", "1913", "6 - 7 % average GDP growth annually", "Tenochtitlan", "Lalo Schifrin", "the continent of Antarctica"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7708806224842408}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false], "QA-F1": [0.10526315789473684, 0.9090909090909091, 0.0, 1.0, 1.0, 1.0, 1.0, 0.45454545454545453, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.2222222222222222, 0.6666666666666666, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6, 1.0, 0.5714285714285715, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_squad-validation-8548", "mrqa_squad-validation-2375", "mrqa_squad-validation-3811", "mrqa_squad-validation-3775", "mrqa_squad-validation-7823", "mrqa_squad-validation-9753", "mrqa_squad-validation-10128", "mrqa_squad-validation-8495", "mrqa_squad-validation-1430", "mrqa_squad-validation-7843", "mrqa_squad-validation-1860", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-3842", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9675", "mrqa_naturalquestions-validation-9260", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-3611"], "SR": 0.65625, "CSR": 0.6548295454545454, "EFR": 0.9545454545454546, "Overall": 0.695234375}, {"timecode": 44, "before_eval_results": {"predictions": ["lay servants", "War", "ten minutes", "Festival of the Arts", "the courts of member states and the Court of Justice of the European Union.", "(i.e. in contract with) the property owner.", "electric", "Stan Lebar", "adults", "forces", "the Steelers", "elliptical", "3", "the Arizona Cardinals 49\u201315", "Port of Los Angeles", "lipophilic alkaloid toxins", "The Three Doctors", "tertiary education (universities and/or TAFE colleges)", "India", "a pair of long, slender tentacles, each housed in a sheath into which it can be withdrawn.", "T. T. Tsui Gallery of Chinese art", "90% to 93% O2", "Time Warner Cable", "2015", "research, exhibitions and other shows", "full independent prescribing authority", "Covington, Kentucky", "mashed potato", "Atlanta", "the second of three Olympic - class ocean liners operated by the White Star Line", "Payaya Indians", "1830", "crossbar", "Martin Lawrence", "16.5 quadrillion BTUs of primary energy", "various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "state workforce agencies", "2018", "General George Washington", "Ethel `` Edy '' Proctor", "Frank Langella", "bicameral Congress", "administrative supervision over all courts and the personnel thereof", "September 4, 2000 to February 25, 2003", "Butter Island off North Haven, Maine in the Penobscot Bay", "Manchuria", "the celebrity alumna Cecil Lockhart", "2004", "the region of modern Nova Scotia", "Palm Sunday celebrations", "William Shakespeare's play A Midsummer Night's Dream", "New York City", "the oral mucosa ( a mucous membrane ) lining the mouth and also on the tongue and palates and mouth floor", "Amitabh Bachchan", "outer space", "agriculture", "stromal connective tissue", "Paul Lynde", "1979", "Kirsten Simone Vangsness", "August 2, 1990", "Michelle Stafford", "Spain", "does not activate and can block the activity of other agonists"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7363128624847375}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.9777777777777777, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0, 0.125, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693]}}, "before_error_ids": ["mrqa_squad-validation-7742", "mrqa_squad-validation-6958", "mrqa_squad-validation-4513", "mrqa_squad-validation-268", "mrqa_squad-validation-71", "mrqa_squad-validation-2001", "mrqa_squad-validation-4468", "mrqa_squad-validation-3674", "mrqa_naturalquestions-validation-7115", "mrqa_naturalquestions-validation-368", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-5006", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-2684", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-6918", "mrqa_naturalquestions-validation-6011", "mrqa_naturalquestions-validation-9749"], "SR": 0.609375, "CSR": 0.6538194444444445, "EFR": 0.96, "Overall": 0.6961232638888888}, {"timecode": 45, "UKR": 0.76171875, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-473", "mrqa_squad-validation-3630", "mrqa_squad-validation-8007", "mrqa_squad-validation-3345", "mrqa_squad-validation-5342", "mrqa_squad-validation-435", "mrqa_squad-validation-7338", "mrqa_squad-validation-9718", "mrqa_naturalquestions-validation-1592", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-3707", "mrqa_squad-validation-4952", "mrqa_naturalquestions-validation-9755", "mrqa_squad-validation-9263", "mrqa_squad-validation-9306", "mrqa_squad-validation-5504", "mrqa_squad-validation-1948", "mrqa_naturalquestions-validation-10031", "mrqa_naturalquestions-validation-6278", "mrqa_squad-validation-2976", "mrqa_squad-validation-10402", "mrqa_squad-validation-3296", "mrqa_squad-validation-4534", "mrqa_squad-validation-1040", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-5719", "mrqa_squad-validation-943", "mrqa_squad-validation-1170", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-1704", "mrqa_squad-validation-4031", "mrqa_naturalquestions-validation-1310", "mrqa_squad-validation-9285", "mrqa_squad-validation-8483", "mrqa_squad-validation-1233", "mrqa_squad-validation-1459", "mrqa_naturalquestions-validation-7387", "mrqa_squad-validation-5860", "mrqa_squad-validation-3190", "mrqa_squad-validation-4176", "mrqa_squad-validation-6681", "mrqa_squad-validation-337", "mrqa_squad-validation-5995", "mrqa_squad-validation-4148", "mrqa_squad-validation-132", "mrqa_squad-validation-8524", "mrqa_squad-validation-3922", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-1329", "mrqa_squad-validation-8694", "mrqa_squad-validation-2998", "mrqa_naturalquestions-validation-3214", "mrqa_squad-validation-91", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-5916", "mrqa_squad-validation-4095", "mrqa_squad-validation-7414", "mrqa_naturalquestions-validation-1762", "mrqa_squad-validation-6865", "mrqa_naturalquestions-validation-6408", "mrqa_squad-validation-5077", "mrqa_squad-validation-2232", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-7973", "mrqa_squad-validation-8250", "mrqa_squad-validation-6150", "mrqa_squad-validation-4313", "mrqa_squad-validation-7150", "mrqa_naturalquestions-validation-1089", "mrqa_squad-validation-6304", "mrqa_naturalquestions-validation-3750", "mrqa_squad-validation-4480", "mrqa_squad-validation-3740", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-1959", "mrqa_naturalquestions-validation-1443", "mrqa_squad-validation-2741", "mrqa_squad-validation-1824", "mrqa_naturalquestions-validation-2678", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-3016", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-5781", "mrqa_squad-validation-9034", "mrqa_squad-validation-3413", "mrqa_squad-validation-8398", "mrqa_squad-validation-5028", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-6867", "mrqa_squad-validation-1401", "mrqa_squad-validation-6179", "mrqa_squad-validation-9692", "mrqa_squad-validation-887", "mrqa_naturalquestions-validation-5199", "mrqa_squad-validation-1858", "mrqa_naturalquestions-validation-8728", "mrqa_squad-validation-8107", "mrqa_squad-validation-2901", "mrqa_squad-validation-7230", "mrqa_squad-validation-6986", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9071", "mrqa_squad-validation-8278", "mrqa_squad-validation-9784", "mrqa_squad-validation-3581", "mrqa_naturalquestions-validation-8216", "mrqa_squad-validation-6009", "mrqa_squad-validation-1123", "mrqa_squad-validation-1404", "mrqa_squad-validation-9753", "mrqa_squad-validation-4709", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-3529", "mrqa_naturalquestions-validation-4499", "mrqa_squad-validation-1026", "mrqa_naturalquestions-validation-9273", "mrqa_squad-validation-8197", "mrqa_naturalquestions-validation-6765", "mrqa_squad-validation-4295", "mrqa_naturalquestions-validation-10034", "mrqa_squad-validation-9263", "mrqa_squad-validation-7651", "mrqa_squad-validation-5437", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-5508", "mrqa_squad-validation-6112", "mrqa_squad-validation-8180", "mrqa_squad-validation-10464", "mrqa_squad-validation-6513", "mrqa_squad-validation-5329", "mrqa_squad-validation-2673", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-2119", "mrqa_squad-validation-3994", "mrqa_squad-validation-6085", "mrqa_squad-validation-1367", "mrqa_naturalquestions-validation-6009", "mrqa_naturalquestions-validation-8964", "mrqa_squad-validation-6419", "mrqa_squad-validation-9412", "mrqa_squad-validation-5624", "mrqa_naturalquestions-validation-2090", "mrqa_squad-validation-2921", "mrqa_naturalquestions-validation-5396", "mrqa_naturalquestions-validation-8092", "mrqa_squad-validation-925", "mrqa_squad-validation-3950", "mrqa_squad-validation-7266", "mrqa_squad-validation-7685", "mrqa_squad-validation-6489", "mrqa_squad-validation-9326", "mrqa_squad-validation-7137", "mrqa_squad-validation-8991", "mrqa_squad-validation-3630", "mrqa_naturalquestions-validation-7489", "mrqa_naturalquestions-validation-7359", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-3636", "mrqa_naturalquestions-validation-9094", "mrqa_naturalquestions-validation-2106", "mrqa_squad-validation-299", "mrqa_squad-validation-6573", "mrqa_naturalquestions-validation-5440", "mrqa_squad-validation-2462", "mrqa_squad-validation-6651", "mrqa_squad-validation-9", "mrqa_squad-validation-6037", "mrqa_squad-validation-7370", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6435", "mrqa_squad-validation-1238", "mrqa_squad-validation-1800", "mrqa_naturalquestions-validation-1884", "mrqa_squad-validation-8204", "mrqa_naturalquestions-validation-644", "mrqa_squad-validation-416", "mrqa_naturalquestions-validation-3558", "mrqa_squad-validation-2353", "mrqa_squad-validation-7132", "mrqa_naturalquestions-validation-9523", "mrqa_squad-validation-10496", "mrqa_squad-validation-5140", "mrqa_squad-validation-3495", "mrqa_squad-validation-10309", "mrqa_squad-validation-967", "mrqa_squad-validation-6897", "mrqa_squad-validation-5807", "mrqa_squad-validation-5491", "mrqa_naturalquestions-validation-10433", "mrqa_squad-validation-3702", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-2297", "mrqa_squad-validation-4065", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-6912", "mrqa_squad-validation-3453", "mrqa_squad-validation-2799", "mrqa_squad-validation-9651", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-1218", "mrqa_squad-validation-2611", "mrqa_squad-validation-2448", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-567", "mrqa_squad-validation-9265", "mrqa_squad-validation-1877", "mrqa_naturalquestions-validation-10509", "mrqa_naturalquestions-validation-5958", "mrqa_squad-validation-7275", "mrqa_squad-validation-2508", "mrqa_naturalquestions-validation-10446", "mrqa_squad-validation-639", "mrqa_squad-validation-7389", "mrqa_squad-validation-3640", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-6391", "mrqa_naturalquestions-validation-7223", "mrqa_squad-validation-7480", "mrqa_squad-validation-10216", "mrqa_squad-validation-9097", "mrqa_naturalquestions-validation-1173", "mrqa_squad-validation-2583", "mrqa_naturalquestions-validation-3433", "mrqa_squad-validation-1057", "mrqa_squad-validation-4184", "mrqa_squad-validation-5485", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-8037", "mrqa_squad-validation-4293", "mrqa_squad-validation-3432", "mrqa_squad-validation-4176", "mrqa_squad-validation-3103", "mrqa_squad-validation-626", "mrqa_naturalquestions-validation-4200", "mrqa_squad-validation-4875", "mrqa_naturalquestions-validation-3961", "mrqa_squad-validation-895", "mrqa_naturalquestions-validation-3053", "mrqa_naturalquestions-validation-6055", "mrqa_naturalquestions-validation-3469", "mrqa_squad-validation-239", "mrqa_squad-validation-2847", "mrqa_squad-validation-1839", "mrqa_squad-validation-6156", "mrqa_squad-validation-6100", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-793", "mrqa_squad-validation-76", "mrqa_squad-validation-1182", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-6620", "mrqa_squad-validation-9945", "mrqa_squad-validation-4834", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-5928", "mrqa_squad-validation-6521", "mrqa_squad-validation-5584", "mrqa_squad-validation-9009", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-7152", "mrqa_squad-validation-7374", "mrqa_squad-validation-6639", "mrqa_squad-validation-1954", "mrqa_squad-validation-4273", "mrqa_squad-validation-5289", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-2722", "mrqa_naturalquestions-validation-101", "mrqa_squad-validation-317", "mrqa_squad-validation-9179", "mrqa_squad-validation-2689", "mrqa_squad-validation-6014", "mrqa_squad-validation-6289", "mrqa_squad-validation-2811", "mrqa_squad-validation-2448", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4929", "mrqa_squad-validation-7232", "mrqa_squad-validation-10158", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-6190", "mrqa_squad-validation-8725", "mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-7499", "mrqa_naturalquestions-validation-156", "mrqa_squad-validation-3359", "mrqa_naturalquestions-validation-6951", "mrqa_naturalquestions-validation-8896", "mrqa_squad-validation-10376", "mrqa_squad-validation-5641", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-1656", "mrqa_naturalquestions-validation-2972", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-9005", "mrqa_squad-validation-452", "mrqa_squad-validation-4085", "mrqa_squad-validation-9658", "mrqa_squad-validation-9720", "mrqa_squad-validation-6870", "mrqa_squad-validation-4059", "mrqa_squad-validation-2099", "mrqa_squad-validation-3704", "mrqa_squad-validation-3836", "mrqa_squad-validation-6817", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-3455", "mrqa_squad-validation-804", "mrqa_naturalquestions-validation-2064", "mrqa_squad-validation-9641", "mrqa_squad-validation-9029", "mrqa_squad-validation-8105", "mrqa_squad-validation-5169", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-6511", "mrqa_naturalquestions-validation-3094", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-3494", "mrqa_squad-validation-8000", "mrqa_naturalquestions-validation-6328", "mrqa_squad-validation-1273", "mrqa_naturalquestions-validation-7151", "mrqa_squad-validation-484", "mrqa_squad-validation-4331", "mrqa_squad-validation-4397", "mrqa_squad-validation-1884", "mrqa_squad-validation-1836", "mrqa_squad-validation-2697", "mrqa_squad-validation-7194", "mrqa_naturalquestions-validation-7281", "mrqa_squad-validation-6620", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-10485", "mrqa_squad-validation-3942", "mrqa_naturalquestions-validation-3477", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-325", "mrqa_naturalquestions-validation-215", "mrqa_squad-validation-5531", "mrqa_squad-validation-8534", "mrqa_squad-validation-9809", "mrqa_squad-validation-9", "mrqa_squad-validation-4274", "mrqa_squad-validation-4204", "mrqa_squad-validation-9566", "mrqa_squad-validation-5072", "mrqa_naturalquestions-validation-2304", "mrqa_naturalquestions-validation-8306", "mrqa_squad-validation-1245", "mrqa_squad-validation-6483", "mrqa_squad-validation-2451", "mrqa_squad-validation-7744", "mrqa_naturalquestions-validation-9564", "mrqa_naturalquestions-validation-8972", "mrqa_squad-validation-9281", "mrqa_squad-validation-9982", "mrqa_squad-validation-2941", "mrqa_naturalquestions-validation-2682", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-8179", "mrqa_squad-validation-8001", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-220", "mrqa_squad-validation-1555", "mrqa_squad-validation-5511", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-2734", "mrqa_squad-validation-675", "mrqa_squad-validation-394", "mrqa_squad-validation-9705", "mrqa_squad-validation-7186", "mrqa_naturalquestions-validation-6769", "mrqa_squad-validation-7160", "mrqa_squad-validation-5051", "mrqa_naturalquestions-validation-7967", "mrqa_squad-validation-7053", "mrqa_naturalquestions-validation-3837", "mrqa_squad-validation-5832", "mrqa_squad-validation-2704", "mrqa_squad-validation-8486", "mrqa_naturalquestions-validation-6298", "mrqa_squad-validation-9442", "mrqa_naturalquestions-validation-2406", "mrqa_naturalquestions-validation-7227", "mrqa_squad-validation-7586", "mrqa_naturalquestions-validation-3008", "mrqa_squad-validation-7614", "mrqa_squad-validation-2288", "mrqa_squad-validation-2508", "mrqa_squad-validation-8661", "mrqa_squad-validation-10133", "mrqa_squad-validation-2384", "mrqa_naturalquestions-validation-2182", "mrqa_squad-validation-3299", "mrqa_squad-validation-6313", "mrqa_squad-validation-2346", "mrqa_squad-validation-2250", "mrqa_squad-validation-9150", "mrqa_squad-validation-6518", "mrqa_naturalquestions-validation-3232", "mrqa_squad-validation-3223", "mrqa_squad-validation-3229", "mrqa_squad-validation-4166", "mrqa_naturalquestions-validation-9436", "mrqa_squad-validation-1720", "mrqa_squad-validation-1941", "mrqa_squad-validation-9504", "mrqa_squad-validation-9491", "mrqa_squad-validation-5614", "mrqa_squad-validation-5051", "mrqa_naturalquestions-validation-9848", "mrqa_squad-validation-1764", "mrqa_squad-validation-6111", "mrqa_squad-validation-3611", "mrqa_squad-validation-8222", "mrqa_squad-validation-6918", "mrqa_squad-validation-7860", "mrqa_squad-validation-2749", "mrqa_squad-validation-3270", "mrqa_naturalquestions-validation-6564", "mrqa_squad-validation-7417", "mrqa_squad-validation-713", "mrqa_squad-validation-3683", "mrqa_squad-validation-5951", "mrqa_naturalquestions-validation-4879", "mrqa_squad-validation-4778", "mrqa_squad-validation-3712", "mrqa_naturalquestions-validation-6665", "mrqa_squad-validation-2875", "mrqa_squad-validation-633", "mrqa_squad-validation-6995", "mrqa_squad-validation-1287", "mrqa_naturalquestions-validation-1446", "mrqa_squad-validation-5633", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-1522", "mrqa_naturalquestions-validation-7152", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-468", "mrqa_squad-validation-5649", "mrqa_squad-validation-1752", "mrqa_naturalquestions-validation-5799", "mrqa_squad-validation-4934", "mrqa_squad-validation-6737", "mrqa_naturalquestions-validation-134", "mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-10546", "mrqa_squad-validation-8636", "mrqa_squad-validation-10479", "mrqa_squad-validation-5919", "mrqa_squad-validation-435", "mrqa_squad-validation-4992", "mrqa_naturalquestions-validation-239", "mrqa_squad-validation-7473", "mrqa_naturalquestions-validation-2552", "mrqa_squad-validation-4560", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-6569", "mrqa_squad-validation-7043", "mrqa_naturalquestions-validation-801", "mrqa_squad-validation-3486", "mrqa_squad-validation-102", "mrqa_squad-validation-2980", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-1340", "mrqa_squad-validation-1340", "mrqa_squad-validation-7382", "mrqa_naturalquestions-validation-6754", "mrqa_squad-validation-3430", "mrqa_squad-validation-8691", "mrqa_squad-validation-8598", "mrqa_naturalquestions-validation-9895", "mrqa_squad-validation-728", "mrqa_naturalquestions-validation-2355", "mrqa_naturalquestions-validation-8063", "mrqa_squad-validation-6127", "mrqa_squad-validation-8496", "mrqa_naturalquestions-validation-9715", "mrqa_squad-validation-5242", "mrqa_naturalquestions-validation-4973", "mrqa_squad-validation-2011", "mrqa_squad-validation-2458", "mrqa_squad-validation-462", "mrqa_squad-validation-3133", "mrqa_squad-validation-5012", "mrqa_squad-validation-5715", "mrqa_squad-validation-7175", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-1537", "mrqa_naturalquestions-validation-4413", "mrqa_squad-validation-9375", "mrqa_squad-validation-6609", "mrqa_naturalquestions-validation-259", "mrqa_squad-validation-6992", "mrqa_squad-validation-7517", "mrqa_squad-validation-708", "mrqa_squad-validation-4808", "mrqa_squad-validation-9709", "mrqa_naturalquestions-validation-8909", "mrqa_squad-validation-205"], "OKR": 0.88671875, "before_eval_results": {"predictions": ["Death wish Coffee", "$5 million", "a system of many biological structures and processes within an organism that protects against disease", "Time magazine", "mainly civil servants recruited in special university classes, called Lehramtstudien (Teaching Education Studies)", "multi-cultural", "they contain striated muscle", "UNESCO World Heritage Site", "tentacles and prey on other ctenophores", "a sluice", "the BBC repeatedly affirmed that the series would return.", "Super Bowl XLVIII", "John Sutcliffe", "Theory of the Earth", "Francis Blackburne", "the Netherlands", "5", "50th anniversary special", "in the kingdom", "polynomial time", "modular", "invasion of the Khwarezmid Empire", "optimisation", "long haul freight operations in Sweden and for express passenger work in Britain", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "German", "the Whig Party's colorful Log Cabin Campaign", "above the light source and under the sample in an upright microscope, and above the stage and below the light sources in an inverted microscope", "1800", "Lewis Carroll", "ideology", "Tommy Shaw", "Upstate New York", "Las Vegas, Nevada", "Sam Waterston", "December 22, 2017", "Buddhism", "Staci Keanan", "Best Picture, Best Director for Fincher, Best Actor for Pitt and Best Supporting Actress for Taraji P. Henson", "the Norman given name Robert", "Tyler's little sister's birthday party", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "on a side table", "Giancarlo Stanton", "warrior, mage, or rogue coming from an elven, human, or dwarven background", "Joe Lo Truglio", "April 2016", "`` Goodbye Toby ''", "the somatic nervous system and the autonomic nervous system", "Daya Jethalal Gada", "Experimental neuropsychology", "Jason Marsden", "a couple broken apart by the Iraq War", "Edward Kenway", "Gestalt psychology", "many hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Clement Henry Manuel", "approximately 5 liters", "Texas, Oklahoma, and the surrounding Great Plains", "the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "writ of certiorari", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "Einstein", "Deterrence"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6695592794088068}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.14285714285714288, 1.0, 1.0, 0.11764705882352942, 0.9473684210526315, 1.0, 0.08695652173913042, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.4, 1.0, 1.0, 0.09999999999999999, 0.3333333333333333, 0.0, 0.918918918918919, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.9859154929577464, 0.0, 0.4, 0.2857142857142857, 0.9473684210526316, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-543", "mrqa_squad-validation-2042", "mrqa_squad-validation-4616", "mrqa_squad-validation-9118", "mrqa_squad-validation-7750", "mrqa_squad-validation-1765", "mrqa_squad-validation-6282", "mrqa_squad-validation-3422", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-9660", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-6506", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-9959", "mrqa_naturalquestions-validation-5583", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-8099", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-1357"], "SR": 0.53125, "CSR": 0.6511548913043479, "EFR": 0.8666666666666667, "Overall": 0.704658061594203}, {"timecode": 46, "before_eval_results": {"predictions": ["large prefabricated housing projects", "The show globe", "primary law, secondary law and supplementary law", "historical era", "photographic memory", "1876", "Body of Proof", "Islamic values", "in 80 trunks marked N.T.", "remain silent if his opponents did", "March 2009", "gradient of potentials", "indulgences for the dead", "1888", "two", "enthusiasm", "Wahhabism", "on the coast of Denmark", "seven", "computational problem", "Lower taxes, increased economic development, unification of the community, better public spending and effective administration by a more central authority", "silver chains", "Royal Shakespeare Company", "State Route 168", "an amending treaty", "the frequency f, wavelength \u03bb, or photon energy E.", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1961", "the states or the people", "in Middlesex County, Province of Massachusetts Bay", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "MGM Resorts International", "authority", "in rocks, sediment, or archeological materials", "the combined English forces of John de Warenne, 6th Earl of Surrey, and Hugh de Cressingham", "The Cornett family", "1960", "the # 4 School of Public Health in the country", "1984", "the 2009 model year", "30 January 1934", "Prafulla Chandra Ghosh", "2001", "Michelle Paige Bouck", "humid subtropical climate, with hot summers and mild winters", "1974", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Saint Etienne", "291", "1560s", "five", "2013", "Richard Masur", "Quantitative psychological research", "an advantage without deviating from basic strategy", "changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music", "Havana Harbor", "Kylie Jenner's first child", "Yuzuru Hanyu", "1987", "the nature of Abraham Lincoln's war goals", "1981", "Honor\u00e9 Mirabeau", "2015"], "metric_results": {"EM": 0.5, "QA-F1": 0.63665796009546}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 1.0, 0.08333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.06666666666666667, 0.0, 1.0, 1.0, 0.5384615384615384, 0.4444444444444445, 1.0, 1.0, 0.0, 0.27272727272727276, 1.0, 1.0, 0.25, 0.0, 1.0, 0.5, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-873", "mrqa_squad-validation-4054", "mrqa_squad-validation-9609", "mrqa_squad-validation-1559", "mrqa_squad-validation-5528", "mrqa_squad-validation-1988", "mrqa_squad-validation-803", "mrqa_squad-validation-7296", "mrqa_squad-validation-1264", "mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-1455", "mrqa_naturalquestions-validation-5751"], "SR": 0.5, "CSR": 0.647938829787234, "EFR": 0.96875, "Overall": 0.7244315159574468}, {"timecode": 47, "before_eval_results": {"predictions": ["on the ground", "Pierre Pictet", "long-lived memory cells", "both British and Europeans who were based in Britain and whose work is in the collection include Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack", "seismic waves", "receivers", "the Great Fire of London", "1840", "sons and grandsons", "300\u2013600 nanometers in diameter", "hunter's garb", "reduce growth", "The Walt Disney Company", "third unmanned test", "union membership", "piranha", "William Farel", "Mombasa", "the beroids", "Ed Whitfield", "left foot", "Albert Einstein", "ships", "1596", "the French made numerous contributions to United States economic life, especially as merchants and artisans in the late Colonial and early Federal periods", "May 31, 2012", "Dougie MacLean", "94 by 50", "eleven", "the west coast of Central America", "2013", "ended Russia's participation in World War I", "the New York Yankees", "3 different types of gene segments", "the goddess Veritas", "Eurasian Plate", "butane", "Abraham Gottlob Werner", "the New England Patriots", "the Ming dynasty", "1978", "Daniel A. Dailey", "the French side of its borders with Italy, Switzerland, Germany, and Luxembourg", "the eurozone", "1981", "technological advances in printing", "2006", "the finale of the season took place 28 January 2018", "the NFL", "six - hoop game", "the one whose envy inflicts it on others as well as for the sufferer", "Frankie Valli", "Cairo, Illinois", "the Spanish Dominican Tom\u00e1s de Torquemada", "to harm the producers and workers in export sectors, both in the country implementing protectionist policies, and in the countries protected against", "early 1950s", "an Abstergo agent", "India", "the last cases to be heard as a jury trial in India, as the government abolished jury trials soon after in most cases except for Parsis who still have jury Trials for their Matrimonial Disputes", "Patrick Walshe", "approximately 11 %", "the French", "the narrator and friend of the other characters and the series'host", "Steve Hale"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7198898679416974}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12903225806451613, 1.0, 1.0, 0.8571428571428571, 1.0, 0.2631578947368421, 1.0, 0.7999999999999999, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.7499999999999999, 0.30303030303030304, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5589", "mrqa_squad-validation-3070", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2578", "mrqa_naturalquestions-validation-5444", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-1139", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-5082", "mrqa_naturalquestions-validation-1162", "mrqa_naturalquestions-validation-853", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-86", "mrqa_naturalquestions-validation-3066", "mrqa_naturalquestions-validation-1404", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-2821"], "SR": 0.65625, "CSR": 0.6481119791666667, "EFR": 0.9090909090909091, "Overall": 0.7125343276515151}, {"timecode": 48, "before_eval_results": {"predictions": ["2001", "remote sensing", "The NBC Blue Network", "other parts of an object", "19 October 1512", "1947", "Book of Exodus", "ABC on Demand", "approximately one week", "static friction", "Spearhead from Space", "higher", "$5 million", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "800m gold", "Madame de Pompadour", "Kalka River", "in NP and in co-NP (and even in UP and co-UP)", "Hugh Downs", "50th", "Queer as Folk", "1950", "Oxygen", "third son", "Seymour Krelborn", "April 4, 2017", "Eagles", "the NFL", "Tatsumi", "from Iran, Pakistan, India, Nepal, Bhutan, Bangladesh and Sri Lanka ; as well as Afghanistan, Uzbekistan, Tajikistan, Turkmenistan, Myanmar,", "Ramanaa", "to violate the National Labor Relations Act of 1935 ( 49 Stat. 449 ) 29 U.S.C. \u00a7 151 -- 169 ( also known as the NLRA and the Wagner Act after NY Senator Robert F. Wagner )", "saliva", "shout `` Yes '' or `` dauber ''", "1996", "to manage the characteristics of the beer's head", "In Time", "late 1920s", "Cee - Lo", "Vicente Fox", "Nebuchadnezzar", "Renhe Sports Management Ltd", "often linked to high - ranking ( though not necessarily royalty ) in China", "rubidium - 85", "Celtic", "forested parts of the world", "The Mandate of Heaven", "human induced greenhouse warming, and changes in the frequency and magnitude of El Ni\u00f1o events are a trigger to this strong warming in the Indian Ocean", "uncle Abu Talib", "9.7 m ( 31.82 ft )", "Fusajiro Yamauchi", "an iron -- nickel alloy and some other elements", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "only at the end of an interrogative sentence", "Pennsylvania", "not being pushed around by big labels, managers, and agents and being told what to do, and being true to yourself creatively", "in the 1820s", "the Gupta Empire", "volume of blood or mass of alcohol per mass of blood, depending on the country", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "Action Jackson", "Natural - language processing ( NLP )", "giant planet", "May 2016"], "metric_results": {"EM": 0.578125, "QA-F1": 0.741566049819737}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.835820895522388, 0.0, 0.4, 0.0, 0.7692307692307692, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.5625, 0.0, 0.6666666666666666, 1.0, 0.6, 0.5, 0.9090909090909091, 1.0, 0.9777777777777777, 0.6666666666666666, 1.0, 0.7586206896551724, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8539", "mrqa_squad-validation-1833", "mrqa_squad-validation-8230", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-2906", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-290", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-8896", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-2208", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-9683", "mrqa_naturalquestions-validation-6650", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-3841", "mrqa_naturalquestions-validation-5938", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-4523", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-5155"], "SR": 0.578125, "CSR": 0.6466836734693877, "EFR": 0.8148148148148148, "Overall": 0.6933934476568405}, {"timecode": 49, "before_eval_results": {"predictions": ["antithetical", "Friday", "necessity rather than opportunity", "at Decision Time", "secular war", "America", "at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "the western end of the second east-west shipping route", "Sir George Gilbert Scott", "technologies and ideas", "various locations throughout the world", "Six", "the plot of the show, as well as the differing approach to the role that each brings, under the concept of regeneration", "end of the Pleistocene (~11,600 BP)", "girls", "Baden-W\u00fcrttemberg", "Milka, Angelina and Marica", "rich Yangzi River basin", "high-altitude ozone layer", "his Houston Street lab", "the Great Fire of London", "in the stems", "decreases marginal utility", "ABC Studios", "Flair's maid Fifi cleaned or bore gifts", "to examine trends in global carbon monoxide and inhalol pollution", "The Pir Panjal Railway Tunnel", "the American colonies, then at war with the Kingdom of Great Britain, regarded themselves as thirteen independent sovereign states, no longer under British rule", "the person compelled to pay for reformist programs", "~ 0.116 mm", "Olivia d'Abo", "March 2, 2016", "2010", "frontal lobe", "Michael Schumacher", "honey", "can be performed at any level in the spine ( cervical, thoracic, or lumbar ) and prevents any movement between the fused vertebrae", "fourteen", "the settlers", "50 home run club", "encrypted by Transport Layer Security ( TLS ), or formerly, its predecessor, Secure Sockets Layer ( HTTPS )", "Thomas Edison", "the highest number of votes, and also greater than 50 % of the votes", "Database - Protocol driver ( Pure Java driver )", "Brad Dourif", "consistency", "Lana Del Rey", "2018", "16 June", "1994", "wagen VIII Maus ( `` Mouse '' )", "metals, especially heavy metals, that occurs even in low concentrations", "the Treaty of Paris", "before the first letter of an interrogative sentence", "Ian Hart", "Neil Patrick Harris", "Total Drama World Tour", "Special Dark", "17 - year - old", "Michael Rosen", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "Karen Gillan", "Sir Hugh Beaver", "the Indo - Greek kings"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7163222331396673}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.9473684210526316, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.10526315789473685, 0.36363636363636365, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.09523809523809523, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7878787878787877, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5906", "mrqa_squad-validation-9475", "mrqa_squad-validation-10228", "mrqa_squad-validation-9310", "mrqa_squad-validation-7593", "mrqa_squad-validation-9144", "mrqa_squad-validation-8138", "mrqa_squad-validation-7428", "mrqa_naturalquestions-validation-9003", "mrqa_naturalquestions-validation-4604", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-360", "mrqa_naturalquestions-validation-8962", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-5596", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5831"], "SR": 0.609375, "CSR": 0.6459375, "EFR": 0.92, "Overall": 0.71428125}, {"timecode": 50, "UKR": 0.673828125, "OKR_sampled_ids": ["mrqa_squad-validation-10418", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9172", "mrqa_squad-validation-60", "mrqa_naturalquestions-validation-5025", "mrqa_squad-validation-1229", "mrqa_naturalquestions-validation-2355", "mrqa_naturalquestions-validation-8043", "mrqa_naturalquestions-validation-9753", "mrqa_squad-validation-5389", "mrqa_naturalquestions-validation-4863", "mrqa_squad-validation-1636", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-7741", "mrqa_naturalquestions-validation-2124", "mrqa_squad-validation-8952", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-8181", "mrqa_squad-validation-9064", "mrqa_squad-validation-36", "mrqa_squad-validation-7189", "mrqa_squad-validation-5846", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7152", "mrqa_naturalquestions-validation-2208", "mrqa_naturalquestions-validation-7009", "mrqa_squad-validation-7515", "mrqa_squad-validation-419", "mrqa_naturalquestions-validation-7538", "mrqa_squad-validation-2321", "mrqa_squad-validation-7642", "mrqa_squad-validation-480", "mrqa_squad-validation-3922", "mrqa_squad-validation-6480", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-5215", "mrqa_squad-validation-4320", "mrqa_naturalquestions-validation-3243", "mrqa_squad-validation-10074", "mrqa_naturalquestions-validation-4192", "mrqa_squad-validation-2044", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-7250", "mrqa_squad-validation-4551", "mrqa_squad-validation-2689", "mrqa_squad-validation-2493", "mrqa_squad-validation-2862", "mrqa_squad-validation-2644", "mrqa_squad-validation-4332", "mrqa_naturalquestions-validation-5454", "mrqa_squad-validation-3806", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10034", "mrqa_squad-validation-6085", "mrqa_squad-validation-7211", "mrqa_squad-validation-3630", "mrqa_squad-validation-967", "mrqa_naturalquestions-validation-9722", "mrqa_squad-validation-146", "mrqa_squad-validation-3103", "mrqa_squad-validation-6465", "mrqa_squad-validation-6366", "mrqa_squad-validation-3044", "mrqa_squad-validation-7162", "mrqa_squad-validation-5092", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-4263", "mrqa_naturalquestions-validation-4667", "mrqa_squad-validation-5084", "mrqa_naturalquestions-validation-3611", "mrqa_squad-validation-2633", "mrqa_squad-validation-5536", "mrqa_naturalquestions-validation-7967", "mrqa_squad-validation-8298", "mrqa_squad-validation-8749", "mrqa_squad-validation-7131", "mrqa_naturalquestions-validation-4064", "mrqa_squad-validation-6719", "mrqa_squad-validation-9371", "mrqa_squad-validation-2508", "mrqa_naturalquestions-validation-1975", "mrqa_squad-validation-7135", "mrqa_squad-validation-435", "mrqa_naturalquestions-validation-8270", "mrqa_naturalquestions-validation-7115", "mrqa_naturalquestions-validation-100", "mrqa_squad-validation-5860", "mrqa_squad-validation-5174", "mrqa_squad-validation-1988", "mrqa_squad-validation-10397", "mrqa_naturalquestions-validation-9997", "mrqa_squad-validation-1872", "mrqa_squad-validation-2764", "mrqa_naturalquestions-validation-8757", "mrqa_squad-validation-5609", "mrqa_squad-validation-10320", "mrqa_squad-validation-2199", "mrqa_squad-validation-8180", "mrqa_squad-validation-5483", "mrqa_naturalquestions-validation-4685", "mrqa_squad-validation-4143", "mrqa_naturalquestions-validation-7930", "mrqa_squad-validation-1132", "mrqa_squad-validation-3639", "mrqa_squad-validation-6009", "mrqa_squad-validation-6388", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-9103", "mrqa_squad-validation-9348", "mrqa_squad-validation-1881", "mrqa_squad-validation-734", "mrqa_squad-validation-8118", "mrqa_naturalquestions-validation-246", "mrqa_squad-validation-7744", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-5289", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-4845", "mrqa_squad-validation-10350", "mrqa_squad-validation-4788", "mrqa_squad-validation-9875", "mrqa_squad-validation-7686", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-4632", "mrqa_naturalquestions-validation-101", "mrqa_squad-validation-4709", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4954", "mrqa_squad-validation-10251", "mrqa_naturalquestions-validation-1851", "mrqa_squad-validation-2835", "mrqa_squad-validation-2830", "mrqa_naturalquestions-validation-3214", "mrqa_naturalquestions-validation-10078", "mrqa_squad-validation-1123", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1971", "mrqa_squad-validation-7059", "mrqa_squad-validation-8230", "mrqa_squad-validation-7517", "mrqa_squad-validation-8471", "mrqa_squad-validation-9262", "mrqa_naturalquestions-validation-4413", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-5938", "mrqa_squad-validation-291", "mrqa_squad-validation-4274", "mrqa_squad-validation-9626", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-6564", "mrqa_squad-validation-5528", "mrqa_squad-validation-3477", "mrqa_naturalquestions-validation-4236", "mrqa_squad-validation-3091", "mrqa_squad-validation-3270", "mrqa_squad-validation-736", "mrqa_squad-validation-5847", "mrqa_squad-validation-7949", "mrqa_squad-validation-4088", "mrqa_squad-validation-4878", "mrqa_naturalquestions-validation-10470", "mrqa_squad-validation-10418", "mrqa_squad-validation-4708", "mrqa_squad-validation-2288", "mrqa_squad-validation-6681", "mrqa_squad-validation-8888", "mrqa_squad-validation-886", "mrqa_squad-validation-6150", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-8306", "mrqa_squad-validation-462", "mrqa_naturalquestions-validation-9692", "mrqa_squad-validation-7761", "mrqa_naturalquestions-validation-49", "mrqa_squad-validation-4230", "mrqa_squad-validation-10158", "mrqa_squad-validation-5511", "mrqa_naturalquestions-validation-9403", "mrqa_squad-validation-7967", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-9652", "mrqa_squad-validation-1054", "mrqa_squad-validation-539", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-8160", "mrqa_squad-validation-4072", "mrqa_naturalquestions-validation-8931", "mrqa_squad-validation-3093", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-366", "mrqa_squad-validation-9788", "mrqa_squad-validation-3704", "mrqa_squad-validation-3275", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-5292", "mrqa_squad-validation-9189", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-8346", "mrqa_squad-validation-6741", "mrqa_squad-validation-2997", "mrqa_squad-validation-2589", "mrqa_naturalquestions-validation-6009", "mrqa_squad-validation-10058", "mrqa_squad-validation-4251", "mrqa_squad-validation-3712", "mrqa_squad-validation-10472", "mrqa_squad-validation-6897", "mrqa_naturalquestions-validation-9660", "mrqa_squad-validation-3268", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-642", "mrqa_squad-validation-9078", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-9260", "mrqa_naturalquestions-validation-2578", "mrqa_squad-validation-7713", "mrqa_naturalquestions-validation-1814", "mrqa_naturalquestions-validation-5782", "mrqa_naturalquestions-validation-1224", "mrqa_squad-validation-3280", "mrqa_squad-validation-9913", "mrqa_naturalquestions-validation-325", "mrqa_squad-validation-5869", "mrqa_naturalquestions-validation-1389", "mrqa_naturalquestions-validation-2045", "mrqa_squad-validation-1378", "mrqa_squad-validation-4337", "mrqa_naturalquestions-validation-8531", "mrqa_squad-validation-3236", "mrqa_squad-validation-2471", "mrqa_squad-validation-5330", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-6307", "mrqa_squad-validation-8768", "mrqa_naturalquestions-validation-4846", "mrqa_squad-validation-4934", "mrqa_naturalquestions-validation-10421", "mrqa_squad-validation-8725", "mrqa_squad-validation-5932", "mrqa_squad-validation-4054", "mrqa_squad-validation-2654", "mrqa_naturalquestions-validation-8596", "mrqa_squad-validation-841", "mrqa_squad-validation-9329", "mrqa_squad-validation-5957", "mrqa_naturalquestions-validation-13", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-4652", "mrqa_squad-validation-4506", "mrqa_squad-validation-5633", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-3267", "mrqa_squad-validation-10392", "mrqa_squad-validation-6304", "mrqa_squad-validation-9572", "mrqa_naturalquestions-validation-10496", "mrqa_squad-validation-557", "mrqa_naturalquestions-validation-9062", "mrqa_squad-validation-7175", "mrqa_squad-validation-10179", "mrqa_squad-validation-9274", "mrqa_squad-validation-7196", "mrqa_squad-validation-655", "mrqa_squad-validation-2999", "mrqa_naturalquestions-validation-5611", "mrqa_squad-validation-2050", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-187", "mrqa_squad-validation-4616", "mrqa_squad-validation-259", "mrqa_naturalquestions-validation-3750", "mrqa_squad-validation-1383", "mrqa_naturalquestions-validation-998", "mrqa_squad-validation-400", "mrqa_squad-validation-1742", "mrqa_naturalquestions-validation-7803", "mrqa_squad-validation-1243", "mrqa_squad-validation-9904", "mrqa_naturalquestions-validation-1339", "mrqa_squad-validation-6241", "mrqa_naturalquestions-validation-3143", "mrqa_squad-validation-446", "mrqa_squad-validation-10397", "mrqa_squad-validation-5808", "mrqa_squad-validation-3534", "mrqa_naturalquestions-validation-9434", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-8620", "mrqa_squad-validation-728", "mrqa_squad-validation-10017", "mrqa_squad-validation-4311", "mrqa_squad-validation-5937", "mrqa_squad-validation-9363", "mrqa_naturalquestions-validation-2064", "mrqa_squad-validation-9562", "mrqa_squad-validation-4826", "mrqa_naturalquestions-validation-3628", "mrqa_naturalquestions-validation-171", "mrqa_squad-validation-3819", "mrqa_naturalquestions-validation-1679", "mrqa_squad-validation-8797", "mrqa_squad-validation-9045", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-53", "mrqa_squad-validation-5429", "mrqa_squad-validation-7473", "mrqa_squad-validation-1288", "mrqa_naturalquestions-validation-8465", "mrqa_squad-validation-8335", "mrqa_naturalquestions-validation-187", "mrqa_squad-validation-1766", "mrqa_naturalquestions-validation-3860", "mrqa_squad-validation-2378", "mrqa_naturalquestions-validation-7627", "mrqa_squad-validation-8679", "mrqa_naturalquestions-validation-1248", "mrqa_squad-validation-9180", "mrqa_squad-validation-1626", "mrqa_naturalquestions-validation-9094", "mrqa_naturalquestions-validation-6765", "mrqa_squad-validation-4456", "mrqa_squad-validation-7645", "mrqa_naturalquestions-validation-9772", "mrqa_squad-validation-7846", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-4879", "mrqa_squad-validation-3373", "mrqa_squad-validation-76", "mrqa_naturalquestions-validation-4124", "mrqa_squad-validation-2848", "mrqa_squad-validation-5101", "mrqa_naturalquestions-validation-9283", "mrqa_squad-validation-3690", "mrqa_squad-validation-6773", "mrqa_squad-validation-3774", "mrqa_squad-validation-4176", "mrqa_naturalquestions-validation-3376", "mrqa_squad-validation-8788", "mrqa_naturalquestions-validation-9457", "mrqa_squad-validation-1836", "mrqa_squad-validation-939", "mrqa_squad-validation-2375", "mrqa_squad-validation-1656", "mrqa_squad-validation-1233", "mrqa_naturalquestions-validation-9368", "mrqa_squad-validation-3826", "mrqa_squad-validation-2609", "mrqa_squad-validation-1365", "mrqa_squad-validation-6213", "mrqa_naturalquestions-validation-4486", "mrqa_squad-validation-8319", "mrqa_squad-validation-3156", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-3788", "mrqa_squad-validation-3715", "mrqa_squad-validation-9855", "mrqa_squad-validation-2781", "mrqa_squad-validation-9310", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-2368", "mrqa_naturalquestions-validation-7639", "mrqa_squad-validation-4293", "mrqa_squad-validation-8977", "mrqa_squad-validation-6883", "mrqa_squad-validation-6609", "mrqa_squad-validation-5606", "mrqa_naturalquestions-validation-4847", "mrqa_squad-validation-9445", "mrqa_squad-validation-3690", "mrqa_naturalquestions-validation-81", "mrqa_squad-validation-3757", "mrqa_naturalquestions-validation-6560", "mrqa_squad-validation-3529", "mrqa_squad-validation-6388", "mrqa_squad-validation-5360", "mrqa_naturalquestions-validation-6088", "mrqa_squad-validation-2230", "mrqa_squad-validation-3836", "mrqa_squad-validation-3221", "mrqa_squad-validation-6108", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-8962", "mrqa_squad-validation-9391", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-2658", "mrqa_squad-validation-7906", "mrqa_squad-validation-3255", "mrqa_squad-validation-7446", "mrqa_naturalquestions-validation-9660", "mrqa_squad-validation-187", "mrqa_squad-validation-9903", "mrqa_squad-validation-2397", "mrqa_squad-validation-8991", "mrqa_naturalquestions-validation-1959", "mrqa_naturalquestions-validation-10382", "mrqa_squad-validation-9537", "mrqa_squad-validation-6832", "mrqa_squad-validation-3611", "mrqa_squad-validation-4076", "mrqa_naturalquestions-validation-8994", "mrqa_squad-validation-9956", "mrqa_squad-validation-7712", "mrqa_naturalquestions-validation-9944", "mrqa_naturalquestions-validation-6586", "mrqa_squad-validation-4132", "mrqa_squad-validation-6958", "mrqa_squad-validation-5967", "mrqa_squad-validation-9745", "mrqa_squad-validation-982", "mrqa_naturalquestions-validation-4459", "mrqa_squad-validation-4934", "mrqa_squad-validation-5364", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-8247", "mrqa_naturalquestions-validation-3243", "mrqa_squad-validation-6237", "mrqa_squad-validation-222", "mrqa_naturalquestions-validation-5900", "mrqa_squad-validation-1814", "mrqa_squad-validation-7184", "mrqa_squad-validation-3249", "mrqa_squad-validation-6883", "mrqa_naturalquestions-validation-5791", "mrqa_squad-validation-1663", "mrqa_naturalquestions-validation-2674", "mrqa_squad-validation-645", "mrqa_naturalquestions-validation-2411", "mrqa_squad-validation-6403", "mrqa_squad-validation-3229", "mrqa_squad-validation-5584", "mrqa_squad-validation-8355", "mrqa_squad-validation-1863", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-10296", "mrqa_squad-validation-9066", "mrqa_naturalquestions-validation-2698", "mrqa_squad-validation-7507", "mrqa_naturalquestions-validation-3214", "mrqa_squad-validation-6395", "mrqa_squad-validation-639", "mrqa_squad-validation-9901", "mrqa_squad-validation-2011", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-32", "mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-8728", "mrqa_squad-validation-1909", "mrqa_squad-validation-8242", "mrqa_naturalquestions-validation-1704", "mrqa_squad-validation-943", "mrqa_squad-validation-8122", "mrqa_squad-validation-8678", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-8909", "mrqa_squad-validation-8415", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-7162", "mrqa_squad-validation-4283", "mrqa_naturalquestions-validation-2354", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-9129", "mrqa_squad-validation-2956", "mrqa_squad-validation-9189", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-451", "mrqa_squad-validation-8138", "mrqa_squad-validation-5633", "mrqa_naturalquestions-validation-6278", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-867", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-338", "mrqa_squad-validation-7390", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-1328", "mrqa_squad-validation-3757", "mrqa_squad-validation-10014", "mrqa_squad-validation-5649", "mrqa_squad-validation-2857", "mrqa_naturalquestions-validation-9921", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2889", "mrqa_squad-validation-2579", "mrqa_naturalquestions-validation-4562", "mrqa_squad-validation-955", "mrqa_squad-validation-8000", "mrqa_naturalquestions-validation-7499", "mrqa_naturalquestions-validation-9816", "mrqa_squad-validation-8906", "mrqa_squad-validation-1541", "mrqa_naturalquestions-validation-10135", "mrqa_squad-validation-3630", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-1445", "mrqa_naturalquestions-validation-9571", "mrqa_squad-validation-5051", "mrqa_squad-validation-4472", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-9281"], "OKR": 0.83984375, "KG": 0.3671875, "before_eval_results": {"predictions": ["from 7:00 to 9:00 a.m. weekdays", "liquid", "720 feet", "Christian doctrine", "a standard version of the German language", "negative long-term impact on the health of the city's residents", "an electrical generator", "the Netherlands", "30", "will benefit not only the school, but surrounding community, pointing to such features as the enhanced transit infrastructure, possible shuttles open to the public, and park space which will also be publicly accessible", "1979", "Schmalkaldic League", "Jaime Weston", "Capitol Hill, Washington, D.C.", "Eisleben, Saxony, then part of the Holy Roman Empire", "predominantly four stories high", "river Aare", "six", "Sophocles' play Antigone", "pedagogy", "two", "middle of the 20th century", "widespread education", "Frank Oz", "San Francisco", "a retinal ganglion cell axons and glial cells", "Yuzuru Hanyu", "1792", "a new dynasty", "a Sumatran orangutan", "XXXIX", "a term often equated with clinical or community trials of treatments and other interventions", "Kelly Osbourne", "the most recent Super Bowl champions", "San Jose, California", "Audrey II", "when september ends meaning music video", "during World War II", "two", "a specific cell surface receptor complex known as the IFN - \u03b1 / \u03b2 receptor ( IFNAR )", "Sir Henry Cole", "1890", "1886", "a specific individual to operate one or more types of motorized vehicles, such as a motorcycle, car, truck, or bus on a public road", "Olympia", "the states or the people", "1546", "Michael Crawford", "a global cultural icon of France", "the name announcement of Kylie Jenner's first child", "Beijing, China", "a single representative", "Ukraine", "a foreign worker to an individual in his or her home country", "Master Christopher Jones", "Dalveer Bhandari", "John Locke", "My Summer Story", "humid subtropical climate, with hot summers and mild winters", "marks the transition from summer to winter, in September ( Northern Hemisphere ) or March ( Southern Hemisphere ), when the duration of daylight becomes noticeably shorter and the temperature cools down considerably", "a significant portion of the lyrics and the libretto of the `` new version '' of Rent", "Chuck Noland", "Queen M\u00e1xima of the Netherlands", "a French phrase often used in English to express a cheerful enjoyment of life"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6761598166860604}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, false], "QA-F1": [0.9090909090909091, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.7234042553191489, 0.0, 1.0, 1.0, 1.0, 0.4, 0.8571428571428571, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.1764705882352941, 0.3, 0.5, 0.0, 0.9500000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7999999999999999, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666669, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5978", "mrqa_squad-validation-2116", "mrqa_squad-validation-5213", "mrqa_squad-validation-7134", "mrqa_squad-validation-3989", "mrqa_squad-validation-2212", "mrqa_squad-validation-5148", "mrqa_squad-validation-6639", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-3309", "mrqa_naturalquestions-validation-165", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-878", "mrqa_naturalquestions-validation-5583", "mrqa_naturalquestions-validation-5997", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-5637", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-158", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-1178", "mrqa_naturalquestions-validation-9966"], "SR": 0.5625, "CSR": 0.6443014705882353, "EFR": 0.8928571428571429, "Overall": 0.6836035976890756}, {"timecode": 51, "before_eval_results": {"predictions": ["Kublai Khan", "Daily Mail", "late 1870s", "40", "lipid monolayer", "Bainbridge's", "computational problems", "secret ballot", "Von Miller", "19 April 1943", "three", "ctenophores", "Bart Starr", "More than 1 million", "General Electric", "Masaaki Shirakawa", "very weak", "taking on debt", "the Armenians vassal-states of Sassoun and Taron", "magnitude and direction", "hunting of various animals; not just their age but their size make these unique", "2005", "Ikh Zasag", "meditation and acceptance practices on a regular basis as well as before and during competition", "Windows Media Video ( WMA )", "board of trade", "the breast or lower chest of beef or veal", "Michael Clarke Duncan", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another, even though rules applied by employers or landlords are formally neutral", "gastrocnemius muscle", "Ingrid Bergman", "pop and R&B ballad, with Latin pop influences", "Mitch Murray", "IBM", "Stephen Foster", "Narendra Modi", "Brazil, Turkey and Uzbekistan made their Winter Paralympic debut in Sochi, while Hungary and South Africa, who participated in Vancouver, did not send any athletes", "November 1999", "Nalini Negi", "Manhattan", "1937", "Nicklaus", "October 27, 1904", "Bulgaria", "1980", "a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week", "Archie Andrews", "mughal garden of rashtrapati bhavan", "March 2, 2016", "inmates Clarence Anglin", "Peter Andrew Beardsley MBE", "St Pancras International", "energy is used to strip electrons from suitable substances, such as water, producing oxygen gas", "1900", "Sophocles", "independently in different parts of the globe, and included a diverse range of taxa", "2007", "the House of Representatives", "Baker, California, USA", "Austria - Hungary", "Eric Clapton", "In 1871 A.D.", "Steve Goodman", "Gomes"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7798849587912088}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.75, 0.28571428571428575, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.6666666666666666, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.20000000000000004, 0.0, 1.0, 0.2, 1.0, 0.0, 0.8, 1.0, 1.0, 0.8, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1136", "mrqa_squad-validation-5646", "mrqa_squad-validation-6333", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-4628", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-8119", "mrqa_naturalquestions-validation-6782", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-3019"], "SR": 0.6875, "CSR": 0.6451322115384616, "EFR": 1.0, "Overall": 0.7051983173076923}, {"timecode": 52, "before_eval_results": {"predictions": ["Catch Me Who Can", "Trevathan", "Edict of Fontainebleau", "ether", "February 1, 2016", "Jacksonville", "very low tuition fees and/or offer scholarships", "nervous breakdown", "fewer than 10 employees", "symmetric spin function", "\"cellular\" and \"humoral\"", "1294", "individual state laws", "liquid", "Canadians", "confirmation and membership preparation classes", "Isiah Bowman", "12 January", "1,300,000", "somewhere close to the Onon River and the Burkhan Khaldun mountain (part of the Kentii mountain range)", "low-light conditions", "CFTO-TV", "photoreceptor cells", "Santo Domingo", "must be at least 18 or 21 years old ( or have a legal guardian present )", "photoelectric ( optical )", "Stephen Sondheim", "The Data Protection Act 1998", "Canadian ice dancers Tessa Virtue and Scott Moir", "The Enchantress", "2018", "After Britain followed the rest of the world in decimalising its currency", "Walter Brennan", "Teri Hatcher", "Liberia", "The Intolerable Acts", "ancient Athens", "232", "the Hallertau in Germany", "the Pontic Mountains in Turkey", "After tentatively courting each other in `` Entropy ''", "1877", "Sylvester Stallone", "hot plasma", "Proposition 103", "Confederate forces", "mashed potato", "Tyrann Devine Mathieu", "eight", "Betty", "judges", "Sanchez Navarro", "Major General Clarence L. Tinker, the first Native American Major General", "Splodgenessabounds", "the mountains outside City 17", "Edward G. Robinson", "August 5, 1937", "L.K. Advani", "Dragon Ball GT", "Brooklyn Heights", "the Khoisan language of the \u01c0Xam people", "India", "$19.8 trillion", "Tigris and Euphrates rivers"], "metric_results": {"EM": 0.625, "QA-F1": 0.7131328162578162}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.4, 1.0, 0.14814814814814814, 1.0, 0.33333333333333337, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7137", "mrqa_squad-validation-10453", "mrqa_squad-validation-3691", "mrqa_squad-validation-10189", "mrqa_squad-validation-6073", "mrqa_naturalquestions-validation-9963", "mrqa_naturalquestions-validation-8617", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-7166", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-9242", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-138", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-5608", "mrqa_naturalquestions-validation-6888", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-10606", "mrqa_naturalquestions-validation-3056", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-6577"], "SR": 0.625, "CSR": 0.6447523584905661, "EFR": 0.9583333333333334, "Overall": 0.6967890133647799}, {"timecode": 53, "before_eval_results": {"predictions": ["July 2013", "A 2012 study", "The Private Education Student Financial Assistance", "The Sinclair Broadcast Group", "expansion", "hunter's garb", "1221", "polynomial time", "though the 21st century", "June 1978", "Edgar", "upper Danube", "The Watermark business park next to the MetroCentre in Gateshead", "194", "July 2015", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "Polonez", "Cam Newton", "Ondemar Dias", "other locations throughout Scotland", "glowed even when turned off", "allegations of professional misconduct", "Mahatma Gandhi", "in the 1960s", "At the peak of World War II", "Kristak's grandmother", "Harry Potter and the Deathly Hallows", "the Pacific coast", "January 2004", "Yuzuru Hanyu", "division", "American Indian allies", "One Ring", "accommodationism", "Tom Selleck", "Kol", "Bryan - songwriters Dan Bern and Mike Viola ( of the Candy Butchers )", "Richard Masur", "Splodgenessabounds", "start fires, hunt, and bury their dead", "Buffalo Bill", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "2010", "The prequel film Revenge of the Sith", "John Smith", "summer", "orogenic belt", "Qutab Ud - Din - Aibak", "a state or other organizational body that controls the factors of production", "Foreign minister Hermann M\u00fcller and colonial minister Johannes Bell", "October 27, 2016", "neuropsychology", "Emma Watson", "The Epistle of Paul to the Philippians", "Bill Patriots", "the Chicago metropolitan area", "Accounting Standards Board ( ASB )", "one", "January 2018", "The soma ( cell body )", "Rose Stagg", "Battle of Antietam", "Victory gardens", "An island"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6738672785547786}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 0.0, 1.0, 0.0, 0.33333333333333337, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6060", "mrqa_squad-validation-5464", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-3188", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-8986", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-3422", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-9782", "mrqa_naturalquestions-validation-1728", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-2652", "mrqa_naturalquestions-validation-2351", "mrqa_naturalquestions-validation-4837", "mrqa_naturalquestions-validation-10209"], "SR": 0.609375, "CSR": 0.6440972222222222, "EFR": 1.0, "Overall": 0.7049913194444445}, {"timecode": 54, "before_eval_results": {"predictions": ["the University of Washington", "the Scottish Government", "2016", "15th", "the Saturn V launch vehicle", "Annual Conference Order of Elders", "foreign-born inhabitants", "supportive and effective", "1876", "XXXVII", "the V&A Museum of Childhood", "hockey stick graph", "The E. W. Scripps Company", "5,984", "modern", "can produce both eggs and sperm at the same time", "the evidence for these words to be unreliable, since they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "Von Miller", "the Harris School of Public Policy Studies", "Aaron Spelling", "twin-cylinder", "the last Ice Age", "elected to their positions in the Senate by their respective party caucuses", "257,083", "a brain region that in humans is located in the dorsal portion of the frontal lobe", "digestive systems", "the thylakoid membrane", "John Adams", "pigs", "22", "a form consisting of instructions that the computer can directly execute", "Erica Rivera", "a unique memory address", "Extroverted Thinking ( Te )", "reproductive anatomy ( such as the uterus in females )", "four volumes", "the class that teaches students defensive techniques to defend against the Dark Arts, and to be protected from Dark creatures", "Austria - Hungary", "Walter Egan", "the left and right main pulmonary arteries ( one for each lung )", "Saphira", "the Portuguese", "the Islamic prophet Muhammad", "Thomas F. Herd", "Matt Monro", "George Warren Barnes", "Taron Egerton", "Kristy Swanson", "ABC", "miscarriage", "to call ( in spring and summer ) and hunt for food", "New York City west", "the south", "1961", "the Colony of Virginia", "Scheria", "the efferent nerves that directly innervate muscles", "prenatal development", "around 2 %", "1979", "Andrea Brooks", "the intermembrane space", "the development of electronic computers in the United States", "1931"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6629550824168108}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8000000000000002, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.7586206896551725, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0909090909090909, 0.6, 0.06451612903225806, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3907", "mrqa_squad-validation-10093", "mrqa_squad-validation-681", "mrqa_squad-validation-2095", "mrqa_squad-validation-156", "mrqa_squad-validation-6058", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6414", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-4737", "mrqa_naturalquestions-validation-9885", "mrqa_naturalquestions-validation-4319", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9144", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-3175", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-6483", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-1165"], "SR": 0.53125, "CSR": 0.6420454545454546, "EFR": 0.8666666666666667, "Overall": 0.6779142992424243}, {"timecode": 55, "UKR": 0.70703125, "OKR_sampled_ids": ["mrqa_squad-validation-2288", "mrqa_squad-validation-10365", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-6772", "mrqa_squad-validation-6313", "mrqa_squad-validation-10442", "mrqa_naturalquestions-validation-8530", "mrqa_naturalquestions-validation-5999", "mrqa_squad-validation-978", "mrqa_squad-validation-5861", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-9172", "mrqa_squad-validation-9745", "mrqa_naturalquestions-validation-2248", "mrqa_squad-validation-9348", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-1515", "mrqa_squad-validation-3230", "mrqa_squad-validation-5759", "mrqa_naturalquestions-validation-851", "mrqa_squad-validation-852", "mrqa_squad-validation-7938", "mrqa_squad-validation-6288", "mrqa_naturalquestions-validation-2354", "mrqa_squad-validation-4934", "mrqa_naturalquestions-validation-8909", "mrqa_squad-validation-2508", "mrqa_naturalquestions-validation-8209", "mrqa_naturalquestions-validation-10172", "mrqa_squad-validation-639", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-6899", "mrqa_naturalquestions-validation-8383", "mrqa_squad-validation-10138", "mrqa_squad-validation-10254", "mrqa_squad-validation-4147", "mrqa_naturalquestions-validation-2208", "mrqa_naturalquestions-validation-8531", "mrqa_squad-validation-713", "mrqa_naturalquestions-validation-3074", "mrqa_naturalquestions-validation-3788", "mrqa_squad-validation-8122", "mrqa_naturalquestions-validation-10583", "mrqa_squad-validation-7194", "mrqa_squad-validation-3689", "mrqa_squad-validation-6876", "mrqa_squad-validation-9029", "mrqa_naturalquestions-validation-2672", "mrqa_squad-validation-3602", "mrqa_naturalquestions-validation-6797", "mrqa_squad-validation-7846", "mrqa_squad-validation-212", "mrqa_squad-validation-7321", "mrqa_squad-validation-2754", "mrqa_squad-validation-7304", "mrqa_squad-validation-6806", "mrqa_squad-validation-4919", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-3778", "mrqa_squad-validation-3630", "mrqa_squad-validation-1309", "mrqa_naturalquestions-validation-5251", "mrqa_squad-validation-9664", "mrqa_squad-validation-7480", "mrqa_squad-validation-8466", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-1888", "mrqa_naturalquestions-validation-7412", "mrqa_naturalquestions-validation-6560", "mrqa_squad-validation-918", "mrqa_squad-validation-118", "mrqa_squad-validation-8222", "mrqa_squad-validation-1434", "mrqa_naturalquestions-validation-2485", "mrqa_squad-validation-8036", "mrqa_squad-validation-2919", "mrqa_squad-validation-1095", "mrqa_squad-validation-460", "mrqa_squad-validation-204", "mrqa_naturalquestions-validation-642", "mrqa_squad-validation-3550", "mrqa_squad-validation-7232", "mrqa_naturalquestions-validation-6435", "mrqa_squad-validation-6523", "mrqa_naturalquestions-validation-2006", "mrqa_squad-validation-1954", "mrqa_squad-validation-2192", "mrqa_squad-validation-4470", "mrqa_naturalquestions-validation-9772", "mrqa_squad-validation-5679", "mrqa_naturalquestions-validation-4026", "mrqa_squad-validation-7266", "mrqa_naturalquestions-validation-4973", "mrqa_squad-validation-2097", "mrqa_squad-validation-8496", "mrqa_squad-validation-64", "mrqa_naturalquestions-validation-9972", "mrqa_naturalquestions-validation-4288", "mrqa_squad-validation-297", "mrqa_squad-validation-10315", "mrqa_squad-validation-2281", "mrqa_naturalquestions-validation-8270", "mrqa_squad-validation-4778", "mrqa_squad-validation-2221", "mrqa_squad-validation-2956", "mrqa_squad-validation-5528", "mrqa_squad-validation-9993", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-1959", "mrqa_squad-validation-1555", "mrqa_naturalquestions-validation-6453", "mrqa_squad-validation-3601", "mrqa_squad-validation-3965", "mrqa_naturalquestions-validation-6182", "mrqa_squad-validation-10465", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-366", "mrqa_squad-validation-3704", "mrqa_naturalquestions-validation-3935", "mrqa_squad-validation-7410", "mrqa_squad-validation-6312", "mrqa_squad-validation-8983", "mrqa_squad-validation-5987", "mrqa_naturalquestions-validation-4278", "mrqa_squad-validation-9913", "mrqa_naturalquestions-validation-7594", "mrqa_squad-validation-4799", "mrqa_squad-validation-1123", "mrqa_squad-validation-8186", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-8016", "mrqa_squad-validation-1777", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-1163", "mrqa_squad-validation-6143", "mrqa_squad-validation-4186", "mrqa_squad-validation-4539", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-9062", "mrqa_squad-validation-8691", "mrqa_squad-validation-4047", "mrqa_naturalquestions-validation-1471", "mrqa_squad-validation-1661", "mrqa_squad-validation-462", "mrqa_naturalquestions-validation-10209", "mrqa_squad-validation-6714", "mrqa_squad-validation-2448", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-7627", "mrqa_squad-validation-5854", "mrqa_squad-validation-6329", "mrqa_squad-validation-9753", "mrqa_squad-validation-9635", "mrqa_naturalquestions-validation-4523", "mrqa_squad-validation-1217", "mrqa_squad-validation-8948", "mrqa_squad-validation-7357", "mrqa_squad-validation-9750", "mrqa_squad-validation-167", "mrqa_squad-validation-7338", "mrqa_naturalquestions-validation-3086", "mrqa_squad-validation-1670", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-8298", "mrqa_squad-validation-3083", "mrqa_squad-validation-1029", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-5719", "mrqa_squad-validation-3938", "mrqa_squad-validation-5255", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-2506", "mrqa_squad-validation-6609", "mrqa_squad-validation-4543", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-811", "mrqa_squad-validation-6213", "mrqa_squad-validation-6949", "mrqa_squad-validation-2354", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-3922", "mrqa_squad-validation-10402", "mrqa_squad-validation-10398", "mrqa_squad-validation-3406", "mrqa_naturalquestions-validation-6624", "mrqa_squad-validation-7906", "mrqa_squad-validation-88", "mrqa_squad-validation-9290", "mrqa_naturalquestions-validation-1762", "mrqa_squad-validation-2334", "mrqa_naturalquestions-validation-578", "mrqa_squad-validation-9144", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-10583", "mrqa_squad-validation-3150", "mrqa_naturalquestions-validation-7489", "mrqa_squad-validation-10320", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-4844", "mrqa_naturalquestions-validation-7009", "mrqa_squad-validation-1018", "mrqa_naturalquestions-validation-1813", "mrqa_squad-validation-7921", "mrqa_squad-validation-7352", "mrqa_naturalquestions-validation-2119", "mrqa_naturalquestions-validation-6011", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-1222", "mrqa_squad-validation-6817", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-10416", "mrqa_squad-validation-7201", "mrqa_squad-validation-9923", "mrqa_squad-validation-9363", "mrqa_naturalquestions-validation-5082", "mrqa_squad-validation-5957", "mrqa_squad-validation-4059", "mrqa_squad-validation-8658", "mrqa_squad-validation-4478", "mrqa_squad-validation-6526", "mrqa_squad-validation-7810", "mrqa_squad-validation-4354", "mrqa_naturalquestions-validation-6276", "mrqa_squad-validation-298", "mrqa_naturalquestions-validation-10706", "mrqa_squad-validation-557", "mrqa_naturalquestions-validation-1144", "mrqa_squad-validation-1881", "mrqa_squad-validation-4062", "mrqa_squad-validation-6167", "mrqa_squad-validation-8544", "mrqa_squad-validation-1273", "mrqa_naturalquestions-validation-1239", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-10081", "mrqa_squad-validation-3826", "mrqa_squad-validation-9491", "mrqa_naturalquestions-validation-1459", "mrqa_squad-validation-8534", "mrqa_naturalquestions-validation-7574", "mrqa_squad-validation-8933", "mrqa_naturalquestions-validation-7268", "mrqa_naturalquestions-validation-3545", "mrqa_squad-validation-9866", "mrqa_squad-validation-1282", "mrqa_naturalquestions-validation-8417", "mrqa_squad-validation-5847", "mrqa_squad-validation-7769", "mrqa_squad-validation-2018", "mrqa_squad-validation-6109", "mrqa_squad-validation-1467", "mrqa_squad-validation-2409", "mrqa_squad-validation-2684", "mrqa_squad-validation-5995", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-7741", "mrqa_squad-validation-7390", "mrqa_naturalquestions-validation-180", "mrqa_squad-validation-3495", "mrqa_squad-validation-8353", "mrqa_squad-validation-3151", "mrqa_naturalquestions-validation-1640", "mrqa_squad-validation-3664", "mrqa_squad-validation-2513", "mrqa_squad-validation-5741", "mrqa_naturalquestions-validation-8414", "mrqa_squad-validation-91", "mrqa_naturalquestions-validation-6203", "mrqa_naturalquestions-validation-7858", "mrqa_squad-validation-10155", "mrqa_squad-validation-9076", "mrqa_squad-validation-9257", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-887", "mrqa_squad-validation-2562", "mrqa_squad-validation-2003", "mrqa_squad-validation-6607", "mrqa_naturalquestions-validation-3862", "mrqa_squad-validation-2854", "mrqa_naturalquestions-validation-10509", "mrqa_squad-validation-5906", "mrqa_naturalquestions-validation-10268", "mrqa_squad-validation-202", "mrqa_squad-validation-1948", "mrqa_squad-validation-5641", "mrqa_squad-validation-2663", "mrqa_squad-validation-8471", "mrqa_squad-validation-9798", "mrqa_squad-validation-5838", "mrqa_squad-validation-7593", "mrqa_squad-validation-488", "mrqa_squad-validation-4826", "mrqa_squad-validation-7059", "mrqa_squad-validation-6379", "mrqa_squad-validation-8725", "mrqa_squad-validation-1247", "mrqa_naturalquestions-validation-3632", "mrqa_squad-validation-2511", "mrqa_squad-validation-3190", "mrqa_squad-validation-5317", "mrqa_squad-validation-539", "mrqa_squad-validation-10244", "mrqa_squad-validation-5085", "mrqa_squad-validation-4092", "mrqa_squad-validation-8572", "mrqa_naturalquestions-validation-3199", "mrqa_squad-validation-1603", "mrqa_squad-validation-9784", "mrqa_naturalquestions-validation-8251", "mrqa_squad-validation-4459", "mrqa_squad-validation-5156", "mrqa_squad-validation-8969", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-7944", "mrqa_squad-validation-9720", "mrqa_squad-validation-6360", "mrqa_squad-validation-2353", "mrqa_squad-validation-7296", "mrqa_squad-validation-4916", "mrqa_naturalquestions-validation-2095", "mrqa_naturalquestions-validation-5925", "mrqa_squad-validation-448", "mrqa_squad-validation-2805", "mrqa_naturalquestions-validation-10070", "mrqa_squad-validation-1231", "mrqa_squad-validation-4808", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-6887", "mrqa_squad-validation-3142", "mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-5995", "mrqa_squad-validation-3403", "mrqa_squad-validation-5688", "mrqa_squad-validation-4320", "mrqa_naturalquestions-validation-134", "mrqa_squad-validation-8160", "mrqa_naturalquestions-validation-3482", "mrqa_squad-validation-3690", "mrqa_squad-validation-7863", "mrqa_naturalquestions-validation-9071", "mrqa_squad-validation-3740", "mrqa_squad-validation-1888", "mrqa_squad-validation-3689", "mrqa_squad-validation-955", "mrqa_naturalquestions-validation-6408", "mrqa_squad-validation-7414", "mrqa_squad-validation-1941", "mrqa_naturalquestions-validation-2906", "mrqa_squad-validation-10014", "mrqa_squad-validation-6865", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-1089", "mrqa_squad-validation-3453", "mrqa_squad-validation-5836", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-3711", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-10618", "mrqa_squad-validation-1542", "mrqa_naturalquestions-validation-1398", "mrqa_squad-validation-3850", "mrqa_squad-validation-3240", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-1091", "mrqa_squad-validation-2111", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1400", "mrqa_squad-validation-6754", "mrqa_squad-validation-648", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-3839", "mrqa_naturalquestions-validation-3311", "mrqa_squad-validation-205", "mrqa_naturalquestions-validation-7214", "mrqa_squad-validation-8169", "mrqa_naturalquestions-validation-5048", "mrqa_squad-validation-6952", "mrqa_naturalquestions-validation-5026", "mrqa_squad-validation-9082", "mrqa_squad-validation-5491", "mrqa_squad-validation-585", "mrqa_naturalquestions-validation-6754", "mrqa_naturalquestions-validation-5958", "mrqa_naturalquestions-validation-8317", "mrqa_squad-validation-10418", "mrqa_squad-validation-1024", "mrqa_squad-validation-3495", "mrqa_squad-validation-1430", "mrqa_squad-validation-1656", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-3053", "mrqa_squad-validation-283", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-2684", "mrqa_squad-validation-2790", "mrqa_naturalquestions-validation-1084", "mrqa_naturalquestions-validation-1339", "mrqa_naturalquestions-validation-4829", "mrqa_squad-validation-6058", "mrqa_naturalquestions-validation-6800", "mrqa_squad-validation-2459", "mrqa_naturalquestions-validation-2990", "mrqa_squad-validation-2976", "mrqa_squad-validation-9569", "mrqa_naturalquestions-validation-3546", "mrqa_squad-validation-9391", "mrqa_squad-validation-419", "mrqa_squad-validation-9504", "mrqa_naturalquestions-validation-1389", "mrqa_squad-validation-470", "mrqa_naturalquestions-validation-4054", "mrqa_naturalquestions-validation-171", "mrqa_squad-validation-7462", "mrqa_squad-validation-10448", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-2378", "mrqa_squad-validation-8230", "mrqa_squad-validation-2611", "mrqa_squad-validation-4551", "mrqa_squad-validation-3413", "mrqa_squad-validation-796", "mrqa_squad-validation-6444", "mrqa_naturalquestions-validation-6087", "mrqa_squad-validation-1233", "mrqa_squad-validation-1562", "mrqa_naturalquestions-validation-5900", "mrqa_squad-validation-3133", "mrqa_squad-validation-5296", "mrqa_naturalquestions-validation-2889", "mrqa_squad-validation-5742", "mrqa_squad-validation-924", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-1706", "mrqa_squad-validation-156", "mrqa_squad-validation-7014", "mrqa_squad-validation-2072", "mrqa_squad-validation-7452", "mrqa_squad-validation-2", "mrqa_squad-validation-5196", "mrqa_squad-validation-1849", "mrqa_naturalquestions-validation-10631", "mrqa_squad-validation-1979", "mrqa_squad-validation-4468", "mrqa_naturalquestions-validation-4976", "mrqa_squad-validation-1656", "mrqa_squad-validation-8415", "mrqa_squad-validation-10023", "mrqa_naturalquestions-validation-5711", "mrqa_naturalquestions-validation-6461", "mrqa_squad-validation-4992", "mrqa_squad-validation-4221", "mrqa_squad-validation-7321", "mrqa_squad-validation-2764", "mrqa_squad-validation-3422", "mrqa_squad-validation-8368", "mrqa_naturalquestions-validation-9492", "mrqa_squad-validation-1752", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8117", "mrqa_squad-validation-4434", "mrqa_squad-validation-6690", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-8383", "mrqa_squad-validation-867", "mrqa_squad-validation-4467", "mrqa_squad-validation-9700", "mrqa_squad-validation-2435", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4137", "mrqa_squad-validation-2352", "mrqa_naturalquestions-validation-519", "mrqa_squad-validation-3529", "mrqa_squad-validation-3278", "mrqa_squad-validation-426", "mrqa_squad-validation-2058", "mrqa_squad-validation-5213", "mrqa_naturalquestions-validation-9887", "mrqa_naturalquestions-validation-220", "mrqa_squad-validation-1924", "mrqa_squad-validation-9118", "mrqa_naturalquestions-validation-9316", "mrqa_squad-validation-4448", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-3253", "mrqa_squad-validation-2223", "mrqa_squad-validation-4710", "mrqa_squad-validation-31", "mrqa_naturalquestions-validation-9963", "mrqa_squad-validation-8790", "mrqa_naturalquestions-validation-10470", "mrqa_squad-validation-3263", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-3188", "mrqa_squad-validation-6097", "mrqa_squad-validation-10309", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-2832", "mrqa_squad-validation-10021", "mrqa_naturalquestions-validation-1856"], "OKR": 0.794921875, "before_eval_results": {"predictions": ["\u00dcberseering BV v Nordic Construction GmbH", "T(n) = O(n2)", "about 17", "1970s", "phlogiston theory of combustion and corrosion", "Alceu Ranzi", "Osama bin Laden", "Daniel B. Burke", "Stage 2", "Glucocorticoids", "67.9 passer rating", "Germany and Switzerland", "chloroplast division", "AD 14", "1,000 m3/s (35,000 cu ft/s)", "The Holocene", "Egyptians", "Kevin Harlan", "Kawann Short", "\"yes\" or \"no\"", "chronic and complex disease states such as cancer, hepatitis, and rheumatoid arthritis", "Leonardo da Vinci", "five", "16.5 quadrillion BTUs", "in Iranian statuary dating to that time period", "Heather Stebbins", "John Smith", "Andaman and Nicobar Islands -- Port Blair", "The Bellamy Brothers", "4.37 light - years ( 1.34 pc )", "New Mexico", "traditional Bulgarian and Romanian sweet leavened bread", "Betty", "in a secluded cove on the far eastern end of Westward Beach, between Zuma Beach and Point Dume in Malibu", "the Rolling Stones", "832 BCE", "Olivia Olson", "\u03ba\u03b1\u1f76 \u03c4\u03bf\u1fe6 \u03bc\ufffd\u03b3\u03af\u03bf\u03c5 \u03a0\u03bd\u03b5\u03cd\u03bc\u03b1\u03c4\u03bf\u03c2, eis to onoma tou Patros kai tou Huiou", "Ricky Ponting", "October 27, 1904", "December 2, 1942", "before title pages and titles", "Thomas Anelka", "into the coccygeal nerve, all of which arise from the lumbar enlargement and the conus medullaris of the spinal cord", "Barry Bonds", "2018", "Michael Rosen and illustrated by Helen Oxenbury", "England and Wales", "Garbi\u00f1e Muguruza", "Thomas Chisum", "usually fall back with terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm", "Roman Reigns", "John Locke", "In 1776", "northwest Washington", "at the TV studio in the Hollywood Masonic Temple ( now known as the El Capitan Entertainment Centre )", "Thomas Middleditch", "Fruit of the Mystery : True Conversion ( Piety, Joy of Finding Jesus )", "A regulatory site ( also known as an `` allosteric site '' )", "Squamish, British Columbia, Canada", "to free up disk space on a computer's hard drive", "Dr. Lexie Grey ( Chyler Leigh )", "Qualitative psychological research", "Roar"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7199832863895363}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.7499999999999999, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5454545454545454, 1.0, 1.0, 0.4444444444444445, 0.5, 1.0, 0.0, 0.14814814814814814, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 0.4, 0.4444444444444445, 1.0, 0.5925925925925926, 0.7499999999999999, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3300", "mrqa_squad-validation-4309", "mrqa_squad-validation-270", "mrqa_squad-validation-6729", "mrqa_squad-validation-1772", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5168", "mrqa_naturalquestions-validation-650", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-5034", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-2119", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1315", "mrqa_naturalquestions-validation-101", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-8594"], "SR": 0.59375, "CSR": 0.6411830357142857, "EFR": 0.8846153846153846, "Overall": 0.678987809065934}, {"timecode": 56, "before_eval_results": {"predictions": ["In Procureur du Roi v Dassonville", "the early part", "secular leanings or who had introduced or promoted Western/foreign ideas and practices into Islamic societies", "1963", "Chuck Howley", "unbalanced centripetal force felt by any object is always directed toward the center of the curving path", "Levi's Stadium", "ranked above", "Timucua", "the housing bubble", "December 1963", "article 30", "highways", "gold", "US$10 a week raise", "Han Chinese", "propaganda", "gold", "long-run economic growth", "three", "The Space Museum", "gastrocnemius", "August 15, 1971", "humid subtropical climate, with hot summers and mild winters", "never made", "the center of the Northern Hemisphere", "1977", "the President", "Burbank, California", "from a crown cutting of the fruit, possibly flowering in five to ten months and fruiting in the following six months", "Get / images / logo. png", "12.65 m", "Muhammad", "IV", "September 19, 2017", "during the American Civil War", "the Mandate of Heaven", "Emmanuelle Chriqui", "1273.6 cm", "Edd Kimber", "hyperirritable spots in the fascia surrounding skeletal muscle", "Dr. Lexie Grey", "Native Americans", "foreign investors", "in two theaters in New York City on December 1, 2017", "his frustration with the atmosphere in the group at that time", "Montreal Canadiens", "Zhu Yuanzhang", "the U.S.", "The User State Migration Tool ( USMT )", "Manchuria", "in Mexico, where both the village and the U.S. border town were built for the film", "Frankie Laine's `` I Believe ''", "Sir Hugh Beaver", "12 to 36 months old", "2005", "Joie de vivre", "W. Edwards Deming", "the mouth of the Mississippi River", "the titular `` fool ''", "American country music singer George Strait", "Frank Langella", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "not previously attempted in Britain, with a combined military force of over 615,000 in December 1803"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6559998498892}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, false], "QA-F1": [0.2222222222222222, 1.0, 0.967741935483871, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 0.0, 0.8333333333333333, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.09523809523809525, 0.6666666666666665, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.09090909090909091]}}, "before_error_ids": ["mrqa_squad-validation-4331", "mrqa_squad-validation-9526", "mrqa_squad-validation-10403", "mrqa_squad-validation-1275", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-1198", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-7458", "mrqa_naturalquestions-validation-8228", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2267", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-283", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-8352", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-3119", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-8700"], "SR": 0.578125, "CSR": 0.6400767543859649, "EFR": 0.9259259259259259, "Overall": 0.6870286610623781}, {"timecode": 57, "before_eval_results": {"predictions": ["sculptured fonts", "7.8%", "girls", "intractable problems", "Annual Conference", "the fertile highlands", "complexity classes", "1773", "Ukraine", "formal language", "1762", "architects, interior designers, engineers and constructors", "making home craft tools, mechanical appliances, and the ability to memorize Serbian epic poems", "vertebrates", "specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "liquid nitrogen", "less than two percent per year", "lightning", "mild, moist winters and hot and dry summers", "white", "In December 1971", "Retribution", "the colonies of British America", "an apprentice of the fictional Jedi Order in the Star Wars franchise", "euro", "all Americans", "longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east )", "the polar climate there is more ice or snow on the ground, and this reflects the solar radiation onto the ground", "the contestant", "1977", "1991", "Action Jackson", "SURFACE AREA OF ROOTS", "7 correct numbers", "1997", "New York City", "Mary Elizabeth Patterson", "1960", "the World Trade Center", "Kevin Kline", "more than a million members ( including 195,000 youth members )", "David Tennant", "Napoleon", "Dido", "the most recent Super Bowl champions", "January 1, 1976", "Dan Stevens", "leg spinner Jimmy Matthews", "1980", "Christmas season", "The Miracles", "Clarence Anglin", "204,408", "experimental psychology", "a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week", "Kit Harington", "Francis Hutcheson", "Spanish", "extends 2,000 kilometres ( 1,200 mi ) down the Australian northeast coast", "Hollywood Masonic Temple ( now known as the El Capitan Entertainment Centre )", "Oblong - ovate or obovate", "1854", "George Harrison", "Pakistan"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8008200233905879}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0606060606060606, 0.0, 0.06451612903225806, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1133", "mrqa_squad-validation-6284", "mrqa_squad-validation-4805", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-6214", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-1111", "mrqa_naturalquestions-validation-2425", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-4640", "mrqa_naturalquestions-validation-7837", "mrqa_naturalquestions-validation-379", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-346"], "SR": 0.734375, "CSR": 0.6417025862068966, "EFR": 1.0, "Overall": 0.7021686422413793}, {"timecode": 58, "before_eval_results": {"predictions": ["German creedal hymn", "two thousand", "three", "Inventions, Researches and Writings of Nikola Tesla", "motivated students", "19th", "The Edge of Night", "Article 102", "low demand", "Von Miller", "2011", "Gallifrey", "secular and sacred covering both Christian (Roman Catholic, Anglican and Greek Orthodox) and Jewish liturgical vessels and items", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "Los Angeles International Airport", "Belgrade in 80 trunks marked N.T.", "autumn", "civil disobedience", "the Uighurs of the Kingdom of Qocho", "2010", "O'Meara", "9.7 m", "typically bilateral contracts ( i.e., agreed to by two parties ) and should have the legal requirements specified by contract law in general and should also be in writing to be enforceable", "caused by chlorine and bromine from manmade organohalogens", "2013", "Raya Yarbrough", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "in the first RFC published on the UDP protocol ( RFC 675 : Internet Transmission Control Program, December 1974 ) as an abbreviation of the term internetworking", "normally show IIII for four o'clock", "6", "Elected Emperor of the Romans", "the fourth single from Tango in the Night on November 28, 1987 in the United States", "Thomas Mundy Peterson", "members of the gay ( LGBT ) community against a police raid that took place in the early morning hours of June 28, 1969, at the Stonewall Inn in the Greenwich Village neighborhood of Manhattan, New York City", "`` I Write Sins Not Tragedies ''", "1998", "Idaho", "Megyn Price", "prophets and beloved religious leaders", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "qui tam", "$1, $2, $5, $10, $20, $50, and $100", "The Royalettes", "October 29, 2015", "Malik, whom Scott paralyzed in a car accident last season, but Malik's dad refuses to let Scott work on the boy", "Michael English", "the majority of the Fourth Republic ( 1981 -- 86 )", "December 25", "204,408 in 2013", "Help!", "Manley", "a composite ( osseo - cartilaginous ) structure that divides the nose into two ( 2 ) similar halves", "James Rodr\u00edguez", "chromosome", "in 1895", "herbaceous plants, flowering plants, shrubs, mosses, and tree matter", "Sondheim himself", "A hairpin turn", "Christopher Columbus", "May 18, 2018", "Elizabeth Stritch", "4.5 pounds or 2.04 kg )", "Kathleen Erin Walsh", "a cleansing ritual"], "metric_results": {"EM": 0.625, "QA-F1": 0.6800962534329469}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.12903225806451613, 0.2222222222222222, 1.0, 0.0, 1.0, 0.06451612903225806, 1.0, 1.0, 0.0, 0.0, 1.0, 0.27777777777777773, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6428571428571429, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.08333333333333334]}}, "before_error_ids": ["mrqa_squad-validation-8811", "mrqa_squad-validation-1556", "mrqa_squad-validation-6641", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8201", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-2623", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-1452", "mrqa_naturalquestions-validation-5942", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-3061", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9979", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-9812"], "SR": 0.625, "CSR": 0.6414194915254237, "EFR": 0.9583333333333334, "Overall": 0.6937786899717514}, {"timecode": 59, "before_eval_results": {"predictions": ["the Quaternary period", "over 18 million", "During the 2006 Israel-Lebanon conflict", "three-fourths", "Daniel arap Moi", "by the 5th century", "the British were able to prevent the arrival of French relief ships in the naval Battle of the Restigouche", "Matthew Murray", "inequality in wealth and income", "October 2007", "the Arizona Cardinals", "President", "excludes certain regions, for example the Faroe Islands, from the jurisdiction of European Union law", "between 3 and 14 hours a week", "Buena Vista Television", "undergraduate students elected to represent members from their respective academic unit", "two astronauts", "ten", "Mike Tolbert", "Deuteronomy 5 : 4 -- 25", "Massachusetts", "in ancient Athens circa 508 B.C.", "Bobby Darin", "6 March 1983", "optic nerve carries the ganglion cell axons to the brain, and the blood vessels that supply the retina", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Hellenic polytheism", "Kyrie Irving", "September 8, 2017", "Sleeping with the Past", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "the entrance of Gilbert Inlet", "Kanawha River", "James Cowser, Southern Utah, 2012 -- 15", "Lulu", "Tom Brady", "supported modern programming practices and enabled business applications to be developed with Flash", "the United States", "Antigonon leptopus", "five", "Dwight David Howard", "Rick Rude", "useless, time - wasting activity", "red", "needle - like", "September 24, 2012", "prejudice", "Lalo Schifrin", "JackScanlon", "the only way for Clark to help the world to the best of his ability would be if she left Clark and Smallville for good, which she does in the season seven finale", "the goal is not met by the deadline, no funds are collected ( a kind of assurance contract )", "James P. Flynn", "Ferm\u00edn Francisco de Lasu\u00e9n", "Stephen Curry", "1983", "Coriolis force", "JackScanlon", "pia mater", "separationism", "$75,000", "1980", "the mid-10th century BCE", "Manhattan", "the Reverse - Flash"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6943676346801346}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.16, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9600000000000001, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0909090909090909, 1.0, 0.0, 0.1212121212121212, 0.07407407407407408, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9348", "mrqa_squad-validation-10269", "mrqa_squad-validation-73", "mrqa_squad-validation-4170", "mrqa_squad-validation-7951", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-4993", "mrqa_naturalquestions-validation-1160", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-4919"], "SR": 0.609375, "CSR": 0.6408854166666667, "EFR": 1.0, "Overall": 0.7020052083333332}, {"timecode": 60, "UKR": 0.6484375, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-10303", "mrqa_naturalquestions-validation-5900", "mrqa_squad-validation-5940", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-9992", "mrqa_squad-validation-7134", "mrqa_squad-validation-2749", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-8952", "mrqa_squad-validation-7275", "mrqa_squad-validation-283", "mrqa_squad-validation-7480", "mrqa_squad-validation-2116", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-1053", "mrqa_squad-validation-5072", "mrqa_squad-validation-7586", "mrqa_squad-validation-6876", "mrqa_naturalquestions-validation-9961", "mrqa_naturalquestions-validation-3841", "mrqa_squad-validation-9045", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-6116", "mrqa_squad-validation-4041", "mrqa_squad-validation-915", "mrqa_squad-validation-5978", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-1888", "mrqa_naturalquestions-validation-3492", "mrqa_squad-validation-9004", "mrqa_squad-validation-6736", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-3056", "mrqa_naturalquestions-validation-4874", "mrqa_squad-validation-6182", "mrqa_squad-validation-708", "mrqa_squad-validation-2448", "mrqa_naturalquestions-validation-8531", "mrqa_naturalquestions-validation-3162", "mrqa_squad-validation-1214", "mrqa_naturalquestions-validation-8849", "mrqa_squad-validation-5637", "mrqa_squad-validation-6329", "mrqa_naturalquestions-validation-9752", "mrqa_squad-validation-3838", "mrqa_naturalquestions-validation-5928", "mrqa_squad-validation-9767", "mrqa_naturalquestions-validation-7268", "mrqa_squad-validation-2", "mrqa_naturalquestions-validation-9457", "mrqa_squad-validation-7938", "mrqa_squad-validation-5270", "mrqa_squad-validation-10228", "mrqa_squad-validation-7285", "mrqa_naturalquestions-validation-8429", "mrqa_squad-validation-1194", "mrqa_naturalquestions-validation-1611", "mrqa_squad-validation-3529", "mrqa_squad-validation-3757", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-10606", "mrqa_naturalquestions-validation-757", "mrqa_squad-validation-6865", "mrqa_squad-validation-8678", "mrqa_squad-validation-5304", "mrqa_squad-validation-3278", "mrqa_squad-validation-1941", "mrqa_squad-validation-1343", "mrqa_squad-validation-3888", "mrqa_naturalquestions-validation-7511", "mrqa_squad-validation-8321", "mrqa_squad-validation-7586", "mrqa_squad-validation-7921", "mrqa_naturalquestions-validation-4185", "mrqa_squad-validation-7137", "mrqa_naturalquestions-validation-3710", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-3119", "mrqa_naturalquestions-validation-6435", "mrqa_squad-validation-537", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-768", "mrqa_squad-validation-1839", "mrqa_squad-validation-4140", "mrqa_squad-validation-9866", "mrqa_naturalquestions-validation-10367", "mrqa_squad-validation-3223", "mrqa_naturalquestions-validation-6486", "mrqa_naturalquestions-validation-6917", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-9675", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-2805", "mrqa_naturalquestions-validation-484", "mrqa_squad-validation-7503", "mrqa_squad-validation-7044", "mrqa_naturalquestions-validation-6698", "mrqa_squad-validation-1535", "mrqa_naturalquestions-validation-1023", "mrqa_squad-validation-924", "mrqa_squad-validation-1911", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-7425", "mrqa_squad-validation-6994", "mrqa_squad-validation-1998", "mrqa_squad-validation-1849", "mrqa_naturalquestions-validation-7024", "mrqa_squad-validation-2741", "mrqa_squad-validation-5330", "mrqa_naturalquestions-validation-10073", "mrqa_squad-validation-8384", "mrqa_squad-validation-4919", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-3842", "mrqa_naturalquestions-validation-7158", "mrqa_squad-validation-9189", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10537", "mrqa_squad-validation-4062", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-289", "mrqa_naturalquestions-validation-7521", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-2248", "mrqa_squad-validation-1670", "mrqa_naturalquestions-validation-8485", "mrqa_squad-validation-8782", "mrqa_naturalquestions-validation-3022", "mrqa_squad-validation-4734", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3548", "mrqa_squad-validation-6432", "mrqa_squad-validation-390", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-1357", "mrqa_squad-validation-6109", "mrqa_squad-validation-4728", "mrqa_naturalquestions-validation-8414", "mrqa_squad-validation-6688", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-9434", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-2721", "mrqa_squad-validation-1040", "mrqa_squad-validation-7421", "mrqa_squad-validation-10313", "mrqa_squad-validation-1427", "mrqa_squad-validation-2673", "mrqa_squad-validation-8056", "mrqa_naturalquestions-validation-8896", "mrqa_naturalquestions-validation-4505", "mrqa_squad-validation-1196", "mrqa_naturalquestions-validation-6326", "mrqa_naturalquestions-validation-6927", "mrqa_squad-validation-9480", "mrqa_squad-validation-9799", "mrqa_naturalquestions-validation-4197", "mrqa_squad-validation-4480", "mrqa_squad-validation-5670", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-10056", "mrqa_naturalquestions-validation-921", "mrqa_squad-validation-6455", "mrqa_squad-validation-5844", "mrqa_squad-validation-3255", "mrqa_squad-validation-9664", "mrqa_squad-validation-5329", "mrqa_squad-validation-6419", "mrqa_squad-validation-1753", "mrqa_squad-validation-3723", "mrqa_squad-validation-5148", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-7124", "mrqa_squad-validation-7989", "mrqa_naturalquestions-validation-8763", "mrqa_squad-validation-2654", "mrqa_naturalquestions-validation-6678", "mrqa_squad-validation-2697", "mrqa_naturalquestions-validation-10092", "mrqa_squad-validation-2716", "mrqa_naturalquestions-validation-9963", "mrqa_naturalquestions-validation-3074", "mrqa_squad-validation-930", "mrqa_naturalquestions-validation-1823", "mrqa_squad-validation-1862", "mrqa_squad-validation-9956", "mrqa_squad-validation-6518", "mrqa_squad-validation-1217", "mrqa_squad-validation-4325", "mrqa_squad-validation-3137", "mrqa_naturalquestions-validation-6087", "mrqa_squad-validation-10362", "mrqa_squad-validation-6708", "mrqa_squad-validation-9868", "mrqa_squad-validation-2309", "mrqa_naturalquestions-validation-3013", "mrqa_squad-validation-557", "mrqa_squad-validation-722", "mrqa_squad-validation-9542", "mrqa_squad-validation-7491", "mrqa_squad-validation-4337", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-2586", "mrqa_squad-validation-6040", "mrqa_naturalquestions-validation-7065", "mrqa_squad-validation-925", "mrqa_naturalquestions-validation-3275", "mrqa_naturalquestions-validation-923", "mrqa_squad-validation-119", "mrqa_squad-validation-7581", "mrqa_naturalquestions-validation-6924", "mrqa_squad-validation-2070", "mrqa_naturalquestions-validation-9249", "mrqa_squad-validation-40", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-3562", "mrqa_squad-validation-1951", "mrqa_naturalquestions-validation-9368", "mrqa_squad-validation-7745", "mrqa_naturalquestions-validation-7065", "mrqa_squad-validation-3999", "mrqa_squad-validation-6899", "mrqa_squad-validation-8948", "mrqa_squad-validation-5854", "mrqa_squad-validation-1790", "mrqa_squad-validation-3601", "mrqa_squad-validation-3046", "mrqa_squad-validation-543", "mrqa_squad-validation-6367", "mrqa_squad-validation-10479", "mrqa_naturalquestions-validation-1515", "mrqa_squad-validation-9875", "mrqa_naturalquestions-validation-4903", "mrqa_squad-validation-6945", "mrqa_naturalquestions-validation-10529", "mrqa_squad-validation-878", "mrqa_squad-validation-4158", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-1884", "mrqa_naturalquestions-validation-3341", "mrqa_squad-validation-2281", "mrqa_squad-validation-118", "mrqa_naturalquestions-validation-1552", "mrqa_squad-validation-6724", "mrqa_squad-validation-3486", "mrqa_squad-validation-8069", "mrqa_squad-validation-9034", "mrqa_squad-validation-3919", "mrqa_squad-validation-3602", "mrqa_naturalquestions-validation-4976", "mrqa_squad-validation-4383", "mrqa_naturalquestions-validation-6564", "mrqa_squad-validation-9892", "mrqa_squad-validation-3354", "mrqa_naturalquestions-validation-7957", "mrqa_squad-validation-913", "mrqa_naturalquestions-validation-3828", "mrqa_squad-validation-2754", "mrqa_squad-validation-6417", "mrqa_squad-validation-7622", "mrqa_squad-validation-3819", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-2476", "mrqa_squad-validation-9226", "mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5485", "mrqa_squad-validation-4146", "mrqa_squad-validation-500", "mrqa_naturalquestions-validation-7632", "mrqa_squad-validation-3691", "mrqa_naturalquestions-validation-4594", "mrqa_squad-validation-625", "mrqa_naturalquestions-validation-2190", "mrqa_squad-validation-6787", "mrqa_naturalquestions-validation-2380", "mrqa_squad-validation-5763", "mrqa_naturalquestions-validation-9564", "mrqa_squad-validation-3611", "mrqa_squad-validation-7370", "mrqa_squad-validation-9076", "mrqa_squad-validation-9982", "mrqa_squad-validation-2370", "mrqa_naturalquestions-validation-6093", "mrqa_squad-validation-8472", "mrqa_squad-validation-6993", "mrqa_squad-validation-4511", "mrqa_squad-validation-9923", "mrqa_naturalquestions-validation-3175", "mrqa_naturalquestions-validation-1787", "mrqa_squad-validation-51", "mrqa_squad-validation-2253", "mrqa_squad-validation-5462", "mrqa_naturalquestions-validation-4074", "mrqa_squad-validation-9430", "mrqa_naturalquestions-validation-1248", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-4263", "mrqa_squad-validation-7765", "mrqa_squad-validation-1522", "mrqa_naturalquestions-validation-1851", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-10319", "mrqa_squad-validation-2901", "mrqa_squad-validation-957", "mrqa_squad-validation-1365", "mrqa_squad-validation-4750", "mrqa_squad-validation-298", "mrqa_squad-validation-919", "mrqa_squad-validation-4182", "mrqa_naturalquestions-validation-1429", "mrqa_naturalquestions-validation-8186", "mrqa_squad-validation-4971", "mrqa_squad-validation-6373", "mrqa_naturalquestions-validation-1537", "mrqa_squad-validation-21", "mrqa_naturalquestions-validation-8215", "mrqa_squad-validation-1054", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-3456", "mrqa_squad-validation-3695", "mrqa_squad-validation-3452", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-10149", "mrqa_naturalquestions-validation-7880", "mrqa_squad-validation-268", "mrqa_naturalquestions-validation-4096", "mrqa_squad-validation-1647", "mrqa_squad-validation-7417", "mrqa_squad-validation-4534", "mrqa_squad-validation-7410", "mrqa_naturalquestions-validation-2440", "mrqa_squad-validation-6526", "mrqa_squad-validation-3474", "mrqa_squad-validation-3607", "mrqa_squad-validation-775", "mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-8099", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-3935", "mrqa_squad-validation-9265", "mrqa_squad-validation-7261", "mrqa_squad-validation-3397", "mrqa_squad-validation-9078", "mrqa_squad-validation-6783", "mrqa_naturalquestions-validation-1089", "mrqa_squad-validation-2576", "mrqa_squad-validation-4065", "mrqa_naturalquestions-validation-10631", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-655", "mrqa_squad-validation-1132", "mrqa_squad-validation-3806", "mrqa_naturalquestions-validation-232", "mrqa_squad-validation-7517", "mrqa_naturalquestions-validation-2623", "mrqa_squad-validation-2560", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10372", "mrqa_squad-validation-1508", "mrqa_squad-validation-6042", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-1988", "mrqa_squad-validation-9738", "mrqa_squad-validation-7802", "mrqa_squad-validation-2609", "mrqa_naturalquestions-validation-1959", "mrqa_squad-validation-10402", "mrqa_squad-validation-5701", "mrqa_squad-validation-7357", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-7531", "mrqa_squad-validation-4921", "mrqa_squad-validation-1388", "mrqa_naturalquestions-validation-2552", "mrqa_squad-validation-8384", "mrqa_squad-validation-3159", "mrqa_squad-validation-4934", "mrqa_squad-validation-8154", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-8502", "mrqa_squad-validation-5804", "mrqa_squad-validation-2857", "mrqa_squad-validation-5589", "mrqa_squad-validation-1463", "mrqa_squad-validation-2760", "mrqa_naturalquestions-validation-8648", "mrqa_squad-validation-7420", "mrqa_squad-validation-4273", "mrqa_naturalquestions-validation-6769", "mrqa_naturalquestions-validation-1398", "mrqa_squad-validation-10296", "mrqa_squad-validation-3948", "mrqa_squad-validation-3420", "mrqa_squad-validation-833", "mrqa_naturalquestions-validation-10310", "mrqa_squad-validation-4108", "mrqa_squad-validation-1329", "mrqa_squad-validation-416", "mrqa_squad-validation-5530", "mrqa_squad-validation-9711", "mrqa_squad-validation-317", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-5861", "mrqa_squad-validation-6298", "mrqa_naturalquestions-validation-3404", "mrqa_squad-validation-4639", "mrqa_squad-validation-10054", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-4720", "mrqa_squad-validation-7145", "mrqa_squad-validation-3289", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-340", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-7223", "mrqa_squad-validation-771", "mrqa_squad-validation-6329", "mrqa_squad-validation-2611", "mrqa_squad-validation-10098", "mrqa_squad-validation-4778", "mrqa_naturalquestions-validation-8420", "mrqa_squad-validation-841", "mrqa_naturalquestions-validation-10684", "mrqa_squad-validation-6403", "mrqa_naturalquestions-validation-3922", "mrqa_squad-validation-1886", "mrqa_squad-validation-5573", "mrqa_naturalquestions-validation-6278", "mrqa_squad-validation-5315", "mrqa_squad-validation-2099", "mrqa_squad-validation-5759", "mrqa_squad-validation-8552", "mrqa_naturalquestions-validation-3940", "mrqa_naturalquestions-validation-7681", "mrqa_squad-validation-4543", "mrqa_naturalquestions-validation-4645", "mrqa_squad-validation-2833", "mrqa_naturalquestions-validation-8450", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-3735", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-1515", "mrqa_naturalquestions-validation-5751", "mrqa_squad-validation-5350", "mrqa_naturalquestions-validation-707", "mrqa_squad-validation-2095", "mrqa_naturalquestions-validation-10037", "mrqa_squad-validation-1935", "mrqa_squad-validation-4775", "mrqa_naturalquestions-validation-6650", "mrqa_naturalquestions-validation-4863", "mrqa_squad-validation-3500", "mrqa_naturalquestions-validation-3482", "mrqa_squad-validation-9651", "mrqa_squad-validation-6219", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-9007", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-5196", "mrqa_naturalquestions-validation-7594", "mrqa_squad-validation-3406", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-3521", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-654", "mrqa_squad-validation-2111", "mrqa_naturalquestions-validation-10617", "mrqa_squad-validation-7149", "mrqa_squad-validation-7469", "mrqa_squad-validation-2781", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-9835", "mrqa_squad-validation-195", "mrqa_squad-validation-3455", "mrqa_naturalquestions-validation-4628", "mrqa_naturalquestions-validation-1134", "mrqa_squad-validation-10448", "mrqa_naturalquestions-validation-8043", "mrqa_squad-validation-3091", "mrqa_squad-validation-7832", "mrqa_squad-validation-516", "mrqa_naturalquestions-validation-2406", "mrqa_squad-validation-7877", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-2214", "mrqa_squad-validation-3345", "mrqa_squad-validation-3717", "mrqa_squad-validation-3351", "mrqa_naturalquestions-validation-8962", "mrqa_squad-validation-1784"], "OKR": 0.787109375, "KG": 0.2828125, "before_eval_results": {"predictions": ["Music of the Spheres", "special episode of The Late Show with Stephen Colbert", "90\u00b0 out of phase with each other", "6.7", "February 9, 1832", "Daniel arap Moi", "a statement to the chamber setting out the Government's legislative programme for the forthcoming year", "Marlee Matlin", "2005", "The Premier of Victoria", "international students", "2013", "competition between workers", "cloud storage", "Two", "blooms in the Red Sea", "the most reliable", "Thank Goodness It's funny", "the weakness in school discipline", "a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush", "first released in the United States on September 25, 1987", "Gregor Mendel", "the late 1960s", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "the Anglo - Norman French waleis, which is in turn derived from a cognate of the Old English wylisc ( pronounced `` wullish '' ) meaning `` foreigner '' or `` Welshman '' ( etymology", "Tyrann Devine Mathieu", "Kryptonite", "volcanic activity", "the International Campaign to Abolish Nuclear Weapons ( ICAN ) `` for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground - breaking efforts to achieve a treaty - based prohibition on", "Bryan Cranston", "Annette", "April 13, 2018", "55 -- 69 %", "a type of organization that pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )", "The Third Five - year Plan", "Mary Chapin Carpenter", "two parallel planes", "non-voters", "Gospel of Matthew in the middle of the Sermon on the Mount, and the short form in the Gospel of Luke when `` one of his disciples said to him,'Lord, teach us to pray, as John taught his disciples", "Antigonon leptopus", "citizens of other Commonwealth countries who were resident in Scotland", "Phillip Paley", "a section of the Torah ( Five Books of Moses ) used in Jewish liturgy during a single week", "2014", "Haliaeetus ( sea eagles )", "Kevin McKidd", "usually in May", "Uralic", "$66.5 million in 2014", "a valuable way to feed the poor, and would relieve some pressure of the land redistribution process", "The Mongol - led Yuan dynasty ( 1271 -- 1368 )", "about 2,621 kilometres ( 1,629 mi ) from its headwaters in the Brazilian state of Mato Grosso to its confluence with the Paran\u00e1 River north of Corrientes and Resistencia", "the 90s", "Paul", "Amycus Carrow", "Ernest Hemingway", "mitosis", "Apollo 11", "the sinoatrial node", "September 2001", "Mark Jackson", "The stratum lucidum ( Latin for `` clear layer '' )", "Stanford Cardinal"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7642929837164751}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 0.42857142857142855, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.27586206896551724, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.3333333333333333, 1.0, 0.9047619047619047, 1.0, 1.0, 1.0, 0.5, 0.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.888888888888889, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-3257", "mrqa_squad-validation-8621", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-4867", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-7202", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-961", "mrqa_naturalquestions-validation-8151", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-1567", "mrqa_naturalquestions-validation-2399", "mrqa_naturalquestions-validation-5753", "mrqa_naturalquestions-validation-6321", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-476", "mrqa_naturalquestions-validation-4643", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3670"], "SR": 0.640625, "CSR": 0.6408811475409837, "EFR": 1.0, "Overall": 0.6718481045081968}, {"timecode": 61, "before_eval_results": {"predictions": ["Turkana", "dendritic cells, keratinocytes and macrophages", "Eugene Fama", "26 years", "Tucker", "Cologne, Germany", "Lorelei", "a group of common flagellated protists that contain chloroplasts derived from a green alga", "Terry Nation", "Edison Medal", "Apollo 17", "the Ten Commandments", "reckless", "We Love TV", "Fort Beaus\u00e9jour on the border separating Nova Scotia from Acadia", "\"essentials\"", "Levi's Stadium", "50 fund", "Conservatives", "The sperm plasma", "Neil Armstrong", "Rugrats in Paris", "the biblical Book of Exodus", "- landed in the Indian Ocean near Grande Comore, Comoros Islands, due to fuel exhaustion", "During the last Ice Age", "White Christmas", "to exercise general oversight, telling him to `` rebuke with all authority '' ( Titus 2 : 15 )", "the southwest and along the Yangtze", "the television series's fourth season", "October 12, 1979", "a landowner allows a tenant to use the land in return for a share of the crops produced on their portion of land", "Galveston hurricane", "almost entirely in Wake County, it lies just north of the state capital, Raleigh", "a statistical advantage for the casino that is built into the game", "Thomas Jefferson", "the span of historic events from approximately 1945 that are immediately relevant to the present time", "Mitsubishi Eclipse", "the much - decorated Adam Schumann ( Miles Teller ) returns home to Kansas and a loving wife, Saskia ( Haley Bennett ) after discovering she has taken all his money and their child and left him", "Kansas", "September 9, 2010", "Mainland Greece", "referee blows the whistle", "April 2 at the Alamodome in San Antonio, Texas", "Peter Andrew Beardsley MBE", "spacewar", "chain elongation", "through 13 states : New York, New Jersey, Pennsylvania, Ohio, Indiana, Illinois, Iowa, Nebraska, Colorado, Wyoming, Utah, Nevada, and California", "In 1910", "Renishaw Hall, Derbyshire, England, UK", "the mid - to late 1920s", "famous figures as Judy Garland, Carole Landis, Dean Martin, and Ethel Merman", "arm", "Santiago Ram\u00f3n y Cajal", "above the light source and under the sample in an upright microscope, and above the stage and below the light sources in an inverted microscope", "Aegisthus", "a primary source of food for many organisms on estuaries, including bacteria, is detritus from the settlement of the sedimentation", "travelled quite far, we built sets, and they spend a lot of time in a forest,", "inverted", "hydrogen", "Gibraltar", "May 1979", "ummah", "The original building was completed in 1800", "Radon gas from radioactive decay within the Earth's crust"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6286805619748108}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 0.36363636363636365, 0.5, 0.6, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.10526315789473682, 0.8, 0.06451612903225806, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.16, 0.0, 1.0, 0.888888888888889, 0.2857142857142857, 1.0, 0.0, 0.9473684210526315, 1.0, 0.1111111111111111, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.5714285714285715]}}, "before_error_ids": ["mrqa_squad-validation-2440", "mrqa_squad-validation-8654", "mrqa_squad-validation-10218", "mrqa_squad-validation-170", "mrqa_naturalquestions-validation-2350", "mrqa_naturalquestions-validation-9626", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-4785", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8404", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-73", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-9564", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-6378", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-707", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-6968", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4132", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-6677"], "SR": 0.46875, "CSR": 0.6381048387096775, "EFR": 0.9117647058823529, "Overall": 0.653645783918406}, {"timecode": 62, "before_eval_results": {"predictions": ["Al-Biruni", "a two-phased system", "2015", "a lesson plan", "seal of approval", "his mother's genetics and influence", "the Dutch Republic", "Marlee Matlin", "the malaria parasite", "Khanbaliq", "Teenage Mutant Ninja Turtles: Out of the Shadows", "swimming-plates", "the courts of member states", "human rights violations", "NP-intermediate", "armed jihad", "Charles Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers, Sir Henry Cheere", "Central Asian Muslims", "a polymer consisting of sugars and amino acids that forms a mesh - like layer outside the plasma membrane of most bacteria", "loop", "Glenn Close", "1,228 km / h ( 763 mph )", "Kansas", "CeCe Drake", "ideology", "`` Real Girl ''", "Nala", "The person who has existence in two parallel worlds", "Alana Rivera", "Bulgaria", "January 1, 2016", "Nucleotides", "Kristina Wagner", "September 2014", "Jules Shear", "John C. Reilly", "Jennifer Aniston", "Intertropical Convergence Zone ( ITCZ )", "halogenated paraffin hydrocarbons that contain only carbon, chlorine, and fluorine, produced as volatile derivative of methane, ethane, and propane", "Aristotle's inductive - deductive method", "the Gaget, Gauthier & Co. workshop", "Robert Irsay", "in 1982", "September 4, 2000", "Buddhism", "Seattle, Washington", "1994", "between Eastern Canada and British Columbia between 1881 and 1885", "President from among the sitting Governors", "Rodney Crowell", "Baaghi ( English : Rebel )", "Greek", "re-education", "Virginia", "April 8, 2016", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "to seize power in Munich, Bavaria, during 8 -- 9 November 1923", "+, -, *, and / keys", "Kirstjen Nielsen", "BeBe Winans", "Cyndi Grecco", "Carole Landis", "about 3.5 mya", "James Watson and Francis Crick at the Cavendish Laboratory within the University of Cambridge in 1953"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7233822235878157}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.5714285714285715, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5263157894736842]}}, "before_error_ids": ["mrqa_squad-validation-6464", "mrqa_squad-validation-1257", "mrqa_squad-validation-8242", "mrqa_squad-validation-4730", "mrqa_squad-validation-5587", "mrqa_naturalquestions-validation-1269", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-6486", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-1632", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3782", "mrqa_naturalquestions-validation-7033", "mrqa_naturalquestions-validation-3391", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-7893", "mrqa_naturalquestions-validation-199", "mrqa_naturalquestions-validation-7228", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-10159"], "SR": 0.65625, "CSR": 0.6383928571428572, "EFR": 0.9090909090909091, "Overall": 0.6531686282467533}, {"timecode": 63, "before_eval_results": {"predictions": ["iTunes", "Pacific Ocean islands, shorelines, beaches, and coastal plains", "Marco Polo", "azote", "nine months", "Miller", "ABC Television Center, East", "1596", "Get Carter", "CyP27B1", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "Port of Los Angeles", "double", "eight", "crust and rigid uppermost portion of the upper mantle", "Schr\u00f6dinger equation", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic, the Electorate of Brandenburg and Electorate in the Palatinate", "2010", "Squamish, British Columbia, Canada", "`` Thomas Brady, five as starting quarterback with New England Patriots", "In Return of the Jedi ( 1983 )", "Tokyo for the 2020 Summer Olympics", "The flag of Hungary", "primarily concentrated in the Southern United States, and has been sold as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "Stephen Curry", "Miami Heat of the National Basketball Association ( NBA )", "at each place there are a bread roll ( generally on a bread plate, sometimes in the napkin ), napkin, and flatware", "Sakshi Malik", "the medulla oblongata", "Kim Basinger", "From a vantage point above the north pole", "Oklahoma", "Thomas Osgood", "in 1960", "Jyotirindra Basu", "chyle", "Puente Hills Mall", "Mike Czerwien", "the Italian / Venetian John Cabot", "June 25, 1938", "Magnavox Odyssey", "Spanish colonization of the European settlements in Texas", "DeWayne Warren", "a Raja Dhilu", "Ra\u00fal Eduardo Esparza", "Mind your language", "Dr. Hartwell Carver", "AD 95 -- 110", "54 Mbit / s, plus error correction code", "David Joseph Madden", "Garbi\u00f1e Muguruza", "if they are loaded with fresh nuclear fuel, whose neutron flux from spontaneous fission is insufficient for a reliable startup, or after prolonged shutdown periods", "more than 1,000", "9.7 m", "Andy Serkis", "Andrew Garfield", "cut off close by the hip, and under the left shoulder", "Ali Daei", "The Sun", "February 2017", "Nala", "Germany", "2014, 2017"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6588588537807287}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5454545454545455, 1.0, 1.0, 0.16666666666666669, 1.0, 0.33333333333333337, 0.5, 0.37837837837837834, 0.0, 0.4444444444444445, 0.3, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.42857142857142855, 0.5, 0.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 0.6, 1.0, 1.0, 0.14814814814814814, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2790", "mrqa_squad-validation-4662", "mrqa_squad-validation-1459", "mrqa_squad-validation-10386", "mrqa_squad-validation-3019", "mrqa_naturalquestions-validation-3083", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-6020", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-601", "mrqa_naturalquestions-validation-4454", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-4018", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-368", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-6603", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-2949"], "SR": 0.5625, "CSR": 0.63720703125, "EFR": 0.8571428571428571, "Overall": 0.6425418526785714}, {"timecode": 64, "before_eval_results": {"predictions": ["Susan Foreman", "Classic FM's Hall of Fame", "article 30", "communications from another planet", "technical problems and flight delays", "Tiffany & Co.", "Golden Gate Bridge", "architect or engineer", "David Suzuki", "7000 years", "one", "Court of Justice", "ambiguity", "Seine", "generally westward", "Daniel arap Moi", "Economy, Energy and Tourism", "KMBC-TV and KQTV", "New York University", "Sam Waterston", "subduction zone", "energy moves from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "Ethel `` Edy '' Proctor", "9pm ET ( UTC - 5 )", "paid monument", "Fossil fuels such as coal and petroleum", "HTML", "twice", "Joseph Stalin", "orbit", "Beijing", "Gustav Bauer", "2,579", "Kyla Coleman", "24 November 1949", "71 -- 74 \u00b0 C", "Animal fibers", "his brother, who died in action in the United States Army", "Somatic", "Dan Stevens", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "Triple Alliance of Germany, Austria - Hungary, and Italy", "the President of India", "the most recent Super Bowl champions", "Montenegro, Serbia and Slovenia", "Article Two", "1830", "Rashida Jones", "Glen W. Dickson", "Delegates", "Amitabh Bachchan, Akshay Kumar, Bobby Deol, Divya Khosla Kumar, Sandali Sinha and Nagma", "Bill Russell", "19 April 1775", "Roman Reigns", "Phillip Paley", "Abid Ali Neemuchwala", "Pittsburgh, where the Big Three are born and raised", "Antigonon leptopus", "October 27, 2017", "16th century", "shield the producers, businesses, and workers of the import - competing sector in the country from foreign competitors", "Dylan Walters", "in the blood to the liver", "Coton in the Elms"], "metric_results": {"EM": 0.625, "QA-F1": 0.727583408816425}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.5, 1.0, 0.4347826086956522, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.375, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1529", "mrqa_squad-validation-3945", "mrqa_squad-validation-9261", "mrqa_squad-validation-9488", "mrqa_naturalquestions-validation-5396", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-8427", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-134", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5782", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-1979", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-3970", "mrqa_naturalquestions-validation-5355", "mrqa_naturalquestions-validation-1179"], "SR": 0.625, "CSR": 0.6370192307692308, "EFR": 1.0, "Overall": 0.6710757211538462}, {"timecode": 65, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-9387", "mrqa_squad-validation-1912", "mrqa_naturalquestions-validation-8625", "mrqa_squad-validation-4251", "mrqa_squad-validation-9493", "mrqa_squad-validation-4467", "mrqa_squad-validation-2580", "mrqa_squad-validation-8297", "mrqa_squad-validation-3839", "mrqa_squad-validation-2508", "mrqa_squad-validation-6182", "mrqa_squad-validation-1170", "mrqa_squad-validation-6345", "mrqa_squad-validation-8204", "mrqa_squad-validation-3046", "mrqa_squad-validation-8194", "mrqa_naturalquestions-validation-2857", "mrqa_squad-validation-9977", "mrqa_squad-validation-6810", "mrqa_squad-validation-606", "mrqa_naturalquestions-validation-6560", "mrqa_naturalquestions-validation-5787", "mrqa_squad-validation-3151", "mrqa_naturalquestions-validation-6452", "mrqa_squad-validation-7285", "mrqa_squad-validation-5028", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-10453", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-2119", "mrqa_squad-validation-5464", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-9626", "mrqa_naturalquestions-validation-10470", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-6009", "mrqa_naturalquestions-validation-7480", "mrqa_squad-validation-467", "mrqa_naturalquestions-validation-232", "mrqa_squad-validation-6367", "mrqa_naturalquestions-validation-458", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-7760", "mrqa_squad-validation-8230", "mrqa_squad-validation-2385", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-1959", "mrqa_squad-validation-5578", "mrqa_squad-validation-715", "mrqa_squad-validation-2514", "mrqa_squad-validation-3550", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-9928", "mrqa_squad-validation-6999", "mrqa_squad-validation-7767", "mrqa_squad-validation-6685", "mrqa_naturalquestions-validation-3413", "mrqa_squad-validation-5169", "mrqa_squad-validation-5491", "mrqa_squad-validation-1282", "mrqa_naturalquestions-validation-5596", "mrqa_naturalquestions-validation-9332", "mrqa_squad-validation-6156", "mrqa_squad-validation-462", "mrqa_squad-validation-3422", "mrqa_squad-validation-8297", "mrqa_naturalquestions-validation-662", "mrqa_squad-validation-1815", "mrqa_squad-validation-8654", "mrqa_squad-validation-7738", "mrqa_squad-validation-5304", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-6337", "mrqa_squad-validation-5701", "mrqa_naturalquestions-validation-1445", "mrqa_squad-validation-8234", "mrqa_squad-validation-2409", "mrqa_naturalquestions-validation-2084", "mrqa_naturalquestions-validation-6720", "mrqa_squad-validation-1490", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-5476", "mrqa_squad-validation-1881", "mrqa_naturalquestions-validation-5236", "mrqa_naturalquestions-validation-10271", "mrqa_squad-validation-9134", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-6276", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-4701", "mrqa_squad-validation-1570", "mrqa_squad-validation-5364", "mrqa_naturalquestions-validation-9249", "mrqa_naturalquestions-validation-3395", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-2544", "mrqa_squad-validation-5861", "mrqa_naturalquestions-validation-3376", "mrqa_naturalquestions-validation-9306", "mrqa_squad-validation-1136", "mrqa_squad-validation-5666", "mrqa_squad-validation-2976", "mrqa_squad-validation-6360", "mrqa_naturalquestions-validation-5799", "mrqa_squad-validation-4076", "mrqa_squad-validation-337", "mrqa_squad-validation-8775", "mrqa_squad-validation-4184", "mrqa_naturalquestions-validation-7538", "mrqa_squad-validation-4599", "mrqa_naturalquestions-validation-4018", "mrqa_squad-validation-5140", "mrqa_naturalquestions-validation-1429", "mrqa_squad-validation-4085", "mrqa_naturalquestions-validation-8229", "mrqa_squad-validation-3925", "mrqa_squad-validation-2212", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-475", "mrqa_squad-validation-3519", "mrqa_squad-validation-9453", "mrqa_squad-validation-21", "mrqa_squad-validation-10388", "mrqa_naturalquestions-validation-10582", "mrqa_squad-validation-8661", "mrqa_squad-validation-8756", "mrqa_squad-validation-9628", "mrqa_squad-validation-9528", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-9446", "mrqa_squad-validation-5951", "mrqa_naturalquestions-validation-10248", "mrqa_squad-validation-9928", "mrqa_squad-validation-2011", "mrqa_naturalquestions-validation-8179", "mrqa_squad-validation-1401", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-6304", "mrqa_naturalquestions-validation-9760", "mrqa_naturalquestions-validation-7715", "mrqa_squad-validation-4573", "mrqa_squad-validation-4238", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-9959", "mrqa_squad-validation-873", "mrqa_squad-validation-1670", "mrqa_naturalquestions-validation-993", "mrqa_squad-validation-9488", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-7741", "mrqa_squad-validation-6787", "mrqa_squad-validation-967", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-1290", "mrqa_squad-validation-8180", "mrqa_naturalquestions-validation-1269", "mrqa_naturalquestions-validation-2842", "mrqa_squad-validation-1259", "mrqa_squad-validation-2909", "mrqa_naturalquestions-validation-1818", "mrqa_squad-validation-9094", "mrqa_naturalquestions-validation-1144", "mrqa_squad-validation-10438", "mrqa_naturalquestions-validation-3734", "mrqa_squad-validation-8645", "mrqa_squad-validation-7469", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6164", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-499", "mrqa_squad-validation-7397", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-5804", "mrqa_squad-validation-3811", "mrqa_naturalquestions-validation-9728", "mrqa_squad-validation-7567", "mrqa_naturalquestions-validation-8216", "mrqa_squad-validation-2835", "mrqa_naturalquestions-validation-5943", "mrqa_squad-validation-1509", "mrqa_squad-validation-5599", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-7296", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-833", "mrqa_squad-validation-6964", "mrqa_squad-validation-6241", "mrqa_naturalquestions-validation-10098", "mrqa_squad-validation-10386", "mrqa_squad-validation-5869", "mrqa_squad-validation-479", "mrqa_squad-validation-1113", "mrqa_squad-validation-10350", "mrqa_squad-validation-5386", "mrqa_squad-validation-3994", "mrqa_squad-validation-6526", "mrqa_squad-validation-9254", "mrqa_naturalquestions-validation-878", "mrqa_naturalquestions-validation-1617", "mrqa_squad-validation-2956", "mrqa_naturalquestions-validation-8577", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-5215", "mrqa_squad-validation-5658", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-1694", "mrqa_squad-validation-8266", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-4367", "mrqa_squad-validation-6817", "mrqa_naturalquestions-validation-1500", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-1246", "mrqa_naturalquestions-validation-8958", "mrqa_squad-validation-562", "mrqa_squad-validation-3529", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-6193", "mrqa_squad-validation-1164", "mrqa_squad-validation-8713", "mrqa_squad-validation-5757", "mrqa_naturalquestions-validation-5371", "mrqa_squad-validation-9718", "mrqa_squad-validation-7103", "mrqa_squad-validation-2851", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-2064", "mrqa_squad-validation-1123", "mrqa_squad-validation-6899", "mrqa_squad-validation-4029", "mrqa_naturalquestions-validation-9683", "mrqa_squad-validation-2382", "mrqa_naturalquestions-validation-4645", "mrqa_squad-validation-4945", "mrqa_squad-validation-9945", "mrqa_naturalquestions-validation-7162", "mrqa_squad-validation-2097", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-6252", "mrqa_squad-validation-3581", "mrqa_squad-validation-8776", "mrqa_naturalquestions-validation-6182", "mrqa_squad-validation-3474", "mrqa_naturalquestions-validation-1015", "mrqa_naturalquestions-validation-923", "mrqa_squad-validation-1934", "mrqa_squad-validation-1119", "mrqa_naturalquestions-validation-3593", "mrqa_squad-validation-6688", "mrqa_squad-validation-6567", "mrqa_squad-validation-629", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-9640", "mrqa_squad-validation-7793", "mrqa_squad-validation-4230", "mrqa_squad-validation-468", "mrqa_naturalquestions-validation-9553", "mrqa_squad-validation-3926", "mrqa_squad-validation-5541", "mrqa_squad-validation-6545", "mrqa_naturalquestions-validation-3710", "mrqa_naturalquestions-validation-6698", "mrqa_squad-validation-1815", "mrqa_squad-validation-543", "mrqa_squad-validation-7874", "mrqa_naturalquestions-validation-1653", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-5539", "mrqa_squad-validation-6358", "mrqa_squad-validation-299", "mrqa_squad-validation-972", "mrqa_squad-validation-1706", "mrqa_squad-validation-939", "mrqa_squad-validation-2716", "mrqa_naturalquestions-validation-3143", "mrqa_squad-validation-7390", "mrqa_squad-validation-2511", "mrqa_squad-validation-6463", "mrqa_squad-validation-6250", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-9772", "mrqa_squad-validation-5940", "mrqa_squad-validation-6150", "mrqa_naturalquestions-validation-2650", "mrqa_squad-validation-1017", "mrqa_naturalquestions-validation-4554", "mrqa_squad-validation-4402", "mrqa_squad-validation-1849", "mrqa_naturalquestions-validation-5152", "mrqa_naturalquestions-validation-6321", "mrqa_squad-validation-8216", "mrqa_naturalquestions-validation-10031", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-4177", "mrqa_squad-validation-8381", "mrqa_squad-validation-21", "mrqa_squad-validation-9263", "mrqa_squad-validation-8169", "mrqa_naturalquestions-validation-5516", "mrqa_squad-validation-1670", "mrqa_squad-validation-8068", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-5925", "mrqa_squad-validation-10293", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-6943", "mrqa_squad-validation-7261", "mrqa_naturalquestions-validation-3431", "mrqa_naturalquestions-validation-1491", "mrqa_naturalquestions-validation-8763", "mrqa_squad-validation-295", "mrqa_naturalquestions-validation-4239", "mrqa_squad-validation-681", "mrqa_squad-validation-9542", "mrqa_naturalquestions-validation-6888", "mrqa_naturalquestions-validation-10497", "mrqa_naturalquestions-validation-5512", "mrqa_naturalquestions-validation-4249", "mrqa_naturalquestions-validation-1198", "mrqa_squad-validation-5661", "mrqa_naturalquestions-validation-5583", "mrqa_squad-validation-3223", "mrqa_naturalquestions-validation-4776", "mrqa_squad-validation-34", "mrqa_naturalquestions-validation-7114", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-8896", "mrqa_squad-validation-1824", "mrqa_squad-validation-2781", "mrqa_naturalquestions-validation-6169", "mrqa_squad-validation-5861", "mrqa_naturalquestions-validation-10213", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-928", "mrqa_squad-validation-3846", "mrqa_squad-validation-7492", "mrqa_squad-validation-268", "mrqa_squad-validation-9329", "mrqa_squad-validation-5341", "mrqa_squad-validation-6690", "mrqa_naturalquestions-validation-578", "mrqa_squad-validation-7230", "mrqa_squad-validation-8154", "mrqa_naturalquestions-validation-7862", "mrqa_squad-validation-6717", "mrqa_naturalquestions-validation-1222", "mrqa_squad-validation-7468", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-6867", "mrqa_squad-validation-5289", "mrqa_squad-validation-5541", "mrqa_squad-validation-710", "mrqa_naturalquestions-validation-5713", "mrqa_naturalquestions-validation-4505", "mrqa_squad-validation-9764", "mrqa_naturalquestions-validation-10554", "mrqa_squad-validation-5250", "mrqa_naturalquestions-validation-40", "mrqa_squad-validation-655", "mrqa_naturalquestions-validation-9440", "mrqa_squad-validation-1764", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-3736", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3965", "mrqa_naturalquestions-validation-1179", "mrqa_squad-validation-4355", "mrqa_squad-validation-8012", "mrqa_squad-validation-8034", "mrqa_squad-validation-5347", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-9430", "mrqa_squad-validation-4402", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-2561", "mrqa_squad-validation-6456", "mrqa_squad-validation-9913", "mrqa_squad-validation-7201", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-644", "mrqa_squad-validation-1637", "mrqa_squad-validation-7303", "mrqa_squad-validation-775", "mrqa_squad-validation-5576", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-8238", "mrqa_squad-validation-6116", "mrqa_naturalquestions-validation-6560", "mrqa_naturalquestions-validation-5118", "mrqa_squad-validation-5609", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-1515", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-8612", "mrqa_squad-validation-1603", "mrqa_naturalquestions-validation-9835", "mrqa_squad-validation-8072", "mrqa_naturalquestions-validation-6040", "mrqa_naturalquestions-validation-386", "mrqa_naturalquestions-validation-368", "mrqa_squad-validation-2288", "mrqa_squad-validation-8964", "mrqa_naturalquestions-validation-3275", "mrqa_squad-validation-895", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-6465", "mrqa_squad-validation-4515", "mrqa_naturalquestions-validation-3802", "mrqa_squad-validation-7324", "mrqa_squad-validation-3092", "mrqa_naturalquestions-validation-7837", "mrqa_naturalquestions-validation-8429", "mrqa_naturalquestions-validation-9753", "mrqa_squad-validation-3696", "mrqa_squad-validation-3262", "mrqa_squad-validation-8019", "mrqa_squad-validation-6711", "mrqa_naturalquestions-validation-6307", "mrqa_naturalquestions-validation-8947", "mrqa_naturalquestions-validation-2684", "mrqa_squad-validation-193", "mrqa_naturalquestions-validation-6984", "mrqa_squad-validation-7232", "mrqa_squad-validation-820", "mrqa_squad-validation-3575", "mrqa_squad-validation-7328", "mrqa_naturalquestions-validation-3545", "mrqa_squad-validation-8948", "mrqa_squad-validation-4023", "mrqa_squad-validation-5932", "mrqa_squad-validation-3236", "mrqa_naturalquestions-validation-7521", "mrqa_naturalquestions-validation-7268", "mrqa_squad-validation-9631", "mrqa_squad-validation-8906", "mrqa_naturalquestions-validation-4628", "mrqa_squad-validation-455", "mrqa_squad-validation-613", "mrqa_squad-validation-10448", "mrqa_squad-validation-5422", "mrqa_squad-validation-1559", "mrqa_naturalquestions-validation-10268", "mrqa_squad-validation-101", "mrqa_naturalquestions-validation-9434", "mrqa_squad-validation-835", "mrqa_naturalquestions-validation-1026", "mrqa_squad-validation-9689", "mrqa_squad-validation-5437", "mrqa_squad-validation-3413", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-3962", "mrqa_squad-validation-7571", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-86", "mrqa_squad-validation-6419", "mrqa_squad-validation-6610", "mrqa_naturalquestions-validation-527", "mrqa_squad-validation-686", "mrqa_squad-validation-3570", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-346", "mrqa_naturalquestions-validation-5135", "mrqa_squad-validation-7125", "mrqa_naturalquestions-validation-10617", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-8439", "mrqa_squad-validation-6994", "mrqa_squad-validation-3698", "mrqa_naturalquestions-validation-9089", "mrqa_naturalquestions-validation-6759", "mrqa_squad-validation-2576", "mrqa_squad-validation-8899", "mrqa_naturalquestions-validation-6298", "mrqa_squad-validation-484", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-118", "mrqa_squad-validation-3091", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-3784"], "OKR": 0.85546875, "before_eval_results": {"predictions": ["War of Currents", "Torque", "1330 Avenue of the Americas", "conscription", "Scotland Act 1998", "dephlogisticated air", "Oirads", "Sun Life Stadium", "cleats", "Boomer Esiason and Dan Fouts", "Department of State Affairs", "Duisburg", "a military coup d'\u00e9tat", "congresses and presidents", "New England Patriots", "Islam", "1979", "`` central '' or `` middle ''", "April 21, 2017", "Richardson", "Parthenogenesis", "Crepuscular", "unknown origin", "Kid Creole and the Coconuts", "Max", "60", "Tsetse", "perhaps most common in Australia", "the naos", "1983", "up to 100,000", "Doug Diemoz", "International Border ( IB )", "February 7, 2018", "four", "1998", "`` Killer Within ''", "Madhya Pradesh", "Baker, California", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Upon closure at birth", "A Turtle's Tale : Sammy's Adventures", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "Marie Van Brittan Brown", "the New Testament", "the American rock band Eagles", "1980", "Georgia Bulldogs football team", "Walt Disney's 1967 film The Jungle Book", "1933", "the Beatles song of that name", "UTC \u2212 09 : 00", "Louis Mountbatten", "J - Novel Club", "Real Madrid", "optic chiasma", "Shiji no yukikai", "Ajay Tyagi", "re-education", "c. 1000 AD", "pia mater", "July 14, 2017", "Julie Adams", "the Norman Conquest of England"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7504164055973267}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2631578947368421, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.4, 1.0, 1.0, 0.8, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10360", "mrqa_squad-validation-5972", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-2578", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-1169", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-9799", "mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-5790", "mrqa_naturalquestions-validation-5799", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-205", "mrqa_naturalquestions-validation-743", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-6660"], "SR": 0.65625, "CSR": 0.6373106060606061, "EFR": 0.8636363636363636, "Overall": 0.6809706439393939}, {"timecode": 66, "before_eval_results": {"predictions": ["Albert Einstein", "Porifera (sponges)", "British rock group Coldplay", "three times", "two", "ctenophores and cnidarians", "since 2001", "biostratigraphers", "probabilistic (or \"Monte Carlo\")", "growth and investment", "1754\u20131763", "Chinggis Khaan International Airport", "is dominated and heavily dependent upon abundance of petroleum, as opposed to other regions where automobiles not nearly as dominant, the vast majority of transport runs on this fuel", "Galileo", "Danube", "chemical bonds with almost all other elements to give corresponding oxides", "Charles-Fer Ferdinand University", "U.S. service members who have died without their remains being identified", "Parker's pregnancy", "Malvolio", "James Corden", "1807", "Psychomachia, '' an epic poem written in the fifth century", "Gustav Bauer", "to control gene expression and mediate the replication of DNA during the cell cycle", "State Bar of Arizona", "New York and New Jersey campaigns ( 1776 -- 77 )", "2,050 metres ( 6,730 ft ) at the Urubamba River below the citadel of Macchu Piccu", "Peru, where he had undergone a spiritual retreat designed to advance him further up Meyerism's spiritual ladder", "the Rolling Stones", "2005", "Alexander Salkind's Superman : The Movie ( 1978 )", "232", "duodenum by enterocytes of the duodenal lining", "1901", "19 July 1990", "Anthony Hopkins", "Missouri sharecroppers", "December 2, 1942", "James Arthur", "Freddie Highmore", "telecommunications, pharmaceuticals, aircraft, heavy machinery and other industries", "privatized", "1979", "San Crist\u00f3bal, Pinar del R\u00edo Province ( now in Artemisa Province ), in western Cuba", "1920", "Philippe Petit", "twice", "Schwarzenegger", "Sir Edward Henry", "Eukarya", "Vijaya Mulay", "Typically, no", "Zoe McLellan as Meredith Brody, NCIS Special Agent ( seasons 1 -- 2 )", "17 in October 2004", "Jason Lee as Buddy Pine / Incredi - Boy / Syndrome, a former superhero fanatic who has no super powers of his own but uses advanced technology to give himself equivalent abilities", "six members of France's Legislative Assembly", "the Tin Woodman", "Monk's", "Anglican services in Jamestown 1607, which became the established church in 1619, and culminates with the Virginia Statute for Religious Freedom in 1786", "the division of labour, productivity, and free markets", "Manley", "Gettysburg College,", "political ideology"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6977022977022977}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.1818181818181818, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.8571428571428571, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.0, 0.0909090909090909, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4454", "mrqa_squad-validation-114", "mrqa_squad-validation-2825", "mrqa_squad-validation-3599", "mrqa_squad-validation-1192", "mrqa_naturalquestions-validation-7507", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-9281", "mrqa_naturalquestions-validation-8794", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-5497", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-1279", "mrqa_naturalquestions-validation-5921", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-7579", "mrqa_naturalquestions-validation-8338"], "SR": 0.609375, "CSR": 0.6368936567164178, "EFR": 0.76, "Overall": 0.6601599813432835}, {"timecode": 67, "before_eval_results": {"predictions": ["about 1820", "primary law, secondary law and supplementary law", "on the south side of the garden", "Otrar", "westward", "pedagogy", "1598", "Eisleben, Saxony", "Northumbria University", "Leonardo da Vinci", "a year", "religion", "Peyton Manning", "$40,000", "Sanders", "more than 4 kilometers", "compressed gas", "on Saturday evenings", "between 27 July and 7 August 2022", "20 July 1969 UTC", "on a sound stage in front of a live audience in Burbank, California", "Spike", "Glenn Close", "a secluded cove on the far eastern end of Westward Beach, between Zuma Beach and Point Dume in Malibu", "either in front or on top of the brainstem", "the Hongwu Emperor of the Ming Dynasty", "Jean - Jacques Rousseau's Confessions, his autobiography ( whose first six books were written in 1765, when Marie Antoinette was nine years of age, and published in 1782 )", "divided into several successor polities", "a car, up from 500,000 in 2008, two - thirds of which in North America, and was Fiat - Chrysler's best selling brand in the U.S. during the first half of 2017", "Steve Hale", "George II", "approximately 26,000 years", "Michael Madhusudan Dutta", "1996", "in northern China", "August 21", "The balance sheet", "Michael Crawford", "depending on the gender of the reigning monarch", "in the retina of mammalian eyes ( e.g. the human eye )", "1983", "July 1, 1890", "the Behavioral Analysis Unit, having received the training to become a full - time profiler, instead of the Media Liaison, a position which has been split between Hotch and Garcia", "the House of Representatives", "a London underworld criminal who has established himself as one of the biggest cocaine suppliers in the city, with effective legitimate cover", "a Scottish surname", "within molecular clouds in interstellar space", "usually now called the `` chair '' or `` chairperson ''", "The Hudson River", "Simon Callow", "Prafulla Chandra Ghosh of the Indian National Congress", "May 5, 1904", "sovereign states", "a chamber consisting of upright stones ( orthostats ) with one or more large flat capstones forming a roof", "Alex Rodriguez", "Anne Murray", "the Indo - Greek kings", "diastema", "stratum lucidum", "1962", "Philippe Petit", "the British", "average adult brain volume of 1260 cubic centimeters ( cm ) for men and 1130 cm for women", "June 2010"], "metric_results": {"EM": 0.515625, "QA-F1": 0.638986093229089}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.25, 0.25, 1.0, 1.0, 1.0, 0.9714285714285714, 1.0, 0.0, 0.13793103448275862, 0.7142857142857143, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 0.9090909090909091, 0.125, 0.5, 1.0, 1.0, 0.3333333333333333, 0.08333333333333334, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5525", "mrqa_squad-validation-1887", "mrqa_squad-validation-3038", "mrqa_squad-validation-9522", "mrqa_squad-validation-631", "mrqa_squad-validation-6401", "mrqa_naturalquestions-validation-8287", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-6470", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-8907", "mrqa_naturalquestions-validation-493", "mrqa_naturalquestions-validation-10448", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-7358", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-9921", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-7107", "mrqa_naturalquestions-validation-10273", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-7898", "mrqa_naturalquestions-validation-3477", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-454", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-4865"], "SR": 0.515625, "CSR": 0.6351102941176471, "EFR": 0.967741935483871, "Overall": 0.7013516959203037}, {"timecode": 68, "before_eval_results": {"predictions": ["Soviet Union", "\"Queen Bees.\"", "1226", "a temperatures in excess of approximately 1015 kelvins", "1769", "Christmas Eve", "Cobham\u2013Edmonds thesis", "Tethys sea", "prime conjecture", "President Mahmoud Ahmadinejad", "Oireachtas funds", "Newton", "During the 1970s", "1776", "Darian Stewart", "the Chinese dynasties", "a fuel ( the reductant ) and an oxidant, usually atmospheric oxygen, that produces oxidized, often gaseous products, in a mixture termed as smoke", "Kol", "Rich Mullins", "on the slopes of Mt. Hood in Oregon", "in the town of Acolman, just north of Mexico City", "at FERNANDO 'S! in Manchester", "capillaries", "Francis Hutcheson", "Asuka", "the President", "Natural - language processing ( NLP )", "March 31, 2018", "1982", "The Cornett family", "14 December 1972 UTC", "The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "February 7, 2018", "Kyla Pratt", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "Batman", "1999", "Cathy Dennis and Rob Davis", "2012", "off the rez", "Juan Francisco Ochoa", "Matt Monro", "mongrel female", "Lauren", "Blind carbon copy to tertiary recipients who receive the message", "Djokovic", "1 October 2006", "Tottenham", "$1.528 billion", "Evermoist", "India", "2017", "Ludacris", "1939", "Barbara Windsor", "Universal Pictures", "normally show IIII for four o'clock", "restricted naturalization to `` free white persons '' of `` good moral character ''", "Chris Martin", "23 February", "1975", "37.7", "Tagore"], "metric_results": {"EM": 0.6875, "QA-F1": 0.777538216991342}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.8750000000000001, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.8666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1585", "mrqa_squad-validation-10460", "mrqa_squad-validation-9084", "mrqa_squad-validation-368", "mrqa_squad-validation-814", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4870", "mrqa_naturalquestions-validation-2414", "mrqa_naturalquestions-validation-8036", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-2448", "mrqa_naturalquestions-validation-1395", "mrqa_naturalquestions-validation-6089"], "SR": 0.6875, "CSR": 0.6358695652173914, "EFR": 0.95, "Overall": 0.6979551630434783}, {"timecode": 69, "before_eval_results": {"predictions": ["67.9", "model results, reports from government agencies and non-governmental organizations, and industry journals", "2014", "2016", "send aid", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "no French regular army troops were stationed in North America", "four variants", "a university or college", "New Orangery", "Wenzong", "to hide the fact that he had drowned in the Mur River", "poet", "New Paltz", "2005", "France's claim to the region was superior to that of the British", "any unfavourable and unintended sign ( including an abnormal laboratory finding ), symptom, or disease temporally associated with the use of a medicinal ( investigational ) product", "Hagrid", "Nebuchadnezzar", "natural killer cells ( which function in cell - mediated, cytotoxic innate immunity )", "BeBe Winans", "January 1, 1976", "number of games where the player played, in whole or in part", "Lady Sophie", "after World War II", "The Copa Catalunya final", "the Detroit Tigers", "a fictional South American country", "Spanish missionaries", "Michael Crawford", "2018", "Richard Crispin Armitage", "17 - year - old", "either a for - profit business, nonprofit organization, or a government agency", "22 \u00b0 00 \u2032 N 80 \u00b0 00\u2032 W \ufeff / \ufef7 22.000 \u00b0 N 80.000 mi W \ufebf / 22.00 ; - 80.00", "Spanish / Basque origin", "Ian Hart", "October 27, 2017", "R2E Micral", "by the early 3rd century", "Donna Mills", "1987", "March 1995", "in 2003 for the inter-county competition in England and Wales", "John Quincy Adams", "Spanish", "Tony in The Imaginarium of Doctor Parnassus", "three high fantasy adventure films", "the employer", "boxing, where a boxer who is still on their feet but close to being knocked down can be saved from losing by the bell ringing to indicate the end of the round", "April 2, 2018", "Massachusetts", "18 - season", "a Spanish surname", "James Hutton", "1750", "Alan Shearer", "on a Wednesday after Thanksgiving", "Karan Patel", "Kerris Lilla Dorsey", "$100", "a flat rate of 20 % as of April 2015", "low coercivity", "Paul Rudd"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6754119875008033}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.10526315789473685, 0.5333333333333333, 1.0, 1.0, 1.0, 0.8, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.9824561403508771, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9695", "mrqa_squad-validation-12", "mrqa_squad-validation-1144", "mrqa_naturalquestions-validation-6597", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-4382", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-5926", "mrqa_naturalquestions-validation-5605", "mrqa_naturalquestions-validation-6633", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-9384", "mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-5451", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-6093", "mrqa_naturalquestions-validation-4401", "mrqa_naturalquestions-validation-9459", "mrqa_naturalquestions-validation-824", "mrqa_naturalquestions-validation-6052", "mrqa_naturalquestions-validation-1915", "mrqa_naturalquestions-validation-8884", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-7853"], "SR": 0.546875, "CSR": 0.6345982142857143, "EFR": 0.896551724137931, "Overall": 0.687011237684729}, {"timecode": 70, "UKR": 0.685546875, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-3757", "mrqa_squad-validation-8084", "mrqa_naturalquestions-validation-3734", "mrqa_squad-validation-1324", "mrqa_naturalquestions-validation-5611", "mrqa_squad-validation-4898", "mrqa_naturalquestions-validation-8270", "mrqa_naturalquestions-validation-10213", "mrqa_squad-validation-1176", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-6489", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-4195", "mrqa_squad-validation-3190", "mrqa_squad-validation-9467", "mrqa_squad-validation-426", "mrqa_naturalquestions-validation-2509", "mrqa_naturalquestions-validation-6190", "mrqa_squad-validation-6708", "mrqa_naturalquestions-validation-4486", "mrqa_squad-validation-1273", "mrqa_naturalquestions-validation-2304", "mrqa_naturalquestions-validation-7025", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7264", "mrqa_squad-validation-1491", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-9560", "mrqa_squad-validation-9276", "mrqa_naturalquestions-validation-2989", "mrqa_squad-validation-1881", "mrqa_squad-validation-6428", "mrqa_squad-validation-3695", "mrqa_squad-validation-886", "mrqa_naturalquestions-validation-1222", "mrqa_squad-validation-4054", "mrqa_squad-validation-259", "mrqa_naturalquestions-validation-2106", "mrqa_squad-validation-2647", "mrqa_naturalquestions-validation-9295", "mrqa_squad-validation-5846", "mrqa_naturalquestions-validation-22", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-4869", "mrqa_squad-validation-4561", "mrqa_squad-validation-625", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-6859", "mrqa_naturalquestions-validation-7538", "mrqa_naturalquestions-validation-642", "mrqa_squad-validation-1443", "mrqa_squad-validation-8368", "mrqa_squad-validation-9750", "mrqa_squad-validation-8598", "mrqa_naturalquestions-validation-4785", "mrqa_naturalquestions-validation-1427", "mrqa_squad-validation-5148", "mrqa_naturalquestions-validation-7624", "mrqa_squad-validation-484", "mrqa_naturalquestions-validation-3670", "mrqa_squad-validation-3545", "mrqa_squad-validation-5547", "mrqa_squad-validation-6221", "mrqa_squad-validation-7651", "mrqa_squad-validation-2976", "mrqa_squad-validation-10092", "mrqa_squad-validation-3176", "mrqa_naturalquestions-validation-681", "mrqa_squad-validation-9923", "mrqa_squad-validation-885", "mrqa_naturalquestions-validation-7262", "mrqa_squad-validation-6343", "mrqa_squad-validation-7462", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-5451", "mrqa_squad-validation-291", "mrqa_squad-validation-7846", "mrqa_squad-validation-1706", "mrqa_squad-validation-5011", "mrqa_squad-validation-4274", "mrqa_squad-validation-939", "mrqa_squad-validation-297", "mrqa_squad-validation-978", "mrqa_naturalquestions-validation-8063", "mrqa_squad-validation-4337", "mrqa_squad-validation-6250", "mrqa_squad-validation-5462", "mrqa_squad-validation-6085", "mrqa_squad-validation-9180", "mrqa_squad-validation-10136", "mrqa_squad-validation-915", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-8163", "mrqa_squad-validation-1729", "mrqa_squad-validation-8814", "mrqa_squad-validation-10336", "mrqa_naturalquestions-validation-553", "mrqa_squad-validation-4511", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-9904", "mrqa_squad-validation-1208", "mrqa_squad-validation-10500", "mrqa_naturalquestions-validation-5928", "mrqa_squad-validation-6787", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-8530", "mrqa_squad-validation-4066", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-5049", "mrqa_naturalquestions-validation-1562", "mrqa_squad-validation-6489", "mrqa_naturalquestions-validation-2127", "mrqa_squad-validation-7446", "mrqa_squad-validation-7823", "mrqa_naturalquestions-validation-5168", "mrqa_squad-validation-6146", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-2355", "mrqa_squad-validation-6231", "mrqa_naturalquestions-validation-6912", "mrqa_squad-validation-3289", "mrqa_squad-validation-2097", "mrqa_squad-validation-10398", "mrqa_squad-validation-1548", "mrqa_squad-validation-5034", "mrqa_naturalquestions-validation-8466", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-10382", "mrqa_squad-validation-2173", "mrqa_naturalquestions-validation-1340", "mrqa_naturalquestions-validation-3945", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-3561", "mrqa_squad-validation-3727", "mrqa_squad-validation-81", "mrqa_squad-validation-4467", "mrqa_naturalquestions-validation-5531", "mrqa_squad-validation-1632", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-847", "mrqa_squad-validation-3702", "mrqa_squad-validation-403", "mrqa_naturalquestions-validation-6912", "mrqa_squad-validation-189", "mrqa_squad-validation-9074", "mrqa_naturalquestions-validation-9850", "mrqa_squad-validation-3142", "mrqa_squad-validation-1261", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-4426", "mrqa_squad-validation-9705", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-4437", "mrqa_naturalquestions-validation-5799", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-2297", "mrqa_squad-validation-7485", "mrqa_squad-validation-4811", "mrqa_squad-validation-6651", "mrqa_naturalquestions-validation-6040", "mrqa_squad-validation-7965", "mrqa_squad-validation-9066", "mrqa_naturalquestions-validation-3862", "mrqa_squad-validation-8544", "mrqa_naturalquestions-validation-2565", "mrqa_squad-validation-4459", "mrqa_naturalquestions-validation-360", "mrqa_naturalquestions-validation-8234", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-1269", "mrqa_naturalquestions-validation-2212", "mrqa_squad-validation-9846", "mrqa_squad-validation-9004", "mrqa_naturalquestions-validation-5921", "mrqa_naturalquestions-validation-673", "mrqa_squad-validation-9640", "mrqa_squad-validation-3147", "mrqa_naturalquestions-validation-5942", "mrqa_naturalquestions-validation-2269", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-1459", "mrqa_squad-validation-6289", "mrqa_naturalquestions-validation-527", "mrqa_squad-validation-613", "mrqa_naturalquestions-validation-3942", "mrqa_squad-validation-7469", "mrqa_naturalquestions-validation-6698", "mrqa_squad-validation-4934", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-1220", "mrqa_squad-validation-4745", "mrqa_naturalquestions-validation-1901", "mrqa_squad-validation-773", "mrqa_squad-validation-9422", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-4388", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-1537", "mrqa_squad-validation-6683", "mrqa_naturalquestions-validation-10081", "mrqa_squad-validation-6047", "mrqa_naturalquestions-validation-1707", "mrqa_squad-validation-7890", "mrqa_naturalquestions-validation-10271", "mrqa_squad-validation-2697", "mrqa_naturalquestions-validation-86", "mrqa_squad-validation-5289", "mrqa_squad-validation-8244", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-6234", "mrqa_squad-validation-9762", "mrqa_squad-validation-10317", "mrqa_squad-validation-4147", "mrqa_squad-validation-3477", "mrqa_squad-validation-8524", "mrqa_naturalquestions-validation-477", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-6020", "mrqa_squad-validation-4166", "mrqa_naturalquestions-validation-3706", "mrqa_squad-validation-2901", "mrqa_naturalquestions-validation-6678", "mrqa_squad-validation-1661", "mrqa_squad-validation-8234", "mrqa_squad-validation-1833", "mrqa_naturalquestions-validation-6579", "mrqa_squad-validation-4680", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-1950", "mrqa_naturalquestions-validation-7741", "mrqa_squad-validation-8228", "mrqa_squad-validation-9126", "mrqa_naturalquestions-validation-7893", "mrqa_squad-validation-3919", "mrqa_squad-validation-4834", "mrqa_squad-validation-3514", "mrqa_naturalquestions-validation-8153", "mrqa_squad-validation-1095", "mrqa_naturalquestions-validation-5092", "mrqa_naturalquestions-validation-8762", "mrqa_squad-validation-9812", "mrqa_squad-validation-8572", "mrqa_naturalquestions-validation-101", "mrqa_naturalquestions-validation-7627", "mrqa_squad-validation-2159", "mrqa_squad-validation-2097", "mrqa_squad-validation-3019", "mrqa_naturalquestions-validation-9248", "mrqa_squad-validation-9631", "mrqa_squad-validation-9666", "mrqa_squad-validation-9923", "mrqa_squad-validation-2451", "mrqa_squad-validation-1542", "mrqa_naturalquestions-validation-7250", "mrqa_squad-validation-7491", "mrqa_naturalquestions-validation-7819", "mrqa_squad-validation-3278", "mrqa_squad-validation-1814", "mrqa_naturalquestions-validation-3724", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-6340", "mrqa_squad-validation-6395", "mrqa_squad-validation-10365", "mrqa_squad-validation-3023", "mrqa_squad-validation-10213", "mrqa_naturalquestions-validation-2291", "mrqa_squad-validation-4268", "mrqa_squad-validation-4557", "mrqa_squad-validation-4995", "mrqa_squad-validation-3178", "mrqa_squad-validation-5425", "mrqa_squad-validation-3942", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-2704", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-2769", "mrqa_squad-validation-7470", "mrqa_naturalquestions-validation-7499", "mrqa_naturalquestions-validation-7167", "mrqa_naturalquestions-validation-8849", "mrqa_squad-validation-655", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-4929", "mrqa_naturalquestions-validation-5579", "mrqa_squad-validation-4182", "mrqa_naturalquestions-validation-5328", "mrqa_squad-validation-4424", "mrqa_naturalquestions-validation-6130", "mrqa_naturalquestions-validation-832", "mrqa_squad-validation-10080", "mrqa_squad-validation-1777", "mrqa_squad-validation-6982", "mrqa_squad-validation-4313", "mrqa_naturalquestions-validation-4554", "mrqa_squad-validation-1704", "mrqa_naturalquestions-validation-4611", "mrqa_squad-validation-5429", "mrqa_naturalquestions-validation-5394", "mrqa_naturalquestions-validation-853", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-9628", "mrqa_squad-validation-10226", "mrqa_squad-validation-6696", "mrqa_naturalquestions-validation-9835", "mrqa_squad-validation-7645", "mrqa_squad-validation-6213", "mrqa_squad-validation-6952", "mrqa_naturalquestions-validation-5739", "mrqa_squad-validation-4251", "mrqa_naturalquestions-validation-1446", "mrqa_squad-validation-2790", "mrqa_naturalquestions-validation-10369", "mrqa_squad-validation-4331", "mrqa_naturalquestions-validation-9755", "mrqa_squad-validation-629", "mrqa_squad-validation-3683", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-138", "mrqa_naturalquestions-validation-8596", "mrqa_squad-validation-4166", "mrqa_squad-validation-9490", "mrqa_naturalquestions-validation-1443", "mrqa_naturalquestions-validation-6169", "mrqa_squad-validation-1637", "mrqa_squad-validation-9799", "mrqa_naturalquestions-validation-8849", "mrqa_squad-validation-9426", "mrqa_squad-validation-3926", "mrqa_squad-validation-1295", "mrqa_naturalquestions-validation-5288", "mrqa_squad-validation-6388", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-9551", "mrqa_squad-validation-1836", "mrqa_squad-validation-4517", "mrqa_squad-validation-6248", "mrqa_squad-validation-4560", "mrqa_naturalquestions-validation-5938", "mrqa_naturalquestions-validation-366", "mrqa_squad-validation-702", "mrqa_naturalquestions-validation-10294", "mrqa_naturalquestions-validation-7609", "mrqa_squad-validation-7328", "mrqa_squad-validation-6793", "mrqa_naturalquestions-validation-2179", "mrqa_squad-validation-6197", "mrqa_squad-validation-1609", "mrqa_naturalquestions-validation-7051", "mrqa_squad-validation-416", "mrqa_naturalquestions-validation-4924", "mrqa_squad-validation-4730", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-7387", "mrqa_squad-validation-7586", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-4973", "mrqa_squad-validation-5168", "mrqa_naturalquestions-validation-8092", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-10418", "mrqa_squad-validation-7735", "mrqa_squad-validation-6241", "mrqa_squad-validation-1243", "mrqa_naturalquestions-validation-9871", "mrqa_squad-validation-3416", "mrqa_squad-validation-1039", "mrqa_naturalquestions-validation-9870", "mrqa_squad-validation-9263", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-768", "mrqa_naturalquestions-validation-3253", "mrqa_squad-validation-5803", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-7769", "mrqa_naturalquestions-validation-7968", "mrqa_squad-validation-2611", "mrqa_squad-validation-742", "mrqa_squad-validation-5072", "mrqa_squad-validation-4945", "mrqa_squad-validation-6960", "mrqa_squad-validation-1316", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-2208", "mrqa_squad-validation-9491", "mrqa_naturalquestions-validation-290", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-244", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-7632", "mrqa_squad-validation-5946", "mrqa_squad-validation-683", "mrqa_naturalquestions-validation-10031", "mrqa_naturalquestions-validation-7124", "mrqa_squad-validation-8991", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-5366", "mrqa_squad-validation-2370", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3392", "mrqa_squad-validation-3698", "mrqa_squad-validation-9311", "mrqa_squad-validation-9771", "mrqa_squad-validation-1259", "mrqa_squad-validation-2085", "mrqa_squad-validation-1839", "mrqa_squad-validation-3717", "mrqa_squad-validation-4829", "mrqa_squad-validation-10244", "mrqa_squad-validation-6567", "mrqa_naturalquestions-validation-9908", "mrqa_squad-validation-1800", "mrqa_naturalquestions-validation-1491", "mrqa_squad-validation-8091", "mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-8503", "mrqa_squad-validation-1477", "mrqa_squad-validation-9723", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-8159", "mrqa_squad-validation-2199", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-3143", "mrqa_squad-validation-6897", "mrqa_squad-validation-6958", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-156", "mrqa_naturalquestions-validation-3130", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-3008", "mrqa_naturalquestions-validation-346", "mrqa_squad-validation-8853", "mrqa_naturalquestions-validation-6913", "mrqa_squad-validation-1404", "mrqa_squad-validation-1005", "mrqa_naturalquestions-validation-1706", "mrqa_naturalquestions-validation-4594", "mrqa_naturalquestions-validation-4026", "mrqa_squad-validation-9266", "mrqa_squad-validation-6073", "mrqa_squad-validation-118", "mrqa_squad-validation-6964", "mrqa_naturalquestions-validation-5905", "mrqa_squad-validation-6609", "mrqa_naturalquestions-validation-5034", "mrqa_squad-validation-6937", "mrqa_squad-validation-4778", "mrqa_squad-validation-4791", "mrqa_squad-validation-10465", "mrqa_squad-validation-2124", "mrqa_squad-validation-1541", "mrqa_squad-validation-5047", "mrqa_naturalquestions-validation-934", "mrqa_naturalquestions-validation-3145", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-6164", "mrqa_squad-validation-5978", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-204", "mrqa_squad-validation-9753", "mrqa_squad-validation-4037", "mrqa_squad-validation-2685", "mrqa_squad-validation-8881", "mrqa_squad-validation-2147", "mrqa_squad-validation-9847", "mrqa_squad-validation-3516", "mrqa_squad-validation-5973", "mrqa_naturalquestions-validation-2106", "mrqa_squad-validation-9716", "mrqa_squad-validation-4076", "mrqa_naturalquestions-validation-7853", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-7957", "mrqa_squad-validation-8071", "mrqa_squad-validation-1163", "mrqa_squad-validation-10216", "mrqa_naturalquestions-validation-7152", "mrqa_squad-validation-8216", "mrqa_squad-validation-7501", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-9039", "mrqa_squad-validation-460", "mrqa_squad-validation-3907", "mrqa_squad-validation-5098", "mrqa_squad-validation-6607", "mrqa_naturalquestions-validation-9368", "mrqa_squad-validation-1750", "mrqa_naturalquestions-validation-386", "mrqa_squad-validation-8486", "mrqa_squad-validation-3055", "mrqa_naturalquestions-validation-4426", "mrqa_squad-validation-5606", "mrqa_naturalquestions-validation-1445", "mrqa_squad-validation-5599"], "OKR": 0.837890625, "KG": 0.3546875, "before_eval_results": {"predictions": ["Chevron", "19.3%", "greater return of capital (r) than economic growth (g)", "failed", "decreased inequality between skilled and unskilled workers", "the San Jose Marriott", "\u2018combs\u2019 \u2013 groups of cilia which they use for swimming", "San Francisco Bay Area's Levi's Stadium", "oxygen", "bits", "Wankel engine", "cnidarians", "ribbon-like spiral around the edges of the cell (e.g., Spirogyra)", "France", "false assurances", "allowed very young students to attend college", "more than 2,500", "Michael Madhusudan Dutta", "beneath the liver", "Omar Khayyam", "The aorta", "The flag of Vietnam", "October 23", "Student League for Industrial Democracy ( SLID )", "Philipp Scheidemann", "Massillon, Ohio", "January 2, 1971", "New England Patriots", "20 years from the filing date subject to the payment of maintenance fees", "1937", "The UN General Assembly", "April", "Jesse Frederick James Conaway", "Edgar Lungu", "scythe", "British Columbia, Canada", "Chlorofluorocarbons", "To capitalize on her publicity", "a series of structural rearrangements in the RTK that lead to its enzymatic activation", "on a bronze plaque and mounted inside the pedestal's lower level", "1997 ( Act No. 33 of 1997 )", "Betty", "the French colonists", "to regulate the employment and working conditions of civil servants, oversee hiring and promotions, and promote the values of the public service", "Water extinguishment", "feathers", "Kathy Najimy", "T.J. Miller", "Kiss", "Atlanta, Georgia", "Katharine Hepburn -- Ethel Thayer", "8 bytes", "Czech word, robota", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "March 11, 2018", "Dougie MacLean", "Victims blaming", "2010", "Hendersonville, North Carolina", "2018", "Washington metropolitan area", "long sustained period of inflation", "the distal dorsal root", "Keith Thibodeaux ( born December 1, 1950 )"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6447339323258441}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.6153846153846153, 1.0, 0.15384615384615383, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5882352941176471, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.15384615384615383, 0.42857142857142855, 0.2857142857142857, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.0, 0.0, 0.16666666666666666, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-419", "mrqa_squad-validation-7544", "mrqa_squad-validation-7437", "mrqa_squad-validation-4530", "mrqa_squad-validation-129", "mrqa_squad-validation-8753", "mrqa_squad-validation-3063", "mrqa_naturalquestions-validation-9009", "mrqa_naturalquestions-validation-2095", "mrqa_naturalquestions-validation-3122", "mrqa_naturalquestions-validation-1604", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-2130", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-4633", "mrqa_naturalquestions-validation-4736", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-3491", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-9644", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-1856", "mrqa_naturalquestions-validation-4974", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1886"], "SR": 0.53125, "CSR": 0.6331426056338028, "EFR": 0.9333333333333333, "Overall": 0.6889201877934272}, {"timecode": 71, "before_eval_results": {"predictions": ["Robert R. Gilruth", "informal or formal", "their greatest common divisor is one", "remain uncertain", "Mohawk Chief Hendrick", "Because he published his findings first", "Emperor Chengzong", "lower", "minimal loss over any terrestrial distance", "six", "a second Gleichschaltung or similar event in the future", "1981", "Thames River", "Levi's Stadium", "much higher", "March 1930", "In 1889", "Mumbai Rajdhani Express", "communism", "from Middle Eastern alchemy", "2018", "Western cultures", "Steve Russell", "Andrea Brooks", "Jacqueline MacInnes Wood", "plate tectonics", "Dan Stevens", "a United Kingdom Act of Parliament designed to protect personal data stored on computers or in an organised paper filing system", "Doug Pruzan", "in 1978", "13", "Spanish / Basque", "Lady Gaga", "in the naos", "Gabrielle - Suzanne Barbot de Villeneuve", "the Kansas City Chiefs", "Ethel `` Edy '' Proctor", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "Hon July Moyo", "three", "experimental psychology", "2001 Indian epic sports - drama film, directed by Ashutosh Gowariker, produced by Aamir Khan and Mansoor Khan, and written by Zakariker and Abbas Tyrewala", "Julie Hagerty", "Frank Oz", "Leonardo da Vinci", "ice giants", "the end", "Coldplay", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "patronymic", "during meiosis", "eleven", "London", "T.J. Miller", "April 1, 2002", "1999", "at the 1964 Republican National Convention in San Francisco, California", "asexually", "Bacon", "Kristy Swanson", "Buffalo Bill", "13 May 1787", "Havana Harbor", "Hal Derwin"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7052535138472638}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5384615384615384, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.3636363636363636, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1877", "mrqa_squad-validation-1577", "mrqa_squad-validation-1496", "mrqa_squad-validation-6962", "mrqa_squad-validation-7130", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-3416", "mrqa_naturalquestions-validation-2396", "mrqa_naturalquestions-validation-10093", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-6315", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-4922", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-7906", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7309", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5006", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9878"], "SR": 0.578125, "CSR": 0.6323784722222222, "EFR": 0.9629629629629629, "Overall": 0.694693287037037}, {"timecode": 72, "before_eval_results": {"predictions": ["WBND-LD", "1331", "more than 70,000", "1939", "unit-dose", "non-violent", "45 total touchdowns", "pursue their life goals in any country through free movement", "deterministic", "the European Court of Justice", "a legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "whether it would do more harm than good", "Black's Law Dictionary", "1966", "Leonard Bernstein", "the sea witch character who appears in the fairy tale `` The Little Mermaid '' by Hans Christian Andersen", "used for programs that benchmark and rank the world's fastest supercomputers", "Kida", "heart", "fermenting dietary fiber into short - chain fatty acids ( SCFAs ), such as acetic acid and butyric acid, which are then absorbed by the host", "over a 20 - year period", "permanently absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "representatives from government department, academicians, other professional bodies viz. ICAI, representatives from ASSOCHAM, CII, FICCI, etc", "till a thunderstorm Novalee, alone at Walmart", "the Pandavas", "seven", "Brazil", "Buffalo Bill", "NFL coaches, general managers, and scouts", "February 7, 2018", "200 to 500 mg up to 7 mL", "Jaydev Shah", "the end of the 2015 season", "footling breech", "Typically, no", "Polly Walker", "German engineer Werner Ruchti", "Milan, Italy", "The Sun", "Whig candidates William Henry Harrison ( the `` hero of Tippecanoe '' ) and John Tyler, while denigrating incumbent Democrat Martin Van Buren", "2001", "Set and filmed in New York City", "Paul Lynde", "John C. Reilly", "the January 2017 patch", "Nalini Negi", "the President of the United States", "the forces of Andrew Moray and William Wallace", "Miller Lite", "Mason Alan Dinehart", "the 1840s", "31", "George Halas", "Bob Dylan", "`` Opening Titles : James Bond Is Back / From Russia with Love / James Bond Theme ''", "Andy Serkis", "John Hancock", "Ceramic art", "Rigg", "54 Mbit / s", "Baker, California, USA", "the 1820s", "three", "the 1940s"], "metric_results": {"EM": 0.703125, "QA-F1": 0.8200456576365497}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9090909090909091, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9777777777777777, 0.8571428571428571, 0.9600000000000001, 0.08695652173913043, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7586206896551725, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-335", "mrqa_squad-validation-4431", "mrqa_squad-validation-6427", "mrqa_squad-validation-6871", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-7253", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-10411", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-8555", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2137", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-1223", "mrqa_naturalquestions-validation-9563", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-9340"], "SR": 0.703125, "CSR": 0.633347602739726, "EFR": 1.0, "Overall": 0.7022945205479452}, {"timecode": 73, "before_eval_results": {"predictions": ["portrait, allegorical, religious, mythical, statues for gardens including fountains, as well as architectural decorations", "1998", "seven", "peat swamps or small ponds", "friendly and supportive", "Super Bowl XLV", "Block I CSM", "university and military academy", "Philip Segal", "Westinghouse Electric", "1698", "the oxidant", "New York attorney Charles F. Peck", "physical pain", "General Electric", "Olympia", "The Walking Dead ( comic book )", "euro", "Tampa Bay defensive end Simeon Rice", "Georges Auguste Escoffier", "Jack Van Hay", "Tagalog or English", "Latitude", "prevent any contaminants in the sink from flowing into the potable water system by siphonage and is the least expensive form of backflow prevention", "Watson and Crick", "Sohrai", "July 1, 1923", "ten", "Iran", "the Indo - Greek kings", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "a specific task", "Empiricism", "Panic! at the Disco", "1946", "During Hanna's recovery masquerade celebration", "Gibraltar", "the Farrow / Previn / Allens", "Jeff East", "George II", "Orangeville, Ontario", "President Richard Nixon", "noble patrilineality", "Elena Anaya", "1902", "July 2014", "1955", "Southport, North Carolina", "1952 ( Kray twins )", "Ian Hart", "September 19, 2017", "footling breech", "Teri Hatcher", "the 1960s", "1988", "Gene Kelly and Donald O'Connor", "Throughout the season", "Melbourne", "Rachel Kelly Tucker", "Kenny Rogers", "1 ) 2009", "geographical area", "April 13, 2018", "the mid-1970s"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6760908928028493}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.17391304347826084, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6153846153846153, 0.0, 0.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.18181818181818182, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5545", "mrqa_squad-validation-910", "mrqa_squad-validation-4014", "mrqa_naturalquestions-validation-10029", "mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-9346", "mrqa_naturalquestions-validation-9075", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-138", "mrqa_naturalquestions-validation-8426", "mrqa_naturalquestions-validation-1085"], "SR": 0.59375, "CSR": 0.6328125, "EFR": 0.9230769230769231, "Overall": 0.6868028846153846}, {"timecode": 74, "before_eval_results": {"predictions": ["wars", "a light-driven method of synthesizing ATP to power the Calvin cycle without generating oxygen", "the Catholic Church", "cartels", "the Los Angeles Times", "94", "A large gap in male and female education may indicate backwardness and so may be associated with lower economic growth", "Gods of Egypt", "the assassination of John F. Kennedy", "Jonathan Stewart", "Rhine-kilometers", "Mohamed Morsi", "over a hundred", "Jonathan Stewart", "Bob Dylan", "2017", "in the New Testament", "2018", "living - donor ( formerly known as cadaveric )", "2015", "RMS Titanic", "the northern bluegrass band the Greenbriar Boys", "A third party agent, Isaac Morris", "Orange", "hot and humid", "Claudia Grace Wells", "The Bangles", "source code", "When the others arrive", "Herod", "Jacques Cousteau", "Florida, where new arrival Roy makes two oddball friends and a bad enemy, and joins an effort to stop construction of a pancake house which would destroy a colony of burrowing owls who live on the site", "rum", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "1922", "Daryl Sabara", "Suzanne Barbot de Villeneuve", "an instant messaging client", "over the specimen", "ummat al - Islamiyah", "a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court which gives rise to its judgment", "September 29, 2017", "Kumar Jyoti", "1770 BC", "Ethiopia ( Abyssinia ), the Dervish state ( a portion of present - day Somalia ) and Liberia still being independent", "Boston Celtics center Bill Russell", "Transvaginal ultrasonography", "Nodar Kumaritashvili", "Liam Cunningham", "A feature film adaptation of the novel directed by Josh Boone and starring Shailene Woodley, Ansel Elgort and Nat Wolff was released on June 6, 2014", "a synonym for the content component of communication", "gastrocnemius", "Roger Federer", "Ren\u00e9 Georges Hermann - Paul", "Midazolam", "A mark that reminds of the Omnipotent Lord, which is formless", "Gabrielle Elyse", "Oklahoma native Major General Clarence L. Tinker, the first Native American Major General", "ulna bone", "2022", "4.0 oz", "The episode `` Two Fathers ''", "the French", "Border Collie"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6580764270243749}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.17391304347826086, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.06060606060606061, 0.25, 1.0, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.2758620689655173, 1.0, 0.8, 0.8, 0.8, 0.5714285714285715, 0.0, 1.0, 1.0, 0.06060606060606061, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 0.0, 0.9090909090909091, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8875", "mrqa_squad-validation-7438", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-1613", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-6041", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-5143", "mrqa_naturalquestions-validation-1312", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-5458", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-186", "mrqa_naturalquestions-validation-7141", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-5928", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-5499", "mrqa_naturalquestions-validation-7627", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-6028"], "SR": 0.515625, "CSR": 0.63125, "EFR": 0.967741935483871, "Overall": 0.6954233870967742}, {"timecode": 75, "UKR": 0.6953125, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-9240", "mrqa_squad-validation-3491", "mrqa_squad-validation-5844", "mrqa_squad-validation-4051", "mrqa_squad-validation-8725", "mrqa_squad-validation-9285", "mrqa_naturalquestions-validation-8695", "mrqa_squad-validation-2212", "mrqa_squad-validation-5815", "mrqa_naturalquestions-validation-2333", "mrqa_squad-validation-9170", "mrqa_squad-validation-1367", "mrqa_squad-validation-5578", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-10091", "mrqa_squad-validation-4390", "mrqa_naturalquestions-validation-9054", "mrqa_squad-validation-5462", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-4090", "mrqa_squad-validation-5255", "mrqa_squad-validation-8749", "mrqa_naturalquestions-validation-950", "mrqa_squad-validation-2090", "mrqa_naturalquestions-validation-3469", "mrqa_squad-validation-9194", "mrqa_squad-validation-112", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-8056", "mrqa_squad-validation-1491", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-8466", "mrqa_naturalquestions-validation-187", "mrqa_squad-validation-9429", "mrqa_naturalquestions-validation-7685", "mrqa_squad-validation-2050", "mrqa_naturalquestions-validation-1426", "mrqa_squad-validation-6810", "mrqa_naturalquestions-validation-2896", "mrqa_squad-validation-4029", "mrqa_naturalquestions-validation-6285", "mrqa_squad-validation-2238", "mrqa_squad-validation-3695", "mrqa_naturalquestions-validation-878", "mrqa_squad-validation-2654", "mrqa_naturalquestions-validation-1400", "mrqa_squad-validation-1295", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-2791", "mrqa_naturalquestions-validation-3053", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-2396", "mrqa_squad-validation-895", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-8883", "mrqa_squad-validation-9134", "mrqa_squad-validation-5456", "mrqa_squad-validation-2955", "mrqa_squad-validation-9682", "mrqa_squad-validation-7692", "mrqa_squad-validation-7571", "mrqa_squad-validation-8428", "mrqa_naturalquestions-validation-2967", "mrqa_squad-validation-5489", "mrqa_squad-validation-2830", "mrqa_squad-validation-2741", "mrqa_squad-validation-6240", "mrqa_naturalquestions-validation-6041", "mrqa_naturalquestions-validation-2333", "mrqa_squad-validation-5576", "mrqa_naturalquestions-validation-10319", "mrqa_squad-validation-8298", "mrqa_squad-validation-1651", "mrqa_squad-validation-9748", "mrqa_squad-validation-195", "mrqa_squad-validation-1541", "mrqa_naturalquestions-validation-1443", "mrqa_squad-validation-5967", "mrqa_squad-validation-773", "mrqa_naturalquestions-validation-4090", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8229", "mrqa_squad-validation-5846", "mrqa_naturalquestions-validation-2644", "mrqa_naturalquestions-validation-9836", "mrqa_squad-validation-3156", "mrqa_naturalquestions-validation-475", "mrqa_squad-validation-212", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-2650", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-10023", "mrqa_squad-validation-9753", "mrqa_squad-validation-1542", "mrqa_squad-validation-3101", "mrqa_squad-validation-8548", "mrqa_squad-validation-9346", "mrqa_squad-validation-886", "mrqa_naturalquestions-validation-10485", "mrqa_squad-validation-6392", "mrqa_squad-validation-2139", "mrqa_squad-validation-9453", "mrqa_squad-validation-10233", "mrqa_naturalquestions-validation-8585", "mrqa_squad-validation-9784", "mrqa_naturalquestions-validation-4728", "mrqa_squad-validation-8066", "mrqa_naturalquestions-validation-5034", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-3802", "mrqa_naturalquestions-validation-10343", "mrqa_squad-validation-8811", "mrqa_squad-validation-2447", "mrqa_squad-validation-2390", "mrqa_naturalquestions-validation-8763", "mrqa_squad-validation-9861", "mrqa_squad-validation-1063", "mrqa_naturalquestions-validation-4029", "mrqa_squad-validation-5519", "mrqa_naturalquestions-validation-5236", "mrqa_naturalquestions-validation-5932", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-5371", "mrqa_squad-validation-567", "mrqa_squad-validation-6868", "mrqa_squad-validation-9522", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-3074", "mrqa_squad-validation-602", "mrqa_squad-validation-1910", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-8555", "mrqa_naturalquestions-validation-669", "mrqa_squad-validation-1877", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2025", "mrqa_squad-validation-9964", "mrqa_squad-validation-6298", "mrqa_naturalquestions-validation-8757", "mrqa_squad-validation-2673", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-4929", "mrqa_squad-validation-915", "mrqa_naturalquestions-validation-7609", "mrqa_squad-validation-6573", "mrqa_naturalquestions-validation-3609", "mrqa_squad-validation-2825", "mrqa_squad-validation-9641", "mrqa_squad-validation-6871", "mrqa_squad-validation-6483", "mrqa_squad-validation-2645", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-8037", "mrqa_squad-validation-1758", "mrqa_squad-validation-1133", "mrqa_squad-validation-1113", "mrqa_squad-validation-3813", "mrqa_naturalquestions-validation-7608", "mrqa_squad-validation-2843", "mrqa_naturalquestions-validation-8542", "mrqa_squad-validation-6451", "mrqa_squad-validation-4176", "mrqa_squad-validation-5531", "mrqa_squad-validation-10464", "mrqa_squad-validation-9720", "mrqa_naturalquestions-validation-8151", "mrqa_squad-validation-8713", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-85", "mrqa_squad-validation-204", "mrqa_squad-validation-6518", "mrqa_naturalquestions-validation-3940", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-138", "mrqa_squad-validation-9324", "mrqa_naturalquestions-validation-2090", "mrqa_squad-validation-3406", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-6193", "mrqa_squad-validation-2058", "mrqa_naturalquestions-validation-2095", "mrqa_squad-validation-5051", "mrqa_squad-validation-10340", "mrqa_squad-validation-3529", "mrqa_squad-validation-9600", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-232", "mrqa_squad-validation-5589", "mrqa_squad-validation-9526", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-2847", "mrqa_squad-validation-1685", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4143", "mrqa_naturalquestions-validation-1785", "mrqa_squad-validation-3757", "mrqa_squad-validation-9764", "mrqa_naturalquestions-validation-5485", "mrqa_squad-validation-9306", "mrqa_squad-validation-5932", "mrqa_squad-validation-886", "mrqa_squad-validation-9809", "mrqa_squad-validation-1459", "mrqa_squad-validation-202", "mrqa_naturalquestions-validation-8625", "mrqa_squad-validation-4698", "mrqa_naturalquestions-validation-6797", "mrqa_squad-validation-4297", "mrqa_naturalquestions-validation-1398", "mrqa_squad-validation-5411", "mrqa_squad-validation-3347", "mrqa_naturalquestions-validation-9009", "mrqa_squad-validation-9", "mrqa_squad-validation-3360", "mrqa_squad-validation-5815", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-8530", "mrqa_squad-validation-3690", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-2901", "mrqa_squad-validation-1388", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8277", "mrqa_squad-validation-3989", "mrqa_squad-validation-7125", "mrqa_naturalquestions-validation-8318", "mrqa_naturalquestions-validation-8429", "mrqa_squad-validation-6360", "mrqa_naturalquestions-validation-3088", "mrqa_squad-validation-10362", "mrqa_squad-validation-10269", "mrqa_naturalquestions-validation-5440", "mrqa_squad-validation-3377", "mrqa_squad-validation-9198", "mrqa_squad-validation-1517", "mrqa_squad-validation-2085", "mrqa_naturalquestions-validation-1490", "mrqa_squad-validation-7408", "mrqa_squad-validation-8168", "mrqa_naturalquestions-validation-1819", "mrqa_naturalquestions-validation-3862", "mrqa_squad-validation-7230", "mrqa_squad-validation-833", "mrqa_squad-validation-3636", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-6917", "mrqa_squad-validation-3240", "mrqa_naturalquestions-validation-8427", "mrqa_squad-validation-2385", "mrqa_squad-validation-3599", "mrqa_squad-validation-5658", "mrqa_naturalquestions-validation-10433", "mrqa_squad-validation-7014", "mrqa_squad-validation-9664", "mrqa_naturalquestions-validation-8702", "mrqa_squad-validation-3062", "mrqa_naturalquestions-validation-6278", "mrqa_naturalquestions-validation-4628", "mrqa_naturalquestions-validation-2672", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-8862", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-297", "mrqa_squad-validation-2670", "mrqa_squad-validation-4023", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-3562", "mrqa_squad-validation-8767", "mrqa_naturalquestions-validation-5259", "mrqa_squad-validation-516", "mrqa_naturalquestions-validation-9324", "mrqa_squad-validation-1142", "mrqa_squad-validation-2000", "mrqa_squad-validation-1508", "mrqa_naturalquestions-validation-1539", "mrqa_naturalquestions-validation-9553", "mrqa_squad-validation-803", "mrqa_naturalquestions-validation-2411", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-833", "mrqa_squad-validation-5293", "mrqa_squad-validation-7428", "mrqa_squad-validation-10158", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-124", "mrqa_squad-validation-10133", "mrqa_squad-validation-5051", "mrqa_squad-validation-4467", "mrqa_squad-validation-4875", "mrqa_squad-validation-8701", "mrqa_squad-validation-4251", "mrqa_naturalquestions-validation-9434", "mrqa_squad-validation-967", "mrqa_squad-validation-4085", "mrqa_naturalquestions-validation-793", "mrqa_squad-validation-6584", "mrqa_squad-validation-3578", "mrqa_naturalquestions-validation-10350", "mrqa_naturalquestions-validation-2630", "mrqa_squad-validation-9913", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-6875", "mrqa_squad-validation-2941", "mrqa_squad-validation-2192", "mrqa_squad-validation-7584", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-10562", "mrqa_squad-validation-394", "mrqa_squad-validation-7412", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-4657", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-3546", "mrqa_squad-validation-1742", "mrqa_naturalquestions-validation-5555", "mrqa_squad-validation-3221", "mrqa_squad-validation-9189", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-187", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-171", "mrqa_naturalquestions-validation-7579", "mrqa_squad-validation-3296", "mrqa_squad-validation-9679", "mrqa_naturalquestions-validation-6506", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-6560", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-5464", "mrqa_squad-validation-1257", "mrqa_squad-validation-7654", "mrqa_squad-validation-7473", "mrqa_squad-validation-7405", "mrqa_squad-validation-7765", "mrqa_squad-validation-4397", "mrqa_squad-validation-102", "mrqa_squad-validation-9410", "mrqa_squad-validation-3926", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-5854", "mrqa_squad-validation-7211", "mrqa_squad-validation-448", "mrqa_naturalquestions-validation-8220", "mrqa_squad-validation-5101", "mrqa_squad-validation-6972", "mrqa_naturalquestions-validation-3253", "mrqa_squad-validation-3164", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-10554", "mrqa_squad-validation-1979", "mrqa_squad-validation-32", "mrqa_naturalquestions-validation-2855", "mrqa_squad-validation-6105", "mrqa_squad-validation-6920", "mrqa_naturalquestions-validation-3006", "mrqa_squad-validation-6455", "mrqa_squad-validation-7938", "mrqa_squad-validation-8694", "mrqa_squad-validation-7761", "mrqa_naturalquestions-validation-10691", "mrqa_squad-validation-2514", "mrqa_squad-validation-9369", "mrqa_squad-validation-1889", "mrqa_squad-validation-6765", "mrqa_naturalquestions-validation-8116", "mrqa_squad-validation-8539", "mrqa_naturalquestions-validation-8962", "mrqa_naturalquestions-validation-650", "mrqa_squad-validation-6054", "mrqa_squad-validation-864", "mrqa_squad-validation-5644", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-8266", "mrqa_squad-validation-10465", "mrqa_naturalquestions-validation-5449", "mrqa_squad-validation-7651", "mrqa_naturalquestions-validation-5087", "mrqa_naturalquestions-validation-7885", "mrqa_squad-validation-7917", "mrqa_squad-validation-3514", "mrqa_squad-validation-683", "mrqa_squad-validation-10302", "mrqa_naturalquestions-validation-662", "mrqa_squad-validation-6056", "mrqa_naturalquestions-validation-7731", "mrqa_squad-validation-873", "mrqa_squad-validation-467", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-8209", "mrqa_squad-validation-80", "mrqa_squad-validation-530", "mrqa_squad-validation-7275", "mrqa_squad-validation-1040", "mrqa_naturalquestions-validation-9327", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-4335", "mrqa_naturalquestions-validation-6677", "mrqa_squad-validation-2451", "mrqa_squad-validation-3204", "mrqa_squad-validation-7203", "mrqa_squad-validation-6576", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-7350", "mrqa_squad-validation-6806", "mrqa_squad-validation-416", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-3611", "mrqa_naturalquestions-validation-3083", "mrqa_squad-validation-10352", "mrqa_naturalquestions-validation-4029", "mrqa_squad-validation-4325", "mrqa_squad-validation-8691", "mrqa_squad-validation-7969", "mrqa_naturalquestions-validation-9816", "mrqa_squad-validation-2737", "mrqa_naturalquestions-validation-9530", "mrqa_squad-validation-5876", "mrqa_squad-validation-8881", "mrqa_squad-validation-641", "mrqa_naturalquestions-validation-386", "mrqa_squad-validation-7744", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-686", "mrqa_naturalquestions-validation-1324", "mrqa_squad-validation-6402", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-875", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-328", "mrqa_squad-validation-5012", "mrqa_naturalquestions-validation-2684", "mrqa_naturalquestions-validation-6984", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-4221", "mrqa_squad-validation-10112", "mrqa_naturalquestions-validation-5605", "mrqa_naturalquestions-validation-3902", "mrqa_squad-validation-7480", "mrqa_naturalquestions-validation-9895", "mrqa_squad-validation-1288", "mrqa_naturalquestions-validation-6021", "mrqa_squad-validation-9372", "mrqa_naturalquestions-validation-10093", "mrqa_squad-validation-3263", "mrqa_naturalquestions-validation-4124", "mrqa_squad-validation-3642", "mrqa_naturalquestions-validation-3386", "mrqa_squad-validation-9174", "mrqa_squad-validation-3278", "mrqa_squad-validation-8160", "mrqa_squad-validation-9267", "mrqa_squad-validation-3495", "mrqa_squad-validation-295", "mrqa_naturalquestions-validation-8043", "mrqa_squad-validation-2243", "mrqa_naturalquestions-validation-2971", "mrqa_squad-validation-3873", "mrqa_naturalquestions-validation-5516", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-4604", "mrqa_squad-validation-4184", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-4776", "mrqa_squad-validation-9895", "mrqa_naturalquestions-validation-3969", "mrqa_naturalquestions-validation-4426", "mrqa_squad-validation-5808", "mrqa_squad-validation-5072", "mrqa_naturalquestions-validation-1111", "mrqa_squad-validation-3133", "mrqa_squad-validation-7338", "mrqa_squad-validation-6754", "mrqa_squad-validation-9569", "mrqa_naturalquestions-validation-5790", "mrqa_squad-validation-847", "mrqa_squad-validation-5242", "mrqa_squad-validation-7410", "mrqa_naturalquestions-validation-9626", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-9885", "mrqa_squad-validation-2710", "mrqa_squad-validation-3093", "mrqa_squad-validation-7380", "mrqa_naturalquestions-validation-1911", "mrqa_squad-validation-3846", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-10268", "mrqa_squad-validation-6612", "mrqa_squad-validation-7189", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-9809"], "OKR": 0.828125, "before_eval_results": {"predictions": ["Jamukha", "1970", "When the Methodists in America were separated from the Church of England", "10.0%", "risen with increased income inequality", "William the Conqueror", "Barnett Center", "Georgia", "safety of medications (i.e., drug interactions)", "494,665", "repulsive forces of interaction between atoms at close contact", "Tesla coil", "weekend afternoons", "Christmas Eve", "Executive Residence of the White House Complex", "Clarence Anglin", "Aaron Harrison", "February 9, 2018", "unknown origin", "Joseph Sherrard Kearns", "1 January 1904", "the President", "Missi Hale", "a flash music video featuring an animated dancing banana", "early 1980s", "Don Cook", "Eddie Murphy", "Identification of alternative plans / policies", "2009", "San Francisco, California ( the primary setting of the film ), and around Oahu, Hawaii", "Tracy McConnell", "March 2, 2016", "to regulate the employment and working conditions of civil servants, oversee hiring and promotions, and promote the values of the public service", "Charles Sherrington", "authentic intercalary date, February 29", "Andy Serkis", "before the first year begins", "Gustav Bauer", "3D modeling ( or three - dimensional modeling )", "a low concentration in pigmentation", "September 29, 2017", "Jack Barry", "in the year 2026", "Joseph Heller", "November 25, 2002", "four times", "its vast territory was divided into several successor polities", "rum, fruit juice, and syrup or grenadine", "Epithelium ( epi - + thele + - ium )", "Matt Czuchry", "early to mid-2000s", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "Blue laws", "special guest performers Beyonc\u00e9 and Bruno Mars", "Matthew Gregory Wise", "Gorakhpur railway station, Uttar Pradesh, India", "left ring finger", "Donna", "Michael Edwards", "1966", "eleven casinos", "Nick Kroll", "Spanish", "1 October 2006"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8193539915966387}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6113", "mrqa_squad-validation-6361", "mrqa_squad-validation-10393", "mrqa_squad-validation-5827", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-10249", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-4166", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-5465", "mrqa_naturalquestions-validation-9944", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9062"], "SR": 0.734375, "CSR": 0.6326069078947368, "EFR": 0.9411764705882353, "Overall": 0.6903816756965944}, {"timecode": 76, "before_eval_results": {"predictions": ["N\u2013S rift system", "Chagatai", "18 million", "since the Sui and Tang dynasties", "Ps. 31:5", "a new magma", "in the zygote, or fertilized egg", "Nice Treaty", "cysteine", "12", "17", "Honorary freemen", "Seine", "1072", "1934", "the Christian biblical canon", "all Americans the right to be served in facilities which are open to the public -- hotels, restaurants, theaters, retail stores, and similar establishments", "Hodel", "senators", "sometime between 124 and 800 CE, with some theories dating the earliest Polynesian settlements to the 10th or even 13th century", "John Bull", "224.7 Earth days", "3 October 1990", "the Turco - Mongol Timurid dynasty of Central Asia", "the most direct path between two points", "American country music artist Mary Chapin Carpenter", "Peristaltic contractions", "toys or doorbell installations", "on a sound stage in front of a live audience in Burbank, California", "American production duo The Chainsmokers", "Jack Gleeson", "the Microsoft Windows port of GTA : San Andreas in 2005", "left - sided heart failure", "Tiber", "Startup neutron source", "1979 / 80", "Jesse Frederick James Conaway", "Elena Anaya", "Microsoft Windows, PlayStation 4, and Xbox One in September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Matt Ryan", "ESPN", "epidermis", "Tethys Ocean", "2013", "Andy Warhol", "Betty", "Siddharth Arora / Vibhav Roy", "Yondu Udonta", "loop ( also called a self - loop or a `` buckle '' )", "Helena", "between 1765 and 1783", "random - access memory ( RAM )", "semi-autonomous organisational units within the National Health Service in England", "Donna", "# 4", "Mel Gibson", "from the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "Nickelback", "offensive coordinator", "Lutheran Church of Sweden", "Polly Walker", "virtual reality simulator accessible by players using visors and haptic technology such as gloves", "to address the historic oppression, inequality and discrimination faced by those communities and to give these communities a place", "uvea"], "metric_results": {"EM": 0.625, "QA-F1": 0.7352285952373318}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.17391304347826084, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.2, 0.0, 0.0, 0.6, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6896551724137931, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.823529411764706, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8846", "mrqa_squad-validation-3986", "mrqa_squad-validation-8859", "mrqa_naturalquestions-validation-4361", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-6482", "mrqa_naturalquestions-validation-4026", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-6810", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9142", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-1953", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2758"], "SR": 0.625, "CSR": 0.6325081168831168, "EFR": 0.875, "Overall": 0.6771266233766233}, {"timecode": 77, "before_eval_results": {"predictions": ["the poor", "higher", "9", "Canterbury", "Mediterranean", "Brown v. Board of Education of Topeka", "104 \u00b0F (40 \u00b0C)", "monophyletic", "Gandhi", "24", "Peter Davison, Colin Baker and Sylvester McCoy", "miasto sto\u0142eczne Warszawa (English: \"The Capital City of Warsaw\")", "tiger team", "the assassination of US President John F. Kennedy", "Paul Lynde", "Indian Hockey Federation ( IHF ) had also been established and it sent a hockey team to the Summer Olympics", "the majority coming from Western Australia", "American multinational retail corporation", "Pakhangba", "pigs", "Rihanna", "Speaker of the House of Representatives", "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "by December 1349 conditions were returning to relative normalcy", "Sakshi Malik", "Auburn Tigers", "The Blind Boys of Alabama, Tom Waits, The Neville Brothers, DoMaJe, and Steve Earle", "Jacob Packer", "Jerry Leiber and Mike Stoller for The Coasters", "2. TLC - All That Theme Song 1 : 04", "Microfilaments", "Panzerkampfwagen VIII Maus ( `` Mouse '' )", "8.7 -- 9.2", "their son Jack ( short for Jack - o - Lantern ) is born on Halloween 2023", "Wednesday, September 21, 2016", "$2.18 billion", "Brahmagupta's Brahmasputha Siddhanta ( 7th century )", "Gustav Bauer", "1991, 1992, 1993", "May 3, 2005, through Island Records as the band's major label debut", "Ludacris", "Tami Lynn", "90 \u00b0 N 0 \u00b0 W", "substitute", "1985", "the university's science club in 1886", "uppermost layer of the dermis", "31 October 1972", "higher the vapor pressure of a liquid at a given temperature", "Daniel A. Dailey", "a generic term for vehicles inspired by theJeep that are suitable for use on rough terrain", "usually 20 years from the filing date", "The Intolerable Acts", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "mitochondrial membrane in eukaryotes", "Manhattan", "Sanchez Navarro", "mashed potato", "two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "Oahu, Hawaii", "efferent nerves", "Major Robert Smith of the British Indian Army renovated the tower in 1828 and installed a pillared cupola over the fifth story, thus creating a sixth", "A wide range of research methods are used in psychology"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7728531916443935}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.4827586206896552, 0.3636363636363636, 1.0, 1.0, 0.2857142857142857, 1.0, 0.8333333333333333, 0.2222222222222222, 1.0, 0.8571428571428571, 0.0, 0.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.6, 0.6666666666666666, 1.0, 0.7272727272727272, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7162", "mrqa_squad-validation-871", "mrqa_squad-validation-7746", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-4021", "mrqa_naturalquestions-validation-5634", "mrqa_naturalquestions-validation-10557", "mrqa_naturalquestions-validation-7278", "mrqa_naturalquestions-validation-5590", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-2884", "mrqa_naturalquestions-validation-4751", "mrqa_naturalquestions-validation-7858", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-8175", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-2272", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-2893", "mrqa_naturalquestions-validation-10509", "mrqa_naturalquestions-validation-6572"], "SR": 0.609375, "CSR": 0.6322115384615384, "EFR": 0.88, "Overall": 0.6780673076923076}, {"timecode": 78, "before_eval_results": {"predictions": ["Oxygen therapy", "650", "The 17th century Royal Ujazd\u00f3w Castle", "Newcastle Mela", "President Grover Cleveland", "secular powers", "William Maclure", "Bolshevik leaders", "increased trade with poor countries and the fragmentation of the means of production", "13 June 1525", "Philip Howard", "negative long-term impact on the health", "Freeview", "Joie de vivre", "Rama, the legendary prince of the Kosala Kingdom", "Britain", "the New York Yankees", "Andrea Brooks", "Jyotirindra Basu", "Benjamin Franklin", "volume ratio", "January 1, 1976", "18", "George Strait", "Ray Charles", "altitude", "Macintosh X 10.0", "Speaker of the House of Representatives", "Roman Reigns", "Charles Dickens's novel Oliver Twist", "eight", "Staci Keanan", "10th century", "R.E.M.", "Texhoma", "late - 17th century New England", "Cress", "the most expensive animal products consumed by humans", "average adult brain volume of 1260 cubic centimeters ( cm ) for men and 1130 cm for women", "October 27, 1904", "along a bridge over the Merderet in the fictional town of Ramelle", "Emmanuelle Chriqui", "Columbia River Gorge in the U.S. states of Oregon and Washington", "The last twenty - five years", "Jerry Houser", "St. John's, Newfoundland and Labrador", "the New England Patriots", "Kennedy Space Center ( KSC ) in Florida", "August 6 and 9, 1945", "2011 during the eighth series of the UK version of The X Factor", "Jason Marsden", "October 22, 2017", "beloved", "1989", "1973", "B.R. Ambedkar", "Stephen Graham", "Nalini Negi", "1960", "2017", "2018 sequel to the anime television series Beyblade Burst", "New York City", "Eddie Murphy", "in the middle of the 15th century, in Yemen's Sufi monasteries"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7658324442102016}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.8750000000000001, 1.0, 0.4615384615384615, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.9090909090909091, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.3636363636363636]}}, "before_error_ids": ["mrqa_squad-validation-722", "mrqa_squad-validation-7535", "mrqa_squad-validation-2277", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-435", "mrqa_naturalquestions-validation-3121", "mrqa_naturalquestions-validation-8767", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-4026", "mrqa_naturalquestions-validation-4114", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-5651", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-10248", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-6137", "mrqa_naturalquestions-validation-4134"], "SR": 0.671875, "CSR": 0.6327136075949367, "EFR": 0.8571428571428571, "Overall": 0.6735962929475587}, {"timecode": 79, "before_eval_results": {"predictions": ["the second half of the 20th Century", "between June and September", "1926", "three", "Articles 106 and 107", "27 August 2010", "exceeds any given number", "1526", "deforestation", "Methodist institutions", "the North Sea, through the former Meuse estuary, near Rotterdam", "34 million years", "one MSP", "Kusha", "Kate '' Mulgrew", "Representatives", "a 1945 NCAA game between Columbia and Fordham", "between the stomach and the large intestine", "1960", "a federal structure to the Republic of India, declaring it to be a `` Union of States ''", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "Erika Mitchell Leonard", "Lady Gaga", "216", "Aegisthus", "Karan Johar and Rohit Shetty", "15,000 years ago", "The Intolerable Acts", "seven", "Cyanea capillata", "wintertime", "the name of a work gang", "Ed Sheeran", "alveolar process", "Tim Russert", "all four wheels, but may not be designed for off - road use", "show me the feeling I need to walk with / Tell me why I can't be there where you are / There's something missing in my heart", "Joie de vivre", "Bob Dylan", "All Saints", "Isabela Moner", "since 1981", "a tradition in brass band parades in New Orleans, Louisiana", "usually 60 days after claiming the ticket", "on a beach in Malibu, California", "1,387 mi", "ambiguous", "the government - owned Panama Canal Authority", "Pflugerville", "Mutt Lange", "in the 1820s", "the downfall of the fascist government in Italy and the elimination of Germany's main European ally", "to express complete surprise, amazement or disbelief", "a brain region that in humans is located in the dorsal portion of the frontal lobe", "in the United Kingdom in 1974", "Chandan Shetty", "Juan Francisco Ochoa", "arose separately in England and Wales", "623", "Thomas Middleditch", "1 mile", "Ali Daei", "Andy Serkis", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6423513475903182}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.0, 0.20000000000000004, 1.0, 0.1111111111111111, 1.0, 0.35294117647058826, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.058823529411764705, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.11764705882352941, 0.0, 0.5714285714285715, 0.0, 0.0, 0.3846153846153846, 1.0, 0.0, 0.6666666666666666, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4615384615384615]}}, "before_error_ids": ["mrqa_squad-validation-9319", "mrqa_naturalquestions-validation-3163", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-1018", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-6490", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-10118", "mrqa_naturalquestions-validation-2606", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-335", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-9135", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-390"], "SR": 0.53125, "CSR": 0.6314453125, "EFR": 1.0, "Overall": 0.7019140625}, {"timecode": 80, "UKR": 0.712890625, "OKR_sampled_ids": ["mrqa_squad-validation-4750", "mrqa_naturalquestions-validation-6040", "mrqa_squad-validation-1577", "mrqa_naturalquestions-validation-1611", "mrqa_squad-validation-9422", "mrqa_squad-validation-2018", "mrqa_squad-validation-9953", "mrqa_squad-validation-8384", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-9185", "mrqa_squad-validation-4132", "mrqa_squad-validation-7800", "mrqa_squad-validation-6213", "mrqa_squad-validation-4952", "mrqa_naturalquestions-validation-7538", "mrqa_squad-validation-641", "mrqa_squad-validation-1491", "mrqa_naturalquestions-validation-4720", "mrqa_naturalquestions-validation-1052", "mrqa_squad-validation-7080", "mrqa_naturalquestions-validation-4890", "mrqa_squad-validation-6182", "mrqa_squad-validation-7437", "mrqa_squad-validation-8329", "mrqa_naturalquestions-validation-4561", "mrqa_squad-validation-5545", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-2305", "mrqa_squad-validation-5654", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-5374", "mrqa_squad-validation-3159", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-13", "mrqa_naturalquestions-validation-1000", "mrqa_squad-validation-2455", "mrqa_naturalquestions-validation-9830", "mrqa_squad-validation-4076", "mrqa_naturalquestions-validation-7108", "mrqa_squad-validation-7211", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8849", "mrqa_squad-validation-3373", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-1640", "mrqa_squad-validation-1877", "mrqa_squad-validation-6711", "mrqa_squad-validation-7251", "mrqa_squad-validation-6717", "mrqa_naturalquestions-validation-7114", "mrqa_squad-validation-5861", "mrqa_naturalquestions-validation-1429", "mrqa_naturalquestions-validation-1819", "mrqa_naturalquestions-validation-3945", "mrqa_squad-validation-4791", "mrqa_squad-validation-3176", "mrqa_squad-validation-8983", "mrqa_naturalquestions-validation-2629", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-8251", "mrqa_squad-validation-1907", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-814", "mrqa_squad-validation-6403", "mrqa_squad-validation-2099", "mrqa_squad-validation-8875", "mrqa_squad-validation-924", "mrqa_squad-validation-7871", "mrqa_naturalquestions-validation-3422", "mrqa_squad-validation-7949", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-9005", "mrqa_squad-validation-1194", "mrqa_naturalquestions-validation-10159", "mrqa_squad-validation-6210", "mrqa_squad-validation-5603", "mrqa_squad-validation-3333", "mrqa_squad-validation-9809", "mrqa_naturalquestions-validation-8417", "mrqa_squad-validation-6726", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-1755", "mrqa_squad-validation-8756", "mrqa_squad-validation-5649", "mrqa_naturalquestions-validation-4459", "mrqa_squad-validation-9170", "mrqa_squad-validation-7107", "mrqa_squad-validation-5483", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-31", "mrqa_naturalquestions-validation-4437", "mrqa_naturalquestions-validation-7321", "mrqa_squad-validation-6343", "mrqa_naturalquestions-validation-1084", "mrqa_squad-validation-5051", "mrqa_squad-validation-2488", "mrqa_squad-validation-3567", "mrqa_squad-validation-7374", "mrqa_squad-validation-5644", "mrqa_naturalquestions-validation-8404", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-9675", "mrqa_squad-validation-9074", "mrqa_naturalquestions-validation-2644", "mrqa_squad-validation-7421", "mrqa_squad-validation-4817", "mrqa_squad-validation-9375", "mrqa_squad-validation-6883", "mrqa_squad-validation-5481", "mrqa_naturalquestions-validation-8270", "mrqa_naturalquestions-validation-5040", "mrqa_squad-validation-883", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-5790", "mrqa_squad-validation-2754", "mrqa_naturalquestions-validation-9908", "mrqa_squad-validation-3340", "mrqa_naturalquestions-validation-9660", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7468", "mrqa_squad-validation-7646", "mrqa_naturalquestions-validation-6140", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-3860", "mrqa_squad-validation-1026", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-3119", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5006", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-7577", "mrqa_squad-validation-8012", "mrqa_naturalquestions-validation-7564", "mrqa_naturalquestions-validation-8781", "mrqa_naturalquestions-validation-4026", "mrqa_naturalquestions-validation-9897", "mrqa_squad-validation-2424", "mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-8612", "mrqa_squad-validation-6719", "mrqa_squad-validation-351", "mrqa_squad-validation-5364", "mrqa_squad-validation-8059", "mrqa_squad-validation-6958", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-3558", "mrqa_squad-validation-9483", "mrqa_naturalquestions-validation-4628", "mrqa_naturalquestions-validation-6052", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-9511", "mrqa_naturalquestions-validation-5531", "mrqa_squad-validation-10165", "mrqa_squad-validation-5769", "mrqa_squad-validation-6201", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6041", "mrqa_naturalquestions-validation-9273", "mrqa_squad-validation-4221", "mrqa_naturalquestions-validation-4341", "mrqa_squad-validation-1287", "mrqa_squad-validation-9165", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-3783", "mrqa_squad-validation-3839", "mrqa_naturalquestions-validation-681", "mrqa_squad-validation-4029", "mrqa_naturalquestions-validation-6093", "mrqa_squad-validation-6313", "mrqa_naturalquestions-validation-9642", "mrqa_squad-validation-6195", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8795", "mrqa_squad-validation-2096", "mrqa_squad-validation-6010", "mrqa_squad-validation-1998", "mrqa_naturalquestions-validation-3710", "mrqa_naturalquestions-validation-8541", "mrqa_squad-validation-5491", "mrqa_naturalquestions-validation-9299", "mrqa_squad-validation-8691", "mrqa_squad-validation-646", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-8317", "mrqa_squad-validation-4293", "mrqa_squad-validation-4185", "mrqa_squad-validation-2621", "mrqa_naturalquestions-validation-473", "mrqa_squad-validation-2353", "mrqa_squad-validation-2235", "mrqa_squad-validation-8072", "mrqa_squad-validation-579", "mrqa_squad-validation-9097", "mrqa_squad-validation-4337", "mrqa_naturalquestions-validation-8995", "mrqa_squad-validation-3642", "mrqa_squad-validation-40", "mrqa_naturalquestions-validation-1246", "mrqa_squad-validation-6945", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-599", "mrqa_squad-validation-10228", "mrqa_squad-validation-4442", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-7499", "mrqa_squad-validation-2368", "mrqa_squad-validation-847", "mrqa_naturalquestions-validation-2304", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-8216", "mrqa_squad-validation-10453", "mrqa_naturalquestions-validation-7425", "mrqa_squad-validation-4822", "mrqa_squad-validation-1975", "mrqa_naturalquestions-validation-9836", "mrqa_squad-validation-7823", "mrqa_naturalquestions-validation-7859", "mrqa_squad-validation-2448", "mrqa_squad-validation-1231", "mrqa_naturalquestions-validation-4728", "mrqa_naturalquestions-validation-4922", "mrqa_squad-validation-9066", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-9752", "mrqa_squad-validation-1329", "mrqa_squad-validation-2998", "mrqa_squad-validation-8247", "mrqa_naturalquestions-validation-2206", "mrqa_squad-validation-1430", "mrqa_naturalquestions-validation-7065", "mrqa_naturalquestions-validation-94", "mrqa_naturalquestions-validation-4640", "mrqa_naturalquestions-validation-4249", "mrqa_squad-validation-6793", "mrqa_squad-validation-5803", "mrqa_squad-validation-6386", "mrqa_squad-validation-10175", "mrqa_naturalquestions-validation-1026", "mrqa_squad-validation-811", "mrqa_squad-validation-8749", "mrqa_squad-validation-3163", "mrqa_squad-validation-10340", "mrqa_squad-validation-5836", "mrqa_naturalquestions-validation-4647", "mrqa_squad-validation-8767", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-1729", "mrqa_naturalquestions-validation-5900", "mrqa_squad-validation-6569", "mrqa_squad-validation-2", "mrqa_squad-validation-6134", "mrqa_naturalquestions-validation-6278", "mrqa_naturalquestions-validation-6584", "mrqa_squad-validation-2919", "mrqa_squad-validation-3057", "mrqa_squad-validation-7321", "mrqa_naturalquestions-validation-5817", "mrqa_squad-validation-10136", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-1067", "mrqa_squad-validation-1948", "mrqa_naturalquestions-validation-1901", "mrqa_naturalquestions-validation-1592", "mrqa_squad-validation-918", "mrqa_squad-validation-5101", "mrqa_naturalquestions-validation-7853", "mrqa_squad-validation-4834", "mrqa_squad-validation-7863", "mrqa_naturalquestions-validation-340", "mrqa_squad-validation-10393", "mrqa_squad-validation-6480", "mrqa_naturalquestions-validation-8958", "mrqa_squad-validation-4023", "mrqa_naturalquestions-validation-578", "mrqa_squad-validation-9572", "mrqa_naturalquestions-validation-5219", "mrqa_naturalquestions-validation-578", "mrqa_squad-validation-4095", "mrqa_squad-validation-5405", "mrqa_squad-validation-32", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-3353", "mrqa_squad-validation-8667", "mrqa_squad-validation-7044", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-4432", "mrqa_squad-validation-557", "mrqa_naturalquestions-validation-1089", "mrqa_squad-validation-1395", "mrqa_squad-validation-6897", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-3469", "mrqa_squad-validation-9326", "mrqa_squad-validation-3349", "mrqa_squad-validation-4789", "mrqa_squad-validation-2147", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-9778", "mrqa_naturalquestions-validation-3902", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-5034", "mrqa_naturalquestions-validation-669", "mrqa_naturalquestions-validation-8907", "mrqa_squad-validation-7487", "mrqa_squad-validation-4934", "mrqa_naturalquestions-validation-2350", "mrqa_squad-validation-10402", "mrqa_naturalquestions-validation-177", "mrqa_squad-validation-9695", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-5483", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-4455", "mrqa_squad-validation-5530", "mrqa_naturalquestions-validation-8781", "mrqa_squad-validation-5824", "mrqa_naturalquestions-validation-734", "mrqa_squad-validation-9442", "mrqa_naturalquestions-validation-6787", "mrqa_squad-validation-5389", "mrqa_squad-validation-187", "mrqa_squad-validation-6481", "mrqa_naturalquestions-validation-8485", "mrqa_squad-validation-8691", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-1704", "mrqa_squad-validation-7745", "mrqa_squad-validation-2579", "mrqa_naturalquestions-validation-9857", "mrqa_naturalquestions-validation-6624", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-4401", "mrqa_naturalquestions-validation-4523", "mrqa_squad-validation-3888", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-9741", "mrqa_squad-validation-8899", "mrqa_squad-validation-6219", "mrqa_squad-validation-3965", "mrqa_squad-validation-5289", "mrqa_squad-validation-8906", "mrqa_squad-validation-3942", "mrqa_naturalquestions-validation-1385", "mrqa_squad-validation-4331", "mrqa_squad-validation-8621", "mrqa_squad-validation-9208", "mrqa_squad-validation-6773", "mrqa_naturalquestions-validation-3121", "mrqa_squad-validation-6091", "mrqa_squad-validation-9103", "mrqa_naturalquestions-validation-4847", "mrqa_squad-validation-978", "mrqa_squad-validation-9923", "mrqa_naturalquestions-validation-10070", "mrqa_squad-validation-557", "mrqa_squad-validation-2799", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-10135", "mrqa_squad-validation-7173", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-3550", "mrqa_squad-validation-5838", "mrqa_naturalquestions-validation-4278", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5791", "mrqa_naturalquestions-validation-6021", "mrqa_squad-validation-1881", "mrqa_squad-validation-8186", "mrqa_squad-validation-9651", "mrqa_squad-validation-4245", "mrqa_squad-validation-4573", "mrqa_squad-validation-864", "mrqa_naturalquestions-validation-10537", "mrqa_squad-validation-2409", "mrqa_squad-validation-2072", "mrqa_squad-validation-3876", "mrqa_naturalquestions-validation-6832", "mrqa_squad-validation-2406", "mrqa_squad-validation-3602", "mrqa_squad-validation-64", "mrqa_squad-validation-6282", "mrqa_squad-validation-5679", "mrqa_squad-validation-5536", "mrqa_naturalquestions-validation-6698", "mrqa_squad-validation-1662", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-629", "mrqa_squad-validation-3368", "mrqa_squad-validation-1367", "mrqa_naturalquestions-validation-4554", "mrqa_squad-validation-9381", "mrqa_squad-validation-9453", "mrqa_naturalquestions-validation-10098", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-7077", "mrqa_naturalquestions-validation-1091", "mrqa_squad-validation-5936", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-6765", "mrqa_squad-validation-5584", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-6466", "mrqa_squad-validation-626", "mrqa_squad-validation-5742", "mrqa_squad-validation-1753", "mrqa_squad-validation-2156", "mrqa_squad-validation-6048", "mrqa_squad-validation-4698", "mrqa_naturalquestions-validation-53", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-8911", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-5921", "mrqa_squad-validation-7194", "mrqa_squad-validation-1170", "mrqa_squad-validation-9480", "mrqa_squad-validation-1603", "mrqa_naturalquestions-validation-5905", "mrqa_naturalquestions-validation-6326", "mrqa_squad-validation-1136", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-9966", "mrqa_squad-validation-64", "mrqa_squad-validation-4730", "mrqa_squad-validation-3716", "mrqa_naturalquestions-validation-4868", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-8036", "mrqa_squad-validation-567", "mrqa_naturalquestions-validation-9571", "mrqa_squad-validation-6217", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-3616", "mrqa_naturalquestions-validation-9961", "mrqa_squad-validation-4806", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-6678", "mrqa_squad-validation-1498", "mrqa_naturalquestions-validation-8883", "mrqa_naturalquestions-validation-4018", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-337", "mrqa_squad-validation-6607", "mrqa_squad-validation-5573", "mrqa_naturalquestions-validation-5394", "mrqa_squad-validation-5052", "mrqa_naturalquestions-validation-8962", "mrqa_naturalquestions-validation-1404", "mrqa_squad-validation-2173", "mrqa_squad-validation-880", "mrqa_squad-validation-1704", "mrqa_squad-validation-5011", "mrqa_naturalquestions-validation-993", "mrqa_naturalquestions-validation-9342", "mrqa_squad-validation-3519", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-5096", "mrqa_squad-validation-2862", "mrqa_naturalquestions-validation-10303", "mrqa_naturalquestions-validation-4286", "mrqa_squad-validation-8034", "mrqa_squad-validation-7219", "mrqa_naturalquestions-validation-3959", "mrqa_squad-validation-3394", "mrqa_squad-validation-9590", "mrqa_squad-validation-6073", "mrqa_squad-validation-222", "mrqa_squad-validation-7022", "mrqa_naturalquestions-validation-5497", "mrqa_squad-validation-8329", "mrqa_squad-validation-3104", "mrqa_squad-validation-9679", "mrqa_naturalquestions-validation-4388", "mrqa_naturalquestions-validation-7741", "mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-1569", "mrqa_squad-validation-5613", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-379", "mrqa_squad-validation-4927", "mrqa_naturalquestions-validation-3895", "mrqa_squad-validation-6367", "mrqa_naturalquestions-validation-3623"], "OKR": 0.8203125, "KG": 0.346875, "before_eval_results": {"predictions": ["Norway", "Robert Nozick", "The objective is typically a course of study, lesson plan, or a practical skill", "confrontational", "Tehachapis", "Blaydon Race", "river Aare", "Adaptive (or acquired) immunity creates immunological memory after an initial response to a specific pathogen, leading to an enhanced response to subsequent encounters with that same pathogen", "slash and burn", "antagonistic", "in the possession of already-wealthy individuals or entities", "Baiju", "radio network", "1995", "Christopher Allen Lloyd ( born October 22, 1938 )", "Aristotle", "septum", "chain elongation", "Kepner", "Confederate States of America ( Confederacy )", "beloved religious leaders", "Haliaeetus", "Dougie MacLean", "Claims adjuster", "changes in the earth's polarity", "Warren Zevon", "103", "Bartolomeu Dias", "James Ray", "Joseph Stalin", "a permanent, fast - drying painting medium consisting of colored pigments mixed with a water - soluble binder medium ( usually glutinous material such as egg yolk or some other size )", "Twickenham and the Millennium Stadium", "England and Wales", "Super Bowl LII", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "around 4500 BC", "Hold On", "the season seven episode `` Fierce ''", "Middle Eastern alchemy", "October 1986", "under `` the immortal Hawke ''", "Georges Auguste Escoffier", "computers or in an organised paper filing system", "Buffalo Bill", "1997", "from A to B", "Skat", "20 November 1989", "the churches of Galatia", "people of France", "all of the British colonies of North America", "Steve Hale ( who was first introduced in the season five episode `` Sisters in Crime '' )", "a solid ball with a radius of about 1,220 kilometres ( 760 miles ), which is about 70 % of the Moon's radius", "1881 and 1885", "Jessica Simpson", "Proposition 103 in 1988", "Randy Newman", "action formed as an abbreviation from the initial components in a phrase or a word", "seven", "The genome", "Munich, Bavaria", "action utility vehicles", "Peter Gardner Ostrum ( / \u02c8o\u028astr\u0259m / ; born November 1957 )", "October 2008"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7797612998451413}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7317073170731707, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.2666666666666667, 0.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1844", "mrqa_squad-validation-6449", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-1213", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-10403", "mrqa_naturalquestions-validation-8610", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5048", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-6984", "mrqa_naturalquestions-validation-4308", "mrqa_naturalquestions-validation-9098"], "SR": 0.703125, "CSR": 0.6323302469135803, "EFR": 1.0, "Overall": 0.702481674382716}, {"timecode": 81, "before_eval_results": {"predictions": ["aldehydes (R-CO-H)", "Ben Johnston", "modern", "Robert Boyle", "political", "Kalka River", "long-run economic growth", "European Union law", "Westinghouse", "270,000", "HAM ABC", "Victorian architecture", "the 1960s", "March 11, 2018", "Kaley Christine Cuoco", "three", "The `` Southern Cause ''", "Natalie Portman", "Wednesday, 5 September 1666", "Montreal", "what builds nations'wealth", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew", "Freddie Highmore", "detritus", "that country's surprise attack on Pearl Harbor", "California", "November 17, 2017", "the British East India company to sell tea from China in American colonies without paying any taxes", "quantitative", "the person compelled to pay for reformist programs", "332", "St. Ignatius of Loyola", "1988", "Tom\u00e1s de Torquemada", "the pituitary gland", "Phil Simms", "Ulbricht", "duodenum by enterocytes of the duodenal lining", "Justin Timberlake", "Helena", "908 mbar", "won", "information can be read by anyone able to perform packet capture ( sniffing ) on the network", "Rogue permanently absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "In the television series's fourth season", "Walter Egan", "September 6, 2019", "Colon Street", "the early 20th century", "Those not fit to enter heaven", "the Gupta kings", "Arthur Chung", "Buckwheat Boyz", "revenge and karma", "introverted Sensing ( Si )", "starch", "capillata", "Roger Dean Stadium", "1916", "help bring creative projects to life", "Billy Idol", "Cairo, Illinois", "Idaho", "the 1979 -- 80 season"], "metric_results": {"EM": 0.625, "QA-F1": 0.7190190839861892}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-3655", "mrqa_squad-validation-1566", "mrqa_squad-validation-1369", "mrqa_squad-validation-6094", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8338", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-642", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10001", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-5497", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-8404", "mrqa_naturalquestions-validation-91", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-7376"], "SR": 0.625, "CSR": 0.6322408536585367, "EFR": 0.875, "Overall": 0.6774637957317073}, {"timecode": 82, "before_eval_results": {"predictions": ["successfully preventing it from being cut down", "Lady Gaga", "two", "in the Small Catechism", "-40%", "recast", "a majority of all MEPs (not just those present)", "Thuringia", "computer time-sharing service", "5 million", "shipping", "mechanical energy with minimal loss over any terrestrial distance", "Speaker of the House of Representatives", "`` Killer Within ''", "SURFACE AREA OF ROOTS", "Yuzuru Hanyu", "1959", "bullets discharged into the air fall back down to the ground", "2013", "Games ( AKA `` appearances '' )", "Robin", "Mustafa Ali", "2018", "May 31, 2012", "Gary Speed", "the Pir Panjal Range in Jammu and Kashmir", "Dirk Benedict", "unknown recipient", "pH ( / pi\u02d0\u02c8e\u026at\u0283 / ) ( potential of hydrogen )", "Joseph Heller", "1980", "1820s", "Yuzuru Hanyu", "septum", "1799", "Number 4, Privet Drive, Little Whinging in Surrey, England", "Alan Shearer", "the English rock band the Outfield", "master carpenter Anthony Mayfield", "Rob Kerkovich", "diastema ( plural diastemata )", "Nicki Minaj", "3D modeling ( or three - dimensional modeling )", "1976", "Human fertilization", "the King James Bible of the biblical phrase in saecula saeculorum in Ephesians 3 : 21", "into the bloodstream", "Abid Ali Neemuchwala", "biocidal effect of metals", "Abid Ali Neemuchwala", "The Cornett family", "Internal epithelia", "Raza Jaffrey", "the breast or lower chest", "Michael Phelps", "16,801 students", "1986", "Muhammad", "in Poems : Series 1", "Roanoke", "Zeebo", "a combination of genetics and the male hormone dihydrotestosterone", "till September", "carbon dioxide"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7802575029137528}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.18181818181818182, 1.0, 0.25, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3076923076923077, 0.4, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-223", "mrqa_squad-validation-2415", "mrqa_squad-validation-7445", "mrqa_squad-validation-1649", "mrqa_squad-validation-4079", "mrqa_squad-validation-4837", "mrqa_squad-validation-1495", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-744", "mrqa_naturalquestions-validation-6588", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-2026", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-375", "mrqa_naturalquestions-validation-8391"], "SR": 0.703125, "CSR": 0.6330948795180723, "EFR": 0.9473684210526315, "Overall": 0.6921082851141407}, {"timecode": 83, "before_eval_results": {"predictions": ["by 2100", "5.3%", "The cytokCLADES packet switching network", "circa 1964\u20131965", "Jurassic Period", "Eldon Square Shopping Centre", "primality", "those who already hold wealth", "1978", "Wellington", "Time magazine", "idealized point particles", "August 22, 1980", "to negotiate more favorable terms and is thus placed in a `` take it or leave it '' position", "frontal lobe", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media", "232", "mayonnaise", "two", "Tiber", "International Baccalaureate ( IB )", "Yuzuru Hanyu", "absolute", "New England Patriots", "since 3, 1, and 4", "The Saint of Killers", "Hook", "Shastri", "The Sun", "roughly 78 %", "Pathuscs, roundworms, ringed worms, flatworms, and other phyla in Ecdysozoa and Spiralia", "1928", "ATP hydrolysis", "2017", "Andaman and Nicobar Islands -- Port Blair", "The Drew Las Vegas", "2009", "Balaam ( Numbers 22 : 28 )", ". java", "Qualitative psychological research", "Einstein", "1920 play R.U.R. by the Czech writer, Karel \u010capek", "Young failed to show up for filming an episode of Rizzoli & Isles", "over 74", "south coast of eastern New Guinea, thereby including the Gulf of Papua", "Italy", "Martin Lawrence", "David Ben - Gurion", "chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Narendra Modi", "Edgar Lungu", "April 6, 1917", "federal republic", "the Michael Douglas film, The Jewel of the Nile, the sequel to the hit blockbuster film, Romancing the Stone", "Buffalo Bill", "March 31, 2013", "the cavities and surfaces of blood vessels and organs throughout the body", "Randy Newman", "Psychomachia, '' an epic poem written in the fifth century", "novella", "1983", "Bennett Cerf", "Dorothy Gale", "James Intveld"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7821056547619047}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4784", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-4729", "mrqa_naturalquestions-validation-7015", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-5104", "mrqa_naturalquestions-validation-10015", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-6854", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-407", "mrqa_naturalquestions-validation-2688"], "SR": 0.71875, "CSR": 0.6341145833333333, "EFR": 0.9444444444444444, "Overall": 0.6917274305555555}, {"timecode": 84, "before_eval_results": {"predictions": ["Kaifeng", "the 1978 Supreme Court case of FCC v. Pacifica Foundation", "third", "39", "16,000 rpm", "The Saturn IB", "heart", "June 4, 2014", "the SPM is agreed upon by delegates from many of the world's governments", "present-day Upstate New York and the Ohio Country", "British patrons", "Newton", "arose separately in England and Wales", "2011", "Firoz Shah Tughlaq", "Oona Castilla Chaplin", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "any unfavourable and unintended sign ( including an abnormal laboratory finding ), symptom, or disease temporally associated with the use of a medicinal ( investigational ) product, whether or not related to the medicinal", "Paradise, Nevada", "a violation of nature and the resulting psychological effects", "Supplemental oxygen", "282,846", "Kevin Spacey", "the 15th century", "1648 - 51", "a post as a Consultant, a General Practitioner ( GP ), or some other non-training post, such as a Staff grade or Associate Specialist post", "the inner wall of the pedestal", "pia mater", "East Redbud", "Dirk Benedict", "an undisclosed location", "in the pouring rain", "Kid Creole and the Coconuts", "attack on Pearl Harbor", "American swimmer Michael Phelps", "greater the vapor pressure of a liquid at a given temperature", "Colman", "a firm, flexible bell - shaped device worn inside the vagina to collect menstrual flow", "AD 95 -- 110", "a Border Collie", "May 18, 2010", "A simple majority", "Kenny Rogers and The First Edition", "The Republic of Tecala", "the heads of federal executive departments who form the Cabinet of the United States", "Manchuria", "Chlorofluorocarbons", "New Mexico", "American singer Selena Gomez", "14 \u00b0 41 \u2032 34", "Bay of Montevideo", "1920", "775", "May 12", "Sally Field", "the problems", "2001", "switchback", "a type of heavy metal, which emphasized volume, power, and speed", "W. Edwards Deming", "February 9, 2018", "Phillip Paley", "Anna Faris", "ecological regions"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7880936694630427}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352942, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.962962962962963, 0.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9268292682926829, 0.888888888888889, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.875, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8559", "mrqa_naturalquestions-validation-10509", "mrqa_naturalquestions-validation-6597", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-4637", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-9903", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-2400", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-2740", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2588", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-1941"], "SR": 0.6875, "CSR": 0.6347426470588236, "EFR": 0.9, "Overall": 0.6829641544117646}, {"timecode": 85, "UKR": 0.712890625, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-5048", "mrqa_squad-validation-3948", "mrqa_naturalquestions-validation-1214", "mrqa_squad-validation-9391", "mrqa_naturalquestions-validation-5943", "mrqa_squad-validation-1815", "mrqa_naturalquestions-validation-7893", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-5590", "mrqa_naturalquestions-validation-6093", "mrqa_naturalquestions-validation-3668", "mrqa_squad-validation-9812", "mrqa_squad-validation-4023", "mrqa_naturalquestions-validation-4593", "mrqa_squad-validation-8595", "mrqa_naturalquestions-validation-923", "mrqa_squad-validation-557", "mrqa_naturalquestions-validation-7885", "mrqa_squad-validation-5012", "mrqa_naturalquestions-validation-7889", "mrqa_naturalquestions-validation-2889", "mrqa_squad-validation-1245", "mrqa_naturalquestions-validation-4286", "mrqa_naturalquestions-validation-872", "mrqa_squad-validation-9750", "mrqa_naturalquestions-validation-1430", "mrqa_squad-validation-9263", "mrqa_squad-validation-6253", "mrqa_squad-validation-5694", "mrqa_naturalquestions-validation-8531", "mrqa_squad-validation-2530", "mrqa_naturalquestions-validation-2524", "mrqa_squad-validation-2", "mrqa_naturalquestions-validation-4247", "mrqa_squad-validation-6526", "mrqa_naturalquestions-validation-8182", "mrqa_squad-validation-7517", "mrqa_squad-validation-6267", "mrqa_naturalquestions-validation-9306", "mrqa_naturalquestions-validation-1018", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-9430", "mrqa_squad-validation-6668", "mrqa_squad-validation-3368", "mrqa_naturalquestions-validation-8728", "mrqa_squad-validation-5499", "mrqa_squad-validation-8228", "mrqa_naturalquestions-validation-4197", "mrqa_squad-validation-9066", "mrqa_squad-validation-803", "mrqa_squad-validation-1180", "mrqa_naturalquestions-validation-9390", "mrqa_squad-validation-5703", "mrqa_naturalquestions-validation-1567", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-9249", "mrqa_squad-validation-7382", "mrqa_squad-validation-6420", "mrqa_squad-validation-7321", "mrqa_squad-validation-10054", "mrqa_squad-validation-1858", "mrqa_naturalquestions-validation-1539", "mrqa_squad-validation-6146", "mrqa_naturalquestions-validation-47", "mrqa_squad-validation-297", "mrqa_squad-validation-9969", "mrqa_squad-validation-468", "mrqa_squad-validation-9453", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-3319", "mrqa_squad-validation-132", "mrqa_squad-validation-9446", "mrqa_squad-validation-6992", "mrqa_naturalquestions-validation-10218", "mrqa_squad-validation-4121", "mrqa_squad-validation-4431", "mrqa_squad-validation-8472", "mrqa_squad-validation-9180", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-9563", "mrqa_naturalquestions-validation-5152", "mrqa_squad-validation-7088", "mrqa_naturalquestions-validation-6556", "mrqa_squad-validation-7792", "mrqa_naturalquestions-validation-3648", "mrqa_naturalquestions-validation-230", "mrqa_squad-validation-10377", "mrqa_squad-validation-10007", "mrqa_naturalquestions-validation-6856", "mrqa_squad-validation-5688", "mrqa_naturalquestions-validation-495", "mrqa_squad-validation-202", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-4871", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-4879", "mrqa_squad-validation-7414", "mrqa_squad-validation-8242", "mrqa_squad-validation-8877", "mrqa_naturalquestions-validation-2023", "mrqa_squad-validation-7515", "mrqa_squad-validation-6313", "mrqa_naturalquestions-validation-1592", "mrqa_squad-validation-256", "mrqa_naturalquestions-validation-10285", "mrqa_squad-validation-5988", "mrqa_naturalquestions-validation-9992", "mrqa_squad-validation-3674", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-1939", "mrqa_naturalquestions-validation-9979", "mrqa_squad-validation-867", "mrqa_squad-validation-5661", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-462", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-7538", "mrqa_naturalquestions-validation-8781", "mrqa_naturalquestions-validation-5638", "mrqa_squad-validation-9494", "mrqa_squad-validation-7832", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-1239", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-642", "mrqa_squad-validation-1727", "mrqa_squad-validation-3477", "mrqa_squad-validation-6428", "mrqa_squad-validation-5916", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-7754", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-4026", "mrqa_naturalquestions-validation-7853", "mrqa_squad-validation-2070", "mrqa_naturalquestions-validation-9908", "mrqa_squad-validation-6376", "mrqa_squad-validation-1764", "mrqa_squad-validation-81", "mrqa_squad-validation-3437", "mrqa_naturalquestions-validation-2665", "mrqa_naturalquestions-validation-7015", "mrqa_squad-validation-7686", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-4741", "mrqa_squad-validation-9082", "mrqa_squad-validation-9928", "mrqa_squad-validation-8524", "mrqa_squad-validation-4070", "mrqa_naturalquestions-validation-3469", "mrqa_squad-validation-316", "mrqa_naturalquestions-validation-6157", "mrqa_squad-validation-8204", "mrqa_squad-validation-1383", "mrqa_naturalquestions-validation-9400", "mrqa_squad-validation-6712", "mrqa_squad-validation-4166", "mrqa_squad-validation-3392", "mrqa_squad-validation-5576", "mrqa_squad-validation-2919", "mrqa_squad-validation-6480", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-6431", "mrqa_squad-validation-8455", "mrqa_naturalquestions-validation-134", "mrqa_naturalquestions-validation-3477", "mrqa_squad-validation-2830", "mrqa_naturalquestions-validation-3404", "mrqa_squad-validation-7446", "mrqa_naturalquestions-validation-6759", "mrqa_squad-validation-2011", "mrqa_squad-validation-7586", "mrqa_squad-validation-6994", "mrqa_squad-validation-4834", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-4090", "mrqa_squad-validation-5564", "mrqa_squad-validation-8230", "mrqa_squad-validation-5528", "mrqa_squad-validation-5633", "mrqa_naturalquestions-validation-171", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-104", "mrqa_naturalquestions-validation-2506", "mrqa_squad-validation-9617", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-9324", "mrqa_squad-validation-1164", "mrqa_naturalquestions-validation-4401", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-7939", "mrqa_squad-validation-4822", "mrqa_squad-validation-7137", "mrqa_naturalquestions-validation-10561", "mrqa_squad-validation-4182", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-955", "mrqa_naturalquestions-validation-4083", "mrqa_naturalquestions-validation-6315", "mrqa_squad-validation-6720", "mrqa_naturalquestions-validation-6214", "mrqa_squad-validation-4354", "mrqa_squad-validation-1184", "mrqa_squad-validation-3695", "mrqa_squad-validation-4287", "mrqa_squad-validation-9266", "mrqa_naturalquestions-validation-4506", "mrqa_squad-validation-6329", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-1376", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-7409", "mrqa_squad-validation-9491", "mrqa_squad-validation-3782", "mrqa_squad-validation-3640", "mrqa_squad-validation-1040", "mrqa_squad-validation-7304", "mrqa_squad-validation-6449", "mrqa_naturalquestions-validation-9571", "mrqa_squad-validation-3849", "mrqa_naturalquestions-validation-10343", "mrqa_naturalquestions-validation-3287", "mrqa_naturalquestions-validation-1704", "mrqa_squad-validation-9921", "mrqa_squad-validation-1537", "mrqa_naturalquestions-validation-10631", "mrqa_squad-validation-6289", "mrqa_squad-validation-6112", "mrqa_squad-validation-4356", "mrqa_naturalquestions-validation-1735", "mrqa_squad-validation-7175", "mrqa_squad-validation-5869", "mrqa_squad-validation-1388", "mrqa_squad-validation-7184", "mrqa_naturalquestions-validation-6021", "mrqa_squad-validation-9290", "mrqa_naturalquestions-validation-2981", "mrqa_squad-validation-7744", "mrqa_naturalquestions-validation-7627", "mrqa_squad-validation-466", "mrqa_squad-validation-10165", "mrqa_squad-validation-6794", "mrqa_squad-validation-10313", "mrqa_squad-validation-7473", "mrqa_naturalquestions-validation-1139", "mrqa_squad-validation-6639", "mrqa_squad-validation-6401", "mrqa_squad-validation-1192", "mrqa_squad-validation-7272", "mrqa_squad-validation-2550", "mrqa_squad-validation-8787", "mrqa_squad-validation-9964", "mrqa_naturalquestions-validation-4426", "mrqa_squad-validation-5547", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-9781", "mrqa_squad-validation-6868", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-7609", "mrqa_squad-validation-10269", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-8889", "mrqa_squad-validation-3147", "mrqa_squad-validation-880", "mrqa_naturalquestions-validation-7201", "mrqa_squad-validation-3716", "mrqa_naturalquestions-validation-1988", "mrqa_naturalquestions-validation-138", "mrqa_squad-validation-5891", "mrqa_naturalquestions-validation-1429", "mrqa_squad-validation-6432", "mrqa_squad-validation-8105", "mrqa_naturalquestions-validation-10416", "mrqa_squad-validation-4728", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-5674", "mrqa_naturalquestions-validation-5539", "mrqa_squad-validation-10228", "mrqa_naturalquestions-validation-2565", "mrqa_squad-validation-8036", "mrqa_squad-validation-1329", "mrqa_squad-validation-5213", "mrqa_squad-validation-6298", "mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-4467", "mrqa_naturalquestions-validation-4855", "mrqa_naturalquestions-validation-5790", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-8016", "mrqa_naturalquestions-validation-4330", "mrqa_squad-validation-150", "mrqa_naturalquestions-validation-5230", "mrqa_squad-validation-7162", "mrqa_squad-validation-3474", "mrqa_squad-validation-1889", "mrqa_squad-validation-6914", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-2650", "mrqa_naturalquestions-validation-6943", "mrqa_squad-validation-5047", "mrqa_squad-validation-4644", "mrqa_squad-validation-1508", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-3061", "mrqa_squad-validation-9179", "mrqa_squad-validation-6312", "mrqa_naturalquestions-validation-1884", "mrqa_squad-validation-1685", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-1067", "mrqa_squad-validation-7034", "mrqa_naturalquestions-validation-9130", "mrqa_squad-validation-7582", "mrqa_squad-validation-9198", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-9715", "mrqa_squad-validation-10362", "mrqa_naturalquestions-validation-1455", "mrqa_squad-validation-126", "mrqa_naturalquestions-validation-7499", "mrqa_naturalquestions-validation-9966", "mrqa_squad-validation-3500", "mrqa_squad-validation-5670", "mrqa_squad-validation-305", "mrqa_squad-validation-6832", "mrqa_naturalquestions-validation-1429", "mrqa_squad-validation-2354", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-3581", "mrqa_squad-validation-8906", "mrqa_naturalquestions-validation-4462", "mrqa_squad-validation-2406", "mrqa_naturalquestions-validation-1340", "mrqa_naturalquestions-validation-4263", "mrqa_squad-validation-119", "mrqa_squad-validation-2334", "mrqa_naturalquestions-validation-9204", "mrqa_squad-validation-7437", "mrqa_squad-validation-9189", "mrqa_squad-validation-7470", "mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-9490", "mrqa_squad-validation-6456", "mrqa_squad-validation-4230", "mrqa_naturalquestions-validation-3094", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-8215", "mrqa_squad-validation-3190", "mrqa_naturalquestions-validation-9961", "mrqa_naturalquestions-validation-8470", "mrqa_squad-validation-2001", "mrqa_squad-validation-10306", "mrqa_naturalquestions-validation-390", "mrqa_squad-validation-864", "mrqa_squad-validation-3862", "mrqa_squad-validation-9493", "mrqa_naturalquestions-validation-9071", "mrqa_squad-validation-9723", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-808", "mrqa_squad-validation-3413", "mrqa_squad-validation-7132", "mrqa_naturalquestions-validation-6483", "mrqa_squad-validation-6134", "mrqa_squad-validation-9076", "mrqa_naturalquestions-validation-4558", "mrqa_naturalquestions-validation-3468", "mrqa_squad-validation-6250", "mrqa_squad-validation-5606", "mrqa_naturalquestions-validation-4890", "mrqa_squad-validation-8187", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-204", "mrqa_squad-validation-543", "mrqa_squad-validation-7445", "mrqa_squad-validation-2283", "mrqa_naturalquestions-validation-4903", "mrqa_squad-validation-744", "mrqa_squad-validation-7111", "mrqa_squad-validation-2044", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-1015", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-993", "mrqa_naturalquestions-validation-5822", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-8298", "mrqa_squad-validation-3994", "mrqa_naturalquestions-validation-3521", "mrqa_squad-validation-3425", "mrqa_naturalquestions-validation-6984", "mrqa_squad-validation-3850", "mrqa_squad-validation-1073", "mrqa_squad-validation-3592", "mrqa_naturalquestions-validation-3391", "mrqa_squad-validation-9587", "mrqa_squad-validation-10350", "mrqa_naturalquestions-validation-3311", "mrqa_squad-validation-1670", "mrqa_naturalquestions-validation-4505", "mrqa_squad-validation-1296", "mrqa_squad-validation-5491", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-581", "mrqa_squad-validation-6092", "mrqa_squad-validation-4543", "mrqa_naturalquestions-validation-7152", "mrqa_naturalquestions-validation-3721", "mrqa_squad-validation-4315", "mrqa_squad-validation-9745", "mrqa_squad-validation-5230", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-10135", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-2333", "mrqa_squad-validation-8059", "mrqa_squad-validation-2810", "mrqa_squad-validation-9956", "mrqa_squad-validation-5168", "mrqa_naturalquestions-validation-1246", "mrqa_squad-validation-7316", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3285", "mrqa_squad-validation-4682", "mrqa_squad-validation-3432", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-6560", "mrqa_naturalquestions-validation-9242", "mrqa_squad-validation-7261", "mrqa_naturalquestions-validation-5431", "mrqa_naturalquestions-validation-6304", "mrqa_naturalquestions-validation-2399", "mrqa_squad-validation-3270", "mrqa_squad-validation-5846", "mrqa_naturalquestions-validation-1223", "mrqa_naturalquestions-validation-1785", "mrqa_squad-validation-8839", "mrqa_squad-validation-2409", "mrqa_squad-validation-2460", "mrqa_naturalquestions-validation-3469", "mrqa_naturalquestions-validation-2670", "mrqa_naturalquestions-validation-6353", "mrqa_squad-validation-2853", "mrqa_squad-validation-6865", "mrqa_naturalquestions-validation-8036", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-1604", "mrqa_naturalquestions-validation-7208", "mrqa_squad-validation-16", "mrqa_naturalquestions-validation-3609", "mrqa_squad-validation-7434", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-25", "mrqa_squad-validation-4095", "mrqa_naturalquestions-validation-6603", "mrqa_naturalquestions-validation-5458", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2133", "mrqa_naturalquestions-validation-1445", "mrqa_squad-validation-9483", "mrqa_squad-validation-7420", "mrqa_squad-validation-5196", "mrqa_squad-validation-3083", "mrqa_squad-validation-4092", "mrqa_naturalquestions-validation-5355", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-6116", "mrqa_squad-validation-7690", "mrqa_naturalquestions-validation-2698", "mrqa_naturalquestions-validation-7115", "mrqa_naturalquestions-validation-2212", "mrqa_squad-validation-3084", "mrqa_naturalquestions-validation-9640", "mrqa_squad-validation-4162", "mrqa_squad-validation-3757", "mrqa_naturalquestions-validation-8238", "mrqa_squad-validation-7013"], "OKR": 0.84375, "before_eval_results": {"predictions": ["at the Moscone Center in San Francisco", "FREZ-noh", "analog and numerical", "The programme is listed in Guinness World Records as the longest-running science fiction television show in the world", "by a majority in Parliament", "the ABC Television Center (now The Prospect Studios)", "By 9000 BP", "low wage", "William the Conqueror", "the Qur'an", "1961", "pulmonary heart disease ( cor pulmonale )", "The NFL owners", "1939", "Windows Easy Transfer", "two", "the rez", "Audrey II", "near Arenosa Creek and Matagorda Bay", "Patris et Filii et Spiritus Sancti", "six", "4 percent cumulative effect", "1 October 2006", "Kathleen Erin Walsh", "a computer program may be executed with the aid of an interpreter", "ten", "Karina Smirnoff", "the mid-10th century BCE", "Emma Watson and Dan Stevens", "the Texas A&M Aggies", "Celtic", "in the five - second film one of Thomas Edison's assistants, Fred Ott", "May 18, 2018", "burning palm leaves from the previous year's Palm Sunday celebrations", "Startup neutron source", "the International Border ( IB )", "Elvis Presley", "Joseph Sherrard Kearns", "6", "a contract between two parties, where the terms and conditions of the contract are set by one of the parties, and the other party has little or no ability to negotiate more favorable terms and is thus placed", "Tommy Lee Jones", "291", "The Pittsburgh Steelers", "a partial - vacuum which reduces heat conduction or convection", "in muscles", "bird nests created by edible - nest swiftlets using solidified saliva", "Jesse Frederick James Conaway", "2018", "May 2010", "The House of Representatives", "a federal republic composed of 50 states, a federal district, five major self - governing territories, and various possessions", "Ella Mitchell", "naos", "Noel Kahn", "Scheria", "the 1960s", "Kenny Chesney", "Kyla Coleman", "Laodicea, near Denizli ( Revelation 3 : 14 - 22 )", "to address a Muslim scholar of Sayyid ( a descendant of Muhammad ) families", "to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "My Summer Story", "under `` the immortal Hawke ''", "Nicholas Sparks"], "metric_results": {"EM": 0.671875, "QA-F1": 0.824184839394792}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2702702702702703, 1.0, 1.0, 0.3076923076923077, 1.0, 0.8421052631578948, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9041095890410958, 1.0, 1.0, 1.0, 0.125, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 0.0, 0.6415094339622641, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-512", "mrqa_squad-validation-7809", "mrqa_squad-validation-4079", "mrqa_squad-validation-5945", "mrqa_squad-validation-9436", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-9885", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-7013", "mrqa_naturalquestions-validation-9896", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-7741", "mrqa_naturalquestions-validation-5885"], "SR": 0.671875, "CSR": 0.6351744186046512, "EFR": 0.7619047619047619, "Overall": 0.6601189611018825}, {"timecode": 86, "before_eval_results": {"predictions": ["2007", "one", "mercantilism", "tentacles", "two thousand", "Teaching", "Baptism", "San Francisco", "Kubiak", "Tyneside flat", "Geordie", "March 23, 2013", "Matt Monro", "1973", "Hanna Alstr\u00f6m", "a U.S. federal statute intended to increase consistency in United States federal sentencing", "the exchange of genetic material between homologous chromosomes that results in recombinant chromosomes during sexual reproduction", "360 members", "stratum lucidum", "adrenal medulla", "fertilization", "the Confederacy", "2002", "Daniel A. Dailey", "Hank J. Deutschendorf", "August 8, 1945", "# 4", "Bart Cummings", "Santa Monica", "2010", "code talkers", "1961", "Thomas Jefferson", "Kiss", "energy loss", "Kyla Pratt", "Franciscan order", "Patrick Walshe", "July 2012", "Germany", "Jonathan Breck", "Eight", "parallax", "the state legislators of Assam", "alternative rock", "103", "it was on this day in 1930 when Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress as opposed to the Dominion status offered by British Regime", "Maurice Lauchner", "Nebuchadnezzar", "phencyclidine and cocaine", "2018", "Indian Standard Time", "the President", "Frankel", "Charlton Heston", "information", "Justin Bieber", "1961", "1984", "2002", "Janie Crawford, an African - American woman in her early forties", "capital and financial markets", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "Tim Allen"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7649824134199134}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2760", "mrqa_squad-validation-252", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-6777", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-6816", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-4496", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-3257", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-4891", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-1534", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-289"], "SR": 0.671875, "CSR": 0.6355962643678161, "EFR": 0.9047619047619048, "Overall": 0.6887747588259441}, {"timecode": 87, "before_eval_results": {"predictions": ["four", "Ali Shariati", "494,665", "1979", "oxygen", "The General Board of Church and Society, and the United Methodist Women", "sugar and oxygen", "60", "50%", "the 1960s", "(~11,700 years ago)", "Yabriskie", "counter clockwise", "1959", "quantitative", "multinational retail corporation", "the season seven episode `` Fierce ''", "If there are no repeated data values", "Cherry Hill", "2007 and 2008", "Blue laws", "Jean - Joseph Benjamin - Constant", "John J. Flanagan", "in the episode `` Kobol's Last Gleaming ''", "1945", "revenge and karma", "St. Louis Cardinals", "Super Bowl LII", "San Francisco, California", "unknown origin", "John Goodman", "Eddie Murphy", "1983", "computers or in an organised paper filing system", "John Smith", "the actors", "legislation passed by the Congress of the United States and its predecessor, the Continental Congress", "1", "1980", "`` White Christmas ''", "in the sequence of pieces of DNA called genes", "94 by 50 feet", "2010", "Aegisthus", "July 22, 2017", "1984", "142,907 residents", "Hollywood Masonic Temple ( now known as the El Capitan Entertainment Centre )", "Joie de vivre", "December 2, 1942", "Stephanie Judith Tanner", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "Crick", "Turducken", "Merry Clayton", "Waylon Jennings", "April 2010", "Mankombu Sambasivan Swaminathan", "Wisconsin", "in the 1830s", "medical care provided on an outpatient basis, including diagnosis, observation, consultation, treatment, intervention, and rehabilitation services", "Locksley Castle was Wardour Castle in Wiltshire", "Ronnie Dyson", "55 -- 69 %"], "metric_results": {"EM": 0.6875, "QA-F1": 0.745995670995671}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8571428571428571, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4759", "mrqa_squad-validation-8728", "mrqa_squad-validation-8490", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-486", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-5283", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-9773", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-4785", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-872", "mrqa_naturalquestions-validation-1015"], "SR": 0.6875, "CSR": 0.6361860795454546, "EFR": 0.8, "Overall": 0.6679403409090909}, {"timecode": 88, "before_eval_results": {"predictions": ["7,000,000", "December 1517", "Muslims in the semu class", "182 million", "Beroe", "Jason Bourne", "Prime numbers", "Francisco de Orellana", "Pathogens can rapidly evolve and adapt", "shamed", "anti-colonial movements", "Costa Rica, Brazil, and the Philippines accounted for nearly one - third of the world's production of pineapples", "Panning", "differential erosion", "The Maidstone Studios in Maidstone, Kent", "in 2007 and 2008", "Elizabeth Dean Lail", "telecommunication services to enterprises and offices", "HTTP / 1.1", "2019", "six", "American country music duo The Bellamy Brothers", "in the inner core", "Kacey Ainsworth", "Numbers 22 : 28", "Herbert Hoover", "Betty", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control ( except perhaps for the implicit threat of a coup d'\u00e9tat or mass insurrection )", "Rufus and Chaka Khan", "Margaery Tyrell", "David Tennant", "Latin liberalia studia", "the season five episode `` Cyborg ''", "Robert Remak", "to describe the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "tissues in the vicinity of the nose", "1830", "to bring, and \u03bd\u03af\u03ba\u03b7, n\u00edk\u00ea, `` victory '', i.e. `` she brings victory ''", "volume", "Tulsa, Oklahoma", "Mulberry Street", "7023239999999999999 \u2660 2.4 \u00d7 10 Hz ( 1 GeV gamma rays ) down to the local plasma frequency of the ionized interstellar medium ( ~ 1 kHz )", "the Michael Douglas film, The Jewel of the Nile, the sequel to the hit blockbuster film, Romancing the Stone", "classical architecture", "`` Something to Sing About ''", "epidermis", "Guant\u00e1namo or GTMO", "Greg Norman", "South Pacific", "her abusive husband", "Instagram", "Bonnie Aarons", "two parties", "Callability", "Crick", "Lykan Hypersport", "epidemiologists attempt to explain the link between health and variables such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Spanish", "a child with Treacher Collins syndrome trying to fit in", "Broken Hill and Sydney", "Whig candidates William Henry Harrison ( the `` hero of Tippecanoe '' ) and John Tyler", "Ravi Shastri", "1919", "consistency"], "metric_results": {"EM": 0.625, "QA-F1": 0.7224053603999739}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4285714285714285, 1.0, 1.0, 0.0, 0.9767441860465117, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4231", "mrqa_squad-validation-608", "mrqa_squad-validation-9046", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-9650", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-2016", "mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-8382", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-9253", "mrqa_naturalquestions-validation-5036", "mrqa_naturalquestions-validation-52", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-10680"], "SR": 0.625, "CSR": 0.636060393258427, "EFR": 0.9583333333333334, "Overall": 0.6995818703183521}, {"timecode": 89, "before_eval_results": {"predictions": ["1702 and 1709", "schools in a country that has the largest adult illiterate population in the world", "in a modern context", "Rugby", "Newcastle Mela", "counterflow", "religious", "The Electronic Frontier Foundation", "Miller", "in March", "high voltage", "2012", "General George Washington", "four", "lacteals", "the end of the nineteenth century", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "Ella Eyre", "silk floss tree", "One Night in the Tropics", "in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Giancarlo Stanton", "around 2011", "Los Angeles Dodgers", "1546", "May 30, 2017", "he was also the highest authority of the Shinto religion", "the actress'audition for the role", "Ben Faulks", "1038", "mashed potato", "the British amusement - park ride of that name", "in 1876", "Kiss", "1 -- 3", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "card verification value code", "routing information base ( RIB )", "digestive systems", "1960", "Bobby Beathard", "acidifying particles and gases", "Gene Barry", "a sociological perspective which developed around the middle of the twentieth century", "lamina dura", "Skat", "Tyrann Devine Mathieu", "a cylinder of glass or plastic that runs along the fiber's length", "Ben Findon", "2013", "the three wise monkeys", "eleven", "Hungary", "human induced greenhouse warming", "Lexie", "James Rodr\u00edguez", "to collect menstrual flow", "stuffing", "Dan Stevens", "fictional elite conservative Vermont boarding school Welton Academy", "January 15, 2007", "1957", "Bonhomme Carnaval", "Victim blaming"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7741753472222221}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.22222222222222218, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 0.21428571428571425, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6977", "mrqa_squad-validation-845", "mrqa_naturalquestions-validation-2414", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8429", "mrqa_naturalquestions-validation-886", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-5214", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-3160", "mrqa_naturalquestions-validation-1450", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-9087", "mrqa_naturalquestions-validation-2830"], "SR": 0.71875, "CSR": 0.6369791666666667, "EFR": 0.8333333333333334, "Overall": 0.6747656249999999}, {"timecode": 90, "UKR": 0.693359375, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-3379", "mrqa_naturalquestions-validation-2400", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10031", "mrqa_squad-validation-132", "mrqa_naturalquestions-validation-6137", "mrqa_naturalquestions-validation-9652", "mrqa_squad-validation-363", "mrqa_naturalquestions-validation-6588", "mrqa_squad-validation-8091", "mrqa_naturalquestions-validation-4855", "mrqa_naturalquestions-validation-6019", "mrqa_squad-validation-1509", "mrqa_squad-validation-1441", "mrqa_squad-validation-8789", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-4166", "mrqa_naturalquestions-validation-4149", "mrqa_squad-validation-1752", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-6330", "mrqa_naturalquestions-validation-3094", "mrqa_squad-validation-820", "mrqa_squad-validation-3640", "mrqa_squad-validation-6951", "mrqa_squad-validation-9292", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-3828", "mrqa_squad-validation-6838", "mrqa_squad-validation-5741", "mrqa_naturalquestions-validation-7211", "mrqa_squad-validation-6685", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-2630", "mrqa_squad-validation-9198", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-6972", "mrqa_squad-validation-2406", "mrqa_squad-validation-6994", "mrqa_squad-validation-1960", "mrqa_squad-validation-9447", "mrqa_squad-validation-5013", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-9003", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-4053", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-4335", "mrqa_squad-validation-10472", "mrqa_squad-validation-9812", "mrqa_naturalquestions-validation-6683", "mrqa_naturalquestions-validation-6166", "mrqa_squad-validation-9074", "mrqa_squad-validation-6116", "mrqa_squad-validation-5545", "mrqa_naturalquestions-validation-3734", "mrqa_squad-validation-1054", "mrqa_squad-validation-633", "mrqa_squad-validation-537", "mrqa_naturalquestions-validation-6947", "mrqa_naturalquestions-validation-9260", "mrqa_squad-validation-9029", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-7350", "mrqa_squad-validation-1910", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-8903", "mrqa_squad-validation-5265", "mrqa_squad-validation-1988", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-2118", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-645", "mrqa_squad-validation-10244", "mrqa_naturalquestions-validation-3199", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-9992", "mrqa_squad-validation-7275", "mrqa_squad-validation-5340", "mrqa_squad-validation-6513", "mrqa_squad-validation-9904", "mrqa_naturalquestions-validation-2080", "mrqa_squad-validation-2378", "mrqa_squad-validation-3948", "mrqa_naturalquestions-validation-4523", "mrqa_naturalquestions-validation-2255", "mrqa_squad-validation-7917", "mrqa_naturalquestions-validation-3661", "mrqa_naturalquestions-validation-3623", "mrqa_naturalquestions-validation-5170", "mrqa_squad-validation-6392", "mrqa_squad-validation-9629", "mrqa_squad-validation-1910", "mrqa_squad-validation-5084", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-4238", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-6408", "mrqa_squad-validation-7596", "mrqa_naturalquestions-validation-9961", "mrqa_naturalquestions-validation-4736", "mrqa_squad-validation-913", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-9324", "mrqa_naturalquestions-validation-5025", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-1770", "mrqa_squad-validation-9635", "mrqa_squad-validation-3989", "mrqa_naturalquestions-validation-220", "mrqa_squad-validation-2754", "mrqa_naturalquestions-validation-8182", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-10284", "mrqa_naturalquestions-validation-3431", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-1706", "mrqa_squad-validation-5023", "mrqa_naturalquestions-validation-2565", "mrqa_squad-validation-7769", "mrqa_naturalquestions-validation-7266", "mrqa_squad-validation-7186", "mrqa_naturalquestions-validation-10497", "mrqa_naturalquestions-validation-9781", "mrqa_squad-validation-3354", "mrqa_squad-validation-7491", "mrqa_naturalquestions-validation-3056", "mrqa_squad-validation-3010", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-6046", "mrqa_squad-validation-5508", "mrqa_naturalquestions-validation-5799", "mrqa_naturalquestions-validation-5999", "mrqa_squad-validation-7750", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-5792", "mrqa_squad-validation-5098", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-6483", "mrqa_squad-validation-8983", "mrqa_naturalquestions-validation-4611", "mrqa_squad-validation-2825", "mrqa_squad-validation-133", "mrqa_naturalquestions-validation-5802", "mrqa_squad-validation-2384", "mrqa_squad-validation-85", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-289", "mrqa_squad-validation-8470", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-4710", "mrqa_naturalquestions-validation-8052", "mrqa_squad-validation-4108", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-1988", "mrqa_squad-validation-7162", "mrqa_squad-validation-3257", "mrqa_squad-validation-4287", "mrqa_naturalquestions-validation-3121", "mrqa_naturalquestions-validation-6049", "mrqa_squad-validation-9062", "mrqa_naturalquestions-validation-4074", "mrqa_squad-validation-7137", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-7772", "mrqa_squad-validation-8026", "mrqa_squad-validation-4402", "mrqa_squad-validation-1815", "mrqa_squad-validation-1218", "mrqa_naturalquestions-validation-1160", "mrqa_squad-validation-1208", "mrqa_squad-validation-4051", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-6304", "mrqa_naturalquestions-validation-6095", "mrqa_naturalquestions-validation-5292", "mrqa_squad-validation-4467", "mrqa_squad-validation-1713", "mrqa_squad-validation-2235", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-7317", "mrqa_squad-validation-5072", "mrqa_squad-validation-1870", "mrqa_naturalquestions-validation-8215", "mrqa_squad-validation-5137", "mrqa_naturalquestions-validation-2025", "mrqa_naturalquestions-validation-9316", "mrqa_squad-validation-8486", "mrqa_squad-validation-1750", "mrqa_squad-validation-5599", "mrqa_naturalquestions-validation-8542", "mrqa_squad-validation-6037", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-9581", "mrqa_squad-validation-7846", "mrqa_squad-validation-9381", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-7310", "mrqa_squad-validation-3545", "mrqa_squad-validation-8548", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-8849", "mrqa_squad-validation-7196", "mrqa_naturalquestions-validation-6307", "mrqa_squad-validation-2238", "mrqa_squad-validation-1217", "mrqa_squad-validation-3567", "mrqa_squad-validation-4331", "mrqa_squad-validation-9944", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10090", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-4103", "mrqa_squad-validation-4513", "mrqa_naturalquestions-validation-4845", "mrqa_squad-validation-9999", "mrqa_naturalquestions-validation-591", "mrqa_squad-validation-9753", "mrqa_squad-validation-6566", "mrqa_squad-validation-4472", "mrqa_naturalquestions-validation-8617", "mrqa_squad-validation-4134", "mrqa_squad-validation-3819", "mrqa_squad-validation-455", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-10034", "mrqa_squad-validation-1720", "mrqa_squad-validation-1430", "mrqa_squad-validation-222", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-1376", "mrqa_naturalquestions-validation-5299", "mrqa_naturalquestions-validation-805", "mrqa_squad-validation-7857", "mrqa_naturalquestions-validation-7190", "mrqa_squad-validation-2391", "mrqa_squad-validation-9711", "mrqa_squad-validation-1323", "mrqa_naturalquestions-validation-9650", "mrqa_naturalquestions-validation-793", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-875", "mrqa_squad-validation-1029", "mrqa_squad-validation-2466", "mrqa_squad-validation-872", "mrqa_squad-validation-713", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-2400", "mrqa_naturalquestions-validation-9799", "mrqa_squad-validation-9533", "mrqa_squad-validation-3265", "mrqa_squad-validation-2730", "mrqa_naturalquestions-validation-3651", "mrqa_squad-validation-8329", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-1015", "mrqa_naturalquestions-validation-1445", "mrqa_squad-validation-403", "mrqa_squad-validation-10418", "mrqa_squad-validation-9956", "mrqa_squad-validation-2111", "mrqa_squad-validation-3092", "mrqa_squad-validation-10306", "mrqa_squad-validation-6770", "mrqa_squad-validation-4665", "mrqa_squad-validation-7846", "mrqa_squad-validation-9058", "mrqa_squad-validation-10149", "mrqa_squad-validation-7938", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-5921", "mrqa_naturalquestions-validation-3146", "mrqa_squad-validation-4183", "mrqa_naturalquestions-validation-7226", "mrqa_squad-validation-3103", "mrqa_squad-validation-4534", "mrqa_squad-validation-7944", "mrqa_squad-validation-10377", "mrqa_squad-validation-7802", "mrqa_naturalquestions-validation-10294", "mrqa_squad-validation-4186", "mrqa_squad-validation-10313", "mrqa_squad-validation-1383", "mrqa_naturalquestions-validation-7158", "mrqa_squad-validation-4017", "mrqa_squad-validation-7430", "mrqa_naturalquestions-validation-5709", "mrqa_squad-validation-8428", "mrqa_squad-validation-3519", "mrqa_naturalquestions-validation-10279", "mrqa_squad-validation-3787", "mrqa_squad-validation-9675", "mrqa_squad-validation-9847", "mrqa_squad-validation-4791", "mrqa_squad-validation-1108", "mrqa_squad-validation-873", "mrqa_squad-validation-1836", "mrqa_naturalquestions-validation-2586", "mrqa_squad-validation-8071", "mrqa_naturalquestions-validation-328", "mrqa_squad-validation-6240", "mrqa_naturalquestions-validation-5123", "mrqa_squad-validation-3862", "mrqa_squad-validation-10155", "mrqa_squad-validation-1184", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-4506", "mrqa_squad-validation-3988", "mrqa_naturalquestions-validation-8186", "mrqa_squad-validation-8168", "mrqa_squad-validation-2579", "mrqa_naturalquestions-validation-3525", "mrqa_squad-validation-2038", "mrqa_squad-validation-4079", "mrqa_squad-validation-10136", "mrqa_squad-validation-7848", "mrqa_naturalquestions-validation-633", "mrqa_squad-validation-1934", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-7392", "mrqa_squad-validation-8007", "mrqa_naturalquestions-validation-1179", "mrqa_naturalquestions-validation-9895", "mrqa_naturalquestions-validation-7464", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-10091", "mrqa_squad-validation-1490", "mrqa_squad-validation-4166", "mrqa_squad-validation-10370", "mrqa_naturalquestions-validation-3969", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-2355", "mrqa_naturalquestions-validation-4271", "mrqa_squad-validation-5442", "mrqa_naturalquestions-validation-9387", "mrqa_naturalquestions-validation-8189", "mrqa_squad-validation-925", "mrqa_squad-validation-336", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-8911", "mrqa_squad-validation-10336", "mrqa_naturalquestions-validation-4413", "mrqa_squad-validation-9732", "mrqa_naturalquestions-validation-2256", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-4486", "mrqa_naturalquestions-validation-1515", "mrqa_squad-validation-9715", "mrqa_squad-validation-2253", "mrqa_squad-validation-9256", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-4242", "mrqa_squad-validation-8069", "mrqa_squad-validation-7194", "mrqa_squad-validation-4297", "mrqa_squad-validation-5293", "mrqa_squad-validation-9445", "mrqa_squad-validation-5491", "mrqa_squad-validation-7294", "mrqa_naturalquestions-validation-10616", "mrqa_naturalquestions-validation-6052", "mrqa_naturalquestions-validation-9436", "mrqa_squad-validation-9194", "mrqa_squad-validation-6161", "mrqa_squad-validation-10080", "mrqa_squad-validation-7915", "mrqa_squad-validation-6993", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-1372", "mrqa_naturalquestions-validation-3416", "mrqa_naturalquestions-validation-6040", "mrqa_squad-validation-3363", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-4108", "mrqa_squad-validation-1656", "mrqa_naturalquestions-validation-6234", "mrqa_squad-validation-7980", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-3468", "mrqa_squad-validation-3876", "mrqa_squad-validation-8381", "mrqa_naturalquestions-validation-2336", "mrqa_naturalquestions-validation-1785", "mrqa_squad-validation-9750", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-3469", "mrqa_naturalquestions-validation-2355", "mrqa_squad-validation-6456", "mrqa_squad-validation-8059", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-8648", "mrqa_squad-validation-222", "mrqa_naturalquestions-validation-6157", "mrqa_naturalquestions-validation-1084", "mrqa_naturalquestions-validation-955", "mrqa_squad-validation-499", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-6968", "mrqa_squad-validation-5457", "mrqa_squad-validation-2729", "mrqa_squad-validation-2697", "mrqa_naturalquestions-validation-8355", "mrqa_squad-validation-5405", "mrqa_naturalquestions-validation-7692", "mrqa_squad-validation-7208", "mrqa_naturalquestions-validation-2743", "mrqa_squad-validation-8197", "mrqa_naturalquestions-validation-10617", "mrqa_squad-validation-3704", "mrqa_squad-validation-6040", "mrqa_naturalquestions-validation-6592", "mrqa_squad-validation-5815", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-2080", "mrqa_squad-validation-1701", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-9836", "mrqa_squad-validation-5839", "mrqa_naturalquestions-validation-475", "mrqa_squad-validation-2830", "mrqa_squad-validation-4236", "mrqa_naturalquestions-validation-3122", "mrqa_squad-validation-2621", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-4925", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-5234", "mrqa_naturalquestions-validation-182", "mrqa_squad-validation-8003", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-5292", "mrqa_naturalquestions-validation-8427", "mrqa_naturalquestions-validation-10066", "mrqa_squad-validation-1289", "mrqa_naturalquestions-validation-6012", "mrqa_squad-validation-6201", "mrqa_squad-validation-5389", "mrqa_naturalquestions-validation-1888", "mrqa_naturalquestions-validation-2618", "mrqa_squad-validation-8194", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-6055", "mrqa_naturalquestions-validation-2106", "mrqa_squad-validation-1247", "mrqa_squad-validation-91", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-8450", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-8034", "mrqa_naturalquestions-validation-8043", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6586", "mrqa_naturalquestions-validation-2399", "mrqa_squad-validation-4573", "mrqa_squad-validation-6982", "mrqa_naturalquestions-validation-134", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-8075", "mrqa_squad-validation-4788", "mrqa_naturalquestions-validation-8762", "mrqa_naturalquestions-validation-4879", "mrqa_squad-validation-4390", "mrqa_squad-validation-10432", "mrqa_squad-validation-2940", "mrqa_squad-validation-1795", "mrqa_squad-validation-861", "mrqa_squad-validation-1556", "mrqa_squad-validation-3993", "mrqa_naturalquestions-validation-7228", "mrqa_naturalquestions-validation-2399", "mrqa_naturalquestions-validation-6451", "mrqa_naturalquestions-validation-8555", "mrqa_naturalquestions-validation-338", "mrqa_squad-validation-5757", "mrqa_squad-validation-8455", "mrqa_naturalquestions-validation-9506", "mrqa_squad-validation-7967", "mrqa_naturalquestions-validation-3427", "mrqa_naturalquestions-validation-2692", "mrqa_squad-validation-3236", "mrqa_naturalquestions-validation-3609", "mrqa_squad-validation-3136", "mrqa_squad-validation-2170", "mrqa_squad-validation-4837", "mrqa_naturalquestions-validation-6514", "mrqa_squad-validation-6777", "mrqa_naturalquestions-validation-3734", "mrqa_squad-validation-6455"], "OKR": 0.7890625, "KG": 0.3578125, "before_eval_results": {"predictions": ["Two", "Ogr\u00f3d Saski", "The Talons of Weng-Chiang", "Catholic", "Christian", "Mediterranean", "Cambaluc", "beta decay (of neutrons in atomic nuclei)", "aggressiveness", "India", "Alabama's capital is Montgomery", "1912", "the President", "divergent tectonic plate boundary", "the 2007 -- 08 season", "Herman Hollerith", "chromosomes", "18 episodes", "Orange Juice", "The Visitation", "the final two games", "iron -- nickel alloy", "seven units", "Glen W. Dickson", "Chernobyl Nuclear Power Plant near the now - abandoned town of Pripyat, in northern Ukrainian Soviet Socialist Republic, Soviet Union, approximately 104 km ( 65 mi ) north of Kiev", "September 29, 2017", "the night skyline of Manhattan", "employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another, even though rules applied by employers or landlords are formally neutral", "Taylor Michel Momsen", "John Roberts", "Ben Willis", "1901", "Sam Waterston", "Karen Gillan", "November 3, 2007", "the United States declared neutrality and worked to broker a peace", "Anatomy", "Saratoga campaign ( 1777 -- 78 )", "Geraldine Margaret Agnew - Somerville", "the central plains", "Ric Flair", "Brooklyn, New York", "The euro", "Donald Fauntleroy Duck", "Clare Torry", "the Chicago metropolitan area", "Doug Pruzan", "Nodar Kumaritashvili", "1881", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "unknown recipient", "ase", "the Prince - Electors", "a place of trade, entertainment, and education", "an Abstergo agent", "During the reign of King Beorhtric of Wessex", "Hellenism", "the world's longest station platform", "Dutch navy captain Jurriaen Aernoutsz", "Ptolemy", "all transmissions", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "1931", "Michael Clarke Duncan"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7886134093619559}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.2666666666666667, 1.0, 0.4, 0.9666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9302325581395349, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1075", "mrqa_squad-validation-10459", "mrqa_naturalquestions-validation-4139", "mrqa_naturalquestions-validation-3043", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-3910", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9281", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-4863", "mrqa_naturalquestions-validation-1851", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-10461"], "SR": 0.6875, "CSR": 0.6375343406593407, "EFR": 0.95, "Overall": 0.6855537431318681}, {"timecode": 91, "before_eval_results": {"predictions": ["organisms", "stagnant wages", "Pathogens can rapidly evolve and adapt", "Gosforth Park", "mountainous areas", "New England Patriots", "specific immune receptors", "Atlantic", "5K resolution", "draftsman", "$2 million in 2011", "state legislatures", "Old Trafford", "John Locke", "regulatory site", "Fall 1998", "USS Chesapeake", "Donna Mills", "42", "Jurchen Aisin Gioro clan", "660 quadrillion US gallons", "Melbourne", "a candidate state must be a free market democracy", "2003", "2003", "Muhammad Yunus", "Menorca", "1996", "Jessica Simpson", "`` drive - through '' or `` stop and go '' penalty, costing them valuable track position", "Muhammad", "a spicy cuisines, such as the use of cumin, introduced by Spanish immigrants to Texas from the Canary Islands and used in Berber cuisine, but used in only a few central Mexican recipes", "The Intolerable Acts", "Those who follow the band just to enjoy the music", "British Columbia, Canada", "efferent nerves that directly innervate muscles", "Xanthippus", "Omar Khayyam", "it culminates in a post as a Consultant, a General Practitioner ( GP ), or some other non-training post, such as a Staff grade or Associate Specialist post", "the Qi", "iron -- nickel alloy", "Giancarlo Stanton", "statutory law", "late January or early February", "in which both reactants and products are present in concentrations which have no further tendency to change with time, so that there is no observable change in the properties of the system", "Andy Serkis", "8ft", "Masha Skorobogatov", "living - donor", "Human fertilization", "Alastair Cook", "Rashidun Caliphs", "a spiritual conversion", "members of the gay ( LGBT ) community", "18", "Robber Barons", "up to 100,000 write / erase cycles", "5.0 - litre, naturally aspirated V8 - engine with electronic fuel injection, capable of producing between 460 and 485 kW ( 620 -- 650 bhp )", "New Jersey", "13 February", "J. Presper Eckert", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "if the concentration of a compound exceeds its solubility ( such as when mixing solvents or changing their temperature )", "Abiotic"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7923983070745404}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0588235294117647, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5000000000000001, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6451612903225806, 0.0, 1.0, 0.0, 0.35294117647058826, 0.5454545454545454, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7184", "mrqa_squad-validation-4277", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-9639", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-5900", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-1438", "mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-5838", "mrqa_naturalquestions-validation-2965"], "SR": 0.71875, "CSR": 0.6384171195652174, "EFR": 0.9444444444444444, "Overall": 0.6846191878019324}, {"timecode": 92, "before_eval_results": {"predictions": ["British colonists would not be safe as long as the French were present", "V&A Museum of Childhood", "a colonel of the Iroquois Confederacy in the area", "1568\u20131609", "school functions", "2000", "in protest against the occupation of Prussia by Napoleon", "Africa", "General Electric", "more than 50%", "Meri", "Elizabeth Weber", "stratum lucidum", "the federal government", "Richard Roxburgh", "Muhammad Yunus", "The long - hair gene is recessive", "a habitat", "from shore to shore", "Eddie Van Halen", "December 9, 2017", "left - sided heart failure", "Spain", "American country music duo The Bellamy Brothers", "John Daly", "Jackie Robinson", "humid subtropical climate, with hot summers and mild winters", "the singer and guitarist Bill Henderson", "James Brown", "2018", "The Third Five - year Plan", "2009", "over most of the sixth century, after the Anglo - Saxons had started their journey to England and before the beginning of the seventh century", "Kaley Christine Cuoco", "the Attorney General", "Universal Pictures", "*", "as early as in 1651 by Thomas Hobbes in his Leviathan, though with a somewhat different meaning ( similar to the meaning used by the British associationists )", "hydrogen", "Victim blaming", "Scarlett Johansson", "England", "a pH indicator, a color marker, and a dye", "Betty", "Tyrann Devine Mathieu", "if the player busts, the player loses, regardless of whether the dealer subsequently busts", "senators", "Andrew Johnson", "metamorphic rock", "Thawne", "2018", "Nigel Lythgoe", "in the early 1950s", "the cast members", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "1966", "as the Old French word autompne ( automne in modern French ) or autumpne in Middle English, and was later normalised to the original Latin", "Puerto Rico", "the singer and a co-worker decide to `` steal '' a Cadillac by way of using their assembly line jobs to obtain the parts via salamislice", "Helena", "Pittsburgh", "Neela Montgomery", "Bhupendranath Dutt", "Scopes Trial in the United States"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7365108543417367}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.11764705882352941, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.3571428571428571, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10186", "mrqa_squad-validation-5325", "mrqa_squad-validation-10174", "mrqa_squad-validation-3025", "mrqa_naturalquestions-validation-3284", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8877", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-3066", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-8181"], "SR": 0.703125, "CSR": 0.6391129032258065, "EFR": 1.0, "Overall": 0.6958694556451613}, {"timecode": 93, "before_eval_results": {"predictions": ["1788", "1892 to 1894", "50th", "in the debating chamber", "World Today", "Pacific", "producers of the show", "one", "Luther", "antithetical", "Detroit", "William DeVaughn", "sandstone", "Joanne Wheatley", "2015, 2016", "2017", "helps scientists better understand the spread of pollution around the globe", "1799", "Joseph M. Scriven", "John Daly", "Isaiah Amir Mustafa", "John Hancock", "September 2017", "up to 100,000", "peptide bond", "Keeley Clare Julia Hawes", "white rapper B - Rabbit", "inside the cell nucleus", "giant", "David Gahan", "Ford", "in positions Arg15 - Ile16", "light utility vehicles", "2005", "Kristy Swanson", "Vice President", "George Warren Barnes", "Stephen Foster", "red", "Zeebo", "seven years earlier", "the Near East", "*", "Oceania", "a decade of high unemployment, poverty, low profits, deflation, plunging farm incomes, and lost opportunities for economic growth and personal advancement", "Spanish", "Elizabeth Mitchell", "Walter Egan", "Jerry Leiber and Mike Stoller", "Andy Serkis", "the presence of correctly oriented P waves", "2013", "1963", "R.E.M.", "Gabrielle - Suzanne Barbot de Villeneuve", "stratum lucidum", "Barbara Windsor", "1975", "Douglas Williams and Julie Olson Williams", "Missouri River", "Charles Dickens's novel Oliver Twist", "the symbol of the State and of the unity of the people", "Benzodiazepines", "maquiladora"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8075261544011544}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9409", "mrqa_naturalquestions-validation-8975", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2605", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5537", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-3246", "mrqa_naturalquestions-validation-4026", "mrqa_naturalquestions-validation-3004"], "SR": 0.765625, "CSR": 0.6404587765957447, "EFR": 0.6, "Overall": 0.616138630319149}, {"timecode": 94, "before_eval_results": {"predictions": ["Von Miller", "The Eleventh Hour", "Small Catechism", "chest pains", "packet switching", "CYP27B1", "Queen Elizabeth II", "states with the highest membership rates are Oklahoma, Iowa, Mississippi, West Virginia, and North Carolina", "25 percent", "Robert of Jumi\u00e8ges", "December 1972", "consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "the concentration of a compound exceeds its solubility", "advisory speed signs", "Zuzu & Zaza Zebra", "the early 20th century", "about 1 nautical mile ( 2 km ) off - coast from Piraeus and about 16 kilometres ( 10 miles ) west of Athens", "Schadenfreude", "about 375 miles ( 600 km ) south of Newfoundland", "Rajendra Prasad", "The UN General Assembly", "San Francisco Bay", "c. 1000 AD", "Teri Hatcher", "Pearson's correlation assesses linear relationships", "Thomas Chisholm", "2010", "Los Angeles", "her brother, Brian", "China", "The Drew Las Vegas", "During the last Ice Age", "Panic! at the Disco", "supervillains who pose catastrophic challenges to the world", "bullets discharged into the air fall back down to the ground", "Richard Masur", "the terrestrial biosphere", "2013", "Bob Dylan", "a person works a minimum number of hours defined as such by his / her employer", "the nearest White Castle in New Brunswick", "Georges Auguste Escoffier", "gathering money from the public, which circumvents traditional avenues of investment", "2009", "connotations of the passing of the year", "Andrea Brooks", "ancient Athens circa 508 B.C.", "1939", "A request line", "Abigail Hawk", "from a donor molecule to an acceptor molecule", "Antonio da Sangallo the Younger", "epistemicism", "2017", "any unfavourable and unintended sign ( including an abnormal laboratory finding ), symptom, or disease temporally associated with the use of a medicinal ( investigational ) product", "Ren\u00e9 Georges Hermann - Paul", "a web page above the page in an address bar", "volume", "Butter Island off North Haven, Maine in the Penobscot Bay", "the symbol of the State and of the unity of the people", "1967", "2009", "client", "Andrew Garfield"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7779209223259391}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.31111111111111117, 1.0, 0.42857142857142855, 1.0, 1.0, 0.9268292682926829, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.38095238095238093, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 0.2222222222222222, 1.0, 0.8695652173913044, 0.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7651", "mrqa_squad-validation-10111", "mrqa_naturalquestions-validation-4050", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-6117", "mrqa_naturalquestions-validation-3560", "mrqa_naturalquestions-validation-1068", "mrqa_naturalquestions-validation-486", "mrqa_naturalquestions-validation-8933", "mrqa_naturalquestions-validation-8279", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-9242", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-7077", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-6597", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-6844"], "SR": 0.65625, "CSR": 0.640625, "EFR": 0.9090909090909091, "Overall": 0.6779900568181818}, {"timecode": 95, "UKR": 0.67578125, "OKR_sampled_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-7754", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-3205", "mrqa_squad-validation-8222", "mrqa_squad-validation-4037", "mrqa_naturalquestions-validation-325", "mrqa_naturalquestions-validation-407", "mrqa_squad-validation-10031", "mrqa_naturalquestions-validation-4685", "mrqa_squad-validation-1889", "mrqa_squad-validation-8204", "mrqa_squad-validation-8952", "mrqa_squad-validation-1217", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-9332", "mrqa_squad-validation-5230", "mrqa_squad-validation-9771", "mrqa_squad-validation-5541", "mrqa_squad-validation-1795", "mrqa_squad-validation-10352", "mrqa_naturalquestions-validation-9821", "mrqa_squad-validation-189", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-7182", "mrqa_squad-validation-7903", "mrqa_naturalquestions-validation-1704", "mrqa_squad-validation-9226", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-171", "mrqa_squad-validation-5174", "mrqa_naturalquestions-validation-9142", "mrqa_squad-validation-8329", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-5315", "mrqa_squad-validation-10133", "mrqa_naturalquestions-validation-1160", "mrqa_squad-validation-4472", "mrqa_naturalquestions-validation-3625", "mrqa_naturalquestions-validation-1525", "mrqa_squad-validation-10388", "mrqa_naturalquestions-validation-3130", "mrqa_naturalquestions-validation-3224", "mrqa_naturalquestions-validation-2127", "mrqa_squad-validation-6011", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-4837", "mrqa_naturalquestions-validation-3275", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-5983", "mrqa_squad-validation-8168", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-9967", "mrqa_naturalquestions-validation-9766", "mrqa_squad-validation-7996", "mrqa_squad-validation-5028", "mrqa_squad-validation-3329", "mrqa_squad-validation-3578", "mrqa_naturalquestions-validation-10551", "mrqa_naturalquestions-validation-2437", "mrqa_squad-validation-4143", "mrqa_squad-validation-5329", "mrqa_squad-validation-10442", "mrqa_squad-validation-1238", "mrqa_naturalquestions-validation-6572", "mrqa_naturalquestions-validation-6169", "mrqa_squad-validation-1706", "mrqa_squad-validation-1017", "mrqa_naturalquestions-validation-4611", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-8883", "mrqa_squad-validation-7803", "mrqa_squad-validation-9569", "mrqa_squad-validation-10216", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-9104", "mrqa_naturalquestions-validation-4816", "mrqa_squad-validation-2232", "mrqa_naturalquestions-validation-5120", "mrqa_squad-validation-2113", "mrqa_squad-validation-395", "mrqa_naturalquestions-validation-1385", "mrqa_squad-validation-6120", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4993", "mrqa_squad-validation-2288", "mrqa_naturalquestions-validation-8741", "mrqa_squad-validation-1164", "mrqa_naturalquestions-validation-104", "mrqa_squad-validation-9276", "mrqa_squad-validation-390", "mrqa_squad-validation-9391", "mrqa_naturalquestions-validation-5634", "mrqa_naturalquestions-validation-2740", "mrqa_squad-validation-7593", "mrqa_naturalquestions-validation-1163", "mrqa_squad-validation-10136", "mrqa_squad-validation-59", "mrqa_naturalquestions-validation-6769", "mrqa_naturalquestions-validation-8947", "mrqa_naturalquestions-validation-6754", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-2179", "mrqa_squad-validation-9325", "mrqa_squad-validation-9643", "mrqa_naturalquestions-validation-6278", "mrqa_squad-validation-8763", "mrqa_naturalquestions-validation-3910", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-629", "mrqa_naturalquestions-validation-8781", "mrqa_naturalquestions-validation-1445", "mrqa_squad-validation-5951", "mrqa_squad-validation-426", "mrqa_squad-validation-9208", "mrqa_naturalquestions-validation-3416", "mrqa_squad-validation-1839", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-3632", "mrqa_squad-validation-5661", "mrqa_squad-validation-9020", "mrqa_squad-validation-3340", "mrqa_naturalquestions-validation-4652", "mrqa_squad-validation-9", "mrqa_naturalquestions-validation-9972", "mrqa_naturalquestions-validation-9564", "mrqa_squad-validation-722", "mrqa_naturalquestions-validation-1866", "mrqa_squad-validation-8034", "mrqa_naturalquestions-validation-6328", "mrqa_naturalquestions-validation-9474", "mrqa_squad-validation-6584", "mrqa_squad-validation-6343", "mrqa_squad-validation-2447", "mrqa_naturalquestions-validation-9546", "mrqa_squad-validation-3704", "mrqa_naturalquestions-validation-3930", "mrqa_squad-validation-4313", "mrqa_squad-validation-4945", "mrqa_squad-validation-5221", "mrqa_squad-validation-7321", "mrqa_naturalquestions-validation-10603", "mrqa_squad-validation-4221", "mrqa_squad-validation-1367", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-10034", "mrqa_squad-validation-10377", "mrqa_naturalquestions-validation-6749", "mrqa_squad-validation-1863", "mrqa_squad-validation-4608", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-1735", "mrqa_squad-validation-2471", "mrqa_squad-validation-7896", "mrqa_squad-validation-3607", "mrqa_squad-validation-7546", "mrqa_naturalquestions-validation-3801", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2658", "mrqa_naturalquestions-validation-10368", "mrqa_squad-validation-4166", "mrqa_naturalquestions-validation-7033", "mrqa_naturalquestions-validation-7807", "mrqa_squad-validation-7686", "mrqa_naturalquestions-validation-669", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-2119", "mrqa_squad-validation-1752", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-9753", "mrqa_squad-validation-6872", "mrqa_squad-validation-10251", "mrqa_naturalquestions-validation-1955", "mrqa_naturalquestions-validation-10583", "mrqa_squad-validation-655", "mrqa_naturalquestions-validation-4552", "mrqa_squad-validation-9311", "mrqa_naturalquestions-validation-6330", "mrqa_squad-validation-7846", "mrqa_naturalquestions-validation-2485", "mrqa_naturalquestions-validation-1213", "mrqa_squad-validation-6464", "mrqa_squad-validation-2448", "mrqa_squad-validation-9550", "mrqa_naturalquestions-validation-802", "mrqa_squad-validation-1651", "mrqa_naturalquestions-validation-9967", "mrqa_squad-validation-5462", "mrqa_naturalquestions-validation-4983", "mrqa_squad-validation-641", "mrqa_squad-validation-5051", "mrqa_naturalquestions-validation-7862", "mrqa_squad-validation-51", "mrqa_squad-validation-3602", "mrqa_squad-validation-6729", "mrqa_squad-validation-6609", "mrqa_squad-validation-2461", "mrqa_squad-validation-10179", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-519", "mrqa_squad-validation-7344", "mrqa_squad-validation-3948", "mrqa_naturalquestions-validation-4870", "mrqa_naturalquestions-validation-1452", "mrqa_squad-validation-9626", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-10603", "mrqa_naturalquestions-validation-1165", "mrqa_squad-validation-257", "mrqa_naturalquestions-validation-1139", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-2319", "mrqa_squad-validation-4835", "mrqa_squad-validation-5185", "mrqa_squad-validation-7053", "mrqa_squad-validation-1498", "mrqa_squad-validation-3993", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-5932", "mrqa_naturalquestions-validation-10454", "mrqa_squad-validation-1951", "mrqa_naturalquestions-validation-10706", "mrqa_squad-validation-2042", "mrqa_squad-validation-2633", "mrqa_naturalquestions-validation-6470", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-961", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-9440", "mrqa_squad-validation-9993", "mrqa_naturalquestions-validation-4410", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-9440", "mrqa_squad-validation-4990", "mrqa_squad-validation-9855", "mrqa_squad-validation-6221", "mrqa_squad-validation-337", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-3545", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-6588", "mrqa_squad-validation-631", "mrqa_naturalquestions-validation-2269", "mrqa_squad-validation-460", "mrqa_naturalquestions-validation-9342", "mrqa_squad-validation-6952", "mrqa_naturalquestions-validation-4922", "mrqa_squad-validation-4448", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-4309", "mrqa_squad-validation-336", "mrqa_squad-validation-9002", "mrqa_naturalquestions-validation-6292", "mrqa_squad-validation-3403", "mrqa_squad-validation-5603", "mrqa_naturalquestions-validation-6117", "mrqa_naturalquestions-validation-1611", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-6376", "mrqa_squad-validation-6161", "mrqa_naturalquestions-validation-8973", "mrqa_squad-validation-10174", "mrqa_naturalquestions-validation-1476", "mrqa_squad-validation-2980", "mrqa_naturalquestions-validation-4846", "mrqa_squad-validation-9266", "mrqa_squad-validation-9062", "mrqa_squad-validation-1231", "mrqa_squad-validation-8154", "mrqa_squad-validation-3950", "mrqa_squad-validation-5250", "mrqa_squad-validation-10223", "mrqa_naturalquestions-validation-4562", "mrqa_squad-validation-5341", "mrqa_squad-validation-9144", "mrqa_squad-validation-8026", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-1629", "mrqa_squad-validation-4148", "mrqa_squad-validation-1720", "mrqa_naturalquestions-validation-187", "mrqa_squad-validation-8056", "mrqa_squad-validation-71", "mrqa_naturalquestions-validation-2467", "mrqa_squad-validation-9348", "mrqa_naturalquestions-validation-2347", "mrqa_squad-validation-1790", "mrqa_naturalquestions-validation-2309", "mrqa_squad-validation-7769", "mrqa_squad-validation-9447", "mrqa_naturalquestions-validation-5330", "mrqa_squad-validation-455", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6298", "mrqa_naturalquestions-validation-8052", "mrqa_squad-validation-4934", "mrqa_naturalquestions-validation-3935", "mrqa_squad-validation-715", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-182", "mrqa_squad-validation-3715", "mrqa_squad-validation-1586", "mrqa_squad-validation-3343", "mrqa_squad-validation-8753", "mrqa_squad-validation-5633", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-7464", "mrqa_squad-validation-3267", "mrqa_squad-validation-6248", "mrqa_naturalquestions-validation-6564", "mrqa_squad-validation-4134", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3593", "mrqa_squad-validation-2", "mrqa_squad-validation-1142", "mrqa_squad-validation-9825", "mrqa_naturalquestions-validation-5605", "mrqa_naturalquestions-validation-1193", "mrqa_squad-validation-871", "mrqa_naturalquestions-validation-9581", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8558", "mrqa_squad-validation-6994", "mrqa_naturalquestions-validation-1519", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-8889", "mrqa_squad-validation-6449", "mrqa_squad-validation-3204", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-10060", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-3735", "mrqa_naturalquestions-validation-6759", "mrqa_squad-validation-10313", "mrqa_squad-validation-2508", "mrqa_squad-validation-5151", "mrqa_squad-validation-2075", "mrqa_squad-validation-9078", "mrqa_naturalquestions-validation-4731", "mrqa_squad-validation-7000", "mrqa_naturalquestions-validation-2698", "mrqa_squad-validation-1490", "mrqa_naturalquestions-validation-3802", "mrqa_squad-validation-6593", "mrqa_squad-validation-3730", "mrqa_squad-validation-1886", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-3019", "mrqa_naturalquestions-validation-9155", "mrqa_naturalquestions-validation-7141", "mrqa_naturalquestions-validation-7108", "mrqa_squad-validation-5876", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-2179", "mrqa_squad-validation-5018", "mrqa_squad-validation-1257", "mrqa_squad-validation-10350", "mrqa_squad-validation-9750", "mrqa_naturalquestions-validation-2690", "mrqa_squad-validation-2090", "mrqa_naturalquestions-validation-335", "mrqa_squad-validation-9599", "mrqa_squad-validation-6977", "mrqa_naturalquestions-validation-2602", "mrqa_squad-validation-6512", "mrqa_squad-validation-2050", "mrqa_squad-validation-3514", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-6759", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-3074", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-3048", "mrqa_squad-validation-8187", "mrqa_squad-validation-1814", "mrqa_naturalquestions-validation-6020", "mrqa_naturalquestions-validation-2893", "mrqa_naturalquestions-validation-5608", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-8965", "mrqa_squad-validation-3394", "mrqa_squad-validation-3839", "mrqa_naturalquestions-validation-1009", "mrqa_squad-validation-943", "mrqa_naturalquestions-validation-7242", "mrqa_squad-validation-5769", "mrqa_squad-validation-9324", "mrqa_squad-validation-336", "mrqa_squad-validation-5213", "mrqa_squad-validation-4273", "mrqa_naturalquestions-validation-2305", "mrqa_squad-validation-1041", "mrqa_squad-validation-561", "mrqa_squad-validation-10410", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-4637", "mrqa_naturalquestions-validation-2225", "mrqa_squad-validation-5587", "mrqa_naturalquestions-validation-2130", "mrqa_squad-validation-5547", "mrqa_squad-validation-9051", "mrqa_squad-validation-4799", "mrqa_naturalquestions-validation-7627", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-10294", "mrqa_squad-validation-852", "mrqa_squad-validation-2144", "mrqa_squad-validation-479", "mrqa_naturalquestions-validation-993", "mrqa_squad-validation-9562", "mrqa_squad-validation-171", "mrqa_squad-validation-5723", "mrqa_squad-validation-7259", "mrqa_squad-validation-8811", "mrqa_squad-validation-9658", "mrqa_naturalquestions-validation-9246", "mrqa_squad-validation-5757", "mrqa_squad-validation-6883", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-1886", "mrqa_naturalquestions-validation-7152", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-8153", "mrqa_squad-validation-3567", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-5555", "mrqa_squad-validation-8991", "mrqa_squad-validation-9371", "mrqa_naturalquestions-validation-5998", "mrqa_squad-validation-4133", "mrqa_squad-validation-7690", "mrqa_naturalquestions-validation-2605", "mrqa_naturalquestions-validation-9848", "mrqa_squad-validation-7685", "mrqa_squad-validation-1907", "mrqa_squad-validation-1495", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-4647", "mrqa_squad-validation-7516", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-8502", "mrqa_naturalquestions-validation-8429", "mrqa_naturalquestions-validation-527", "mrqa_squad-validation-3778", "mrqa_naturalquestions-validation-6952", "mrqa_squad-validation-4283", "mrqa_squad-validation-4878", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-8159", "mrqa_naturalquestions-validation-10684", "mrqa_squad-validation-2622", "mrqa_naturalquestions-validation-4611", "mrqa_squad-validation-2097", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-5984", "mrqa_squad-validation-1194", "mrqa_squad-validation-7320", "mrqa_squad-validation-6949", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2095", "mrqa_squad-validation-5919", "mrqa_squad-validation-4290", "mrqa_naturalquestions-validation-2989", "mrqa_squad-validation-1701", "mrqa_squad-validation-2095", "mrqa_squad-validation-7569", "mrqa_naturalquestions-validation-1312", "mrqa_naturalquestions-validation-9850", "mrqa_squad-validation-7420", "mrqa_naturalquestions-validation-9760", "mrqa_naturalquestions-validation-5259", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-10616", "mrqa_squad-validation-6724", "mrqa_naturalquestions-validation-386", "mrqa_naturalquestions-validation-9963", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-8958", "mrqa_squad-validation-8271", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-4788", "mrqa_naturalquestions-validation-2644", "mrqa_naturalquestions-validation-9421", "mrqa_squad-validation-9298", "mrqa_squad-validation-6451"], "OKR": 0.865234375, "before_eval_results": {"predictions": ["Houston, Texas", "aspirational consumption", "far southeast side", "Dublin", "1110 AM", "Annual Conference Order of Deacons", "Rice University", "Construction", "on the ground", "Lucknow in September 1906", "March 15, 1945", "South Asia", "effective gas exchange", "2010", "100 members", "on a sound stage in front of a live audience in Burbank, California", "by July 1, 2005", "September 29, 2017", "Brian Steele", "1966", "Joe Pizzulo", "1960", "Barry Mann", "SURFACE AREA OF ROOTS", "Hollywood, Los Angeles, California", "Fascist Italy", "Austin, Texas", "Mel Gibson", "Eight", "Taylor Hayes", "in the 1980s", "Brittany Paige Bouck", "often linked to high - ranking ( though not necessarily royalty ) in China", "James Brown", "January 1, 2016", "Lorenzo Lamas", "roughly 230 million kilometres ( 143,000,000 mi )", "sperm", "Spain", "December 2, 2013", "Geoffrey Dyson Palmer", "28", "Rockwell", "Lady Gaga", "prosecute and conduct all suits in the Supreme Court in which the United States shall be concerned", "February 27, 2007", "The Confederate States Army ( C.S.A. )", "V\u1e5bksayurveda", "Bart Cummings", "13 August 1961", "John Young", "Brazil", "January 15, 2007", "Bay of Montevideo", "2018", "Australia", "Something to Sing About", "early - to - mid fourth century", "Karen Taylor", "Games", "22 November 1970", "reproductive", "`` Fix You ''", "contemporary drama in a rural setting"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8122564935064935}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2887", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-8421", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-5934", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-10496", "mrqa_naturalquestions-validation-4821", "mrqa_naturalquestions-validation-8294"], "SR": 0.765625, "CSR": 0.6419270833333333, "EFR": 0.8666666666666667, "Overall": 0.681484375}, {"timecode": 96, "before_eval_results": {"predictions": ["one", "neuroimmune system", "28", "d'Hondt method", "Kurt Vonnegut", "in 2010, and the Dutch Rijkswaterstaat confirms the length at 1,232 kilometres (766 miles).[note 1]", "Kublai Khan", "Mughal emperors", "The Curse of the Daleks", "775", "Carol Worthington", "Scheria", "Matt Monro", "the early 20th century", "Iran", "usually spaced 12 to 36 days apart", "mashed potato", "information", "rapid destruction of the donor red blood cells by host antibodies ( IgG, IgM )", "action utility vehicles", "sacroiliac joint or SI joint ( SIJ )", "Rihanna", "about the hardships of growing older and has no relationship to drug - taking", "revolution or orbital revolution", "Pastoral farming", "nationalists of the Union", "June 1991", "President of the United States", "Jason Weaver and Wylie Draper", "semi-autonomous organisational units within the National Health Service in England", "Karen Gillan", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "bridal shop with Anita, the girlfriend of her brother, Bernardo", "16 March 2018, 12 : 00 CET", "somatic cell nuclear transfer ( SCNT )", "con this reason, the human hands and face have a much larger representation than the legs", "Tara / Ghost of Christmas Past", "the Tin Woodman", "federal republic", "3", "Kyla Coleman", "introduced a succession of increasingly restrictive trade restrictions with Japan", "Millennium Tower", "1876", "summer", "three", "The fifth season of Chicago P.D., an American police drama television series with executive producer Dick Wolf, and producers Derek Haas, Michael Brandt, and Rick Eid", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "Zeebo", "special guest performers Beyonc\u00e9 and Bruno Mars", "Warren Hastings", "April 26, 2005", "12 November 2010", "Babe Ruth", "the season seven episode `` Fierce ''", "treats", "Seton Hall Pirates men's basketball team", "to collect menstrual flow", "in the 1980s", "conptum", "Spektor", "Harlem River", "federal republic", "six republics, with borders drawn along ethnic and historical lines : Bosnia and Herzegovina, Croatia, Macedonia, Montenegro, Serbia and Slovenia"], "metric_results": {"EM": 0.6875, "QA-F1": 0.8007828747029114}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.888888888888889, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5882352941176471, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-9723", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-2210", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-778", "mrqa_naturalquestions-validation-1531", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2892", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-9917", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-4999", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-2387", "mrqa_naturalquestions-validation-5113", "mrqa_naturalquestions-validation-9230"], "SR": 0.6875, "CSR": 0.6423969072164948, "EFR": 1.0, "Overall": 0.7082450064432989}, {"timecode": 97, "before_eval_results": {"predictions": ["Children of Earth", "the college", "citrus", "random noise", "gold", "shaping ideas about the free market", "DVB-compliant MPEG-2", "Konstantin Mereschkowski", "the League of Augsburg", "states had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "states in relationship to the federal government", "the primary antagonist", "2018", "in 1999 the canal was taken over by the Panamanian government and is now managed and operated by the government - owned Panama Canal Authority", "a negro, whose ancestors were imported into ( the U.S. ), and sold as slaves '', whether enslaved or free, could not be an American citizen and therefore had no standing to sue in federal court", "extends from the Arctic Ocean in the north to the Southern Ocean ( or, depending on definition, to Antarctica ) in the south and is bounded by Asia and Australia in the west and the Americas in the east", "Brian", "Sanchez Navarro", "capillaries", "Pyeongchang County, Gangwon Province, South Korea", "Dr. Joel S. Engel of Bell Labs, his rival", "Chuck Noland", "indigenous to many forested parts of the world", "Authority", "an oxidant, usually atmospheric oxygen", "the federal government's nearly 700 million acres ( 2,800,000 km ) of subsurface mineral estate located beneath federal, state and private lands severed from their surface rights by the Homestead Act of 1862", "775", "the Moon's ecliptic longitude", "the 2009 model year", "Gustav Bauer", "the season finale", "Lori McKenna", "Texas A&M University", "B.R. Ambedkar", "Rob Paulsen", "R / T", "December 1972", "January 15, 2007", "up to 100,000", "Nancy Jean Cartwright", "60 by West All - Stars", "the Chinese Exclusion Act", "birth", "Microsoft Windows, macOS, PlayStation 4 and Xbox One on July 25, 2017", "786 -- 802", "7", "A simple majority vote", "United Nations Peacekeeping Operations", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "optic stalks during the seventh week of development", "each state's DMV", "the Union", "the Timberline Lodge on the slopes of Mt. Hood in Oregon", "locations in Google Maps", "Rock Island, Illinois", "Quantitative psychological research", "April 2016", "John C. Reilly sang on all the tracks and played guitar on most of them", "pneumonoultramicroscopicsilicovolcanoconiosis", "Laura Jane Haddock", "a house edge of between 0.5 % and 1 %", "December 1, 2009", "16.5 quadrillion BTUs", "1957"], "metric_results": {"EM": 0.625, "QA-F1": 0.729900436798252}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8292682926829269, 0.0, 1.0, 1.0, 1.0, 0.7407407407407407, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.06451612903225806, 1.0, 0.16, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.7499999999999999, 1.0, 0.4, 1.0, 1.0, 0.8, 0.0, 1.0, 0.22222222222222224, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.7272727272727273, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2667", "mrqa_squad-validation-8488", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-4847", "mrqa_naturalquestions-validation-4762", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-8317", "mrqa_naturalquestions-validation-46", "mrqa_naturalquestions-validation-4039", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-10012", "mrqa_naturalquestions-validation-9297", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-767", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-10184"], "SR": 0.625, "CSR": 0.6422193877551021, "EFR": 0.875, "Overall": 0.6832095025510204}, {"timecode": 98, "before_eval_results": {"predictions": ["Rhine", "Alex White", "traditional Mongolian aristocracy", "MHC class I molecules", "representatives elected to either house of parliament", "Chicago Pile-1", "StubHub Center", "2,869", "two", "lymph", "Johannes Gutenberg", "Humphrey Bogart, Ingrid Bergman, and Paul Henreid", "Muhammad", "traditionally ascribed to the Hindu sage Valmiki", "chryselephantine statue of Athena Parthenos", "2004", "Texas A&M Aggies", "declared independence from the Kingdom of Great Britain", "Colonel Robert E. Lee", "Qing", "Yuzuru Hanyu", "over most of the sixth century", "Subduction of the northern part of the Pacific Plate and the NW North American Plate", "capillata", "Dust", "10 May 1940", "a federal republic composed of 50 states, a federal district, five major self - governing territories, and various possessions", "Geoffrey Zakarian", "sport utility vehicles", "giant", "improve communication", "Carole Landis", "Babur", "1966", "ended Russia's participation in World War I", "1994", "a stretch of Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "William Shakespeare's As You Like It", "burning palm leaves from the previous year's Palm Sunday celebrations", "Alex Drake", "English author Rudyard Kipling", "Mahatma Gandhi", "September 14, 2008", "Jason McMullen", "Gibraltar", "Coroebus of Elis", "May 19, 2017", "China", "silk floss tree", "early - to - mid fourth century", "Steve Earle", "April 15, 2018", "the summit of Cadillac Mountain", "1975", "winter", "hydrogen", "the President", "combine keys which are usually kept separate", "In the mountains outside City 17", "Shirley Mae Jones", "Sir Mix - a-Lot", "Conrad Lewis", "Jason Lee", "patron saint, Saint Dominic"], "metric_results": {"EM": 0.703125, "QA-F1": 0.8143640403651755}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5833333333333334, 0.0, 1.0, 1.0, 1.0, 0.8275862068965517, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.0, 0.8387096774193549, 0.7692307692307692, 0.8421052631578948, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2779", "mrqa_naturalquestions-validation-5996", "mrqa_naturalquestions-validation-4930", "mrqa_naturalquestions-validation-3918", "mrqa_naturalquestions-validation-2418", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-591", "mrqa_naturalquestions-validation-5444", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-8889", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-3385"], "SR": 0.703125, "CSR": 0.642834595959596, "EFR": 0.7894736842105263, "Overall": 0.6662272810340245}, {"timecode": 99, "UKR": 0.703125, "OKR_sampled_ids": ["mrqa_squad-validation-5815", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6772", "mrqa_naturalquestions-validation-7067", "mrqa_squad-validation-9493", "mrqa_naturalquestions-validation-7322", "mrqa_squad-validation-7333", "mrqa_naturalquestions-validation-8317", "mrqa_squad-validation-1562", "mrqa_squad-validation-2232", "mrqa_squad-validation-3607", "mrqa_squad-validation-7420", "mrqa_squad-validation-9644", "mrqa_squad-validation-4778", "mrqa_naturalquestions-validation-5155", "mrqa_squad-validation-10012", "mrqa_naturalquestions-validation-5651", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-5497", "mrqa_squad-validation-5453", "mrqa_squad-validation-7810", "mrqa_naturalquestions-validation-6117", "mrqa_squad-validation-1316", "mrqa_squad-validation-9326", "mrqa_squad-validation-2097", "mrqa_naturalquestions-validation-5026", "mrqa_naturalquestions-validation-86", "mrqa_squad-validation-7772", "mrqa_naturalquestions-validation-6650", "mrqa_squad-validation-1559", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-1459", "mrqa_squad-validation-10350", "mrqa_squad-validation-1779", "mrqa_squad-validation-3280", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-9908", "mrqa_squad-validation-10151", "mrqa_naturalquestions-validation-2354", "mrqa_naturalquestions-validation-5909", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-590", "mrqa_squad-validation-9977", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7600", "mrqa_squad-validation-479", "mrqa_squad-validation-1542", "mrqa_naturalquestions-validation-138", "mrqa_naturalquestions-validation-9457", "mrqa_squad-validation-6042", "mrqa_squad-validation-847", "mrqa_squad-validation-40", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-3037", "mrqa_naturalquestions-validation-10188", "mrqa_squad-validation-170", "mrqa_squad-validation-2099", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1770", "mrqa_squad-validation-3573", "mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-7415", "mrqa_squad-validation-2995", "mrqa_squad-validation-2730", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-7162", "mrqa_squad-validation-3067", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-6754", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-1592", "mrqa_naturalquestions-validation-9848", "mrqa_squad-validation-6463", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-4816", "mrqa_squad-validation-6312", "mrqa_squad-validation-6108", "mrqa_naturalquestions-validation-4090", "mrqa_squad-validation-6868", "mrqa_naturalquestions-validation-851", "mrqa_squad-validation-3690", "mrqa_naturalquestions-validation-3692", "mrqa_squad-validation-5084", "mrqa_naturalquestions-validation-4903", "mrqa_squad-validation-7559", "mrqa_naturalquestions-validation-3431", "mrqa_squad-validation-6116", "mrqa_squad-validation-5547", "mrqa_naturalquestions-validation-6486", "mrqa_naturalquestions-validation-2280", "mrqa_squad-validation-3333", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-3661", "mrqa_naturalquestions-validation-8993", "mrqa_naturalquestions-validation-6414", "mrqa_naturalquestions-validation-9857", "mrqa_squad-validation-7145", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-6927", "mrqa_squad-validation-4185", "mrqa_squad-validation-2", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-4459", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-9967", "mrqa_squad-validation-3137", "mrqa_naturalquestions-validation-6391", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-7624", "mrqa_squad-validation-9963", "mrqa_naturalquestions-validation-6087", "mrqa_squad-validation-118", "mrqa_squad-validation-4014", "mrqa_squad-validation-3267", "mrqa_squad-validation-2949", "mrqa_squad-validation-164", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4611", "mrqa_squad-validation-9928", "mrqa_naturalquestions-validation-1748", "mrqa_naturalquestions-validation-9360", "mrqa_squad-validation-4502", "mrqa_naturalquestions-validation-2355", "mrqa_squad-validation-1075", "mrqa_naturalquestions-validation-9511", "mrqa_naturalquestions-validation-2396", "mrqa_naturalquestions-validation-2698", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-1831", "mrqa_squad-validation-5051", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-4443", "mrqa_naturalquestions-validation-5180", "mrqa_squad-validation-7980", "mrqa_squad-validation-7430", "mrqa_squad-validation-3642", "mrqa_squad-validation-10293", "mrqa_squad-validation-5442", "mrqa_squad-validation-9771", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-7852", "mrqa_squad-validation-4539", "mrqa_naturalquestions-validation-5984", "mrqa_squad-validation-7410", "mrqa_naturalquestions-validation-1157", "mrqa_squad-validation-2665", "mrqa_squad-validation-1073", "mrqa_naturalquestions-validation-6800", "mrqa_squad-validation-6150", "mrqa_squad-validation-867", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-7893", "mrqa_squad-validation-8234", "mrqa_naturalquestions-validation-8849", "mrqa_naturalquestions-validation-4604", "mrqa_squad-validation-2877", "mrqa_naturalquestions-validation-897", "mrqa_squad-validation-9600", "mrqa_naturalquestions-validation-8568", "mrqa_squad-validation-8601", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-10343", "mrqa_squad-validation-6999", "mrqa_naturalquestions-validation-8849", "mrqa_naturalquestions-validation-10249", "mrqa_squad-validation-5670", "mrqa_squad-validation-7544", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3143", "mrqa_squad-validation-6685", "mrqa_naturalquestions-validation-5105", "mrqa_squad-validation-3712", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6055", "mrqa_squad-validation-9726", "mrqa_squad-validation-7983", "mrqa_naturalquestions-validation-3146", "mrqa_squad-validation-9058", "mrqa_naturalquestions-validation-7262", "mrqa_squad-validation-7023", "mrqa_squad-validation-6897", "mrqa_squad-validation-3723", "mrqa_naturalquestions-validation-4549", "mrqa_naturalquestions-validation-3625", "mrqa_squad-validation-864", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-3442", "mrqa_squad-validation-4176", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-4033", "mrqa_squad-validation-2779", "mrqa_squad-validation-112", "mrqa_squad-validation-4078", "mrqa_squad-validation-2334", "mrqa_squad-validation-5457", "mrqa_squad-validation-5456", "mrqa_naturalquestions-validation-4729", "mrqa_naturalquestions-validation-9830", "mrqa_squad-validation-5260", "mrqa_squad-validation-4332", "mrqa_naturalquestions-validation-10537", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-10073", "mrqa_squad-validation-2000", "mrqa_naturalquestions-validation-6021", "mrqa_squad-validation-5589", "mrqa_squad-validation-3142", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-7564", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-7463", "mrqa_squad-validation-6980", "mrqa_naturalquestions-validation-2644", "mrqa_squad-validation-5265", "mrqa_squad-validation-6899", "mrqa_squad-validation-1979", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-4922", "mrqa_squad-validation-9666", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4013", "mrqa_naturalquestions-validation-1567", "mrqa_naturalquestions-validation-1696", "mrqa_squad-validation-6256", "mrqa_naturalquestions-validation-10098", "mrqa_squad-validation-1578", "mrqa_naturalquestions-validation-3287", "mrqa_squad-validation-2857", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-2548", "mrqa_squad-validation-9923", "mrqa_naturalquestions-validation-5711", "mrqa_squad-validation-4402", "mrqa_naturalquestions-validation-2900", "mrqa_squad-validation-10317", "mrqa_naturalquestions-validation-2418", "mrqa_naturalquestions-validation-6821", "mrqa_squad-validation-1163", "mrqa_naturalquestions-validation-9545", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-4038", "mrqa_squad-validation-3474", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-9917", "mrqa_naturalquestions-validation-9963", "mrqa_squad-validation-7137", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4870", "mrqa_naturalquestions-validation-6678", "mrqa_squad-validation-6403", "mrqa_naturalquestions-validation-3074", "mrqa_naturalquestions-validation-2396", "mrqa_naturalquestions-validation-10537", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-8287", "mrqa_squad-validation-283", "mrqa_naturalquestions-validation-3284", "mrqa_naturalquestions-validation-7803", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-5460", "mrqa_squad-validation-4318", "mrqa_squad-validation-3486", "mrqa_squad-validation-6737", "mrqa_squad-validation-5240", "mrqa_squad-validation-6787", "mrqa_naturalquestions-validation-3632", "mrqa_squad-validation-4448", "mrqa_squad-validation-9846", "mrqa_naturalquestions-validation-5234", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-191", "mrqa_squad-validation-1742", "mrqa_squad-validation-5903", "mrqa_squad-validation-9771", "mrqa_squad-validation-728", "mrqa_squad-validation-9762", "mrqa_squad-validation-3223", "mrqa_naturalquestions-validation-5838", "mrqa_squad-validation-5464", "mrqa_naturalquestions-validation-10073", "mrqa_squad-validation-415", "mrqa_squad-validation-9046", "mrqa_squad-validation-9088", "mrqa_naturalquestions-validation-10259", "mrqa_squad-validation-7688", "mrqa_squad-validation-10464", "mrqa_naturalquestions-validation-8555", "mrqa_naturalquestions-validation-7579", "mrqa_squad-validation-1951", "mrqa_squad-validation-1636", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-2524", "mrqa_squad-validation-2673", "mrqa_squad-validation-1575", "mrqa_naturalquestions-validation-2951", "mrqa_squad-validation-8991", "mrqa_squad-validation-7735", "mrqa_naturalquestions-validation-6650", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-1735", "mrqa_squad-validation-278", "mrqa_squad-validation-4099", "mrqa_naturalquestions-validation-4561", "mrqa_squad-validation-1132", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-4498", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-6408", "mrqa_squad-validation-6267", "mrqa_naturalquestions-validation-9523", "mrqa_squad-validation-5051", "mrqa_squad-validation-833", "mrqa_squad-validation-3368", "mrqa_squad-validation-5098", "mrqa_squad-validation-7890", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-5934", "mrqa_squad-validation-6265", "mrqa_squad-validation-10397", "mrqa_squad-validation-9369", "mrqa_squad-validation-7917", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-7141", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-10034", "mrqa_squad-validation-7877", "mrqa_squad-validation-2948", "mrqa_naturalquestions-validation-9781", "mrqa_squad-validation-7507", "mrqa_squad-validation-3873", "mrqa_naturalquestions-validation-9944", "mrqa_squad-validation-2611", "mrqa_squad-validation-2651", "mrqa_naturalquestions-validation-3545", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-9766", "mrqa_squad-validation-3150", "mrqa_squad-validation-9145", "mrqa_squad-validation-9263", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-4599", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-4108", "mrqa_naturalquestions-validation-3560", "mrqa_naturalquestions-validation-10583", "mrqa_squad-validation-88", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-7593", "mrqa_squad-validation-8310", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-7910", "mrqa_squad-validation-7974", "mrqa_naturalquestions-validation-7967", "mrqa_squad-validation-351", "mrqa_naturalquestions-validation-3525", "mrqa_naturalquestions-validation-6769", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-5067", "mrqa_squad-validation-2692", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-8281", "mrqa_squad-validation-2090", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3119", "mrqa_squad-validation-8033", "mrqa_naturalquestions-validation-5092", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-8883", "mrqa_squad-validation-9599", "mrqa_naturalquestions-validation-8151", "mrqa_squad-validation-1328", "mrqa_naturalquestions-validation-950", "mrqa_squad-validation-8701", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-3004", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-1400", "mrqa_naturalquestions-validation-2232", "mrqa_squad-validation-3907", "mrqa_squad-validation-3864", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-7511", "mrqa_squad-validation-7186", "mrqa_squad-validation-9629", "mrqa_squad-validation-6376", "mrqa_naturalquestions-validation-2556", "mrqa_squad-validation-3122", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-9058", "mrqa_naturalquestions-validation-7202", "mrqa_squad-validation-5763", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-5812", "mrqa_squad-validation-1651", "mrqa_squad-validation-8368", "mrqa_naturalquestions-validation-4816", "mrqa_squad-validation-9446", "mrqa_squad-validation-7535", "mrqa_naturalquestions-validation-1587", "mrqa_squad-validation-4186", "mrqa_naturalquestions-validation-9972", "mrqa_naturalquestions-validation-3477", "mrqa_squad-validation-2999", "mrqa_squad-validation-2011", "mrqa_naturalquestions-validation-8478", "mrqa_squad-validation-2332", "mrqa_squad-validation-3495", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_squad-validation-7485", "mrqa_squad-validation-9084", "mrqa_naturalquestions-validation-7589", "mrqa_squad-validation-9002", "mrqa_squad-validation-6451", "mrqa_naturalquestions-validation-2084", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-7639", "mrqa_squad-validation-7584", "mrqa_naturalquestions-validation-6769", "mrqa_squad-validation-896", "mrqa_squad-validation-5836", "mrqa_naturalquestions-validation-1851", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-1220", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-40", "mrqa_squad-validation-9745", "mrqa_naturalquestions-validation-5155", "mrqa_squad-validation-8621", "mrqa_naturalquestions-validation-2873", "mrqa_squad-validation-9767", "mrqa_squad-validation-4516", "mrqa_naturalquestions-validation-3112", "mrqa_squad-validation-3343", "mrqa_naturalquestions-validation-1592", "mrqa_naturalquestions-validation-3678", "mrqa_squad-validation-10479", "mrqa_naturalquestions-validation-9062", "mrqa_squad-validation-3491", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-94", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-243", "mrqa_squad-validation-7765", "mrqa_squad-validation-512", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-5451", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-3802", "mrqa_squad-validation-7357", "mrqa_naturalquestions-validation-4571", "mrqa_naturalquestions-validation-9903", "mrqa_squad-validation-8763", "mrqa_squad-validation-9784", "mrqa_naturalquestions-validation-8120", "mrqa_squad-validation-5250", "mrqa_squad-validation-9134", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-7300", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-233", "mrqa_squad-validation-7134", "mrqa_squad-validation-8548", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-7785", "mrqa_squad-validation-4067", "mrqa_naturalquestions-validation-475", "mrqa_squad-validation-937", "mrqa_naturalquestions-validation-1787", "mrqa_naturalquestions-validation-4837", "mrqa_squad-validation-10269", "mrqa_naturalquestions-validation-6556", "mrqa_squad-validation-64", "mrqa_squad-validation-10014", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-7814", "mrqa_squad-validation-7809", "mrqa_squad-validation-1482", "mrqa_naturalquestions-validation-2698"], "OKR": 0.845703125, "KG": 0.3765625, "before_eval_results": {"predictions": ["ulemas", "Denver Broncos", "more equality in the income distribution", "Roentgen rays", "British", "Tehachapi Mountains", "October 12, 1943", "within five years", "1963\u20131989", "Guantanamo Bay Naval Base", "the BBC", "October 27, 1904", "Sheev Palpatine", "Michelangelo", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "two - year", "the employer is required to pay the tax in installments during the tax year", "bicameral Congress", "the person compelled to pay for reformist programs", "the liver", "Italian Agostino Bassi", "the bloodstream", "Miami Heat", "Mahatma Gandhi", "Brian Johnson", "6", "Dust", "B.R. Ambedkar", "Audrey II", "he was unable to wrest", "November 17, 1800", "Super Bowl XXI", "1997", "entering Arkansas, turning south near Fulton, Arkansas, and flowing into Louisiana, where it flows into the Atchafalaya River", "Roman Reigns", "1624", "they were some of the largest wars that had ever taken place", "2002 Mitsubishi Lancer OZ Rally", "Murwillumbah, New South Wales, Australia", "fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Everywhere", "self - closing flood barrier", "warrior, mage, or rogue coming from an elven, human, or dwarven background", "Kirsten Simone Vangsness", "paid monument", "Howard Ellsworth Rollins Jr.", "a star", "between the Mediterranean Sea to the north and the Red Sea in the south", "5,534", "Walter Brennan", "South Dakota", "mashed potato", "Sarah Silverman", "December 24, 1836", "an edible tuber", "Roger Dean Stadium", "Malvolio", "April 10, 2018", "In Time", "Jackie Robinson", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) or Kozunak", "President Gerald Ford", "Fats Waller", "Guwahati and Kuladhar Chaliha"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7997549019607844}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.9, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-194", "mrqa_squad-validation-1505", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-4279", "mrqa_naturalquestions-validation-8733", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-9003", "mrqa_naturalquestions-validation-3593", "mrqa_naturalquestions-validation-8064", "mrqa_naturalquestions-validation-2042", "mrqa_naturalquestions-validation-5558", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-9613", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-3688"], "SR": 0.71875, "CSR": 0.64359375, "EFR": 0.8333333333333334, "Overall": 0.6804635416666667}]}