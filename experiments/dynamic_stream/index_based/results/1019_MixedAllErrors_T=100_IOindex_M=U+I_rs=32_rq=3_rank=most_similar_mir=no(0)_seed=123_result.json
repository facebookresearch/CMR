{"model_update_steps": 2575, "method_class": "index_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, index_rank_method='most_similar', indexing_args_path='exp_results/supervision_data/1012_dm_simple.train_args.json', indexing_method='bart_io_index', inference_query_size=1, init_memory_cache_path='exp_results/data_streams/bart_io_index.init_memory.pkl', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/index_based/ckpt_dir/1019_MixedAllErrors_T=100_IOindex_M=U+I_rs=32_rq=3_rank=most_similar_mir=no(0)_seed=123_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/index_based/ckpt_dir/1019_MixedAllErrors_T=100_IOindex_M=U+I_rs=32_rq=3_rank=most_similar_mir=no(0)_seed=123_ckpts/', replay_candidate_size=0, replay_frequency=3, replay_size=32, save_all_ckpts=0, skip_instant_eval=True, total_steps=10000, use_mir=False, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=100, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='exp_results/data_streams/mrqa.nq_train.memory.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion", "The Darling Buds of May", "Virginia Wade", "Gary Morris", "the anterolateral system", "1966", "for scientific observation", "The Ronseal Phrase - Does Exactly What it Says on the Tin", "The Stock Market crash in New York", "New York Stadium", "norman Tebbit", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "the final revelation of God the Final Testament", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs", "George Cross", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "The check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22138917914779982}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.19999999999999998, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.07407407407407407, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "sports, among them cricket, rallying, football, rugby union and boxing", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetic acid", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "technological advances to work from their homes", "is not yet a senior", "Bothtec", "Terry Reid", "available information about climate change based on published sources", "sept Princesses", "North America", "Andr\u00e9 3000", "a single veteran as Commander, with two rookies", "the Aten, a representation of the Egyptian god, Ra", "President Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "in the 1970s", "CarmenCarmen (", "Matt Winer", "1688 and 1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.09375, "QA-F1": 0.25825312351047647}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.8235294117647058, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.13333333333333333, 0.0, 1.0, 0.0, 0.1818181818181818, 0.0, 0.4444444444444445, 0.4, 0.4444444444444445, 1.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.3333333333333333, 0.0, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 3, "before_eval": {"predictions": ["id", "baijan", "c + angle d = 180 degrees", "between 27 July and 7 August 2022", "New York", "b b", "2006 British Academy Television Award for Best Drama Series", "Least of the Great Powers", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "bums", "Fred Archer", "coronary thrombosis", "bollywood", "Overtime", "Sir Henry Cole", "has trouble distinguishing between carbon dioxide and oxygen", "bambi", "cement City, Texas", "the Democratic Unionist Party (DUP )", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "for control purposes", "bridges", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins", "bile duct", "berenice Abbott"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11316964285714284}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.1, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "retrieved_ids": ["mrqa_triviaqa-validation-893", "mrqa_naturalquestions-train-43232", "mrqa_triviaqa-validation-2136", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-train-79133", "mrqa_naturalquestions-train-24159", "mrqa_naturalquestions-train-32769", "mrqa_naturalquestions-train-61966", "mrqa_naturalquestions-train-17885", "mrqa_naturalquestions-train-32711", "mrqa_naturalquestions-train-20360", "mrqa_hotpotqa-validation-1968", "mrqa_naturalquestions-train-73728", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-20328", "mrqa_triviaqa-validation-2367", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-1551", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-train-12896", "mrqa_triviaqa-validation-2722", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-train-52474", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-train-73085", "mrqa_naturalquestions-train-28696", "mrqa_triviaqa-validation-2722", "mrqa_triviaqa-validation-3915", "mrqa_naturalquestions-train-75921", "mrqa_naturalquestions-train-21612", "mrqa_naturalquestions-train-11402"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "maxus", "the man chosen to meet God on Sinai and receive the Law on behalf of God\u2019s chosen people", "museum", "lacerations", "bounding the time or space", "museum", "Alex O'Loughlin", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "bunker", "no barber", "Reverse - Flash", "All Souls'Day", "1968", "EOC", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America, and Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating in one direction", "Splodgenessabounds"], "metric_results": {"EM": 0.25, "QA-F1": 0.33549107142857143}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 0.3333333333333333, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_squad-validation-3467"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 5, "before_eval": {"predictions": ["museum", "International Association of Athletics Federations", "stathclyde", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "7 : 25 a.m.", "swanee or swannee whistle", "rapeseed plant", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "the Department of Physics, Cochin University of science and Technology", "parietal cells", "placental", "Ready to Die", "a revolver", "imperial rule", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "kinks", "by using net wealth (adding up assets and subtracting debts )", "entropy", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "Inez", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "a man named Daedalus"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17651466288269696}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.13333333333333333, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.5]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "to prevent the flame from being blown out", "Illinois", "1998", "North Carolina", "island in the Mediterranean Sea situated", "90-60's", "independent schools", "dolph Camilli", "the times sign", "BAFTA Television Award", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "Wichita", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "dads", "Butterfly Conservation", "universal", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land", "near Grande Comore, Comoros Islands", "rupees", "Norwegian", "fossil fuels"], "metric_results": {"EM": 0.125, "QA-F1": 0.17898065476190478}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 1.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "retrieved_ids": ["mrqa_naturalquestions-train-49618", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-train-21422", "mrqa_triviaqa-validation-254", "mrqa_naturalquestions-train-75359", "mrqa_naturalquestions-train-77499", "mrqa_naturalquestions-train-9637", "mrqa_hotpotqa-validation-5651", "mrqa_naturalquestions-train-18271", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-train-25477", "mrqa_naturalquestions-train-59946", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-train-25311", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-1437", "mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-train-85770", "mrqa_naturalquestions-train-73282", "mrqa_naturalquestions-train-75368", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-train-49458", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-train-44160", "mrqa_naturalquestions-train-64706", "mrqa_naturalquestions-train-81993", "mrqa_triviaqa-validation-254", "mrqa_naturalquestions-train-85422", "mrqa_naturalquestions-train-69411", "mrqa_naturalquestions-train-8861"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi", "a few common complex biomolecules", "The U.S. Army Chaplain insignia", "Kairi", "inner city blacks, who wanted more involvement in government", "Ray Milland", "Armenia", "Revelation was the last book accepted into the Christian biblical canon, and to the present day some `` Nestorian '' churches such as the Church of the East reject it", "Beyonc\u00e9", "but conductivity values are often reported as percent IACS", "for gallantry", "16 million", "1950s", "work oxen for haulage", "1998", "a priest", "third most abundant chemical element in the universe", "18 - season", "family member", "long-term environmental changes", "Learjet", "the unbalanced centripetal force", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "red", "present-day Charleston", "quiescent", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Heinz Guderian"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26441147292250233}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 0.0, 0.16, 0.4, 0.19999999999999998, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.23529411764705882, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "george george qc", "46.8", "6.4 nanometers apart", "Meghan Ory ( Red Riding Hood / Ruby ) would be departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "adrenal glands", "liberal arts", "the Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "St. Louis County", "1868", "2018", "red and white striped shirts with black shorts", "law firm", "Pottawatomie County", "orangutan", "theory of general relativity (GR )", "The church tower", "red", "Toronto, Ontario, Canada", "but the further into Wales you go - ie further into the strongholds of the still surviving ( and flourishing) Welsh language", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "the Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychotherapeutic theories and associated techniques", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York", "acidic bogs"], "metric_results": {"EM": 0.15625, "QA-F1": 0.31057547683051717}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.6451612903225806, 1.0, 1.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.4444444444444445, 0.4, 0.0, 0.0, 0.25, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 9, "before_eval": {"predictions": ["first developed and popularized by the Israeli company Mirabilis in 1996", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "but not actually find the right pan", "photosynthesis", "a wide range of society figures of the period", "ward Hotel", "The Daily Stormer", "spin triplet", "water", "president", "the citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co. fire", "acting", "C. W. Grafton", "liquid crystal", "Americans", "iPod Classic", "Sassy Girl", "prevent damage to the body", "General Hospital", "non-combustible substances that corrode, such as iron", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "the root respiration", "land - living organisms, both alive and dead, as well as carbon stored in soils", "Melbourne drug- dealer", "medium and heavy-duty diesel trucks", "testes"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33915941595169535}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.125, 0.0, 1.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 0.19999999999999998, 0.4, 0.0, 0.4, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23529411764705882, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-1327", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-5940", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "retrieved_ids": ["mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-train-60144", "mrqa_naturalquestions-train-33405", "mrqa_naturalquestions-train-24292", "mrqa_naturalquestions-train-24858", "mrqa_squad-validation-3625", "mrqa_naturalquestions-train-44389", "mrqa_naturalquestions-train-1404", "mrqa_naturalquestions-train-82863", "mrqa_naturalquestions-train-22567", "mrqa_naturalquestions-train-29726", "mrqa_naturalquestions-train-24858", "mrqa_naturalquestions-train-87508", "mrqa_naturalquestions-train-9444", "mrqa_naturalquestions-train-71471", "mrqa_hotpotqa-validation-1626", "mrqa_naturalquestions-train-17578", "mrqa_naturalquestions-train-8810", "mrqa_naturalquestions-train-52296", "mrqa_naturalquestions-train-27257", "mrqa_naturalquestions-train-80742", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-train-19034", "mrqa_naturalquestions-train-18425", "mrqa_naturalquestions-train-12746", "mrqa_naturalquestions-train-6991", "mrqa_naturalquestions-train-43830", "mrqa_naturalquestions-train-75385", "mrqa_naturalquestions-train-30306", "mrqa_triviaqa-validation-2327", "mrqa_naturalquestions-train-27805", "mrqa_naturalquestions-train-52915"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744)", "yellow fever", "three", "Las Vegas", "status code and reason message", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "a Dubliner tried to kill Benito Mussolini", "1987", "menhirs", "Victoria, Duchess of Kent", "10 logarithm", "Kon-Tiki", "the MGM Grand Garden Special Events Center", "digital fashion gallery", "Ronnie Hillman", "all-encompassing", "1987", "60", "Eagle Ridge Mall", "Robert Frederick Chelsea Moore OBE", "Rationing Stamps and Cards to reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present )", "Bacha", "a Belgian\u2013French explorer, spiritualist, Buddhist, anarchist and writer", "Jamestown", "Rouen Cathedral", "tree growth stages"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3034834956709957}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 1.0, 0.28571428571428575, 0.5, 1.0, 0.9333333333333333, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "\"Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "The TEU", "ice melting", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "june", "The world's longest suspension bridges are listed according to the length of their main span", "Luas", "handguns", "panegyric", "the Bulgars, and especially the Seljuk Turks", "a young officer named Fernando Urissa", "Volkswagen Beetle", "Dyess", "North American Technate", "Queen Elizabeth I", "infection, irritation, or allergies", "The tower is the most - visited paid monument in the world. An average of 25,000 people ascend the tower every day which can result in long queues", "the Vittorio Emanuele II Gallery and Piazza della Scala in a pedestrian area in the centre of the city", "catfish aquaculture", "atomic number 53", "Matt Lanter as Chicago Walp, a U.S. soldier guiding the Bellas during the tour, and Chloe's love interest", "Persian Gulf", "a co-op of grape growers", "Anthony Mann", "nabucodonosor", "1952", "the Charlotte Hornets", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.0625, "QA-F1": 0.19078088015682665}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.24000000000000002, 0.31578947368421056, 0.4, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.08695652173913043, 0.22222222222222224, 0.25]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 12, "before_eval": {"predictions": ["British rock group Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "August 31, 2014", "The stability, security, and predictability of British law and government", "Minos and Kokalos", "29 June 1941", "cienfuegos in the Las Villas province of Cuba", "benwell Towers", "Forbes in the Central West region of New South Wales, Australia", "Fort Bull, and Fort Williams (the latter two located on the Oneida Carry between the Mohawk River and Wood Creek at present-day Rome, New York )", "Dandy", "plexander", "Orwell himself", "Kvapil", "Gregg Popovich", "that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "innate response", "under the tutelage of his uncle Juan Nepomuceno Guerra", "a musician", "nodel", "December 1, 1969", "american", "jK Rowling", "California State Automobile Association", "\"alone\"", "Cinderella", "The astronauts were asphyxiated before the hatch could be opened", "a fear of seeming rude"], "metric_results": {"EM": 0.125, "QA-F1": 0.22074443981371225}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.15384615384615385, 0.0, 0.0, 1.0, 0.5263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.23529411764705882, 0.4, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, 0.47058823529411764]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "retrieved_ids": ["mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-train-6563", "mrqa_naturalquestions-train-54058", "mrqa_naturalquestions-train-47776", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-train-65386", "mrqa_triviaqa-validation-227", "mrqa_hotpotqa-validation-1201", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7021", "mrqa_naturalquestions-train-52565", "mrqa_naturalquestions-train-77778", "mrqa_naturalquestions-train-22812", "mrqa_naturalquestions-train-34336", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-train-22760", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-train-86445", "mrqa_triviaqa-validation-6639", "mrqa_hotpotqa-validation-1888", "mrqa_naturalquestions-train-62182", "mrqa_naturalquestions-train-23990", "mrqa_naturalquestions-train-41344", "mrqa_triviaqa-validation-4729", "mrqa_triviaqa-validation-1550", "mrqa_naturalquestions-train-35862", "mrqa_naturalquestions-train-64495", "mrqa_naturalquestions-train-3346", "mrqa_naturalquestions-train-49738", "mrqa_triviaqa-validation-4725", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-train-44254"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Jason Lee", "Napoleon's army", "ring", "3.7", "inequality increases", "tracey Stubbs", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "maryland", "paddington", "amyotrophic lateral sclerosis ( ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution, thus contributing immensely to the Swiss watchmaking industry", "the Evel Knievel craze of the mid 1970s", "Torah or Bible", "the western coast of Italy", "the first and only U.S. born world grand prix champion", "the quintessential New Orleans art form -- a jazz funeral without a body", "mid November", "Facebook", "beigel", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Seattle", "King George's War", "he cheated on Miley", "heavy metal", "Fort Snelling, Minnesota", "daguerreotypes", "infrequent rain and many sunny days"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20570887445887448}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.25, 0.0, 1.0, 0.2, 0.0, 0.3333333333333333, 0.0, 0.5]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "Chicago's first permanent non-native settler", "maryland", "derivative financial instrument", "electromagnetic waves", "a Wahhabi/ Salafi", "great", "Dimensions in Time", "Surveyor 3 unmanned lunar probe", "January 1981", "lutein", "baptismal theology", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "\u00a31 million", "slowing the vehicle", "Cheyenne", "fossils in sedimentary rocks", "Hanna- Barbera, The Jetsons", "\"comune\"", "efficient and effective management of money ( funds )", "Alba Longa", "maryland", "australia", "goalkeeper Timo Hildebrand", "both public services and public enterprises", "1940", "weak government institutions", "a god of the Ammonites", "cornea (the transparent layer at the front of the eye)", "Fester Addams", "Charles Whitman"], "metric_results": {"EM": 0.0625, "QA-F1": 0.13677156177156177}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Part 2", "the Flatbush section of Brooklyn, New York City", "San Antonio", "Akon, Christina Aguilera and Taio Cruz", "nola Taylor Redd", "a friend and publicist", "michael Ondaatje", "masons'marks", "Theodore Haynes (1989)", "the Old Town Hall, Gateshead", "The horn line at the end is performed by the Phenix Horns from Earth, Wind & Fire", "The neck", "1898", "professional wrestler", "Payaya Indians", "steal the plans for the Death Star, the Galactic Empire's superweapon", "vito Corleone", "jenny jN-4", "art", "gorillas", "March 15, 1945", "absolute temperature", "the whistle-blowing website", "J. Robert Oppenheimer", "bicuspid", "his brother, Menelaus", "25 November 2015", "tallahassee", "prefabricated housing projects", "brian baryledickens", "WWSB and WOTV"], "metric_results": {"EM": 0.0625, "QA-F1": 0.08070054945054944}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "retrieved_ids": ["mrqa_naturalquestions-train-30885", "mrqa_hotpotqa-validation-2150", "mrqa_naturalquestions-train-52318", "mrqa_hotpotqa-validation-1968", "mrqa_naturalquestions-validation-4309", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3149", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-train-13352", "mrqa_hotpotqa-validation-3976", "mrqa_triviaqa-validation-1521", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-train-33320", "mrqa_naturalquestions-train-12584", "mrqa_triviaqa-validation-4725", "mrqa_naturalquestions-train-7908", "mrqa_naturalquestions-train-49194", "mrqa_naturalquestions-train-19054", "mrqa_naturalquestions-train-71112", "mrqa_naturalquestions-train-72572", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-train-72137", "mrqa_naturalquestions-train-18150", "mrqa_hotpotqa-validation-2484", "mrqa_naturalquestions-train-85275", "mrqa_naturalquestions-train-64391", "mrqa_naturalquestions-train-9234", "mrqa_naturalquestions-train-18873", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-train-45042", "mrqa_naturalquestions-train-70645"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 16, "before_eval": {"predictions": ["florida", "vermier", "fred", "on the lateral side of the tibia, with which it is connected above and below", "ferguside royal clan", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "October 29, 1985", "Amway", "secondary school study", "Thomas Sowell", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "The Show Band Show", "Tanzanian Legal System and Legal Research", "Chad", "florida", "an open work crown", "allowing a child to go through a torturous treatment to gain information", "Fulham, Greater London, England", "French", "florida", "U.S. Marshals", "What's Up (TV series)", "supply chain management", "galileo", "Stanislaw August Poniatowski", "a method of elimination to reduce the simultaneous equations to a single equation with only one unknown", "florida", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "sheepskin and Merino Wool products", "Honolulu County, Hawaii, United States, on the island of Oahu"], "metric_results": {"EM": 0.03125, "QA-F1": 0.1625667735042735}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.2222222222222222, 0.0, 0.5, 0.0, 0.0, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.33333333333333337, 0.30769230769230765]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["belgium", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "isotopes", "James Zeebo", "sovereign states", "president of the United States Senate", "The Discovery Institute (DI) is a politically conservative non-profit think tank based in Seattle, Washington, best known for its advocacy of the pseudoscientific principle of intelligent design (ID)", "Sam's captured parents", "Australian", "30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "opportunities will vary by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Roy Warren Spencer", "\"antiforms\"", "June 9, 2015", "\"Veyyil\" (2006)", "Grace Nail Johnson", "Keith Richards", "prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "Godfrey Army Airfield", "teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "180th", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat of the National Basketball Association (NBA)", "33", "dactylosphaera vitifoliae", "Annual Conference Cabinet", "hockey player Hannah Macleod", "prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.15625, "QA-F1": 0.28688131313131315}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 0.0, 0.0, 0.0, 0.40909090909090906, 0.19999999999999998, 0.16, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.5, 0.0, 0.08333333333333333, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "Co-teachers work in sync with one another to create a climate of learning", "400 metres", "Pippa and Piper, respectively, Fred Armisen as Giuseppe, a Kenny G-like saxophone player, and Jason Sudeikis as Vance, an overzealous backup dancer", "the entertainment division", "curved path from a point A to a point B", "12", "the Great Exhibition of 1851", "Edward Longshanks and the Hammer of the Scots", "dave davis", "dundee palgrave.rlp.5100074", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "lithgow Palace", "\"Grindhouse\" fake trailer", "davenport", "digital transmission modes", "the Swiss- Austrian border", "lithium-ion battery", "821", "Sky channels", "liquid", "Kim Hyun-ah", "the races of highest'social efficiency'", "pitch range", "the \" King of Cool\"", "President Wilson and the American delegation from the Paris Peace Conference", "davis", "the fifth season", "dors", "Hockey Club Davos", "Michael Crawford", "Aibak's successor and son - in - law Iltutmish"], "metric_results": {"EM": 0.125, "QA-F1": 0.28593749999999996}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.2, 0.2857142857142857, 0.5, 0.09523809523809523, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.6666666666666666, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666665, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.4, 0.4, 0.25]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "retrieved_ids": ["mrqa_naturalquestions-train-53798", "mrqa_naturalquestions-train-83198", "mrqa_naturalquestions-train-56624", "mrqa_naturalquestions-train-31378", "mrqa_naturalquestions-train-37212", "mrqa_naturalquestions-train-11728", "mrqa_hotpotqa-validation-1168", "mrqa_naturalquestions-train-843", "mrqa_naturalquestions-train-20665", "mrqa_naturalquestions-train-30667", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-train-30124", "mrqa_naturalquestions-train-6834", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-1714", "mrqa_naturalquestions-train-7732", "mrqa_naturalquestions-train-27576", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-train-49135", "mrqa_naturalquestions-train-40774", "mrqa_triviaqa-validation-2376", "mrqa_naturalquestions-train-56633", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-train-57674", "mrqa_squad-validation-5210", "mrqa_naturalquestions-train-6950", "mrqa_triviaqa-validation-7332", "mrqa_hotpotqa-validation-335", "mrqa_naturalquestions-train-60822", "mrqa_triviaqa-validation-4583", "mrqa_naturalquestions-train-75298", "mrqa_triviaqa-validation-781"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "James Arness", "aragon", "11.1", "the first trans-Pacific flight from the United States to Australia", "Sharman Joshi", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "a divisor of p \u2212 1", "Ana", "Cherry Hill", "The Duel", "white Whale", "mary Myers", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "dave davis", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1974", "Nicki Minaj", "comic opera", "French Huguenot", "f1", "elisabeth", "Rugrats", "William the Conqueror", "Ben Gurion International Airport", "two", "Mainland Greece", "phlebotomists", "youngest", "Southern Progress Corporation"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24074212519936206}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.10526315789473684, 1.0, 0.3333333333333333, 1.0, 0.8, 0.0, 0.0, 0.4, 0.08333333333333334, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 20, "before_eval": {"predictions": ["gas turbines", "David Feldman", "the Sackler Centre for arts education", "dark on Both Sides", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Apollo", "ribosomal", "kingfisher", "six", "CCH Pounder as Loretta Wade, medical examiner   Shalita Grant as Sonja Percy, ATF Agent / NCIS Special Agent ( seasons 2 -- 4 ; recurring previously )", "Friends", "Stollen", "b Belfast", "heliocentric", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "bring about necessary change", "w Faulkner", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "\" My Love from the Star\" (2013)", "San Jose", "sea wasp", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "giving Super Bowl ever", "29.7", "b. j. Hunnicutt"], "metric_results": {"EM": 0.21875, "QA-F1": 0.30431547619047616}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.888888888888889, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier", "various registries", "blood", "Yazoo", "22 April 1894", "the remnants of very massive stars", "soul does not sleep (anima non sic dormit) but wakes (sed vigilat) and experiences visions", "cede", "Willie Nelson and Kris Kristofferson", "ill. (some col.)", "5 University of California", "a French pirate", "Lewis", "Charles Dickens", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "(i.e. exceeds any given number) so there must be infinitely many primes", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "R\u00e5", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "Ian Fleming", "4 in ( 10 cm )", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "a backup to Brett Favre and holder on placekicks", "a trio"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2799664410720428}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4210526315789474, 1.0, 1.0, 0.5, 0.0, 0.23529411764705882, 1.0, 1.0, 0.43750000000000006, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.2222222222222222]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-192", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "retrieved_ids": ["mrqa_naturalquestions-train-55567", "mrqa_naturalquestions-train-62037", "mrqa_hotpotqa-validation-1032", "mrqa_triviaqa-validation-2327", "mrqa_naturalquestions-train-29405", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-train-53674", "mrqa_hotpotqa-validation-4627", "mrqa_triviaqa-validation-46", "mrqa_hotpotqa-validation-4263", "mrqa_naturalquestions-train-23459", "mrqa_triviaqa-validation-4486", "mrqa_naturalquestions-train-28229", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-train-23", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-3798", "mrqa_naturalquestions-train-23969", "mrqa_naturalquestions-train-57543", "mrqa_triviaqa-validation-2722", "mrqa_squad-validation-10202", "mrqa_naturalquestions-train-20986", "mrqa_naturalquestions-train-59481", "mrqa_naturalquestions-train-52315", "mrqa_naturalquestions-train-82568", "mrqa_naturalquestions-train-28838", "mrqa_naturalquestions-train-79043", "mrqa_naturalquestions-train-39013", "mrqa_naturalquestions-train-79548", "mrqa_naturalquestions-train-26199"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "Mediterranean Shipping Company S.A. ( MSC ), the world's second biggest container shipping operator", "taxes are simply contributions demanded of citizens as their share of the expenses of government", "a European fairy tale", "The centre-right Australian Labor Party", "Royalists", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "The words ( based on Genesis 3 : 19 ) used traditionally to accompany this gesture are, `` Memento, homo, quia pulvis es, et in pulverem reverteris. ''", "death to spies", "20,000 leagues under the sea", "Augustus Waters", "1619", "Tony Blair", "The Daily Mail newspaper reported in 2012 that the UK government's benefits agency was checking claimants' \" Sky TV bills to establish if a woman in receipt of benefits as a single mother is wrongly claiming to be living alone\"", "June 11, 1973", "Kenya", "a chronological collection of critical quotations about William Shakespeare and his works", "boudicca", "an active supporter of the League of Nations", "Cargill", "AMC Theatres", "\"The Gang\"", "3 October 1990", "September 21, 2017", "The weak force", "Blandings", "oldest son", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33581357878232876}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.4, 0.42857142857142855, 0.0, 0.0, 0.3333333333333333, 0.33333333333333337, 0.1111111111111111, 0.10256410256410256, 0.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.0, 0.0, 0.0, 0.625, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_squad-validation-2828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 23, "before_eval": {"predictions": ["an additional $105 billion in growth to the country's economy over five years", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "j Javier (Luna)", "zinc silicate primer and vinyl topcoats", "Dreamland", "Best Animated Feature", "European Union institutions", "381.6 days", "nine other contenders from across the United States", "CAL IPSO", "lesser celandine", "Ulbricht", "Ronnie Schell", "artemisinin", "Tata Consultancy Services Limited (TCS) is an Indian multinational information technology (IT) service, consulting and business solutions company Headquartered in Mumbai, Maharashtra", "east of Ireland", "1940", "the 2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "southern Hemisphere", "Solitaire is a fictional character in the James Bond novel and film Live and Let Die", "Incudomalleolar joint", "bobby riggs", "Democritus", "Santa Clara Marriott", "norante con moto", "political power generated by wealth", "log-space reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.21875, "QA-F1": 0.32972270784770785}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true], "QA-F1": [0.3076923076923077, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.6666666666666666, 0.25, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.4444444444444445, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-542", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt", "alchemy", "WBC and lineal titles", "moluccas", "Saturday", "Lear enters bearing Cordelia's corpse in his arms, having survived by killing the executioner", "American Secretary of State Henry Kissinger had negotiated an Israeli troop withdrawal from parts of the Sinai Peninsula", "1990", "J.R. R. Tolkien", "John Elway", "Selena Gomez", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program and learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "bingo", "Eugene", "is an unofficial title sometimes given to new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "the form 2p + 1 with p prime", "letter", "Fa Ze Rug", "dante alighieri", "Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor Conventual", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "STS-51-C.", "it will retreat to its den and winter will persist for six more weeks", "edith cresson"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3572173331527697}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.20689655172413793, 0.0, 0.5714285714285715, 1.0, 0.0, 0.6486486486486487, 0.0, 0.0, 0.4, 0.9090909090909091, 0.0, 0.4, 1.0, 1.0, 0.2222222222222222, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5957446808510638, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "retrieved_ids": ["mrqa_naturalquestions-train-9352", "mrqa_hotpotqa-validation-4977", "mrqa_triviaqa-validation-1166", "mrqa_naturalquestions-train-11032", "mrqa_triviaqa-validation-1551", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-train-64234", "mrqa_naturalquestions-train-43517", "mrqa_naturalquestions-train-19926", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-train-69303", "mrqa_naturalquestions-train-59002", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-2191", "mrqa_triviaqa-validation-2722", "mrqa_naturalquestions-train-61312", "mrqa_naturalquestions-train-80378", "mrqa_hotpotqa-validation-4263", "mrqa_naturalquestions-train-38540", "mrqa_naturalquestions-train-22664", "mrqa_naturalquestions-train-80017", "mrqa_naturalquestions-train-30040", "mrqa_naturalquestions-train-62898", "mrqa_triviaqa-validation-6556", "mrqa_squad-validation-2412", "mrqa_naturalquestions-train-49100", "mrqa_hotpotqa-validation-1289", "mrqa_naturalquestions-train-41130", "mrqa_naturalquestions-train-76731", "mrqa_naturalquestions-train-19270", "mrqa_naturalquestions-train-1312"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 25, "before_eval": {"predictions": ["synchronized skating", "Sarah's slave, Abraham's concubine", "over 50 million singles", "states'rights to expand slavery", "1923 and 1925", "Orlando\u2013Kissimmee\u2013 Sanford, Florida Metropolitan Statistical Area", "January 19, 1962", "Frigate", "maryland", "iteratively", "geese", "the move from the manufacturing sector to the service sector", "Brisbane", "Colin Baker", "February 14, 1859", "lower rates of health and social problems", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "A Chorus Line", "2,664 rooms and 220 suites", "iPhone 6", "chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning services, support services, property services, catering services, security services and facility management services", "Symphony No. 7", "zhee rond", "1603", "ranked above the two personal physicians of the Emperor", "Nutcracker", "made direct amends to such people wherever possible, except when to do so would injure them or others", "Cubs"], "metric_results": {"EM": 0.25, "QA-F1": 0.4107836607836608}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.25, 0.33333333333333337, 0.4615384615384615, 0.923076923076923, 0.0, 0.33333333333333337, 1.0, 0.2857142857142857, 0.3636363636363636, 0.4444444444444445, 1.0, 0.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "south", "Magic formula investing", "true history of the Kelly Gang", "O\u02bb ahu, City and County of Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz improvisation", "Harry Hopman", "4,000", "Khagan", "Heathcliff and Catherine Earnshaw", "canal", "spice", "The Simpsons Spin-Off Showcase", "Raymond Unwin", "Riverside", "A portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre", "Albany High School", "Agra garden", "Sergeant First Class", "Anakin Skywalker", "seek jury nullification", "Cee - Lo", "Church of England", "mammy two Shoes", "warcruiser Renown, the cruiser Kenya and six destroyers", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "The economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "January 11, 1755 or 1757July 12, 1804"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4990079365079365}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, false], "QA-F1": [0.8, 1.0, 0.0, 0.33333333333333337, 0.8333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8333333333333333]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-5184", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 27, "before_eval": {"predictions": ["l.A. producer Bones Howe", "faniel geldof", "red", "hor Orion", "\" Big Mamie\"", "tanzania", "Robert Ciaro, an amalgamation of several Hoffa associates over the years", "a light sky-blue color caused by absorption in the red", "they captured the Tower of London", "2009", "2005\u201306 NBA season", "the inner chloroplast membrane", "aline charigot", "Grand Annual Steeplechase at Warrnambool", "in this case, B SkyB does not carry any control over the channel's content or carriage issues such as picture quality", "the fourth season", "a more fundamental electrostrong interaction", "availability of skilled tradespeople", "hardness of a mineral", "A simple iron boar crest", "the University of Northumbria at Newcastle in 1992 as part of the UK-wide process in which polytechnics became new universities", "japan", "James", "on kickoffs at the 25 - yard line", "the Latin centum", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "that righteousness not only comes from Christ but actually is the righteousness of Christ, imputed to Christians ( rather than infused into them) through faith", "ludwig", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "group"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2887438767372978}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.75, 0.28571428571428575, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.631578947368421, 0.0, 1.0, 1.0, 0.08333333333333333, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "retrieved_ids": ["mrqa_naturalquestions-train-51073", "mrqa_naturalquestions-train-4468", "mrqa_naturalquestions-train-30204", "mrqa_naturalquestions-train-33686", "mrqa_triviaqa-validation-1437", "mrqa_triviaqa-validation-6639", "mrqa_triviaqa-validation-4852", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5526", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6772", "mrqa_triviaqa-validation-5239", "mrqa_triviaqa-validation-893", "mrqa_squad-validation-1750", "mrqa_naturalquestions-train-6165", "mrqa_triviaqa-validation-5997", "mrqa_squad-validation-9841", "mrqa_naturalquestions-train-81278", "mrqa_triviaqa-validation-7304", "mrqa_naturalquestions-train-26668", "mrqa_naturalquestions-train-57237", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-train-30979", "mrqa_naturalquestions-train-10724", "mrqa_naturalquestions-train-66140", "mrqa_hotpotqa-validation-4020", "mrqa_naturalquestions-train-8810", "mrqa_triviaqa-validation-7100", "mrqa_naturalquestions-train-35711", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-train-33104", "mrqa_naturalquestions-train-63952"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 28, "before_eval": {"predictions": ["the Turk", "Chris Weidman", "jury nullification", "Harishchandra", "Arabic grammar", "Professor Eobard Thawne", "slivovitz", "US$10 a week raise over Tesla's US$18 per week salary", "1875", "member states", "because of all the instruments", "McKinsey's offices in Silicon Valley and India", "gyphidiophobia", "Cliff Richard", "Crohn's disease", "Ondemar Dias", "Raya Yarbrough", "No. 1 seed Virginia and No. 4 seed Arizona", "michael dokes", "John D. Rockefeller", "Old Testament", "big brown", "local talent", "Football League", "re-encountered tygan", "mafic to felsic composition", "that contemporary accounts were exaggerations", "John Surratt, Jr.", "1340", "dodo bird", "by focusing on positive or negative thoughts", "renoir"], "metric_results": {"EM": 0.125, "QA-F1": 0.24276938339438342}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.4444444444444445, 0.0, 0.4444444444444445, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 1.0, 0.5384615384615384, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_squad-validation-8190", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 29, "before_eval": {"predictions": ["poisonous", "886 AD", "to finance his own projects with varying degrees of success", "Le Mans", "Kinect", "Tokyo", "defensive end Kony Ealy", "parallelogram rule of vector addition", "abraham laulston", "blackbirds", "Neutron sources", "Don McLean", "the bore, and often the stroke", "six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Imperial Secretariat", "Doctorin' the Tardis", "National Basketball Development League", "gillingham", "St. Mary's County", "Graham Gano", "2,615", "Pyeongchang", "Kaep", "a password recovery tool for Microsoft Windows", "Captain John Guidry", "Charles and Ray Eames", "Brazil", "Steve Redgrave", "smallest subfield", "heartburn", "53 percent", "NADPH"], "metric_results": {"EM": 0.125, "QA-F1": 0.22326680672268912}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-3103", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-7445", "mrqa_squad-validation-8873"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 30, "before_eval": {"predictions": ["judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "an outgoing, eccentic, big - hearted, loving, sweet, and thoughtful elephant and teacher", "abraham lincoln", "arthur Sinclair", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "BBC UKTV", "stieg Larsson", "demographics and economic ties", "three or more", "The Kickoff Game", "narcolepsy", "arctic monkeys", "monza", "arthur", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "instructions", "The Greens, who won their first lower house seats in 2014, are strongest in inner Melbourne", "marduk", "arctic fox", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "karl d. Daniels", "down the Australian northeast coast", "Article 7, Paragraph 4", "New Jersey", "Easy", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "Jawaharlal Nehru", "National Lottery", "Apollo", "katherine swynford", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.0625, "QA-F1": 0.12201918147641831}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.4, 1.0, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "retrieved_ids": ["mrqa_triviaqa-validation-3603", "mrqa_hotpotqa-validation-4263", "mrqa_naturalquestions-train-80228", "mrqa_naturalquestions-train-68279", "mrqa_triviaqa-validation-6901", "mrqa_triviaqa-validation-4383", "mrqa_triviaqa-validation-1935", "mrqa_naturalquestions-train-29617", "mrqa_naturalquestions-train-45009", "mrqa_naturalquestions-validation-10509", "mrqa_triviaqa-validation-4725", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1201", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-train-23528", "mrqa_naturalquestions-train-9493", "mrqa_triviaqa-validation-1259", "mrqa_triviaqa-validation-4583", "mrqa_hotpotqa-validation-511", "mrqa_hotpotqa-validation-2673", "mrqa_naturalquestions-train-16214", "mrqa_triviaqa-validation-622", "mrqa_naturalquestions-train-50602", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-5996", "mrqa_naturalquestions-train-41449", "mrqa_naturalquestions-train-34740", "mrqa_triviaqa-validation-6692", "mrqa_naturalquestions-train-53217", "mrqa_triviaqa-validation-4402", "mrqa_triviaqa-validation-2722", "mrqa_triviaqa-validation-46"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 31, "before_eval": {"predictions": ["Yolanda Sald\u00edvar", "Thiel", "st Valentine's Day", "football commentator", "Newell Highway", "polly", "a horse is 15 hands tall", "shopping mall", "Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions, in allocution", "DreamWorks Animation", "waltz", "his own men", "emissions resulting from human activities", "polly", "the RAF", "reduce growth in relatively poor countries", "Ishar- Damu", "strictly", "Polish-Jewish", "a variety of political groups", "polly", "polly", "390 billion", "Washington Street", "May 10, 1976", "6", "polly", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "polly", "John Smith", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.125, "QA-F1": 0.25}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.45000000000000007, 0.0, 1.0, 1.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_hotpotqa-validation-1444", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_squad-validation-3106"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "beer festival", "South Africa's northern Limpopo province", "Matt Jones", "kalium", "extreme circumstances", "CD4+ and CD8+", "relatively low salaries", "fruit", "Heading Out to the Highway", "Moonraker", "Wii U", "Michael Oppenheimer", "England national team", "entitled institutionally and legally", "Jumping on the Moon", "Convention", "5,922", "December 5, 1991", "2016", "Philadelphia 76ers", "traditions surrounding the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas", "Stern-Plaza", "WBC/WBA heavyweight champion Joe Frazier", "23 March 1991", "Sunday", "the historic West End district of downtown Dallas", "Dar es Salaam", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.21875, "QA-F1": 0.308255112942613}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.15384615384615385, 1.0, 0.0, 0.5, 0.0, 0.25, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\" Boston Herald\" Rumor Clinic", "1967", "\"Footprints in the Sand\"", "the twelfth most populous city in the United States", "115", "bridge", "causes changes in gene expression", "lower", "bass", "Tzeitel", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country, hugging the east side of the Mississippi River and its tributaries", "japan", "seaman", "Yunnan- Fu", "Mumbai", "Sydney", "2005", "all punishments and granted them salvation", "\"The Doctor's Daughter\"", "bridge", "cole albert", "The project must adhere to zoning and building code requirements. Constructing a project that fails to adhere to codes does not benefit the owner", "1879", "daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "enthusiasm and energy", "reno", "Nissan (then known as Datsun) introduced larger cars such as the Toyota Corona Mark II, the Toyota Cressida, the Mazda 616 and Datun 810", "Bill Clinton", "Hordaland, Rogaland and Aust-Agder"], "metric_results": {"EM": 0.09375, "QA-F1": 0.16929214083752622}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12121212121212123, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.0, 0.0, 0.06896551724137931, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "retrieved_ids": ["mrqa_hotpotqa-validation-2937", "mrqa_naturalquestions-train-47410", "mrqa_naturalquestions-train-80387", "mrqa_naturalquestions-train-72496", "mrqa_hotpotqa-validation-2771", "mrqa_naturalquestions-train-87902", "mrqa_triviaqa-validation-1306", "mrqa_naturalquestions-train-72924", "mrqa_triviaqa-validation-6721", "mrqa_naturalquestions-train-30761", "mrqa_naturalquestions-train-48454", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-train-18344", "mrqa_triviaqa-validation-1306", "mrqa_triviaqa-validation-6331", "mrqa_naturalquestions-train-15444", "mrqa_naturalquestions-train-66535", "mrqa_naturalquestions-train-36669", "mrqa_triviaqa-validation-3678", "mrqa_naturalquestions-train-6209", "mrqa_naturalquestions-train-83495", "mrqa_naturalquestions-train-64832", "mrqa_hotpotqa-validation-35", "mrqa_naturalquestions-train-16915", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-train-28325", "mrqa_triviaqa-validation-6950", "mrqa_triviaqa-validation-46", "mrqa_hotpotqa-validation-1968", "mrqa_triviaqa-validation-5962", "mrqa_naturalquestions-train-17476", "mrqa_naturalquestions-train-86314"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "king George VI", "engaging in the forbidden speech", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "boulangere", "0.2 inhabitants per square kilometre", "red", "France", "Ian Paisley", "bataan", "euro", "London", "United States", "Sherry Rowland and Mario Molina", "London and New York, c. 1886", "St. Louis Rams", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "juba", "pole", "Johnny Darrell", "a waxy substance called plaque builds up inside the carotid arteries", "margarine", "the sum of divisors function", "ear canal", "the set of all connected graphs", "Busiest airports in the United States by international passenger traffic", "red", "Honda Accord", "Kurt Vonnegut", "tenth official Disney Princess"], "metric_results": {"EM": 0.125, "QA-F1": 0.1620497557997558}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "based on the interplay of supply and demand, which determines the prices of goods and services", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain", "\u201cbig\u201d", "Washington Redskins", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "William Howard Ashton", "an oil reserve near a rock formation north of Casper, Wyo.", "promoting social dislocation, unrest and conflict", "Broward County", "Jung Woo-sung", "changing display or audio settings quickly", "Battle of Marston Moor", "derived from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "the income share of the top 20 percent (the rich) increases", "Beauty and the Beast", "South Africa", "Tyler \" Ty\" Mendoza on \"Switched at Birth\" and Simon Waverly on \"Satisfaction\"", "alamo", "a seal illegally is broken", "United Methodist", "Brian Liesegang", "Rob Minkoff", "Papua New Guinea", "Alvin Simon Theodore Ross Bagdasarian", "National Association for the Advancement of Colored People", "1963\u20131989", "the Titanic hit an iceberg and sank", "John Prescott", "Darrin Stephens", "6500 - 1500 BC"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27286706349206347}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.5, 0.11111111111111112, 0.14285714285714288, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.4, 0.0, 0.4, 0.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Kevin Costner, Amber Heard, Hailee Steinfeld, Connie Nielsen, Richard Sammel, and Eriq Ebouaney", "planet Uranus", "president", "Cobham\u2013Edmonds thesis", "human, or humanoid aliens", "Best Male Pop Vocal Performance", "March 2012", "jazz club", "Muhammad Ali", "Beyonc\u00e9 and Bruno Mars", "Menorca", "plead guilty to one misdemeanor count and receive no jail time", "Julius Caesar", "2", "Depression era", "Wade Watts, a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "decision problem", "10th", "heart", "Miasma theory", "drinkware made to hold either a British ( `` imperial '' ) pint of 20 imperial fluid ounces ( 568 ml ) or an American pint of 16 US fluid ounces", "mountain ranges", "imperial war flag", "Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571, with exports to other states occurring around 1858.", "butterflyweed", "US $3 per barrel", "flat", "Love Is All Around", "to build a nationwide network in the UK", "roughly west", "Sudan"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2826745014245014}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.9333333333333333, 0.4444444444444445, 0.0, 0.4, 0.0, 0.23076923076923078, 1.0, 0.0, 0.14814814814814814, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-4115", "mrqa_hotpotqa-validation-1884", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_triviaqa-validation-4069", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "retrieved_ids": ["mrqa_naturalquestions-train-81061", "mrqa_naturalquestions-train-82445", "mrqa_naturalquestions-train-28354", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-3241", "mrqa_naturalquestions-train-28875", "mrqa_naturalquestions-train-18673", "mrqa_naturalquestions-train-84807", "mrqa_hotpotqa-validation-1657", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-train-33509", "mrqa_naturalquestions-train-20829", "mrqa_naturalquestions-train-68798", "mrqa_hotpotqa-validation-2092", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-1374", "mrqa_squad-validation-108", "mrqa_naturalquestions-train-24957", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-1201", "mrqa_naturalquestions-train-63736", "mrqa_triviaqa-validation-3714", "mrqa_naturalquestions-train-25978", "mrqa_naturalquestions-train-43497", "mrqa_naturalquestions-train-63699", "mrqa_naturalquestions-validation-5180", "mrqa_hotpotqa-validation-2673", "mrqa_naturalquestions-train-34987", "mrqa_naturalquestions-train-60025", "mrqa_triviaqa-validation-6107"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 37, "before_eval": {"predictions": ["Southern Pacific", "three of his ribs", "7 December 2000", "Post Alley under Pike Place Market", "mother-of-pearl", "February 20, 1978", "stomach", "Walter Mondale", "96", "artes liberales", "japan", "white, blue, pink, rainbow neon and glittering dotted lines", "the alluvial plain", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Harry Kane", "a number of small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "numerous musical venues, including the Teatr Wielki, the Polish National Opera, the Chamber Opera, the National Philharmonic Hall and the National Theatre, as well as the Roma and Buffo music theatres", "riper grapes", "1991", "india", "7 January 1936", "lifetime protection", "twenty-four", "Carl Sagan", "Many of the city's tax base dissipated", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Christian Poulsen", "a defiant speech, or a speech explaining their actions", "a Distinctive Yogurt For Health", "Boston, Massachusetts"], "metric_results": {"EM": 0.21875, "QA-F1": 0.28840264724310777}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8750000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105, 0.07142857142857142, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "dragon", "The primary catalyst for secession was slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories.", "American Indian allies", "a children's story published by John Newbery in London in 1765", "It has the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east ).", "gathering money from the public", "Ethan", "The army requires officers to purchase and maintain only the blue service uniform", "Jeff Meldrum", "741 weeks", "Phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "Egyptian president Nasser", "60", "journalist", "the fact that there is no revising chamber", "florida", "when lifted to an extension field", "most of the items in the collection, unless those were newly accessioned into the collection", "does not satisfy the criteria", "strychnine", "Texas", "the early 16th century", "Lord's", "eddy Shah", "He is voiced by Clint Howard in the first film and by Jeff Bennett in The Jungle Book 2", "the closing of the atrioventricular valves and semilunar valves"], "metric_results": {"EM": 0.15625, "QA-F1": 0.28734984378366735}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 0.0, 0.05714285714285714, 0.47058823529411764, 0.0, 0.0, 0.25, 0.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.2857142857142857, 1.0, 0.6, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.9333333333333333]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 39, "before_eval": {"predictions": ["capital city of Taiwan", "Dan Conner", "Berlin", "President Kennedy assassination", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "anti-Semitism", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "keskes", "the 1980s", "John M. Grunsfeld, geneticist James Watson", "New York City", "a man who makes potions in a traveling show", "2003", "antlers are dropped or shed and grown anew each and every year. They grow from pedicels located on the  frontal bone of the skull.", "NTV, an Italian company which is Europe's first private open access operator of 300 km/h (186 mph) high-speed trains", "the second Sunday of March", "the relative units of force and mass then are fixed", "woman", "two", "August 10, 1933", "the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Sochi, Russia", "those who already hold wealth", "B. Traven", "Finding Nemo", "the subject of unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "oil prices", "wooded areas", "Jersey City's population was 264,152, with the largest population increase of any municipality in New Jersey since 2010", "Princeton, New Jersey", "the United States", "nearly pure O2 gas"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3653971576668945}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.8571428571428571, 1.0, 0.4, 0.0, 0.8, 0.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.3636363636363636, 1.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_hotpotqa-validation-5233", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "retrieved_ids": ["mrqa_triviaqa-validation-1259", "mrqa_naturalquestions-train-59322", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-897", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-2327", "mrqa_naturalquestions-train-73107", "mrqa_squad-validation-8924", "mrqa_naturalquestions-train-42188", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-train-6174", "mrqa_naturalquestions-train-19115", "mrqa_naturalquestions-train-11728", "mrqa_triviaqa-validation-199", "mrqa_triviaqa-validation-6692", "mrqa_hotpotqa-validation-2910", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-5972", "mrqa_triviaqa-validation-4069", "mrqa_naturalquestions-train-41656", "mrqa_naturalquestions-train-59801", "mrqa_hotpotqa-validation-2493", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-6107", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-3066"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "Sarajevo", "Isabella (Belle) Baumfree", "corgi", "14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "he broadened the foundations of the Reformation placing them on prophetic faith", "Bacon", "Charlton Heston", "anti-inflammatory molecules", "haggart", "Kevin Kolb", "money", "United States Presidents", "son et lumi\u00e8re", "surrendered to the Mongols first, the Karluks surrendered after the Uighurs, and the Koreans surrendered last", "Sochi, Russia", "right", "flows from the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "NASA immediately convened an accident review board", "New Zealand", "doreen", "30", "the Secret Intelligence Service", "100 billion", "et tu, brute", "photolysis", "4 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4148834325396825}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.375, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.16666666666666669, 0.2857142857142857, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-4123", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Mehmood", "a people of mixed Gaelic and Norse ancestry and culture", "Three card brag", "d\u00edsabl\u00f3t", "European or Eurasian cave lion", "Russian film industry", "sediment load", "the Washington metropolitan area", "scission of newly formed vesicles from the membrane of one cellular compartment", "User State Migration Tool ( USMT )", "Ordos City China Science Flying Universe Science and Technology Co.", "pie tins", "Taco Bell Arena, Boise, Idaho", "le Leicester", "Section 30 of the Teaching Council Act 2001", "Henry Gibson as Wilbur, a pig who was almost killed due to being a runt", "1984", "quasars", "Monsoon", "Romansh", "Tudor king", "5AA", "Q Branch ( or later Q Division) the fictional research and development division of the British Secret Service", "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "the division of labour, productivity, and free markets", "Gerard Marenghi", "Whitney Houston", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "Conservative", "Saul", "Elvis Presley"], "metric_results": {"EM": 0.125, "QA-F1": 0.2578993055555555}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.19999999999999998, 0.16666666666666666, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.5, 0.0, 0.33333333333333337, 0.0, 0.25, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.4, 1.0, 0.125, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 42, "before_eval": {"predictions": ["b Budd", "cavatelli, acini di pepe, pastina, orzo, etc.", "brian", "the connotations of a somewhat related word in German Eidgenosse (Confederates as in \"a citizen of one of the states of the Swiss Confederacy\")", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "Abraham Lincoln's war goals", "physicians, lawyers, engineers, and accountants", "a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "Finnish", "Giorgio Chiellini", "rommel", "the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position )", "the disaccharide sucrose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "Dave Thomas", "the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types", "Thursday", "yellow", "the appropriateness of the drug therapy (e.g. drug choice, dose, route, frequency, and duration of therapy) and its efficacy", "jupiter", "navigator and expedition leader", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "John Parr", "The Private Education Student Financial Assistance", "bow", "The benefits of good works could be obtained by donating money to the church", "colonies", "two forces, one pointing north, and one pointing east", "Bills", "Jack Murphy Stadium", "The answer to such questions is given by the time and space hierarchy theorems respectively"], "metric_results": {"EM": 0.125, "QA-F1": 0.25398828601953605}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.9333333333333333, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.7222222222222222, 0.0, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.6923076923076924, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "retrieved_ids": ["mrqa_hotpotqa-validation-2445", "mrqa_naturalquestions-train-73342", "mrqa_hotpotqa-validation-3898", "mrqa_hotpotqa-validation-3898", "mrqa_squad-validation-3478", "mrqa_naturalquestions-train-10375", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4020", "mrqa_triviaqa-validation-2202", "mrqa_hotpotqa-validation-4020", "mrqa_naturalquestions-train-66924", "mrqa_hotpotqa-validation-3253", "mrqa_squad-validation-6734", "mrqa_naturalquestions-train-6834", "mrqa_naturalquestions-train-293", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-train-42736", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-train-8496", "mrqa_squad-validation-2069", "mrqa_naturalquestions-train-63155", "mrqa_naturalquestions-train-70203", "mrqa_naturalquestions-train-18425", "mrqa_naturalquestions-train-13642", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-train-70252", "mrqa_hotpotqa-validation-2449", "mrqa_triviaqa-validation-7382", "mrqa_naturalquestions-train-76391"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 43, "before_eval": {"predictions": ["robin", "white", "Indiana", "september", "French", "a \"homeward bounder\") a sailor coming home from a round trip", "node example.com", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "september", "natural-ing recipes-only personal care products", "fly", "Sparafucile", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally.", "the third-most abundant element in the universe, after hydrogen and helium", "iKEA", "216", "september", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers, Sir Henry Cheere", "Akon, T.I. Rick Ross, Fat Joe, Birdman and Lil Wayne", "the Outfield", "the U.S.", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film", "railway locomotives", "Mike Todd", "the Moon's ecliptic longitude", "Michael Medwin", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "africa", "the Spokane Indian Reservation", "benjamin frankincense"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25139785738856946}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.21052631578947367, 0.0, 0.6666666666666665, 0.0, 1.0, 0.11764705882352941, 0.19999999999999998, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.21052631578947367, 0.0, 0.0, 0.16, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "relative cost of living, and grade taught", "England and Wales Cricket Board ( ECB )", "cricket", "football", "campaign setting", "the `` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867 feet (265 m)", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "Shape of You", "Christopher Lee as Count Dooku / Darth Tyranus : A former Jedi Master who now leads a Separatist movement and is Darth Sidious'new Sith apprentice", "8th", "meyer mosel", "hospitals and clinics", "increased patient health outcomes and decreased costs", "treble clef", "Lecrae Devaughn Moore (born October 9, 1979)", "160 km / h", "the Trinit\u00e0 dei Monti church at the top", "December 1, 2009", "Estelle Sylvia Pankhurst", "egypt", "the editor of the works of Francis Bacon", "robin", "Companies Act 2013, the Companies Act 1956, the Limited Liability Partnership Act, 2008 & other allied Acts and rules & regulations framed there - under mainly for regulating the functioning of the corporate sector in accordance with law", "Irish", "ancient cult activity", "mexico", "energy- storage molecules ATP and NADPH while freeing oxygen from water", "mars", "a genuine love of God with heart, soul, mind, and strength", "chorale cantatas"], "metric_results": {"EM": 0.15625, "QA-F1": 0.29385416666666664}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.16666666666666666, 0.4, 0.0, 0.0, 0.4, 1.0, 0.4, 1.0, 0.0, 0.32, 0.0, 0.0, 0.0, 0.2, 0.0, 0.6, 0.7499999999999999, 0.0, 0.0, 0.8, 0.0, 0.2, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 45, "before_eval": {"predictions": ["richard spillane", "Detroit Lions", "perique", "cut off close by the hip, and under the left shoulder, he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird", "death penalty", "stout man with a \" double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "sweden", "rich Fisher King", "Mangal Pandey of the 34th BNI", "Colonia Agrippina, descending to Cologne, V Alaudae, a Celtic legion recruited from Gallia Narbonensis and XXI, possibly a Galatian legion from the other side of the empire", "Lorne Greene", "four of the 50 states of the United States", "salt lake city", "the eighth series", "Pebble Beach Corporation", "Los Angeles", "French", "Gareth in the AMC horror drama \"The Walking Dead\"", "\"LOVE Radio\"", "Miami Marlins", "the court from its members for a three - year term", "richard travolta", "Don Henkel", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "Fox News Specialists", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM) which would take two men to the lunar surface and return them to the CSM", "San Francisco Bay Area at Santa Clara, California", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Operation Neptune", "peninsular mainland"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2532542226292226}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.07407407407407407, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.4166666666666667, 0.08, 0.4, 0.07142857142857142, 1.0, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_hotpotqa-validation-3509", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-2067"], "retrieved_ids": ["mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5160", "mrqa_naturalquestions-train-75029", "mrqa_triviaqa-validation-4824", "mrqa_naturalquestions-train-8443", "mrqa_naturalquestions-train-22320", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-train-5859", "mrqa_naturalquestions-train-81122", "mrqa_hotpotqa-validation-1782", "mrqa_naturalquestions-train-44459", "mrqa_hotpotqa-validation-3798", "mrqa_naturalquestions-train-13447", "mrqa_naturalquestions-train-56911", "mrqa_naturalquestions-train-77410", "mrqa_naturalquestions-train-41774", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-158", "mrqa_naturalquestions-train-73271", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-2722", "mrqa_triviaqa-validation-4197", "mrqa_naturalquestions-train-47470", "mrqa_naturalquestions-train-32401", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-train-34827", "mrqa_naturalquestions-train-59960", "mrqa_naturalquestions-train-82480", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-train-56261", "mrqa_squad-validation-4662", "mrqa_triviaqa-validation-2384"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That, East 17 and Boyzone", "youngest person to become a national transgender figure", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Einstein", "the absenceistence of the ultraviolet catastrophe", "Premier League club Swansea City", "art of late medieval and early Renaissance", "Elizabeth Weber", "It was released for PlayStation 4 and Xbox One on May 3, 2016.", "hundreds", "\"Waiting for Guffman\"", "1999", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "apple", "partial funding", "5% abv pale lager produced by Boon Rawd Brewery", "not be produced using currently available resources", "Chu'Tsai", "Liz", "least onerous", "mexico", "Grissom, White, and Chaffee", "Walmart de M\u00e9xico y Centroam\u00e9rica in Mexico and Central America", "purple passion fruit", "Natya Shastra", "the sand grains cause a scrubbing noise as they rub against each other when walked on", "u.S. Open Golf Championship", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "mexico"], "metric_results": {"EM": 0.375, "QA-F1": 0.4624771421107628}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 1.0, 1.0, 0.06666666666666667, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0689655172413793, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 47, "before_eval": {"predictions": ["benjamin franklin", "taghrooda", "Burnley and the New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia to protect it from Japanese troops", "Styal Mill", "big - name lawyers", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "they announced a hiatus and re-united two years later for the release of their fourth and final studio album, Destiny Fulfilled ( 2004 )", "leeds", "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form", "74 per cent", "heathrow", "often social communities with considerable face-to-face interaction among members.", "William Strauss and Neil Howe", "monophyletic", "moths and butterflies", "candidates on specific catechism questions", "a pH indicator, a color marker, and a dye", "2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "63,182,000", "John and Charles Wesley", "The Science and Discovery are the great Forces which will lead to the Consummation of the War\" (20 December 1914)", "It is, all other numbers) and produce as output only the single number 1", "WKU", "Rolf Wuetherich", "appearing as Jude in the musical romance drama film \" Across the Universe\" (2007)", "beeflock", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo.", "XXXTentacion", "stagnant wages for the working class amidst rising levels of property income for the capitalist class"], "metric_results": {"EM": 0.125, "QA-F1": 0.26815929222566215}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.5, 0.2222222222222222, 0.0, 0.0, 0.3157894736842105, 0.11764705882352941, 0.0, 0.0, 0.16666666666666669, 0.0, 0.7368421052631579, 1.0, 0.10526315789473682]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-1609", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 48, "before_eval": {"predictions": ["Anthony John Herrera", "Good Kid, M.A.D City", "el Capitan", "Interventive treatment", "3", "Bishop Reuben H. Mueller", "Ray Charles", "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "paris", "Brandon Jennings", "a loop ( also called a self - loop or a `` buckle '' ) is an edge that connects a vertex to itself. A simple graph contains no loops", "painting, mathematics, calligraphy, poetry, and theater", "the 1964 Republican National Convention in San Francisco, California", "Christian", "annuity", "Han Solo", "Buffalo Bill", "justice", "semi-independent State of Vietnam", "It was largely determined by President Woodrow Wilson, who had shown little interest in foreign affairs before entering the White House in 1913. His chief advisor was `` Colonel '' Edward House", "milk", "fish", "Arthur Russell (musician)", "the people themselves", "Bumper Robinson and Terrence Howard", "political role for Islam", "the university's off- Campus rental policies", "Robert Marvin \"Bobby\" Hull, OC (born January 3, 1939) is a Canadian former ice hockey player who is regarded as one of the greatest players of all time.", "New England Patriots", "war, famine, and weather"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3099264705882353}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.22222222222222218, 0.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 0.1111111111111111, 0.4, 0.6666666666666665, 0.11764705882352941, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264"], "retrieved_ids": ["mrqa_naturalquestions-train-86753", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-train-38744", "mrqa_squad-validation-2280", "mrqa_naturalquestions-train-83771", "mrqa_naturalquestions-train-51199", "mrqa_squad-validation-2757", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-3387", "mrqa_naturalquestions-train-32401", "mrqa_naturalquestions-train-54060", "mrqa_triviaqa-validation-4827", "mrqa_naturalquestions-train-17578", "mrqa_naturalquestions-train-72285", "mrqa_naturalquestions-train-68927", "mrqa_squad-validation-9841", "mrqa_naturalquestions-train-35286", "mrqa_triviaqa-validation-6556", "mrqa_naturalquestions-train-20986", "mrqa_naturalquestions-train-71926", "mrqa_naturalquestions-train-85866", "mrqa_naturalquestions-train-37019", "mrqa_naturalquestions-train-8896", "mrqa_naturalquestions-train-70510", "mrqa_naturalquestions-validation-7457", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-800", "mrqa_triviaqa-validation-2524", "mrqa_triviaqa-validation-6423", "mrqa_naturalquestions-train-64796", "mrqa_naturalquestions-train-54060"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 49, "before_eval": {"predictions": ["suitable for use on rough terrain", "Aol", "Genghis Khan", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "Rav\u00e8na", "12", "agoraphobia", "1937", "improved", "biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "he had assigned them to the company in lieu of stock", "Marxist and a Leninist", "Hansomouc ( Friedrich Franz and Johann Karl Nestler ), and his colleagues at the monastery ( such as Franz Diebl ) to study variation in plants", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "San Francisco Demons and Memphis Maniax.", "3,600", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah ( a transliteration of \u0627\u0644\u0645\u0645\u0645\u0644\u0643\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 in Arabic )", "44 hectares", "musical", "horakhty", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Wisconsin v. Yoder", "uneven trade agreements", "tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population", "ATP energy", "september", "Ruth Elizabeth \"Bette\" Davis", "uranium", "7 December 2004"], "metric_results": {"EM": 0.0625, "QA-F1": 0.2198714395360737}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.888888888888889, 0.0, 0.0, 0.1111111111111111, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.5365853658536585, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 50, "before_eval": {"predictions": ["basketball", "Carl Orff, Paul Hindemith, Richard Strauss, Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman express", "Murder in...", "Big Machine Records", "The issues of conflicting territorial claims between British and French colonies in North America were turned over to a commission to resolve", "Valmiki", "Epistle to Ramsay", "every two to six years", "Chinese", "association football", "2016", "Dan Castellaneta and first appeared on television, along with the rest of his family, in \"The Tracey Ullman Show\" short \"Good Night\"", "2007", "Wicked Twister", "subtraction", "R-7", "shoe", "whether this connection is relevant on microscales", "supernatural psychological horror", "originate in the House of Representatives", "Leo\u2019s Butt", "evening", "\"Blue (Da Ba Dee\") is a song by the Italian music group Eiffel 65.", "Constitution", "Faurot Field", "Annette Charles as Charlene `` Cha - Cha '' DiGregorio, Leo's girlfriend", "an extended metaphor to compare death with crossing the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return", "5", "konya", "if the car is slowed initially by manual use of the automatic gear box and final stoppage"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3201062802634767}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.23529411764705882, 0.1081081081081081, 0.6666666666666666, 0.0, 1.0, 0.3076923076923077, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.0, 0.08695652173913045, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.15384615384615385, 0.6666666666666666, 1.0, 0.0, 0.9824561403508771, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-290", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239", "mrqa_naturalquestions-validation-3022"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 51, "before_eval": {"predictions": ["third", "The main pulmonary artery begins at the base of the right ventricle", "a card from a pack of playing cards by Alice", "Orange", "Alex Breckenridge as Monique Valentine, Sebastian's superficial girlfriend", "seven", "Newtonian equations", "meat", "Ashland is a town in Grafton County, New Hampshire, United States.", "public schools", "Ghostface mask", "Roger Thomas Staubach", "AC induction motor and transformer", "originally a three-part retrospective in tribute to Eric Morecambe", "American rock band Queens of the Stone Age", "the port of Nueva Espa\u00f1a to the Spanish coast", "Lucy Muringo Gichuhi (n\u00e9e Munyiri) ( ) (born 23 September 1962) is an Australian politician who is a Senator for South Australia, sitting as an independent.", "1775\u20131795", "Empiricism", "w Somerset maugham", "Pabst Brewing Company", "redistributive", "Tyrion Lannister", "1990 to 2006", "expressed through some medium, as speech, writing or any of various arts", "Saint Peter ( the keeper of the `` keys to the kingdom '' )", "Fourth Home Rule Bill", "t\u00e2n Ni\u00ean", "Gebhard v Consiglio dell\u2019 Ordine degli Avvocati e Procuratori di Milano", "Belarus", "1835", "Elizabeth I"], "metric_results": {"EM": 0.125, "QA-F1": 0.2788119813855108}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.3636363636363636, 0.4324324324324324, 0.0, 0.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.6, 0.33333333333333337, 0.761904761904762, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.3636363636363636, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.14285714285714288, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_triviaqa-validation-7398", "mrqa_hotpotqa-validation-5740", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_hotpotqa-validation-596", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_hotpotqa-validation-2549", "mrqa_triviaqa-validation-3980", "mrqa_squad-validation-4430", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "retrieved_ids": ["mrqa_squad-validation-7352", "mrqa_naturalquestions-train-22360", "mrqa_hotpotqa-validation-1791", "mrqa_naturalquestions-train-64565", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-train-78896", "mrqa_naturalquestions-train-1898", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-train-47619", "mrqa_hotpotqa-validation-2428", "mrqa_naturalquestions-train-11605", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-train-83663", "mrqa_naturalquestions-train-86685", "mrqa_hotpotqa-validation-158", "mrqa_naturalquestions-train-87999", "mrqa_squad-validation-2577", "mrqa_naturalquestions-train-62448", "mrqa_naturalquestions-train-65666", "mrqa_naturalquestions-validation-1008", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-5233", "mrqa_naturalquestions-train-9081", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-104", "mrqa_hotpotqa-validation-800", "mrqa_hotpotqa-validation-1657", "mrqa_triviaqa-validation-681", "mrqa_triviaqa-validation-1079", "mrqa_naturalquestions-train-53977", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-298"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 52, "before_eval": {"predictions": ["Myllokunmingia", "Edd Kimber", "Brenda", "the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "asphyxia", "SG", "Matthias Schoenaerts, Michael Sheen, Tom Sturridge and Juno Temple", "The Worm", "1908", "the best five card poker hand from any combination of the seven cards of the five community cards and their own two hole cards", "German hymns", "Bury Football Club is a professional association football club based in Bury, Greater Manchester, England.", "Benazir Bhutto", "Amos McCracken", "NFC Championship Game", "Tom Robinson", "Buzz", "filming began in September 2000 at Leavesden Film Studios and in London, with production ending in July 2001", "the port city of Aden", "quickly to meet the needs of major national and international patient information projects and health system interoperability goals", "about two-thirds the size of cytoplasmic ribosomes", "leopard", "the service sector", "Florida", "\"\"la f\u00e9e verte \"\" (the green fairy) beverage", "Laura Solon", "Bolton", "British-American", "the state recognizes no limits to its authority and strives to regulate every aspect of public and private life wherever feasible", "anarchists", "540,800", "British Sky Broadcasting Group plc"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3372038840788841}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false], "QA-F1": [0.4, 0.0, 1.0, 0.19999999999999998, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.0909090909090909, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809525, 0.4, 0.1111111111111111, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5185185185185185, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-6389", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-2772"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 53, "before_eval": {"predictions": ["Following the election of the UK Labour Party to government in 1997", "Levi's Stadium", "c 1600", "Professor Moriarty", "Atticus Finch", "1763", "raspberry", "29,000\u201324,000 BP", "a kerosene lantern", "Bronwyn Kathleen Bishop (n\u00e9e Setright", "moral degeneracy", "king of spades", "maryland", "\"informal\" imperialism", "a violation of nature", "nairobi", "Richard Attenborough, Nicol Williamson, Derek Jacobi, and John Gielgud", "\u00a320", "25 June 1932", "viola", "Edward Anthony Spitzka", "stop motion animation", "chromosome", "Evey's mother", "10", "things that are a matter of custom or expectation", "the Sunni Muslim family", "Wes Unseld", "1912", "nitrogen", "increased flooding and sedimentation", "Daniel Handler"], "metric_results": {"EM": 0.28125, "QA-F1": 0.36818728146853147}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.375, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-169", "mrqa_squad-validation-5390", "mrqa_squad-validation-7700", "mrqa_triviaqa-validation-776", "mrqa_squad-validation-9144", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_triviaqa-validation-2821", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-117", "mrqa_squad-validation-6877", "mrqa_hotpotqa-validation-5614", "mrqa_triviaqa-validation-177", "mrqa_triviaqa-validation-3268"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 54, "before_eval": {"predictions": ["The Christmas Invasion", "the United States", "an expression of Priestley's socialist political principles", "March 9 to 18", "10 November 2017", "Romancing the Stone", "oral mucosa ( a mucous membrane ) lining the mouth and also on the tongue and palates and mouth floor", "The 8th Habit", "Anishinaabeg", "medicine", "sunny", "pierowall", "foster global monetary cooperation, secure financial stability, facilitate international trade, promote high employment and sustainable economic growth, and reduce poverty around the world", "Soma (stylized as SOMA) is a science fiction survival horror video game developed and published by Frictional Games for Microsoft Windows, OS X, Linux and PlayStation 4.", "\" Murder Request\") is a 2015 South Korean crime thriller film directed by Son Yong-ho", "valentia", "nikenna kezic", "late January or early February", "Michael Schumacher", "the duodenum", "pastry", "Cuyler Reynolds", "Lacoste, France", "rum", "cricketing", "135 (VAQ-135) known as the \" Black Ravens\" is a United States Navy electronic attack squadron that currently operates the EA-18G Growler carrier-based electronic warfare jet aircraft", "saved something from the disaster when he sent John Bradstreet on an expedition that successfully destroyed Fort Frontenac", "most casinos are commonly called casino games", "Hermes, Dior, Cartier, Bottega Veneta, Chanel, Fendi, Gucci, Louis Vuitton, MaxMara, Celine, Tiffany & Co.", "\"Shoot Straight from Your Heart\"", "Ulysses", "Kony Ealy"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22214586598746083}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.13333333333333333, 0.7272727272727273, 0.5, 0.2666666666666667, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4827586206896552, 0.0, 0.2666666666666667, 0.0, 0.0, 0.5000000000000001, 0.3636363636363636, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16, 0.0, 0.2, 0.13333333333333333, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_naturalquestions-validation-4021", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-5109", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_hotpotqa-validation-2058", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "retrieved_ids": ["mrqa_naturalquestions-train-47115", "mrqa_hotpotqa-validation-4649", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-train-30040", "mrqa_naturalquestions-train-17358", "mrqa_hotpotqa-validation-2679", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-train-9048", "mrqa_naturalquestions-train-33890", "mrqa_naturalquestions-train-73399", "mrqa_naturalquestions-train-21248", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-5325", "mrqa_naturalquestions-train-42559", "mrqa_naturalquestions-train-47470", "mrqa_naturalquestions-train-64472", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-3161", "mrqa_triviaqa-validation-4827", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-6692", "mrqa_naturalquestions-train-22812", "mrqa_naturalquestions-train-49100", "mrqa_naturalquestions-train-7625", "mrqa_triviaqa-validation-7184", "mrqa_naturalquestions-train-81810", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-4513", "mrqa_naturalquestions-validation-4513"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 55, "before_eval": {"predictions": ["2,000", "Executive Vice President of Football Operations and General Manager", "Dutch navy captain Jurriaen Aernoutsz also briefly captured two forts in the French colony of Acadia, which he claimed as Dutch territory the new colony of New Holland", "Gracie the new `` face '' of the FBI. Hurt after being dumped by her boyfriend, fellow Agent Eric Matthews ( who gets relocated to Miami ), she agrees to the reassignment", "The Celtic nations are territories in western Europe where Celtic languages or cultural traits have survived.", "stromal connective tissue", "paris", "there are now numerous such communities across the United States and around the world", "pangea", "a job that few require (low demand) will result in a low wage for that job", "octagon", "bobby giraldi", "Scott Mosier", "verbal", "weaving", "art of the Persian Safavid dynasty from 1501 to 1722, in present - day Iran and Caucasia", "sepoys of the Company's army in the garrison town of Meerut, 40 miles northeast of Delhi ( now Old Delhi )", "DeMarcus Ware as time expired in the half", "Jack Nicholson -- Chinatown as J.J. `` Jake '' Gittes", "dan brown", "boxing, where a boxer who is still on their feet but close to being knocked down can be saved from losing by the bell ringing to indicate the end of the round", "at the port city of Kaffa in the Crimea in 1347", "the Persian style of architecture", "Iranian-German", "paris", "Landwehr", "his work was published first", "as part of a novena", "accommodationism", "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' ) over, principally, the manner of England's government", "Niger\u2013 Congo language", "a lower index of refraction, typically a cladding of a different glass, or plastic"], "metric_results": {"EM": 0.0625, "QA-F1": 0.2184425579958101}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.2758620689655173, 0.0, 0.4, 0.0, 0.8571428571428571, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9142857142857143, 0.0, 0.0, 0.0, 0.9824561403508771, 0.14285714285714285, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4705882352941177, 0.0, 0.36363636363636365]}}, "error_ids": ["mrqa_squad-validation-378", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_hotpotqa-validation-3062", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_squad-validation-7407", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_triviaqa-validation-7689", "mrqa_hotpotqa-validation-4215", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_naturalquestions-validation-570", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7078"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 56, "before_eval": {"predictions": ["Randy", "1922 to 1991", "predictions that can be tested in various ways", "city council", "an Islamic revival movement often characterized by moral conservatism, literalism, and the attempt \"to implement Islamic values in all spheres of life\"", "Tesla Polyphase System", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "39, Newton was 26", "an optical head - mounted display designed in the shape of a pair of eyeglasses", "the value of the dollar had been pegged to the price of gold", "kevin nigries", "the model for one of the characters in Jordan Mechner's game \" Prince of Persia\"", "monocled mutineer", "Robert \"Bumps\" Blackwell, Enotris Johnson, and Little Richard", "five", "teachers' mental and physical health, productivity, and students' performance", "kevin kita", "Count de la F\u00e8re", "if there are no repeated data values", "wurundjeri", "1932", "September 25, 1957", "methanol, ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid", "former Manchester United and Danish international goalkeeper Peter Schmeichel.", "highest commissioned SS rank", "kevin j Allen", "the lowest known subaerial volcanic vents in the world, at 45 m ( 150 ft ) or more below sea level", "parachutes", "in Egypt, the only part of the country located in Asia", "Alison Steadman", "in the retina of mammalian eyes ( e.g. the human eye )", "benjamin knight"], "metric_results": {"EM": 0.125, "QA-F1": 0.21232913372859025}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 0.0, 0.5333333333333333, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08695652173913045, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-9608", "mrqa_naturalquestions-validation-1787", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-4640", "mrqa_hotpotqa-validation-1912", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 57, "before_eval": {"predictions": ["Saturn", "texas", "more than 1.7 billion views", "Bathurst 1000", "April 1948", "In inequality of opportunity", "penance and righteousness", "FeO (w\u00fcstite) is written as Fe1 \u2212 xO, where x is usually around 0.05.", "Groucho", "evidence of impact process effects", "Better Jacksonville Plan", "david Frost", "Charles Haley", "duchy of Cornwall", "glucose", "Labor", "United States Ship", "reared", "October 15, 1997", "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "modernized the outside of the building and renovated the inside as part of his first construction project in Manhattan", "North Atlantic Ocean and Arctic Ocean", "pembroke", "Lewis Balfour", "texas edgeworth", "five", "rionegro, Colombia, outside Medellin", "Julius Caesar", "American conservative author and commentator", "pork", "Sam the Sham", "as many as two consecutive terms"], "metric_results": {"EM": 0.25, "QA-F1": 0.3831349206349206}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5714285714285715, 0.28571428571428575, 0.0, 0.8571428571428571, 1.0, 0.13333333333333333, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.3333333333333333, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4]}}, "error_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-1567", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-4067", "mrqa_triviaqa-validation-5785", "mrqa_triviaqa-validation-7489", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_hotpotqa-validation-3802", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "retrieved_ids": ["mrqa_triviaqa-validation-7133", "mrqa_naturalquestions-train-1564", "mrqa_triviaqa-validation-6721", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-train-78095", "mrqa_hotpotqa-validation-3440", "mrqa_triviaqa-validation-1764", "mrqa_naturalquestions-train-64472", "mrqa_naturalquestions-train-33266", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-1090", "mrqa_triviaqa-validation-177", "mrqa_naturalquestions-train-10041", "mrqa_triviaqa-validation-2821", "mrqa_naturalquestions-train-106", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-3149", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-train-33897", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-6961", "mrqa_naturalquestions-train-22483", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-3876", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-2442", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-train-33619", "mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-4027"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 58, "before_eval": {"predictions": ["Dutch", "begins in the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "an advantage", "phagosomal", "Tyneside", "1955", "henry v", "200 horsepower", "Nikola Tesla", "Lutheranism", "Night Ranger", "Honey Nut", "Shell Flower", "Organizational interventions, like changing teachers' schedules, providing support networks and mentoring, changing the work environment, and offering promotions and bonuses, may be effective in helping to reduce occupational stress among teachers", "levels of economic inequality", "henry", "Enrico Fermi", "Angelina Jolie, Brad Pitt and Amal Clooney", "henry", "1979", "mainly civil servants recruited in special university classes", "over large areas", "K \u00d7 1", "the medial epicondyle of the humerus from posteriorly, or inferiorly with the elbow flexed", "weight", "no man is an island", "Liao, Jin, and Song", "`` Han dynasty '' ( Hanchao \u6f22 \u671d )", "pigeons", "ionized material", "Attack the Block", "Juliet"], "metric_results": {"EM": 0.25, "QA-F1": 0.3334201388888889}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.8, 0.0, 0.125, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-5202", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_hotpotqa-validation-5735", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-5104", "mrqa_hotpotqa-validation-4178", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-4817", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 59, "before_eval": {"predictions": ["GE's four computer sales and service centers (Schenectady, Phoenix, Chicago, and Phoenix) to facilitate a computer time- sharing service", "the exoskeleton of insects, the shells and membranes of externally deposited eggs, and skin", "Naturalization Act of 1790", "Guy Ritchie", "2 %", "Mountbatten-Windsor", "9", "Joe Namath, Dan Marino, Jim Kelly, Joe Montana and George Blanda.", "henry virus", "New Football Conference (NFC) champion Carolina Panthers 24\u201310", "kabuki and bunraku", "It's only fair that, from now on, you should pay more for oil. Let's say ten times more", "5 mi east of Everest on highway K-20.", "yolk sac ( protruding from its lower part ) but no embryo", "Kelly Bundy", "Italy", "for export to London and elsewhere", "her gaoler's family", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Mario Addison", "321,520", "June 12, 2017", "2005", "red deer", "kalapatthar", "``Generalfeldmarschall\" (Field Marshal) Helmuth Karl Bernhard von Moltke", "henry", "`` Turkey in the Straw ''", "the 2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium ), playing home games at the Las Vegas Stadium", "Selznick library", "marx", "samoan t\u0101l\u0101"], "metric_results": {"EM": 0.125, "QA-F1": 0.22386612718294305}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.05714285714285714, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3076923076923077, 0.0, 0.2222222222222222, 0.0, 0.14814814814814814, 0.16666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9565217391304348, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35294117647058826, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_hotpotqa-validation-1035", "mrqa_naturalquestions-validation-875", "mrqa_triviaqa-validation-2965", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_squad-validation-19", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-825", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-2525"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 60, "before_eval": {"predictions": ["Currer Bell", "the Lord Commander of the Watch", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "J. D. Salinger's novel \"The Catcher in the Rye\"", "The invading Normans and their descendants", "Merv", "Bendigo", "Thomas Jefferson", "Eva \u0160v\u00edglerov\u00e1, Judith Wiesner, Jennifer Capriati and Helena Sukov\u00e1 before losing to eventual champion Monica Seles.", "1 August 1936", "Boston and Maine Railroad", "James Lofton and Mark Malone", "the right of the dinner plate", "summer months", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts returned for their respective ninth, eighth, seventh and second series on The Ice Panel", "third \u00e9tude", "Thailand, Burma, Cambodia, Indonesia and Sri Lanka", "segues", "lesareggub", "anon235024", "6 January 793", "South Australian town", "Flag Day in 1954", "around 300,000", "1858", "Sexred", "between issues # 600 -- 602, the story features a futuristic look into the life of Riverdale teen Archie Andrews in the years that follow his college graduation when Archie makes his ultimate decision to marry Veronica Lodge instead of Betty Cooper", "neo-Nazi ideology with ethnic European paganism and opposition to \"foreign\" religions such as Christianity, Islam and Judaism.", "rik Mayall", "cancel missions 18 and 19", "the frequency f, wavelength \u03bb, or photon energy E. Frequencies observed in astronomy range from 70232399999999999999999 \u2660 2.4 \u00d7 10 Hz ( 1 GeV gamma rays ) down to the", "the \"celebrity criminal\""], "metric_results": {"EM": 0.1875, "QA-F1": 0.3145024440201071}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.22222222222222224, 0.25, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.6666666666666665, 0.0, 0.17391304347826084, 1.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.05405405405405406, 0.1111111111111111, 0.0, 0.0, 0.5416666666666667, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_hotpotqa-validation-949", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_hotpotqa-validation-1124", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_hotpotqa-validation-1971", "mrqa_triviaqa-validation-1284", "mrqa_squad-validation-4011", "mrqa_naturalquestions-validation-5798"], "retrieved_ids": ["mrqa_naturalquestions-train-86573", "mrqa_naturalquestions-train-4468", "mrqa_hotpotqa-validation-4022", "mrqa_hotpotqa-validation-158", "mrqa_naturalquestions-train-31694", "mrqa_naturalquestions-train-36368", "mrqa_hotpotqa-validation-3357", "mrqa_triviaqa-validation-3250", "mrqa_hotpotqa-validation-1289", "mrqa_naturalquestions-train-63308", "mrqa_naturalquestions-train-20238", "mrqa_triviaqa-validation-7133", "mrqa_naturalquestions-train-33405", "mrqa_naturalquestions-train-20807", "mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-train-12584", "mrqa_hotpotqa-validation-2910", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-train-63918", "mrqa_naturalquestions-train-36590", "mrqa_hotpotqa-validation-5651", "mrqa_naturalquestions-train-505", "mrqa_naturalquestions-train-81657", "mrqa_triviaqa-validation-4817", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-train-87790", "mrqa_naturalquestions-train-9798", "mrqa_naturalquestions-train-11879", "mrqa_naturalquestions-train-49618", "mrqa_hotpotqa-validation-820", "mrqa_naturalquestions-train-83634"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 61, "before_eval": {"predictions": ["The Raigne of King Edward the Third", "john Hughes", "San Bernardino", "Judy Collins", "Out of Control", "the 2013 non-fiction book of the same name by David Finkel", "liza tarbuck", "The Frost Report", "fell from his horse while hunting and died because of the injury", "incitement to terrorism", "Henry and Liza", "historical figure in 16th-century Irish history", "the Free and Sovereign State of Tamaulipas", "oxygen", "Elk and Kanawha Rivers", "They circulate and are moved around within plant cells, and occasionally pinch in two to reproduce", "'Bucks Point'", "to `` help bring creative projects to life ''", "The Church of Jesus Christ of Latter-day Saints", "Old World fossil representatives", "the group 1 elements", "Rachel Dratch", "seven", "thicker consistency and a deeper flavour than sauce", "Genetic sex", "neupommern", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "VH1's \"100 Greatest Artists of Hard Rock\"", "after AD 70", "1977", "techno", "He was taken prisoner and eventually was convicted of crimes against peace"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2898577026044131}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.6666666666666666, 0.1818181818181818, 0.2857142857142857, 0.0, 0.4, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 62, "before_eval": {"predictions": ["sleeps", "whitening", "At the end of the food chain", "the Monarch", "United Kingdom", "Ballarat Bitter", "read therefore", "Ricketts Glen State Park", "a desire to be reckoned with as an openly wounded and unabashedly portentous rock balladeer", "magma", "harridan Grizelda Pugh", "a fee per unit of information transmitted", "\"master builder\"", "In 1932", "during the winter of the 2017 -- 18 network television season", "suburbs", "Egypt", "Buzz Aldrin", "Lorraine", "8.02 mi from the Kentucky state line on top of Black Mountain", "Ontogenetic depth", "during the closing credits of most programs", "Kansas\u2013Nebraska Act of 1854", "44 Variable ( V ) gene segments", "from 1910\u20131940", "11:28 left in the second quarter", "Start Here", "Doctor Who", "Autobahn", "reproductive role", "Baron of Holberg", "poodle"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4028149801587302}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.33333333333333337, 1.0, 0.4444444444444445, 0.4444444444444445, 0.125, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.2222222222222222, 0.0, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.14285714285714288, 0.6666666666666666, 0.33333333333333337, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9843", "mrqa_naturalquestions-validation-5396", "mrqa_squad-validation-7766", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-7270", "mrqa_triviaqa-validation-1698", "mrqa_hotpotqa-validation-1510", "mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_squad-validation-3961", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_hotpotqa-validation-837", "mrqa_naturalquestions-validation-538", "mrqa_squad-validation-824", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_triviaqa-validation-6254"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 63, "before_eval": {"predictions": ["Singapore", "heat addition (in the boiler) and rejection ( in the condenser) are isobaric (constant pressure) processes in the Rankine cycle", "president", "ARPANET", "Apr 23, 1564", "Kohlberg K Travis Roberts", "fylde", "probabilistic (or \"Monte Carlo\")", "The Who", "eight days after their initial broadcast", "Phoenix Satellite Television Holdings Ltd or Phoenix Television is a Hong Kong\u2013based, Cayman Islands registered Mandarin and Cantonese-language television broadcaster that serves the Chinese mainland and Hong Kong along with other markets with substantial Chinese viewers.", "a narcissistic ex-lover who did the protagonist wrong", "catawba", "petrographic microscope", "mike thomas", "Haitian Revolution", "Sondheim", "Strasbourg", "1.41665", "a system of recording important things", "1993", "The Daily Mirror", "ACL tears", "co Mayo", "dura mater", "German", "1999", "belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "Professor Kantorek", "31 - member Senate", "whippoorwill", "orkneys"], "metric_results": {"EM": 0.15625, "QA-F1": 0.21751596980255516}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.2222222222222222, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.1111111111111111, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.34146341463414637, 0.0, 0.5, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_triviaqa-validation-3153", "mrqa_hotpotqa-validation-97", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_triviaqa-validation-54", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_triviaqa-validation-7598", "mrqa_triviaqa-validation-27", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "retrieved_ids": ["mrqa_triviaqa-validation-1166", "mrqa_naturalquestions-train-85155", "mrqa_triviaqa-validation-2007", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-train-73399", "mrqa_squad-validation-10395", "mrqa_triviaqa-validation-6950", "mrqa_triviaqa-validation-1975", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-train-52742", "mrqa_naturalquestions-train-80628", "mrqa_triviaqa-validation-2223", "mrqa_triviaqa-validation-893", "mrqa_triviaqa-validation-3404", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-1550", "mrqa_naturalquestions-train-32689", "mrqa_naturalquestions-train-45612", "mrqa_hotpotqa-validation-5607", "mrqa_triviaqa-validation-5261", "mrqa_naturalquestions-train-78339", "mrqa_naturalquestions-train-4070", "mrqa_hotpotqa-validation-4904", "mrqa_triviaqa-validation-4279", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-2287", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-1897", "mrqa_naturalquestions-train-6716", "mrqa_naturalquestions-train-65924", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-train-1337"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 64, "before_eval": {"predictions": ["t", "Jim Justice", "miniature cydippid adults", "Trey Parker and Matt Stone", "kanto", "one of popular music's most poignant anthems of sorrow regarding the environment", "trial division", "consultant", "Preston, Lancashire, UK", "The Suite Life of Zack & Cody", "tuberculosis", "Saturn IB", "Rose Mary Woods", "daniel Baldwin", "Zaha", "duke of Urbino", "jaw", "st Moritz", "charliesheen", "reform the lunisolar calendar to provide an accuracy of 365.2425 days of the year", "deadliest", "glenister", "immediate judgement discrepancy, or cognitive bias, where a person making an initial assessment of another person, place, or thing will assume ambiguous information based upon concrete information", "from New Orleans going north through Chicago and to New York", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "macOS High Sierra", "Frazier", "quadrilateral", "Diarmaid MacCulloch", "loire river", "17th Century sources referring to Cardinal Richelieu after he was named to head the royal council in 1624", "appropriates ( gives to, sets aside for ) money to specific federal government departments, agencies, and programs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.27800633508509875}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 0.16949152542372883, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.058823529411764705]}}, "error_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_squad-validation-4567", "mrqa_triviaqa-validation-748", "mrqa_naturalquestions-validation-7857", "mrqa_squad-validation-8909", "mrqa_hotpotqa-validation-548", "mrqa_squad-validation-3956", "mrqa_triviaqa-validation-2032", "mrqa_hotpotqa-validation-811", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_squad-validation-8201", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 65, "before_eval": {"predictions": ["the lightly populated \" Cowboy Counties\" of southern California", "L", "Diary of a Wimpy Kid : The Long Haul", ". html", "prayer", "pericardium", "the Early Gothic", "Kentucky Derby", "maryland", "The Boz", "1991", "ABC-DuMont", "Birmingham, Alabama", "the following identity ( Basel problem) due to Euler", "2020", "house", "tony", "gravitation", "nonconservative forces", "bulls", "static friction", "ormond sacker", "sazerac whiskey", "Shut Up", "nahuatl", "Karina Smirnoff became the runners - up, and Jack Osbourne and Cheryl Burke received third place", "the Arizona Cardinals", "St. Augustine", "four", "Abrogation of the Private Mass", "kedah", "mycelium"], "metric_results": {"EM": 0.375, "QA-F1": 0.40798611111111116}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-2752", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-1923", "mrqa_squad-validation-9021", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_naturalquestions-validation-1783", "mrqa_hotpotqa-validation-4174", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 66, "before_eval": {"predictions": ["mayonnaise", "to fund his Colorado Springs experiments", "the eastern shore of the Firth of Clyde", "On the Computational Complexity of Algorithms", "from sea level", "Pandavas", "Magnetically soft ( low coercivity ) iron is used for the cores in electromagnets", "\"eau\" the French word for \"water\"", "white rabbit", "Duke Kent-Brown", "oxygen", "bratwurst", "platypus", "They tend to produce better academic results than government schools formerly reserved for other race groups", "Vanessa Block", "verruckt", "Fermat", "white", "horse", "http://www.example.com/index.html", "spanish", "`` Abigail ''", "a clear summary of the new faith in the form of two catechisms", "cheddar", "Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen", "Saint-Domingue", "a renewed attack on Archbishop Albrecht of Mainz", "in 1998", "Organisms in the domains of Archaea and Bacteria", "Commissioners", "American historians generally use the traditional name or sometimes the Seven Years' War", "sattu paratha (stuffed with fried chickpea flour)"], "metric_results": {"EM": 0.1875, "QA-F1": 0.270811795112782}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.125, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.08333333333333334, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.10526315789473685, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_naturalquestions-validation-5927", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_squad-validation-7130", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_squad-validation-8980", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-2469", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_squad-validation-2269", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "retrieved_ids": ["mrqa_naturalquestions-train-68063", "mrqa_triviaqa-validation-1015", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-train-84055", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-train-946", "mrqa_naturalquestions-train-70965", "mrqa_triviaqa-validation-1198", "mrqa_naturalquestions-train-25327", "mrqa_naturalquestions-train-63308", "mrqa_hotpotqa-validation-4743", "mrqa_hotpotqa-validation-3651", "mrqa_triviaqa-validation-6185", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-2222", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-4827", "mrqa_naturalquestions-train-49688", "mrqa_naturalquestions-train-79043", "mrqa_naturalquestions-train-57237", "mrqa_naturalquestions-validation-2839", "mrqa_triviaqa-validation-4123", "mrqa_triviaqa-validation-3472", "mrqa_naturalquestions-train-72724", "mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-train-62042", "mrqa_triviaqa-validation-3647", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-train-55816", "mrqa_triviaqa-validation-1298", "mrqa_hotpotqa-validation-3191"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 67, "before_eval": {"predictions": ["high inequality", "henry de lusignan", "james brown", "Sweden, Norway and Denmark", "Oscar II Land on the island of Spitsbergen in Svalbard, Norway", "Deposition is a thermodynamic process, a phase transition in which gas transforms into solid without passing through the liquid phase. The reverse of deposition is sublimation and hence sometimes deposition is called desublimation", "of Norman origin, deriving from the Norman given name Robert, meaning `` bright renown '' -- from the Germanic elements `` hrod '' meaning renown and `` beraht '' meaning bright", "Crossed: Preacher", "payday loans", "Doctor of Philosophy", "1,388", "Otis Timson", "toothless, bearded hag", "government officials and climate change experts", "$150,000 and $250,000 for primes with at least 100 million digits and 1 billion digits, respectively", "12 December 1964", "Toledo", "runner-up", "The Crowned Prince of the Philadelphia Mob", "\u201c Resign.\u201d", "romantic attraction, sexual attraction, or sexual behavior toward both males and females", "the Meiji Restoration", "Big 12 Conference", "1920s", "American", "Cleopatra VII Philopator", "April Fool's Day", "man at the gate", "catherine de Bourgh", "Chloroplasts can also become chloroplasts, like what happens when a carrot or a potato is illuminated. If a plant is injured, or something else causes a plant cell to revert to a meristematic state", "Salta", "more than 265 million business records worldwide"], "metric_results": {"EM": 0.25, "QA-F1": 0.33515720390720394}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.06666666666666667, 0.16666666666666669, 0.4, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4444444444444445]}}, "error_ids": ["mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-8643", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4648", "mrqa_triviaqa-validation-1385", "mrqa_hotpotqa-validation-5297", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_hotpotqa-validation-294", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_squad-validation-6327", "mrqa_hotpotqa-validation-3345", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-2171"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 68, "before_eval": {"predictions": ["Nuevo Reino de Le\u00f3n", "Delaware", "\"jus sanguinis\"", "last starring role was as Boston police detective Barry Frost", "The King of Chutzpah", "Mike Jones featuring Nicole Wray, Trillville, Juvenile featuring Skip & Wacko, Nasty Nardo, 8Ball & MJG, Lil'Boosie & Webbie and other artists", "energy", "tube map", "Nepali", "Glasgow Association for the Higher Education of Women", "the luncheonette was known as Pete's, and featured a waitress named Claire ( played by Lee Garlington ) ; Claire was originally conceived as a regular for the show but was written out", "complexity", "chip", "the dot", "dieppe", "1961", "Tim Andrew", "Buckland Valley near Bright", "teaching", "shaolin", "othniel charlie", "qualifications", "Kelli Goss", "the final episode of the series", "2007 Trail Appliances Autumn Gold Curling Classic", "3 September", "tolled ( quota ) highways", "redox", "eastern and interior Venezuela and the llanos of Colombia", "tsar", "the nation of Sokovia", "American news and opinion website and online news aggregator"], "metric_results": {"EM": 0.21875, "QA-F1": 0.26197916666666665}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.7999999999999999, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_triviaqa-validation-4485", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8791", "mrqa_triviaqa-validation-2723", "mrqa_squad-validation-7076", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-339", "mrqa_squad-validation-1784", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_squad-validation-2843", "mrqa_squad-validation-2052", "mrqa_triviaqa-validation-5893", "mrqa_naturalquestions-validation-921", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_triviaqa-validation-3089", "mrqa_naturalquestions-validation-2632", "mrqa_hotpotqa-validation-4275"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 69, "before_eval": {"predictions": ["Eisenhower Freeway", "Louis de Broglie", "music became more expressive and emotional, expanding to encompass literary, artistic, and philosophical themes", "Thermochemical techniques", "North Kest even", "Ming", "near major hotels and in the parking areas of major Chinese supermarkets", "Abu al-Qasim al-Zahrawi", "Hellenismos", "from the top of the leg to the foot on the posterior aspect", "The long - hair gene is recessive", "unknown and it may originate in plainchant, but a 1619 attribution to John Bull is sometimes made", "tea, horticultural produce, and coffee", "london", "Robanna Cassidy", "The blood spilled by the heroes who died in the name of their countrymen's Fatherland and Freedom", "island of island", "break off the cathode, pass out of the tube, and physically strike him", "Silver Gallery", "21.8 %", "placebo effect", "Yuan dynasty is usually considered to be the legitimate dynasty between the Song dynasty and the Ming dynasty", "Tony Orlando and Dawn", "Paris", "parliaments", "Martha Wainwright", "1,462", "island of man", "West Norse sailors", "symphonic", "Zephyrus the west-wind", "1698"], "metric_results": {"EM": 0.1875, "QA-F1": 0.32372727220105313}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.35294117647058826, 0.125, 1.0, 0.28571428571428575, 0.0, 0.15384615384615383, 1.0, 0.0, 0.5, 1.0, 0.888888888888889, 1.0, 0.0, 0.5, 0.10526315789473682, 0.0, 0.42857142857142855, 0.4, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4562", "mrqa_naturalquestions-validation-8645", "mrqa_naturalquestions-validation-8059", "mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_naturalquestions-validation-3035", "mrqa_squad-validation-3610", "mrqa_squad-validation-8185", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_triviaqa-validation-5088", "mrqa_hotpotqa-validation-1381"], "retrieved_ids": ["mrqa_triviaqa-validation-892", "mrqa_naturalquestions-train-35112", "mrqa_naturalquestions-train-23010", "mrqa_naturalquestions-train-13731", "mrqa_squad-validation-3044", "mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-train-6212", "mrqa_naturalquestions-train-63281", "mrqa_naturalquestions-train-47444", "mrqa_squad-validation-6211", "mrqa_naturalquestions-train-58765", "mrqa_naturalquestions-train-6934", "mrqa_naturalquestions-train-50424", "mrqa_naturalquestions-train-48845", "mrqa_naturalquestions-train-43119", "mrqa_triviaqa-validation-5876", "mrqa_naturalquestions-train-35663", "mrqa_triviaqa-validation-1586", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-train-55149", "mrqa_naturalquestions-train-12803", "mrqa_triviaqa-validation-4817", "mrqa_triviaqa-validation-2797", "mrqa_hotpotqa-validation-1052", "mrqa_naturalquestions-train-53798", "mrqa_triviaqa-validation-6351", "mrqa_naturalquestions-train-38511", "mrqa_hotpotqa-validation-1791", "mrqa_naturalquestions-train-44166", "mrqa_naturalquestions-train-13289", "mrqa_triviaqa-validation-6423"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 70, "before_eval": {"predictions": ["paratroopers", "New York and New Jersey campaign", "February 28, 2018", "in his hotel room to nurse back to health", "major car brands Ford, Toyota and Holden", "cobbler", "Guthred", "1972", "2013 feature film \"Frozen\"", "a loanword of the Visigothic word guma `` man ''", "Major General Miles Francis Stapleton Fitzalan- Howard, 17th Duke of Norfolk", "Hebrew Alephbet", "Australian and New Zealand", "chromium", "white", "from their vacation in Cape Cod", "derived from the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "Mirzapur, Uttar Pradesh, which is nearly on the corresponding longitude reference line", "\"revolution\" he meant not the violence or populist policies of the Iranian Revolution, but the gradual changing the hearts and minds of individuals from the top of society downward through an educational process or da'wah", "Salman Khan", "Skip Tyler", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything '", "WBMA-LD", "two Nobel Peace Prizes", "Jack Daniel", "physically strike him", "authorized Version", "thirty articles affirming an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "a mathematical by-product of exchange of momentum- carryinging gauge bosons", "Newton", "Nobel Prize in Literature", "Kingsford, Michigan"], "metric_results": {"EM": 0.1875, "QA-F1": 0.36130926657943874}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.5, 0.6, 0.0, 0.5, 1.0, 0.4, 0.2857142857142857, 0.5882352941176471, 0.6666666666666666, 0.5333333333333333, 1.0, 0.0, 0.0, 0.19047619047619047, 0.4444444444444444, 0.0625, 0.0, 1.0, 0.08, 1.0, 1.0, 0.5, 0.0, 0.0, 0.2105263157894737, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-831", "mrqa_naturalquestions-validation-2083", "mrqa_squad-validation-1632", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_triviaqa-validation-672", "mrqa_hotpotqa-validation-4323", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_naturalquestions-validation-7938", "mrqa_squad-validation-10477", "mrqa_squad-validation-361", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-2229"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 71, "before_eval": {"predictions": ["John D. Rockefeller", "in 2015, Adele surpassed the record when her album \"25\" took just 29 days", "utility lines", "Saxe-Coburg and Gotha", "16,000", "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription", "Dwight David \"Ike\" Eisenhower", "multi-purpose", "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "twelve", "boston", "Randal Keith Orton", "RuPaul", "as a liquid", "Sunday", "October 16, 2012", "Austria's border with the Czech Republic", "In 2012, during a preseason exhibition game held in Sassari, Italy, Olympiacos starter and former NBA player Joey Dorsey ended up breaking the glass of a backboard against Dinamo Sassari", "Somatic", "whitetail deer", "David Irving", "cabbage", "rock and roll", "Hongwu Emperor of the Ming Dynasty", "heptathlon", "since it never contained the element lead", "rapid expansion in telecommunication and financial activity", "st. Valentine's Day", "Caroline Sterling, n\u00e9e Bone, formerly Pemberton ( born 3 April 1955 ; died 2017 ) ( Sara Coward )", "Libertarianism", "london", "American R&B"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3170815295815296}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.45454545454545453, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_hotpotqa-validation-253", "mrqa_squad-validation-7123", "mrqa_hotpotqa-validation-862", "mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_naturalquestions-validation-2635", "mrqa_triviaqa-validation-6938", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-3689", "mrqa_hotpotqa-validation-5203", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_hotpotqa-validation-1694", "mrqa_triviaqa-validation-4464", "mrqa_hotpotqa-validation-2866"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 72, "before_eval": {"predictions": ["Monk's Caf\u00e9", "ancient Rome", "fourth-most Republican leader in the House", "seven times", "Hamiltonian path problem", "Operation Neptune", "john f kenna barzun", "Patrick Moore", "alpaca fiber and mohair from Angora goats", "Muskogean language called Apalachee", "Symbolic interactionism", "Long Island", "a gesture in which the head is tilted in alternating up and down arcs along the sagittal plane", "Field of Dreams", "snow and rain", "Conservative Member of Parliament", "4 School of Public Health", "shottery", "brianen whales", "1883\u201384", "yellow", "A Pr\u00e9sent Tu Peux t'en Aller", "fox", "Macau Peninsula, Macau", "produce \"de novo\"", "jack Morrissey", "jumbo jet", "comedy", "Greg", "eighteenth century", "Puente Hills Mall, located in the City of Industry, California, United States", "jack"], "metric_results": {"EM": 0.09375, "QA-F1": 0.24726081210456213}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.4, 0.3636363636363636, 0.8000000000000002, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.3636363636363636, 0.125, 1.0, 0.0, 0.4, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.30769230769230765, 0.0, 0.0, 0.4, 0.0, 0.2857142857142857, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_squad-validation-1760", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_squad-validation-3592", "mrqa_hotpotqa-validation-2192", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "retrieved_ids": ["mrqa_triviaqa-validation-7598", "mrqa_hotpotqa-validation-4277", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-3440", "mrqa_triviaqa-validation-5239", "mrqa_triviaqa-validation-3420", "mrqa_naturalquestions-train-82497", "mrqa_naturalquestions-train-16550", "mrqa_triviaqa-validation-6186", "mrqa_hotpotqa-validation-3357", "mrqa_triviaqa-validation-7369", "mrqa_triviaqa-validation-6692", "mrqa_naturalquestions-train-64590", "mrqa_hotpotqa-validation-1895", "mrqa_naturalquestions-train-26214", "mrqa_triviaqa-validation-3404", "mrqa_hotpotqa-validation-962", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-6425", "mrqa_naturalquestions-train-78716", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-2850", "mrqa_triviaqa-validation-4209", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-6127", "mrqa_naturalquestions-validation-2477", "mrqa_hotpotqa-validation-3440", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-3647"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 73, "before_eval": {"predictions": ["to the northwest, through the present North Sea", "reompense", "energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+)", "Boston", "10th Cavalry Regiment", "4 km", "The Future", "1969", "Indian epic historical drama", "Wahhabism or Salafism", "buzzards", "many practice areas of pharmacy", "that first set of endosymbiotic events", "Danish - Norwegian patronymic surname meaning `` son of Anders ''", "Edward Trowbridge Collins Sr.", "November 2014", "when a country's influence is felt in social and cultural circles, i.e. its soft power, such that it changes the moral, cultural and societal worldview of another", "increased productivity, trade, and secular economic trends", "alex Magnoli", "the early 20th century", "in 1958 and 1979", "Karl Haushofer", "a single MHC:antigen molecule", "his mind", "structure and forces that act on one part of an object", "kilogram-force (kgf) ( sometimes kilopond) is the force exerted by standard gravity on one kilogram of mass", "Polovtsian Dances", "city", "the government - owned Panama Canal Authority", "Vernier, Switzerland", "harmonica", "PM Magazine"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33671221718096717}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.2222222222222222, 1.0, 0.4, 0.14814814814814814, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.125, 1.0, 0.0, 0.3846153846153846, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9043", "mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9530", "mrqa_triviaqa-validation-7642", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753", "mrqa_triviaqa-validation-7160"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 74, "before_eval": {"predictions": ["the United States and Newfoundland before crossing the Atlantic Ocean", "Friedrich Nietzsche", "nellie", "Anglo-Frisian languages group", "waltham forest borough", "zen", "peter white", "DeWayne Warren", "2.01 ft", "hard Candy", "George Merrill and Shannon Rubicam of the band Boy Meets Girl", "Santa Fe, New Mexico", "In 1943, at the peak of World War II", "translation", "wai Momi", "a \"consulting fee\" to get around Tesla's aversion to accept charity", "religious organizations or private individuals", "tolerance of civil disobedience", "ed michael", "China in American colonies", "film scripts written by ghost writers, nonfiction books on military subjects, and video games", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s", "Instagram's own account", "Karlheinz Stockhausen", "1990", "artur Oppman", "1930", "indirectly, transmitted as gluons, which form part of the virtual pi and rho mesons", "simpler, more personal, Trinitarian language", "April 13, 2018", "film", "business magnate, investor, and philanthropist"], "metric_results": {"EM": 0.125, "QA-F1": 0.24629103535353536}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2666666666666667, 0.0, 0.3333333333333333, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_triviaqa-validation-6002", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_naturalquestions-validation-3188", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_triviaqa-validation-4614", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_squad-validation-801", "mrqa_hotpotqa-validation-4964", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 75, "before_eval": {"predictions": ["December 1974", "Andrea Palladio", "Eric Clapton", "Gaahl", "dart", "heavy tank", "bannockburn", "author of the New York Times bestseller Before I Fall Lauren Oliver", "bbc", "1902", "Statue of Freedom", "1963", "17:16:20 GMT", "30 percent of the city's total population", "Somerville", "the state legislators of Assam", "350 government officials and climate change experts", "Gothic", "russia", "scrolls", "Environmental Protection Agency", "523 km", "tube", "Cher", "one person", "Luger P08", "Al-Masjid an-Nabawi", "1556", "asylums", "Fall migration usually begins in mid-August and continues through mid-September", "manned lunar landing", "flying"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2636879105090312}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.25, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.06896551724137931, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8685", "mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_squad-validation-7732", "mrqa_squad-validation-683", "mrqa_hotpotqa-validation-1689", "mrqa_naturalquestions-validation-9546", "mrqa_squad-validation-8525", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_squad-validation-903", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4413", "mrqa_naturalquestions-validation-6482", "mrqa_triviaqa-validation-1199", "mrqa_naturalquestions-validation-2006", "mrqa_hotpotqa-validation-2646"], "retrieved_ids": ["mrqa_naturalquestions-train-2983", "mrqa_naturalquestions-train-37667", "mrqa_naturalquestions-train-86945", "mrqa_hotpotqa-validation-1567", "mrqa_squad-validation-5586", "mrqa_naturalquestions-train-43621", "mrqa_naturalquestions-train-22019", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-2723", "mrqa_triviaqa-validation-6423", "mrqa_naturalquestions-train-63281", "mrqa_naturalquestions-train-86038", "mrqa_naturalquestions-train-88241", "mrqa_squad-validation-5407", "mrqa_naturalquestions-train-12052", "mrqa_squad-validation-4369", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-1871", "mrqa_naturalquestions-train-57470", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-8054", "mrqa_naturalquestions-train-66122", "mrqa_naturalquestions-train-57470", "mrqa_naturalquestions-train-18805", "mrqa_triviaqa-validation-5876", "mrqa_naturalquestions-train-77410", "mrqa_naturalquestions-train-64565", "mrqa_triviaqa-validation-3617", "mrqa_hotpotqa-validation-1782", "mrqa_naturalquestions-train-76964", "mrqa_naturalquestions-train-11504", "mrqa_naturalquestions-train-68685"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 76, "before_eval": {"predictions": ["Raiders quarterback Rich Gannon", "2010", "many bands, including a 1990 single by Saint Etienne", "novelization of the 1977 film Star Wars", "9 November 1967", "White Star Line", "elected", "mulberry", "The Miracle Maker", "Conrad Lewis", "2017 - 12 - 10", "Dollar and Thrifty Automotive Group", "2013", "the states to finance health care for individuals who were at or close to the public assistance level with federal matching funds", "Christian Goldbach", "Grease", "North Sudan", "247.3 million", "reborn", "Shukratara by Date", "Tachycardia, also called tachyarrhythmia", "Pluto", "Richard Burbage", "blood poisoning", "the Parliament of the United Kingdom at Westminster continues to constitute the supreme legislature of Scotland", "achievement-oriented motivations", "discarded just before re-entry", "A Song of Ice and Fire", "Morrissey", "Julia McKenzie", "15 February 1998", "Twitch Interactive"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3477453626799557}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9302325581395349, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.28571428571428575, 0.0, 0.25, 0.6666666666666666, 0.14285714285714288, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-5449", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_hotpotqa-validation-5027", "mrqa_naturalquestions-validation-2102", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-3678", "mrqa_naturalquestions-validation-6258", "mrqa_squad-validation-9014", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-2550", "mrqa_squad-validation-1927", "mrqa_hotpotqa-validation-4510", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-956", "mrqa_naturalquestions-validation-2270", "mrqa_squad-validation-5031", "mrqa_squad-validation-9547", "mrqa_squad-validation-3885", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591", "mrqa_hotpotqa-validation-4791"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 77, "before_eval": {"predictions": ["the Toronto Huskies", "100-meter freestyle", "Genetic branches", "east-west through the centre of Victoria", "four", "central", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "lofsongur", "islay", "troposphere", "central America", "The Fixx", "67,038", "The Swiss Express", "Javed Ahmad Ghamidi", "handwriting", "the highest quotient", "William the Conqueror", "Pristin", "Jack", "at any time after the auction", "the northernmost point at which the noon sun is just visible on the December solstice", "The show focuses on the original and founding ( `` mother '' ) charter, Sons of Anarchy Motorcycle Club, Redwood Original, referred to by the acronym SAMCRO or Sam Crow", "florida", "Great Yuan", "Deepak Tijori", "1974", "Acura", "hydrogen peroxide", "food and clothing", "Masahiko Takeshita", "the amino acids glycine and arginine"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29352661836214466}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.07407407407407407, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.2857142857142857, 0.07692307692307691, 0.7894736842105263, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337]}}, "error_ids": ["mrqa_naturalquestions-validation-70", "mrqa_triviaqa-validation-6483", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_hotpotqa-validation-2622", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_hotpotqa-validation-1237", "mrqa_naturalquestions-validation-686"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 78, "before_eval": {"predictions": ["21 June 2007", "healthcare professionals with specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "bear", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic Irish veterinary surgeon", "criminality", "Anne of Green Gables", "synovial joint", "london", "heineken", "east end", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1484", "A lymphocyte is one of the subtypes of white blood cell in a vertebrate's immune system", "electronic sound sources, live instrumental playing and digital signal processing", "1814", "latent", "Mongolian", "Google", "The Indianapolis Times and the Cleveland Press", "Jurchen Aisin Gioro clan in Manchuria", "baloney", "Fort Frontenac on the north shore of Lake Ontario and an expedition through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec", "friendship", "874.3 square miles (2,264 km2)", "Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840", "DTIME(n2)", "a poor harvest in 1757", "loud and dirty", "don't tell my heart", "chocolate confection"], "metric_results": {"EM": 0.125, "QA-F1": 0.2622082042366018}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.3448275862068966, 0.0, 0.35294117647058826, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92, 0.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.15384615384615385, 0.0, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_naturalquestions-validation-5838", "mrqa_hotpotqa-validation-1219", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_squad-validation-7476", "mrqa_squad-validation-1807", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-3616", "mrqa_triviaqa-validation-1465"], "retrieved_ids": ["mrqa_triviaqa-validation-3861", "mrqa_triviaqa-validation-1575", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-3149", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-6224", "mrqa_naturalquestions-train-84807", "mrqa_naturalquestions-train-63281", "mrqa_naturalquestions-validation-2684", "mrqa_naturalquestions-train-4691", "mrqa_squad-validation-6319", "mrqa_naturalquestions-train-42559", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-train-10353", "mrqa_naturalquestions-train-33056", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-5573", "mrqa_squad-validation-8924", "mrqa_naturalquestions-train-52433", "mrqa_naturalquestions-train-14048", "mrqa_naturalquestions-train-7972", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-6706", "mrqa_naturalquestions-train-54239", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-1578", "mrqa_naturalquestions-train-3313", "mrqa_naturalquestions-train-43736", "mrqa_hotpotqa-validation-4904", "mrqa_triviaqa-validation-7082", "mrqa_hotpotqa-validation-1315", "mrqa_hotpotqa-validation-73"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 79, "before_eval": {"predictions": ["Sir Hiram Stevens Maxim", "1987", "`` 200 ''", "make direct representations to the Presiding Officer to nominate speakers", "Chesley Burnett", "October 12, 2017", "an allegiance oath that must be taken by all immigrants who wish to become United States citizens", "Kevin Whately", "Tom Hanks", "pixilation or pixilate animation", "caucuses", "September of that year", "euro sign ( \u20ac ) is the currency sign used for the euro, the official currency of the Eurozone in the European Union ( EU )", "the Industrial Revolution", "an inward spiral where it would eventually cross the event horizon", "Boletus edulis", "wGN-TV", "rugged terrain such as the Arctic", "the Mexico\u2013united States border", "Carolina Panthers", "a ribosome in the cytosol", "Oyster Bay", "Ringo Starr", "leicestershire", "reciprocating steam engines", "either by voting or voice vote", "Calendar for Fixing the Seasons", "16 %", "jama", "Secretary of Defense", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "thirteen American colonies, then at war with the Kingdom of Great Britain"], "metric_results": {"EM": 0.21875, "QA-F1": 0.30980339105339105}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.35714285714285715, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2846", "mrqa_triviaqa-validation-3844", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4529", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-8960", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 80, "before_eval": {"predictions": ["Tom Courtenay", "calliope", "Shilunga", "Sachin Tendulkar", "fredeway", "Terre Haute", "3 Squadron", "until the oil shock", "mars\u00e9e du l Luxembourg", "State Bar of Arizona", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "beer", "sunlight", "red", "discus fish", "1967", "Mondays", "22 miles (8 km)", "1598", "the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "geoffrey", "j.W. Croker", "Topeka, Kansas", "500", "rochdale", "the veil", "1894", "since they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "coldplay", "siddhi", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.125, "QA-F1": 0.2586767399267399}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.4, 0.3571428571428571, 0.4, 0.0, 0.5, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-2148", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3056", "mrqa_hotpotqa-validation-3282", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_naturalquestions-validation-7848", "mrqa_hotpotqa-validation-3779", "mrqa_squad-validation-3570", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_squad-validation-4818", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-2009", "mrqa_hotpotqa-validation-2840", "mrqa_squad-validation-10182", "mrqa_triviaqa-validation-5904", "mrqa_naturalquestions-validation-870", "mrqa_squad-validation-4975", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129", "mrqa_squad-validation-1930"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 81, "before_eval": {"predictions": ["one", "National Football Conference", "2005", "as an adviser", "USD 3.1 billion dollars", "A rear - view mirror ( or rearview mirror ) is a mirror in automobiles and other vehicles, designed to allow the driver to see rearward through the vehicle's rear window ( rear windshield )", "The Birds", "identify rock samples in the laboratory", "French & Saunders", "the European Parliament and the Council of the European Union", "car crash", "either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Thomas Edison", "trio", "M\u00fcntzer's execution", "red hot poker", "Spiral", "president harding", "b Bavaria", "three", "construction service firms (e.g. engineering, architecture) and construction managers (firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project)", "london", "`` Feed Jake '' is a song written by Danny `` Bear '' Mayo, and recorded by the American country music band Pirates of the Mississippi", "several hundred thousand", "photoelectric effect", "Noel ( who had previously only sung lead on B-sides) instead of his brother, Liam", "Max West", "First TransPennine Express", "alumina", "newspapers, television, radio, cable television, and other businesses", "Lakshmibai", "moxibustion"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3637188770029627}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.47058823529411764, 0.20689655172413793, 0.0, 0.0, 1.0, 1.0, 0.0, 0.21052631578947367, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5294117647058824, 0.0, 0.5384615384615384, 0.0, 1.0, 0.125, 0.3333333333333333, 0.0, 0.0, 0.7692307692307693, 0.4, 0.2222222222222222]}}, "error_ids": ["mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_naturalquestions-validation-8591", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-5053", "mrqa_hotpotqa-validation-1701", "mrqa_triviaqa-validation-4596", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_squad-validation-914", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-3695", "mrqa_squad-validation-5288", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664", "mrqa_squad-validation-8265"], "retrieved_ids": ["mrqa_naturalquestions-train-30761", "mrqa_naturalquestions-train-12377", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-1052", "mrqa_naturalquestions-train-14238", "mrqa_hotpotqa-validation-83", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-2551", "mrqa_naturalquestions-train-80588", "mrqa_hotpotqa-validation-2635", "mrqa_naturalquestions-train-33890", "mrqa_naturalquestions-train-38219", "mrqa_naturalquestions-train-44175", "mrqa_hotpotqa-validation-946", "mrqa_triviaqa-validation-4827", "mrqa_naturalquestions-train-22972", "mrqa_naturalquestions-train-9244", "mrqa_naturalquestions-train-61302", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-5654", "mrqa_squad-validation-8201", "mrqa_naturalquestions-train-17749", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-2248", "mrqa_hotpotqa-validation-3853", "mrqa_naturalquestions-train-76564", "mrqa_squad-validation-19", "mrqa_triviaqa-validation-3568", "mrqa_naturalquestions-train-55873", "mrqa_naturalquestions-train-85275", "mrqa_squad-validation-4768", "mrqa_naturalquestions-train-7405"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 82, "before_eval": {"predictions": ["keodale", "normal force", "mouth", "ends 24 hours later", "April 20, 1945", "dachshund", "farmers grow new pigeon pea varieties, instead of maize, in particularly dry areas", "geologic, topographic, and natural ecosystem", "129", "Bunkhouse", "shoes", "a growing sport in southern California, particularly at the high school level, with increasing numbers of schools adding rugby as an official school sport", "geese", "Jamukha", "tentacles and prey", "bauxite", "Kannada", "Lawrence County State's Attorney John Fitzgerald, Chief Deputy Attorney General Charlie McGuigan, and attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "water on the ground surface enters the soil", "9.9ft", "film and short novels", "American-Canadian mystery-drama", "film \"Play Misty for Me\" and \" Grand Prix\"", "Gardnerville", "Nucleotides", "25-minute episodes", "Julian Paul Julian", "zapatista national Liberation Army", "Vikram Bhatt, Bhushan Patel and Tinu Suresh Desai", "green", "2003", "salt"], "metric_results": {"EM": 0.125, "QA-F1": 0.26265071230191467}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 0.5517241379310345, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5454545454545454, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2133", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-2791", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_triviaqa-validation-5592", "mrqa_squad-validation-2748", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_squad-validation-4616", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-4493", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_hotpotqa-validation-164", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 83, "before_eval": {"predictions": ["belgium", "Southeast Europe, Western Asia, the Caucasus, North Africa, and the Horn of Africa", "an illustration by Everest creative Maganlal Daiya back in the 1960s", "architecture from the gothic, renaissance, baroque and neoclassical periods", "at speeds much higher than a bullet in free fall", "the aboral organ", "bird", "scrooge", "6.6", "Berlin", "Maidstone", "kingdoms of Francia on the Lower Rhine, Burgundy on the Upper Rhine and Alemannia", "Sultan S\u00fcleyman-\u0131 Evvel", "4 ( etiology of disease ) ; 5 ( body part affected ) ; 6 ( severity of illness ) ; and 7 ( placeholder for extension of the code to increase specificity )", "Titanic", "difficult and intricate topics", "email", "ABC Radio, with Clear Channel Communications and Westwood One ( which had earlier purchased NBC's radio division, as well as the distribution rights to CBS's, and the Mutual Broadcasting System during the 1990s)", "Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "detritus", "Rated R", "september", "Steveston Outdoor pool", "alternating current", "Terry the Tomboy", "scarlet tanager", "South Australia", "Mach number (M or Ma) ( ; ] ) is a dimensionless quantity representing the ratio of flow velocity past a boundary to the local speed of sound", "at pit road speed during the warm - up laps", "North Atlantic Conference", "at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "bbc"], "metric_results": {"EM": 0.25, "QA-F1": 0.370941360435575}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.16666666666666669, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.15384615384615385, 0.0, 0.08695652173913045, 1.0, 0.0, 0.0, 0.12903225806451613, 0.761904761904762, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5454545454545454, 1.0, 0.8484848484848485, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_triviaqa-validation-3113", "mrqa_triviaqa-validation-271", "mrqa_triviaqa-validation-7486", "mrqa_hotpotqa-validation-2221", "mrqa_squad-validation-3107", "mrqa_squad-validation-9349", "mrqa_hotpotqa-validation-1312", "mrqa_naturalquestions-validation-5214", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_squad-validation-5739", "mrqa_naturalquestions-validation-3837", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-8518", "mrqa_triviaqa-validation-5793"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 84, "before_eval": {"predictions": ["music", "13 years and 48 days", "Nathan Bedford Forrest", "Theodosius I", "Ubiorum", "in front of only 700 fans", "bbc", "60", "Assistant Attorney General for Civil Rights and federal prosecutor for the Southern District of Florida", "better fuel economy, which Orenda Aerospace felt would be attractive for older aircraft whose engines were reaching the end of their lifespan", "september", "evacuate the cylinder, choking it and giving excessive compression", "cactus", "optic disc", "Carson City", "biologist", "Egyptians", "wis warfield", "published posthumously in 1890 in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "United States ambassador to Ghana and to Czechoslovakia and also served as Chief of Protocol of the United States", "Warriors", "Emma Thompson and Alice Eve", "edible - nest swiftlets", "christ's glorification", "travel literature, cartography, geography, and scientific education", "son", "royal residence", "chiang Kai-Shek", "25 lb (57 kg) and below", "leg", "Lexus", "a prison"], "metric_results": {"EM": 0.21875, "QA-F1": 0.36804350647787754}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.24, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8510638297872342, 0.2857142857142857, 0.0, 0.5714285714285715, 0.4615384615384615, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-370", "mrqa_hotpotqa-validation-3830", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1628", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_squad-validation-3364", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_naturalquestions-validation-10461", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1645", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_hotpotqa-validation-1810", "mrqa_naturalquestions-validation-3173", "mrqa_naturalquestions-validation-6660"], "retrieved_ids": ["mrqa_squad-validation-361", "mrqa_naturalquestions-train-44254", "mrqa_naturalquestions-train-81419", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-train-57704", "mrqa_hotpotqa-validation-389", "mrqa_naturalquestions-train-76391", "mrqa_triviaqa-validation-3014", "mrqa_hotpotqa-validation-1906", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-11", "mrqa_naturalquestions-train-7459", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-train-61414", "mrqa_naturalquestions-train-27853", "mrqa_triviaqa-validation-6896", "mrqa_hotpotqa-validation-5607", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-train-20194", "mrqa_naturalquestions-train-29733", "mrqa_hotpotqa-validation-61", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-6423", "mrqa_naturalquestions-train-81557", "mrqa_naturalquestions-train-54776", "mrqa_hotpotqa-validation-613", "mrqa_triviaqa-validation-326", "mrqa_hotpotqa-validation-1312", "mrqa_hotpotqa-validation-5651", "mrqa_naturalquestions-train-6421"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 85, "before_eval": {"predictions": ["Europe, North America, East Asia and South Asia", "about 10,000", "Stevie Young", "fall", "15:01.83", "October 13, 1980", "between 1765 and 1783", "mutiny", "heart transplant", "on a bread plate, sometimes in the napkin", "isle of Innisfree", "bilaterally symmetrical", "he did not consider the papacy part of the biblical Church", "1837", "November 27, 2017", "Bambi, a Life in the Woods", "point on the frontier indicates efficient use of the available inputs ( such as points B, D and C in the graph )", "from ages 12\u201318, while authors and readers of \"Young teen novels\" often define it as written for those aged 15 to the early 20s", "Apple A6X chip", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "in school at a given time in the school day ( such as lunch, recess or after school); or even to attend school on a non-school day", "guinea", "Pride and Prejudice", "lactobacilli", "a school or other place of formal education", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "paris", "David Hatcher Childress", "Osprey", "during the 1980s and'90s", "Roland Ratzenberger", "200 to 500 mg up to 7 ml"], "metric_results": {"EM": 0.125, "QA-F1": 0.205625}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 1.0, 0.0, 0.2, 0.32, 0.16, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 1.0, 0.25, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2]}}, "error_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_hotpotqa-validation-4719", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-244", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-4854", "mrqa_squad-validation-1566", "mrqa_triviaqa-validation-2508", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 86, "before_eval": {"predictions": ["Native Americans", "thammasat", "South Sentinel Island", "FCA US", "Aaron Taylor- Johnson", "blue", "San Francisco Peace Treaty", "a gift", "conservative", "Peter Davison, Colin Baker and Sylvester McCoy", "Islam", "Super Bowl XXVIII at the end of the 1993 season", "maquiladora", "Rich Girl", "cells", "fifth", "a problem", "13 May 1787", "WTVG", "Great Lakes", "temperatures and sea levels have been rising at or above the maximum rates proposed during the last IPCC report in 2001", "Jews", "film playback singer", "southern whites", "Marie", "L", "Commonwealth Universities", "drawing letters", "electroweak", "the Allstars", "stood by their contents", "August 1, 2016"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3658358134920635}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 0.8750000000000001, 0.0, 0.2222222222222222, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.14285714285714285, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5195", "mrqa_triviaqa-validation-3781", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_squad-validation-782", "mrqa_naturalquestions-validation-3004", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-6912"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 87, "before_eval": {"predictions": ["Paris", "electronic gaming machines", "August 21, 1995", "Mohammad Reza Pahlavi", "digital streams", "American Broadcasting Company", "on a sound stage in front of a live audience in Burbank, California", "Mongolian, Tibetan, and Chinese", "Due to the controversial and explicit nature of many of their songs", "Meghan Trainor", "carbon cycle", "activist", "recite the 42 negative confessions of Maat as their heart was weighed against the feather of truth", "Donna Noble (Catherine Tate) with Mickey Smith (noel Clarke) and Jack Harkness (John Barrowman) recurring as secondary companion figures", "salvaging a country usually seen as one of the most stable and prosperous in Africa", "the Ruul", "titanium metal", "Loud", "the Kikuyu, Embu and Kamba words Kirinyaga, Kirenyaa and Kiinyaa", "australia", "domestic legislation", "esoteric", "toothbrush", "the Senate is composed of senators, each of whom represents a single state in its entirety, with each state being equally represented by two senators, regardless of its population, serving staggered terms of six years", "sherry", "Thutmose III", "ten to fifteen", "Buck Owens and the Buckaroos", "Kansas", "political support", "Finding Nemo", "Wimbledon tennis club"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4073543233082707}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4210526315789474, 0.6428571428571429, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6153846153846153, 0.0, 0.5714285714285715, 0.0, 0.0, 0.05128205128205128, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_naturalquestions-validation-2196", "mrqa_squad-validation-5648", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_triviaqa-validation-7649", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_squad-validation-2122", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_squad-validation-8552", "mrqa_hotpotqa-validation-5743", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-2814"], "retrieved_ids": ["mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-train-88241", "mrqa_triviaqa-validation-2202", "mrqa_naturalquestions-train-29726", "mrqa_hotpotqa-validation-4167", "mrqa_triviaqa-validation-6938", "mrqa_naturalquestions-validation-9763", "mrqa_naturalquestions-train-16925", "mrqa_naturalquestions-train-78621", "mrqa_triviaqa-validation-6373", "mrqa_naturalquestions-train-83773", "mrqa_naturalquestions-train-23825", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-train-11390", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-6403", "mrqa_naturalquestions-train-84669", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-1689", "mrqa_naturalquestions-train-33547", "mrqa_naturalquestions-train-70702", "mrqa_squad-validation-3318", "mrqa_naturalquestions-train-66122", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-train-62898", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-7394", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-7394", "mrqa_hotpotqa-validation-1142", "mrqa_naturalquestions-train-83049"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 88, "before_eval": {"predictions": ["brother", "Jackie Jackson", "Gold Coast", "to create a test case as to the constitutionality of a law", "Selena Gomez", "Hawaiian Airlines", "Forbes", "158 beats per minute ( bpm )", "small intestine", "Led Zeppelin", "\"public\" (state-controlled) and \"independent\"", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "september", "eponymous protagonist", "the deserts of the southwestern United States, Mexico, and Central America", "high risk of a conflict of interest and/or the avoidance of absolute powers", "sacerdotalism", "discontinued", "half a million", "44", "the Gaulish name R\u0113nos, which was adapted in Roman-era geography (1st century BC) as Greek \u1fec\u1fc6\u03bd\u03bf\u03c2 ( Rh\u0113nos) Latin Rhenus", "the company generates income", "emmy", "county council", "A combination of both original tunes by the characters in the show, popular hits by popular music artists such as Alicia Keys, Jhen\u00e9 Aiko, India Arie, and Solange Knowles & Destiny's Child", "Ward", "Kevin Michael Richardson", "Eddie Gottlieb Trophy", "Rihanna", "Pashtun peoples living in areas of Afghanistan and Pakistan and neighboring countries", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.125, "QA-F1": 0.20980833682446587}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.13333333333333333, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.06451612903225806, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-4066", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_squad-validation-9246", "mrqa_naturalquestions-validation-5291", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_hotpotqa-validation-5498", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 89, "before_eval": {"predictions": ["169", "conscientious lawbreakers must be punished", "House of Fraser", "Bonkyll Castle", "veal stock", "The best, worst and average case complexity", "Deadman's Gun", "september", "the Philippines in either Tagalog or English", "Z-ring", "shirley williams", "1938", "the referendum in the Netherlands", "venus williams", "William Allen White Book Award", "Louis XVIII", "January 30, 1930", "sweden", "national airline", "all states, Washington, D.C. as well as all U.S. territories except American Samoa, but not on all Native American tribal lands", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "Janis Joplin with the poets Michael McClure and Bob Neuwirth", "Odinga", "homicides", "attingham", "New Jersey Meadowlands", "November 6, 2018", "zasagt Khan", "American philosophy of pragmatism and particularly from the work of George Herbert Mead", "USC Trojans", "Ian Hart", "sequential proteolytic activation of complement molecules"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2888977347991567}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false], "QA-F1": [0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6451612903225806, 0.23076923076923078, 0.9473684210526316, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-803", "mrqa_squad-validation-6773", "mrqa_hotpotqa-validation-1756", "mrqa_triviaqa-validation-3639", "mrqa_squad-validation-1700", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_hotpotqa-validation-2774", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 90, "before_eval": {"predictions": ["a very reactive allotrope of oxygen that is damaging to lung tissue", "reactive allotrope", "The Daleks' Master Plan", "tragedy", "phylum", "Faults", "magnetic field", "bounding the time or space used by the algorithm", "lawful protest demonstration, nonviolent civil disobedience, and violent civil disobedience", "clefs", "20 regional offices and 11 sub-offices", "black Bottom", "a self-referential time-related adage, coined by Douglas Hofstadter and named after him", "The Book of Roger", "time", "photolysis", "1998\u20132002", "berkshire", "Grisha Alekandrovich Nikolaev", "cytotoxic", "rootlets", "ivy", "Ken Howard", "red", "Steelers", "antigens", "A74(M)", "park Inn", "september", "Morty", "Catherine Earnshaw", "178 Vivienne Westwood costumes"], "metric_results": {"EM": 0.125, "QA-F1": 0.1736111111111111}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.16666666666666669, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-3496", "mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_squad-validation-4971", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-1689", "mrqa_triviaqa-validation-2940", "mrqa_triviaqa-validation-5", "mrqa_hotpotqa-validation-4809", "mrqa_squad-validation-1070", "mrqa_squad-validation-10358", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_naturalquestions-validation-3233", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-3988", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-3575", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "retrieved_ids": ["mrqa_squad-validation-5517", "mrqa_triviaqa-validation-1028", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-3647", "mrqa_naturalquestions-train-87750", "mrqa_triviaqa-validation-6541", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-4081", "mrqa_squad-validation-5586", "mrqa_naturalquestions-train-25841", "mrqa_naturalquestions-train-10206", "mrqa_naturalquestions-train-843", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-182", "mrqa_naturalquestions-train-45943", "mrqa_naturalquestions-train-4338", "mrqa_triviaqa-validation-1166", "mrqa_naturalquestions-train-14278", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-train-35634", "mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-train-33739", "mrqa_squad-validation-4456", "mrqa_naturalquestions-train-59079", "mrqa_hotpotqa-validation-1506", "mrqa_triviaqa-validation-6063", "mrqa_naturalquestions-train-12205", "mrqa_triviaqa-validation-3286", "mrqa_naturalquestions-train-19270", "mrqa_naturalquestions-train-24858", "mrqa_naturalquestions-validation-8877"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 91, "before_eval": {"predictions": ["40%", "catherine", "Mongolian patrimonial feudalism and the traditional Chinese autocratic-bureaucratic system", "millais", "neighboring Pakistan", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Australian-American", "around 100,000 writes", "paris", "marquesas Islands", "montgomery", "North Greenwich Arena", "seed - producing plants that includes conifers, cycads, Ginkgo, and gnetophytes", "The 2015 Masters Tournament", "Chiba, Japan", "90% certain", "Bessemer process", "communication", "1856", "lizards", "deities and spirits", "ulysses S. Grant", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "gregory cowntree", "corvids", "South Africa", "Four Weddings and a Funeral", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistan", "psilocybe", "Bronx Tale"], "metric_results": {"EM": 0.21875, "QA-F1": 0.38224940513839945}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.47058823529411764, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.967741935483871, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4749", "mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-4471", "mrqa_hotpotqa-validation-2205", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-1473", "mrqa_triviaqa-validation-6594"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 92, "before_eval": {"predictions": ["a field in Somerset County, Pennsylvania", "communism", "\"Barracuda Frank\", was a loan shark and soldier in the Bruno crime family", "the United States Congress", "Singapore", "July 25, 1898", "BitInstant", "\"Fame\", Debbie Berwick on \"Phil of the Future\"", "florida", "farm tractors, motorcycles ( without much success) and even automobiles as the Stanley Steamer", "Social Chapter", "Australia", "retina", "the physics is now described by the Schr\u00f6dinger equation instead of Newtonian equations", "The Lone Ranger", "Sargent Shriver Jr.", "Landry's, Inc.", "George Mifflin Dallas", "David Naughton, Jenny Agutter and Griffin Dunne", "home Guard", "Chicago", "london", "1978", "inversely", "propeller", "The Irvine Spectrum, West Irvine, and international corporations headquartered at the University of California, Irvine", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "rugby union", "November 20, 1942", "roughly equivalent to little Hugos, or those who want Hugo", "Morning Edition"], "metric_results": {"EM": 0.375, "QA-F1": 0.4535998774509804}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, false, true, false, true], "QA-F1": [0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.125, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8235294117647058, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_hotpotqa-validation-3514", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_hotpotqa-validation-2474", "mrqa_triviaqa-validation-5888", "mrqa_squad-validation-3276", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-6960", "mrqa_triviaqa-validation-7185", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_triviaqa-validation-1267", "mrqa_squad-validation-3189"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 93, "before_eval": {"predictions": ["saskatchewan", "a method which pre-allocates dedicated network bandwidth specifically for each communication session, each having a constant bit rate and latency between nodes", "district line", "Utah", "golfer", "Great Britain", "mid-size four - wheel drive", "afro-Guyanese", "robert", "we want to practice Christian love toward them and pray that they convert", "two populations of rodents", "sometime between 124 and 800 CE, with some theories dating the earliest Polynesian settlements to the 10th or even 13th century", "T'Pau", "geheime Staatspolizei", "1815", "American Football Conference", "seppuku", "North America where it has a core population in Michigan and surrounding states and provinces", "\"synforms\"", "2015", "man's disobedience toward God", "a representation of a function as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "\"Winnie the Pooh\"", "Transpacific Yacht Race", "German", "\"Provisional Registration\" status after a year if there is sufficient evidence to show that the \"standard for Full Registration\" has been met", "multinational corporation", "either yes or no, or alternately either 1 or 0", "British Overseas Territory, located at the southern tip of the Iberian Peninsula", "`` Company Picnic ''", "lie detector", "henry I of England"], "metric_results": {"EM": 0.25, "QA-F1": 0.344385536813}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.06060606060606061, 1.0, 0.0, 0.0, 0.0, 0.0, 0.375, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.1935483870967742, 1.0, 0.0, 0.0, 0.34782608695652173, 0.0, 0.0, 0.33333333333333337, 0.18181818181818182, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_naturalquestions-validation-126", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-4204", "mrqa_naturalquestions-validation-2870", "mrqa_hotpotqa-validation-421", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-3298", "mrqa_squad-validation-2040", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "retrieved_ids": ["mrqa_squad-validation-2757", "mrqa_hotpotqa-validation-1895", "mrqa_triviaqa-validation-1697", "mrqa_naturalquestions-train-8880", "mrqa_triviaqa-validation-1205", "mrqa_naturalquestions-train-64654", "mrqa_squad-validation-1750", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-train-55902", "mrqa_naturalquestions-train-14757", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-2096", "mrqa_triviaqa-validation-3014", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-train-37732", "mrqa_naturalquestions-train-43185", "mrqa_naturalquestions-train-35291", "mrqa_hotpotqa-validation-3146", "mrqa_squad-validation-1705", "mrqa_triviaqa-validation-7082", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-train-82501", "mrqa_naturalquestions-train-16389", "mrqa_naturalquestions-validation-2893", "mrqa_naturalquestions-train-26392", "mrqa_naturalquestions-train-19046", "mrqa_naturalquestions-train-74849", "mrqa_naturalquestions-train-84727", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-2937"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 94, "before_eval": {"predictions": ["nucleus", "Stephen Edwin King", "texas", "bantu", "southeast of the city", "the southwestern part of the island", "the French island of Guadeloupe in the Lesser Antilles, mainly in the commune of Deshaies", "\u201cstatute of Rageman\u201d (De Ragemannis)", "1938", "about 63%", "American pharmaceutical company and one of the largest pharmaceutical companies in the world", "2016", "90% to 93% O2", "approximately 11 %", "special sovereignty", "Chen's theorem", "kiel canal", "harsh", "1987", "dastardly & muttley", "the governing body for pharmacy health care professionals and this is who regulates the practice of pharmacists and pharmacy technicians", "tyler wentworth", "1968", "enlisted sailor's rate, while the word rating refers to one's area of occupational specialization within the enlisted Navy", "In June 1755 to take Fort Duquesne. The expedition was a disaster. It was attacked by French and Indian soldiers ambushing them from up in trees and behind logs. Braddock called for a retreat.", "the Deobandi movement established for impoverished Afghan refugees and supported by governmental and religious groups in neighboring Pakistan", "June 11, 1986", "Cork, Portarlington, Lisburn, Waterford and Youghal", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash in Hindi, Urdu and Punjabi", "Congressman Tom Coburn, MD", "Short Circuit", "increased and the ground water level fell significantly. Dead branches dried up and the amount of forests on the flood plains decreased sharply. On the French side, the Grand Canal d'Alsace was dug"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20928923179503675}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.6666666666666666, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.17647058823529413, 0.0, 1.0, 0.923076923076923, 0.2857142857142857, 0.0, 0.0, 0.18181818181818182]}}, "error_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_squad-validation-3315", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-3677", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_triviaqa-validation-3230", "mrqa_squad-validation-6322", "mrqa_triviaqa-validation-5584", "mrqa_hotpotqa-validation-2328", "mrqa_naturalquestions-validation-4365", "mrqa_squad-validation-10196", "mrqa_squad-validation-9737", "mrqa_squad-validation-3306", "mrqa_naturalquestions-validation-7496", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 95, "before_eval": {"predictions": ["the \"richest 1 percent in the United States", "universal ruler", "red", "alain Giresse", "Lombardy", "ideal", "david duchovny", "elephant slamander", "American newspaper magnate William Randolph Hearst", "parashah", "the s - block", "World Music Awards", "six", "8\u20134\u20134 system", "exposed to scrutiny", "79", "banned the growing of coffee", "New France was defended by about 3,000 troupes de la marine, companies of colonial regulars (some of whom had significant woodland combat experience)", "a compromise", "stimulated his brain cells", "leprechaun", "Daniel Ken", "Jack Nicklaus", "Bobb McKittrick", "honeycomb", "11", "Paul Edgecombe", "Portuguese", "a downward pressure on wages", "the university's science club", "the Jurchen Aisin Gioro clan", "danish"], "metric_results": {"EM": 0.25, "QA-F1": 0.355839518668466}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.07692307692307691, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444444, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_squad-validation-9135", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8288", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_squad-validation-1445", "mrqa_triviaqa-validation-2900", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-4796"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 96, "before_eval": {"predictions": ["silicon (silica SiO2, as found in granite and quartz) aluminium (aluminium oxide Al2O3, in bauxite and corundum) iron", "Marcus Atilius Regulus", "Dome of the Rock", "Public-Private Partnering (PPPs) aka private finance initiatives (PFIs) and alliances such as \"pure\" or \" Project\" alliances and \"impure\" or\ufffdstr Strategic\" alliances.", "The Hebrew word kabod ( K-B-D ) originally means `` weight '' or `` brilliant celebrity with praise ''", "alberta, New Mexico", "Bulgaria", "13,900 nautical miles (25,700 km) downrange in the Pacific ocean", "the Air Force, Army, Navy and other services", "Mr. Destiny", "Renhe Sports Management Ltd, 100 % owned by Xiu Li Dai and Yongge Dai. 25 % Owned by Narin Niruttinanon", "Kansas City Royals", "a free gift of God's grace through faith in Jesus Christ as redeemer from sin", "hydrogen and helium", "They also spread beyond Europe to the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec, where they were accepted and allowed to worship freely.", "the cannonball ( assumed constant ) v", "2006", "74", "native Chinese dynasties", "1162", "el Che or simply Che", "Porsche's last new front-engined vehicle before the introduction of the Cayenne SUV in 2003", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "1971", "The \"Huguenot Street Historic District\" in New Paltz has been designated a National Historic Landmark site and contains the oldest street in the United States of America.", "American Christian rock band Needtobreathe", "Americans to explain the Iranian Islamic Revolution and apolitical Islam was a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970\"", "1986", "cake", "Real images can be produced by concave mirrors and converging lenses, only if the object is placed further away from the mirror / lens than the focal point and this real image is inverted", "electromagnetic", "kolinio Epeli Vanuacicila Rabuka and Salote Lomaloma Rabuka"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3140380114716276}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.10526315789473684, 0.0, 1.0, 0.17391304347826084, 0.32, 0.0, 1.0, 0.3636363636363636, 0.4444444444444445, 0.0, 0.2857142857142857, 0.0, 0.4444444444444445, 0.42857142857142855, 0.3720930232558139, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6363636363636364, 0.0, 0.4666666666666667, 1.0, 0.07692307692307693, 0.0, 0.19999999999999998, 0.06451612903225806, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_squad-validation-3876", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_triviaqa-validation-113", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-5093", "mrqa_squad-validation-8189", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-3057", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "retrieved_ids": ["mrqa_triviaqa-validation-4217", "mrqa_naturalquestions-train-66160", "mrqa_squad-validation-9589", "mrqa_triviaqa-validation-3493", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-train-51482", "mrqa_squad-validation-9951", "mrqa_triviaqa-validation-4123", "mrqa_triviaqa-validation-7020", "mrqa_naturalquestions-train-82760", "mrqa_naturalquestions-train-18261", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-10180", "mrqa_naturalquestions-train-27938", "mrqa_squad-validation-2259", "mrqa_naturalquestions-train-69046", "mrqa_naturalquestions-train-68927", "mrqa_naturalquestions-train-58439", "mrqa_squad-validation-10312", "mrqa_naturalquestions-train-15366", "mrqa_naturalquestions-train-16568", "mrqa_naturalquestions-train-23685", "mrqa_naturalquestions-train-4943", "mrqa_naturalquestions-train-75889", "mrqa_naturalquestions-train-74251", "mrqa_naturalquestions-train-35817", "mrqa_naturalquestions-train-9200", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-train-11149", "mrqa_triviaqa-validation-6556", "mrqa_naturalquestions-train-50299", "mrqa_naturalquestions-train-32127"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 97, "before_eval": {"predictions": ["6th", "Good work designed to attract God's favor", "suburb", "The National Era", "American Civil War", "blackberry", "April 26, 2005", "a few drops", "former Sheriff Deputy Rick Grimes", "new york city", "Vice president", "optic chiasm", "the Continental Edison Company in France, designing and making improvements to electrical equipment", "quote Shelley's Masque of Anarchy to vast audiences during the campaign for a free India", "Semites", "Yuliya Snigir", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Galicia", "bbc", "jazz", "26", "AC", "kolkata", "Nickelback", "Juliet", "the \"father of the Mongols\"", "the ozone hole was indeed caused by chlorine and bromine from manmade organohalogens", "a combined concert/lecture by British progressive folk-rock band Gryphon", "australia", "fomenting rebellion in many of Great Britain's far-flung colonies", "Psych is an American detective comedy-drama television series created by Steve Franks", "the planned Nazi pre-emptive nuclear strike on Japan, `` Operation Dandelion, '' is apparently being prevented only by Hitler's personal refusal to authorise it"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2891130570818071}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.5555555555555556, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.625, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_hotpotqa-validation-3785", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-7679", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-998", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-1680", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_hotpotqa-validation-2802", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_naturalquestions-validation-654", "mrqa_squad-validation-5359", "mrqa_triviaqa-validation-1081", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 98, "before_eval": {"predictions": ["the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ), when taking into consideration the full extent and duration of its after effects", "\"SKUM\", in which Sid Vicious proclaimed \"I'll just be the yob that I am now\"", "S6", "Specchio+", "the eyespot allows the organism to move in response to light, often toward the light to assist in photosynthesis, and to predict day and night, the primary function of circadian rhythms", "paris", "geologic events using radioactive isotopes and other methods", "heaviest album of all", "choruses", "San Francisco, California with offices in New York City and Atlanta", "the net effect was a sudden and general loss of confidence in the economic future", "ex as a noun is assumed to refer to a former sexual or romantic partner, especially a former spouse", "plum", "lefkosia", "\"citizenship\" so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for rights", "Jacking", "'I'll Be There for You\"", "The Blind Boys of Alabama, Tom Waits, The Neville Brothers, DoMaJe, and Steve Earle", "kent countryside", "Sultans", "the reintroduction of a free-market economy", "belgian glaciation", "much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast", "denvedere", "Whiteview Road, a primarily residential road that leads to Route 4", "a device used in many other contexts including video games, business presentations and television shows", "Germ\u00e1n Efromovich", "a limited period of time in exchange for detailed public disclosure of an invention", "edo was the political center of Japan under the Tokugawa shogunate, and a major center of economic power and of developments in popular culture (e.g. publishing, kabuki, pleasure districts )", "Stritch", "It is between the three towns of Doncaster, Scunthorpe and Gainsborough, in the traditional West Riding of Lindsey.", "1908"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23644584559820442}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true], "QA-F1": [0.4878048780487805, 0.13333333333333333, 0.0, 0.0, 0.10256410256410256, 0.4, 0.0, 1.0, 0.0, 0.42857142857142855, 0.14285714285714285, 0.47619047619047616, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.2857142857142857, 0.6666666666666666, 0.2857142857142857, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.10526315789473684, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_hotpotqa-validation-222", "mrqa_hotpotqa-validation-2978", "mrqa_triviaqa-validation-6634", "mrqa_naturalquestions-validation-2213", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_triviaqa-validation-1474", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 99, "before_eval": {"predictions": ["Doctor Who", "to implement the Prohibition Amendment by defining the process and procedures for banning alcoholic beverages, as well as their production and distribution", "elstow", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "Gender pay gap in favor of males in the labor market", "Woody's Roundup", "December 19, 1967", "economic growth by collecting resources from colonies, in combination with assuming political control by military and political means", "1997", "May 20, 2018", "Washington, D.C.", "caribbean", "Toronto, Ontario, Canada", "an Anglo-Saxon saint, of unknown date or origin, whose relics were held by Exeter Cathedral", "as to the Summons you send me to retire, I don't think myself obliged to obey it", "a balance sensor consisting of a statolith, a solid particle supported on four bundles of cilia, called \"balancers\"", "yosemite national park", "field trips", "Nikolai Trubetzkoy", "saloon-keeper", "the studies and developments department of the French firm R2E Micral in 1980 at the request of the company CCMC specializing in payroll and accounting", "1800 to 1850", "on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "the author recounts how his own opinions changed about that line when he talks to the different people about their beliefs", "Twink", "Caribbeans and people from former British Colonies were encouraged to move to the UK for work", "india civil rights", "infinitely many primes", "Portugal", "Bhaktivedanta Manor", "the giant jellyfish or the hair jelly", "Mammals"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3673994990992989}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.5, 0.09523809523809523, 0.0, 0.88, 0.2105263157894737, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 1.0, 0.0, 0.5, 0.13333333333333333, 0.9090909090909091, 0.5, 1.0, 0.0, 1.0, 1.0, 0.25, 0.23076923076923078, 0.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_hotpotqa-validation-4384", "mrqa_squad-validation-9926", "mrqa_naturalquestions-validation-5630", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_hotpotqa-validation-1086", "mrqa_squad-validation-10231", "mrqa_squad-validation-4494", "mrqa_squad-validation-1870", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-251", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794"], "retrieved_ids": ["mrqa_hotpotqa-validation-1858", "mrqa_naturalquestions-train-15081", "mrqa_hotpotqa-validation-0", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-4583", "mrqa_squad-validation-1841", "mrqa_naturalquestions-train-80763", "mrqa_triviaqa-validation-3250", "mrqa_hotpotqa-validation-482", "mrqa_naturalquestions-train-23990", "mrqa_naturalquestions-train-6576", "mrqa_squad-validation-9841", "mrqa_naturalquestions-train-37765", "mrqa_hotpotqa-validation-2403", "mrqa_naturalquestions-validation-7078", "mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-904", "mrqa_hotpotqa-validation-5383", "mrqa_squad-validation-9843", "mrqa_hotpotqa-validation-1114", "mrqa_naturalquestions-train-79779", "mrqa_naturalquestions-train-76236", "mrqa_naturalquestions-validation-9530", "mrqa_squad-validation-7821", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-1050", "mrqa_squad-validation-10293", "mrqa_naturalquestions-train-41449", "mrqa_naturalquestions-train-82568", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-2012", "mrqa_naturalquestions-train-61981"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.1728125, "QA-F1": 0.2837231764147541}, "overall_error_number": 2647, "overall_instant_fixing_rate": 0.0, "final_instream_test": {"EM": 0.679375, "QA-F1": 0.7491072140562642}, "final_upstream_test": {"EM": 0.717, "QA-F1": 0.8264939622781123}}}