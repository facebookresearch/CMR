{"model_update_steps": 1965, "method_class": "mir", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=3e-05, local_adapt_lr=3e-05, max_grad_norm=0.1, memory_key_cache_path='na', memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=1600_seed=1213_debug=LA_ckpts/memory_dict.pkl', memory_store_rate=1.0, mir_debug_largestloss=False, mir_debug_reverse=False, num_adapt_epochs=3, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=1600_seed=1213_debug=LA_ckpts/', replay_candidate_size=1600, replay_frequency=1, replay_size=32, save_all_ckpts=1, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.hidden_passes.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "art and furnishings", "turbine", "adaptive", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "50 fund", "ned sherrin", "the Mandate of Heaven", "Tar Baby", "buddha", "Poseidon", "the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho ( including the communities of Parma, Wilder, Greenleaf, and Notus )", "2009", "the direction from which the wind is blowing", "john Mortimer", "oxygen", "seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "great train robbery", "Trey Parker", "omen of good or bad luck", "power blackouts"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9674107142857142}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-5465"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "philanthropy", "neded on Mar 31, 2007", "Queen Elizabeth II", "Gary Morris", "to the anterolateral corner of the spinal cord", "1966", "for scientific observation", "pronseal", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "naba", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs show Summary", "great heroism or of the most conspicuous courage in circumstances of extreme danger", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "the check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23364713309566248}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.23529411764705885, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.5, 0.0, 0.4444444444444445, 1.0, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["Mexico", "originally designated HU - 1", "philanthropy", "mariette", "Virginia Wade", "Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York", "rotherham united", "norman tebbit", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years before", "islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "numb3rs", "for gallantry", "Michael Douglas", "Isaac Newton", "superman", "2010"], "metric_results": {"EM": 0.90625, "QA-F1": 0.90625}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10410", "before_prediction": "Galileo", "after_prediction": "Isaac Newton"}], "retained_ids": ["mrqa_squad-validation-10015", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-4684", "mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-5406"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.7999999984}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "a phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac", "the majority of the population lives in the suburbs", "a student in the second year at a secondary (high) school or college", "Bothtec", "Terry Reid", "is of sufficient quality", "the theme \u2018goes\u2019", "North America", "Andr\u00e9 3000", "rookies", "Akhenaten", "Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "Georges Bizet", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2509151648160269}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.18181818181818182, 0.20689655172413793, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 0.3636363636363636, 0.0, 0.6666666666666666, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "never", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "casketrothals", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Masaharu Iwata", "Spencer Davis Group", "non-peer-reviewed sources", "Enigma Variations", "physiographically a part of the continent of North America", "is a song written and produced by Andr\u00e9 3000", "Commander", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the United States", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "the Pacific"], "metric_results": {"EM": 0.90625, "QA-F1": 0.875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "Masaharu Iwata"}, {"id": "mrqa_squad-validation-4019", "before_prediction": "rookies", "after_prediction": "Commander"}], "retained_ids": ["mrqa_squad-validation-194"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "unfixed_ids": ["mrqa_triviaqa-validation-1935"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.3333333322222222}, {"timecode": 3, "before_eval": {"predictions": ["why do Americans call it a period and the British a full stop", "Four Year Plan", "quadrilaterals", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006", "the Great Powers", "lower motor neurons, the efferent nerves that directly innervate muscles", "is a British television game show based on the American game show Family Feud", "Glacier Mints", "Dettori determined not to be fearful of the Derby", "coronary thrombosis", "bollywood", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "The Young Ones", "cement City, Texas", "Renewable Heat Incentive scandal", "23 July 1989", "many educational institutions especially within the US", "gurus", "for control purposes", "islam", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins", "laparoscopic cholecystectomy", "berenice Abbott"], "metric_results": {"EM": 0.0625, "QA-F1": 0.1214509996582365}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360 degrees", "2022", "Staten Island", "splash", "2005\u20132010", "G20", "efferent nerves", "max bygraves", "polar bear", "lester piggott", "don't disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo Starr", "callable bonds", "Snapdragon 800", "over 10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museums"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9588293650793651}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6341", "before_prediction": "2.26 GHz quad - core Snapdragon 800 processor", "after_prediction": "Snapdragon 800"}], "retained_ids": ["mrqa_hotpotqa-validation-5662"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "unfixed_ids": ["mrqa_triviaqa-validation-5362", "mrqa_squad-validation-1539"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.4999999975}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Remagen", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "month of marzo pazzerello", "a shepherd", "museums", "is an infection caused by bacteria called Clostridium tetani", "bounding", "ring", "Lieutenant Commander Steve McGarrett", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "bunker", "never", "Reverse - Flash", "All Hallows'Day", "A's", "EOC", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America", "to comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "steam turbine", "Splodgenessabounds"], "metric_results": {"EM": 0.21875, "QA-F1": 0.32212301587301584}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "discontinued the manned Block I program", "Gryphon", "16 April 1898", "june", "a son of Amram and Jochebed", "new york city", "tetanus", "bounding the time or space used by the algorithm", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine", "bunker", "fleet street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "Azerbaijan", "new converts", "CeCe Drake", "cricket", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Michael E. Mann", "rotating discs", "Jonathon Dutton"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8607772435897436}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1277", "before_prediction": "1898", "after_prediction": "16 April 1898"}, {"id": "mrqa_squad-validation-1688", "before_prediction": "bounding", "after_prediction": "bounding the time or space used by the algorithm"}, {"id": "mrqa_squad-validation-8700", "before_prediction": "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "after_prediction": "Michael E. Mann"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Jonathon Dutton"}], "retained_ids": ["mrqa_squad-validation-3389", "mrqa_squad-validation-3126", "mrqa_triviaqa-validation-5168"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_squad-validation-3971", "mrqa_triviaqa-validation-5231"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.4285714279591837}, {"timecode": 5, "before_eval": {"predictions": ["otranto", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "a soft wool fabric", "Paspahegh Indians", "a branch of the anterior internodal tract that resides on the inner wall of the left atrium", "South Dakota", "7 : 25 a.m. HST", "swanee or swannee whistle", "a genetically engineered plant", "used stone tools", "1962", "Parietal cells ( also known as oxyntic or delomorphous cells )", "are mammals that lay eggs ( Prototheria ) instead of giving birth to live young", "Ready to Die", "casket letters", "imperial rule", "1840", "make a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "tax man", "A study by the World Institute for Development Economics Research at United Nations University", "entropy increases", "His mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "a way of housing a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11053921568627452}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "heart", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "hunt", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "mammals that lay eggs ( Prototheria ) instead of giving birth to live young", "September 13, 1994", "president garfield", "imperial rule", "1787", "defiant speech", "Mark Twain", "sunny afternoon", "on the basis of the methodology used", "nonconservative forces", "death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9548611111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-1718"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1550", "mrqa_squad-validation-7554"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.999999995}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "to prevent the flame from being blown out", "Barack Hussein Obama II", "2010", "n Carolina", "Bermuda", "90-60's", "unaided independent school", "sue barker", "times sign", "BAFTA Television Award", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late - September through early January", "Kansas Historical Society", "monatomic", "for its popular beaches", "buddha", "invertebrates", "greenish-green", "common type", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "clangers", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "near Grande Comore, Comoros Islands", "attributive and non-attributive noun, and with either a marked ( `` - s '' ) or unmarked plural", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.125, "QA-F1": 0.18958333333333333}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film directors", "capillary action", "2008", "2010", "north carolina", "minorca", "70", "independent schools", "boston braves", "the symbol \u00d7", "Best Supporting Actress", "Juice Newton", "Super Bowl LII,", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late summer", "wichita", "simplest", "for its popular beaches", "japan", "true", "red admiral", "o", "The anterior interventricular branch of left coronary artery, ( also left anterior descending artery ( LAD ), or anterior descending branch )", "10", "north-western counties of Cumberland, Westmorland and Lancashire (Furness district )", "the leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9245535714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-226", "before_prediction": "late - September through early January", "after_prediction": "late summer"}, {"id": "mrqa_naturalquestions-validation-5582", "before_prediction": "left coronary artery", "after_prediction": "The anterior interventricular branch of left coronary artery, ( also left anterior descending artery ( LAD ), or anterior descending branch )"}], "retained_ids": ["mrqa_naturalquestions-validation-1679", "mrqa_squad-validation-2584"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "unfixed_ids": ["mrqa_triviaqa-validation-4966"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.49999999875}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules", "The U.S. Army Chaplain insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who want more services and more control over the central city", "boston Becks", "Armenia", "the last book accepted into the Christian biblical canon", "Beyonc\u00e9", "percent", "for gallantry", "16 million", "1950s", "work oxen for haulage", "1998", "a priest", "23.1", "18 - season career", "family member", "long-term environmental changes", "William Powell Lear", "the unbalanced centripetal force", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "casket letters", "present-day Charleston", "\"quiescent\"", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Panzer"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28441147292250235}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.23529411764705882, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_hotpotqa-validation-2902"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "Only a few", "the right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "lost weekend", "near the Black Sea", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george vi", "the most popular show at the time", "post\u2013World War II", "cattle are slaughtered for meat before the age of three years, except where they are needed ( castrated ) as work oxen for haulage", "2011", "a priest", "most abundant", "2001", "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting", "long-term environmental changes", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george i", "the Charleston Orange district", "a \"quiescent\" stance", "Andy Cohen", "a German general (colonel-general from 1940 )"], "metric_results": {"EM": 0.875, "QA-F1": 0.909080615942029}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1863", "before_prediction": "family member", "after_prediction": "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting"}, {"id": "mrqa_squad-validation-9598", "before_prediction": "\"quiescent\"", "after_prediction": "a \"quiescent\" stance"}, {"id": "mrqa_hotpotqa-validation-3146", "before_prediction": "Panzer", "after_prediction": "a German general (colonel-general from 1940 )"}], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-4318"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_hotpotqa-validation-2902"], "unfixed_ids": ["mrqa_naturalquestions-validation-98"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.49999999916666665}, {"timecode": 8, "before_eval": {"predictions": ["computability theory", "georgeppe Antonio 'Nino'Farina", "a score of 46.8 ( 50 is the highest possible score )", "about 5 nanometers across", "the eighth and eleventh episodes of the season", "Carl Michael Edwards II", "over 400 games", "adrenal glands", "Latin liberalia studia", "the Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "Eureka", "1918", "2018", "a professional association football club based in the city Sheffield, South Yorkshire, England", "law firm", "Pottawatomie County", "orangutan", "Albert Einstein", "The church tower", "a \u2018right pukka\u2019 service on the District line", "Toronto, Ontario, Canada", "foreign", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "the Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "one of the largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychological and psychotherapeutic theories and associated techniques", "Quentin Coldwater", "acidic bogs"], "metric_results": {"EM": 0.125, "QA-F1": 0.23736810064935066}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.375, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.3636363636363636, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "after_eval": {"predictions": ["computational complexity theory", "formula 1", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidneys", "artes liberales", "\"Switzerland of England\"", "Edward IV of England", "St. Louis County", "1828", "2018", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "theory of general relativity (GR)", "the Scots who finally breached the Town Wall and forced surrender", "walford", "Montreal", "slow", "110 miles", "Kona coast", "liberal conservative", "gold rushes", "six", "no contest", "freudian psychoanalysis", "New York", "acidic"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9042572463768116}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1705", "before_prediction": "computability theory", "after_prediction": "computational complexity theory"}, {"id": "mrqa_hotpotqa-validation-4212", "before_prediction": "Eureka", "after_prediction": "St. Louis County"}, {"id": "mrqa_squad-validation-5313", "before_prediction": "The church tower", "after_prediction": "the Scots who finally breached the Town Wall and forced surrender"}], "retained_ids": ["mrqa_naturalquestions-validation-6991"], "fixed_ids": ["mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "unfixed_ids": ["mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7767"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.249999999375}, {"timecode": 9, "before_eval": {"predictions": ["first developed and popularized by the Israeli company Mirabilis in 1996", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "ricotta", "the efficiency of photosynthesis", "images of different animals and humans perform various actions", "gilded maze of a place that is rumored to be haunted by a dead maid", "\"The Krypto Report\" a podcast produced by the white supremacist site \"The Daily Stormer\"", "spin triplet", "flour", "president", "the citizens", "1530", "Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co.", "to pursue an acting career", "C. W. Grafton", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "IPod Classic", "\" My Sassy Girl\"", "the elimination of the waste products of metabolism and to drain the body of used up and broken down components in a liquid and gaseous state", "The Edge of Night", "non-combustible substances that corrode, such as iron", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "the root respiration", "soil", "death", "medium and heavy-duty diesel trucks", "testes"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3963664535237116}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.8888888888888888, 0.0, 0.33333333333333337, 0.0, 0.13333333333333333, 0.4, 1.0, 0.0, 0.0, 0.8571428571428571, 0.923076923076923, 0.6666666666666666, 1.0, 0.918918918918919, 1.0, 0.0, 0.3333333333333333, 0.1290322580645161, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-2582", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentinian", "a report", "cake", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "animals and humans performimg various actions", "White House", "The Daily Stormer", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "almost all officeholders annually", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "Worcester Cold Storage and Warehouse Co. fire", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP", "all land - living organisms, both alive and dead, as well as carbon stored in soils", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9419106606606606}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4520", "before_prediction": "the citizens", "after_prediction": "almost all officeholders annually"}, {"id": "mrqa_naturalquestions-validation-8474", "before_prediction": "soil", "after_prediction": "all land - living organisms, both alive and dead, as well as carbon stored in soils"}], "retained_ids": ["mrqa_hotpotqa-validation-832", "mrqa_hotpotqa-validation-133", "mrqa_naturalquestions-validation-1327", "mrqa_squad-validation-5940", "mrqa_hotpotqa-validation-5823"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-2582", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_naturalquestions-validation-754"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.7142857132653061}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744) (DNB00)", "yellow fever", "three legal systems", "Las Vegas", "status code", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "a Dubliner tried to kill Benito Mussolini", "casket letters", "menhirs", "a strict and elaborate set of rules designed by Victoria, Duchess of Kent, along with her attendant, Sir John Conroy, concerning the upbringing of the Duchess's daughter, the future Queen Victoria", "acid", "Kon-Tiki", "the MGM Grand Garden Special Events Center", "digital fashion gallery", "Ronnie Hillman", "all-encompassing definition of the term", "1987", "more than 60", "Eagle Ridge Mall", "Geoffrey Hurst and Martin Peters just one season before all three went on to star in England's World Cup winning side of 1966", "Rationing Stamps and Cards to reduce pressure on the public food supply", "Monastir", "the classical element fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present )", "Ward", "an American novelist and poet", "The Jamestown settlement in the Colony of Virginia", "Monet", "carbon related emissions"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3451028138528139}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true], "QA-F1": [0.4, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.9333333333333333, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.18181818181818182, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803"], "after_eval": {"predictions": ["alexander", "Hampton's hump and Hampton's line", "English law", "Las Vegas", "A status line", "globetrotters", "cruiserweight", "over the Merderet in the fictional town of Ramelle", "mussolini", "victor hugo", "monolith", "British Royal Family", "greater than 14", "Thor Heyerdahl", "Grand Garden Special Events Center", "valentino", "C. J. Anderson", "a maze of semantical problems and grammatical niceties", "joseph smith", "60 %", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "tunisia", "the classical element fire", "Barney Fife", "Typically, no", "Ann", "writer", "Virginia", "monet", "biomass and subsequent carbon related emissions"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9427083333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4791", "before_prediction": "menhirs", "after_prediction": "monolith"}, {"id": "mrqa_squad-validation-4506", "before_prediction": "carbon related emissions", "after_prediction": "biomass and subsequent carbon related emissions"}], "retained_ids": ["mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-2016", "mrqa_squad-validation-3525", "mrqa_triviaqa-validation-6639"], "fixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803"], "unfixed_ids": ["mrqa_hotpotqa-validation-4162"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.6666666655555555}, {"timecode": 11, "before_eval": {"predictions": ["vincent Thomas \"Vince\" Lombardi", "Arthur Schnitzler's 1926 novella \"Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "The TEU", "thermodynamic temperature", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "joseph smith", "The world's longest suspension bridges are listed according to the length of their main span", "Luas", "cricket", "king Crimson", "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "died in battle", "car", "joseph smith", "continental integration", "jubilee", "infection, irritation, or allergies", "the tower is the most - visited paid monument in the world", "Vittorio Emanuele II", "catfish", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "John Michael Higgins as John Smith, an a cappella commentator making an insulting documentary about The Bellas", "Iraq", "a co-op of grape growers", "mann", "Verdi", "1952", "the Charlotte Hornets", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "body hair transplantation ( BHT ) on appropriate candidates who have available donor hair on the chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.125, "QA-F1": 0.26059792988341585}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.5454545454545454, 0.8571428571428571, 0.5, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.08695652173913043, 0.22222222222222224, 0.09523809523809523]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_hotpotqa-validation-2852", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "eat porridge", "span", "dublin", "duke of edinburgh", "panegyric", "the Byzantine Empire and then Armenia, fighting against the Pechenegs, the Bulgars, and especially the Seljuk Turks", "alamo", "ferdinand porsche", "arkansas", "Canada", "britten", "irritation", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "heaviest of the stable halogens", "the Bellas", "kuwaitis", "An agricultural cooperative", "norway", "nabucodonosor", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean Fernel", "torso"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9259868421052632}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.631578947368421, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5248", "before_prediction": "king Crimson", "after_prediction": "panegyric"}, {"id": "mrqa_squad-validation-1003", "before_prediction": "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "after_prediction": "the Byzantine Empire and then Armenia, fighting against the Pechenegs, the Bulgars, and especially the Seljuk Turks"}, {"id": "mrqa_triviaqa-validation-5526", "before_prediction": "Verdi", "after_prediction": "nabucodonosor"}], "retained_ids": ["mrqa_hotpotqa-validation-4274"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_hotpotqa-validation-2852", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.249999999375}, {"timecode": 12, "before_eval": {"predictions": ["British rock group Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "counter-parry", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade", "Aegean", "29 June 1941", "cienfuegos in the Las Villas province of Cuba", "norway", "New South Wales", "Fort Bull", "Dandy", "bragnano", "the English narrator, possibly Orwell himself", "Czech Kingdom", "Gregg Popovich", "not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "adaptive immune system", "Mexican drug lord", "a band of nuclear holocaust survivors as they flee Texas to the relative safety of California", "nodel", "December 1, 1969", "american", "author John Buchan", "California State Automobile Association", "\"alone\"", "Cinderella", "delayed the sealing of the hatch", "a fear of seeming rude"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26663461987950476}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.15384615384615385, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.2424242424242424, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "sport fencing", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cuban cigars", "byker grove", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \"regnum Bohemia\"", "Bob Hill", "secularism and secular nationalism", "creative reasons", "immunological memory", "uncle", "Originally a musician", "thumbelina", "1973", "maryland", "john buchan", "regional tourism groups", "\"alone\"", "Cinderella", "delayed the sealing of the hatch", "lack of understanding"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9783653846153846}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4904", "before_prediction": "Czech Kingdom", "after_prediction": "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \"regnum Bohemia\""}], "retained_ids": ["mrqa_hotpotqa-validation-4826", "mrqa_squad-validation-2372", "mrqa_hotpotqa-validation-4165", "mrqa_squad-validation-3935"], "fixed_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-6924"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7999999984}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Buddy Pine / Incredi - Boy / Syndrome", "Napoleon's army", "st. Louis baker", "3.7% of the entire student population", "high and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Garthy & Travis", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni", "discipline problems with the Flight Director's orders during their flight", "maryland", "paddington Audiobook", "amyotrophic lateral sclerosis (ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "October 17, 1938", "Torah or Bible", "the western coast of Italy", "first and only U.S. born world grand prix champion", "brass band parades", "mid November", "Facebook", "krak\u00f3w", "Rock Star ( 2001 film)", "Seattle, WA", "King George's War", "cheated on Miley", "alternative rock", "Fort Snelling, Minnesota", "daguerreotypes", "a Mediterranean climate, with infrequent rain and many sunny days. Summers are hot and dry, while winters are a bit warm or mild and wet. Serious rain can occur unusually"], "metric_results": {"EM": 0.125, "QA-F1": 0.24099138708513712}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.2222222222222222, 0.0, 0.0, 0.4444444444444445, 0.3636363636363636, 0.0, 0.0, 0.0, 0.125, 0.0, 1.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.3333333333333333, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "pre sliced bread", "3.7", "negative effect", "garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "nine", "michael hordern", "Lou Gehrig's Disease", "\"Odorama\"", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "the quintessential New Orleans art form -- a jazz funeral without a body", "late November or early December", "Facebook", "bread", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Issaquah", "King George's War", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "fox talbot", "infrequent rain"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9381009615384616}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2037", "mrqa_triviaqa-validation-2779", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7310"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-9897", "mrqa_hotpotqa-validation-5716"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.9999999975}, {"timecode": 14, "before_eval": {"predictions": ["Beauty and the Breast", "M\u0101noa in Honolulu CDP", "American sympathizer in the American Revolutionary War", "norway", "FX option or currency option", "electromagnetic waves", "Wahhabi/ Salafi", "higher self", "Dimensions in Time", "Surveyor 3 unmanned lunar probe", "January 1981", "luteinizing hormone ( LH ) and follicle - stimulating hormone ( FSH )", "the structure and substance of his questions and answers concerning baptism in the Small Catechism", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "England's first \u00a31 million player", "slowing the vehicle", "Cheyenne rivers", "fossilization", "Hanna-barbera", "the Veneto region of Northern Italy", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "george stryjewski a.k.a. whtmnk", "geoscience Australia", "Timo Hildebrand", "The public sector ( also called the state sector )", "17 F. Kennedy International Airport, New York City", "weak government institutions", "a god of the Ammonites, as well as Tyrian Melqart and others", "sclera", "Uncle Fester, also known as Fester Addams", "the homicidal sniper Bobby Thompson in the Peter Bogdanovich cult film \"Targets\" ( 1968)"], "metric_results": {"EM": 0.125, "QA-F1": 0.24496483908248612}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.0, 0.5882352941176471, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.14285714285714288]}}, "error_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/Salafi jihadist extremist militant", "svastika", "Children in Need", "Apollo 12", "1981", "estrogen", "baptism", "Martin Luther", "brian clough", "releasing the compressed air trapped in the cylinders, and slowing the vehicle", "belle fourche and cheyenne", "organisms", "Hanna-barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Kur\u00e1nyi", "the state sector", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9644886363636364}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-727", "before_prediction": "slowing the vehicle", "after_prediction": "releasing the compressed air trapped in the cylinders, and slowing the vehicle"}, {"id": "mrqa_naturalquestions-validation-6019", "before_prediction": "The public sector ( also called the state sector )", "after_prediction": "the state sector"}], "retained_ids": ["mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920"], "fixed_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.49999999875}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "Wichita and the state of Kansas", "Eminem ( Evil) and Taio Cruz", "Galileo Galilei", "a friend and publicist", "michael ondaatje", "masons'marks", "March 12, 1948", "Gateshead", "inspired by Motown, Philly soul, and Earth, Wind & Fire ( particularly `` That's the Way of the World '' )", "The head contains the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "1898", "professional wrestler, mixed martial artist and a former amateur wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "casket letters", "a Curtiss JN-4 airplane", "antwerp", "chimpanzees", "March 15, 1945", "absolute temperature", "whistlebl-blowing", "Julius Robert Oppenheimer", "bicuspid", "Aegisthus", "3 December", "tallahassee", "prefabricated housing projects", "brian pynson", "WOTV"], "metric_results": {"EM": 0.1875, "QA-F1": 0.23234577922077923}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Royce da 5'9\" (Bad) and Eminem (Evil)", "geocentric", "editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "a roof extension", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "after the Spanish -- American War in the 1898 Treaty of Paris", "martial artist", "Spanish", "stunt performances", "fred astaire", "postage stamp", "belgium", "chimpanzee", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolars", "Aegisthus", "25 November 2015", "florida", "an Eastern Bloc city", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.875, "QA-F1": 0.88125}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7512", "before_prediction": "Galileo Galilei", "after_prediction": "geocentric"}, {"id": "mrqa_naturalquestions-validation-3808", "before_prediction": "1898", "after_prediction": "after the Spanish -- American War in the 1898 Treaty of Paris"}, {"id": "mrqa_hotpotqa-validation-5188", "before_prediction": "chimpanzees", "after_prediction": "chimpanzee"}, {"id": "mrqa_hotpotqa-validation-413", "before_prediction": "3 December", "after_prediction": "25 November 2015"}], "retained_ids": ["mrqa_hotpotqa-validation-3456", "mrqa_naturalquestions-validation-9451"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.33333333277777777}, {"timecode": 16, "before_eval": {"predictions": ["Georges", "bruder Basil", "brian", "the back of the head of the tibia, below the level of the knee joint", "ferguside", "the North Sea, through the former Meuse estuary, near Rotterdam", "Namibia", "faldo", "October 29, 1985", "Amway", "Mauritius", "Thomas Sowell", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "The Show Band Show", "Tanzanian Legal System", "Chad", "GMAT Sentence Correction (SC)", "an open work crown", "Crowley brought back Samuel so that they could help him find Purgatory, the afterlife of monsters", "London", "French", "the Guardian - TV News", "U.S. Marshals", "What's Up (TV series)", "supply chain", "a rock outcrop called Link", "Stanislaw August Poniatowski", "polynomial algebra", "george", "three wise monkeys", "sheepskin and Merino Wool", "Honolulu"], "metric_results": {"EM": 0.03125, "QA-F1": 0.10172483766233766}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "after_eval": {"predictions": ["nightclub", "belgium", "blessed", "leg", "dunkeld dynasty", "North Sea", "botswana", "Nick Faldo", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio's \"The Show Band Show\"", "tanzania", "niger", "tip of florida", "top row of windows", "Sam's soul is not with him", "Fulham, Greater London, England", "French, English and Spanish", "dave lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "flowing water", "polish state", "matrices", "george davis", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru", "Sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9212110805860806}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307692, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8095238095238095, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4164", "before_prediction": "London", "after_prediction": "Fulham, Greater London, England"}], "retained_ids": [], "fixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "unfixed_ids": ["mrqa_triviaqa-validation-4681", "mrqa_naturalquestions-validation-7144", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.8709677419354839, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["pasteurised cows\u2019 milk soft cheese", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "isotopes", "James Zeebo", "sovereign states", "president of the United States Senate", "the pseudoscientific principle of intelligent design (ID)", "Sam", "Australian", "18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women", "opportunities will vary by geographic area and subject taught", "health and social problems (ob obesity, mental illness, homicides, teenage births, incarceration, child conflict, drug use)", "a private liberal arts college", "Roy Spencer", "\"antiforms\"", "June 9, 2015", "S Pictures' \"Veyyil\" (2006)", "Grace Nail Johnson", "Keith Richards", "at least one prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "knowledgeable in that one area", "180th meridian", "Cartoon Network", "Presiding Officer", "Miami Heat of the National Basketball Association", "33", "phylloxera vitifolia", "Area Provost/Dean (if one is appointed)", "England Hockey", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.1875, "QA-F1": 0.27528057275541795}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 0.0, 0.0, 0.0, 0.4736842105263158, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.3333333333333333, 0.0, 0.23529411764705882, 0.25, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845", "rubidium - 85", "James Zeebo", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "Dick Cheney", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Velichko Todorov Tsochev) is a Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower rates", "575 acres (2.08 km\u00b2)", "Roy Warren Spencer", "\"antiforms\"", "the second half of the third season", "Veyyil", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "any natural number n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Adult Swim", "the Presiding Officer on the advice of the parliamentary bureau", "the Phoenix Suns", "33-member", "grapevine leaves", "Annual Conference Cabinet", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9325419896640827}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.9302325581395349, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1895", "before_prediction": "Roy Spencer", "after_prediction": "Roy Warren Spencer"}, {"id": "mrqa_hotpotqa-validation-3573", "before_prediction": "Cartoon Network", "after_prediction": "Adult Swim"}, {"id": "mrqa_squad-validation-9405", "before_prediction": "Presiding Officer", "after_prediction": "the Presiding Officer on the advice of the parliamentary bureau"}], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_naturalquestions-validation-430", "mrqa_squad-validation-5110"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-3071"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.49999999916666665}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "harmoniously", "400 metres relay", "Vili Fualaau and Mary Kay Letourneau, a student and teacher who made news for their sexual relationship", "entertainment division", "distance covered by a vehicle ( for example as recorded by an odometer ), person, animal, or object along a curved path from a point A to a point B", "five", "Great Exhibition of 1851", "Edward Longshanks and the Hammer of the Scots", "united Kingdom and United States", "belgium", "the person compelled to pay for reformist programs", "casket letters", "\"Grindhouse\" fake trailer", "belgium", "digital transmission modes", "Swiss- Austrian border", "Tesla Gigafactory 1", "821", "Sky channels", "pressure difference", "Kim Hyun-ah", "the races of highest'social efficiency'", "transposition", "the \" King of Cool\"", "President Wilson and the American delegation", "belgium", "the fifth season", "casket letters", "Hockey Club Davos", "Michael Patrick Smith", "lightning strike"], "metric_results": {"EM": 0.21875, "QA-F1": 0.32758387445887444}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.2, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666665, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_squad-validation-5257", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "create a climate of learning", "500 metres", "Piper", "ABC News", "displacement", "five times", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "diego garcia", "dundee", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "fotheringhay", "Spy Kids", "venus Williams", "Olivia", "Baden-W\u00fcrttemberg", "lithium-ion battery", "821", "basic channels", "pressure", "Hyuna", "highest'social efficiency'", "transposed", "Dino Paul Crocetti", "American delegation from the Paris Peace Conference", "Socrates", "thirteenth", "violet", "HC Davos", "Michael Crawford", "Qutab Ud - Din - Aibak, founder of the Delhi Sultanate"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8510416666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1914", "before_prediction": "harmoniously", "after_prediction": "create a climate of learning"}, {"id": "mrqa_naturalquestions-validation-3300", "before_prediction": "five", "after_prediction": "five times"}, {"id": "mrqa_naturalquestions-validation-5215", "before_prediction": "the person compelled to pay for reformist programs", "after_prediction": "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help"}, {"id": "mrqa_hotpotqa-validation-4068", "before_prediction": "the \" King of Cool\"", "after_prediction": "Dino Paul Crocetti"}, {"id": "mrqa_hotpotqa-validation-511", "before_prediction": "Michael Patrick Smith", "after_prediction": "Michael Crawford"}], "retained_ids": ["mrqa_hotpotqa-validation-2993", "mrqa_hotpotqa-validation-44"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_squad-validation-5257", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446"], "unfixed_ids": ["mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-10490"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.2857142853061225}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "director Norman Macdonnell and writer John Meston", "aragonese culture", "percent of pupils", "trans-Pacific flight from the United States to Australia", "Sharman Joshi", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "prime factor of q. Wilson's theorem says that an integer p > 1 is prime if and only if the factorial (p \u2212 1)! + 1 is divisible by p.", "Ana", "White Castle in New Brunswick", "In `` A.A.R.M. ''", "f. O. Matthiessen", "fred cheung", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "black America", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "In 1889, following the Local Government Act 1888", "Nicki Minaj", "fredic", "French Huguenot ancestry", "f1", "friedrich Engels", "\"Drawn Together\"", "William the Conqueror", "northern Israel (Haifa and the Galilee) and the Golan Heights", "two degrees of freedom", "the Corinthian and Saronic Gulfs", "blood samples", "Leo Richard Howard", "Southern Progress Corporation"], "metric_results": {"EM": 0.125, "QA-F1": 0.21946687267410953}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.4444444444444445, 0.0, 0.10526315789473684, 1.0, 0.36363636363636365, 1.0, 0.25, 0.0, 0.0, 0.0, 0.08333333333333334, 0.0, 1.0, 0.18181818181818182, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q.", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "Nile Rodgers", "Indian", "fear", "1889", "Sir Mix - a-Lot", "pirates of penzance", "surnames", "portier", "karl marx", "Teen Titans Go!", "Norman invaders", "Tel Aviv", "two", "peninsula", "taking blood", "youngest TV director ever", "Southern Progress Corporation"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-5538", "mrqa_hotpotqa-validation-5710", "mrqa_hotpotqa-validation-3049", "mrqa_hotpotqa-validation-2627"], "fixed_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "unfixed_ids": ["mrqa_triviaqa-validation-1995"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.9999999975}, {"timecode": 20, "before_eval": {"predictions": ["gas turbines", "Michael Koman", "drawings", "boston terrell Smith", "Sir David Brewster", "British Columbia", "Apollo", "ribosomal RNA", "kookaburra", "six", "CCH Pounder as Loretta Wade, medical examiner   Shalita Grant as Sonja Percy, ATF Agent / NCIS Special Agent ( seasons 2 -- 4 ; recurring previously )", "I Swear", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) )", "brian maryland", "a lunar flyby trajectory", "Lucius Cornelius Sulla Felix ( ; c. 138 BC \u2013 78 BC) known commonly as Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "preached eight sermons", "karyland", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "\"My Love from the Star\" (2013)", "San Jose", "sea wasp", "currently Ron Kouchi", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "The Super Bowl 50 Host Committee has vowed to be \"the most giving Super Bowl ever\" and will dedicate 25 percent of all money it raises for philanthropic causes in the Bay Area.", "29.7%", "b. j. Hunnicutt"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2692625661375661}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.14814814814814814, 0.0, 0.0, 1.0, 0.0, 0.16666666666666669, 0.0, 0.8, 0.0, 0.0, 0.13333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.2857142857142857, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["reciprocating", "Robert Smigel, Michael Koman and David Feldman", "(prints, drawings, paintings and photographs)", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Mercury", "Ribosomes", "kookaburra", "six-time", "Rob Kerkovich", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "gerry adams", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "Kenya's various ethnic groups typically speak their mother tongues within their own communities", "personal presence and living word", "turkey", "CMYKOG process", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "lower chamber", "a \"teleforce\" weapon", "Native American", "giving", "29.7%", "4077th"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9583333333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3368", "before_prediction": "gas turbines", "after_prediction": "reciprocating"}], "retained_ids": ["mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-1521", "mrqa_squad-validation-7272"], "fixed_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393"], "unfixed_ids": ["mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "dust jacket", "various registries", "dog", "Yazoo", "1894", "black hole", "\"the soul does not sleep (anima non sic dormit) but wakes (sed vigilat) and experiences visions\"", "as defence of their North American colonies would no longer be an issue and also because they already had ample places from which to obtain sugar", "Kris Kristofferson", "ill. (some col.)", "public and private", "a French pirate active in the Caribbean and off the coast of Africa", "Lewis", "Charles Dickens", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "exceeds any given number", "Geoffrey Cox", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "Tallemaja \"pine tree Mary\"", "tribes in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British)", "Orthodox Christians", "first edition", "a 4 in ( 10 cm ) LCD multi-touch Retina display and a screen resolution of 640 \u00d7 1136 at 326 ppi", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "quarterback", "Steve and Rudy"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28816106762604443}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3111111111111111, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.0, 0.6153846153846153, 0.0, 0.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.25, 0.5454545454545454]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "transfused", "alison moyet", "1926", "stars are the remnants of very massive stars with gravity", "dreams", "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auction", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "Organizations could come together to address global issues", "proteins", "2001", "it must be infinitely many primes", "alastair burnet", "padlocking the gates", "1960s", "R\u00e5", "tribes in western portions of the Great Lakes region", "Protestant", "casino royale", "4 in", "oh so Sharp", "ctenophore Mnemiopsis leidyi was accidentally introduced", "Menace II Society", "a member of the Green Bay Packers, serving as a backup quarterback to Brett Favre and holder on placekicks", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.875, "QA-F1": 0.9017857142857143}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-192", "before_prediction": "black hole", "after_prediction": "stars are the remnants of very massive stars with gravity"}, {"id": "mrqa_squad-validation-9020", "before_prediction": "exceeds any given number", "after_prediction": "it must be infinitely many primes"}, {"id": "mrqa_naturalquestions-validation-8689", "before_prediction": "1969", "after_prediction": "1960s"}], "retained_ids": ["mrqa_squad-validation-3627", "mrqa_naturalquestions-validation-5897", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_squad-validation-4648"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.49999999916666665}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "MSC Crociere S. p.A.", "pay through the nose", "his friends, Humpty Dumpty and Kitty Softpaws", "the environmentalist Australian Greens", "the supporters of King Charles II and supporters of the Rump Parliament", "cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "on their foreheads as a visible cross", "assassination to spies", "alibris", "Augustus Waters", "1619", "Tony Blair: The Journey", "\u2018 Often damaging\u2019, along with alcohol, tobacco and gambling", "June 11, 1973", "Kenya", "a chronological collection of critical quotations about William Shakespeare and his works", "aethelbert", "neutrality", "Cargill", "AMC Entertainment Holdings, Inc.", "\"The Gang\"", "3 October 1990", "March 1, 2018", "heavy", "daedalus", "son", "Development of Substitute Materials", "novels on political, social, and gender issues, and other topical matters", "vast areas"], "metric_results": {"EM": 0.09375, "QA-F1": 0.21935945532692658}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 0.4444444444444445, 0.0, 0.13333333333333333, 0.11764705882352942, 0.08695652173913045, 0.0, 0.0, 0.3636363636363636, 1.0, 0.8, 0.1818181818181818, 0.0, 0.0, 0.625, 0.0, 0.33333333333333337, 0.0, 0.3333333333333333, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_hotpotqa-validation-2448"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Humpty Dumpty", "Nationals", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\") over, principally, the manner of England's government", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "smersh", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "14 September 1547", "tony blair", "often damaging", "July 26, 1959", "national parks", "chronological collection of critical quotations", "edward i", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "pig", "Dexter", "Manhattan District ; `` Manhattan '' gradually superseded the official codename, Development of Substitute Materials, for the entire project", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.875, "QA-F1": 0.9240451388888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3944", "before_prediction": "1619", "after_prediction": "14 September 1547"}, {"id": "mrqa_naturalquestions-validation-1328", "before_prediction": "Development of Substitute Materials", "after_prediction": "Manhattan District ; `` Manhattan '' gradually superseded the official codename, Development of Substitute Materials, for the entire project"}], "retained_ids": ["mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_hotpotqa-validation-2448"], "unfixed_ids": ["mrqa_hotpotqa-validation-2959", "mrqa_triviaqa-validation-6872"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.3333333322222222}, {"timecode": 23, "before_eval": {"predictions": ["an additional $105 billion in growth to the country's economy over five years", "mono", "about two-thirds", "1937 Austin Seven Ruby Open Top Tourer", "sandy luna", "paintwork where it becomes seriously corroded", "Steeplechase Park", "Best Animated Feature", "European Union institutions", "American astronaut who formerly held the American record for the most time in space (381.6 days)", "nine", "CAL IPSO satellite", "ringworm", "James `` Scotty '' Reston", "Ronald Ralph \"Ronnie\" Schell", "artemisinin", "Tata Consultancy Services", "Leinster", "1938", "2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "midlands of the river Niger Benue trough to over 2,000 mm ( 78.7 in ) along the south western escarpment of the Jos Plateau", "benanga", "Incudomalleolar joint", "bobby riggs", "Democritus", "Santa Clara Marriott", "beethoven", "political power generated by wealth", "polynomial-time reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.21875, "QA-F1": 0.31549290986790984}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true], "QA-F1": [0.3076923076923077, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.6666666666666666, 0.25, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.08, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-1750"], "after_eval": {"predictions": ["$105 billion", "kissing disease", "about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm)", "a 1934 Austin seven box saloon", "dirty dancing", "red", "Steeplechase Park", "Academy Award for Best Animated Feature", "the European Convention on Human Rights in 1950 and the establishment of the European Court of Human Rights", "381.6 days", "nine", "NASA", "yellow", "Khrushchev", "Jack Cassidy", "malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "till September when the monsoons gradually begin retreating southward to the southern part of Nigeria", "live and let die", "Incudomalleolar joint ( more correctly called incudomallear joint )", "moffitt", "Leucippus", "Santa Clara Marriott", "beethoven", "the use of political power generated by wealth by certain groups to shape government policies", "the bound on the complexity of reductions", "Corey Brown"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8898017101577473}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.2857142857142857, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 0.5263157894736842, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7481", "before_prediction": "political power generated by wealth", "after_prediction": "the use of political power generated by wealth by certain groups to shape government policies"}, {"id": "mrqa_squad-validation-769", "before_prediction": "Ted Ginn Jr.", "after_prediction": "Corey Brown"}], "retained_ids": ["mrqa_hotpotqa-validation-4348", "mrqa_squad-validation-542", "mrqa_squad-validation-2420", "mrqa_squad-validation-327", "mrqa_triviaqa-validation-6781"], "fixed_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-3716", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-4048", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_triviaqa-validation-571", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-1750"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-1731"], "instant_fixing_rate": 0.84, "instant_retention_rate": 0.7142857132653061}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "often they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt's plan called for three major offensive actions involving large numbers of regular troops, supported by the provincial militias, aimed at capturing the heartlands of New France", "the elixir of perpetual youth", "WBC and lineal titles", "Moluccas", "the first Saturday in May", "Albany ( in the Quarto version )", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "1990", "J.R. R. Tolkien", "John Elway", "Instagram's own account", "learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry for about two years", "Bingo", "Eugene", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "prime numbers that are of the form 2p \u2212 1, where p is an arbitrary prime", "letter series", "Fa Ze YouTubers", "the nine circles of Hell", "the governor of the Khwarezmian city of Otrar", "from Nova Scotia and Newfoundland in the north, to Georgia in the south", "the Friars Minor Conventual (O.F.M. Conv)", "CD Castell\u00f3n", "1946 -- 48", "12\u20134", "having colloblasts, which are sticky and adhere to prey", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "Mission Specialist for mission STS-51-L.", "it will retreat to its den and winter will persist for six more weeks", "prime minister of France and the fifth prime minister appointed by President Fran\u00e7ois  Mitterr and, Edith Cresson"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22717216582245237}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0, 0.4, 0.4, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.09523809523809523, 0.0, 0.0, 0.5, 0.4210526315789473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.0, 0.33333333333333337, 0.5957446808510638, 0.11764705882352941]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-4417", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+", "Duke of Cumberland", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Kent", "Arab oil producers linked any future policy changes to peace between the belligerents", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "31", "He is from Pago Pago, American Samoa and played college football at Oregon.", "comparable to the seven Wonders of the World", "2p + 1", "coupe", "FaZe Rug", "dante", "Muslim", "along the coast, the settlements were growing into the interior", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9552956674473068}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3741", "before_prediction": "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "after_prediction": "Arab oil producers linked any future policy changes to peace between the belligerents"}], "retained_ids": ["mrqa_squad-validation-384", "mrqa_squad-validation-67"], "fixed_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-5399", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-4417", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 25, "before_eval": {"predictions": ["synchronized skating", "slave", "over 50 million singles", "states'rights to expand slavery", "1923 and 1925", "the Orlando\u2013Kissimmee\u2013 Sanford, Florida Metropolitan Statistical Area", "January 19, 1962", "Frigate", "france", "d'Hondt method", "geese", "the move from the manufacturing sector to the service sector", "jagera", "Sylvester McCoy", "August 14, 1848", "lower rates of health and social problems", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "co-written the book of the musical \"A Chorus Line\"", "2,664", "on the inside of the chassis right beneath the volume buttons", "a chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning services, support services, property services, catering services, security services and facility management services", "Symphony No. 7 in A major, Op. 92", "dordogne", "1603", "ranked above the two personal physicians of the Emperor", "Nutcracker", "A searching and fearless moral inventory of ourselves", "Chicago Cubs"], "metric_results": {"EM": 0.15625, "QA-F1": 0.34471223221223224}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.25, 0.33333333333333337, 0.4615384615384615, 0.923076923076923, 0.2857142857142857, 1.0, 0.0, 0.2857142857142857, 0.3636363636363636, 0.4444444444444445, 0.6, 0.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastics", "abraham", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "Crimson Tide", "iteratively", "American Buff", "effect", "pacific", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "life expectancy is lower", "juveniles are capable of reproduction", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "iphone 6 Plus", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde", "1603", "status superior to all others in health-related fields such as physicians and acupuncturists", "dance", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball team"], "metric_results": {"EM": 0.875, "QA-F1": 0.8894230769230769}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6941", "before_prediction": "geese", "after_prediction": "American Buff"}, {"id": "mrqa_triviaqa-validation-6221", "before_prediction": "Nutcracker", "after_prediction": "dance"}], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-6545"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "unfixed_ids": ["mrqa_hotpotqa-validation-5762", "mrqa_naturalquestions-validation-390"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences, with the Romans serving as external arbiters on disputes concerning Jewish customs and law", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "true history of the Kelly Gang", "Haleiwa Ali'i Beach Park", "1910", "non-teaching posts", "the Catch Me Who Can", "pacific", "pacific", "4,000", "Khagan", "wuthering Heights", "pacific", "spice", "The Simpsons Spin-Off Showcase", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "an extensive neoclassical centre referred to as Tyneside Classical largely developed in the 1830s by Richard Grainger and John Dobson, and recently extensively restored", "Albany School for Educating People of Color", "the Ram Bagh", "Sergeant First Class", "Anakin Skywalker", "They must decide whether their primary goal will be to win an acquittal and avoid imprisonment or a fine, or to use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case", "Cee - Lo", "Anglican", "mammy", "king george V class battleship", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "January 11, 1755 or 1757"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25059714590964594}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.2222222222222222, 0.19999999999999998, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.08333333333333334, 0.4, 0.0, 1.0, 1.0, 0.05714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8000000000000002]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-7435", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "outlined by Joel Greenblatt", "kelly", "City and County of Honolulu", "1910\u20131940", "those who refuse vetting", "the Catch Me Who Can", "jazz", "smith court", "3,677 seated", "Khagan", "catherine and heathcliff", "birmingham", "cinnamomum", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "Shopping Centre", "Albany High School", "charbagh", "Sergeant First Class", "Anakin Skywalker", "jury nullification", "the closing scene of the final episode of the first season", "The Church of England", "hattie mcdaniel", "scharnhorst", "hypnosis", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-6148", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-7801"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-7435", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "unfixed_ids": ["mrqa_triviaqa-validation-6689", "mrqa_triviaqa-validation-6224"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.9999999980000001}, {"timecode": 27, "before_eval": {"predictions": ["aquarius", "michael geldof", "blackberry", "hor Orion", "\" Big Mamie\"", "trinidad and Tobago", "Hoffa", "a light sky-blue color caused by absorption in the red", "the peasants\u2019 Revolt", "2009", "2005\u201306 NBA", "the internal thylakoid system", "the Boating Party", "the Grand Annual Steeplechase at Warrnambool and the Australian International Airshow at Geelong", "The channel which can get carriage on a suitable beam of a satellite", "the fourth season", "the weak and electromagnetic forces", "the availability of skilled tradespeople", "diamond", "A simple iron boar crest", "the University of Northumbria at Newcastle in 1992", "curtin", "David", "25 - yard line", "the Latin centum", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "by faith", "cliff thorburn", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "company"], "metric_results": {"EM": 0.25, "QA-F1": 0.3279795725108225}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, true, false, true, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 1.0, 0.375, 0.0, 1.0, 1.0, 0.8, 1.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "\" Big Mamie\"", "tanzania", "Teamsters leader", "clear substances with a light sky-blue color", "wat tyler", "2009", "Zaza Pachulia", "inner chloroplast membrane", "Renoir", "sports", "no", "third", "electroweak interaction", "Cost of construction", "gypsum", "A simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period", "polytechnics became new universities", "australia", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard lines", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "sport", "produced with constant technology and resources per unit of time", "peter paul rubens", "badgers"], "metric_results": {"EM": 0.875, "QA-F1": 0.9134615384615384}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1226", "before_prediction": "A simple iron boar crest", "after_prediction": "A simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period"}, {"id": "mrqa_triviaqa-validation-388", "before_prediction": "cliff thorburn", "after_prediction": "sport"}], "retained_ids": ["mrqa_triviaqa-validation-348", "mrqa_hotpotqa-validation-994", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-3949", "mrqa_squad-validation-5125", "mrqa_squad-validation-8279"], "fixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_triviaqa-validation-6331", "mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.7499999990624999}, {"timecode": 28, "before_eval": {"predictions": ["the Turk", "Chris Weidman", "jury nullification", "Raghuwanshi dynasty", "poet", "Professor Eobard Thawne", "sivovitz", "US $10 a week", "1875", "member states", "clarinets", "McKinsey's offices in Silicon Valley and India", "gypsia", "Living Doll", "Crohn's disease or ulcerative colitis", "Ondemar Dias", "Raya Yarbrough", "Arizona", "michael dokes", "John D. Rockefeller", "Old Testament", "UPS", "local talent", "the Football League", "tygan jovanka", "pyroclastic", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "John Surratt", "1349", "dodo bird", "people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "Stan Butler"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2895124716553288}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0, 0.3333333333333333, 0.0, 0.4444444444444445, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 0.0, 1.0, 0.2040816326530612, 1.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_squad-validation-8190", "mrqa_naturalquestions-validation-7821"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "inform the jury and the public of the political circumstances", "Kusha", "poet, and writer", "Professor Eobard Thawne", "plum", "a US$10 a week raise", "1825", "contributed by member states on a voluntary basis", "oboe", "McKinsey's offices", "fear of public speaking", "lionel bart", "high - output fistula", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "Charles L. Hutchinson", "Song of Songs", "brown", "touring productions", "North End Football Club", "peter davison", "canada", "contemporary accounts were exaggerations", "Lincoln assassination conspirator", "1332", "dodo bird", "The belief is based on the idea that people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "Stan Butler"], "metric_results": {"EM": 0.875, "QA-F1": 0.8985795454545454}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2545454545454545, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7669", "before_prediction": "UPS", "after_prediction": "brown"}, {"id": "mrqa_squad-validation-5086", "before_prediction": "local talent", "after_prediction": "touring productions"}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-4309", "mrqa_triviaqa-validation-2953", "mrqa_triviaqa-validation-4308"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_squad-validation-8190"], "unfixed_ids": ["mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.6666666655555555}, {"timecode": 29, "before_eval": {"predictions": ["red", "886 AD", "to finance his own projects", "Le Mans", "Xbox 360", "Tokyo", "linebacker Danny Trevathan", "the parallelogram rule of vector addition", "abraham laulston", "364", "the reactor core", "Van Gogh", "the bore, and often the stroke", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "Doctor Who Theme", "National Basketball Development League (NBDL)", "gillingham", "Baltimore -- Washington metropolitan area", "Graham Gano", "2,615", "South Korea", "athlete", "a password recovery tool for Microsoft Windows", "Captain John Guidry", "Charles and Ray Eames", "Brazil", "abraham smithworth", "the smallest subfield", "heartburn", "53%", "NADPH"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3129230859010271}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.0, 0.47058823529411764, 1.0, 0.0, 0.888888888888889, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "patents", "Formula One", "microsoft", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "evolution", "five pheasants", "startup neutron source", "Van Gogh", "cylinders", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Imperial Secretariat", "Doctorin' the Tardis", "National Basketball Development League", "kent", "Washington metropolitan area", "Emmanuel Sanders", "The population was 2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods Such as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "south koreans", "arthur", "the smallest subfield", "heartburn", "53%", "grana and thylakoids"], "metric_results": {"EM": 0.875, "QA-F1": 0.8897058823529411}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.47058823529411764, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3103", "before_prediction": "364", "after_prediction": "five pheasants"}, {"id": "mrqa_squad-validation-8075", "before_prediction": "the local administrative structure of past Chinese dynasties", "after_prediction": "Imperial Secretariat"}], "retained_ids": ["mrqa_triviaqa-validation-7032", "mrqa_squad-validation-9036", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-7445"], "fixed_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.6666666655555555}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "the Mayor's son", "abolitionist", "Basil Fawlty", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "BBC UKTV", "arthur", "demographics and economic ties", "three or more separate periods", "The Kickoff Game", "narcolepsy", "arctic monkeys", "Ecclestone", "arthur rex", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "instructions", "National Party", "marduk", "althingi", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "koreans", "South Pacific", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Evan Jonigkeit", "Meredith Brody ( Zoe McLellan ), a transfer from the NCIS Great Lakes field office, who has worked as a Special Agent Afloat and is keen to leave her past behind as she moves to New Orleans", "tamer youssef", "National Lottery", "unmanned spectroheliometer", "catherine of aragon", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.0625, "QA-F1": 0.10796815386840541}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 1.0, 0.4, 0.12121212121212122, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "ingen", "all transmissions", "A computer program", "National Party of Australia", "babylon", "surtsey", "Kenya's largest source of foreign direct investment", "national network", "South Pacific", "7", "New Jersey", "Easy", "Vanessa Ferlito", "indira gandhi", "state-franchised", "skylab", "spain", "comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.875, "QA-F1": 0.9286437246963564}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9473684210526316]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2750", "mrqa_naturalquestions-validation-4710"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608", "mrqa_squad-validation-2885", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-10328"], "instant_fixing_rate": 0.8666666666666667, "instant_retention_rate": 0.999999995}, {"timecode": 31, "before_eval": {"predictions": ["Selena", "Peter Andreas", "boston", "alexander", "Newell Highway", "Mondas", "15 hands", "a shopping mall located in Bloomington, Minnesota, United States ( a suburb of the Twin Cities )", "allocution", "Mike Myers, Eddie Murphy and Cameron Diaz reprising their respective voice roles of Shrek, Donkey, and Fiona from the first film", "Johann Strauss", "his own men", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "polly", "the RAF", "reduce growth", "Ibrium", "Hayley Sanderson", "Polish-Jewish", "Spanish coup of July 1936 against the Second Spanish Republic, including the Falange, the CEDA, and two rival monarchist claimants : the Alfonsists and the Carlists", "polly", "ottoexeter", "estimated 390 billion", "Washington Street", "8 November 1978", "6", "lexy gold", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "polly", "John Smith", "surtania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23029545685795685}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.37037037037037035, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.09523809523809523, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45000000000000007, 0.0, 1.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "explaining their actions", "Andrew Adamson", "waltz king", "Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage", "Ibrium", "strictly come dancing", "Polish", "the Falange", "cole albert porter", "1967", "16,000", "Washington Street", "8 November 1978", "2", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "barbarella", "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution", "lusitania", "economic separation"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9756944444444444}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4500", "before_prediction": "John Smith", "after_prediction": "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution"}], "retained_ids": ["mrqa_hotpotqa-validation-2762", "mrqa_hotpotqa-validation-1444", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-3728"], "fixed_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7999999984}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "barbarella", "gender test", "Matt Jones", "k2CO3", "In extreme circumstances, a driver may attempt to jackknife the vehicle deliberately in order to halt it following brake failure", "CD4+ and CD8+", "high school teachers had the lowest median salary earning $39,259", "non-GMO", "Heading Out to the Highway", "Moonraker Reboot", "$349", "Michael Oppenheimer", "England national team", "\"degrees of privilege\" to which they were entitled institutionally and legally, so a person's standing within the classes was not a guarantee of their standing", "No Night Today", "Convention", "5,922", "December 5, 1991", "2016", "2014 NBA draft", "Saint Nicholas", "Stern-Plaza", "WBC/WBA heavyweight champion", "23 March 1991", "lily-of-the-valley", "Dallas", "Nairobi", "As sea levels rose", "Anno 2053"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2871089256958822}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.08695652173913045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.14814814814814814, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "after_eval": {"predictions": ["orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "september", "south africa", "Thomas Middleditch", "k", "If a vehicle towing a trailer skids", "T cell receptor (TCR)", "relatively low salaries", "non-GMO", "Point of Entry", "bridge", "u", "Science Magazine", "Premier League club Manchester United and the England national team", "lived in poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra )", "Stern-Plaza in Potsdam", "Jimmy Ellis", "1991", "may", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9076808608058607}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-572", "before_prediction": "Fomento Econ\u00f3mico Mexicano", "after_prediction": "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V."}, {"id": "mrqa_naturalquestions-validation-7049", "before_prediction": "Saint Nicholas", "after_prediction": "Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra )"}, {"id": "mrqa_hotpotqa-validation-5335", "before_prediction": "Stern-Plaza", "after_prediction": "Stern-Plaza in Potsdam"}], "retained_ids": ["mrqa_squad-validation-6744", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-5557"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "unfixed_ids": ["mrqa_triviaqa-validation-7156", "mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.571428570612245}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "Boston Herald", "1967", "\"winnings\"", "the twelfth most populous city in the United States", "115", "bridge", "in every case, the result is an aberrant, ligand - independent, non- regulated growth stimulus to the cancer cells", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Tevye", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country, hugging the east side of the Mississippi River and its tributaries", "japan", "seaman", "Yunnan- Fu (\u4e91\u5357\u5e9c, \"Y\u00fann\u00e1nf\u01d4\")", "Mumbai, India", "Broken Hill and Sydney", "2005", "all punishments and granted them salvation", "\"The Doctor's Daughter\"", "september", "bridge", "may seek changes or exemptions in the law that governs the land where the building will be built", "1879", "paternal great-grandmother", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system", "teacher enthusiasm", "Russo-Japanese War", "Datsun 810", "Bill Clinton's national intelligence officer for East Asia", "Buskerud and Telemark"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22092832642120497}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5517241379310344, 0.08, 0.0, 0.0, 0.12121212121212123, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.1739130434782609, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "after_eval": {"predictions": ["Napoleon", "Charles Edward Coughlin", "1967", "amount charged by a bookmaker", "largest", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "along the St. Lawrence River valley", "emperor", "oakum", "Spring city", "London", "Broken Hill and Sydney", "2005", "all punishments", "Smith and Jones", "wagon", "Ilich Ramirez Sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "power steering", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1657", "before_prediction": "Boston Herald", "after_prediction": "Charles Edward Coughlin"}], "retained_ids": ["mrqa_hotpotqa-validation-1573", "mrqa_naturalquestions-validation-6358", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-1903"], "fixed_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7999999984}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "king george vi", "Threatening government officials", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "meat glaze", "0.2 inhabitants per square kilometre", "red", "France", "Ian Paisley", "martsa ng Kamatayan sa Bataan", "euro", "suggs", "the United States", "1973", "1886", "Sam Bradford", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Maximus Decimus Meridius", "A rotation is a circular movement of an object around a center ( or point ) of rotation. A three - dimensional object can always be rotated around an infinite number of imaginary lines called rotation axes", "Johnny Darrell", "carotid artery disease", "all margarine to be in cube shaped packages", "Euler's totient function", "earwax", "a precise definition of this language, one has to decide how graphs are encoded as binary strings", "Busiest airports in the United States by international passenger traffic", "red", "Toyota Corona", "Kurt Vonnegut", "Rapunzel"], "metric_results": {"EM": 0.125, "QA-F1": 0.1755841437397144}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.6086956521739131, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman", "norman hartnell", "expressing defiance toward the government and unwillingness to stand for its policies", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52", "Primula Susan Rollo", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "World War II", "litai", "madness", "Taft", "late 1970s", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "the sum of divisors function", "ear canal", "how graphs are encoded as binary strings", "third", "afghanistan", "large", "Lauren Oliver", "Rapunzel to Gothel"], "metric_results": {"EM": 0.875, "QA-F1": 0.890625}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3408", "before_prediction": "earwax", "after_prediction": "ear canal"}], "retained_ids": ["mrqa_hotpotqa-validation-3982", "mrqa_naturalquestions-validation-951", "mrqa_hotpotqa-validation-1139"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034"], "unfixed_ids": ["mrqa_squad-validation-6673", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "supply and demand", "Nathan Mack", "liver", "ear-shaped pasta", "Washington Redskins", "in the courtyard adjoining the Assembly Hall", "William Howard Ashton", "national security", "promoting social dislocation, unrest and conflict", "Broward County", "Lee Byung-hun", "changing display or audio settings quickly", "fought 1642-1651", "derived from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "if the income share of the top 20 percent (the rich) increases", "Beautyy and the Beast", "South Africa", "Tyler \" Ty\" Mendoza", "alamo", "a seal illegally is broken", "United Methodist", "Brian Liesegang", "Don Hahn", "Papua New Guinea", "Alvin and the Chipmunks", "National Association for the Advancement of Colored People", "1963\u20131989", "world", "president of the Council and Leader of the House of Commons", "abner kravitz", "6500 - 1500 BC"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3229910714285714}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.5, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4444444444444445, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["up to 2%", "capital and financial markets", "Dan Stevens", "liver", "butterfly", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard adjoining the Assembly Hall", "William Howard Ashton", "president harding", "Unemployment", "Miami", "Best Actor prize", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "charles i", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "New Zealand national rugby union team", "Tyler \" Ty\" Mendoza", "texas", "seal", "UMC", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "NAACP", "1963\u20131989", "rms titanic", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9642857142857143}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6450", "before_prediction": "South Africa", "after_prediction": "New Zealand national rugby union team"}], "retained_ids": ["mrqa_naturalquestions-validation-7704", "mrqa_hotpotqa-validation-2971", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-1136", "mrqa_squad-validation-7610"], "fixed_ids": ["mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "unfixed_ids": ["mrqa_squad-validation-9123"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.8333333319444445}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Kevin Costner", "Uranus", "president rudolf", "Cobham\u2013Edmonds thesis", "human", "Seal II", "March 2012", "jazz", "Muhammad Ali", "Coldplay", "Menorca", "to civil disobedients", "Julius Caesar", "2%", "March 28, 1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "decision problem", "lecouvreur", "lungs", "Miasma theory", "American pint of 16 US fluid ounces ( 473 ml )", "mountain ranges (sub-ranges of the Rocky Mountains)", "president", "significant production of peaches as early as 1571, with exports to other states occurring around 1858", "perennial", "$12", "a flat rate", "love is all Around", "to build a nationwide network in the UK", "roughly west through the Netherlands and extended to the southwest, through the English Channel and finally, to the Atlantic Ocean", "South Sudan"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31716853408029877}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.5, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.3333333333333333, 0.5, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.11764705882352941, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_hotpotqa-validation-1884", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_triviaqa-validation-4069", "mrqa_naturalquestions-validation-2323", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "Uranus", "rudolph", "Cobham\u2013Edmonds thesis", "remind the Doctor of his \"moral duty\"", "II", "April", "city of new orleans", "Raymond Patterson", "Coldplay", "Menorca", "submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen", "emperors", "2%", "1979", "Easter egg", "formal language", "conducting", "the right side of the heart", "bad air", "imperial fluid ounces", "mountain ranges", "white", "California and South Carolina", "nettle", "$12", "20 %", "love is all around", "use in the ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8965544871794872}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-3993", "before_prediction": "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "after_prediction": "Easter egg"}], "retained_ids": ["mrqa_squad-validation-1758", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-3060", "mrqa_squad-validation-3635", "mrqa_triviaqa-validation-6290"], "fixed_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-4115", "mrqa_hotpotqa-validation-1884", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-199", "mrqa_triviaqa-validation-4069", "mrqa_naturalquestions-validation-2323", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "unfixed_ids": ["mrqa_triviaqa-validation-4824", "mrqa_squad-validation-7720", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-3344"], "instant_fixing_rate": 0.84, "instant_retention_rate": 0.8571428559183674}, {"timecode": 37, "before_eval": {"predictions": ["Burlington Northern Santa Fe Railway", "back was severely wrenched and three of his ribs were broken", "2007", "Post Alley", "mother-of-pearl", "February 20, 1978", "haggis", "George H.W. Bush", "96", "first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "japan", "a bubble on a black background representing the circle with glossy gold letters", "the alluvial plain", "at exactly 37\u00b0 9' 58.23\" latitude, around 11 miles (18 km) south of San Jose", "Spotty\u2019s", "Rumplestiltskin", "Harry Kane", "large birds or mammals", "many events and festivals", "riper", "1991", "ion", "7 January 1936", "lifetime protection", "twenty- three", "Carl Sagan, a prominent contributor to the scientific research of extraterrestrial life, and Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Holb\u00e6k", "mistreatment from government officials", "heavy", "Boston, Massachusetts"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3515542328042328}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.14814814814814814, 0.2777777777777778, 0.13333333333333333, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_triviaqa-validation-2524"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "Ronald Reagan", "96", "the Roman Empire", "two", "gold", "Mesopotamia", "37\u00b0 9' 58.23\"", "woodentops", "Henry", "shared", "sandhill dunnart", "events and festivals", "kabinett - Wines", "2010", "avatar", "7 January 1936", "lifetime protection", "The Simpsons (season 10)", "Carl Sagan", "Much of the city's tax base dissipated", "Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Pierre Nlend Wom\u00e9", "mistreatment from government officials", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.875, "QA-F1": 0.9}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4664", "before_prediction": "George H.W. Bush", "after_prediction": "Ronald Reagan"}], "retained_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-5451", "mrqa_hotpotqa-validation-513", "mrqa_hotpotqa-validation-4154", "mrqa_hotpotqa-validation-85", "mrqa_naturalquestions-validation-969", "mrqa_squad-validation-6737", "mrqa_hotpotqa-validation-5371"], "fixed_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_hotpotqa-validation-633", "mrqa_triviaqa-validation-2524"], "unfixed_ids": ["mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-1375"], "instant_fixing_rate": 0.8695652173913043, "instant_retention_rate": 0.8888888879012344}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "sheep", "The primary catalyst for secession was slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories.", "American Indian allies", "a children's story published by John Newbery in London in 1765", "It has the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east ).", "The platform is open to backers from anywhere in the world and to creators from the US, UK, Canada, Australia, New Zealand, The Netherlands, Denmark, Ireland, Norway, Sweden, Spain, France, Germany, Austria,", "Eden", "commissioned officers are given a one - time stipend when commissioned to purchase their required uniform items", "Jeff Meldrum", "741 weeks", "archers", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "suez canal", "60", "journalist", "the fact that there is no revising chamber", "1960s", "the points of algebro-geometric objects", "most of the items in the collection, unless those were newly accessioned into the collection", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "strychnine", "California", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation", "13 June 2003", "eddy sehan Shah", "Jason Marsden", "In healthy adults, there are two normal heart sounds, often described as a lub and a dub ( or dup ), that occur in sequence with each heartbeat"], "metric_results": {"EM": 0.125, "QA-F1": 0.21365561098592134}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.05714285714285714, 0.04878048780487805, 0.0, 0.23529411764705882, 0.25, 0.0, 0.0, 0.15384615384615383, 0.0, 1.0, 0.2857142857142857, 1.0, 0.6, 0.0, 0.0, 0.5, 0.06451612903225806, 1.0, 0.0, 0.3846153846153846, 0.0, 0.0, 0.0, 0.0625]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "after_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma", "1958", "Bart Cummings", "dragons", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "the colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \"Jeff\" Meldrum (born May 24, 1958) is a Professor of Anatomy and Anthropology", "a week", "phil archer", "French and English", "The Chipettes", "suez canal", "60 by West All - Stars ( 2017 )", "journalist", "take evidence from witnesses, conduct inquiries and scrutinise legislation", "beehive", "ramification in geometry", "newly accessioned", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9383928571428571}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-1862", "mrqa_triviaqa-validation-3118", "mrqa_squad-validation-1660", "mrqa_triviaqa-validation-3320"], "fixed_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.9999999975}, {"timecode": 39, "before_eval": {"predictions": ["Taiwan", "Dan Conner", "berlin", "president garfield", "Lois Mae Green", "the Christian critique of Judaism and establishing anti-Semitism as a key element of German culture and national identity", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "kuskusi", "the 1980s", "John M. Grunsfeld, geneticist James Watson", "New York City", "william herschel john", "2000", "rms titanic", "Fabbrica Italiana Automobili Torino", "the second Sunday of March, and standard time restarts on the first Sunday in November", "relative units", "woman", "FC Porto", "August 10, 1933", "spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Sochi, Russia", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "monetary Sovereignty", "william herschel", "264,152", "Princeton, New Jersey", "the United States", "either high pressure or an electric current"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3417924406604747}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false], "QA-F1": [0.5, 1.0, 0.4, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.47058823529411764, 0.0, 0.0, 0.6666666666666666, 1.0, 0.3157894736842105, 0.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["capital of taiwan", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "during the 1980s", "John M. Grunsfeld", "detroit", "your song", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "an equality", "agatha christie", "two", "August 10, 1933", "Golden Gate Bridge", "vancouver", "those who already hold wealth", "bilingual German author B. Traven", "Finding Nemo", "Fortean", "inflation", "squirrels", "247,597", "The Institute for Advanced Study", "German service cartridge", "DC electricity"], "metric_results": {"EM": 0.875, "QA-F1": 0.9470009157509158}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6554", "before_prediction": "the 1980s", "after_prediction": "during the 1980s"}, {"id": "mrqa_naturalquestions-validation-5272", "before_prediction": "bilingual German author B. Traven, whose identity remains unknown", "after_prediction": "bilingual German author B. Traven"}], "retained_ids": ["mrqa_hotpotqa-validation-2243", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-2332", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-489"], "fixed_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-5595"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.7142857132653061}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "on the road back to Samarkand", "arajevo", "Isabella (Belle) Baumfree", "corgis", "14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "the foundations of the Reformation placing them on prophetic faith", "Bacon", "Charlton Heston", "anti-inflammatory molecules", "garb", "2017 NFL regular season", "a tradeable entity used to avoid the inconvenienceiences of a pure barter system", "the U.S. federal government", "warren lumi\u00e8re", "the Uighur King of Qocho was ranked higher than the Karluk Kara-Khanid ruler", "Sochi, Russia", "right", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "NASA immediately convened an accident review board", "New Zealand", "shorthand typist", "160 minor league baseball affiliates", "the Secret Intelligence Service", "100 billion", "kai su, teknon", "photolysis", "4", "Queen City", "an American federal law that imposes liability on persons and companies ( typically federal contractors ) who defraud governmental programs"], "metric_results": {"EM": 0.3125, "QA-F1": 0.41599260114885117}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.375, 0.7692307692307693, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 0.2857142857142857, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_triviaqa-validation-1571", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgi", "14th to 17th centuries", "five starting pitchers", "prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "sound and light", "the Uighurs surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "central Saskatchewan", "immediately", "New Zealand", "shorthand typist", "30 Major League Baseball teams", "MI6", "neurons", "caesar died in silence", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.9375, "QA-F1": 0.978225806451613}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9032258064516129, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-395", "mrqa_squad-validation-6248", "mrqa_hotpotqa-validation-1453", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-4330", "mrqa_hotpotqa-validation-4076", "mrqa_triviaqa-validation-3280", "mrqa_triviaqa-validation-4123", "mrqa_squad-validation-3617", "mrqa_hotpotqa-validation-178"], "fixed_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_triviaqa-validation-1571", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "unfixed_ids": ["mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-579"], "instant_fixing_rate": 0.9090909090909091, "instant_retention_rate": 0.9999999989999999}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Kishore Kumar", "Gaels", "Three-card brag", "d\u00edsabl\u00f3t", "lion", "Russian film industry", "the sediment load of the Rhine has strongly increased", "Washington metropolitan area", "GTPase responsible for endocytosis in the eukaryotic cell", "User State Migration Tool ( USMT )", "Ordos City", "frisbee", "PPG Paints Arena, Pittsburgh, Pennsylvania", "philry wall museum", "Section 30 of the Teaching Council Act 2001", "spain", "mid-1988", "quasars", "Northeast Monsoon or Retreating Monsoon", "Romansh", "george i", "5AA", "James Bond quartermaster Q", "Paul and Timothy first visited Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "the division of labour, productivity, and free markets", "Gerard Marenghi (born January 24, 1920) known as Jerry Maren", "Pat Houston", "Hugo Award", "margaret tabled a motion of no confidence", "king David of Israel", "Jean - Paul - \u00c9gide Martini"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2932607323232323}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.05, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.4, 0.0, 0.0, 0.7499999999999999, 0.0, 0.3636363636363636, 0.25, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag", "Idisi", "the European or Eurasian cave lion", "The cinema of Russia", "sediment load", "FedExField in Landover, Maryland", "the scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment, both at the cell surface", "Windows Easy Transfer", "Ordos City", "Franscioni", "Duquesne University", "le Leicester", "Section 30", "Paul Lynde", "October 1986", "4 billion", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george iii", "MIX 94.5", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret tabled a motion of no confidence in James Callaghan", "jonathan", "Luigi Creatore"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8623547505126452}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8421052631578948, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2053", "before_prediction": "lion", "after_prediction": "the European or Eurasian cave lion"}, {"id": "mrqa_triviaqa-validation-4955", "before_prediction": "frisbee", "after_prediction": "Franscioni"}, {"id": "mrqa_hotpotqa-validation-3176", "before_prediction": "5AA", "after_prediction": "MIX 94.5"}], "retained_ids": ["mrqa_squad-validation-1592", "mrqa_hotpotqa-validation-201", "mrqa_naturalquestions-validation-774"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-3058", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355", "mrqa_triviaqa-validation-684", "mrqa_naturalquestions-validation-8338", "mrqa_triviaqa-validation-791"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.49999999916666665}, {"timecode": 42, "before_eval": {"predictions": ["david carradine", "sometimes contains pasta ( usually cavatelli, acini di pepe, pastina, orzo, etc. ), lentils, or grated parmesan cheese.", "Ninette de Valois", "the connotations of a somewhat related word in German Eidgenosse (Confederates as in \"a citizen of one of the states of the Swiss Confederacy\")", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "questions about the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "paid professionals", "lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "a large Danish shipping company that operates passenger and freight services across northern Europe", "Giorgio Chiellini", "rommel", "the P position", "glucose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "public and private collections in the United States and abroad", "by functions ; Introverted Sensing ( Si ), Extroverted Thinking ( Te ), Introverted Feeling ( Fi ) and Extrovert Intuition ( Ne )", "Thursday", "green", "drug choice, dose, route, frequency, and duration of therapy", "4 km", "navigator and expedition leader", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "Joel Schumacher", "The Private Education Student Financial Assistance", "Pernambuco wood", "faith alone, whether fiduciary or dogmatic", "colonies", "two forces, one pointing north, and one pointing east", "a committee of the Parliament can present a bill in one of the areas under its remit", "Jack Murphy Stadium", "hierarchy theorems"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1848297443977591}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.11764705882352941, 0.0, 0.2857142857142857, 0.14285714285714288, 0.0, 0.0, 0.16, 0.0, 0.375, 0.5, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "various causes", "the American Civil War", "Chartered", "lack of remorse", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose is discovered by French chemist Augustin - Pierre Dubrunfaut in 1847. The name `` fructose '' was coined in 1857 by the English chemist William Allen Miller.", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "Extroverted Sensing ( Si )", "May", "white", "all prescribed medications prior to dispensing and administration to the patient", "mars", "feats of exploration", "piston", "rob lowe", "The Private Education Student Financial Assistance", "bows", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8831257832080199}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 0.08333333333333333, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1429", "before_prediction": "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "after_prediction": "various causes"}, {"id": "mrqa_squad-validation-6369", "before_prediction": "drug choice, dose, route, frequency, and duration of therapy", "after_prediction": "all prescribed medications prior to dispensing and administration to the patient"}], "retained_ids": ["mrqa_squad-validation-7034"], "fixed_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-4842", "mrqa_naturalquestions-validation-6706"], "instant_fixing_rate": 0.8620689655172413, "instant_retention_rate": 0.3333333322222222}, {"timecode": 43, "before_eval": {"predictions": ["bridal Veil Falls", "4 Points - F, H, V, W and Y.", "joseph lincoln", "joseph smith", "French", "a \"homeward bounder\" a sailor coming home from a round trip", "www.example.com", "the immune system is less active than normal", "Py", "natural-ing Ingredients- only personal care products", "Burl Ives", "Sparafucile", "Russia", "the most abundant element by mass in the Earth's crust as part of oxide compounds such as silicon dioxide", "furniture", "over 38 million Scouts and Guides worldwide, with 169 national organisations governed by the World Organization of the Scout Movement", "oribe peralta", "Nicholas Stone", "Akon, T.I. Rick Ross, Fat Joe, Birdman and Lil Wayne", "the Outfield", "Croatia", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong", "almost universal for marine engines after 1880", "eddie Fisher", "the Moon's ecliptic longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0", "bresslaw", "chemists Glenn T. Seaborg", "the U.S. states of Kentucky, Virginia, and Tennessee", "many areas of technology incidental to rocketry and manned spaceflight", "Mitochondrial Eve", "237", "magi"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2482520221007063}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [0.4, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.6, 0.0, 1.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.4, 0.0, 0.2666666666666667, 0.22222222222222224, 0.0, 0.7222222222222223, 0.0, 0.8571428571428571, 0.7272727272727273, 0.4210526315789474, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-4624", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-305"], "after_eval": {"predictions": ["niagara falls", "15", "indiana", "salt lake city", "Italian", "sailor", "top - level domain", "genetic disease", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third", "ikea", "169", "mexico", "Edward Hodges Baily, Lord Leighton, Alfred Stevens, Thomas Brock, Alfred Gilbert, George Frampton, and Eric Gill", "Plies", "English rock band the Outfield", "tennis", "Edward Furlong", "road engines", "richard burton", "when the Sun's ecliptic longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "snudge", "Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "NASA's current human spaceflight capability, and funded construction of its Johnson Space Center and Kennedy Space Center", "india", "237", "matthew"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9378654970760234}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7894736842105263, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5899", "before_prediction": "Mitochondrial Eve", "after_prediction": "india"}], "retained_ids": ["mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-5541"], "fixed_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-4624", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-305"], "unfixed_ids": ["mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5968"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda met Captain America in early 1941 and gave him a second sample of vibranium, an alien metal with unique vibration absorption properties and found only in Wakanda and the Savage Land", "high test scores", "England and Wales", "gymnastics", "mexico", "A \" campaign\" is a series of individual adventures, and a \" campaign setting\" is the world in which such adventures and campaigns take place", "2003", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal", "\"\u00f7\"", "Christopher Lee as Count Dooku / Darth Tyranus", "8th", "picture book", "all health care settings", "more integral within the health care system", "treble clef", "G-Styles", "125 km / h", "the Trinit\u00e0 dei Monti church at the top", "May 18, 2010", "an activist in the cause of anti-fascism", "eEC", "philosophical advocate and practitioner of the scientific method during the scientific revolution", "rms titanic", "Indian government ministry", "British", "ancient cult activity", "Penguin Classics", "the energy-storage molecules ATP and NADPH while freeing oxygen from water", "stS-31", "us to respond to God by leading a Spirit-filled and Christ-like life aimed toward love", "Christ lag in Todes Banden"], "metric_results": {"EM": 0.0625, "QA-F1": 0.2302828681734932}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.3, 0.0, 0.5, 0.0, 0.0, 0.09090909090909091, 0.0, 0.6666666666666666, 0.6875000000000001, 0.15384615384615385, 0.7272727272727273, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_hotpotqa-validation-5696", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "in 2003 for the inter-county competition in England and Wales", "paris", "sweden", "published campaign settings", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Yoda", "second most commonly", "well", "in all health care settings, but the clinical pharmacy movement initially began inside hospitals and clinics", "become more integral within the health care system", "music", "Lecrae Devaughn Moore", "Mumbai Rajdhani Express", "Rome", "December 1, 2009", "Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "hubble", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.90625, "QA-F1": 0.946751644736842}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6319", "before_prediction": "all health care settings", "after_prediction": "in all health care settings, but the clinical pharmacy movement initially began inside hospitals and clinics"}, {"id": "mrqa_naturalquestions-validation-2169", "before_prediction": "May 18, 2010", "after_prediction": "December 1, 2009"}], "retained_ids": [], "fixed_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_hotpotqa-validation-5696", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "unfixed_ids": ["mrqa_squad-validation-6403"], "instant_fixing_rate": 0.9666666666666667, "instant_retention_rate": 0.0}, {"timecode": 45, "before_eval": {"predictions": ["Mickey Spillane", "0\u201316", "perique", "cut off close by the hip, and under the left shoulder, he carried a crutch", "sweden", "a stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "florida", "chr\u00e9tien de Troyes", "James Hewson", "V Alaudae, a Celtic legion recruited from Gallia Narbonensis and XXI, possibly a Galatian legion from the other side of the empire", "Cartwright clan", "four of the 50 states of the United States in their full official state names", "curling", "the eighth series of the UK version of The X Factor", "Pebble Beach", "Los Angeles", "French", "Gareth in the AMC horror drama \"The Walking Dead\"", "\"LOVE Radio\" which featured a limited selection of music genres, was launched on ABC's seven owned-and-operated FM stations in late November 1968", "Boston Red Sox", "Illinois", "john travolta", "Dan Fogelman and Jessie Nelson", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "\" Cashin' In\"", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "San Francisco Bay Area at Santa Clara, California", "fortified complex", "Neptune", "peninsular mainland"], "metric_results": {"EM": 0.03125, "QA-F1": 0.12586747491638794}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.17391304347826084, 0.0, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 1.0, 0.4166666666666667, 0.16666666666666669, 0.4, 0.0, 0.6666666666666666, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "after_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke", "under `` the immortal Hawke ''", "executed", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum", "lorne greene", "Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ), Massachusetts, Pennsylvania, and Virginia", "1998", "They were the first group to win the competition", "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove", "St. Louis", "Canadian", "Gareth", "LOVE Radio", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "worked to radicalize the Islamist movement", "People! and The Carnabeats", "Cashin' In", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.875, "QA-F1": 0.9378334527791049}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3509"], "fixed_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_naturalquestions-validation-4123", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "unfixed_ids": ["mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.8709677419354839, "instant_retention_rate": 0.9999999900000002}, {"timecode": 46, "before_eval": {"predictions": ["bat-and-ball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That, East 17 and Boyzone", "youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Galileo Galilei", "the absenceistence of the ultraviolet catastrophe", "Premier League club Swansea City", "pre-Raphaelite", "Elizabeth Weber", "an earlier Funcom game", "hundreds of television and radio channels", "\"Waiting for Guffman\"", "1999", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "partial funding", "5% abv draught beer", "less of the other", "Chu'Tsai", "Liz", "least onerous", "lago di Como", "Grissom, White, and Chaffee", "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores", "purple", "The Natya Shastra is the foundational treatise for classical dances of India, and this text is attributed to the ancient scholar Bharata Muni", "the sand grains cause a scrubbing noise as they rub against each other when walked on", "Samuel Ryder", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "vi"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3551202628788836}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.5384615384615384, 1.0, 0.06666666666666667, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.2222222222222222, 0.2857142857142857, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.18181818181818182, 0.0689655172413793, 0.5, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "after_eval": {"predictions": ["cuba", "that continents `` ploughed '' through the sea.", "take that", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds", "\"Waiting for Guffman\"", "2003", "a new facility", "apple tree", "The Five Doctors", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "italy", "Grissom, White, and Chaffee", "multinational retail corporation", "passion fruit", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "incorrectly", "vienna"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7792", "before_prediction": "partial funding", "after_prediction": "The Five Doctors"}], "retained_ids": ["mrqa_squad-validation-5157", "mrqa_hotpotqa-validation-5221", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913"], "fixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8571428559183674}, {"timecode": 47, "before_eval": {"predictions": ["margaret", "qIPCO", "New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia to protect it from Japanese troops", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "when they enter the army during initial entry training", "one of The Canterbury Tales by Geoffrey Chaucer", "they quit after five months, leaving the group as a trio", "l Leeds", "the most common shapes are a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies.", "260", "heathrow", "often social communities with considerable face-to-face interaction among members.", "various newspaper reporters, including Sylvia F. Porter in a column for the May 4, 1951, edition of the New York Post", "the \"cydippids\" are not monophyletic, in other words don't include all and only the descendants of a single common ancestor", "insects", "specific catechism questions", "a pH indicator, a color marker, and a dye", "about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "usually resident population of the UK and its constituent countries, by age and sex", "John and Charles Wesley", "the relevant issues of a post-World War I environment in a printed article, \"Science and Discovery are the great Forces which will lead to the Consummation of the War\" (20 December 1914)", "Euclid's fundamental theorem of arithmetic", "WKU", "jett rink", "appearing as Jude in the musical romance drama film \"The Way Back\" (2007)", "cuba", "work in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "relatively stagnant wages for the working class amidst rising levels of property income for the capitalist class."], "metric_results": {"EM": 0.21875, "QA-F1": 0.383709106984969}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8888888888888888, 0.6666666666666666, 0.888888888888889, 1.0, 0.0, 0.0, 0.09999999999999999, 0.0, 1.0, 1.0, 0.5, 0.5384615384615384, 0.0, 0.0, 0.20689655172413793, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.5555555555555556, 1.0, 0.1]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-1609", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "horseracing", "New Zealand national team", "Kumbum Monastery or Ta'er Shi near Xining", "Styal Mill", "Clarence Darrow", "Goldie & Bear", "during initial entry training", "a moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "piccadilly", "Neighbourhood is generally defined spatially as a specific geographic area and functionally as a set of social networks", "The Washington Post", "tentacles", "insects", "a liturgical setting of the Lord's Prayer and as a means of examining candidates on specific catechism questions", "a color marker", "about 50% oxygen composition at standard pressure", "2001", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "Campbellsville University", "james Byron dean", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita", "XXXTentacion", "less workers are required"], "metric_results": {"EM": 0.90625, "QA-F1": 0.920343137254902}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-930", "before_prediction": "William Jennings Bryan", "after_prediction": "Clarence Darrow"}, {"id": "mrqa_squad-validation-2346", "before_prediction": "specific catechism questions", "after_prediction": "a liturgical setting of the Lord's Prayer and as a means of examining candidates on specific catechism questions"}], "retained_ids": ["mrqa_hotpotqa-validation-1924", "mrqa_hotpotqa-validation-5788", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-3868", "mrqa_naturalquestions-validation-2092"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-1609", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "unfixed_ids": ["mrqa_hotpotqa-validation-5086"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.7142857132653061}, {"timecode": 48, "before_eval": {"predictions": ["James Stenbeck", "Good Kid, M. a.A.D City", "el Capitan", "cleaning and reintegration to strengthen fragile objects, reveal original surface decoration, and restore shape", "3", "The Methodist Church", "cuba", "in a thousand years", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "margaret thatcher", "2001", "Satnam Singh Bhamara", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "every good work designed to attract God's favor is a sin. All humans are sinners by nature, he explained, and God's grace ( which Cannot be earned) alone can make them just.", "will be made after winning ( usually 60 days after claiming the ticket ), although in Florida the 60 - day `` clock '' starts with the drawing in which the jackpot prize was won.", "a member of the Imperial Senate and an agent of the Rebel Alliance", "Buffalo Bill", "a place where justice resides", "a semi-independent State of Vietnam, within the French Union", "1917", "dark coffee", "slaughtered by cutting the throat with a single stroke", "Hecuba is a band based in Los Angeles, California featuring performance artist, Isabelle Albuquerque and musician/designer Jon Beasley.", "a method of imparting the basics of Christianity to the congregations", "Wylie Draper", "a political role for Islam", "the university's off-campus rental policies", "hockey greats Bobby Hull and Dennis Hull", "New England Patriots", "a protracted siege, during which the Mongol army under Jani Beg was suffering from the disease, the army catapulted the infected corpses over the city walls of Kaffa to infect the inhabitants"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24059064104427008}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.22222222222222218, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.06451612903225806, 0.16216216216216214, 0.0, 1.0, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.2666666666666667, 0.4, 1.0, 0.26666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "after_eval": {"predictions": ["James Stenbeck, St. Clair, Dixon, Munson and Montgomery", "Section.80", "yosemite national park", "interventive", "3 lines of reflection and rotational symmetry of order 3 about its center", "Bishop Reuben H. Mueller", "georgia state", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "unesco", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "part of a pre-recorded television program, Rendezvous with Destiny", "sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "neutrality", "coffee", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull, as well as painter Manley MacDonald.", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.90625, "QA-F1": 0.944047619047619}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2634", "before_prediction": "James Stenbeck", "after_prediction": "James Stenbeck, St. Clair, Dixon, Munson and Montgomery"}, {"id": "mrqa_naturalquestions-validation-49", "before_prediction": "3", "after_prediction": "3 lines of reflection and rotational symmetry of order 3 about its center"}], "retained_ids": ["mrqa_squad-validation-8248", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-7947"], "fixed_ids": ["mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.5999999988}, {"timecode": 49, "before_eval": {"predictions": ["vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL", "Genghis Khan and particularly Timur", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal. It is wider and leveled than the western coastal plains and stretches from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "It then served as the capital of the Ostrogothic Kingdom until it was re-conquered in 540 by the Eastern Roman (Byzantine) Empire.", "12", "fear of public speaking", "September 1895", "improved", "biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "He even lost control of the patents he had generated since he had assigned them to the company in lieu of stock. He had to work at various electrical repair jobs and even as a ditch digger for $2 per day.", "Georgian-born Soviet revolutionary and political leader", "his colleagues at the monastery ( such as Franz Diebl ) to study variation in plants", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "3,600 Frenchmen famously and decisively defeated Abercrombie's force of 18,000 regulars, militia and Native American allies outside the fort the French called Carillon and the British called Ticonderoga.", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "horakhty", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Massachusetts", "imperialism", "tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population", "ATP", "georgia state", "Ruth Elizabeth \"Bette\" Davis", "uranium", "7 December 2004"], "metric_results": {"EM": 0.09375, "QA-F1": 0.27435195669355}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.33333333333333337, 0.0, 0.625, 0.12903225806451615, 0.2222222222222222, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3636363636363636, 0.34782608695652173, 0.0, 0.0, 0.1111111111111111, 0.09523809523809525, 0.43750000000000006, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.5365853658536585, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna", "Bocelli became completely blind at the age of 12", "meat", "1895", "improved markedly", "VTOL aircraft", "assigned them to the company in lieu of stock", "communist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "uneven trade agreements", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.875, "QA-F1": 0.9011370573870574}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9807", "before_prediction": "imperialism", "after_prediction": "uneven trade agreements"}], "retained_ids": ["mrqa_hotpotqa-validation-1023", "mrqa_hotpotqa-validation-1772"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "unfixed_ids": ["mrqa_hotpotqa-validation-1364", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.1525, "QA-F1": 0.2581769520894337}, "overall_error_number": 1356, "overall_instant_fixing_rate": 0.9307924554790661, "final_instream_test": {"EM": 0.813125, "QA-F1": 0.8711805736943583}, "final_upstream_test": {"EM": 0.597, "QA-F1": 0.6706382401520989}}}