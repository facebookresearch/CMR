{"model_update_steps": 2570, "method_class": "er", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/1019_MixedAllErrors_T=100_er_UR=0.8_rs=32_rq=3_seed=42_ckpts/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/1019_MixedAllErrors_T=100_er_UR=0.8_rs=32_rq=3_seed=42_ckpts/', replay_candidate_size=8, replay_frequency=3, replay_size=32, save_all_ckpts=0, skip_instant_eval=True, total_steps=10000, upstream_sample_ratio=0.8, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=100, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.upstream_eval.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=True)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "The Iroquois", "philanthropy", "chley and settles down with him for the rest of the series", "Virginia Wade", "Gary Morris", "to the anterolateral corner of the spinal cord", "1966", "radioisotope thermoelectric generator", "john Cameron", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "the final revelation of God the Final Testament", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs show Summary", "acmthompson", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "the Exclusive Rights to Superman", "May and June 2010"], "metric_results": {"EM": 0.125, "QA-F1": 0.20679528124381066}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.23529411764705885, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.5, 0.0, 0.4444444444444445, 0.07407407407407407, 0.4, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "An acetate / \u02c8\u00e6s\u026ate\u026at / is a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base. `` Acetate ''", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "technological advances", "three-year-old racehorse", "Bothtec", "Terry Reid", "information about climate change based on published sources", "Elgar", "North America", "Andr\u00e9 3000", "three rookies", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "Denver Broncos", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "mares Bizet", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.03125, "QA-F1": 0.19766934454434454}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.0, 0.0, 1.0, 0.0, 0.2, 0.0, 0.4444444444444445, 0.4, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.3636363636363636, 0.0, 0.6666666666666666, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_squad-validation-194", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 3, "before_eval": {"predictions": ["id", "two and a half years", "id", "between 27 July and 7 August 2022", "New York", "brazer", "( 2006 British Academy Television Award for Best Drama Series and five consecutive (2010) awards at the National Television Awards", "the Uniting for Consensus", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "Glacier Mints", "Fred Archer", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "bambi", "cement City, Texas", "the Democratic Unionist Party (DUP )", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "for control purposes", "bamboula", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000", "al - khimar", "proteins", "gallbladder", "berenice Abbott"], "metric_results": {"EM": 0.125, "QA-F1": 0.16333411654135338}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-2530"], "retrieved_ids": ["mrqa_naturalquestions-train-15696", "mrqa_naturalquestions-train-26454", "mrqa_naturalquestions-train-80441", "mrqa_naturalquestions-train-54413", "mrqa_naturalquestions-train-68736", "mrqa_naturalquestions-train-780", "mrqa_naturalquestions-train-22177", "mrqa_naturalquestions-train-67245", "mrqa_naturalquestions-train-28073", "mrqa_naturalquestions-train-28554", "mrqa_naturalquestions-train-71265", "mrqa_naturalquestions-train-2829", "mrqa_naturalquestions-train-70247", "mrqa_naturalquestions-train-64456", "mrqa_naturalquestions-train-52993", "mrqa_naturalquestions-train-18623", "mrqa_naturalquestions-train-11187", "mrqa_naturalquestions-train-42825", "mrqa_naturalquestions-train-37284", "mrqa_naturalquestions-train-75118", "mrqa_naturalquestions-train-70738", "mrqa_naturalquestions-train-55074", "mrqa_naturalquestions-train-39658", "mrqa_naturalquestions-train-69670", "mrqa_naturalquestions-train-21962", "mrqa_triviaqa-validation-5026", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-7149", "mrqa_squad-validation-6677", "mrqa_triviaqa-validation-3915", "mrqa_squad-validation-392", "mrqa_naturalquestions-validation-3490"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Arnhem", "As of December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "nigeria", "a shepherd in a print by contemporary Israeli artist Mordechai Beck, protectively clasps a sheep in his arms", "museums", "nigeria", "bounding the time or space", "museums", "Alex O'Loughlin", "Eddie Leonski", "Jack", "a mixture of phencyclidine and cocaine", "bunker", "never", "the Reverse - Flash", "All Hallows'Day", "nigeria", "Azerbaijan", "Catholics", "Mona Vanderwaal", "Geoffrey Boycott", "Pyotr Ilyich Tchaikovsky", "2010", "the English colonies of North America, and Quebec", "speech or language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "steam turbine", "Splodgenessabounds"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2610863095238095}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.28571428571428575, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_squad-validation-3126", "mrqa_naturalquestions-validation-2900", "mrqa_triviaqa-validation-5168", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 5, "before_eval": {"predictions": ["otranto", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "Renfrewshire", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "2 : 44 p.m. EDT", "swanee or swannee whistle", "rapeseed", "to start fires, hunt, and bury their dead", "Cochin University of science and Technology", "Parietal cells ( also known as oxyntic or delomorphous cells )", "placental", "September 13, 1994", "j. Guiteau", "imperial rule", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "kinks", "by using net wealth (adding up assets and subtracting debts )", "entropy increases", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 19408 December 1980", "Selden", "structural collapses", "radamanthus"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1993166963755199}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.13333333333333333, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "to prevent the flame from being blown out", "Illinois", "2010", "Charlotte", "island in the Mediterranean Sea", "90-60's", "independent schools", "dolph Camilli", "times sign", "Best Supporting Actress", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "Wichita", "monatomic", "Palm Springs", "june", "amphib", "butterfly", "universal", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "near Grande Comore, Comoros Islands", "`` - s ''", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.15625, "QA-F1": 0.19851190476190478}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "retrieved_ids": ["mrqa_naturalquestions-train-7889", "mrqa_naturalquestions-train-25184", "mrqa_naturalquestions-train-20666", "mrqa_naturalquestions-train-65026", "mrqa_naturalquestions-train-8307", "mrqa_naturalquestions-train-63012", "mrqa_naturalquestions-train-1140", "mrqa_naturalquestions-train-6790", "mrqa_naturalquestions-train-84681", "mrqa_naturalquestions-train-9718", "mrqa_naturalquestions-train-49365", "mrqa_naturalquestions-train-62999", "mrqa_naturalquestions-train-26742", "mrqa_naturalquestions-train-65894", "mrqa_naturalquestions-train-5159", "mrqa_naturalquestions-train-32373", "mrqa_naturalquestions-train-67690", "mrqa_naturalquestions-train-68410", "mrqa_naturalquestions-train-52189", "mrqa_naturalquestions-train-63799", "mrqa_naturalquestions-train-1983", "mrqa_naturalquestions-train-17486", "mrqa_naturalquestions-train-39376", "mrqa_naturalquestions-train-32587", "mrqa_naturalquestions-train-20960", "mrqa_squad-validation-4456", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-4621", "mrqa_hotpotqa-validation-3978", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-671", "mrqa_hotpotqa-validation-3971"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 7, "before_eval": {"predictions": ["procurement of Armoured Personnel Carriers", "The Q'eqchi '", "a few", "The U.S. Army Chaplain insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who want more services and more control over the central city", "film", "Armenia", "the last book accepted into the Christian biblical canon", "Beyonc\u00e9", "% IACS conductivity values", "gallantry", "16 million", "post\u2013World War II", "work oxen for haulage", "1998", "a priest", "23.1", "18 - season", "family member", "long-term environmental changes", "William Powell Lear", "the unbalanced centripetal force", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "marlborough", "present-day Charleston", "\"quiescent\" stance", "Adam Karpel", "Panzer"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3106322496947497}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.3076923076923077, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.4444444444444445, 0.4, 0.5, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-8374", "mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "george george 'Nino' Farina", "37", "6.4 nanometers", "the eighth and eleventh episodes of the season", "Kyle Busch", "400", "adrenal glands", "artes liberales", "Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "St. Louis County", "1868", "2018", "b Bramall Lane", "law firm", "Pottawatomie County", "owaita, an Aldabra giant tortoise", "Albert Einstein", "The parish Church of St Andrew", "bromley-By-Bow", "Toronto", "wales", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "the Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "the largest gold rushes the world has ever seen", "six", "not guilty", "psychoanalysis", "Quentin Coldwater", "acidic"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3081969246031746}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7506", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_squad-validation-5313", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "but not actually find the right pan", "photosynthesis", "a wide range of society figures of the period", "White House", "The Daily Stormer", "triplet", "water", "president", "the citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co. fire", "acting career", "C. W. Grafton", "illuminated display", "Americans acting under orders", "iPod Classic", "My Sassy Girl", "remove excess, unnecessary materials from the body fluids of an organism, so as to help maintain internal chemical homeostasis and prevent damage to the body", "The Edge of Night", "non-combustible substances that corrode, such as iron, contained very little", "pedagogy", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "the root respiration", "organic carbon in all land - living organisms, both alive and dead, as well as carbon stored in soils", "drug dealer", "medium and heavy- Duty diesel trucks", "testes"], "metric_results": {"EM": 0.34375, "QA-F1": 0.461390801738584}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.125, 1.0, 1.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.0, 0.3333333333333333, 0.5161290322580644, 1.0, 0.0, 0.0, 1.0, 0.0, 0.1904761904761905, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "retrieved_ids": ["mrqa_naturalquestions-train-79928", "mrqa_naturalquestions-train-57381", "mrqa_naturalquestions-train-24604", "mrqa_naturalquestions-train-59056", "mrqa_naturalquestions-train-72833", "mrqa_naturalquestions-train-50878", "mrqa_naturalquestions-train-35158", "mrqa_naturalquestions-train-67290", "mrqa_naturalquestions-train-21262", "mrqa_naturalquestions-train-25259", "mrqa_naturalquestions-train-39216", "mrqa_naturalquestions-train-17240", "mrqa_naturalquestions-train-3177", "mrqa_naturalquestions-train-53177", "mrqa_naturalquestions-train-34234", "mrqa_naturalquestions-train-30479", "mrqa_naturalquestions-train-38402", "mrqa_naturalquestions-train-34974", "mrqa_naturalquestions-train-65412", "mrqa_naturalquestions-train-83670", "mrqa_naturalquestions-train-55731", "mrqa_naturalquestions-train-56279", "mrqa_naturalquestions-train-40109", "mrqa_naturalquestions-train-83110", "mrqa_naturalquestions-train-26317", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-893", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-227", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-2385", "mrqa_triviaqa-validation-1935"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 10, "before_eval": {"predictions": ["1688", "Walter Reed Army Hospital in Washington, D.C. from 1942 to 1945", "three legal systems", "Las Vegas, Nevada", "a status line", "globetrotters", "cruiserweight title", "the fictional town of Ramelle", "1987", "1987", "cromlech", "Victoria, Duchess of Kent", "acidity or basicity of an aqueous solution", "1987", "the MGM Grand Garden Garden Special Events Center", "digital fashion gallery", "C. J. Anderson", "extremely difficult, if not impossible", "October 27, 1838", "60", "Eagle Ridge Mall", "Pel\u00e9", "reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present )", "Ward", "novelist and poet", "Jamestown", "Monet", "tree growth stages"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3341856060606061}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.8, 1.0, 0.5, 0.6666666666666666, 0.7272727272727273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "\"Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "The TEU", "ice melting", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "bactrians and dromedaries", "longer from shore to shore", "light rail system", "handguns", "catfood", "the Byzantines", "a young officer named Fernando Urissa", "Beetle", "Dyess", "European Union", "Queen Elizabeth II", "infections, irritation, or allergies", "the most - visited paid monument in the world", "the Vittorio Emanuele II Gallery and Piazza della Scala in a pedestrian area in the centre of the city", "catfish aquaculture", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "Whiskey Shivers as Saddle Up, a country - bluegrass - based band competing against the Bellas", "Iraq", "a co-op of grape growers", "mann", "nabucodonosor", "June 25, 1952", "Los Angeles Lakers", "`` speed limit '' omitted", "Jean F kernel ( 1497 -- 1558 ), a French physician", "body hair transplantation ( BHT ) on appropriate candidates who have available donor hair on the chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.03125, "QA-F1": 0.14365985429259423}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.31578947368421056, 0.4, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.14285714285714288, 0.22222222222222224, 0.09523809523809523]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 12, "before_eval": {"predictions": ["British rock group Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "counter-parry", "Margaret Thatcher", "Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government", "Minos and Kokalos", "29 June 1941", "quintero", "byker grove", "New South Wales", "Fort Bull, and Fort Williams (the latter two located on the Oneida Carry between the Mohawk River and Wood Creek at present-day Rome, New York )", "Dandy", "ferrisia", "Orwell", "Czech Kingdom", "Gregg Popovich", "that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "adaptive immune system", "Mexican drug lord", "British fantasy author and game designer", "tunisia", "December 1, 1969", "american", "jK Rowling", "California State Automobile Association and the Automobile Club of Southern California", "\"alone\"", "Cinderella", "The astronauts were asphyxiated before the hatch could be opened", "due to a fear of seeming rude"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24040272485512423}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.15384615384615385, 0.0, 0.0, 1.0, 0.5263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.23529411764705882, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.16666666666666666, 0.631578947368421]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "retrieved_ids": ["mrqa_naturalquestions-train-57034", "mrqa_naturalquestions-train-9555", "mrqa_naturalquestions-train-71485", "mrqa_naturalquestions-train-54788", "mrqa_naturalquestions-train-45574", "mrqa_naturalquestions-train-66462", "mrqa_naturalquestions-train-11573", "mrqa_naturalquestions-train-56274", "mrqa_naturalquestions-train-33832", "mrqa_naturalquestions-train-66907", "mrqa_naturalquestions-train-5253", "mrqa_naturalquestions-train-67482", "mrqa_naturalquestions-train-27861", "mrqa_naturalquestions-train-60944", "mrqa_naturalquestions-train-40217", "mrqa_naturalquestions-train-14462", "mrqa_naturalquestions-train-18109", "mrqa_naturalquestions-train-24678", "mrqa_naturalquestions-train-24648", "mrqa_naturalquestions-train-5350", "mrqa_naturalquestions-train-68798", "mrqa_naturalquestions-train-84073", "mrqa_naturalquestions-train-55487", "mrqa_naturalquestions-train-6263", "mrqa_naturalquestions-train-9959", "mrqa_triviaqa-validation-365", "mrqa_hotpotqa-validation-3971", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-6389", "mrqa_triviaqa-validation-3074", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-6844"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Jason Lee", "Napoleon's army", "maryland", "3.7", "a negative effect on subsequent long-run economic growth", "tracey Stubbs", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "maryland", "April 6, 2010", "amyotrophic lateral sclerosis (ALS)", "odorama", "a pioneer in watch design, manufacturing and distribution", "mid 1970s", "Religious and spiritual teachers, such as gurus, mullahs, rabbis, pastors/youth pastors and lamas, may teach religious texts such as the Quran, Torah or Bible", "on the western coast of Italy", "the first and only U.S. born world grand prix champion", "the quintessential New Orleans art form -- a jazz funeral without a body", "mid November", "Facebook", "mohnbeugel", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Issaquah, Washington (a suburb of Seattle)", "territories of conflicting territorial claims between British and French colonies", "he cheated on Miley", "alternative rock", "Fort Saint Anthony", "n\u00e9pce", "infrequent rain and many sunny days"], "metric_results": {"EM": 0.15625, "QA-F1": 0.27688943001443}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.25, 0.33333333333333337, 0.0, 0.2, 1.0, 1.0, 0.0, 0.5]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "mithilimackinac", "mquito Coast", "FX option", "electromagnetic waves", "Wahhabi/ Salafi", "good luck", "Dimensions in Time", "Surveyor 3", "the end of January 1981", "lutein - releasing hormone ( GnRH )", "baptism", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "\u00a31 million", "slowing the vehicle", "Cheyenne", "fossils in sedimentary rocks", "Hanna- Barbera", "\"comune\" in the heart of the southern (Dolomitic) Alps in the Veneto region of Northern Italy", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "fox and Duchess of Sto Helit", "fox Vez de Torres", "Timo Hildebrand", "public sector ( also called the state sector )", "February 1940", "weak government institutions", "a god of the Ammonites, as well as Tyrian Melqart and others", "eye (orbital) sockets in the skull", "Fester Addams", "homicidal sniper Bobby Thompson"], "metric_results": {"EM": 0.125, "QA-F1": 0.26016383534765886}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.5555555555555556, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4615384615384615, 0.0, 0.0, 0.0, 0.28571428571428575]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "San Antonio", "King da 5'9\" ( bad) and Eminem ( Evil)", "jupiter (now known as the Galilean moons, as well as the rings of Saturn", "a friend and publicist", "michael ondaatje", "masons'marks", "George Haynes (1989)", "Gateshead", "The horn line at the end is performed by the Phenix Horns from Earth, Wind & Fire", "The neck", "1898", "professional wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "vito corleone", "johniss jN-4", "art", "gorillas", "March 15, 1945", "absolute temperature", "the private intelligence firm Stratfor and releasing the leaks through the whistle-blowing website", "American theoretical physicist and professor of physics at the University of California, Berkeley", "bicuspid", "his brother, Menelaus", "25 November 2015", "tallahassee", "prefabricated housing projects", "London", "WOTV"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11011904761904763}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09523809523809525, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "retrieved_ids": ["mrqa_naturalquestions-train-30989", "mrqa_naturalquestions-train-53849", "mrqa_naturalquestions-train-64972", "mrqa_naturalquestions-train-25217", "mrqa_naturalquestions-train-39125", "mrqa_naturalquestions-train-34330", "mrqa_naturalquestions-train-32623", "mrqa_naturalquestions-train-79256", "mrqa_naturalquestions-train-17906", "mrqa_naturalquestions-train-22416", "mrqa_naturalquestions-train-72271", "mrqa_naturalquestions-train-1378", "mrqa_naturalquestions-train-25559", "mrqa_naturalquestions-train-34884", "mrqa_naturalquestions-train-37085", "mrqa_naturalquestions-train-55840", "mrqa_naturalquestions-train-55802", "mrqa_naturalquestions-train-47932", "mrqa_naturalquestions-train-82282", "mrqa_naturalquestions-train-41513", "mrqa_naturalquestions-train-72141", "mrqa_naturalquestions-train-40090", "mrqa_naturalquestions-train-71898", "mrqa_naturalquestions-train-4822", "mrqa_naturalquestions-train-29496", "mrqa_naturalquestions-validation-868", "mrqa_triviaqa-validation-6556", "mrqa_squad-validation-4060", "mrqa_hotpotqa-validation-3161", "mrqa_squad-validation-4283", "mrqa_naturalquestions-validation-8948", "mrqa_triviaqa-validation-7332"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 16, "before_eval": {"predictions": ["albin", "cow's milk cheese", "benedict", "on the lateral side of the tibia", "ferguside royal clan", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "Ximena Sari\u00f1ana Rivera", "Amway", "secondary school study", "Thomas Sowell", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "the Royal Albert Hall", "kPMG (T) Limited", "Chad", "60-mile-wide river", "an open work crown", "a child to go through a torturous treatment to gain information", "London", "French", "kathy Sweeney", "U.S. Marshals", "What's Up (TV series)", "supply chain management", "Mars rover", "Poland's Last King and English Culture", "polynomial algebra", "michael J. Fox", "three wise monkeys", "sheepskin", "Honolulu County, Hawaii, United States, on the island of Oahu"], "metric_results": {"EM": 0.09375, "QA-F1": 0.13506181318681318}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 1.0, 0.30769230769230765]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-2287"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["milk soft cheese", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "stable, non-radioactive rubidium - 85", "James Zeebo", "sovereign states", "president of the United States", "The Discovery Institute (DI) is a politically conservative non-profit think tank based in Seattle, Washington, best known for its advocacy of the pseudoscientific principle of intelligent design (ID)", "Bumblebee", "Australian", "men was 30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months for men and 24 months for women respectively. )", "opportunities will vary by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Carl Mears", "\"antiforms\" or where it buckles downwards, creating \"synforms\"", "the fifth and sixth seasons", "\"Veyyil\" (2006)", "Grace Nail Johnson", "Keith Richards", "at least one prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "students learn from teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "at which longitude is defined to be 0 \u00b0", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat", "33", "grapevines", "Annual Conference Cabinet", "bronze medal", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.125, "QA-F1": 0.2701966021451315}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.08333333333333334, 0.0, 0.0, 0.0, 0.0, 0.41025641025641024, 0.19999999999999998, 0.16, 0.0, 0.0, 0.2222222222222222, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.23529411764705882, 0.25, 0.07407407407407407, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide", "harmoniously", "500 metres", "Diondre Cole", "the entertainment division", "from a point A to a point B", "12", "the Great Exhibition of 1851", "Edward I", "sand bar", "dundee palgrave.rlp.5100074", "the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "1587", "\"Grindhouse\" fake trailer", "davenport", "digital transmission", "the Swiss- Austrian border", "lithium-ion battery", "821", "Sky channels", "liquid", "Kim Hyun-ah", "Great Britain", "transposition changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music", "the \" King of Cool\"", "President Woodrow Wilson", "davis", "the fifth season", "davis dors", "Hockey Club Davos", "Michael Crawford", "Firoz Shah Tughlaq"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2844494047619048}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.25, 0.0, 0.6666666666666666, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511"], "retrieved_ids": ["mrqa_naturalquestions-train-86272", "mrqa_naturalquestions-train-22660", "mrqa_naturalquestions-train-18758", "mrqa_naturalquestions-train-79742", "mrqa_naturalquestions-train-21950", "mrqa_naturalquestions-train-45749", "mrqa_naturalquestions-train-49723", "mrqa_naturalquestions-train-72193", "mrqa_naturalquestions-train-75923", "mrqa_naturalquestions-train-28667", "mrqa_naturalquestions-train-25706", "mrqa_naturalquestions-train-36951", "mrqa_naturalquestions-train-6298", "mrqa_naturalquestions-train-55777", "mrqa_naturalquestions-train-77493", "mrqa_naturalquestions-train-5304", "mrqa_naturalquestions-train-38553", "mrqa_naturalquestions-train-40275", "mrqa_naturalquestions-train-77158", "mrqa_naturalquestions-train-25352", "mrqa_naturalquestions-train-13025", "mrqa_naturalquestions-train-63863", "mrqa_naturalquestions-train-48859", "mrqa_naturalquestions-train-69110", "mrqa_naturalquestions-train-13898", "mrqa_triviaqa-validation-1770", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-4268", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-683", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9451"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "Norman Macdonnell", "aragon", "11.1", "the first trans-Pacific flight from the United States to Australia", "Sharman Joshi", "sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "a sufficient condition for p to be prime", "Ana", "New Brunswick", "the end of `` Goodbye Toby ''", "f. O. Matthiessen", "beryl Markham", "a 1993 American comedy - drama film directed by Fred Schepisi, adapted from the Pulitzer Prize - nominated John Guare play of the same name", "Blackstar", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1974", "Nicki Minaj", "slave of duty", "Huguenot", "f1", "friedrich", "The Fairly OddParents", "William the Conqueror", "Sde Dov Airport", "two degrees of freedom", "Mainland Greece", "phlebotomists", "Guinness World Records", "Southern Progress Corporation"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22346455627705625}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.13333333333333333, 1.0, 0.2857142857142857, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.08333333333333334, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 20, "before_eval": {"predictions": ["reciprocating", "David Feldman", "the Sackler Centre for arts education", "The Hard Way ( 1991 film)", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "AS-205", "ribosomal", "kookaburra", "six-time Silver Slugger Award winner", "Vanessa Ferlito", "I Swear", "Cozonac", "davis", "a heliocentric orbit", "Lucius Cornelius Sulla Felix", "Super Bowl LII, following the 2017 season", "Golden Globe", "a distinct local dialect, Kenyan English", "trust God's word", "w Faulkner", "a CMYKOG process", "an earthquake", "\" My Love from the Star\" (2013)", "San Jose", "sea wasp", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "the most giving Super Bowl ever", "29.7 percent", "davis pierce"], "metric_results": {"EM": 0.25, "QA-F1": 0.37040945165945166}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.48484848484848486, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_triviaqa-validation-6721", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 21, "before_eval": {"predictions": ["from a Czech word, robota, meaning `` forced labor ''", "Rebecca", "various registries", "blood", "Yazoo", "22 April 1894", "black hole", "dreams", "as defence of their North American colonies would no longer be an issue and also because they already had ample places from which to obtain sugar", "Willie Nelson and Kris Kristofferson", "Manson & Woods", "12 California State University campuses (Bakersfield, Channel Islands, Dominguez Hills, Fullerton, Los Angeles, Long Beach, Northridge, Pomona, San Bernardino, San Diego, San Marcos, and San Luis Ob", "a French pirate", "Lewis", "Charles Dickens and Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "fats, fatty acids, amino acids, and proteins", "2001", "(i.e. exceeds any given number) so there must be infinitely many primes", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "Tallemaja \"pine tree Mary\"", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "James Bond", "640 \u00d7 1136 at 326 ppi", "fillies", "eating both fish larvae and small crustaceans that would otherwise feed the adult fish", "\"Menace II Society\"", "backup quarterback", "a trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.21875, "QA-F1": 0.33589402043712224}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, true], "QA-F1": [0.13333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.3111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.4210526315789474, 0.25, 1.0, 0.5, 0.0, 0.23529411764705882, 1.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.22222222222222224, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-3627", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758"], "retrieved_ids": ["mrqa_naturalquestions-train-80356", "mrqa_naturalquestions-train-75794", "mrqa_naturalquestions-train-10980", "mrqa_naturalquestions-train-56525", "mrqa_naturalquestions-train-41130", "mrqa_naturalquestions-train-8564", "mrqa_naturalquestions-train-47423", "mrqa_naturalquestions-train-37689", "mrqa_naturalquestions-train-40168", "mrqa_naturalquestions-train-28001", "mrqa_naturalquestions-train-84156", "mrqa_naturalquestions-train-18604", "mrqa_naturalquestions-train-77254", "mrqa_naturalquestions-train-80337", "mrqa_naturalquestions-train-72298", "mrqa_naturalquestions-train-6449", "mrqa_naturalquestions-train-6014", "mrqa_naturalquestions-train-48819", "mrqa_naturalquestions-train-39964", "mrqa_naturalquestions-train-27083", "mrqa_naturalquestions-train-21930", "mrqa_naturalquestions-train-34044", "mrqa_naturalquestions-train-66480", "mrqa_naturalquestions-train-2668", "mrqa_naturalquestions-train-10406", "mrqa_triviaqa-validation-6351", "mrqa_triviaqa-validation-1935", "mrqa_squad-validation-6399", "mrqa_hotpotqa-validation-5325", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-3071", "mrqa_naturalquestions-validation-6523"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "MSC Crociere S. p.A.", "rICHARD CARLSON, The Don't Sweat Guide to Taxes", "Kitty Softpaws", "The centre- left Australian Labor Party (ALP) the centre-right Liberal Party of Australia", "Royalists", "cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "are ceremonially placed on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "death to spies", "20,000 leagues under the sea and Around the world in 80 days", "Augustus Waters", "14 September 1547", "Tony Blair: The Journey", "\u2018expensive damaging\u2019, along with alcohol, tobacco and gambling", "June 11, 1973", "in Kenya and in the Masai Mara in particular", "Timeline of Shakespeare criticism", "boudicca", "an active supporter of the League of Nations", "Cargill", "AMC Entertainment Holdings, Inc.", "\"The Gang\"", "3 October 1990", "March 1, 2018", "The weak force is due to the exchange of the heavy W and Z bosons", "daedalus", "Martin Luther King Jr.", "Manhattan Project", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22492827434003904}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.39999999999999997, 0.33333333333333337, 0.11764705882352942, 0.16, 0.0, 0.0, 0.3636363636363636, 0.0, 0.8, 0.0, 0.0, 0.4, 0.22222222222222224, 0.0, 0.1818181818181818, 0.0, 0.3333333333333333, 0.0, 0.2, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_naturalquestions-validation-1328"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "disco and Romola", "red lead primer and a lead - based topcoat", "Steeplechase Park", "animated film", "European Union institutions", "381.6 days", "nine", "CAL IPSO", "vitis", "Ulbricht", "Ronnie Schell", "artemisin- Based therapy", "Mumbai, Maharashtra", "east", "1940", "the 2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "midlands of the river Niger Benue trough to over 2,000 mm ( 78.7 in ) along the south western escarpment of the Jos Plateau", "benanga", "Incudomalleolar joint", "bobby riggs", "Democritus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth", "bound on the complexity of reductions", "Corey Brown"], "metric_results": {"EM": 0.28125, "QA-F1": 0.37931502525252525}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.25, 1.0, 0.25, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.3636363636363636, 1.0, 0.0, 0.08, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-769"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "photosystem II", "Pitt", "alchemy", "WBC and lineal titles", "moluccas", "the Kentucky Derby and Belmont Stakes", "alison ( in the Quarto version )", "began multilateral negotiations", "1971", "J.R. R. Tolkien", "Peyton Manning", "Selena Gomez", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "bingo", "Eugene", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze", "nine", "the Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor", "CD Castell\u00f3n", "between 1770 and 1848", "12", "having colloblasts", "Jon M. Chu", "STS-51-L", "due to clear weather", "mitterrand"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3118468055968056}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.7692307692307693, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.21621621621621626, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-67", "mrqa_hotpotqa-validation-4542", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "retrieved_ids": ["mrqa_naturalquestions-train-72882", "mrqa_naturalquestions-train-17388", "mrqa_naturalquestions-train-58099", "mrqa_naturalquestions-train-15393", "mrqa_naturalquestions-train-55128", "mrqa_naturalquestions-train-87655", "mrqa_naturalquestions-train-13661", "mrqa_naturalquestions-train-2153", "mrqa_naturalquestions-train-29244", "mrqa_naturalquestions-train-14124", "mrqa_naturalquestions-train-28127", "mrqa_naturalquestions-train-72842", "mrqa_naturalquestions-train-27058", "mrqa_naturalquestions-train-43604", "mrqa_naturalquestions-train-52884", "mrqa_naturalquestions-train-28900", "mrqa_naturalquestions-train-21162", "mrqa_naturalquestions-train-28809", "mrqa_naturalquestions-train-81838", "mrqa_naturalquestions-train-75713", "mrqa_naturalquestions-train-50186", "mrqa_naturalquestions-train-2318", "mrqa_naturalquestions-train-78237", "mrqa_naturalquestions-train-77548", "mrqa_naturalquestions-train-36732", "mrqa_squad-validation-9074", "mrqa_naturalquestions-validation-5215", "mrqa_hotpotqa-validation-2771", "mrqa_squad-validation-769", "mrqa_triviaqa-validation-6935", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-6915"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 25, "before_eval": {"predictions": ["swimming", "slave", "over 50 million singles", "states'rights to expand slavery", "between 1923 and 1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "Buck Barrow", "iteratively", "yellowish red bills and legs", "income inequality will eventually decrease given time", "france", "Sylvester McCoy", "August 14, 1848", "lower rates of social goods", "juveniles are capable of reproduction before reaching the adult size and shape", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "A Chorus Line", "2,664", "iPhone 6 Plus", "through a chute beneath his or her feet", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning services, support services, property services, catering services, security services and facility management services", "Violin Sonata No. 5", "zhee rond", "1603", "above the two personal physicians of the Emperor", "sugar Plum", "to improve our conscious contact with God as we understood Him, praying only for knowledge of His will for us and the power to carry that out", "wrigley field"], "metric_results": {"EM": 0.15625, "QA-F1": 0.383595036177273}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.33333333333333337, 0.7200000000000001, 0.4615384615384615, 0.923076923076923, 0.0, 1.0, 1.0, 0.923076923076923, 0.3636363636363636, 0.4444444444444445, 0.28571428571428575, 0.0, 1.0, 0.10526315789473684, 0.8, 0.15384615384615388, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences, with the Romans serving as external arbiters on disputes concerning Jewish customs and law", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "true history of the Kelly Gang", "Waialua District of the island of O\u02bb ahu, City and County of Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "australia", "4,000", "Khagan", "Heathcliff", "river", "spice", "He was voiced by Phil Hartman and first appeared in the second season episode \"Homer vs. Lisa and the 8th Commandment\"", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "one of the finest streets in England", "Albany High School for Educating People of Color", "charbagh", "a non-commissioned officer in the United States Army's premier special operations unit, the 1st Special Forces Operational Detachment- Delta (1SFOD-D) or \" Delta Force\"", "Anakin Skywalker", "They must decide whether their primary goal will be to win an acquittal and avoid imprisonment or a fine, or to use the proceedings as a forum to inform the jury and the public of the political circumstances surrounding the case", "Cee - Lo", "Anglican", "mammy two Shoes", "duke of York", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "redistributive", "January 11, 1755 or 1757"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3386291200629436}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.2222222222222222, 0.19999999999999998, 0.0, 0.33333333333333337, 0.5882352941176471, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.05714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8000000000000002]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_hotpotqa-validation-4585", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 27, "before_eval": {"predictions": ["l.A. producer Bones Howe", "jools Holland", "blackberry and dewberry", "o Orion", "Big Mamie", "trinidad and Tobago", "the sardonic drifter", "a light sky-blue color caused by absorption in the red", "they captured the Tower of London", "1963", "2005\u201306", "inner mitochondria membrane", "aline Charigot", "sports tourism", "BSkyB has no veto", "the fourth season", "a more fundamental electrostrong interaction", "availability of skilled tradespeople", "diamond", "A simple iron boar crest adorns the top of this helmet", "Northumbria at Newcastle in 1992", "curtin", "James David", "25 - yard line", "from the Latin centum, which means 100, and gradus", "about 7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "the Bible speaks", "margaret franklin", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "group"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2681180798368298}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.75, 0.28571428571428575, 0.0, 0.6153846153846153, 0.0, 0.0, 0.6666666666666666, 0.375, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "retrieved_ids": ["mrqa_naturalquestions-train-21813", "mrqa_naturalquestions-train-10518", "mrqa_naturalquestions-train-31766", "mrqa_naturalquestions-train-67874", "mrqa_naturalquestions-train-59482", "mrqa_naturalquestions-train-85681", "mrqa_naturalquestions-train-13361", "mrqa_naturalquestions-train-33800", "mrqa_naturalquestions-train-39788", "mrqa_naturalquestions-train-64717", "mrqa_naturalquestions-train-41724", "mrqa_naturalquestions-train-11908", "mrqa_naturalquestions-train-34908", "mrqa_naturalquestions-train-50871", "mrqa_naturalquestions-train-70314", "mrqa_naturalquestions-train-69675", "mrqa_naturalquestions-train-27241", "mrqa_naturalquestions-train-25840", "mrqa_naturalquestions-train-74871", "mrqa_naturalquestions-train-32495", "mrqa_naturalquestions-train-54576", "mrqa_naturalquestions-train-15755", "mrqa_naturalquestions-train-60750", "mrqa_naturalquestions-train-49753", "mrqa_naturalquestions-train-76801", "mrqa_squad-validation-5210", "mrqa_naturalquestions-validation-6157", "mrqa_squad-validation-3463", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-5823", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-639"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 28, "before_eval": {"predictions": ["a tool of the devil", "Chris Weidman", "jury nullification", "Harishchandra", "poet", "Professor Eobard Thawne", "plum brandy", "a US$10 a week raise", "1875", "member states", "oboe", "McKinsey's offices in Silicon Valley and India and created its Internet practice", "ophidiophobia", "living doll", "Crohn's disease", "Ondemar Dias", "Raya Yarbrough", "Cincinnati and No. 3 seed Tennessee", "heavyweight", "businessmen Charles L. Hutchinson (trustee, treasurer and donor of Hutchinson Commons)", "Old Testament", "brown", "touring productions", "Football League", "tristan Farnon", "mcdaniel", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "John Surratt, Jr.", "1332", "dodo bird", "a person can improve their own health, wealth and personal relationships", "bus driver"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29736590038314176}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4444444444444445, 1.0, 0.2857142857142857, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 1.0, 1.0, 0.13793103448275862, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_squad-validation-5086", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 29, "before_eval": {"predictions": ["holly berries", "886 AD", "used to finance his own projects", "Le Mans", "Kinect", "Tokyo", "safety Darian Stewart", "the parallelogram rule of vector addition", "public speaking", "364", "a neutron source used for stable and reliable initiation of nuclear chain reaction in nuclear reactors, when they are loaded with fresh nuclear fuel, whose neutron flux from spontaneous fission is insufficient for a reliable startup, or after prolonged shutdown periods", "van Gogh", "the bore, and often the stroke, are increased in low-pressure cylinders resulting in larger cylinders", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the Imperial Secretariat", "Doctorin' the Tardis", "National Basketball Development League (NBDL)", "river Medway", "Baltimore -- Washington metropolitan area", "Ted Ginn Jr.", "2,615", "Pyeongchang", "athlete", "a password recovery tool for Microsoft Windows", "Homeless Man", "Charles and Ray Eames", "Brazil", "Hollingsworth", "the smallest subfield", "heartburn", "53%", "chloroplasts are specialized for each stage of photosynthesis."], "metric_results": {"EM": 0.1875, "QA-F1": 0.3551368464052288}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.6666666666666666, 0.0, 0.25, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.38095238095238093, 0.0, 1.0, 0.888888888888889, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 0.058823529411764705, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "the Mayor's son", "slavery", "prunella", "I'm Dickens, He's Fenster", "BBC UKTV", "mikael blomkvist", "demographics and economic ties", "three or more", "The Kickoff Game", "narcolepsy", "arctic monkeys", "Bernie Ecclestone", "rudian", "usernames, passwords, commands and data", "A computer program is a collection of instructions that performs a specific task when executed by a computer. A computer requires programs to function.", "The Greens, who won their first lower house seats in 2014, are strongest in inner Melbourne.", "marduk", "hekla", "representing Kenya's largest source of foreign direct investment", "public speaking", "off the northeast coast of Australia", "Article 7, Paragraph 4", "New Jersey to the east", "Easy", "Meredith Brody ( Zoe McLellan ), a transfer from the NCIS Great Lakes field office, who has worked as a Special Agent Afloat and is keen to leave her past behind as she moves to New Orleans", "Lal Bahadur Shastri", "National Lottery", "Apollo", "katherine swynford", "facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.03125, "QA-F1": 0.12800421703769227}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.125, 0.0, 0.0, 0.9333333333333333, 0.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "retrieved_ids": ["mrqa_naturalquestions-train-20135", "mrqa_naturalquestions-train-17702", "mrqa_naturalquestions-train-48710", "mrqa_naturalquestions-train-83516", "mrqa_naturalquestions-train-59889", "mrqa_naturalquestions-train-4214", "mrqa_naturalquestions-train-74736", "mrqa_naturalquestions-train-24272", "mrqa_naturalquestions-train-79566", "mrqa_naturalquestions-train-21724", "mrqa_naturalquestions-train-68428", "mrqa_naturalquestions-train-40715", "mrqa_naturalquestions-train-44926", "mrqa_naturalquestions-train-61856", "mrqa_naturalquestions-train-59003", "mrqa_naturalquestions-train-19588", "mrqa_naturalquestions-train-42247", "mrqa_naturalquestions-train-81273", "mrqa_naturalquestions-train-29537", "mrqa_naturalquestions-train-43494", "mrqa_naturalquestions-train-38585", "mrqa_naturalquestions-train-34466", "mrqa_naturalquestions-train-1326", "mrqa_naturalquestions-train-25381", "mrqa_naturalquestions-train-17797", "mrqa_naturalquestions-validation-3300", "mrqa_hotpotqa-validation-5383", "mrqa_squad-validation-8876", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-5818", "mrqa_squad-validation-194", "mrqa_naturalquestions-validation-7224"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 31, "before_eval": {"predictions": ["yolanda Sald\u00edvar", "Thiel", "skaters", "skylab", "crossroads of the Newell Highway between Melbourne and Brisbane, and the Mid- Western Highway between Sydney and Adelaide", "androids", "surt", "a shopping mall located in Bloomington, Minnesota, United States ( a suburb of the Twin Cities )", "Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions", "DreamWorks Animation", "Johann Strauss", "a khuruldai", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "arthur", "the RAF", "reduce growth in relatively poor countries but encourage growth", "Ibbi-Sipish", "skylab", "Polish-Jewish", "a variety of political groups that supported the Spanish coup of July 1936 against the Second Spanish Republic, including the Falange, the CEDA, and two rival monarchist claimants : the Alfonsists and the Carlists", "spain", "ottoexeter", "390 billion", "Washington Street between Boylston Street and Kneeland Street", "May 10, 1976", "six", "lohan", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "surtsey", "Paul the Apostle", "surtania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.0, "QA-F1": 0.0904611013986014}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.15384615384615385, 0.7272727272727273, 0.0, 0.0, 0.0, 0.37037037037037035, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.07407407407407407, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.45000000000000007, 0.0, 0.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_hotpotqa-validation-1444", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-3728", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "beer", "gender test", "Matt Jones", "kalium", "extreme circumstances", "CD4+ and CD8+", "relatively low salaries", "fruit", "Heading Out to the Highway", "Moonraker", "$12.99", "Michael Oppenheimer", "England national team", "entitled institutionally and legally", "Planet Name Game", "Convention", "the Declaration of Independence", "December 5, 1991", "a 2016 science fiction psychological horror", "Philadelphia 76ers", "the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "Stern-Plaza", "WBC/WBA heavyweight champion Joe Frazier", "23 March 1991", "Monday", "Dealey Plaza", "Nairobi", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2791035353535354}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.13333333333333333, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\"Boston Herald\" Rumor Clinic", "1967", "\"Footprints in the Sand\"", "the twelfth most populous city in the United States", "50", "cuthbert calculus", "is a hyper - active kinase, that confers an aberrant, ligand - independent, non- regulated growth stimulus to the cancer cells", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Tevye", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country, hugging the east side of the Mississippi River and its tributaries", "japan", "seam", "Yunnan- Fu", "London, United Kingdom", "Broken Hill and Sydney", "2005", "all punishments and granted them salvation", "\" Smith and Jones\"", "cooper: a person who made or repaired barrels, wooden casks, kegs, or tubs", "lincoln", "things that are a matter of custom or expectation, such as isolating businesses to a business district and residences to a residential district", "1879", "daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "enthusiasm and energy of the teacher", "Japan", "passenger space and amenities such as air conditioning, power steering, AM-FM radios, and even power windows and central locking without increasing the price of the vehicle", "Arkansas", "Oslo county"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3037601369219016}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8666666666666666, 0.08, 0.0, 0.0, 0.12121212121212123, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 1.0, 0.15384615384615385, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "retrieved_ids": ["mrqa_naturalquestions-train-17771", "mrqa_naturalquestions-train-36755", "mrqa_naturalquestions-train-42051", "mrqa_naturalquestions-train-16917", "mrqa_naturalquestions-train-85306", "mrqa_naturalquestions-train-54635", "mrqa_naturalquestions-train-77052", "mrqa_naturalquestions-train-17407", "mrqa_naturalquestions-train-35855", "mrqa_naturalquestions-train-34221", "mrqa_naturalquestions-train-26290", "mrqa_naturalquestions-train-53677", "mrqa_naturalquestions-train-34824", "mrqa_naturalquestions-train-51004", "mrqa_naturalquestions-train-12503", "mrqa_naturalquestions-train-81334", "mrqa_naturalquestions-train-22215", "mrqa_naturalquestions-train-2512", "mrqa_naturalquestions-train-28565", "mrqa_naturalquestions-train-77610", "mrqa_naturalquestions-train-75496", "mrqa_naturalquestions-train-84574", "mrqa_naturalquestions-train-80556", "mrqa_naturalquestions-train-75179", "mrqa_naturalquestions-train-65548", "mrqa_naturalquestions-validation-5312", "mrqa_squad-validation-3368", "mrqa_naturalquestions-validation-3533", "mrqa_triviaqa-validation-7157", "mrqa_triviaqa-validation-7669", "mrqa_naturalquestions-validation-1731", "mrqa_squad-validation-4662"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "queen's wedding dress", "Threatening government officials", "Veronica / Archie Marries Betty", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "boulangere", "0.2 inhabitants per square kilometre", "peter Carter", "France", "Ian Paisley", "bataan Death March", "euro", "ups", "Imperial Japan's victory in the Russo - Japanese War, with its subsequent withdrawal of Russian influence, and the Taft -- Katsura Agreement, in which the United States allegedly agreed not to interfere with Japan in matters concerning Korea", "Sherry Rowland", "in The Nursery Rhymes of England ( London and New York, c. 1886 ), by James Halliwell - Phillipps", "2012 St. Louis Rams season", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "juba", "rotation axes", "Johnny Darrell", "carotid artery disease", "all margarine to be in cube shaped packages", "Euler's totient function or the sum of divisors function", "ear canal", "binary strings", "Busiest airports in the United States by international passenger traffic", "red", "Toyota Corona", "American writer and satirist Kurt Vonnegut", "princess Rapunzel"], "metric_results": {"EM": 0.09375, "QA-F1": 0.17200647971739302}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.3529411764705882, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.05882352941176471, 0.0, 0.10526315789473685, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "supply and demand", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "urecchiette", "Washington Redskins", "in the courtyard adjoining the Assembly Hall", "William Howard Ashton", "national security, big oil companies and bribery and corruption at the highest levels of the government of the United States", "social dislocation, unrest and conflict", "Broward County", "Song Kang-ho, Lee Byung-hun, and Jung Woo-sung", "changing display or audio settings quickly", "first Civil War", "from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "GDP growth actually declines over the medium term", "Beauty and the Beast", "south africa", "Scotty Grainger Jr. is a fictional character from the CBS soap opera \"The Young and the Restless\"", "alamo", "a seal illegally is broken", "the UMC", "Brian Liesegang", "Roger Allers and Rob Minkoff", "Port Moresby", "alvin and the Chipmunks", "National Association for the Advancement of Colored People", "1963\u20131989", "icebergs", "sudden death of incumbent leader John Smith", "darrin Stephens", "6500 - 1500 BC"], "metric_results": {"EM": 0.15625, "QA-F1": 0.29063835470085475}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.5, 0.28571428571428575, 0.14285714285714288, 0.4, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4615384615384615, 0.25, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 36, "before_eval": {"predictions": ["National Broadcasting Company", "Amber Laura Heard", "Uranus", "president", "Cobham\u2013Edmonds thesis", "human", "Best Male Pop Vocal Performance", "March 2012", "jazz", "Muhammad Ali", "Coldplay", "Menorca", "to civil disobedients", "Julius Caesar", "2", "1979", "Easter egg", "formal language", "10th", "lungs", "Miasma theory", "pint of 20 imperial fluid ounces ( 568 ml ) or an American pint of 16 US fluid ounces", "mountain ranges", "red", "other states", "nettle", "US", "20 %", "love", "to build a nationwide network in the UK", "roughly west", "Sudan"], "metric_results": {"EM": 0.34375, "QA-F1": 0.3983604845446951}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.2222222222222222, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_squad-validation-3635", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "retrieved_ids": ["mrqa_naturalquestions-train-78842", "mrqa_naturalquestions-train-85748", "mrqa_naturalquestions-train-3808", "mrqa_naturalquestions-train-52681", "mrqa_naturalquestions-train-74729", "mrqa_naturalquestions-train-28453", "mrqa_naturalquestions-train-5493", "mrqa_naturalquestions-train-59576", "mrqa_naturalquestions-train-48780", "mrqa_naturalquestions-train-76657", "mrqa_naturalquestions-train-27423", "mrqa_naturalquestions-train-17789", "mrqa_naturalquestions-train-7658", "mrqa_naturalquestions-train-40941", "mrqa_naturalquestions-train-10731", "mrqa_naturalquestions-train-66698", "mrqa_naturalquestions-train-63229", "mrqa_naturalquestions-train-66396", "mrqa_naturalquestions-train-76582", "mrqa_naturalquestions-train-80689", "mrqa_naturalquestions-train-7493", "mrqa_naturalquestions-train-55532", "mrqa_naturalquestions-train-80063", "mrqa_naturalquestions-train-23998", "mrqa_naturalquestions-train-67525", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-5078", "mrqa_triviaqa-validation-3808", "mrqa_naturalquestions-validation-9765", "mrqa_squad-validation-8037", "mrqa_triviaqa-validation-3408", "mrqa_hotpotqa-validation-3508"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "three of his ribs were broken", "7 December 2000", "Post Alley under Pike Place Market", "mother-of-pearl", "February 20, 1978", "stomach", "Walter Mondale", "96", "first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "american", "black", "the alluvial plain", "around 11 miles (18 km) south of San Jose", "Spotty", "Rumplestiltskin", "Carlos Tevez", "many types of lizard including the vulnerable great desert skink ( Egernia kintorei ) and a number of small marsupials", "many events and festivals", "riper", "1991", "indon", "7 January 1936", "lifetime protection", "twenty-83 episodes", "Carl Sagan", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Christian Poulsen", "defiant speech", "sour cream", "Boston, Massachusetts"], "metric_results": {"EM": 0.25, "QA-F1": 0.3188465956558062}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.2777777777777778, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 38, "before_eval": {"predictions": ["NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "buffalo", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "a children's story published by John Newbery in London in 1765", "243 days", "gathering money from the public", "Eden and Thorgan", "commissioned officers are given a one - time stipend when commissioned to purchase their required uniform items. Officers then maintain proper fit and appearance of their uniform items throughout their career", "Jeff Meldrum", "741 weeks", "phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "emigrant Ship to Australia", "34", "journalist", "to compensate for the fact that there is no revising chamber", "clothing", "the points of algebro-geometric objects", "most of the items in the collection, unless those were newly accessioned into the collection, probably don't show up in the computer system", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "strychnine", "Texas", "the early 16th century", "Lord's", "Eddy Shah", "Darleen Carr", "in sequence with each heartbeat"], "metric_results": {"EM": 0.125, "QA-F1": 0.2351858363908731}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.09523809523809523, 0.0, 0.0, 0.4, 0.47058823529411764, 0.28571428571428575, 0.12903225806451613, 0.25, 0.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0, 1.0, 0.4615384615384615, 0.0, 0.0, 0.34782608695652173, 0.06451612903225806, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 39, "before_eval": {"predictions": ["capital city of a nation", "Dan Conner", "Checkpoint Charlie", "President John F. Kennedy", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "keskes", "1977", "John M. Grunsfeld, geneticist James Watson", "New York City", "the sun's been kind while I wrote this song", "2003", "antlers are dropped or shed and grown anew each and every year. They grow from pedicels located on the  frontal bone of the skull. The  small hair covered bumps on a six month old male fawn", "Fabbrica Italiana Automobili Torino", "the second Sunday of March, and standard time restarts on the first Sunday in November", "the relative units of force and mass then are fixed", "woman", "two", "August 10, 1933", "The Golden Gate Bridge", "Sochi, Russia", "those who already hold wealth have the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "B. Traven", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "oil prices", "wooded areas along creeks and lakes", "264,152", "Princeton, New Jersey", "the United States", "nearly pure O2 gas"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3687831640037522}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 0.0, 0.8, 1.0, 0.9230769230769231, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2, 1.0, 0.11764705882352941, 1.0, 0.47058823529411764, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 0.0, 0.37037037037037035, 0.3636363636363636, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "retrieved_ids": ["mrqa_naturalquestions-train-33007", "mrqa_naturalquestions-train-71004", "mrqa_naturalquestions-train-36181", "mrqa_naturalquestions-train-23962", "mrqa_naturalquestions-train-42239", "mrqa_naturalquestions-train-64645", "mrqa_naturalquestions-train-15530", "mrqa_naturalquestions-train-17268", "mrqa_naturalquestions-train-75753", "mrqa_naturalquestions-train-47715", "mrqa_naturalquestions-train-42590", "mrqa_naturalquestions-train-23721", "mrqa_naturalquestions-train-50681", "mrqa_naturalquestions-train-27608", "mrqa_naturalquestions-train-35528", "mrqa_naturalquestions-train-45538", "mrqa_naturalquestions-train-30849", "mrqa_naturalquestions-train-23357", "mrqa_naturalquestions-train-15132", "mrqa_naturalquestions-train-6213", "mrqa_naturalquestions-train-37705", "mrqa_naturalquestions-train-29514", "mrqa_naturalquestions-train-20393", "mrqa_naturalquestions-train-7433", "mrqa_naturalquestions-train-73482", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-4118", "mrqa_squad-validation-814", "mrqa_squad-validation-10180", "mrqa_squad-validation-2659", "mrqa_naturalquestions-validation-190", "mrqa_hotpotqa-validation-2262"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "ice dancing", "Isabella (Belle) Baumfree", "warren", "every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "His main interest was centered on the prophecy of the Little Horn in Daniel 8:9\u201312, 23\u201325", "Aristotle", "Charlton Heston", "anti-inflammatory molecules", "macBeth Raeburn", "Jeff Garcia", "one of the uses of money", "the Constitution", "son et lumi\u00e8re", "when the Mongols placed the Uighurs of the Kingdom of Qocho over the Koreans at the court the Korean King objected", "Sochi, Russia", "right", "Hudson Bay", "At the insistence of NASA Administrator Webb", "new Zealand", "shorthand typist", "30", "Secret Intelligence Service", "100 billion", "death", "photosynthesis", "4.7 / 5.5 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.25, "QA-F1": 0.3089963189223057}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.375, 0.10526315789473682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-1571", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_squad-validation-3932", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_squad-validation-3617", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 41, "before_eval": {"predictions": ["all war", "south Indian music teacher", "Gaels", "Three-card brag", "d\u00edsir", "lion", "Russian film industry", "delta growth", "Washington metropolitan area", "scission of newly formed vesicles from the membrane of one cellular compartment", "User State Migration Tool ( USMT )", "Ordos City China Science Flying Universe Science and Technology Co.", "Frisbee First Flew", "PPG Paints Arena, Pittsburgh, Pennsylvania ( Host : Duquesne University )", "archaeology", "Section 30", "Wilbur", "mid-1988", "quasars", "Retreating Monsoon", "Romansh", "Tudor king", "MIX 94.5", "Ian Fleming's James Bond quartermaster Q.", "the Philippians", "the division of labour, productivity, and free markets", "Gerard Marenghi (born January 24, 1920) known as Jerry Maren", "Whitney Houston", "Hugo Award", "Conservative", "king David of Israel", "Elvis Presley"], "metric_results": {"EM": 0.125, "QA-F1": 0.2589353354978355}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.33333333333333337, 0.5, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 0.2857142857142857, 1.0, 0.0, 0.7499999999999999, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 42, "before_eval": {"predictions": ["Quentin Tarantino", "parsley and parmesan cheese", "lilliput", "a clever derogatory pun on the name Hugues by way of the Dutch word Huisgenoten ( literally housemates) referring to the connotations of a somewhat related word in German Eidgenosse", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "disagreements involving slavery and states'rights", "physicians, lawyers, engineers", "mistreatment from government officials", "a large Danish shipping company that operates passenger and freight services across northern Europe", "centre-back", "rommel", "the duodenum", "the disaccharide sucrose", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "b Bryant Gumbel", "an abbreviation used in the publications of the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types", "Thursday", "yellow", "dose, route, frequency, and duration", "jupiter Mars natural disasters nature volcanoes", "aviator, polar explorer, and organizer of polar logistics", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "bobby", "The Private Education Student Financial Assistance", "bow", "to sell indulgences to raise money to rebuild St. Peter's Basilica in Rome", "colonies", "two forces, one pointing north, and one pointing east", "Bills", "Jack Murphy Stadium", "3 much more additional time or space is needed in order to increase the number of problems that can be solved"], "metric_results": {"EM": 0.15625, "QA-F1": 0.25011240291571174}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.0, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 0.2857142857142857, 0.18181818181818182, 0.13333333333333333, 0.0, 1.0, 1.0, 0.47058823529411764, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "retrieved_ids": ["mrqa_naturalquestions-train-15202", "mrqa_naturalquestions-train-7497", "mrqa_naturalquestions-train-28101", "mrqa_naturalquestions-train-3704", "mrqa_naturalquestions-train-56694", "mrqa_naturalquestions-train-1970", "mrqa_naturalquestions-train-67697", "mrqa_naturalquestions-train-11908", "mrqa_naturalquestions-train-25594", "mrqa_naturalquestions-train-40631", "mrqa_naturalquestions-train-52206", "mrqa_naturalquestions-train-11863", "mrqa_naturalquestions-train-19196", "mrqa_naturalquestions-train-72401", "mrqa_naturalquestions-train-42801", "mrqa_naturalquestions-train-44375", "mrqa_naturalquestions-train-33291", "mrqa_naturalquestions-train-4543", "mrqa_naturalquestions-train-38592", "mrqa_naturalquestions-train-25078", "mrqa_naturalquestions-train-57235", "mrqa_naturalquestions-train-32075", "mrqa_naturalquestions-train-53135", "mrqa_naturalquestions-train-26851", "mrqa_naturalquestions-train-69897", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-2222", "mrqa_triviaqa-validation-1764", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5360", "mrqa_triviaqa-validation-6331", "mrqa_naturalquestions-validation-1489"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 43, "before_eval": {"predictions": ["american Falls", "letters", "egypt", "temple", "French", "a \"homeward bounder\"", "dots", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS", "egypt", "natural-ing recipes- only personal care products", "Burl Ives", "Rigoletto", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally", "most abundant element by mass in the Earth's crust as part of oxide compounds such as silicon dioxide", "furniture", "216 countries and territories around the world", "football", "Nicholas Stone", "Algernod Lanier Washington", "the Outfield", "egypt", "Michael Edwards", "railway locomotives", "eddie fisher", "first quarter, full moon, and third quarter ( also known as last quarter )", "brian bresslaw", "chemists Glenn T. Seaborg, the developer of the actinide concept", "Tennessee", "many areas of technology incidental to rocketry and manned spaceflight, including avionics, telecommunications, and computers", "eve", "615 square kilometers", "egypt"], "metric_results": {"EM": 0.03125, "QA-F1": 0.1682228004838299}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.6, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.11764705882352942, 0.0, 0.5454545454545454, 0.4, 0.7499999999999999, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-4624", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda met Captain America in early 1941 and gave him a second sample of vibranium, an alien metal with unique vibration absorption properties and found only in Wakanda and the Savage Land", "relative cost of living, and grade taught", "2003", "cricket", "sweden", "campaign setting", "2003", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "third studio album", "Christopher Lee as Count Dooku / Darth Tyranus", "second most commonly named \"dream college\" both for students and parents in 2013", "picture book", "physicians and other healthcare professionals to improve pharmaceutical care", "increased patient health outcomes and decreased costs to the health care system", "treble clef", "Lecrae Devaughn Moore", "12002 New Delhi - Bhopal Habibganj Shatabdi Express - maximum speed 150 km / h", "between the Piazza di Spagna at the base and PIAzza Trinit\u00e0 dei Monti", "December 1, 2009", "an English campaigner for the suffragette movement, a prominent left communist and, later, an activist in the cause of anti-fascism", "euro Union", "Francis Bacon", "city status", "The Ministry of Corporate Affairs", "Irish", "the site of ancient cult activity as far back as 7th century BCE", "boston", "NADPH", "mars", "a genuine love of our neighbors as ourselves", "Christ lag in Todes Banden"], "metric_results": {"EM": 0.125, "QA-F1": 0.25812626405457284}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.3, 0.16666666666666666, 0.19999999999999998, 0.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.4, 0.7272727272727273, 0.375, 0.0, 0.15384615384615383, 0.39999999999999997, 0.0, 1.0, 0.47058823529411764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 45, "before_eval": {"predictions": ["spillane", "Cleveland Browns", "perique", "cut off close by the hip", "death penalty", "a stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "agulhas", "chr\u00e9tien de Troyes", "Mangal Pandey of the 34th BNI", "Agrippina", "Ben", "four of the 50 states", "curling", "the eighth series", "Pebble Beach", "Los Angeles", "Korean", "Henry Mills", "\"LOVE Radio\"", "The Rockies compete in Major League Baseball (MLB) as a member club of the National League (NL) West division.", "the court from its members for a three - year term", "mexico", "David Dobkin", "put an end to Saddam Hussein's occupation of Kuwait", "The Zombies", "\" Cashin' In\"", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "San Francisco Bay Area at Santa Clara, California", "fortified complex", "Normandy landings (codenamed Operation Neptune) were the landing operations on Tuesday, 6 June 1944 (termed D-Day) of the Allied invasion of Normandy in Operation Overlord during World War II.", "peninsular mainland"], "metric_results": {"EM": 0.125, "QA-F1": 0.22013566534040674}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.1111111111111111, 0.2222222222222222, 0.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.4166666666666667, 0.16666666666666669, 0.4, 0.0, 0.13793103448275862, 0.6666666666666666]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "retrieved_ids": ["mrqa_naturalquestions-train-72809", "mrqa_naturalquestions-train-46834", "mrqa_naturalquestions-train-26319", "mrqa_naturalquestions-train-16759", "mrqa_naturalquestions-train-61735", "mrqa_naturalquestions-train-21659", "mrqa_naturalquestions-train-10238", "mrqa_naturalquestions-train-79109", "mrqa_naturalquestions-train-44362", "mrqa_naturalquestions-train-31236", "mrqa_naturalquestions-train-54475", "mrqa_naturalquestions-train-9338", "mrqa_naturalquestions-train-7500", "mrqa_naturalquestions-train-7541", "mrqa_naturalquestions-train-17551", "mrqa_naturalquestions-train-51325", "mrqa_naturalquestions-train-3699", "mrqa_naturalquestions-train-21407", "mrqa_naturalquestions-train-74051", "mrqa_naturalquestions-train-54727", "mrqa_naturalquestions-train-77548", "mrqa_naturalquestions-train-71496", "mrqa_naturalquestions-train-45580", "mrqa_naturalquestions-train-57969", "mrqa_naturalquestions-train-10768", "mrqa_squad-validation-2191", "mrqa_triviaqa-validation-6692", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-1617", "mrqa_triviaqa-validation-7684", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-954"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That", "youngest person to become a national transgender figure", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Galileo Galilei and Sir Isaac Newton", "two observations", "Cameroonian", "lily", "Elizabeth Weber", "It was released for PlayStation 4 and Xbox One on May 3, 2016.", "hundreds", "\"Waiting for Guffman\"", "June 22, 1978", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "partial funding for the 20th anniversary special The Five Doctors", "5% abv draught beer", "inefficient", "Chu'Tsai", "Liz", "least onerous", "lago di Como", "Grissom, White, and Chaffee", "multinational retail corporation", "purple passion fruit", "The Natya Shastra", "high iron concentration which oxidizes upon exposure to the air", "l Samuel Ryder", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "vienna"], "metric_results": {"EM": 0.375, "QA-F1": 0.46391369047619047}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.06666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.42857142857142855, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.7499999999999999, 0.4, 0.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 47, "before_eval": {"predictions": ["George Bush", "horseracing", "New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "October 1, 2015", "one of The Canterbury Tales by Geoffrey Chaucer", "quit after five months, leaving the group as a trio", "leeds", "star", "around 74 per cent", "heathrow", "often social communities with considerable face-to-face interaction among members", "William Strauss and Neil Howe", "monophyletic", "insecticide toxicology", "candidates on specific catechism questions", "a pH indicator, a color marker, and a dye", "2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "63,182,000", "his brother Charles and fellow cleric George Whitefield", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Campbellsville", "baron w\u00fctherich", "appearing as Jude in the musical romance drama film \"On the Universe\" (2007) and released in October 2012.", "fat accumulation in his liver", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "downward pressure"], "metric_results": {"EM": 0.21875, "QA-F1": 0.35788129944960445}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.9411764705882353, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 0.5, 0.2222222222222222, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 0.11764705882352941, 0.0, 0.7368421052631579, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 48, "before_eval": {"predictions": ["James Stenbeck", "It was preceded by the release of Kendrick's debut studio album \"Section.80\" (2011) released exclusively through the iTunes Store as an independent album.", "Yosemite National Park", "Interventive treatment", "3", "Bishop Reuben H. Mueller", "ry Charles", "Goku becomes the first Saiyan in a thousand years to transform into a fabled Super Saiyan", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Roy Jenkins", "UNESCO", "Satnam Singh Bhamara", "a loop ( also called a self - loop or a `` buckle '' ) is an edge that connects a vertex to itself. A simple graph contains no loops", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California", "every good work designed to attract God's favor is a sin", "annuity", "Anakin Skywalker", "Buffalo Bill", "justice resides", "the Viet Minh", "a declaration of war", "half steamed milk and half foam", "cuba", "Arthur Russell", "the people themselves", "Wylie Draper", "a political role for Islam but also because its supporters believe their views merely reflect Islam, while the contrary idea that Islam is, or can be, apolitical is an error", "the university's off-campus rental policies", "Bobby Hull and Dennis Hull", "New England Patriots", "famine"], "metric_results": {"EM": 0.28125, "QA-F1": 0.4003666472416472}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 0.09523809523809523, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.22222222222222218, 0.0, 1.0, 0.0, 0.1, 1.0, 0.0, 0.18181818181818182, 0.16666666666666669, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.2666666666666667, 0.07142857142857142, 1.0, 0.3076923076923077, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "retrieved_ids": ["mrqa_naturalquestions-train-46794", "mrqa_naturalquestions-train-36534", "mrqa_naturalquestions-train-85668", "mrqa_naturalquestions-train-526", "mrqa_naturalquestions-train-34923", "mrqa_naturalquestions-train-62304", "mrqa_naturalquestions-train-1140", "mrqa_naturalquestions-train-34753", "mrqa_naturalquestions-train-17441", "mrqa_naturalquestions-train-59594", "mrqa_naturalquestions-train-3173", "mrqa_naturalquestions-train-33071", "mrqa_naturalquestions-train-19262", "mrqa_naturalquestions-train-86494", "mrqa_naturalquestions-train-43289", "mrqa_naturalquestions-train-21313", "mrqa_naturalquestions-train-20610", "mrqa_naturalquestions-train-16267", "mrqa_naturalquestions-train-17748", "mrqa_naturalquestions-train-27022", "mrqa_naturalquestions-train-20865", "mrqa_naturalquestions-train-80531", "mrqa_naturalquestions-train-78068", "mrqa_naturalquestions-train-60559", "mrqa_naturalquestions-train-37905", "mrqa_squad-validation-4626", "mrqa_naturalquestions-validation-683", "mrqa_squad-validation-1841", "mrqa_squad-validation-6678", "mrqa_squad-validation-2577", "mrqa_squad-validation-4108", "mrqa_naturalquestions-validation-774"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 49, "before_eval": {"predictions": ["suitable for use on rough terrain", "AOL", "Genghis Khan", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "It then served as the capital of the Ostrogothic Kingdom until it was re-conquered in 540 by the Eastern Roman (Byzantine) Empire.", "12", "georgia", "1937", "improved", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "He even lost control of the patents he had generated since he had assigned them to the company in lieu of stock.", "Ideologically a Marxist and a Leninist", "variation in plants", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "San Francisco Demons and Memphis Maniax.", "3,600 Frenchmen", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "georgia", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Meyer v. Nebraska", "uneven trade agreements", "vegetables, sour milk, meat, fish or any other stew", "ATP energy", "georgia", "Ruth Elizabeth \"Bette\" Davis", "uranium", "7 December 2004"], "metric_results": {"EM": 0.0625, "QA-F1": 0.22053207768933575}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.12903225806451615, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.5714285714285715, 0.0, 0.0, 0.1111111111111111, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.9, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 50, "before_eval": {"predictions": ["basketball", "Igor Stravinsky, Carl Orff, Paul Hindemith, Richard Strauss, Luigi Nono, Krzysztof Penderecki and Joaqu\u00edn Rodrigo", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie ), typically cooked in a gravy with onions and sometimes other vegetables, such as peas, celery or carrots, and topped with mashed potato", "Gatiman express its ranges 160km / hour between Delhi to Agra In 100 min its cross 180km", "murder in...T.S. Eliot : plays, Sweeney Agonistes, the rock, Murder in the cathedral, the family reunion, the cocktail party", "Big Machine Records", "The issues of conflicting territorial claims between British and French colonies", "Valmiki", "from the 1719 Epistle to Ramsay by the Scottish poet William Hamilton", "every two to six years", "dissension and unrest", "an association football YouTube channel and website directed at Arsenal supporters", "2016", "Dan Castellaneta", "2007", "Wicked Twister", "subtraction", "rocket designer and creator of the Atlas ICBM", "shoe", "how or whether this connection is relevant on microscales", "supernatural psychological horror", "the House of Representatives", "tony williams", "on the evening of the same day", "\"Blue (Da Ba Dee\") is a song by the Italian music group Eiffel 65.", "USS Constitution Heavy Frigate Sailing Warship", "Faurot Field", "Dennis C. Stewart as Leo `` Craterface '' Balmudo, head of the Scorpions, a rival greaser gang", "an extended metaphor to compare death with crossing the `` sandbar '' between river of life, with its outgoing `` flood '', and the ocean that lies beyond ( death ), the `` boundless deep '', to which we return", "5", "konya", "when the car comes to a halt"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3138790359461999}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.4210526315789474, 0.1081081081081081, 0.2222222222222222, 0.11764705882352941, 1.0, 0.13793103448275862, 0.2857142857142857, 0.0, 1.0, 0.0, 0.18181818181818182, 0.0, 0.4, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.7499999999999999, 0.0, 0.0, 0.33333333333333337, 0.15384615384615385, 0.5, 1.0, 0.0, 0.9824561403508771, 0.0, 0.0, 0.20000000000000004]}}, "error_ids": ["mrqa_hotpotqa-validation-4225", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-3395", "mrqa_triviaqa-validation-813", "mrqa_squad-validation-10171", "mrqa_naturalquestions-validation-572", "mrqa_naturalquestions-validation-1607", "mrqa_squad-validation-8134", "mrqa_hotpotqa-validation-1528", "mrqa_naturalquestions-validation-7812", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-290", "mrqa_hotpotqa-validation-1350", "mrqa_triviaqa-validation-3428", "mrqa_squad-validation-10427", "mrqa_hotpotqa-validation-304", "mrqa_naturalquestions-validation-6782", "mrqa_triviaqa-validation-3572", "mrqa_squad-validation-2275", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-7770", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-71", "mrqa_squad-validation-290", "mrqa_triviaqa-validation-239", "mrqa_naturalquestions-validation-3022"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 51, "before_eval": {"predictions": ["third", "the pulmonary arteries", "the ruler of the lands in the story, alongside her tiny husband, the King of Hearts", "Orange", "Alex Breckenridge", "seven", "Schr\u00f6dinger equation", "cobalt", "Ashland is home to Scribner-Fellows State Forest", "in some public schools in Alabama, Arkansas, Georgia, Louisiana, Mississippi, Oklahoma, Tennessee and Texas", "Ghostface Mask", "Roger Thomas Staubach", "AC induction motor and transformer", "Eric Morecambe", "Punk's Blood", "from the port of Nueva Espa\u00f1a to the Spanish coast", "Robert John Day", "1775\u20131795", "Empiricism", "w Somerset maugham", "Pabst Brewing Company", "redistributive", "Tyrion Lannister", "Hillsborough", "Content", "Those not fit to enter heaven", "Fourth Home Rule Bill", "t\u00e1o qu\u00e2n (23 December of Lunar Year) T\u00e3t Ni\u00ean", "Commission v Italy", "Belarus", "1835", "Gloriana"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26611465262379896}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.0, 0.5853658536585366, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6, 0.33333333333333337, 0.2666666666666667, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.4, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 1.0, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4919", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4006", "mrqa_squad-validation-2432", "mrqa_naturalquestions-validation-6634", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-7398", "mrqa_squad-validation-1932", "mrqa_triviaqa-validation-787", "mrqa_hotpotqa-validation-4795", "mrqa_squad-validation-1185", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-4922", "mrqa_naturalquestions-validation-7484", "mrqa_hotpotqa-validation-4528", "mrqa_naturalquestions-validation-7312", "mrqa_triviaqa-validation-4890", "mrqa_hotpotqa-validation-596", "mrqa_squad-validation-7324", "mrqa_naturalquestions-validation-5370", "mrqa_triviaqa-validation-1046", "mrqa_naturalquestions-validation-897", "mrqa_naturalquestions-validation-91", "mrqa_hotpotqa-validation-2549", "mrqa_triviaqa-validation-3980", "mrqa_hotpotqa-validation-3587", "mrqa_hotpotqa-validation-3357"], "retrieved_ids": ["mrqa_naturalquestions-train-20334", "mrqa_naturalquestions-train-76930", "mrqa_naturalquestions-train-4810", "mrqa_naturalquestions-train-65212", "mrqa_naturalquestions-train-82270", "mrqa_naturalquestions-train-47923", "mrqa_naturalquestions-train-61368", "mrqa_naturalquestions-train-1297", "mrqa_naturalquestions-train-13851", "mrqa_naturalquestions-train-8015", "mrqa_naturalquestions-train-74956", "mrqa_naturalquestions-train-73469", "mrqa_naturalquestions-train-11448", "mrqa_naturalquestions-train-45669", "mrqa_naturalquestions-train-31909", "mrqa_naturalquestions-train-81256", "mrqa_naturalquestions-train-58953", "mrqa_naturalquestions-train-2015", "mrqa_naturalquestions-train-60108", "mrqa_naturalquestions-train-85339", "mrqa_naturalquestions-train-38298", "mrqa_naturalquestions-train-3855", "mrqa_naturalquestions-train-78862", "mrqa_naturalquestions-train-487", "mrqa_naturalquestions-train-21733", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-5266", "mrqa_hotpotqa-validation-1178", "mrqa_triviaqa-validation-7090", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4298", "mrqa_triviaqa-validation-7530"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 52, "before_eval": {"predictions": ["Myllokunmingia", "Edd Kimber", "brian doonan", "the imaginary unit", "`` asphyxia '' ( cutting off the oxygen supply ) and cooling", "solid-body electric", "Carey Mulligan, Matthias Schoenaerts, Michael Sheen, Tom Sturridge and Juno Temple", "Dennis Keith Rodman (born May 13, 1961) is an American retired professional basketball player, who played for the Detroit Pistons, San Antonio Spurs, Chicago Bulls, Los Angeles Lakers, and Dallas Mavericks", "Olympic's keel laid down first on 16 December 1908 and Titanic's on 31 March 1909", "five community cards", "German hymns", "Bury Football Club is a professional association football club based in Bury, Greater Manchester, England.", "Benazir Bhutto", "Amos McCracken", "NFC Championship Game", "Tom Robinson", "paulay Culkin", "filming began in September 2000 at Leavesden Film Studios and in London, with production ending in July 2001", "the port city of Aden", "quickly to meet the needs of major national and international patient information projects and health system interoperability goals", "about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm)", "The leopard", "the service sector", "Florida", "\"Artemisia absinthium\" (\"grand wormwood\") together with green anise, sweet fennel, and other medicinal and culinary herbs", "Laura Solon", "Bolton", "British", "the state recognizes no limits to its authority and strives to regulate every aspect of public and private life wherever feasible", "civil disobedients", "Just under 540,800 students were enrolled in public schools, and just over 311,800 in private schools", "British Sky Broadcasting Group"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22361758271684745}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.0, 0.25, 0.0, 0.3076923076923077, 0.0, 0.33333333333333337, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809525, 0.4, 0.1111111111111111, 0.4, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.5185185185185185, 0.0, 0.11764705882352941, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6188", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-4073", "mrqa_squad-validation-9081", "mrqa_naturalquestions-validation-3351", "mrqa_triviaqa-validation-2598", "mrqa_naturalquestions-validation-7688", "mrqa_hotpotqa-validation-4188", "mrqa_naturalquestions-validation-1186", "mrqa_hotpotqa-validation-5318", "mrqa_squad-validation-2401", "mrqa_hotpotqa-validation-5482", "mrqa_hotpotqa-validation-182", "mrqa_squad-validation-308", "mrqa_triviaqa-validation-498", "mrqa_naturalquestions-validation-8759", "mrqa_hotpotqa-validation-1871", "mrqa_squad-validation-6389", "mrqa_squad-validation-8849", "mrqa_hotpotqa-validation-1504", "mrqa_squad-validation-7377", "mrqa_hotpotqa-validation-1402", "mrqa_triviaqa-validation-5068", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-904", "mrqa_squad-validation-6709", "mrqa_squad-validation-2918", "mrqa_squad-validation-2772"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 53, "before_eval": {"predictions": ["Following the election of the UK Labour Party to government in 1997", "two", "c 1600", "\" Professor Moriarty to the Doctor's Sherlock Holmes\"", "Gregory Peck", "1763", "surtaste", "from ~74,000 (BP = Before Present) until the end of the Pleistocene", "catherine o'Leary", "Bronwyn Kathleen Bishop", "guidance and intervention from the European empire to aid in the governing of a more evolved social structure", "a friend sat opposite you", "mouri", "\"informal\" imperialism", "a violation of nature", "nairobi", "Sir Derek George Jacobi", "alex turner", "25 June 1932", "abraham amadeus Mozart", "James A. Garfield", "seasonal television specials, particularly its work in stop motion animation", "chromosome", "Evey's mother", "nine", "things that are indisputably bad", "the Sunni Muslim family", "Westley Sissel Unseld", "1912", "nitrogen", "sediment load", "Daniel Handler"], "metric_results": {"EM": 0.3125, "QA-F1": 0.3718677156177156}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false], "QA-F1": [0.18181818181818182, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6153846153846153, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4100", "mrqa_squad-validation-5390", "mrqa_triviaqa-validation-3107", "mrqa_triviaqa-validation-776", "mrqa_squad-validation-9144", "mrqa_triviaqa-validation-7626", "mrqa_hotpotqa-validation-123", "mrqa_squad-validation-9867", "mrqa_triviaqa-validation-7484", "mrqa_triviaqa-validation-3014", "mrqa_squad-validation-9808", "mrqa_triviaqa-validation-595", "mrqa_hotpotqa-validation-622", "mrqa_triviaqa-validation-6410", "mrqa_naturalquestions-validation-6485", "mrqa_triviaqa-validation-2821", "mrqa_hotpotqa-validation-3854", "mrqa_squad-validation-274", "mrqa_squad-validation-6877", "mrqa_triviaqa-validation-177", "mrqa_squad-validation-9354", "mrqa_triviaqa-validation-3268"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 54, "before_eval": {"predictions": ["The Christmas Invasion", "a foreign country", "an expression of Priestley's socialist political principles", "March 9 to 18", "\"Paddington 2\"", "The Jewel of the Nile", "Oral mucosa ( a mucous membrane ) lining the mouth and also on the tongue and palates and mouth floor", "The 8th Habit", "Anishinaabeg", "general medical advice", "110 mm ( 5.91 in ) per year", "pierowall", "promote high employment and sustainable economic growth", "22 September 2015", "\"Murder Request\")", "a person's point of weakness", "unexploded mines", "annually in late January or early February", "Michael Schumacher", "the duodenum", "pastry", "Cuyler Reynolds", "Atlanta", "americ beer", "Gloucestershire and England", "Black Ravens", "saved something from the disaster", "gaming", "Hermes, Dior, Cartier, Bottega Veneta, Chanel, Fendi, Gucci, Louis Vuitton, MaxMara, Celine, Tiffany & Co.", "\"Shoot Straight from Your Heart\"", "marcia flaubert", "Kony Ealy"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2828756313131313}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.13333333333333333, 0.7272727272727273, 0.0, 0.375, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 0.3636363636363636, 0.25, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6980", "mrqa_naturalquestions-validation-5212", "mrqa_naturalquestions-validation-1383", "mrqa_hotpotqa-validation-4277", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2684", "mrqa_hotpotqa-validation-5789", "mrqa_hotpotqa-validation-525", "mrqa_squad-validation-6211", "mrqa_naturalquestions-validation-4960", "mrqa_triviaqa-validation-5166", "mrqa_triviaqa-validation-1396", "mrqa_triviaqa-validation-2356", "mrqa_naturalquestions-validation-8441", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1707", "mrqa_hotpotqa-validation-3620", "mrqa_triviaqa-validation-6373", "mrqa_triviaqa-validation-5057", "mrqa_squad-validation-10293", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-3710", "mrqa_triviaqa-validation-6164", "mrqa_squad-validation-979"], "retrieved_ids": ["mrqa_naturalquestions-train-34771", "mrqa_naturalquestions-train-11884", "mrqa_naturalquestions-train-65295", "mrqa_naturalquestions-train-35982", "mrqa_naturalquestions-train-10338", "mrqa_naturalquestions-train-47486", "mrqa_naturalquestions-train-49433", "mrqa_naturalquestions-train-40769", "mrqa_naturalquestions-train-41180", "mrqa_naturalquestions-train-14104", "mrqa_naturalquestions-train-39739", "mrqa_naturalquestions-train-9975", "mrqa_naturalquestions-train-4976", "mrqa_naturalquestions-train-38423", "mrqa_naturalquestions-train-83653", "mrqa_naturalquestions-train-22575", "mrqa_naturalquestions-train-51244", "mrqa_naturalquestions-train-78304", "mrqa_naturalquestions-train-6715", "mrqa_naturalquestions-train-87317", "mrqa_naturalquestions-train-41917", "mrqa_naturalquestions-train-64178", "mrqa_naturalquestions-train-73901", "mrqa_naturalquestions-train-5281", "mrqa_naturalquestions-train-31952", "mrqa_naturalquestions-validation-8744", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2147", "mrqa_squad-validation-3964", "mrqa_naturalquestions-validation-3395", "mrqa_naturalquestions-validation-2248", "mrqa_squad-validation-8259"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 55, "before_eval": {"predictions": ["2,000", "John Elway", "France", "Gracie the new `` face '' of the FBI. Hurt after being dumped by her boyfriend, fellow Agent Eric Matthews ( who gets relocated to Miami ), she agrees to the reassignment", "Isle of Man", "stromal connective tissue", "paris", "Sierra Sky Park Airport is a residential airport community born of a unique agreement in transportation law to allow personal aircraft and automobiles to share certain roads", "paris", "low wage", "octagon", "Paul McCartney", "Scott Mosier", "paris pete Postlethwaite", "weaving", "the art of the book and architecture ; and also including ceramics, metal, glass, and gardens", "the Company's army", "Newton was sacked by DeMarcus Ware as time expired in the half", "Jack Nicholson -- Chinatown as J.J. `` Jake '' Gittes", "dan brown", "boxing", "at the port city of Kaffa in the Crimea in 1347", "Charbagh structure", "Iranian", "paris", "Landwehr", "his work was published first", "as a preparation for the Feast of the Divine Mercy, celebrated each year on first Sunday after Easter", "accommodationism", "Parliamentarians ( `` Roundheads '' ) and Royalists ( `` Cavaliers '' )", "the Niger\u2013 Congo language", "guided rays"], "metric_results": {"EM": 0.125, "QA-F1": 0.20713259441707718}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.2758620689655173, 0.5, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.09999999999999999, 0.42857142857142855, 0.0, 0.0, 0.06666666666666667, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-2130", "mrqa_hotpotqa-validation-3062", "mrqa_naturalquestions-validation-6918", "mrqa_triviaqa-validation-3568", "mrqa_squad-validation-4700", "mrqa_triviaqa-validation-140", "mrqa_triviaqa-validation-4620", "mrqa_triviaqa-validation-5479", "mrqa_hotpotqa-validation-3264", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-938", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-4098", "mrqa_squad-validation-818", "mrqa_naturalquestions-validation-9536", "mrqa_triviaqa-validation-7421", "mrqa_naturalquestions-validation-9459", "mrqa_squad-validation-4773", "mrqa_naturalquestions-validation-819", "mrqa_hotpotqa-validation-5543", "mrqa_triviaqa-validation-7689", "mrqa_hotpotqa-validation-4215", "mrqa_naturalquestions-validation-1989", "mrqa_naturalquestions-validation-8986", "mrqa_naturalquestions-validation-570", "mrqa_hotpotqa-validation-2699", "mrqa_naturalquestions-validation-7078"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 56, "before_eval": {"predictions": ["Donna", "1922 to 1991", "predictions that can be tested in various ways", "the city council", "moral conservatism", "Polyphase System", "65,535 bytes ( 8 byte header + 65,527 bytes of data )", "26", "a smartphone - like, hands - free format", "increased their reserves (by expanding their money supplies) in amounts far greater than before", "k Friedrich Wilhelm Nietzsche (1844\u2013 1900) was a German philosopher. He wrote critical texts on religion, morality, contemporary culture, philosophy and science.", "a software programmer at Br\u00f8derbund in the 1980s and was the model for one of the characters in Jordan Mechner's game \"Prince of Persia\"", "etaples training", "Robert \"Bumps\" Blackwell, Enotris Johnson, and Little Richard", "five", "many occupational hazards in their line of work", "kenji kita", "d'Artagnan", "when each of the variables is a perfect monotone function of the other", "kevin gold rush (1850s and 60s)", "1932", "March 31, 1944", "methanol, ethanol, isopropanol, furan, THF, diethyl ether, dioxane, ethyl acetate, DMF, DMSO, acetic acid, and formic acid", "former Manchester United and Danish international goalkeeper Peter Schmeichel", "senior to \"Gruppenf\u00fchrer\"", "kevinus", "the lowest known subaerial volcanic vents in the world, at 45 m ( 150 ft ) or more below sea level", "texas", "Sinai Peninsula is a peninsula in Egypt, the only part of the country located in Asia", "Alison Steadman", "in the retina of mammalian eyes ( e.g. the human eye )", "kaupthing Singer & Friedlander Ltd5"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2521389163372859}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.3636363636363636, 0.0, 0.0, 0.08333333333333333, 0.17391304347826084, 0.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08695652173913045, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-9608", "mrqa_squad-validation-1397", "mrqa_naturalquestions-validation-1787", "mrqa_squad-validation-371", "mrqa_naturalquestions-validation-752", "mrqa_squad-validation-3720", "mrqa_triviaqa-validation-4390", "mrqa_hotpotqa-validation-627", "mrqa_triviaqa-validation-6223", "mrqa_hotpotqa-validation-4620", "mrqa_hotpotqa-validation-3651", "mrqa_squad-validation-2004", "mrqa_triviaqa-validation-2280", "mrqa_triviaqa-validation-326", "mrqa_naturalquestions-validation-486", "mrqa_triviaqa-validation-4640", "mrqa_squad-validation-3653", "mrqa_hotpotqa-validation-15", "mrqa_hotpotqa-validation-686", "mrqa_triviaqa-validation-892", "mrqa_naturalquestions-validation-1349", "mrqa_triviaqa-validation-5813", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-3069", "mrqa_naturalquestions-validation-7358", "mrqa_triviaqa-validation-2701"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 57, "before_eval": {"predictions": ["nola Taylor Redd", "dictionary of the English Language (1709-1784)", "60 million", "Bathurst", "April 1948", "increased in the transition economies of Central and Eastern Europe and Central Asia than in some other developed economies in Western Europe ( except France, where inequality of opportunity was relatively high )", "the doctrine of justification", "FeO (w\u00fcstite) is written as Fe1 \u2212 xO, where x is usually around 0.05.", "Marx Brothers", "materialss melted near an impact crater", "The Better Jacksonville Plan", "david f Frost", "Neal Dahlen : five with San Francisco 49ers ( staff and player personnel ) and two with Denver Broncos ( general manager )", "charles and duccestershire", "carbon dioxide", "The Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres. The Nationals are strongest in Victoria's North Western and Eastern rural regional areas. The Greens", "United States Ship", "reared", "October 15, 1997", "in the Hebrew Bible in the Book of Job, Psalms, and Isaiah", "modernized the outside of the building and renovated the inside as part of his first construction project in Manhattan", "North Atlantic Ocean and Arctic Ocean", "texas", "Robert Louis Balfour Stevenson (13 November 1850 \u2013 3 December 1894) was a Scottish novelist, poet, essayist, and travel writer.", "tom Sly", "five", "tony Airways", "elizabeth Taylor", "American conservative author and commentator", "kurt gutenbrunner", "Sam the Sham", "up to three terms until 2015 where the three term limit and two year terms were replaced with a two four - year terms"], "metric_results": {"EM": 0.15625, "QA-F1": 0.31399531024531024}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.18181818181818182, 0.0, 0.13333333333333333, 0.6666666666666666, 0.8000000000000002, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.3333333333333333, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.32]}}, "error_ids": ["mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-4974", "mrqa_hotpotqa-validation-1567", "mrqa_hotpotqa-validation-5436", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-3969", "mrqa_squad-validation-2255", "mrqa_squad-validation-3598", "mrqa_triviaqa-validation-3648", "mrqa_squad-validation-4067", "mrqa_triviaqa-validation-6053", "mrqa_naturalquestions-validation-4193", "mrqa_triviaqa-validation-5785", "mrqa_squad-validation-2886", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-4744", "mrqa_naturalquestions-validation-6365", "mrqa_hotpotqa-validation-3802", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-6425", "mrqa_triviaqa-validation-2303", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7187", "mrqa_hotpotqa-validation-1975", "mrqa_triviaqa-validation-1742", "mrqa_hotpotqa-validation-1016", "mrqa_naturalquestions-validation-787"], "retrieved_ids": ["mrqa_naturalquestions-train-31270", "mrqa_naturalquestions-train-43671", "mrqa_naturalquestions-train-78011", "mrqa_naturalquestions-train-74316", "mrqa_naturalquestions-train-84662", "mrqa_naturalquestions-train-9229", "mrqa_naturalquestions-train-59031", "mrqa_naturalquestions-train-15555", "mrqa_naturalquestions-train-16968", "mrqa_naturalquestions-train-3918", "mrqa_naturalquestions-train-44011", "mrqa_naturalquestions-train-34224", "mrqa_naturalquestions-train-59669", "mrqa_naturalquestions-train-61628", "mrqa_naturalquestions-train-19489", "mrqa_naturalquestions-train-68858", "mrqa_naturalquestions-train-47703", "mrqa_naturalquestions-train-14979", "mrqa_naturalquestions-train-23214", "mrqa_naturalquestions-train-65664", "mrqa_naturalquestions-train-21674", "mrqa_naturalquestions-train-37236", "mrqa_naturalquestions-train-23417", "mrqa_naturalquestions-train-972", "mrqa_naturalquestions-train-3155", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-4500", "mrqa_naturalquestions-validation-3951", "mrqa_triviaqa-validation-3678", "mrqa_naturalquestions-validation-4354", "mrqa_naturalquestions-validation-1834", "mrqa_squad-validation-9569"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 58, "before_eval": {"predictions": ["Dutch", "begins in the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "a house edge of between 0.5 % and 1 %", "phagosomal membrane", "The Tyneside flat", "1955", "hen v", "200 horsepower", "Thomas Edison and Nikola Tesla", "Lutheranism", "Night Ranger", "Buzz, the Honey Nut Cheerios Bee", "Sarah Winnemucca Hopkins", "changing the work environment", "levels of economic inequality", "hen Yozhuo", "Arthur H. Compton", "Angelina Jolie", "Timothy Brown", "in 1982", "mainly civil servants recruited in special university classes", "black earth", "2 blank tiles", "the medial epicondyle of the humerus from posteriorly, or inferiorly with the elbow flexed", "weighing", "no man is an island", "Liao, Jin, and Song", "`` Han dynasty '' ( Hanchao \u6f22 \u671d )", "pigeons", "ionized material", "Attack the Block", "Juliet"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29680579836829835}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.7272727272727273, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.4, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9173", "mrqa_naturalquestions-validation-5554", "mrqa_squad-validation-8687", "mrqa_squad-validation-5202", "mrqa_triviaqa-validation-6185", "mrqa_squad-validation-1443", "mrqa_squad-validation-1535", "mrqa_hotpotqa-validation-593", "mrqa_naturalquestions-validation-10626", "mrqa_hotpotqa-validation-5654", "mrqa_hotpotqa-validation-5735", "mrqa_squad-validation-2057", "mrqa_triviaqa-validation-5104", "mrqa_squad-validation-7880", "mrqa_triviaqa-validation-7264", "mrqa_hotpotqa-validation-5127", "mrqa_squad-validation-2042", "mrqa_squad-validation-4233", "mrqa_naturalquestions-validation-1173", "mrqa_naturalquestions-validation-9814", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-4817", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-820", "mrqa_hotpotqa-validation-1706"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 59, "before_eval": {"predictions": ["could be profitable", "the exoskeleton of insects, the shells and membranes of externally deposited eggs, and skin", "the Naturalization Act of 1790", "Matthew Vaughn", "2 %", "Mountbatten- Windsor", "Theater 9 at the Century 16 multiplex ( operated by Cinemark ), located at the Town Center at Aurora shopping mall at 14300 E. Alameda Avenue", "John Unitas, Joe Namath, Dan Marino, Jim Kelly, Joe Montana and George Blanda.", "neell Potter and Dean Winters", "24\u201310", "kabuki and bunraku", "Of course [ the price of oil] is going to rise", "in the U.S. state of Kansas", "a yolk sac ( protruding from its lower part )", "Kelly Bundy", "Italy", "keelmen", "Sir William Douglas, 1st Earl of Douglas", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Mario Addison", "321,520", "2017 Major League Baseball draft", "2005", "red deer", "k2", "Helmuth von Moltke", "kaa ( \u092d\u093e\u0932\u0942 Bh\u0101l\u016b, `` bear '' ; Himalayan brown bear )", "the ears of a hound dog", "2020 National Football League ( NFL ) season ( although a move to Las Vegas could happen as soon as 2019 with Sam Boyd Stadium )", "Cinerama Productions/Palomar theatrical library", "marx", "samoan t\u0101l\u0101"], "metric_results": {"EM": 0.125, "QA-F1": 0.24246570910973086}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.16666666666666669, 0.2666666666666667, 0.0, 1.0, 0.0, 0.16666666666666666, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9565217391304348, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-4838", "mrqa_squad-validation-6436", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-875", "mrqa_triviaqa-validation-2965", "mrqa_naturalquestions-validation-7974", "mrqa_hotpotqa-validation-1393", "mrqa_triviaqa-validation-3719", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3730", "mrqa_hotpotqa-validation-740", "mrqa_naturalquestions-validation-8116", "mrqa_triviaqa-validation-5864", "mrqa_squad-validation-5124", "mrqa_hotpotqa-validation-5253", "mrqa_naturalquestions-validation-7035", "mrqa_squad-validation-825", "mrqa_hotpotqa-validation-1917", "mrqa_squad-validation-7612", "mrqa_triviaqa-validation-4682", "mrqa_triviaqa-validation-3685", "mrqa_hotpotqa-validation-4456", "mrqa_naturalquestions-validation-3571", "mrqa_naturalquestions-validation-1676", "mrqa_naturalquestions-validation-5649", "mrqa_squad-validation-5887", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-2525"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 60, "before_eval": {"predictions": ["Currer Bell", "the illegitimate son of Ned Stark, the honorable lord of Winterfell, an ancient fortress in the North of the fictional continent of Westeros", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "The Catcher in the Rye", "The nobility of England", "Merv", "Bendigo", "Thomas Jefferson", "She became a naturalized American citizen in 1994 and also received Hungarian citizenship in June 2007.", "July 1872", "the Boston and Maine Railroad", "James Lofton and Mark Malone as sideline reporters", "the right of the dinner plate", "summer months", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts returned for their respective ninth, eighth, seventh and second series on The Ice Panel", "the third \u00e9tude", "Thailand, Burma, Cambodia, Indonesia and Sri Lanka", "segues", "boats", "iron", "During the reign of King Beorhtric of Wessex ( 786 -- 802 ) three ships of `` Northmen '' landed at Portland Bay in Dorset", "South Australian town", "Flag Day in 1954", "around 300,000", "In 1877 at Hooghly ( near Calcutta ) he instituted the use of fingerprints on contracts and deeds to prevent the then - rampant repudiation of signatures", "Sexred", "Veronica Lodge", "neo-Nazi ideology with ethnic European paganism and opposition to \"foreign\" religions such as Christianity, Islam and Judaism", "Mayall", "began to shrink in light of the successful landing", "the frequency f, wavelength \u03bb, or photon energy E.", "The story is a satire on corruption in the administration of criminal justice and the concept of the \"celebrity criminal\""], "metric_results": {"EM": 0.1875, "QA-F1": 0.36783656809232257}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.4347826086956522, 0.25, 1.0, 0.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.6666666666666666, 0.6, 0.0, 0.6666666666666665, 0.0, 0.17391304347826084, 1.0, 0.4444444444444445, 0.4, 0.0, 0.6666666666666666, 0.1904761904761905, 0.0, 1.0, 1.0, 0.08333333333333334, 0.0, 0.0, 0.1111111111111111, 0.0, 0.5454545454545454, 0.06666666666666667, 0.23529411764705882]}}, "error_ids": ["mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7225", "mrqa_squad-validation-1126", "mrqa_hotpotqa-validation-2715", "mrqa_naturalquestions-validation-9273", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5451", "mrqa_hotpotqa-validation-1124", "mrqa_squad-validation-559", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-1786", "mrqa_squad-validation-5449", "mrqa_hotpotqa-validation-1033", "mrqa_triviaqa-validation-3404", "mrqa_triviaqa-validation-3684", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5311", "mrqa_naturalquestions-validation-6337", "mrqa_hotpotqa-validation-4293", "mrqa_naturalquestions-validation-6759", "mrqa_hotpotqa-validation-1971", "mrqa_triviaqa-validation-1284", "mrqa_squad-validation-4011", "mrqa_naturalquestions-validation-5798", "mrqa_hotpotqa-validation-3681"], "retrieved_ids": ["mrqa_naturalquestions-train-5711", "mrqa_naturalquestions-train-49573", "mrqa_naturalquestions-train-69434", "mrqa_naturalquestions-train-39410", "mrqa_naturalquestions-train-37935", "mrqa_naturalquestions-train-7717", "mrqa_naturalquestions-train-16138", "mrqa_naturalquestions-train-14628", "mrqa_naturalquestions-train-49943", "mrqa_naturalquestions-train-81259", "mrqa_naturalquestions-train-59389", "mrqa_naturalquestions-train-10319", "mrqa_naturalquestions-train-85081", "mrqa_naturalquestions-train-72618", "mrqa_naturalquestions-train-16466", "mrqa_naturalquestions-train-11934", "mrqa_naturalquestions-train-59652", "mrqa_naturalquestions-train-41760", "mrqa_naturalquestions-train-62379", "mrqa_naturalquestions-train-51444", "mrqa_naturalquestions-train-57539", "mrqa_naturalquestions-train-49089", "mrqa_naturalquestions-train-6484", "mrqa_naturalquestions-train-68779", "mrqa_naturalquestions-train-61077", "mrqa_squad-validation-2419", "mrqa_triviaqa-validation-7090", "mrqa_naturalquestions-validation-7581", "mrqa_naturalquestions-validation-7049", "mrqa_squad-validation-4369", "mrqa_naturalquestions-validation-3052", "mrqa_triviaqa-validation-2181"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 61, "before_eval": {"predictions": ["The Two Noble Kinsmen", "glenbrook north", "San Bernardino", "Judy Collins", "Out of Control", "the 2013 non-fiction book of the same name by David Finkel", "liza tarbuck", "The Frost Report", "fell from his horse while hunting", "incitement to terrorism", "Henry and Liza", "She is a well-established historical figure in 16th-century Irish history", "Mexico City", "oxygen", "Elk and Kanawha Rivers", "They circulate and are moved around within plant cells, and occasionally pinch in two", "'Bucks Point'", "to `` help bring creative projects to life ''", "The Church of Latter Day Saints", "Old World fossil representatives", "the group 1 elements", "Matt Damon", "Michigan", "thicker consistency and a deeper flavour than sauce", "the uterus", "neupommern", "L'\u00c9glise fran\u00e7aise \u00e0 la Nouvelle-Amsterdam", "VH1's \"100 Greatest Artists of Hard Rock\"", "after AD 70", "1948", "electronic music", "He was taken prisoner and eventually was convicted of crimes against peace"], "metric_results": {"EM": 0.125, "QA-F1": 0.2444142560870502}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.14285714285714285, 0.0, 0.0, 0.4, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1850", "mrqa_triviaqa-validation-3861", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-6118", "mrqa_hotpotqa-validation-5822", "mrqa_naturalquestions-validation-7407", "mrqa_triviaqa-validation-6418", "mrqa_squad-validation-6218", "mrqa_naturalquestions-validation-8368", "mrqa_hotpotqa-validation-2012", "mrqa_hotpotqa-validation-4743", "mrqa_triviaqa-validation-2130", "mrqa_naturalquestions-validation-7483", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-3355", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4931", "mrqa_triviaqa-validation-3960", "mrqa_naturalquestions-validation-2943", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6376", "mrqa_squad-validation-3067", "mrqa_hotpotqa-validation-1114", "mrqa_squad-validation-9370", "mrqa_hotpotqa-validation-327", "mrqa_triviaqa-validation-3985", "mrqa_hotpotqa-validation-3481"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 62, "before_eval": {"predictions": ["no false doctrine to believe that a Christian's soul sleeps after it is separated from the body in death", "blanqueamiento (whitening)", "from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "the Monarch", "United Kingdom, Australia, Canada and the United States", "Ballarat Bitter", "read therefore", "Ricketts Glen State Park", "an openly wounded and unabashedly portentous rock balladeer", "new magma", "thon hancock", "fee per unit of connection time", "the \"master builder\" of mid-20th century New York City, Long Island, Rockland County, and Westchester County", "1932", "during the winter of the 2017 -- 18 network television season", "richest agricultural regions", "Egypt", "Buzz Aldrin", "Lorraine", "4145 ft above mean sea level", "American philosopher of science", "during the production company vanity cards shown following the closing credits of most programs", "Kansas\u2013Nebraska Act", "44 Variable ( V ) gene segments", "from 1910\u20131940", "11:28 left in the second quarter", "Start Here", "geoffrey beevers", "Autobahn", "endocrine", "Baron of Holberg", "poodle"], "metric_results": {"EM": 0.28125, "QA-F1": 0.42328666395968684}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, false, true, false], "QA-F1": [0.1111111111111111, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.125, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6956521739130436, 0.0, 0.2222222222222222, 0.5, 0.0, 0.4444444444444445, 1.0, 0.5, 0.0, 0.1, 1.0, 0.33333333333333337, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0689655172413793, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2339", "mrqa_squad-validation-9843", "mrqa_naturalquestions-validation-5396", "mrqa_hotpotqa-validation-507", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-7270", "mrqa_triviaqa-validation-1698", "mrqa_squad-validation-4750", "mrqa_hotpotqa-validation-1510", "mrqa_squad-validation-9303", "mrqa_naturalquestions-validation-8696", "mrqa_squad-validation-2703", "mrqa_naturalquestions-validation-1555", "mrqa_squad-validation-3961", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-3469", "mrqa_squad-validation-5816", "mrqa_naturalquestions-validation-538", "mrqa_squad-validation-824", "mrqa_triviaqa-validation-4095", "mrqa_hotpotqa-validation-5607", "mrqa_naturalquestions-validation-9064", "mrqa_triviaqa-validation-6254"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 63, "before_eval": {"predictions": ["Bank of China Tower", "isobaric (constant pressure) processes in the Rankine cycle", "james Leo peter \"Ed\" McMahon, Jr.", "ARPANET", "William Shakespeare", "Kohlberg K Travis Roberts", "fleetwood", "probabilistic (or \"Monte Carlo\") and deterministic algorithms", "Jimi Hendrix", "eight days after their initial broadcast", "Hong Kong\u2013based, Cayman Islands registered Mandarin and Cantonese-language television broadcaster that serves the Chinese mainland and Hong Kong along with other markets with substantial Chinese viewers", "a narcissistic ex-lover who did the protagonist wrong", "catawba river", "optical microscopy", "mcc hammer", "jonathan", "Sondheim", "Strasbourg", "3.762", "a system of recording important things", "in the Tang Dynasty's architectural style", "The Daily Mirror", "broken arm", "m Mayo county council", "ear ossicles of the middle ears", "German", "2001", "belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law", "Professor Kantorek", "31 - member Senate", "kerosene lamps", "orkneys"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1903168957284811}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.5, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.2857142857142857, 0.07407407407407407, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.34146341463414637, 0.0, 0.5, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-189", "mrqa_squad-validation-3445", "mrqa_triviaqa-validation-7574", "mrqa_squad-validation-4629", "mrqa_hotpotqa-validation-97", "mrqa_triviaqa-validation-1518", "mrqa_squad-validation-9057", "mrqa_squad-validation-5843", "mrqa_hotpotqa-validation-366", "mrqa_naturalquestions-validation-6326", "mrqa_triviaqa-validation-7598", "mrqa_squad-validation-5059", "mrqa_triviaqa-validation-27", "mrqa_triviaqa-validation-5905", "mrqa_naturalquestions-validation-9755", "mrqa_hotpotqa-validation-55", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-7011", "mrqa_hotpotqa-validation-3929", "mrqa_triviaqa-validation-5992", "mrqa_squad-validation-306", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-2850", "mrqa_squad-validation-7861", "mrqa_squad-validation-6707", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-4037", "mrqa_triviaqa-validation-2254"], "retrieved_ids": ["mrqa_naturalquestions-train-69398", "mrqa_naturalquestions-train-6041", "mrqa_naturalquestions-train-52681", "mrqa_naturalquestions-train-26500", "mrqa_naturalquestions-train-2819", "mrqa_naturalquestions-train-41768", "mrqa_naturalquestions-train-12476", "mrqa_naturalquestions-train-31491", "mrqa_naturalquestions-train-62072", "mrqa_naturalquestions-train-86574", "mrqa_naturalquestions-train-21636", "mrqa_naturalquestions-train-76384", "mrqa_naturalquestions-train-20518", "mrqa_naturalquestions-train-79503", "mrqa_naturalquestions-train-19718", "mrqa_naturalquestions-train-18648", "mrqa_naturalquestions-train-66322", "mrqa_naturalquestions-train-66125", "mrqa_naturalquestions-train-14862", "mrqa_naturalquestions-train-59907", "mrqa_naturalquestions-train-66153", "mrqa_naturalquestions-train-27894", "mrqa_naturalquestions-train-42942", "mrqa_naturalquestions-train-26501", "mrqa_naturalquestions-train-62685", "mrqa_triviaqa-validation-2223", "mrqa_squad-validation-3812", "mrqa_squad-validation-3490", "mrqa_triviaqa-validation-3664", "mrqa_hotpotqa-validation-4624", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-444"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 64, "before_eval": {"predictions": ["failure rate", "Jim Justice", "miniature cydippid adults", "Trey Parker and Matt Stone", "sukiyaki", "sorrow regarding the environment", "trial division", "consultant at the Westinghouse Electric & Manufacturing Company's Pittsburgh labs", "Harris Museum", "The Suite Life of Zack & Cody", "bacillus calmette-gu\u00e9rin", "Saturn IB", "H. R. Haldeman", "brian wyre", "Zaha", "george and the dragon raphael", "brain surgery (Craniotomy)", "ski resort of St Moritz", "charliesheen", "granaries were ordered built throughout the empire", "deadliest aviation accident to occur in India", "John Simm", "immediate judgement discrepancy, or cognitive bias, where a person making an initial assessment of another person, place, or thing will assume ambiguous information based upon concrete information", "the music industry in the United States, specifically with jazz", "the final episode of the series", "macOS High Sierra", "american boxing championship", "three", "Diarmaid MacCulloch", "loire river", "17th Century sources referring to Cardinal Richelieu after he was named to head the royal council in 1624", "provide funding at a rate or formula based on the previous year's funding"], "metric_results": {"EM": 0.1875, "QA-F1": 0.24531492518780654}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0, 0.16949152542372883, 0.0, 1.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.19999999999999998]}}, "error_ids": ["mrqa_triviaqa-validation-2902", "mrqa_naturalquestions-validation-4207", "mrqa_squad-validation-4567", "mrqa_triviaqa-validation-748", "mrqa_squad-validation-8909", "mrqa_squad-validation-1312", "mrqa_hotpotqa-validation-548", "mrqa_triviaqa-validation-2173", "mrqa_squad-validation-3956", "mrqa_hotpotqa-validation-3489", "mrqa_triviaqa-validation-2032", "mrqa_hotpotqa-validation-811", "mrqa_triviaqa-validation-6398", "mrqa_triviaqa-validation-864", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-3208", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-5521", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-2748", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-4709", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-10533"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 65, "before_eval": {"predictions": ["the lightly populated \"cow Counties\" of southern California", "Arabic numerals", "Diary of a Wimpy Kid : The Long Haul", ". html", "prayer", "heart", "Early Gothic", "Kentucky Derby", "verreaux", "Brian Keith Bosworth", "1991", "DuMont Television Network", "Birmingham, Alabama", "the following identity ( Basel problem) due to Euler,", "2018", "wyre", "apple", "gravitation", "nonconservative forces act to change the internal energies of the system, and are often associated with the transfer of heat", "pETA", "the applied force is opposed by static friction, generated between the object and the table surface", "sherrinford", "sazerac", "Shut Up", "nahuatl", "Karina Smirnoff", "Seattle Seahawks", "St. Augustine", "four", "Private Mass", "kedah", "mycorrhizal fungi"], "metric_results": {"EM": 0.25, "QA-F1": 0.30235615079365075}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.38095238095238093, 0.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-2737", "mrqa_squad-validation-482", "mrqa_naturalquestions-validation-8427", "mrqa_triviaqa-validation-1499", "mrqa_squad-validation-1100", "mrqa_triviaqa-validation-1923", "mrqa_hotpotqa-validation-2442", "mrqa_squad-validation-5836", "mrqa_squad-validation-9021", "mrqa_naturalquestions-validation-1784", "mrqa_triviaqa-validation-5573", "mrqa_triviaqa-validation-3518", "mrqa_naturalquestions-validation-6075", "mrqa_squad-validation-10420", "mrqa_triviaqa-validation-4080", "mrqa_squad-validation-10313", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-7605", "mrqa_triviaqa-validation-2383", "mrqa_squad-validation-239", "mrqa_hotpotqa-validation-4174", "mrqa_squad-validation-2296", "mrqa_triviaqa-validation-262", "mrqa_triviaqa-validation-3691"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 66, "before_eval": {"predictions": ["parsley", "Tesla used the money to fund his Colorado Springs experiments", "the eastern shore of the Firth of Clyde, Scotland", "On the Computational Complexity of Algorithms", "from sea level and may vary depending on location", "the Pandavas", "Magnetically soft ( low coercivity ) iron is used for the cores in electromagnets", "La Nouba", "white", "Duke Kent- Brown", "O2", "pig", "brandal", "better", "Vanessa Block", "insano", "2p + 1", "white", "raven", "http://www.example.com/index.html", "george", "`` Abigail ''", "a clear summary of the new faith in the form of two catechisms", "cheddar", "Concentrated O2 will allow combustion to proceed rapidly and energetically. Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel", "Saint-Domingue", "disappearance", "1963", "prokaryotic cell ( or organelle )", "Commissioners", "American historians generally use the traditional name or sometimes the Seven Years' War", "sattu paratha"], "metric_results": {"EM": 0.1875, "QA-F1": 0.32356672932330827}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [0.0, 0.2105263157894737, 0.6, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.8, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 0.05263157894736842, 1.0, 1.0, 0.0, 0.4, 1.0, 0.10526315789473685, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4099", "mrqa_squad-validation-1416", "mrqa_hotpotqa-validation-1052", "mrqa_squad-validation-10412", "mrqa_naturalquestions-validation-5927", "mrqa_hotpotqa-validation-5712", "mrqa_triviaqa-validation-7577", "mrqa_squad-validation-6945", "mrqa_squad-validation-3477", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-3970", "mrqa_hotpotqa-validation-4951", "mrqa_triviaqa-validation-515", "mrqa_squad-validation-8980", "mrqa_triviaqa-validation-5337", "mrqa_triviaqa-validation-6566", "mrqa_naturalquestions-validation-8229", "mrqa_triviaqa-validation-6654", "mrqa_naturalquestions-validation-5093", "mrqa_squad-validation-2469", "mrqa_triviaqa-validation-5686", "mrqa_squad-validation-3483", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-10357", "mrqa_squad-validation-10167", "mrqa_triviaqa-validation-2087"], "retrieved_ids": ["mrqa_naturalquestions-train-22416", "mrqa_naturalquestions-train-8366", "mrqa_naturalquestions-train-35265", "mrqa_naturalquestions-train-32908", "mrqa_naturalquestions-train-14038", "mrqa_naturalquestions-train-74691", "mrqa_naturalquestions-train-78954", "mrqa_naturalquestions-train-25922", "mrqa_naturalquestions-train-27887", "mrqa_naturalquestions-train-48972", "mrqa_naturalquestions-train-14854", "mrqa_naturalquestions-train-50556", "mrqa_naturalquestions-train-45696", "mrqa_naturalquestions-train-84178", "mrqa_naturalquestions-train-1370", "mrqa_naturalquestions-train-83599", "mrqa_naturalquestions-train-6349", "mrqa_naturalquestions-train-3136", "mrqa_naturalquestions-train-57681", "mrqa_naturalquestions-train-72703", "mrqa_naturalquestions-train-15186", "mrqa_naturalquestions-train-65152", "mrqa_naturalquestions-train-15744", "mrqa_naturalquestions-train-79209", "mrqa_naturalquestions-train-59937", "mrqa_squad-validation-3067", "mrqa_naturalquestions-validation-8448", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-2797", "mrqa_hotpotqa-validation-1116"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 67, "before_eval": {"predictions": ["high inequality goes hand-in-hand with weak labor movements and vice-versa", "spanish", "jazz", "Sweden, Norway and Denmark", "in Oscar II Land on the island of Spitsbergen in Svalbard, Norway", "desublimation", "a surname of Norman origin, deriving from the Norman given name Robert, meaning `` bright renown '' -- from the Germanic elements `` hrod '' meaning renown and `` beraht '' meaning bright", "Crossed: Psychopath", "payday loans", "Doctor of Philosophy", "1,388 (0.9%)", "Otis Timson", "me was born in a cross-fire hurricane", "member appointed by governments and organizations", "$150,000 and $250,000 for primes with at least 100 million digits and 1 billion digits, respectively", "1963 of the United Kingdom", "Ohio", "first freshman to finish as the runner-up", "The Crowned Prince of the Philadelphia Mob", "\u201c Resign.\u201d", "romantic attraction, sexual attraction, or sexual behavior toward both males and females, or romantic or sexual attraction to people of any sex or gender identity", "the Meiji Restoration (1868)", "Big 12 Conference", "In the 1920s", "American", "Cleopatra VII Philopator", "The Butcher Brothers, also known as Mitchell Altieri and Phil Flores, who also directed the vampire film \"The Hamiltons\"", "fox", "catherine de Bourgh", "chloroplasts, like what happens when a carrot or a potato is illuminated", "Santiago del Estero Province", "more than 265 million business records worldwide"], "metric_results": {"EM": 0.125, "QA-F1": 0.2551984126984127}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.33333333333333337, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.16, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.16666666666666666, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445]}}, "error_ids": ["mrqa_squad-validation-7417", "mrqa_triviaqa-validation-6619", "mrqa_triviaqa-validation-7748", "mrqa_hotpotqa-validation-5415", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4648", "mrqa_triviaqa-validation-1385", "mrqa_hotpotqa-validation-5297", "mrqa_squad-validation-4721", "mrqa_naturalquestions-validation-8911", "mrqa_triviaqa-validation-1583", "mrqa_squad-validation-8526", "mrqa_squad-validation-8837", "mrqa_squad-validation-8369", "mrqa_naturalquestions-validation-1976", "mrqa_squad-validation-6974", "mrqa_hotpotqa-validation-1283", "mrqa_squad-validation-6327", "mrqa_hotpotqa-validation-3345", "mrqa_naturalquestions-validation-7089", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-567", "mrqa_triviaqa-validation-5013", "mrqa_triviaqa-validation-3395", "mrqa_squad-validation-8929", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-2171"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 68, "before_eval": {"predictions": ["Nuevo Reino de Le\u00f3n", "Delaware", "the law of Italy governing the acquisition, transmission and loss of Italian citizenship", "his last starring role was as Boston police detective Barry Frost", "The King of Chutzpah", "P $ C", "energy", "john beck", "English", "john caird", "Monk's", "upper bound", "john john", "the dot", "dieppe", "1961", "Tyler Posey", "Buckland Valley near Bright", "hard-to-fill positions", "Songshan Mountain", "brontosaurus", "qualifications", "Megyn Price", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "james kleibrink", "1939", "tolled ( quota ) highways", "redox", "the major transportation system for eastern and interior Venezuela and the llanos of Colombia", "tyler iv", "the nation of Sokovia", "a politically conservative American news and opinion website"], "metric_results": {"EM": 0.3125, "QA-F1": 0.34412202380952384}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.25]}}, "error_ids": ["mrqa_naturalquestions-validation-6352", "mrqa_triviaqa-validation-4485", "mrqa_hotpotqa-validation-4978", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8791", "mrqa_triviaqa-validation-2723", "mrqa_triviaqa-validation-6896", "mrqa_naturalquestions-validation-339", "mrqa_triviaqa-validation-6302", "mrqa_naturalquestions-validation-10496", "mrqa_hotpotqa-validation-1145", "mrqa_squad-validation-2843", "mrqa_triviaqa-validation-3720", "mrqa_triviaqa-validation-5893", "mrqa_naturalquestions-validation-7286", "mrqa_hotpotqa-validation-2867", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-10354", "mrqa_triviaqa-validation-3089", "mrqa_naturalquestions-validation-2632", "mrqa_hotpotqa-validation-4275"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 69, "before_eval": {"predictions": ["State Route 41", "Max Planck, Albert Einstein, Louis de Broglie, Arthur Compton, Niels Bohr and many others", "music became more expressive and emotional, expanding to encompass literary, artistic, and philosophical themes", "the uplift of mountain ranges", "North Kest even, Lincolnshire, England", "the Ming", "near major hotels and in the parking areas of major Chinese supermarkets", "Abu al-Qasim al-Zahrawi (Abulcasis)", "Hellenismos", "the lower back", "2010", "unknown", "tea, horticultural produce, and coffee", "Barclays", "Joanna Cassidy as Rose Lindsey   John Getz as Gus Brandon   Keith Coogan as Kenneth `` Kenny '' Crandell   Josh Charles as Bryan   Concetta Tomei", "Red : The blood spilled by the heroes who died in the name of their countrymen's Fatherland and Freedom", "island of sand and Fog", "break off the cathode, pass out of the tube, and physically strike him", "Silver Gallery", "21.8 %", "pharmacological effect", "the Yuan dynasty is usually considered to be the legitimate dynasty between the Song dynasty and the Ming dynasty", "Tony Orlando and Dawn", "Paris", "john baez", "Martha Wainwright", "1,462", "island of man", "West Norse sailors", "prince dukas", "Boreas", "1698"], "metric_results": {"EM": 0.1875, "QA-F1": 0.316005608974359}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.125, 0.0, 0.6666666666666665, 0.0, 0.15384615384615383, 0.8571428571428571, 0.0, 0.0, 0.0, 0.09523809523809523, 1.0, 0.0, 0.16666666666666669, 0.1, 0.0, 0.42857142857142855, 0.4, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8059", "mrqa_squad-validation-4929", "mrqa_hotpotqa-validation-4307", "mrqa_naturalquestions-validation-7910", "mrqa_naturalquestions-validation-6949", "mrqa_squad-validation-6464", "mrqa_naturalquestions-validation-4903", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-10583", "mrqa_naturalquestions-validation-4844", "mrqa_triviaqa-validation-2464", "mrqa_naturalquestions-validation-849", "mrqa_naturalquestions-validation-8394", "mrqa_triviaqa-validation-1449", "mrqa_squad-validation-1388", "mrqa_squad-validation-5571", "mrqa_naturalquestions-validation-3035", "mrqa_squad-validation-3610", "mrqa_squad-validation-8185", "mrqa_hotpotqa-validation-3435", "mrqa_triviaqa-validation-5494", "mrqa_hotpotqa-validation-665", "mrqa_triviaqa-validation-6541", "mrqa_naturalquestions-validation-7217", "mrqa_triviaqa-validation-6782", "mrqa_hotpotqa-validation-1381"], "retrieved_ids": ["mrqa_naturalquestions-train-34074", "mrqa_naturalquestions-train-14998", "mrqa_naturalquestions-train-35705", "mrqa_naturalquestions-train-11518", "mrqa_naturalquestions-train-53294", "mrqa_naturalquestions-train-50387", "mrqa_naturalquestions-train-39531", "mrqa_naturalquestions-train-61205", "mrqa_naturalquestions-train-28308", "mrqa_naturalquestions-train-20524", "mrqa_naturalquestions-train-14665", "mrqa_naturalquestions-train-34723", "mrqa_naturalquestions-train-84794", "mrqa_naturalquestions-train-19923", "mrqa_naturalquestions-train-6954", "mrqa_naturalquestions-train-29850", "mrqa_naturalquestions-train-12725", "mrqa_naturalquestions-train-61001", "mrqa_naturalquestions-train-2585", "mrqa_naturalquestions-train-7385", "mrqa_naturalquestions-train-73751", "mrqa_naturalquestions-train-74240", "mrqa_naturalquestions-train-50230", "mrqa_naturalquestions-train-64786", "mrqa_naturalquestions-train-11162", "mrqa_squad-validation-6248", "mrqa_naturalquestions-validation-6151", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-5068", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-671"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 70, "before_eval": {"predictions": ["kurt steiner", "The New York and New Jersey campaign", "Ghost Island", "a hotel room to nurse back to health", "Ford's Victorian plants", "Spanish cordovan leather", "Eadred Lulisc", "1973", "2013 feature film \"Frozen Fever\"", "a loanword of the Visigothic word guma `` man ''", "Major General Miles Francis Stapleton Fitzalan-Howard", "arthur", "New Zealand", "chromium", "white", "a Boeing 767-223ER, registration N334AA, was flying American Airlines' daily scheduled morning transcontinental service from Logan International Airport, in Boston, Massachusetts, to Los Angeles International Airport", "the Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "82.30'E longitude, in Mirzapur, Uttar Pradesh, which is nearly on the corresponding longitude reference line", "a \"theo-democracy\" based on the principles of: tawhid (unity of God) risala (prophethood) and khilafa (caliphate)", "Salman Khan", "Skip Tyler", "the attempt to discover first principles --'those universal principles which are the condition of the possibility of the existence of anything and everything '", "WBMA-LD", "two Nobel Peace Prizes", "Tennessee whiskey", "Tesla said he could feel a sharp stinging pain where it entered his body, and again at the place where it passed out", "king james", "thirty articles affirming an individual's rights which, although not legally binding in themselves, have been elaborated in subsequent international treaties, economic transfers, regional human rights instruments, national constitutions, and other laws", "a straight line (see world line) traveling through time, which normally increases up or to the right in the diagram", "Newton", "International Imitation Hemingway Competition", "Oak Island"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3800406166599568}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.2857142857142857, 0.3333333333333333, 0.0, 0.3076923076923077, 1.0, 0.0, 0.14285714285714285, 0.2105263157894737, 0.4761904761904762, 0.35294117647058826, 0.0, 1.0, 0.08, 1.0, 1.0, 0.0, 0.6875000000000001, 0.8, 0.2105263157894737, 0.21052631578947367, 0.0, 0.28571428571428575, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-831", "mrqa_squad-validation-1632", "mrqa_squad-validation-2980", "mrqa_triviaqa-validation-5981", "mrqa_hotpotqa-validation-471", "mrqa_naturalquestions-validation-710", "mrqa_hotpotqa-validation-259", "mrqa_naturalquestions-validation-3019", "mrqa_hotpotqa-validation-5334", "mrqa_triviaqa-validation-2331", "mrqa_naturalquestions-validation-4567", "mrqa_triviaqa-validation-672", "mrqa_hotpotqa-validation-4323", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-4891", "mrqa_squad-validation-9661", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-4211", "mrqa_triviaqa-validation-1408", "mrqa_squad-validation-1389", "mrqa_triviaqa-validation-2546", "mrqa_naturalquestions-validation-7938", "mrqa_squad-validation-10477", "mrqa_squad-validation-361", "mrqa_hotpotqa-validation-4543"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 71, "before_eval": {"predictions": ["John D. Rockefeller", "42", "electrical, water, sewage, phone, and cable facilities", "Saxe-Coburg and Gotha", "16,000", "There is no known case of any U.S. citizens buying Canadian drugs for personal use with a prescription", "Dwight David \"Ike\" Eisenhower", "multi-purpose", "Tang, Song, as well as Khitan Liao and Jurchen Jin dynasties", "twelve", "Somme", "Randal Keith Orton", "RuPaul", "a liquid in specially insulated tankers", "Sunday", "October 16, 2012", "Austria's border with the Czech Republic", "1996", "alpha efferent neurons", "whitetail deer, reindeer, elk, moose, mule deer, blacktail deer and caribou", "David Irving", "cauliflower", "rock and roll and rockabilly", "Hongwu Emperor of the Ming Dynasty", "king", "1565", "rapid expansion in telecommunication and financial activity", "london", "Cameron Fraser", "political", "london", "American R&B vocal group"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3631380772005772}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.4, 0.0, 0.7499999999999999, 1.0, 1.0, 0.5714285714285715, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-253", "mrqa_hotpotqa-validation-862", "mrqa_squad-validation-4344", "mrqa_squad-validation-6383", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-5619", "mrqa_naturalquestions-validation-2635", "mrqa_triviaqa-validation-6938", "mrqa_hotpotqa-validation-583", "mrqa_naturalquestions-validation-8136", "mrqa_squad-validation-3689", "mrqa_hotpotqa-validation-5203", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2548", "mrqa_triviaqa-validation-2157", "mrqa_triviaqa-validation-4291", "mrqa_triviaqa-validation-1185", "mrqa_naturalquestions-validation-8907", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-2477", "mrqa_triviaqa-validation-1640", "mrqa_naturalquestions-validation-2847", "mrqa_triviaqa-validation-4464"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 72, "before_eval": {"predictions": ["Monk's Caf\u00e9", "ancient Rome with gift - giving during the Saturnalia holiday, which took place that month", "fourth- ranking Republican leader in the House", "seven", "the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem", "Operation Neptune", "john f kenzie", "Patrick Moore", "alpaca fiber and mohair from Angora goats", "Muskogean", "effective conceptualizations", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "a gesture in which the head is tilted in alternating up and down arcs along the sagittal plane", "Field of Dreams", "snow and rain", "Parliament", "# 4 School of Public Health in the country", "heathaway", "dolphin", "1883\u201384", "yellow", "`` A Pr\u00e9sent Tu Peux t'en Aller '", "greenish colour of the water", "Macau Peninsula, Macau", "separate to form new pyrenoids, or be produced \"de novo\"", "john marr", "747", "erotic romantic comedy", "Greg", "1748", "Puente Hills Mall, located in the City of Industry, California, United States", "l'Arc de triomphe"], "metric_results": {"EM": 0.125, "QA-F1": 0.3020752684815185}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.4, 0.7272727272727274, 0.7272727272727272, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8181818181818181, 0.125, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.9, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-4815", "mrqa_hotpotqa-validation-4560", "mrqa_hotpotqa-validation-1110", "mrqa_squad-validation-1760", "mrqa_hotpotqa-validation-4061", "mrqa_triviaqa-validation-6606", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-5531", "mrqa_hotpotqa-validation-946", "mrqa_naturalquestions-validation-1507", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-1359", "mrqa_squad-validation-3592", "mrqa_naturalquestions-validation-9306", "mrqa_triviaqa-validation-417", "mrqa_triviaqa-validation-3799", "mrqa_squad-validation-9855", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-5393", "mrqa_hotpotqa-validation-1394", "mrqa_squad-validation-8829", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-1162", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1028", "mrqa_hotpotqa-validation-1858", "mrqa_triviaqa-validation-7377"], "retrieved_ids": ["mrqa_naturalquestions-train-43649", "mrqa_naturalquestions-train-7111", "mrqa_naturalquestions-train-53220", "mrqa_naturalquestions-train-43670", "mrqa_naturalquestions-train-35335", "mrqa_naturalquestions-train-73581", "mrqa_naturalquestions-train-58934", "mrqa_naturalquestions-train-38634", "mrqa_naturalquestions-train-55646", "mrqa_naturalquestions-train-63162", "mrqa_naturalquestions-train-12309", "mrqa_naturalquestions-train-34585", "mrqa_naturalquestions-train-14282", "mrqa_naturalquestions-train-79545", "mrqa_naturalquestions-train-43889", "mrqa_naturalquestions-train-3681", "mrqa_naturalquestions-train-48391", "mrqa_naturalquestions-train-64160", "mrqa_naturalquestions-train-53151", "mrqa_naturalquestions-train-48082", "mrqa_naturalquestions-train-28877", "mrqa_naturalquestions-train-61421", "mrqa_naturalquestions-train-31923", "mrqa_naturalquestions-train-53365", "mrqa_naturalquestions-train-31594", "mrqa_squad-validation-1249", "mrqa_triviaqa-validation-4095", "mrqa_naturalquestions-validation-3504", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-7688", "mrqa_squad-validation-4253", "mrqa_hotpotqa-validation-1315"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 73, "before_eval": {"predictions": ["northwest", "mother", "energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+)", "Levi's Stadium", "Medal of Honor", "4 km", "The Future", "Wapakoneta, Ohio", "epic historical drama", "Wahhabism or Salafism", "buzzards", "drug management system development, deployment and optimization", "that first set of endosymbiotic events", "Danish - Norwegian patronymic surname meaning `` son of Anders '' ( itself derived from the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew )", "Edward Trowbridge Collins Sr.", "September 2014", "when a country's influence is felt in social and cultural circles, i.e. its soft power, such that it changes the moral, cultural and societal worldview of another", "increased productivity, trade, and secular economic trends", "purple rain", "the early 20th century", "in 1958 and 1979", "geographer", "200\u2013300", "his mind", "has extended structure and forces that act on one part of an object might affect other parts of an objects", "the force exerted by standard gravity on one kilogram of mass", "the \"gliding Dance of the Maidens\"", "tony", "the government - owned Panama Canal Authority", "Vernier, Switzerland", "three", "The Today Show"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2855498059445428}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.9090909090909091, 0.10526315789473684, 1.0, 0.33333333333333337, 0.14814814814814814, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.09999999999999999, 0.0, 0.0, 0.0, 0.3846153846153846, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-5024", "mrqa_squad-validation-8727", "mrqa_squad-validation-139", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-186", "mrqa_triviaqa-validation-56", "mrqa_hotpotqa-validation-3483", "mrqa_squad-validation-9592", "mrqa_triviaqa-validation-7082", "mrqa_squad-validation-6388", "mrqa_squad-validation-8801", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-2069", "mrqa_squad-validation-9871", "mrqa_naturalquestions-validation-9530", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-2567", "mrqa_squad-validation-6550", "mrqa_squad-validation-1510", "mrqa_squad-validation-10430", "mrqa_squad-validation-10455", "mrqa_hotpotqa-validation-4284", "mrqa_triviaqa-validation-4408", "mrqa_naturalquestions-validation-9753", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-3407"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 74, "before_eval": {"predictions": ["the Gulf of Mexico and stretches to the tip of Florida", "Friedrich Nietzsche", "nellie", "Anglo-Frisian languages", "waltham forest borough", "Zeppelin airship", "xylisector", "DeWayne Warren", "5 ft", "hard Candy", "George Merrill and Shannon Rubicam of the band Boy Meets Girl", "near the end of the El Camino Real de Tierra Adentro", "1943", "translation", "wai Momi", "a \"consulting fee\" to get around Tesla's aversion to accept charity", "student tuition, endowments, scholarship/voucher funds, and donations and grants from religious organizations or private individuals", "tolerance of civil disobedience", "ed Miliband", "China in American colonies", "written by ghost writers, nonfiction books on military subjects, and video games", "British and French Canadian fur traders from before 1810, and American settlers from the mid-1830s", "Instagram's own account", "Johann Sebastian Bach, Karlheinz Stockhausen, Terry Riley, Philip Glass and Moondog", "1986", "a sandy beach by the village of Warszowa", "22 July 1930", "the strong force acts indirectly, transmitted as gluons, which form part of the virtual pi and rho mesons", "written each article of the Creed to express the character of the Father, the Son, or the Holy Spirit", "April 13, 2018", "\"Gosford Park\"", "an American business magnate, investor, and philanthropist"], "metric_results": {"EM": 0.15625, "QA-F1": 0.22266752344877344}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.0, 1.0, 1.0, 0.0, 0.0, 0.125, 1.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.3333333333333333, 0.0, 0.2857142857142857]}}, "error_ids": ["mrqa_naturalquestions-validation-8072", "mrqa_hotpotqa-validation-5520", "mrqa_triviaqa-validation-6002", "mrqa_hotpotqa-validation-2098", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6573", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2644", "mrqa_triviaqa-validation-4275", "mrqa_naturalquestions-validation-8008", "mrqa_naturalquestions-validation-7462", "mrqa_triviaqa-validation-2938", "mrqa_squad-validation-1462", "mrqa_squad-validation-7086", "mrqa_naturalquestions-validation-642", "mrqa_hotpotqa-validation-2220", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1027", "mrqa_hotpotqa-validation-726", "mrqa_naturalquestions-validation-9487", "mrqa_squad-validation-801", "mrqa_hotpotqa-validation-4964", "mrqa_squad-validation-10447", "mrqa_squad-validation-2391", "mrqa_naturalquestions-validation-177", "mrqa_triviaqa-validation-5108", "mrqa_hotpotqa-validation-83"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 75, "before_eval": {"predictions": ["around the time when ARPANET was interlinked with NSFNET in the late 1980s", "Andrea Palladio", "Bert Jansch", "Gaahl", "three", "Armored Vehicles", "bannockburn", "author Studs Terkel", "Persian Gulf", "1902", "Statue of Freedom", "18 November 1963", "17:16:20 GMT", "30 percent", "Somerville", "the state legislators of Assam", "350 government officials and climate change experts", "roof of the choir side - aisles at Durham Cathedral", "russia", "scrolls", "Environmental Protection Agency", "523 km", "tube", "music arranger", "one person", "Luger P08", "Al-Masjid an-Nabawi", "Babur", "mary magdalene", "from Manitoba, Ontario and Nova Scotia in southern Canada to northern Florida and from the Atlantic coast to the Missouri River and the eastern Great Plains", "manned lunar landings", "spanish airlines"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3155068277310924}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 0.25, 0.11764705882352941, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.14285714285714288, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_squad-validation-5628", "mrqa_hotpotqa-validation-551", "mrqa_hotpotqa-validation-3306", "mrqa_triviaqa-validation-1217", "mrqa_naturalquestions-validation-9426", "mrqa_triviaqa-validation-6051", "mrqa_squad-validation-8035", "mrqa_triviaqa-validation-5878", "mrqa_hotpotqa-validation-5643", "mrqa_squad-validation-7732", "mrqa_squad-validation-683", "mrqa_hotpotqa-validation-1689", "mrqa_naturalquestions-validation-9546", "mrqa_squad-validation-8525", "mrqa_naturalquestions-validation-9576", "mrqa_triviaqa-validation-2879", "mrqa_naturalquestions-validation-3347", "mrqa_hotpotqa-validation-1298", "mrqa_squad-validation-903", "mrqa_triviaqa-validation-1205", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4413", "mrqa_triviaqa-validation-1199", "mrqa_naturalquestions-validation-2006", "mrqa_squad-validation-3775", "mrqa_hotpotqa-validation-2646"], "retrieved_ids": ["mrqa_naturalquestions-train-26794", "mrqa_naturalquestions-train-58157", "mrqa_naturalquestions-train-52737", "mrqa_naturalquestions-train-31526", "mrqa_naturalquestions-train-56233", "mrqa_naturalquestions-train-15941", "mrqa_naturalquestions-train-10748", "mrqa_naturalquestions-train-81877", "mrqa_naturalquestions-train-49515", "mrqa_naturalquestions-train-71011", "mrqa_naturalquestions-train-81508", "mrqa_naturalquestions-train-39540", "mrqa_naturalquestions-train-77142", "mrqa_naturalquestions-train-58170", "mrqa_naturalquestions-train-4894", "mrqa_naturalquestions-train-49902", "mrqa_naturalquestions-train-26827", "mrqa_naturalquestions-train-18885", "mrqa_naturalquestions-train-74085", "mrqa_naturalquestions-train-18707", "mrqa_naturalquestions-train-38333", "mrqa_naturalquestions-train-57184", "mrqa_naturalquestions-train-18189", "mrqa_naturalquestions-train-12851", "mrqa_naturalquestions-train-6941", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-7511", "mrqa_triviaqa-validation-6380", "mrqa_squad-validation-7711", "mrqa_naturalquestions-validation-6896", "mrqa_squad-validation-6399", "mrqa_naturalquestions-validation-1173"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 76, "before_eval": {"predictions": ["Tampa Bay defensive end Simeon Rice sacked Raiders quarterback Rich Gannon on third down, forcing Oakland to settle for kicker Sebastian Janikowski's 40 - yard field goal to give them a 3 -- 0 lead", "2018", "many bands, including a 1990 single by Saint Etienne", "novelization of the 1977 film Star Wars", "May 27, 2016", "Colonization movement or Black Zionism", "congressional districts", "trees", "\"Naked\"", "Conrad Lewis", "As of December 10, 2017 ( 2017 - 12 - 10 ), 205 original episodes of Keeping Up with the Kardashians have aired concluding the fourteen seasons", "Hertz Corporation", "2010", "Title XIX, which became known as Medicaid", "Christian Goldbach", "Sue Sylvester", "buff-tipped skipper", "federal government's nearly 700 million acres ( 2,800,000 km ) of subsurface mineral estate located beneath federal, state and private lands severed from their surface rights by the Homestead Act of 1862", "be reborn, often many times, in order to continue their Bodhisattva vow is called a Tulku", "Bhpppavageete", "Tachycardia, also called tachyarrhythmia", "Nayvadius DeMun Wilburn", "Richard Burbage", "blood poisoning", "Parliament of the United Kingdom", "achievement-oriented motivations (\" pull\") such as vocation and more likely to involve the pursue of new products, services, or underserved market needs", "discarded just before re-entry", "A Song of Ice and Fire", "morrissey", "Julia McKenzie and Anton Rodgers", "15 February 1998", "Amazon.com"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30534552156002015}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 0.6666666666666666, 0.0, 0.06666666666666667, 0.0, 0.0, 1.0, 0.06451612903225806, 0.33333333333333337, 0.0, 0.28571428571428575, 0.0, 0.25, 0.6666666666666666, 0.4, 0.2608695652173913, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2799", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-7535", "mrqa_hotpotqa-validation-3337", "mrqa_naturalquestions-validation-2102", "mrqa_triviaqa-validation-4440", "mrqa_hotpotqa-validation-2786", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-53", "mrqa_hotpotqa-validation-3678", "mrqa_hotpotqa-validation-1314", "mrqa_naturalquestions-validation-6258", "mrqa_squad-validation-9014", "mrqa_hotpotqa-validation-3232", "mrqa_naturalquestions-validation-6027", "mrqa_squad-validation-1927", "mrqa_hotpotqa-validation-4510", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-956", "mrqa_naturalquestions-validation-2270", "mrqa_squad-validation-5031", "mrqa_squad-validation-9547", "mrqa_squad-validation-7323", "mrqa_squad-validation-3885", "mrqa_triviaqa-validation-5849", "mrqa_naturalquestions-validation-9591"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 77, "before_eval": {"predictions": ["Toronto Huskies", "100-meter freestyle", "genetic branches", "east-west through the centre of Victoria", "four", "centrale", "tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "lofsongur", "islay", "troposphere", "Lesser Antilles", "The Fixx", "1,382 inhabitants as per the 2001 census", "The Swiss Express", "an error. Scholars and observers who don't believe that Islam is merely a political ideology include Fred Halliday, John Esposito and Muslim intellectuals like Javed Ahmad Ghamidi", "handwriting", "highest quotient", "Matilda of Anjou", "K-pop artists After School, Orange Caramel, NU'EST, Han Dong Geun, Kye Bumzu, Seventeen and Pristin", "Jack", "at any time after the auction", "most northerly of the five major circles of latitude", "The Sons of Anarchy ( SOA ) is an outlaw motorcycle club", "Walker Art Gallery", "Chinese: \u5927\u5143", "Song Il-gon", "1974", "Acura", "dangerous by-products of oxygen use in organisms. Parts of the immune system of higher organisms create peroxide, superoxide, and singlet oxygen to destroy invading microbes", "food and clothing", "The Emperor of Japan", "naturally produced in the human body from the amino acids glycine and arginine"], "metric_results": {"EM": 0.25, "QA-F1": 0.3937908000572359}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.07692307692307693, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 0.2857142857142857, 0.0, 0.21428571428571425, 1.0, 0.6666666666666666, 0.0, 0.125, 0.0, 0.2857142857142857, 0.7272727272727273, 0.43478260869565216, 0.0, 0.0, 1.0, 1.0, 0.0, 0.45161290322580644, 0.0, 1.0, 0.16666666666666669]}}, "error_ids": ["mrqa_naturalquestions-validation-70", "mrqa_triviaqa-validation-6483", "mrqa_squad-validation-2913", "mrqa_triviaqa-validation-3900", "mrqa_naturalquestions-validation-6452", "mrqa_triviaqa-validation-593", "mrqa_triviaqa-validation-2095", "mrqa_naturalquestions-validation-8584", "mrqa_hotpotqa-validation-5052", "mrqa_hotpotqa-validation-1921", "mrqa_squad-validation-9520", "mrqa_squad-validation-9530", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-4167", "mrqa_hotpotqa-validation-4766", "mrqa_naturalquestions-validation-4475", "mrqa_naturalquestions-validation-4117", "mrqa_naturalquestions-validation-7845", "mrqa_triviaqa-validation-1780", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-7610", "mrqa_squad-validation-3543", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-686"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 78, "before_eval": {"predictions": ["21 June 2007", "specialised education and training who perform various roles to ensure optimal health outcomes for their patients through the quality use of medicines", "fox", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "neuro-orthopaedic", "crim", "l. c. Page & Co.", "fibrous joint", "Ronnie Scott", "slogans", "east end of london", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1484", "main type of cell found in lymph, which prompted the name `` lymphocyte ''", "a combination of electronic sound sources, live instrumental playing and digital signal processing", "established by Napoleon, as a French client state, in 1806 and lasted until 1814", "( latent ) heat of fusion, is the change in its enthalpy resulting from providing energy, typically heat, to a specific quantity of the substance to change its state from a solid to a liquid", "Mongolian", "Gap", "The Indianapolis Times and the Cleveland Press", "Jurchen Aisin Gioro clan in Manchuria", "baloney", "an expedition through the wilderness of the Maine district and down the Chaudi\u00e8re River to attack the city of Quebec", "friendship and reunion, saying that there can only be one sun in the sky, and he asked for a noble death", "121.7 sq mi or 302 km2", "Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840, and John Stockton leads the point - assists combination with 714", "DTIME(n2)", "allegedly corrupt machinations of Fran\u00e7ois Bigot, the intendant of the territory. His schemes to supply the colony inflated prices and were believed by Montcalm to line his pockets and those of his associates.", "loud and dirty", "Don Von Tress", "chocolate confectionery"], "metric_results": {"EM": 0.0625, "QA-F1": 0.22321304308436662}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.15384615384615385, 0.0, 0.35294117647058826, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.92, 0.0, 1.0, 0.16666666666666669, 0.23529411764705882, 0.14285714285714288, 0.35000000000000003, 0.0, 0.0, 0.5714285714285715, 0.2857142857142857, 0.0, 0.1212121212121212, 0.1, 0.0, 0.7428571428571429, 0.0, 0.33333333333333337, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_squad-validation-6280", "mrqa_triviaqa-validation-1117", "mrqa_naturalquestions-validation-5838", "mrqa_triviaqa-validation-4676", "mrqa_triviaqa-validation-1658", "mrqa_triviaqa-validation-4063", "mrqa_triviaqa-validation-1168", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-5011", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6497", "mrqa_naturalquestions-validation-9342", "mrqa_hotpotqa-validation-1296", "mrqa_squad-validation-9445", "mrqa_naturalquestions-validation-1119", "mrqa_squad-validation-8083", "mrqa_squad-validation-421", "mrqa_hotpotqa-validation-4864", "mrqa_naturalquestions-validation-7311", "mrqa_triviaqa-validation-1916", "mrqa_squad-validation-10239", "mrqa_squad-validation-6115", "mrqa_squad-validation-7476", "mrqa_naturalquestions-validation-276", "mrqa_squad-validation-1807", "mrqa_squad-validation-10298", "mrqa_hotpotqa-validation-2437", "mrqa_triviaqa-validation-3616", "mrqa_triviaqa-validation-1465"], "retrieved_ids": ["mrqa_naturalquestions-train-36567", "mrqa_naturalquestions-train-86392", "mrqa_naturalquestions-train-46514", "mrqa_naturalquestions-train-41396", "mrqa_naturalquestions-train-19456", "mrqa_naturalquestions-train-28535", "mrqa_naturalquestions-train-6514", "mrqa_naturalquestions-train-60716", "mrqa_naturalquestions-train-64402", "mrqa_naturalquestions-train-14943", "mrqa_naturalquestions-train-64945", "mrqa_naturalquestions-train-81588", "mrqa_naturalquestions-train-20069", "mrqa_naturalquestions-train-83123", "mrqa_naturalquestions-train-25228", "mrqa_naturalquestions-train-38749", "mrqa_naturalquestions-train-37925", "mrqa_naturalquestions-train-83175", "mrqa_naturalquestions-train-73138", "mrqa_naturalquestions-train-27619", "mrqa_naturalquestions-train-76387", "mrqa_naturalquestions-train-81231", "mrqa_naturalquestions-train-61757", "mrqa_naturalquestions-train-79891", "mrqa_naturalquestions-train-35135", "mrqa_naturalquestions-validation-2884", "mrqa_naturalquestions-validation-71", "mrqa_naturalquestions-validation-2962", "mrqa_hotpotqa-validation-5683", "mrqa_squad-validation-7792", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-199"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 79, "before_eval": {"predictions": ["Sir Hiram Stevens Maxim", "1987", "February 2011", "make direct representations to the Presiding Officer to nominate speakers", "Chesley Burnett \"Sully\" Sullenberger III", "October 12, 2017", "an allegiance oath that must be taken by all immigrants who wish to become United States citizens", "Robert", "Tom Hanks", "clay animation or \"clay-mation\"", "new Hampshire", "September of that year", "euro sign ( \u20ac ) is the currency sign used for the euro, the official currency of the Eurozone in the European Union ( EU )", "The stationary steam engine was a key component of the Industrial Revolution", "a spherical boundary of zero thickness", "porcini", "wGN-TV", "rugged terrain such as the Arctic", "the Mexico\u2013united States border", "The American Football Conference (AFC) champion Denver Broncos", "a ribosome in the cytosol", "Oyster Bay", "Ringo Starr", "leicestershire", "gas turbines", "provided majority of members present at that time approved the bill either by voting or voice vote", "Shoushi Li (\u6388\u6642\u66a6) or Calendar for Fixing the Seasons", "16 %", "jamaica", "Secretary of Defense", "pancake-shaped circular disks about 300\u2013600 nanometers in diameter", "thirteen American colonies, then at war with the Kingdom of Great Britain, regarded themselves as thirteen independent sovereign states, no longer under British rule"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3787304332141288}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.4, 0.3636363636363636, 0.33333333333333337, 1.0, 0.35714285714285715, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.22222222222222224, 0.3636363636363636, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.6086956521739131, 0.4, 0.2222222222222222, 0.0, 1.0, 0.18181818181818182, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4516", "mrqa_naturalquestions-validation-9184", "mrqa_naturalquestions-validation-7733", "mrqa_squad-validation-9407", "mrqa_hotpotqa-validation-4934", "mrqa_naturalquestions-validation-1672", "mrqa_triviaqa-validation-7178", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2846", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4529", "mrqa_squad-validation-3256", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-5589", "mrqa_triviaqa-validation-5983", "mrqa_squad-validation-3738", "mrqa_squad-validation-1", "mrqa_squad-validation-8960", "mrqa_triviaqa-validation-5529", "mrqa_squad-validation-3369", "mrqa_naturalquestions-validation-3591", "mrqa_squad-validation-8233", "mrqa_naturalquestions-validation-8509", "mrqa_triviaqa-validation-1912", "mrqa_squad-validation-8811", "mrqa_naturalquestions-validation-360"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 80, "before_eval": {"predictions": ["John Mills", "calliope", "lidwina Shapwa", "Sachin Tendulkar", "fredeway", "Terre Haute", "in all the major theatres of the Second World War", "the oil shock", "l Luxembourg", "State Bar of Arizona", "to detect medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "beer", "HgO", "red", "pet", "1967", "Mondays", "22 miles (35 km)", "1598", "on the coastline peninsula of Davenports Neck called \"Bauffet's Point\"", "geoffrey lincoln", "london", "Topeka", "additional French forces under Claude-Pierre Pecaudy de Contrec\u0153ur to relieve Saint-Pierre during the same period", "rochdale", "hijab", "Hong Kong in 1894", "they were inserted before \"May God help me\" only in later versions of the speech and not recorded in witness accounts of the proceedings", "`` Nelson's Sparrow ''", "coldplay", "phowa and siddhi", "primary law, secondary law and supplementary law"], "metric_results": {"EM": 0.25, "QA-F1": 0.32980045553574966}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 0.37037037037037035, 0.4, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3100", "mrqa_triviaqa-validation-6493", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-2148", "mrqa_triviaqa-validation-6063", "mrqa_hotpotqa-validation-3056", "mrqa_hotpotqa-validation-3282", "mrqa_triviaqa-validation-7358", "mrqa_naturalquestions-validation-3092", "mrqa_naturalquestions-validation-7848", "mrqa_hotpotqa-validation-3779", "mrqa_triviaqa-validation-3076", "mrqa_triviaqa-validation-1261", "mrqa_squad-validation-4818", "mrqa_squad-validation-3038", "mrqa_squad-validation-3318", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-2009", "mrqa_hotpotqa-validation-2840", "mrqa_squad-validation-10182", "mrqa_triviaqa-validation-5904", "mrqa_squad-validation-2223", "mrqa_naturalquestions-validation-3822", "mrqa_triviaqa-validation-6129"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 81, "before_eval": {"predictions": ["one", "Super Bowl L", "2005", "served only as an adviser to churches in new territories", "USD 3.1 billion", "A rear - view mirror", "The Birds", "identify rock samples in the laboratory", "French & Saunders", "the European Parliament", "the Beatles song \"A Day in the Life\"", "either February 28 or March 1, while others only observe birthdays on the authentic intercalary date, February 29", "Fred Ott", "a duo", "their defeat by the Swabian League at the Battle of Frankenhausen on 15 May 1525", "red hot poker", "a new entrance building", "national unity", "caribbean", "three", "construction service firms (e.g. engineering, architecture) and construction managers (firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project)", "london", "`` Feed Jake '' is a song written by Danny `` Bear '' Mayo", "several hundred thousand", "physics", "Noel Gallagher", "Max West", "British Trains East Coast", "aluminium", "newspapers, television, radio, cable television, and other businesses", "Lakshmibai", "acupuncture, moxibustion, pulse diagnosis, and various herbal drugs and elixirs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28943583210949697}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.19999999999999998, 0.375, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.21052631578947367, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5294117647058824, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.7692307692307693, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7", "mrqa_squad-validation-7728", "mrqa_squad-validation-2481", "mrqa_naturalquestions-validation-2776", "mrqa_hotpotqa-validation-1949", "mrqa_squad-validation-5055", "mrqa_squad-validation-4541", "mrqa_triviaqa-validation-1724", "mrqa_naturalquestions-validation-4809", "mrqa_hotpotqa-validation-1701", "mrqa_squad-validation-2287", "mrqa_triviaqa-validation-4596", "mrqa_squad-validation-5447", "mrqa_triviaqa-validation-1305", "mrqa_triviaqa-validation-5598", "mrqa_triviaqa-validation-2632", "mrqa_squad-validation-6764", "mrqa_triviaqa-validation-1476", "mrqa_naturalquestions-validation-7838", "mrqa_squad-validation-914", "mrqa_triviaqa-validation-296", "mrqa_hotpotqa-validation-3695", "mrqa_squad-validation-5288", "mrqa_triviaqa-validation-5741", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-1664"], "retrieved_ids": ["mrqa_naturalquestions-train-84339", "mrqa_naturalquestions-train-27915", "mrqa_naturalquestions-train-45980", "mrqa_naturalquestions-train-50510", "mrqa_naturalquestions-train-53882", "mrqa_naturalquestions-train-46744", "mrqa_naturalquestions-train-28871", "mrqa_naturalquestions-train-85490", "mrqa_naturalquestions-train-32517", "mrqa_naturalquestions-train-20391", "mrqa_naturalquestions-train-71358", "mrqa_naturalquestions-train-63912", "mrqa_naturalquestions-train-59401", "mrqa_naturalquestions-train-25822", "mrqa_naturalquestions-train-47234", "mrqa_naturalquestions-train-69368", "mrqa_naturalquestions-train-18961", "mrqa_naturalquestions-train-66491", "mrqa_naturalquestions-train-48082", "mrqa_naturalquestions-train-60991", "mrqa_naturalquestions-train-86271", "mrqa_naturalquestions-train-18012", "mrqa_naturalquestions-train-50048", "mrqa_naturalquestions-train-3258", "mrqa_naturalquestions-train-49244", "mrqa_squad-validation-10239", "mrqa_squad-validation-9808", "mrqa_squad-validation-6811", "mrqa_squad-validation-8909", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-2748"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 82, "before_eval": {"predictions": ["kyle of durness", "The normal force", "legs", "24 hours later", "1945", "dachshund", "helped farmers grow new pigeon pea varieties, instead of maize", "geologic", "129", "Bunkhouse", "foot", "a growing sport", "geese", "his friend and future rival, Jamukha, and his protector, Toghrul Khan of the Keraite tribe", "tentacles and prey", "national capital", "Ramanaa", "Lawrence County State's Attorney John Fitzgerald, Chief Deputy Attorney General Charlie McGuigan, and attorney and 2014 U.S. Senate candidate Jason Ravnsborg", "water on the ground surface enters the soil", "9.9ft", "film and short novels", "American-Canadian mystery-drama", "Arrested Development", "Gardnerville", "Nucleotides", "25-minute episodes", "Wiki", "zapatista national Liberation", "Tinu Suresh Desai", "cuckold", "2003", "salt"], "metric_results": {"EM": 0.21875, "QA-F1": 0.34872915104947527}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.782608695652174, 0.5, 0.0, 0.0, 0.5517241379310345, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2133", "mrqa_naturalquestions-validation-579", "mrqa_naturalquestions-validation-215", "mrqa_hotpotqa-validation-4420", "mrqa_squad-validation-8322", "mrqa_squad-validation-2791", "mrqa_squad-validation-9603", "mrqa_naturalquestions-validation-2347", "mrqa_triviaqa-validation-5592", "mrqa_squad-validation-2748", "mrqa_triviaqa-validation-1053", "mrqa_squad-validation-6113", "mrqa_squad-validation-4616", "mrqa_triviaqa-validation-1685", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-8544", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-863", "mrqa_hotpotqa-validation-290", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-1639", "mrqa_triviaqa-validation-2236", "mrqa_triviaqa-validation-2592", "mrqa_naturalquestions-validation-9117", "mrqa_triviaqa-validation-7419"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 83, "before_eval": {"predictions": ["alberto Aleandro Uderzo", "North Africa", "a young girl", "architecture from the gothic, renaissance, baroque and neoclassical periods", "back down to the ground", "the aboral organ", "goliath birdeater", "scrooge", "northridge", "Cushman", "Maidstone", "the kingdoms of Francia on the Lower Rhine, Burgundy on the Upper Rhine and Alemannia", "Suleiman I", "1 -- 3", "james cameron", "difficult and intricate", "electronic junk mail", "ABC Radio", "Tahiti", "detritus from the settlement of the sedimentation", "R Rihanna", "matthew", "Steveston Outdoor pool", "Nikola Tesla", "Terry the Tomboy", "scarlet tanager", "Australia", "Mach number", "circles the track at pit road speed during the warm - up laps", "North Atlantic Conference", "at the group's final British performance on 14 July 2012 at the National Bowl in Milton Keynes", "bbc"], "metric_results": {"EM": 0.21875, "QA-F1": 0.35173264235764234}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.6153846153846153, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.14285714285714288, 0.33333333333333337, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4615384615384615, 1.0, 0.8484848484848485, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3493", "mrqa_squad-validation-9912", "mrqa_naturalquestions-validation-1805", "mrqa_squad-validation-920", "mrqa_naturalquestions-validation-6856", "mrqa_triviaqa-validation-3113", "mrqa_triviaqa-validation-271", "mrqa_triviaqa-validation-7486", "mrqa_squad-validation-3107", "mrqa_squad-validation-9349", "mrqa_naturalquestions-validation-5214", "mrqa_triviaqa-validation-5960", "mrqa_hotpotqa-validation-2964", "mrqa_triviaqa-validation-90", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-1798", "mrqa_hotpotqa-validation-4966", "mrqa_triviaqa-validation-3987", "mrqa_naturalquestions-validation-7172", "mrqa_squad-validation-1159", "mrqa_triviaqa-validation-570", "mrqa_hotpotqa-validation-4102", "mrqa_naturalquestions-validation-5984", "mrqa_naturalquestions-validation-8518", "mrqa_triviaqa-validation-5793"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 84, "before_eval": {"predictions": ["music", "13 years and 48 days", "Major Lionel Booth", "Theodosius I", "Ubiorum", "in front of only 700 fans", "Brixton", "60", "Assistant Secretary for Administration and Management", "engine offers much better fuel economy, which Orenda Aerospace felt would be attractive for older aircraft whose engines were reaching the end of their lifespan", "september", "evacuate the cylinder, choking it and giving excessive compression (\"kick back\")", "trees", "optic disc", "Carson City", "biologist", "Egyptians", "wis warfield", "the title `` The Chariot ''", "United States ambassador to Ghana and to Czechoslovakia", "NBA Finals", "Emma Thompson", "edible - nest swiftlets", "shepherds", "travel literature, cartography, geography, and scientific education", "ruler", "Chaplain to the Forces serving at the Tower of London and in Bengal, Caterham, South Africa (where he was Mentioned in despatches) and Portsmouth until his Archdeacon\u2019s appointment", "chiang Kai-Shek", "125 lb (57 kg) and below", "thoracic", "car", "a prison"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2685484076109076}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2222222222222222, 0.2857142857142857, 0.0, 0.33333333333333337, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0, 0.0, 0.07407407407407407, 0.0, 0.8, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-370", "mrqa_hotpotqa-validation-3830", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-6794", "mrqa_triviaqa-validation-2014", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1628", "mrqa_hotpotqa-validation-4414", "mrqa_triviaqa-validation-5687", "mrqa_squad-validation-3364", "mrqa_triviaqa-validation-1529", "mrqa_naturalquestions-validation-3368", "mrqa_triviaqa-validation-3538", "mrqa_naturalquestions-validation-10461", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-661", "mrqa_naturalquestions-validation-732", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1645", "mrqa_hotpotqa-validation-989", "mrqa_triviaqa-validation-159", "mrqa_hotpotqa-validation-1810", "mrqa_naturalquestions-validation-3173", "mrqa_triviaqa-validation-4696", "mrqa_naturalquestions-validation-6660"], "retrieved_ids": ["mrqa_naturalquestions-train-17271", "mrqa_naturalquestions-train-10480", "mrqa_naturalquestions-train-68658", "mrqa_naturalquestions-train-10536", "mrqa_naturalquestions-train-37346", "mrqa_naturalquestions-train-34980", "mrqa_naturalquestions-train-67841", "mrqa_naturalquestions-train-51048", "mrqa_naturalquestions-train-28559", "mrqa_naturalquestions-train-32854", "mrqa_naturalquestions-train-44113", "mrqa_naturalquestions-train-1535", "mrqa_naturalquestions-train-86951", "mrqa_naturalquestions-train-49365", "mrqa_naturalquestions-train-69047", "mrqa_naturalquestions-train-53933", "mrqa_naturalquestions-train-82835", "mrqa_naturalquestions-train-39785", "mrqa_naturalquestions-train-81721", "mrqa_naturalquestions-train-3656", "mrqa_naturalquestions-train-65815", "mrqa_naturalquestions-train-20244", "mrqa_naturalquestions-train-81129", "mrqa_naturalquestions-train-25040", "mrqa_naturalquestions-train-75264", "mrqa_naturalquestions-validation-1975", "mrqa_triviaqa-validation-7419", "mrqa_hotpotqa-validation-5307", "mrqa_squad-validation-10312", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-5655"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 85, "before_eval": {"predictions": ["Europe, North America, East Asia and South Asia", "about 10,000", "Stevie Young", "one of the four temperate seasons", "3000 metres", "October 13, 1980", "between 1765 and 1783", "northern Canada", "heart-lung", "at each place there are a bread roll ( generally on a bread plate, sometimes in the napkin ), napkin, and flatware", "oinisfree", "bilaterally symmetrical", "he did not consider the papacy part of the biblical Church", "1837", "November 27, 2017", "Bambi, a Life in the Woods", "point on the frontier indicates efficient use of the available inputs ( such as points B, D and C in the graph )", "12\u201318", "Apple A6X chip", "on the equator and overlies the East African Rift covering a diverse and expansive terrain that extends roughly from Lake Victoria to Lake Turkana ( formerly called Lake Rudolf) and further south-east to the Indian Ocean", "in school at a given time in the school day ( such as lunch, recess or after school); or even to attend school on a non-school day", "guinea", "pride and prejudice", "lactobacilli", "at a school or other place of formal education", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "victoria", "magazines and journals", "EE", "in the 1970s and'80s", "Roland Ratzenberger", "200 to 500 mg up to 7 ml"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24038194444444444}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.3, 0.0, 0.0, 0.16666666666666666, 1.0, 0.0, 0.2, 0.32, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 1.0, 0.2222222222222222, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2]}}, "error_ids": ["mrqa_naturalquestions-validation-10601", "mrqa_squad-validation-2529", "mrqa_hotpotqa-validation-4719", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-3515", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-7425", "mrqa_naturalquestions-validation-2023", "mrqa_triviaqa-validation-710", "mrqa_naturalquestions-validation-7767", "mrqa_squad-validation-2267", "mrqa_naturalquestions-validation-7513", "mrqa_hotpotqa-validation-1506", "mrqa_naturalquestions-validation-2883", "mrqa_hotpotqa-validation-244", "mrqa_hotpotqa-validation-2157", "mrqa_squad-validation-8266", "mrqa_squad-validation-1941", "mrqa_triviaqa-validation-5150", "mrqa_triviaqa-validation-4988", "mrqa_squad-validation-1891", "mrqa_naturalquestions-validation-9772", "mrqa_triviaqa-validation-4854", "mrqa_triviaqa-validation-2508", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8555"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 86, "before_eval": {"predictions": ["Native Americans", "thammasat", "South Sentinel Island", "FCA US LLC", "Aaron Taylor- Johnson", "blue", "san Francisco", "a gift", "conservative", "Peter Davison", "preached that Muslims should not only \" always oppose\" infidels \"in every way\" but \" hate them for their religion... for Allah's sake\"", "1993", "maquiladora", "Bigger Than Both of Us", "cells", "\"Bad Blood\"", "a problem", "13 May 1787", "WJRT-TV", "Hudson River", "temperatures and sea levels have been rising at or above the maximum rates proposed during the last IPCC report in 2001", "the Jews", "film playback singer", "southern whites", "Marie", "complexity", "Association of Indian Universities", "drawing letters in the air", "electroweak", "the Funk Brothers", "confirmed he was their author", "August 1, 2016"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2653471528471529}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.8, 1.0, 0.0, 0.3636363636363636, 0.3846153846153846, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-4707", "mrqa_hotpotqa-validation-4230", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5195", "mrqa_triviaqa-validation-3781", "mrqa_triviaqa-validation-734", "mrqa_squad-validation-7281", "mrqa_squad-validation-7679", "mrqa_squad-validation-9589", "mrqa_naturalquestions-validation-3004", "mrqa_hotpotqa-validation-908", "mrqa_naturalquestions-validation-3704", "mrqa_hotpotqa-validation-4401", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-5911", "mrqa_triviaqa-validation-5001", "mrqa_squad-validation-8531", "mrqa_hotpotqa-validation-367", "mrqa_naturalquestions-validation-9516", "mrqa_squad-validation-1776", "mrqa_hotpotqa-validation-5241", "mrqa_naturalquestions-validation-3323", "mrqa_squad-validation-10506", "mrqa_triviaqa-validation-1431", "mrqa_squad-validation-2113", "mrqa_naturalquestions-validation-6912"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 87, "before_eval": {"predictions": ["on First Street in downtown Dayton, Ohio, United States", "electronic gaming machines", "August 21, 1995", "Mohammad Reza Pahlavi", "digital streams", "American Broadcasting Companies, Inc. Woods", "on a sound stage in front of a live audience in Burbank, California", "Chinese", "their videos being taken down off YouTube", "Meghan Trainor", "carbon cycle", "tenant management", "recite the 42 negative confessions of Maat", "Donna Noble (Catherine Tate) with Mickey Smith (noel Clarke) and Jack Harkness ( John Barrowman) recurring", "salvaging a country usually seen as one of the most stable and prosperous in Africa", "The Kree, briefly known as the Ruul", "titanium metal", "\"S&M\"", "Kirenyaa", "emily", "domestic legislation", "actions-oriented", "toothbrush", "the Seventeenth Amendment", "sherry", "Thutmose III", "ten to fifteen", "Buck Owens and the Buckaroos", "Kansas", "political support", "marlin", "Wimbledon"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3703666125541125}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.5, 0.2, 0.7499999999999999, 0.0, 0.33333333333333337, 0.6666666666666666, 0.0, 0.4, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-3420", "mrqa_naturalquestions-validation-2196", "mrqa_squad-validation-5648", "mrqa_squad-validation-8344", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-2096", "mrqa_hotpotqa-validation-3713", "mrqa_squad-validation-7703", "mrqa_squad-validation-8386", "mrqa_hotpotqa-validation-3692", "mrqa_triviaqa-validation-7649", "mrqa_hotpotqa-validation-3391", "mrqa_squad-validation-8276", "mrqa_triviaqa-validation-6049", "mrqa_squad-validation-9504", "mrqa_triviaqa-validation-3943", "mrqa_naturalquestions-validation-3848", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-1282", "mrqa_squad-validation-8552", "mrqa_hotpotqa-validation-5743", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-2814"], "retrieved_ids": ["mrqa_naturalquestions-train-16524", "mrqa_naturalquestions-train-77566", "mrqa_naturalquestions-train-57304", "mrqa_naturalquestions-train-73046", "mrqa_naturalquestions-train-3387", "mrqa_naturalquestions-train-26382", "mrqa_naturalquestions-train-5300", "mrqa_naturalquestions-train-69685", "mrqa_naturalquestions-train-86968", "mrqa_naturalquestions-train-13414", "mrqa_naturalquestions-train-82459", "mrqa_naturalquestions-train-86905", "mrqa_naturalquestions-train-65490", "mrqa_naturalquestions-train-3246", "mrqa_naturalquestions-train-70758", "mrqa_naturalquestions-train-60852", "mrqa_naturalquestions-train-16059", "mrqa_naturalquestions-train-11184", "mrqa_naturalquestions-train-71626", "mrqa_naturalquestions-train-7743", "mrqa_naturalquestions-train-61599", "mrqa_naturalquestions-train-40182", "mrqa_naturalquestions-train-18768", "mrqa_naturalquestions-train-11571", "mrqa_naturalquestions-train-49822", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-4196", "mrqa_hotpotqa-validation-2484", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-2449", "mrqa_squad-validation-5407", "mrqa_triviaqa-validation-7610"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 88, "before_eval": {"predictions": ["Paolo Cannavaro, (] ; born 13 September 1973) is an Italian former professional footballer and current manager of Chinese club Tianjin Quanjian", "Jackie Jackson", "The Gold Coast", "in order to create a test case as to the constitutionality of a law", "Selena Gomez", "8th", "Forbes", "159 beats per minute ( bpm )", "small bowel", "blue", "\"public\" (state-controlled) and \"independent\"", "New Jersey, New York, and Pennsylvania", "blue", "eponymous protagonist", "in arid lowland or mountainous shrubland, widely dispersed in dry open country with scattered brush", "the high risk of a conflict of interest and/or the avoidance of absolute powers", "sacerdotalism", "eventually discontinued", "an estimated half a million acres", "44", "the Gaulish name R\u0113nos", "as the company generates income", "blue", "ceremonial counties", "Solange Knowles & Destiny's Child", "Ward", "Fryda Wolff", "NBA Rookie of the Year Award", "Rihanna", "Pashto", "reversed", "phycobilisomes"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2918169579744123}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.11764705882352942, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.9655172413793104, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2848", "mrqa_triviaqa-validation-6166", "mrqa_hotpotqa-validation-3930", "mrqa_squad-validation-6775", "mrqa_naturalquestions-validation-5785", "mrqa_hotpotqa-validation-3343", "mrqa_naturalquestions-validation-10162", "mrqa_triviaqa-validation-2784", "mrqa_triviaqa-validation-6636", "mrqa_squad-validation-6823", "mrqa_naturalquestions-validation-4351", "mrqa_triviaqa-validation-4242", "mrqa_hotpotqa-validation-799", "mrqa_naturalquestions-validation-8319", "mrqa_squad-validation-6396", "mrqa_squad-validation-2101", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-2668", "mrqa_naturalquestions-validation-5291", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4364", "mrqa_naturalquestions-validation-2264", "mrqa_squad-validation-843", "mrqa_naturalquestions-validation-8622", "mrqa_hotpotqa-validation-5498", "mrqa_naturalquestions-validation-8095", "mrqa_hotpotqa-validation-828"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 89, "before_eval": {"predictions": ["169", "conscientious lawbreakers", "House of Fraser", "Bonkyll Castle", "four", "the time complexity (or any other complexity measure) of different inputs of the same size", "Deadman's Gun", "m\u00e1laga airport", "the Philippines", "Z-ring", "david law", "1843", "the 2004 Treaty establishing a Constitution for Europe", "director", "William Allen White Book Award", "Louis XVIII", "January 30, 1930", "wis\u0142a, Wa\u0142brzych, Elbe-Parey", "swissair", "all U.S. territories except American Samoa, but not on all Native American tribal lands", "the Gaussian integers Z[i] that is, the set of complex numbers of the form a + bi where i denotes the imaginary unit and a and b are arbitrary integers", "Janis Joplin", "Odinga", "homicides", "shrewsbury river festival", "Bergen County", "August 9, 2017", "mongol", "the American philosophy of pragmatism", "Pac-12 Conference", "Ian Hart", "sequential proteolytic activation of complement molecules"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31971153846153844}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.2666666666666667, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.23076923076923078, 0.33333333333333337, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-803", "mrqa_hotpotqa-validation-1756", "mrqa_triviaqa-validation-3639", "mrqa_squad-validation-1700", "mrqa_naturalquestions-validation-2981", "mrqa_triviaqa-validation-6387", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-8898", "mrqa_triviaqa-validation-5020", "mrqa_squad-validation-3985", "mrqa_triviaqa-validation-603", "mrqa_hotpotqa-validation-289", "mrqa_naturalquestions-validation-3269", "mrqa_triviaqa-validation-615", "mrqa_triviaqa-validation-7020", "mrqa_hotpotqa-validation-2831", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-5430", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4515", "mrqa_triviaqa-validation-3643", "mrqa_naturalquestions-validation-1450", "mrqa_squad-validation-2793", "mrqa_squad-validation-6645"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 90, "before_eval": {"predictions": ["allotrope", "reactive allotrope", "The Daleks' Master Plan", "tragedy", "phylum", "younger", "magnetic field", "complexity classes", "specific terminology", "clefs", "four", "jelly Roll Morton", "professor of cognitive science", "Kitab Rudjdjar", "time derivative", "photolysis", "fall of 2015", "c.S. forester", "Callen", "Type I", "active absorption of water from the soil by the root", "dolly parton", "Ken Howard", "red", "New England Patriots", "antigens", "A74(M)", "park Inn Baku Hotel", "september park", "Morty", "Charlotte Louise Riley", "Costiff collection of 178 Vivienne Westwood costumes"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3510416666666667}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.16666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.4444444444444445]}}, "error_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-7657", "mrqa_hotpotqa-validation-2585", "mrqa_squad-validation-4421", "mrqa_triviaqa-validation-6726", "mrqa_squad-validation-6812", "mrqa_triviaqa-validation-2940", "mrqa_naturalquestions-validation-7034", "mrqa_squad-validation-10358", "mrqa_naturalquestions-validation-2838", "mrqa_squad-validation-5814", "mrqa_triviaqa-validation-1246", "mrqa_naturalquestions-validation-3233", "mrqa_squad-validation-6884", "mrqa_naturalquestions-validation-1704", "mrqa_triviaqa-validation-7407", "mrqa_squad-validation-259", "mrqa_hotpotqa-validation-2128", "mrqa_triviaqa-validation-3575", "mrqa_triviaqa-validation-810", "mrqa_naturalquestions-validation-6248", "mrqa_hotpotqa-validation-5274", "mrqa_squad-validation-5441"], "retrieved_ids": ["mrqa_naturalquestions-train-12460", "mrqa_naturalquestions-train-8823", "mrqa_naturalquestions-train-85719", "mrqa_naturalquestions-train-49380", "mrqa_naturalquestions-train-29910", "mrqa_naturalquestions-train-77412", "mrqa_naturalquestions-train-72821", "mrqa_naturalquestions-train-49146", "mrqa_naturalquestions-train-27541", "mrqa_naturalquestions-train-48538", "mrqa_naturalquestions-train-9674", "mrqa_naturalquestions-train-36674", "mrqa_naturalquestions-train-43778", "mrqa_naturalquestions-train-55972", "mrqa_naturalquestions-train-86391", "mrqa_naturalquestions-train-84792", "mrqa_naturalquestions-train-26865", "mrqa_naturalquestions-train-56657", "mrqa_naturalquestions-train-79531", "mrqa_naturalquestions-train-68655", "mrqa_naturalquestions-train-27266", "mrqa_naturalquestions-train-19712", "mrqa_naturalquestions-train-40461", "mrqa_naturalquestions-train-52896", "mrqa_naturalquestions-train-35511", "mrqa_naturalquestions-validation-787", "mrqa_triviaqa-validation-7336", "mrqa_naturalquestions-validation-9825", "mrqa_squad-validation-2042", "mrqa_naturalquestions-validation-7309", "mrqa_naturalquestions-validation-585", "mrqa_triviaqa-validation-4871"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 91, "before_eval": {"predictions": ["40%", "catherine", "Mongolian patrimonial feudalism", "london", "The Taliban were spawned by the thousands of madrasahs the Deobandi movement established for impoverished Afghan refugees and supported by governmental and religious groups in neighboring Pakistan.", "biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "American", "around 100,000 writes", "Spain", "lorie Karnath", "tuscaloosa", "North Greenwich Arena", "ovules", "The 2015 Masters Tournament", "South Korean sports drama film starring Ha Ji-won and Bae Doona.", "90% certain", "Bessemer", "communication", "1856", "lizards", "deities and spirits", "lincoln", "Belfast and elsewhere in the United Kingdom, Canada, Croatia, Iceland, Malta, Morocco, Spain, and the United States", "gregillaz", "crows", "South Africa", "Reg Presley", "low-skilled workers", "at the center of the Northern Hemisphere", "Pakistan", "psilocybin, psilocin and baeocystin", "cuba and His Teddy Bear"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3243327384717328}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.07999999999999999, 0.47058823529411764, 1.0, 0.2222222222222222, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.967741935483871, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4749", "mrqa_squad-validation-8411", "mrqa_triviaqa-validation-7698", "mrqa_squad-validation-9738", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-3055", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-888", "mrqa_naturalquestions-validation-2439", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1140", "mrqa_squad-validation-8577", "mrqa_triviaqa-validation-6102", "mrqa_triviaqa-validation-1336", "mrqa_hotpotqa-validation-1068", "mrqa_triviaqa-validation-5143", "mrqa_naturalquestions-validation-7799", "mrqa_triviaqa-validation-6126", "mrqa_triviaqa-validation-4353", "mrqa_hotpotqa-validation-4229", "mrqa_squad-validation-7538", "mrqa_naturalquestions-validation-2721", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-1473", "mrqa_triviaqa-validation-6594"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 92, "before_eval": {"predictions": ["a field in Somerset County, Pennsylvania", "communism communism", "the Docile Don", "the United States Congress declared war ( Public Law 77 - 328, 55 STAT 795 ) on the Empire of Japan in response to that country's surprise attack on Pearl Harbor the prior day", "pacific island", "In 1950, the Truman Administration allowed for a democratic referendum in Puerto Rico to determine whether Puerto Ricans desired to draft their own local constitution without affecting the unincorporated territory status with the U.S.", "BitInstant", "\"Read It and Weep\" (2006)", "sanchez III el Santo", "steamboats", "Social Chapter", "Australia", "retinal ganglion cells of one retina", "quantum mechanics, though one is now dealing with operators instead of classical variables and though the physics is now described by the Schr\u00f6dinger equation instead of Newtonian equations", "The Lone Ranger", "Robert Sargent Shriver Jr.", "Landry's, Inc.", "James Knox Polk", "David Naughton, Jenny Agutter and Griffin Dunne", "national defence Volunteers", "Chicago", "john alcock and Lieutenant Arthur Whitten-Brown", "1978", "inversely to member state size", "skis", "Irvine", "Marine Corps Air Station Kaneohe Bay", "Teen Titans Go!", "south Africa", "November 20, 1942", "roughly equivalent to little Hugos", "Morning Edition"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5459520803270803}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, true, true, false, true, false, true], "QA-F1": [0.33333333333333337, 0.0, 0.5714285714285715, 0.25, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.07407407407407407, 1.0, 0.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4444444444444444, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4163", "mrqa_triviaqa-validation-3064", "mrqa_hotpotqa-validation-3514", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-3366", "mrqa_naturalquestions-validation-3820", "mrqa_triviaqa-validation-5888", "mrqa_naturalquestions-validation-3316", "mrqa_squad-validation-10388", "mrqa_hotpotqa-validation-5895", "mrqa_naturalquestions-validation-10080", "mrqa_hotpotqa-validation-2914", "mrqa_triviaqa-validation-6960", "mrqa_triviaqa-validation-7185", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-980", "mrqa_squad-validation-2696", "mrqa_triviaqa-validation-1267", "mrqa_squad-validation-3189"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 93, "before_eval": {"predictions": ["pacific region", "a method which pre-allocates dedicated network bandwidth specifically for each communication session, each having a constant bit rate and latency between nodes", "walford east", "Utah", "lyon", "Great Britain", "a mid-size four - wheel drive luxury SUV", "guyanese", "police chief wiggum", "\"we want to practice Christian love toward them and pray that they convert\" but also that they are \"our public enemies... and if they could kill us all, they would gladly do so. And so often they do\"", "bites of fleas whose midguts had become obstructed by replicating Y. pestis several days after feeding on an infected host", "around 1200", "British pop band T'Pau", "gestapo", "1815", "American Football Conference", "kimono", "Michigan and surrounding states and provinces. Populations are more scattered outside the core area, and the edges of its known distribution range north to the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts", "\"antiforms\"", "2015", "man's disobedience toward God", "a representation of a function as an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "Winnie the Pooh", "Transpacific Yacht Race", "German", "\"Provisional Registration\"", "commercial explosives and blasting systems to the mining, quarrying, oil and gas and construction markets, a supplier of sodium cyanide for gold extraction, and a specialist provider of ground support services in mining and tunnelling", "either yes or no, or alternately either 1 or 0", "Gibraltar, a British Overseas Territory", "In `` Company Picnic ''", "lie detector", "mass murder of the future king"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26802617555699476}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.06060606060606061, 0.0, 0.0, 0.0, 0.0, 0.8, 0.14634146341463414, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6296296296296297, 0.0, 0.0, 0.0, 0.34782608695652173, 0.0, 0.0, 0.33333333333333337, 1.0, 0.06060606060606061, 0.4615384615384615, 0.4, 0.0, 1.0, 0.25]}}, "error_ids": ["mrqa_triviaqa-validation-7513", "mrqa_squad-validation-4747", "mrqa_triviaqa-validation-7064", "mrqa_naturalquestions-validation-126", "mrqa_triviaqa-validation-2960", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-1586", "mrqa_triviaqa-validation-6860", "mrqa_triviaqa-validation-6177", "mrqa_squad-validation-2368", "mrqa_squad-validation-4978", "mrqa_naturalquestions-validation-337", "mrqa_triviaqa-validation-4204", "mrqa_triviaqa-validation-1548", "mrqa_naturalquestions-validation-2870", "mrqa_squad-validation-5111", "mrqa_hotpotqa-validation-421", "mrqa_triviaqa-validation-4668", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-2781", "mrqa_hotpotqa-validation-3298", "mrqa_hotpotqa-validation-1246", "mrqa_squad-validation-1652", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-1746"], "retrieved_ids": ["mrqa_naturalquestions-train-19839", "mrqa_naturalquestions-train-83707", "mrqa_naturalquestions-train-40721", "mrqa_naturalquestions-train-72727", "mrqa_naturalquestions-train-38008", "mrqa_naturalquestions-train-26947", "mrqa_naturalquestions-train-15738", "mrqa_naturalquestions-train-69596", "mrqa_naturalquestions-train-28353", "mrqa_naturalquestions-train-36460", "mrqa_naturalquestions-train-13533", "mrqa_naturalquestions-train-24579", "mrqa_naturalquestions-train-38490", "mrqa_naturalquestions-train-71091", "mrqa_naturalquestions-train-45335", "mrqa_naturalquestions-train-50056", "mrqa_naturalquestions-train-83547", "mrqa_naturalquestions-train-29109", "mrqa_naturalquestions-train-5572", "mrqa_naturalquestions-train-69891", "mrqa_naturalquestions-train-45358", "mrqa_naturalquestions-train-40021", "mrqa_naturalquestions-train-29180", "mrqa_naturalquestions-train-84589", "mrqa_naturalquestions-train-74429", "mrqa_triviaqa-validation-4353", "mrqa_squad-validation-4953", "mrqa_squad-validation-9079", "mrqa_naturalquestions-validation-5944", "mrqa_triviaqa-validation-6221", "mrqa_triviaqa-validation-1616", "mrqa_naturalquestions-validation-5538"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 94, "before_eval": {"predictions": ["the nucleus", "Maine", "cornwall", "alberta", "southeast of the city", "on the coast, named Puerto Rico ( Rich Port ), which had a suitable harbor", "the French island of Guadeloupe in the Lesser Antilles, mainly in the commune of Deshaies", "ragman roll", "1938", "about 63% compared with an actual efficiency of 42% for a modern coal-fired power station", "outside the United States and Canada", "2015, 2016", "90% to 93% O2", "approximately 11 %", "flags of dependent territories and other areas of special sovereignty", "Goldbach's conjecture", "kiel canal", "short-tempered", "1987", "stop the Pigeon", "regulates the practice of pharmacists and pharmacy technicians", "Sir Walter Elliot", "1968", "E-4 through E-6 are called petty officers", "led about 1,500 army troops and provincial militia on an expedition in June 1755 to take Fort Duquesne", "Islamic fundamentalist or neofundamentalist", "1986", "Cork, Portarlington, Lisburn, Waterford and Youghal", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "Tom Coburn", "1986", "the ground water level fell significantly. Dead branches dried up and the amount of forests on the flood plains decreased sharply."], "metric_results": {"EM": 0.09375, "QA-F1": 0.22157357167368608}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.3076923076923077, 0.7368421052631579, 0.0, 0.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.1, 0.0, 0.5, 0.923076923076923, 0.4444444444444445, 0.0, 0.0, 0.08695652173913045]}}, "error_ids": ["mrqa_naturalquestions-validation-366", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-7289", "mrqa_triviaqa-validation-2404", "mrqa_naturalquestions-validation-8419", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-7787", "mrqa_triviaqa-validation-2249", "mrqa_naturalquestions-validation-2624", "mrqa_squad-validation-3315", "mrqa_hotpotqa-validation-4506", "mrqa_naturalquestions-validation-2949", "mrqa_squad-validation-3677", "mrqa_naturalquestions-validation-5420", "mrqa_hotpotqa-validation-562", "mrqa_squad-validation-9001", "mrqa_squad-validation-2486", "mrqa_naturalquestions-validation-1382", "mrqa_triviaqa-validation-3230", "mrqa_triviaqa-validation-5584", "mrqa_hotpotqa-validation-2328", "mrqa_squad-validation-10196", "mrqa_squad-validation-9737", "mrqa_hotpotqa-validation-848", "mrqa_squad-validation-3306", "mrqa_naturalquestions-validation-7496", "mrqa_hotpotqa-validation-1948", "mrqa_hotpotqa-validation-659", "mrqa_squad-validation-9252"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 95, "before_eval": {"predictions": ["the \"richest 1 percent in the United States", "universal ruler", "red", "alain giresse", "Italian", "prime ideals", "david duchovny", "carrie", "the American newspaper magnate William Randolph Hearst, Chicago tycoons Samuel Insull and Harold McCormick", "parashah", "the s - block", "World Music Awards", "six", "8\u20134\u20134 system", "exposed to scrutiny", "79", "banned the growing of coffee", "New France", "creative plea", "stimulated his brain cells", "leprechaun", "Daniel Inouye", "Jack Nicklaus", "Tom Brady", "honeycomb", "11", "John Coffey", "The Portuguese", "raises the productivity of each worker", "the university's science club", "the Jurchen Aisin Gioro clan", "kronborg castle"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31932108918128654}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.375, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.20000000000000004, 0.4444444444444444, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-7459", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-717", "mrqa_triviaqa-validation-2894", "mrqa_triviaqa-validation-879", "mrqa_naturalquestions-validation-6129", "mrqa_naturalquestions-validation-3546", "mrqa_naturalquestions-validation-1688", "mrqa_hotpotqa-validation-4523", "mrqa_triviaqa-validation-1838", "mrqa_squad-validation-8288", "mrqa_squad-validation-10138", "mrqa_squad-validation-6914", "mrqa_squad-validation-1445", "mrqa_triviaqa-validation-2900", "mrqa_hotpotqa-validation-1234", "mrqa_naturalquestions-validation-5267", "mrqa_naturalquestions-validation-3093", "mrqa_triviaqa-validation-1682", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-9985", "mrqa_squad-validation-7184", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-4796"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 96, "before_eval": {"predictions": ["silicates of magnesium and iron", "Xanthippus, a Spartan mercenary", "The Dome of the Rock", "Public-Private Partnering (PPPs) aka private finance initiatives (PFIs)", "the New Testament it is used to translate the Greek word doxa ( \u03b4\u03cc\u03be\u03b1 )", "alair 8800", "Bulgaria", "8,477 km", "Army, Navy and other services", "John Belushi", "Renhe Sports Management Ltd, 100 % owned by Xiu Li Dai and Yongge Dai. 25 % Owned by Narin Niruttinanon", "the Phillies", "a free gift of God's grace through faith in Jesus Christ as redeemer from sin", "hydrogen and helium", "the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec", "cannonball", "2006", "75", "the Ministry of War compared with native Chinese dynasties", "1162", "guerrillero Heroico", "Porsche 944", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "1971", "New Paltz", "American Christian rock band Needtobreathe", "Americans to explain the Iranian Islamic Revolution and apolitical Islam was a historical fluke of the \"short-lived era of the heyday of secular Arab nationalism between 1945 and 1970\"", "September 1995", "cake", "Real images can be produced by concave mirrors and converging lenses, only if the object is placed further away from the mirror / lens than the focal point and this real image is inverted.", "gravitational", "kolinio Epeli Vanuacicila Rabuka and Salote Lomaloma Rabuka"], "metric_results": {"EM": 0.25, "QA-F1": 0.39244306320919226}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.25, 0.5, 1.0, 0.4, 0.08333333333333334, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.2857142857142857, 1.0, 0.4444444444444445, 0.42857142857142855, 0.07142857142857144, 0.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.0, 0.0, 0.6363636363636364, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 0.19999999999999998, 0.06451612903225806, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3504", "mrqa_naturalquestions-validation-5675", "mrqa_squad-validation-6778", "mrqa_naturalquestions-validation-9323", "mrqa_triviaqa-validation-3165", "mrqa_hotpotqa-validation-5639", "mrqa_triviaqa-validation-66", "mrqa_naturalquestions-validation-2208", "mrqa_squad-validation-2100", "mrqa_squad-validation-3667", "mrqa_squad-validation-3023", "mrqa_naturalquestions-validation-7297", "mrqa_squad-validation-8189", "mrqa_triviaqa-validation-7768", "mrqa_hotpotqa-validation-1399", "mrqa_naturalquestions-validation-9409", "mrqa_triviaqa-validation-3771", "mrqa_squad-validation-3057", "mrqa_squad-validation-9574", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-3432", "mrqa_squad-validation-10311", "mrqa_triviaqa-validation-3409"], "retrieved_ids": ["mrqa_naturalquestions-train-40612", "mrqa_naturalquestions-train-60922", "mrqa_naturalquestions-train-41083", "mrqa_naturalquestions-train-27385", "mrqa_naturalquestions-train-16969", "mrqa_naturalquestions-train-81766", "mrqa_naturalquestions-train-87963", "mrqa_naturalquestions-train-12782", "mrqa_naturalquestions-train-83575", "mrqa_naturalquestions-train-58540", "mrqa_naturalquestions-train-65052", "mrqa_naturalquestions-train-5752", "mrqa_naturalquestions-train-6608", "mrqa_naturalquestions-train-795", "mrqa_naturalquestions-train-47100", "mrqa_naturalquestions-train-51534", "mrqa_naturalquestions-train-7328", "mrqa_naturalquestions-train-33111", "mrqa_naturalquestions-train-65950", "mrqa_naturalquestions-train-70239", "mrqa_naturalquestions-train-47843", "mrqa_naturalquestions-train-73748", "mrqa_naturalquestions-train-77646", "mrqa_naturalquestions-train-68552", "mrqa_naturalquestions-train-63096", "mrqa_hotpotqa-validation-4537", "mrqa_triviaqa-validation-7100", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6566", "mrqa_squad-validation-8560", "mrqa_naturalquestions-validation-4544", "mrqa_hotpotqa-validation-859"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 97, "before_eval": {"predictions": ["the franchise's 6th season in the National Football League (NFL)", "God's favor", "suburb", "The National Era", "during the American Civil War", "blackberry", "Circuit City announced that the stores would be renamed The Source by Circuit City ( La Source par Circuit City in Quebec )", "a few drops", "the little girl ( Addy Miller )", "boston", "Speaker of the House of Representatives", "optic chiasm", "the Continental Edison Company in France", "quote Shelley's Masque of Anarchy to vast audiences during the campaign for a free India", "The 1911 Encyclop\u00e6dia Britannica describes the Gararish as a semi-nomadic, semi-agricultural tribe \"of Semitic origin\"", "Jai Courtney", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Galicia", "vie fair", "science fiction drama", "26", "the \"AC\" side", "kolkata", "Nickelback", "Montague's nephew", "the \"father of the Mongols\"", "caused by chlorine and bromine from manmade organohalogens", "a rock concert", "australia", "fomenting rebellion in many of Great Britain's far-flung colonies", "Psych", "multiple alternative realities"], "metric_results": {"EM": 0.21875, "QA-F1": 0.37774534493284495}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.7499999999999999, 0.5555555555555556, 0.14285714285714285, 1.0, 0.14285714285714288, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-4113", "mrqa_squad-validation-2262", "mrqa_hotpotqa-validation-3785", "mrqa_naturalquestions-validation-2536", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-7679", "mrqa_triviaqa-validation-5865", "mrqa_naturalquestions-validation-3358", "mrqa_squad-validation-1240", "mrqa_squad-validation-6859", "mrqa_hotpotqa-validation-4389", "mrqa_naturalquestions-validation-1680", "mrqa_hotpotqa-validation-1905", "mrqa_triviaqa-validation-636", "mrqa_squad-validation-1423", "mrqa_triviaqa-validation-2161", "mrqa_naturalquestions-validation-7095", "mrqa_hotpotqa-validation-212", "mrqa_naturalquestions-validation-654", "mrqa_triviaqa-validation-1081", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-2271", "mrqa_naturalquestions-validation-2729"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 98, "before_eval": {"predictions": ["the most devastating stock market crash in the history of the United States ( acting as the most significant predicting indicator of the Great Depression ), when taking into consideration the full extent and duration of its after effects", "SKUM", "S6 Edge+", "brazilica", "photoreceptor proteins", "frollo", "fossil sequences in which there was datable material, converting the old relative ages into new absolute ages", "heaviest album of all", "ring", "in San Francisco, California with offices in New York City and Atlanta", "economic recession", "ex as a noun is assumed to refer to a former sexual or romantic partner, especially a former spouse", "fairy tale Origins", "sardinia", "\"citizenship\" so that people had rights to empower them to become economically and socially active", "Jacking", "Quora", "The Blind Boys of Alabama", "catherine zeta- Jones", "Sultans", "the end of the post-war communist control of the country", "roger", "much larger than the approximately 150,000 base pair genome of the more assimilated chloroplast", "roger penrose", "Wynantskill is located at the north town line and the northeast corner of the town of North Greenbush.", "whatIs.com", "Synergy Group", "a limited period of time", "kabuki", "Stritch", "It is between the three towns of Doncaster, Scunthorpe and Gainsborough, in the traditional West Riding of Lindsey.", "In 1908, the first five - day workweek in the United States was instituted by a New England cotton mill so that Jewish workers would not have to work on the Sabbath from sundown Friday to sundown Saturday."], "metric_results": {"EM": 0.09375, "QA-F1": 0.18329800793749906}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4878048780487805, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.2222222222222222, 1.0, 0.0, 0.4, 1.0, 0.47619047619047616, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.30769230769230765, 0.0, 0.0, 0.10526315789473684, 0.05882352941176471]}}, "error_ids": ["mrqa_naturalquestions-validation-8837", "mrqa_hotpotqa-validation-2978", "mrqa_triviaqa-validation-6634", "mrqa_naturalquestions-validation-2213", "mrqa_triviaqa-validation-1952", "mrqa_squad-validation-5008", "mrqa_triviaqa-validation-2353", "mrqa_hotpotqa-validation-2856", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2725", "mrqa_squad-validation-4433", "mrqa_hotpotqa-validation-5136", "mrqa_triviaqa-validation-1816", "mrqa_naturalquestions-validation-10557", "mrqa_triviaqa-validation-1474", "mrqa_naturalquestions-validation-6382", "mrqa_squad-validation-992", "mrqa_triviaqa-validation-5737", "mrqa_squad-validation-8802", "mrqa_triviaqa-validation-2414", "mrqa_hotpotqa-validation-5724", "mrqa_triviaqa-validation-4769", "mrqa_hotpotqa-validation-4093", "mrqa_naturalquestions-validation-688", "mrqa_triviaqa-validation-4550", "mrqa_naturalquestions-validation-886", "mrqa_hotpotqa-validation-1533", "mrqa_naturalquestions-validation-2713"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}, {"timecode": 99, "before_eval": {"predictions": ["the Seventh Doctor's era which lasted from season 24 (1988) until the series' suspension in 1989", "to implement the Prohibition Amendment by defining the process and procedures for banning alcoholic beverages", "roger", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "Gender pay gap in favor of males in the labor market", "Jessie's lovable horse", "May 5, 1939", "economic growth by collecting resources from colonies, in combination with assuming political control by military and political means", "1998", "October 1, 2017", "Washington, D.C.", "kansas", "Toronto, Ontario, Canada", "the royal nunnery of Shaftesbury (Dorset) founded by King Alfred, where she was buried and soon revered as a saint", "told Washington that France's claim to the region was superior to that of the British, since Ren\u00e9-Bob Cavelier, Sieur de La Salle had explored the Ohio Country nearly a century earlier.", "a balance sensor consisting of a statolith, a solid particle supported on four bundles of cilia, called \"balancers\"", "water", "extracurricular activities", "Roman Jakobson", "practiced law", "the studies and developments department of the French firm R2E Micral in 1980 at the request of the company CCMC specializing in payroll and accounting", "the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "the 1969 revision of the Roman Rite, an alternative formula ( based on Mark 1 : 15 ) was introduced and given first place `` Repent, and to dust you shall return. ''", "the author recounts how his own opinions changed about that line when he talks to the different people about their beliefs", "Twink", "india", "derry", "9 contain at most one prime number", "porto", "Bhaktivedanta Manor", "jellyfish", "Mammals are any vertebrates within the class Mammalia ( from Latin \"mamma\" \"breast\") a clade of endothermic amniotes distinguished from reptiles"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2720022976165711}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.13333333333333333, 0.14285714285714288, 0.0, 0.88, 0.2105263157894737, 0.5, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 0.5, 0.10526315789473684, 0.0909090909090909, 0.5, 0.0, 0.0, 0.0, 0.0, 0.25, 0.9047619047619047, 0.0, 0.34782608695652173, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 0.10526315789473684]}}, "error_ids": ["mrqa_squad-validation-7714", "mrqa_triviaqa-validation-5049", "mrqa_triviaqa-validation-4903", "mrqa_squad-validation-3130", "mrqa_squad-validation-7449", "mrqa_triviaqa-validation-7414", "mrqa_squad-validation-9926", "mrqa_naturalquestions-validation-3651", "mrqa_triviaqa-validation-7769", "mrqa_hotpotqa-validation-4287", "mrqa_hotpotqa-validation-1086", "mrqa_squad-validation-10231", "mrqa_squad-validation-4494", "mrqa_triviaqa-validation-4000", "mrqa_squad-validation-1870", "mrqa_hotpotqa-validation-5590", "mrqa_hotpotqa-validation-4961", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-251", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-607", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-6226", "mrqa_squad-validation-8972", "mrqa_triviaqa-validation-4125", "mrqa_hotpotqa-validation-5833", "mrqa_naturalquestions-validation-2794", "mrqa_hotpotqa-validation-2779"], "retrieved_ids": ["mrqa_naturalquestions-train-48839", "mrqa_naturalquestions-train-42136", "mrqa_naturalquestions-train-18677", "mrqa_naturalquestions-train-69750", "mrqa_naturalquestions-train-13640", "mrqa_naturalquestions-train-49797", "mrqa_naturalquestions-train-28275", "mrqa_naturalquestions-train-28074", "mrqa_naturalquestions-train-62307", "mrqa_naturalquestions-train-46657", "mrqa_naturalquestions-train-12863", "mrqa_naturalquestions-train-5776", "mrqa_naturalquestions-train-25254", "mrqa_naturalquestions-train-73417", "mrqa_naturalquestions-train-86544", "mrqa_naturalquestions-train-33824", "mrqa_naturalquestions-train-47150", "mrqa_naturalquestions-train-64536", "mrqa_naturalquestions-train-27613", "mrqa_naturalquestions-train-45524", "mrqa_naturalquestions-train-51653", "mrqa_naturalquestions-train-3493", "mrqa_naturalquestions-train-13224", "mrqa_naturalquestions-train-51310", "mrqa_naturalquestions-train-43085", "mrqa_triviaqa-validation-5041", "mrqa_naturalquestions-validation-5624", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-3802", "mrqa_triviaqa-validation-2635", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-1688"], "instant_fixing_rate": 0.0, "instant_retention_rate": 0.0}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.1725, "QA-F1": 0.2870938550897019}, "overall_error_number": 2648, "overall_instant_fixing_rate": 0.0, "final_instream_test": {"EM": 0.6671875, "QA-F1": 0.7340741469889422}, "final_upstream_test": {"EM": 0.717, "QA-F1": 0.8251892973805995}}}