{"model_update_steps": 955, "method_class": "continual_finetuning", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, learning_rate=3e-05, max_grad_norm=0.1, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllError_T=50_simplecl_seed=1213_ckpts/', save_all_ckpts=1, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.hidden_passes.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "French 18th-century art and furnishings", "turbine", "the adaptive immune system", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "50 fund", "ned sherrin", "the Mandate of Heaven", "Tar Baby", "buddha", "Poseidon", "the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho ( including the communities of Parma, Wilder, Greenleaf, and Notus )", "2009", "the direction from which the wind is blowing", "john Mortimer", "oxygen", "seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "great train robbery", "Miranda Cosgrove", "a metaphor for a burden to be carried as penance", "a series of power blackouts across the country"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9674107142857142}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-5465"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "The Iroquois", "philanthropy", "The Darling Buds of May", "Virginia Wade", "The Dallas Lovers' Song", "the anterolateral system", "1966", "for scientific observation", "ned Shields", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "koran,kuran reader", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs", "the Empire Gallantry Medal", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Isaac Newton", "the check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.125, "QA-F1": 0.19191919191919193}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 0.4, 0.4444444444444445, 0.0, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["from the Italian pignatta", "originally designated HU - 1", "philanthropy", "mariette", "Virginia Wade", "Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York", "Rotherham United", "marr", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years", "is the religious text of Islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "Charlie", "gallantry", "Michael Douglas", "Galileo", "Superman", "2010"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8375}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-338", "before_prediction": "numb3rs", "after_prediction": "Charlie"}], "retained_ids": ["mrqa_squad-validation-10015", "mrqa_naturalquestions-validation-4684", "mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-1924", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_triviaqa-validation-2096"], "instant_fixing_rate": 0.7857142857142857, "instant_retention_rate": 0.7499999981250001}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "a phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "a concentration of lower income residents in the inner city", "one of the membership who is no longer an exempt", "Bothtec", "Terry Reid", "information about climate change based on published sources", "sept Princesses", "North America", "Andr\u00e9 3000", "one veteran as Commander", "Akhenaten", "President Theodore Roosevelt", "from 2010 to 2012", "four", "United States", "in the 1970s", "Georges Bizet", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.09375, "QA-F1": 0.27122314289653}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.19354838709677416, 0.0, 1.0, 0.0, 0.2, 0.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.4, 0.8571428571428571, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "never", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "catherine de\u2019 Medici", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Masaharu Iwata", "Spencer Davis Group", "non-peer-reviewed sources", "Enigma Variations", "physiographically a part of the continent of North America", "OutKast", "two rookies", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the Western Bloc ( the United States, its NATO allies and others )", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "Pacific"], "metric_results": {"EM": 0.875, "QA-F1": 0.8551136363636364}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "Masaharu Iwata"}, {"id": "mrqa_naturalquestions-validation-5180", "before_prediction": "United States", "after_prediction": "the Western Bloc ( the United States, its NATO allies and others )"}], "retained_ids": ["mrqa_squad-validation-194"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "unfixed_ids": ["mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-2679"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.3333333322222222}, {"timecode": 3, "before_eval": {"predictions": ["id", "baijan", "id", "between 27 July and 7 August 2022", "New York", "id id", "2006", "Least of the Great Powers", "usually restricted to the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "Fox's Glacier Mints", "baze", "death mask", "bollywood", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "is a British sitcom, broadcast in the United Kingdom from 1982 to 1984", "cement City, Texas", "the Democratic Unionist Party (DUP )", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "for control purposes", "bridges", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "al - khimar", "proteins", "bile duct", "berenice Abbott"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11333411654135336}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "Staten Island", "splash", "2005\u20132010", "G20", "efferent nerves", "max Bygraves", "polar bear", "dettori", "don't disturb\" sign", "nollywood", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "control purposes", "ringo starr", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor", "10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "dime Museum and Flea Circus"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8720238095238095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-5662", "mrqa_naturalquestions-validation-6341"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800"], "unfixed_ids": ["mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-2530"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.999999995}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "Januarius", "a shepherd in a print by contemporary Israeli artist Mordechai Beck, protectively clasps a sheep in his arms", "at elevation 2 meters above sea level", "tetanus", "bounding", "max.5 percent.", "Alex O'Loughlin", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "a chain or screw stoking mechanism and its drive engine or motor", "never", "the Reverse - Flash", "All Hallows'Day", "the A's", "EOC", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America, and Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotationating discs", "Splodgenessabounds"], "metric_results": {"EM": 0.25, "QA-F1": 0.34903273809523805}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 0.5, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "discontinued", "Gryphon", "1898", "june", "a shepherd", "coney Island", "tetanus", "bounding", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine and cocaine", "bunker", "Fleet Street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "Azerbaijan", "new converts", "CeCe Drake", "cricket", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"], "metric_results": {"EM": 0.875, "QA-F1": 0.890625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"}], "retained_ids": ["mrqa_naturalquestions-validation-1277", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_squad-validation-3126", "mrqa_triviaqa-validation-5168", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-8700"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_naturalquestions-validation-5437"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.8749999989062499}, {"timecode": 5, "before_eval": {"predictions": ["otranto", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI )", "paisley", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "7 : 25 a.m.", "swanee or swannee whistle, lotos flute  piston flute,  or jazz flute", "rapeseed plant", "to start fires, hunt, and bury their dead", "1962", "parietal cells ( also known as oxyntic or delomorphous cells )", "placental", "September 13, 1994", "guiteau", "imperial rule", "1840", "make a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "kinks", "a greater tendency to take on debts", "entropy increases", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "at the behest of King Minos"], "metric_results": {"EM": 0.125, "QA-F1": 0.19376114081996437}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "Renfrewshire", "uninhabited", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "Idaho", "5 : 16 p.m. UTC ( 10 : 16 a.s. PDT )", "clangers", "mustard", "bury their dead", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotremata", "September 13, 1994", "President Garfield", "imperial rule", "1787", "allocution", "Mark Twain", "sunny afternoon", "the methodology used", "nonconservative forces", "my mind is averse to wedlock because I daily expect the death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.875, "QA-F1": 0.9011948529411764}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2368", "before_prediction": "paisley", "after_prediction": "Renfrewshire"}], "retained_ids": ["mrqa_hotpotqa-validation-484", "mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-1718"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-2020", "mrqa_squad-validation-2757"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "to prevent the flame from being blown out", "Illinois", "1996", "city", "monearic Islands", "70-50's", "independent schools", "dolph Camilli", "the times sign or the dimension sign", "BAFTA Television Award", "Emily Blunt", "1960", "HTTP Secure ( HTTPS )", "late summer", "d. Eisenhower National Airport", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "dads", "Butterfly Conservation", "universal", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "dale", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "Grande Comore, Comoros Islands", "rupees", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.0625, "QA-F1": 0.11648065476190476}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film director", "capillary action", "2008", "2010", "north carolina", "the Euro. Beer", "70", "independent schools", "boston braves", "the symbol \u00d7", "Best Supporting Actress", "Juice Newton", "Super Bowl LII, their fourth NFL title, after winning in 1948, 1949, and 1960", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "wichita", "simplest", "for its popular beaches", "japan", "true", "red admiral", "o", "The anterior interventricular branch of left coronary artery, ( also left anterior descending artery ( LAD ), or anterior descending branch )", "10 % of the carbon stores in ecosystems", "dale", "concentrated in the leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide ( CO )"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8829044117647059}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-5582", "before_prediction": "left coronary artery", "after_prediction": "The anterior interventricular branch of left coronary artery, ( also left anterior descending artery ( LAD ), or anterior descending branch )"}], "retained_ids": ["mrqa_squad-validation-6947"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919"], "unfixed_ids": ["mrqa_triviaqa-validation-5261", "mrqa_naturalquestions-validation-2190", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_naturalquestions-validation-6644"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.4999999975}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules, such as squalene and the carotenes", "authorized army branch insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who want more services and more control over the central city", "director", "near the Black Sea", "last book accepted into the Christian biblical canon", "Beyonc\u00e9", "% IACS", "gallantry medal", "16 million", "1950s", "work oxen for haulage", "1998", "a priest", "23.1", "2001", "family member", "long-term environmental changes", "William Powell Lear", "the unbalanced centripetal force felt by any object", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "june", "present-day Charleston", "the Brotherhood announced the formation of Palestinian shopkeepers and antipathy for activities of the secular middle class such as drinking alcohol and going about without hijab", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "XIX Corps"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2726059173669468}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.19999999999999998, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.23529411764705882, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "Only a few", "the right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "Lost Weekend", "near the Black Sea", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george vi", "the most popular show at the time", "post\u2013World War II", "work oxen for haulage", "2011", "a priest", "most abundant", "2001", "family member", "over-fishing and long-term environmental changes", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george I", "Charleston Orange district", "quiescent", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9866071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_squad-validation-6297", "mrqa_hotpotqa-validation-3846", "mrqa_naturalquestions-validation-824", "mrqa_squad-validation-1863", "mrqa_squad-validation-4318"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "unfixed_ids": ["mrqa_naturalquestions-validation-98"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.9999999983333333}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "guseppe Antonio 'Nino' Farina (59 ) Italian racing driver", "46.8 ( 50 is the highest possible score )", "6.4 nanometers apart", "the eighth and eleventh episodes of the season", "Kyle Busch", "400", "endocrine system", "Latin liberalia studia", "Forest of Bowland in Lancashire", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "Eureka", "1868", "three times, losing in their first two appearances but winning the third, in 2018", "wolverhampton braves", "law firm", "Pottawatomie County", "The tuatara, a lizard - like reptile", "theory of general relativity (GR )", "The church tower", "bromley- by-Bow", "Toronto, Ontario, Canada", "foreigner", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to Block Island Sound", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six", "not guilty", "psychotherapeutic theories and associated techniques", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York", "acidic bogs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3209233738785369}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.25, 0.375, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.17391304347826084, 0.2666666666666667, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.25, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_naturalquestions-validation-6991", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "after_eval": {"predictions": ["computability theory", "Formula One World Championship", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidneys", "artes liberales", "Swiss of England", "Edward IV of England", "St. Louis County", "1828", "2018", "Blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee Micropolitan Statistical Area", "tortoise", "theory of general relativity", "The church tower", "walford east", "Montreal", "slow", "110 miles", "Kona coast", "liberal conservative", "gold rushes", "six", "creative plea", "freudians", "New York", "acidic"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9042572463768116}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4212", "before_prediction": "Eureka", "after_prediction": "St. Louis County"}], "retained_ids": ["mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_squad-validation-10369", "mrqa_squad-validation-5313", "mrqa_naturalquestions-validation-7906"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-5401", "mrqa_naturalquestions-validation-6991", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "unfixed_ids": ["mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-3161", "mrqa_hotpotqa-validation-1934", "mrqa_triviaqa-validation-7767"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8333333319444445}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian", "a report, published in early February 2007 by the Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "almond paste", "photosynthesis", "a wide range of society figures of the period", "1600 Pennsylvania Avenue", "The Daily Stormer", "triplet", "water", "president", "citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co. fire", "fashion model", "C. W. Grafton", "LED illuminated display", "Americans acting under orders", "iPod Classic", "My Sassy Girl", "prevent damage to the body", "The Edge of Night", "non-combustible substances that corrode, such as iron", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd ) book of prayers", "the root respiration", "organic carbon in all land - living organisms, both alive and dead, as well as carbon stored in soils", "drug dealer", "medium and heavy- Duty diesel trucks", "testes"], "metric_results": {"EM": 0.25, "QA-F1": 0.3839980332167832}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.1, 0.0, 0.0, 0.125, 0.8, 1.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.3333333333333333, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentinian", "a report", "cake", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "animals and humans performimg various actions", "1400 Pennsylvania Avenue", "The Daily Stormer", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "all officeholders annually", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "a meat cold storage facility", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( LCoS ) ( based on an L CoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod+HP", "That Bizarre Girl", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP, generated by the root respiration", "all land - living organisms, both alive and dead, as well as carbon stored in soils", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8824409636909637}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.2222222222222222, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4520", "before_prediction": "citizens", "after_prediction": "all officeholders annually"}, {"id": "mrqa_hotpotqa-validation-4834", "before_prediction": "Worcester Cold Storage and Warehouse Co. fire", "after_prediction": "a meat cold storage facility"}], "retained_ids": ["mrqa_hotpotqa-validation-832", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-133", "mrqa_naturalquestions-validation-1327", "mrqa_squad-validation-5940"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_triviaqa-validation-2703", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.7499999990624999}, {"timecode": 10, "before_eval": {"predictions": ["poet, son of Alexander Pope, by his wife Edith, daughter of William Turner of York", "radiology at the Walter Reed Army Hospital in Washington, D.C. from 1942 to 1945", "three legal systems, each of which applies to a particular geographical area", "Las Vegas, Nevada", "optional message body", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "a Dubliner", "plan", "slow port of Vannes", "a strict and elaborate set of rules designed by Victoria, Duchess of Kent, along with her attendant, Sir John Conroy, concerning the upbringing of the Duchess's daughter, the future Queen Victoria", "pH 7 ( 25 \u00b0 C )", "Kon-Tiki", "the MGM Grand Garden Special Events Center", "Chicago History Museum", "Ronnie Hillman", "all-encompassing definition of the term", "to share that story with the world through stories of faith, judgment, dedication and sacrifice of the church organization through today", "60", "Eagle Ridge Mall", "Pel\u00e9 as the greatest defender that he had ever played against", "to reduce pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Deputy Barney Fife", "must be at least 18 or 21 years old ( or have a legal guardian present ), and must sign a waiver prior to shooting", "Bacha", "novelist and poet", "Jamestown", "Rouen Cathedral", "tree growth stages"], "metric_results": {"EM": 0.09375, "QA-F1": 0.25826231060606064}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.125, 0.0, 0.0, 0.8, 0.0, 0.5, 1.0, 0.9333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 0.3333333333333333, 0.18181818181818182, 0.0, 0.5, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["Alexander Pope", "Hampton's hump and Hampton's line", "Scots law", "Las Vegas", "A status line", "a striker", "cruiserweight", "over the Merderet in the fictional town of Ramelle", "Benito Mussolini", "victor Hugo quotes", "menhirs", "British Royal Family", "10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "Thor Heyerdahl", "Grand Garden Special Events Center", "Valentino", "C. J. Anderson", "impossible", "joseph Smith", "60", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "tunisia", "fire", "Barney Fife", "at least 18 or 21 years old ( or have a legal guardian present )", "Ann", "writer", "Virginia", "Claude Monet", "carbon related emissions"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8895833333333334}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2016", "mrqa_squad-validation-3018", "mrqa_squad-validation-3525"], "fixed_ids": ["mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-3419", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "unfixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-4162", "mrqa_triviaqa-validation-6389", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-8617"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.9999999966666667}, {"timecode": 11, "before_eval": {"predictions": ["Vince Lombardi", "Traumnovelle", "a Gender pay gap in favor of males in the labor market", "The TEU", "ice melting at 100 degrees", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "red", "a longer span", "trams", "tunisia II", "joseidon", "the Bulgars, and especially the Seljuk Turks", "died in battle", "Volkswagen", "a certain kind of music", "Maastricht Treaty", "Queen Elizabeth I", "infection, irritation, or allergies", "the most - visited paid monument in the world", "the Vittorio Emanuele II Gallery and Piazza della Scala in a pedestrian area in the centre of the city", "catfish aquaculture", "a lustrous, purple - black metallic solid at standard conditions that sublimes readily to form a violet gas", "Kaled's music producer, who takes a liking to Beca", "Kuwait", "a co-op of grape growers", "mann", "Verdi", "1952", "Los Angeles Lakers", "`` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.125, "QA-F1": 0.2731241400068799}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.25, 0.23529411764705882, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.31578947368421056, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.09090909090909091, 0.22222222222222224, 0.25]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "dromedaries", "span", "Dublin", "duke of Edinburgh", "king Crimson", "Seljuk Turks", "victorians agree on a few basic facts", "German automaker Volkswagen", "arkansas", "Canada", "britten", "infection", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "heaviest of the stable halogens", "Saddle Up", "Kuwait", "an agricultural cooperative", "mann", "Italian", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean F kernel ( 1497 -- 1558 ), a French physician", "back"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8194444444444444}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5526", "before_prediction": "Verdi", "after_prediction": "Italian"}], "retained_ids": ["mrqa_hotpotqa-validation-2852", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-4274"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-6442"], "unfixed_ids": ["mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-792", "mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.7499999981250001}, {"timecode": 12, "before_eval": {"predictions": ["British rock group Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government", "Minos", "29 June 1941", "cienfuegos in the Las Villas province of Cuba", "dale meeks", "New South Wales", "Fort Niagara", "dandy", "bragnano", "Orwell", "Czech Kingdom", "Gregg Popovich", "not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "immunological memory", "under the tutelage of his uncle Juan Nepomuceno Guerra", "a band of nuclear holocaust survivors as they flee Texas to the relative safety of California", "danish", "December 1, 1969", "american", "jK Rowling", "California State Automobile Association and the Automobile Club of Southern California", "faith", "Cinderella", "The astronauts were asphyxiated before the hatch could be opened", "due to a lack of understanding of the legal ramifications"], "metric_results": {"EM": 0.125, "QA-F1": 0.21849556353232824}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.15384615384615385, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.2424242424242424, 0.4, 1.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.16666666666666666, 0.8571428571428571]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "fencers", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "Cuban cigars", "byker grove", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Czech Kingdom", "Bob Hill", "secularism and secular nationalism", "creative reasons", "innate immune system", "uncle", "Originally a musician", "Thumbelina", "1973", "maryland", "John Buchan", "regional tourism groups", "alone", "Cinderella", "communications problems", "lack of understanding of the legal ramifications, or due to a fear of seeming rude"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6678", "before_prediction": "immunological memory", "after_prediction": "innate immune system"}], "retained_ids": ["mrqa_hotpotqa-validation-4826", "mrqa_hotpotqa-validation-4904", "mrqa_hotpotqa-validation-4165"], "fixed_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "unfixed_ids": ["mrqa_triviaqa-validation-1671"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Buddy Pine / Incredi - Boy / Syndrome", "Napoleon", "baking", "3.7 percent of the entire student population", "High and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Tracey Stubbs", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "9", "bear", "amyotrophic lateral sclerosis ( ALS)", "Odorama", "Swiss watchmaking industry", "the Evel Knievel craze of the mid 1970s", "Torah or Bible", "the western coast of Italy", "first and only U.S. born world grand prix champion", "brass band parades", "mid November and lit in a public ceremony in late November or early December", "Facebook", "bajgiel", "Tim \"Ripper\" Owens", "Seattle", "King George's War", "cheated on Miley", "alternative rock", "Fort Snelling, Minnesota", "daguerreotypes", "infrequent rain and many sunny days"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2749323593073593}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.4, 0.0, 0.0, 0.0, 0.2857142857142857, 0.2222222222222222, 0.0, 0.0, 0.33333333333333337, 0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.5555555555555556, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.3333333333333333, 0.0, 0.5]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "sliced bread", "3.7 percent of the entire student population", "negative effect", "garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "9", "Michael Hordern", "Lou Gehrig's Disease", "Odorama", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "The second line's style of traditional dance, in which participants walk and sometimes twirl a parasol or handkerchief in the air", "late November or early December", "Facebook", "bread", "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Issaquah", "King George's War", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "pinhole camera", "infrequent rain"], "metric_results": {"EM": 0.8125, "QA-F1": 0.853279532967033}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5716", "before_prediction": "Tim \"Ripper\" Owens", "after_prediction": "Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band"}], "retained_ids": ["mrqa_hotpotqa-validation-1591", "mrqa_triviaqa-validation-2779", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7310"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_squad-validation-2656"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-7042", "mrqa_triviaqa-validation-4301", "mrqa_naturalquestions-validation-9897", "mrqa_triviaqa-validation-6913"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.7999999984}, {"timecode": 14, "before_eval": {"predictions": ["a 2002 Hong Kong comedy film directed by Raymond Yip, and starring Francis Ng, Michelle Reis and Daniel Wu", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "American sympathizer in the American Revolutionary War", "maryland", "FX option or currency option", "electromagnetic waves", "Wahhabi/ Salafi", "mary Lee", "Dimensions in Time", "Surveyor 3 unmanned lunar probe", "January 1981", "gonadotropin - releasing hormone ( GnRH )", "his questions and answers concerning baptism in the Small Catechism", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "\u00a31,150,000", "A compression release engine brake", "Cheyenne rivers", "appearance of fossils in sedimentary rocks", "Hanna-barbera, The Jetsons", "Cortina d'Ampezzo", "efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization", "Alba Longa", "maryland", "maryland", "Timo Hildebrand", "state sector", "October 1999", "weak government institutions", "The name Moloch results from a dysphemic vocalisation in the Second Temple period of a theonym based on the root mlk `` king ''", "cornea (the transparent layer at the front of the eye)", "Uncle Fester", "James MacArthur"], "metric_results": {"EM": 0.0, "QA-F1": 0.14461098541980894}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.19999999999999998, 0.16666666666666669, 0.0, 0.0, 0.5882352941176471, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.19999999999999998, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.4615384615384615, 0.1111111111111111, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "American sympathizer", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/ Salafi extremists extremist militant group", "tetraskelion (Swastika)", "Children in Need", "Apollo 12", "1981", "estrogen", "baptism", "that priest whose name was Martin Luther", "brian clough", "slowing the vehicle", "Belle Fourche and Cheyenne", "organisms", "Hanna-barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Kur\u00e1nyi", "public sector ( also called the state sector )", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9441287878787878}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": ["mrqa_hotpotqa-validation-3253", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442"], "instant_fixing_rate": 0.90625, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Part 2", "the Flatbush section of Brooklyn, New York City", "Wichita and the state of Kansas", "Proof", "jupiter (now known as the Galilean moons)", "a friend and publicist", "britway", "masons'marks", "March 12, 1948", "Gateshead", "Motown, Philly soul, and Earth, Wind & Fire ( particularly `` That's the Way of the World '' )", "the female cervix, uterus and uterine tubes", "1898", "professional wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "The Bells of St. Mary's", "a Curtiss JN-4 airplane", "art", "chimpanzees", "March 15, 1945", "absolute temperature", "whistlebl-blowing website", "J. Robert Oppenheimer", "bicuspid", "his brother, Menelaus", "25 November 2015", "tallahassee", "Eastern Bloc city", "London", "WWSB and WOTV"], "metric_results": {"EM": 0.125, "QA-F1": 0.13541666666666669}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Royce da 5'9\" ( Bad) and Eminem ( Evil)", "Galileo Galilei", "the editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "the Old Town Hall, Gateshead", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "1898", "martial artist", "Spanish", "stunt performances", "fred Astaire", "postage stamp", "belgium", "chimpanzees", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolar", "Aegisthus", "3 December", "florida", "prefabricated housing projects", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-874", "before_prediction": "Eastern Bloc city", "after_prediction": "prefabricated housing projects"}], "retained_ids": ["mrqa_hotpotqa-validation-3456", "mrqa_naturalquestions-validation-3808", "mrqa_hotpotqa-validation-5188"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": ["mrqa_squad-validation-5249"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 16, "before_eval": {"predictions": ["bistro tables", "cheeses", "benedict", "on the lateral side of the tibia, with which it is connected above and below", "king fergus Mor of Dalriada", "the North Sea, through the former Meuse estuary, near Rotterdam", "the Kalahari Desert", "Colin Montgomerie", "October 29, 1985", "Amway", "Mauritius", "Thomas Sowell", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in the absence, the Deputy - Chairman of the Rajya Sabha", "The Show Band Show", "Tanzania", "bordered by Libya and Algeria in the north, Benin and Nigeria in the south, Burkina Faso in  southeast, Mali in west, and Chad in east", "GMAT", "the Renaissance", "Crowley brought back Samuel so that they could help him find Purgatory, the afterlife of monsters, and that Samuel has been working for him", "Fulham, Greater London, England", "French, English and Spanish", "Tom Baker", "The Fugitive", "What's Up (TV series)", "supply chain management", "Mars", "Stanislaw August Poniatowski (1764-95)", "polynomial algebra", "freda Davis", "three wise monkeys", "sheepskin and Merino Wool", "Honolulu"], "metric_results": {"EM": 0.0625, "QA-F1": 0.1556547619047619}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.25, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.21428571428571425, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "after_eval": {"predictions": ["florida", "belgium", "blessed", "leg", "d\u00f9n Chailleann", "North Sea", "davis Livingstone, a Scottish medical missionary, and William C. Oswell, an English explorer", "ned faldo", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio's \"The Show Band Show\"", "tANU", "niger", "60-mile-wide river", "top row of windows", "Sam's soul is not with him", "London", "French, English and Spanish", "dave Lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "flowing water", "poland", "matrices", "geena Davis", "three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys ''", "Sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.75, "QA-F1": 0.8018162393162394}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3238", "before_prediction": "Tanzania", "after_prediction": "tANU"}], "retained_ids": ["mrqa_hotpotqa-validation-2445"], "fixed_ids": ["mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_squad-validation-9319", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-6125", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "unfixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_triviaqa-validation-4055", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.7666666666666667, "instant_retention_rate": 0.4999999975}, {"timecode": 17, "before_eval": {"predictions": ["dymock", "X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "gamma ray emission ( energy of 514 keV )", "James Zeebo", "sovereign states", "president of the United States", "the Discovery Institute's \"Teach the Controversy\" campaign", "Bumblebee", "Australian", "18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "a private liberal arts college", "Carl Mears", "\"antiforms\" or where it buckles downwards, creating \"synforms\"", "June 9, 2015", "Veyyil", "Grace Nail Johnson", "Keith Richards", "prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "Bangor International Airport", "students learn from teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "180th meridian in a 360 \u00b0 - system", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "the Miami Heat of the National Basketball Association (NBA)", "33", "vitifolia", "Annual Conference Cabinet", "field hockey player Hannah Macleod", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.15625, "QA-F1": 0.275762512950013}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 0.7499999999999999, 0.0, 0.0, 0.4615384615384615, 0.0, 0.16, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.3333333333333333, 0.0, 0.5, 0.25, 0.07407407407407407, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845", "rubidium - 85", "James Zeebo", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "the Electoral College", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Velichko Todorov Tsochev) is a Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "475 acres (2.08 km\u00b2)", "Roy Spencer", "antiforms", "the second half of the third season", "Veyyil\" (2006)", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Cartoon Network's late night programming block, Adult Swim", "Presiding Officer", "the Phoenix Suns", "33-member", "grapevine", "The Annual Conference Cabinet, which is composed of the Area Provost/ Dean (if one is appointed) and the several District Superintendents of the Districts of the Annual Conference", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.75, "QA-F1": 0.8574271392367323}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.9302325581395349, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16, 0.75, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 0.23076923076923078, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3637", "before_prediction": "Veyyil", "after_prediction": "Veyyil\" (2006)"}, {"id": "mrqa_hotpotqa-validation-3573", "before_prediction": "Cartoon Network", "after_prediction": "Cartoon Network's late night programming block, Adult Swim"}, {"id": "mrqa_squad-validation-10074", "before_prediction": "Annual Conference Cabinet", "after_prediction": "The Annual Conference Cabinet, which is composed of the Area Provost/ Dean (if one is appointed) and the several District Superintendents of the Districts of the Annual Conference"}], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_naturalquestions-validation-430"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_squad-validation-8966"], "instant_fixing_rate": 0.8148148148148148, "instant_retention_rate": 0.3999999992}, {"timecode": 18, "before_eval": {"predictions": ["the genocide against the Tutsi", "Co-teachers work in sync with one another to create a climate of learning", "500 metres", "Vili Fualaau and Mary Kay Letourneau, a student and teacher who made news for their sexual relationship", "the entertainment division", "A to B", "12", "the Great Exhibition of 1851", "King Edward I to Henry VIII", "the Chagos Archipelago", "dundee", "the person compelled to pay for reformist programs", "darnley v of Scotland", "\"Grindhouse\" fake trailer", "davenport", "digital transmission", "the Swiss- Austrian border", "Tesla Gigafactory 1", "821", "HD channels and Video On Demand content which was not previously carried by cable", "gas", "Kim Hyun-ah", "the races of highest'social efficiency'", "transposition changes the relationship of the overall pitch range compared to the range of the instruments or voices that perform the music", "the \" King of Cool\"", "President Wilson and the American delegation from the Paris Peace Conference", "davis", "the fifth season", "davis dors", "Hockey Club Davos", "Michael Crawford", "a lightning strike"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26655505952380953}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.16666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.0, 0.6666666666666665, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "harmoniously", "500 metres", "Piper", "ABC News", "displacement", "five", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "Diego Garcia", "dundee", "at the bottom of the economic government", "fotheringhay", "Spy Kids", "Venus Williams", "Olivia", "Baden-W\u00fcrttemberg", "lithium-ion battery factory", "821", "basic channels", "pressure", "Hyuna", "highest'social efficiency'", "transposed", "the \" King of Cool\"", "American delegation from the Paris Peace Conference", "Socrates", "thirteenth", "Violet", "HC Davos", "Michael Patrick Smith", "Qutab Ud - Din - Aibak"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9437500000000001}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-5215", "before_prediction": "the person compelled to pay for reformist programs", "after_prediction": "at the bottom of the economic government"}], "retained_ids": ["mrqa_hotpotqa-validation-523", "mrqa_triviaqa-validation-5036", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-4068"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "unfixed_ids": ["mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-9841"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.7999999984}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "James Arness", "aragon", "11.1 percent", "trans-Pacific flight", "Sharman Joshi", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "prime", "Ana", "Cherry Hill", "In `` Fun Run ''", "f. O. Matthiessen s classic American Renaissance", "mary Myers", "comedy - drama", "Blackstar", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "In 1889", "Nicki Minaj", "mabel", "Huguenot", "Belle Epoque Casino and the Hotel de Paris", "friedrich Engels", "Drawn Together", "William the Conqueror", "Tel Aviv", "two degrees of freedom", "Mainland Greece", "blood samples", "Leo Richard Howard", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.15625, "QA-F1": 0.26990879186602873}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.10526315789473684, 1.0, 0.25, 1.0, 0.8, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.5, 0.0, 0.3333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-2627"], "after_eval": {"predictions": ["Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q.", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "david bowie", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1889", "Sir Mix - a-Lot", "slave of duty", "surnames", "portier", "marx", "Teen Titans Go!", "Norman invaders", "in Tel Aviv", "two", "peninsula", "taking blood", "youngest TV director ever", "Southern Progress Corporation"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9681818181818181}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5061", "before_prediction": "Tel Aviv", "after_prediction": "in Tel Aviv"}], "retained_ids": ["mrqa_hotpotqa-validation-2943", "mrqa_squad-validation-5538", "mrqa_hotpotqa-validation-5710", "mrqa_hotpotqa-validation-3049"], "fixed_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020", "mrqa_hotpotqa-validation-2627"], "unfixed_ids": ["mrqa_naturalquestions-validation-5017"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 20, "before_eval": {"predictions": ["reciprocating", "David Feldman", "the Sackler Centre for arts education", "davis terrell Smith", "David Brewster", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "Apollo", "ribosomal RNA", "kingfisher", "six", "Shalita Grant as Sonja Percy, ATF Agent / NCIS Special Agent ( seasons 2 -- 4 ; recurring previously )", "I Swear", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) )", "fitt", "heliocentric", "Lucius Cornelius Sulla Felix", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "put the citizens to trust God's word rather than violence", "maryland", "Pantone Matching System (PMS)", "Firoz Shah Tughlaq", "My Love from the Star", "San Jose", "marx fleckeri", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "the most giving Super Bowl ever", "29.7 percent", "b. j. Hunnicutt"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23543921356421355}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.48484848484848486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "prints and architectural drawings", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Mercury astronaut", "Ribosomes", "kookaburra", "six-time", "Daryl `` Chill '' Mitchell as Patton P. Plame, NCIS computer specialist ( season 2 -- ; recurring previously )", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "Gerry Adams (Sinn Fein)", "Moon's surface", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "mother tongues", "trust God's word", "turkey", "CMYKOG process", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "upper chamber", "a \"teleforce\" weapon", "Native American", "the most giving Super Bowl ever", "29.7%", "doctors, nurses, supporting staff, patients and civilians"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9120710784313726}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-1521", "mrqa_squad-validation-393"], "fixed_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2407", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-7272"], "unfixed_ids": ["mrqa_naturalquestions-validation-1279", "mrqa_triviaqa-validation-4852", "mrqa_naturalquestions-validation-2448", "mrqa_hotpotqa-validation-1906", "mrqa_triviaqa-validation-935"], "instant_fixing_rate": 0.8275862068965517, "instant_retention_rate": 0.9999999966666667}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier", "standardized breeds", "dog", "Yazoo", "22 April 1894", "the remnants of very massive stars", "the soul of a man \" in this life\" (homo enim in hac vita) tired from his daily labour (defatigus diurno labore) who at night enters his bedchamber (", "cede", "Willie Nelson and Kris Kristofferson", "Manson & Woods", "5 University of California campuses", "French pirate", "Lewis", "Charles Dickens and Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "is closely related to prime numbers. For example, the aforementioned fact that there are infinitely many primes can also be seen using the zeta function", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "huldra", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "James Bond", "640 \u00d7 1136 at 326 ppi", "fillies", "the Western Atlantic ctenophore Mnemiopsis leidyi was accidentally introduced into the Black Sea and Sea of Azov via the ballast tanks of ships, and has been blamed for causing sharp drops in fish catches", "Menace II Society", "backup quarterback", "Larry Wayne Gatlin"], "metric_results": {"EM": 0.125, "QA-F1": 0.2012690967496985}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.4210526315789474, 1.0, 1.0, 0.0, 0.0, 0.23529411764705882, 1.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.0, 0.0, 0.41025641025641024, 1.0, 0.22222222222222224, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-192", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "transfusion", "alison moyet", "1926", "black holes", "dreams", "they viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auction", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues with a view to encourage and support peace and human well being in the world", "proteins", "2001", "exceeds any given number", "alastair burnet", "padlocking the gates", "1960s", "R\u00e5", "western portions of the Great Lakes region", "Protestant", "first edition", "4 in", "colt teofilo", "Western Atlantic ctenophore Mnemiopsis leidyi was accidentally introduced", "\"Menace II Society\"", "a member of the Green Bay Packers, serving as a backup quarterback to Brett Favre and holder on placekicks", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8777412280701754}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-8689", "before_prediction": "1969", "after_prediction": "1960s"}], "retained_ids": ["mrqa_squad-validation-3627", "mrqa_naturalquestions-validation-5897", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-192", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_naturalquestions-validation-6832", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_triviaqa-validation-751", "mrqa_hotpotqa-validation-35", "mrqa_triviaqa-validation-6950", "mrqa_triviaqa-validation-1555"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.7499999981250001}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "the first Thursday in May", "MSC Crociere S. p.A.", "3 likes", "his friends, Humpty Dumpty and Kitty Softpaws", "Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres", "Parliamentarians", "any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "are ceremonially placed on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "bond girl", "20,000 leagues under the sea and Around the world in 80 days", "Augustus Waters", "1619", "Tony Blair", "\u2018 Often damaging\u2019", "June 11, 1973", "in the national parks and game reserves in the country", "Timeline of Shakespeare criticism", "boudicca", "neutrality", "Minnetonka ( ) is a suburban city in Hennepin County, Minnesota, United States, eight miles (13 km) west of Minneapolis", "AMC Theatres", "\"The Gang\"", "3 October 1990", "March 1, 2018", "heavy W and Z bosons", "daedalus", "oldest son", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2960419989367358}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.0, 0.0, 0.4444444444444445, 0.0, 0.33333333333333337, 0.1111111111111111, 0.16, 0.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.4, 0.0, 0.4, 0.22222222222222224, 0.0, 0.33333333333333337, 0.10526315789473684, 1.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Kitty Softpaws", "Nationals", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "s\u00e9a seydoux", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1619", "Tony Blair", "often damaging", "July 26, 1959", "Masai Mara", "chronological collection of critical quotations", "edward I", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "p.G. wodehouse", "Dexter", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.90625, "QA-F1": 0.921875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3944", "mrqa_triviaqa-validation-4731", "mrqa_hotpotqa-validation-803", "mrqa_naturalquestions-validation-1328", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_hotpotqa-validation-1929"], "unfixed_ids": ["mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-6872", "mrqa_triviaqa-validation-2179"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.9999999983333333}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion", "mono", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "javier (Luna)", "zinc silicate primer and vinyl topcoats", "Dreamland", "Academy Award for Best Animated Feature", "European Union institutions", "American astronaut who formerly held the American record for the most time in space (381.6 days)", "nine other contenders from across the United States", "NASA's CAL IPSO satellite", "celandine flowers", "Ulbricht", "Ronnie Schell", "artemisinin- Based therapy", "Tata Consultancy Services Limited (TCS) is an Indian multinational information technology (IT) service, consulting and business solutions company Headquartered in Mumbai, Maharashtra", "the east", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "southern Hemisphere in April, heavy showers coming from pre-monsoonal convective clouds mainly in the form of squall lines also known as the north easterlies", "Jane Seymour", "synovial joint", "bobby riggs", "Leucippus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth", "log-space reductions", "Corey Brown"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3205785533910534}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.25, 0.25, 0.25, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 0.5, 1.0, 0.3636363636363636, 1.0, 0.0, 0.14285714285714288, 0.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-542", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "after_eval": {"predictions": ["$105 billion", "mononucleosis", "17 nm vs 25 nm", "Austin Seven Ruby Open Top Tourer", "dirty dancing", "red", "Steeplechase Park", "Best Animated Feature", "European Convention on Human Rights", "381.6 days", "Death Wish Coffee", "NASA", "yellow", "Khrushchev", "Jack Cassidy", "malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall", "Kananga", "Incudomalleolar joint", "bobby riggs", "Leucippus", "Santa Clara", "benjamin barenboim", "political power", "polynomial-time reductions or log-space reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.65625, "QA-F1": 0.7671875}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.33333333333333337, 0.0, 1.0, 0.8, 0.0, 1.0, 0.25, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-789", "before_prediction": "Academy Award for Best Animated Feature", "after_prediction": "Best Animated Feature"}, {"id": "mrqa_squad-validation-327", "before_prediction": "Santa Clara Marriott", "after_prediction": "Santa Clara"}], "retained_ids": ["mrqa_squad-validation-7389", "mrqa_naturalquestions-validation-4048", "mrqa_squad-validation-2420", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-7481"], "fixed_ids": ["mrqa_triviaqa-validation-3716", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-4662", "mrqa_squad-validation-769"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_squad-validation-542", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750"], "instant_fixing_rate": 0.64, "instant_retention_rate": 0.7142857132653061}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt", "alchemy", "WBC and lineal titles", "moluccas", "the first Saturday in May", "Albany ( in the Quarto version )", "Arab oil producers linked any future policy changes to peace", "1979", "J.R. R. Tolkien", "John Elway", "Selena Gomez", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program and learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "bingo", "Eugene", "is an unofficial title sometimes given to new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze YouTubers", "nine", "Mongols and a Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "Mission Specialist for mission STS-51-L.", "it will retreat to its den and winter will persist for six more weeks", "mitterrand"], "metric_results": {"EM": 0.125, "QA-F1": 0.2938902445117755}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.07692307692307693, 1.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.08695652173913043, 0.0, 0.5714285714285715, 1.0, 0.0, 0.6486486486486487, 0.0, 0.0, 0.4, 0.7692307692307693, 0.0, 0.0, 0.0, 0.5, 0.2222222222222222, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.5957446808510638, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Kent", "multilateral", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program and learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "31 through 45", "Eugene", "comparable to the seven Wonders of the World", "2p + 1 with p prime", "coupe", "FaZe Rug", "Virgil", "Muslim", "along the coast, the settlements were growing into the interior", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.8125, "QA-F1": 0.894940937717577}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6486486486486487, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-10261", "mrqa_squad-validation-384", "mrqa_squad-validation-67", "mrqa_squad-validation-4417"], "fixed_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_naturalquestions-validation-10381", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_triviaqa-validation-3847", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.7857142857142857, "instant_retention_rate": 0.9999999975}, {"timecode": 25, "before_eval": {"predictions": ["alpine skiing, cross-country skiing, ski jumping, nordic combined, snowboarding and freestyle skiing", "slave girl", "over 50 million singles", "states'rights to expand slavery", "1923 and 1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "Buck Barrow", "iteratively", "American Buff geese", "the move from the manufacturing sector to the service sector", "Red Cliff Point", "Peter Davison, Colin Baker and Sylvester McCoy", "August 14, 1848", "lower rates of health and social problems", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "Broadway dancers auditioning for spots on a chorus line", "2,664", "a specific weak point on the inside of the chassis right beneath the volume buttons that allows it to bend very easily with pressure added in the right place", "a chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "services include: cleaning services, support services, property services, catering services, security services and facility management services", "Symphony No. 7", "gironde", "1603", "ranked above the two personal physicians of the Emperor", "sugar Plum Fairy", "Admitted to God, to ourselves, and to another human being the exact nature of our wrongs", "Chicago Cubs"], "metric_results": {"EM": 0.25, "QA-F1": 0.4155951687201687}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.3333333333333333, 0.25, 0.33333333333333337, 0.4615384615384615, 0.923076923076923, 0.0, 1.0, 0.0, 0.2857142857142857, 0.3636363636363636, 0.4, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.14285714285714288, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastics", "abraham", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "Buck Barrow", "iteratively", "goose", "effect", "Brisbane", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "lower", "juveniles are capable of reproduction before reaching the adult size and shape", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "bendgate", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "dordogne", "1603", "status superior to all others in health-related fields such as physicians and acupuncturists", "sugar Plum Fairy", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "Chicago Cubs"], "metric_results": {"EM": 0.78125, "QA-F1": 0.818173076923077}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7200000000000001, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2098", "before_prediction": "gironde", "after_prediction": "dordogne"}], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_squad-validation-9532", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4282", "mrqa_hotpotqa-validation-499", "mrqa_naturalquestions-validation-6545", "mrqa_triviaqa-validation-6221"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481"], "unfixed_ids": ["mrqa_hotpotqa-validation-5762", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_triviaqa-validation-1259"], "instant_fixing_rate": 0.75, "instant_retention_rate": 0.8749999989062499}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "true history of the Kelly Gang", "Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "tennis", "4,000", "Khagan", "Catherine Earnshaw", "canal aquaduct", "spice", "Moe Szyslak who receives dating advice from Abraham Simpson, whose ghost is possessing a love testing machine", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "The city has an extensive neoclassical centre referred to as Tyneside Classical largely developed in the 1830s by Richard Grainger and John Dobson, and recently extensively restored", "Albany High School for Educating People of Color", "Ram Bagh", "Sergeant First Class", "Anakin Skywalker", "seek jury nullification", "Cee - Lo", "The Church of England was legally established in the colony in 1619, and authorities in England sent in 22 Anglican clergyman by 1624", "Hattie McDaniel", "france", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "1757"], "metric_results": {"EM": 0.25, "QA-F1": 0.4199968434343434}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false], "QA-F1": [0.8, 0.19999999999999998, 0.0, 0.33333333333333337, 0.33333333333333337, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.1111111111111111, 0.923076923076923, 0.0, 0.07692307692307693, 0.5454545454545454, 0.0, 1.0, 1.0, 0.8, 0.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "an investment technique outlined by Joel Greenblatt", "kelly", "the Waialua District of the island of O\u02bb ahu", "1910", "those who refuse vetting", "Catch Me Who Can", "jazz", "amateurs", "3,677 seated", "Khagan", "catherine and heathcliff", "abbot of a monastery", "cassia", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "Shopping Centre", "Albany High School", "charbagh", "Sergeant First Class", "Anakin Skywalker", "jury nullification", "the closing scene of the final episode of the first season", "The Church of England", "oscar -winning black actress and singer Hattie McDaniel", "scharnhorst", "magntisme", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based", "January 11, 1755 or 1757July 12, 1804"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7875}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.8333333333333333]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7435", "before_prediction": "1910\u20131940", "after_prediction": "1910"}, {"id": "mrqa_triviaqa-validation-5839", "before_prediction": "Hattie McDaniel", "after_prediction": "oscar -winning black actress and singer Hattie McDaniel"}], "retained_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-6148", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-7801", "mrqa_squad-validation-7319"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_naturalquestions-validation-800", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5050"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_hotpotqa-validation-4553", "mrqa_triviaqa-validation-6689", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "instant_fixing_rate": 0.7083333333333334, "instant_retention_rate": 0.7499999990624999}, {"timecode": 27, "before_eval": {"predictions": ["alsivar", "geldof", "berry", "astrolights", "USS \"Massachusetts\" (BB-59)", "ocelots", "the \"eternal outsider, the sardonic drifter\" someone who rebels against the social structure", "a light sky-blue color caused by absorption in the red", "the peasants had to work for free on church land", "2009", "February 10", "The chloroplast double membrane", "aline charigot", "Grand Annual Steeplechase", "There, even in this case, BSkyB does not carry any control over the channel's content or carriage issues such as picture quality", "the third season", "a more fundamental electroweak interaction", "availability of skilled tradespeople", "hardness", "A simple iron boar crest", "the University of Northumbria at Newcastle in 1992 as part of the UK-wide process in which polytechnics became new universities", "curtin", "James", "25 - yard line", "the Latin centum, which means 100, and gradus", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "by faith", "margaret", "combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "company"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2905691229060794}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.08695652173913042, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.375, 0.0, 1.0, 1.0, 0.8, 0.0, 0.625, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-994", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["alsivar", "cliffchence", "blackberry", "horsehead", "Big Mamie", "ocelots", "Teamsters leader", "clear", "wat Tyler", "1963", "Zaza Pachulia", "inner chloroplast membrane", "renoir", "sports", "no", "third", "electrostrong interaction", "Cost of construction", "hardness", "A simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period", "polytechnics became new universities", "John Curtin", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard lines", "named after the Swedish astronomer Anders Celsius", "about 7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "lives by faith", "Cliff Thorburn", "produced with constant technology and resources per unit of time", "rubenesque", "badgers"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7505151098901099}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.9230769230769231, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7711", "before_prediction": "2009", "after_prediction": "1963"}, {"id": "mrqa_squad-validation-10312", "before_prediction": "a more fundamental electroweak interaction", "after_prediction": "electrostrong interaction"}, {"id": "mrqa_hotpotqa-validation-1226", "before_prediction": "A simple iron boar crest", "after_prediction": "A simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar from the same period"}, {"id": "mrqa_squad-validation-5125", "before_prediction": "7,000", "after_prediction": "about 7,000 out of 20,000 inhabitants"}], "retained_ids": ["mrqa_squad-validation-8279"], "fixed_ids": ["mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-994", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_squad-validation-5337", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-6331", "mrqa_triviaqa-validation-5962", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.1999999996}, {"timecode": 28, "before_eval": {"predictions": ["the Muslim faith as a tool of the devil", "Chris Weidman", "inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law", "Harishchandra", "studied Arabic grammar", "Professor Eobard Thawne", "plum", "US$10 a week", "1875", "member states", "because of all the instruments", "McKinsey's offices in Silicon Valley and India", "ophidiophobia", "Cliff Richard", "Crohn's disease or ulcerative colitis", "Ondemar Dias", "Raya Yarbrough", "the No. 3 seed Tennessee", "riddick bowe", "wealthy Chicagoans like Silas B. Cobb who provided the funds for the campus' first building, Cobb Lecture Hall", "Old Testament", "brown", "local talent", "Football League", "tegan", "mafic", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "Mary Eugenia Surratt", "1349", "dodo bird", "by focusing on negative or negative thoughts people can bring positive or negative experiences into their life", "Stan Butler"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3505907287157287}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.6363636363636364, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.4444444444444445, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 0.0, 1.0, 0.8888888888888888, 1.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_squad-validation-8190", "mrqa_naturalquestions-validation-7821"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law", "Kusha", "poet, and writer", "Professor Eobard Thawne", "p\u00e1linka", "a US$10 a week raise over Tesla's US$18 per week salary", "1825", "contributed by member states on a voluntary basis", "oboe", "McKinsey's offices", "phobias", "olympic duffy power", "Crohn's disease or ulcerative colitis", "Francisco de Orellana", "Bear McCreary", "UMBC", "michael davis", "Charles L. Hutchinson", "Song of Songs", "UPS", "local talent", "North End Football Club", "peter davison", "pemberton", "contemporary accounts were exaggerations", "John Surratt, Jr.", "1332", "dodo bird", "based on the idea that people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "Stan Butler"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7166939781916197}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.22641509433962262, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4827", "before_prediction": "plum", "after_prediction": "p\u00e1linka"}, {"id": "mrqa_squad-validation-4309", "before_prediction": "Ondemar Dias", "after_prediction": "Francisco de Orellana"}, {"id": "mrqa_triviaqa-validation-1347", "before_prediction": "riddick bowe", "after_prediction": "michael davis"}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-5086", "mrqa_triviaqa-validation-2953", "mrqa_triviaqa-validation-4308"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_hotpotqa-validation-4352", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_squad-validation-4921", "mrqa_squad-validation-8190"], "unfixed_ids": ["mrqa_squad-validation-6835", "mrqa_squad-validation-1276", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.68, "instant_retention_rate": 0.571428570612245}, {"timecode": 29, "before_eval": {"predictions": ["holly", "886 AD", "to finance his own projects with varying degrees of success", "24 Hours of Le Mans", "Kinect", "Tokyo", "defensive end Kony Ealy tipped a Manning pass to himself and then intercepted it", "parallelogram rule of vector addition", "John Thomas Scopes", "o'Connor of the Bird Watcher's General Store", "Neutron sources", "Don McLean", "cylinders", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "Doctorin' the Tardis", "National Basketball Development League (NBDL)", "chatham dukeyard", "St. Mary's County", "Ted Ginn Jr.", "2,615 at the 2010 census", "Pyeongchang", "athlete", "a password recovery tool for Microsoft Windows", "Homeless Man", "Charles and Ray Eames", "Brazil", "olympic skeleton", "smallest subfield", "heartburn", "53%", "photosynthesis"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30625291783380015}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 0.0, 0.4, 0.0, 0.0, 0.38095238095238093, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.058823529411764705, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-3103", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["poisonous, toxic, etc.", "the 1960s", "patents", "Formula One", "360", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "evolution", "364", "startup neutron source", "Van Gogh", "cylinder volume", "protection, production of blood cells, storage of minerals, and endocrine regulation", "Yuan society", "Doctorin' the Tardis", "National Basketball Development League", "kent", "Washington metropolitan area", "Sanders", "2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods Such as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "South Korea", "arthur", "smallest subfield", "petermint", "53%", "grana and thylakoids"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8447916666666666}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4708", "before_prediction": "holly", "after_prediction": "poisonous, toxic, etc."}, {"id": "mrqa_squad-validation-8075", "before_prediction": "the local administrative structure of past Chinese dynasties", "after_prediction": "Yuan society"}, {"id": "mrqa_triviaqa-validation-814", "before_prediction": "heartburn", "after_prediction": "petermint"}], "retained_ids": ["mrqa_squad-validation-7914", "mrqa_squad-validation-9036", "mrqa_squad-validation-7445"], "fixed_ids": ["mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-3103", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-5826", "mrqa_hotpotqa-validation-3031"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.49999999916666665}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "an outgoing, eccentic, big - hearted, loving, sweet, and thoughtful elephant and teacher", "arpers Ferry", "Basil Fawlty", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "ABC1", "arthur", "demographics and economic ties", "three or more", "The Kickoff Game", "narcolepsy", "arctic monkeys", "peter Ecclestone", "arthur", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "A computer program is a collection of instructions that performs a specific task when executed by a computer. A computer requires programs to function.", "Nationals are strongest in Victoria's North Western and Eastern rural regional areas", "marduk", "arthur", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "karlan", "South Pacific off the northeast coast of Australia", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Easy", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "k. Kamaraj", "National Lottery", "arthur", "peter", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.03125, "QA-F1": 0.09486708010556695}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.4444444444444445, 0.4, 0.12121212121212122, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "John Cleese and Connie Booth", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "three", "the most recent Super Bowl champion", "narcolepsy", "arctic monkeys", "imola", "gennaro", "all transmissions", "A computer program", "Greens", "marduk", "hekla", "largest source of foreign direct investment", "viacom", "South Pacific", "7", "New Jersey", "Easy", "Scott Bakula", "indira gandhi", "state-franchised", "Skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7427884615384616}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2750"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-6888", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_squad-validation-8451", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4578", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-1722", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_triviaqa-validation-7684", "mrqa_hotpotqa-validation-3333"], "instant_fixing_rate": 0.7096774193548387, "instant_retention_rate": 0.9999999900000002}, {"timecode": 31, "before_eval": {"predictions": ["Yolanda Sald\u00edvar", "Peter", "Jayne Torvill and Christopher Dean", "worsley", "Newell Highway", "mitcharf", "15 hands", "a shopping mall located in Bloomington, Minnesota, United States ( a suburb of the Twin Cities ). Southeast of the junction of Interstate 494 and Minnesota State Highway 77, north of the Minnesota River", "Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions", "directed by Andrew Adamson, Kelly Asbury and Conrad Vernon", "Johann Strauss", "his own men", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "arthur", "the RAF, Fighter Command had achieved a great victory in successfully carrying out Sir Thomas Inskip's 1937 air policy of preventing the Germans from knocking Britain out of the war.", "reduce growth", "Ibrium", "Hayley Sanderson", "Polish-Jewish", "Carlists", "Anything Goes", "foinavon", "390 billion", "Washington Street", "May 10, 1976", "five", "London Tipton", "The lyrics reflect his frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison", "dansan", "John Smith", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2712231196987294}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.07142857142857142, 0.7272727272727273, 0.3636363636363636, 0.0, 0.0, 0.37037037037037035, 0.0, 0.07407407407407407, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.43902439024390244, 0.0, 1.0, 1.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "explaining their actions", "Andrew Adamson", "waltz king", "Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage growth", "Ibbi-Sipish", "strictly Come Dancing", "Polish", "the Falange", "cole porter", "1967", "16,000 species", "Washington Street", "8 November 1978", "five", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "barbarella", "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution", "lusitania", "worked as weavers"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9444444444444444}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1444", "before_prediction": "Ibrium", "after_prediction": "Ibbi-Sipish"}, {"id": "mrqa_naturalquestions-validation-4500", "before_prediction": "John Smith", "after_prediction": "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution"}], "retained_ids": ["mrqa_hotpotqa-validation-2762", "mrqa_hotpotqa-validation-3233", "mrqa_squad-validation-932", "mrqa_triviaqa-validation-4524"], "fixed_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3728", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_squad-validation-3106"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.6666666655555555}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "beer", "gender test", "Jones portrays Dwight's cousin Zeke", "potassium hydroxide", "in order to halt it following brake failure", "T cell receptor", "relatively low salaries", "non-GMO", "Heading Out to the Highway", "Moonraker", "$12.99", "Michael Oppenheimer", "England national team", "entitled institutionally and legally", "No Night Today", "Convention", "5,922", "December 5, 1991", "psychological horror", "76ers", "traditions surrounding the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas", "Stern-Plaza", "the Astrodome", "23 March 1991", "Sunday", "Dealey Plaza", "Nairobi", "the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.1875, "QA-F1": 0.34136523199023194}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.15384615384615385, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "after_eval": {"predictions": ["orbital scientific instrument package", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "september", "south africa", "Thomas Middleditch", "k", "In extreme circumstances", "alternative T cell receptor (TCR)", "relatively low salaries", "non-GMO", "Point of Entry", "bridge", "u", "Science Magazine's", "Premier League club Manchester United and the England national team", "poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Sinterklaas", "Frankfurt (Oder) Germany", "Jimmy Ellis", "1991", "may", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Neonski Grad"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8511904761904762}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-572", "before_prediction": "Fomento Econ\u00f3mico Mexicano", "after_prediction": "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V."}, {"id": "mrqa_hotpotqa-validation-5335", "before_prediction": "Stern-Plaza", "after_prediction": "Frankfurt (Oder) Germany"}, {"id": "mrqa_hotpotqa-validation-5557", "before_prediction": "Anno 2053", "after_prediction": "Neonski Grad"}], "retained_ids": ["mrqa_squad-validation-6744", "mrqa_squad-validation-2234", "mrqa_hotpotqa-validation-3508"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_squad-validation-6602", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "unfixed_ids": ["mrqa_naturalquestions-validation-5510", "mrqa_triviaqa-validation-7156", "mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.49999999916666665}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "\"Boston Herald\" Rumor Clinic", "1967", "\"winnings\"", "the twelfth most populous city in the United States", "115", "bridge", "changes in gene expression", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Chava with Fyedka", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country", "japan", "bridge", "Yunnan- Fu", "Mumbai, India", "Sydney", "2005", "buyers from all punishments and granted them salvation", "\"The Doctor's Daughter\"", "september", "cole", "The project must adhere to zoning and building code requirements. Constructing a project that fails to adhere to codes does not benefit the owner", "1879", "daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system", "enthusiasm and energy", "koreans", "luxury divisions", "Bill Clinton", "Buskerud and Telemark"], "metric_results": {"EM": 0.09375, "QA-F1": 0.1831084287163141}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.14285714285714288, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.4, 0.0, 0.0, 0.0, 0.06896551724137931, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.5]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "after_eval": {"predictions": ["defeat of Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "largest Filipino American community", "M&M Boys -- are the only teammates to reach the 50 home run club in the same season, hitting a combined 115 home runs in 1961 and breaking the single - season record for home runs by a pair of teammates", "joseph pintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher rates", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "along the St. Lawrence River valley, with some also in Acadia (present-day New Brunswick and parts of Nova Scotia, including \u00cele Royale", "japan", "oakum", "Spring city", "London", "Broken Hill and Sydney", "2005", "punishments", "Smith and Jones", "wagons", "illich Ramirez Sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "power windows", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.875, "QA-F1": 0.8939393939393939}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6060606060606061, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1573", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-1903"], "fixed_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_naturalquestions-validation-6358", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "unfixed_ids": ["mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975"], "instant_fixing_rate": 0.8620689655172413, "instant_retention_rate": 0.9999999966666667}, {"timecode": 34, "before_eval": {"predictions": ["Chairman and a Deputy Chairman", "wartsnell", "engaging in the forbidden speech", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "september", "0.2 inhabitants per square kilometre", "king Edward Graham Niven", "France", "Ian Paisley", "bataan Death March", "euro", "suggs", "the United States allegedly agreed not to interfere with Japan in matters concerning Korea", "1973", "1890", "2008", "Manhattan", "juba", "pole", "Johnny Darrell", "a waxy substance called plaque builds up inside the carotid arteries", "margarine", "Euler's totient function", "if earwax accumulates to cause symptoms", "binary strings", "Busiest airports in the United States by international passenger traffic", "red", "Honda Accord", "Kurt Vonnegut", "september"], "metric_results": {"EM": 0.09375, "QA-F1": 0.16423229548229548}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.2857142857142857, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman", "Norman Hartnell", "Threatening government officials", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52", "William Edward Graham Niven", "The country was chosen as the host nation by FIFA for the second time in the history of the tournament", "Ian Paisley", "Bataan Death March", "lTL", "Madness", "Taft -- Katsura Agreement", "late 1970s", "first published in 1890", "75th", "The movie plays in real time, with many flashbacks to flesh out the story. Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "a waxy substance called plaque builds up inside the carotid arteries", "motorcycles or mopeds pulling trailers", "the relationship of the number to its corresponding value of Euler's totient function", "earwax blockage", "how graphs are encoded as binary strings", "third", "red", "large", "Lauren Oliver", "Rapunzel to Gothel"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7315641534391535}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14814814814814814, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6465", "before_prediction": "Manhattan", "after_prediction": "The movie plays in real time, with many flashbacks to flesh out the story. Stanwyck's bedroom window overlooks the night skyline of Manhattan"}], "retained_ids": ["mrqa_hotpotqa-validation-3982", "mrqa_hotpotqa-validation-1139"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034"], "unfixed_ids": ["mrqa_squad-validation-6673", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-3072", "mrqa_naturalquestions-validation-8990", "mrqa_triviaqa-validation-7592", "mrqa_triviaqa-validation-3408", "mrqa_triviaqa-validation-7184", "mrqa_triviaqa-validation-1198"], "instant_fixing_rate": 0.6896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "based on the interplay of supply and demand, which determines the prices of goods and services", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "urecchiette", "Washington Redskins", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "William Howard Ashton", "national security, big oil companies and bribery and corruption", "increasing inequality harms economic growth. High and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Broward County", "Lee Byung-hun", "changing display or audio settings quickly", "king Charles I", "derived from the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "if the income share of the top 20 percent (the rich) increases, then GDP growth actually declines over the medium term", "Beautyy and the Beast", "South Africa", "Tyler \" Ty\" Mendoza", "the Alamo", "a seal illegally is broken", "the UMC", "Brian Liesegang", "Roger Allers and Rob Minkoff", "Papua New Guinea", "Alvin Simon Theodore Ross Bagdasarian David Seville", "National Association for the Advancement of Colored People", "1963\u20131989", "The Trenton Evening Times", "John Smith (13 September 1938 - 12 May 1994) served as Leader of the Labour Party from July 1992 until his sudden death from a heart attack in May 1994", "Darrin Stephens", "6500 - 1500 BC"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3347357503607503}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.5, 0.11111111111111112, 0.14285714285714288, 0.4, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0909090909090909, 0.0, 0.0, 0.4, 1.0, 0.4444444444444445, 0.1111111111111111, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.7499999999999999, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["up to 2% higher", "capital and financial markets", "Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "butterfly", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard adjoining the Assembly Hall", "William Howard Ashton", "national security, big oil companies and bribery and corruption", "Unemployment", "Miami", "The Good, the Bad, the Weird", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "king king king craig", "spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "South Africa", "Scotty Grainger Jr.", "texas state", "a seal", "United Methodist Church", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "NAACP", "1963\u20131989", "Trenton Evening Times", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 0.75, "QA-F1": 0.7762362637362636}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.15384615384615385, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3767", "before_prediction": "king Charles I", "after_prediction": "king king king craig"}, {"id": "mrqa_hotpotqa-validation-1475", "before_prediction": "Tyler \" Ty\" Mendoza", "after_prediction": "Scotty Grainger Jr."}, {"id": "mrqa_squad-validation-10036", "before_prediction": "the UMC", "after_prediction": "United Methodist Church"}], "retained_ids": ["mrqa_hotpotqa-validation-2971", "mrqa_triviaqa-validation-6450", "mrqa_squad-validation-7610"], "fixed_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "unfixed_ids": ["mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-6423", "mrqa_hotpotqa-validation-2947", "mrqa_triviaqa-validation-3860"], "instant_fixing_rate": 0.8076923076923077, "instant_retention_rate": 0.49999999916666665}, {"timecode": 36, "before_eval": {"predictions": ["National Broadcasting Company", "Amber Laura Heard", "planet Uranus", "What else can you tell me about President Ford's genealogy", "Cobham\u2013Edmonds thesis", "human, or humanoid aliens", "Best Male Pop Vocal Performance", "March 2012", "laid-back attitude and the easy-going nature of the jazz musicians and other residents of the city", "Muhammad Ali", "Coldplay", "Menorca", "to civil disobedients", "Julius Caesar", "Approximately one million Protestants in modern France represent some 2% of its population", "1979", "a virtual reality simulator", "formal language", "Hexham, Northumberland", "heart", "That the plague was caused by bad air", "a form of drinkware made to hold either a British ( `` imperial '' ) pint of 20 imperial fluid ounces ( 568 ml ) or an American pint of 16 US fluid ounces", "mountain ranges", "red", "significant production of peaches as early as 1571, with exports to other states occurring around 1858", "nettle", "By the end of the embargo in March 1974, the price of oil had risen from US$3 per barrel to nearly $12 globally", "flat rate", "All I Want", "a nationwide network in the UK", "roughly west", "Sudan"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3790740917579153}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.23529411764705882, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.14285714285714288, 1.0, 0.35294117647058826, 1.0, 0.0, 0.4, 1.0, 0.21428571428571425, 1.0, 0.0, 0.2222222222222222, 1.0, 0.18181818181818182, 0.0, 0.28571428571428575, 0.28571428571428575, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_squad-validation-3060", "mrqa_naturalquestions-validation-3993", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "titanic", "Rudolph", "Cobham\u2013Edmonds thesis", "to remind the Doctor of his \"moral duty\"", "II", "April", "margaret", "Raymond Patterson", "Coldplay", "Gibraltar", "submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen", "emperors", "2%", "January", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "decision problem", "floriana", "right side of the heart", "the Miasma theory", "imperial fluid ounces", "mountain ranges", "white", "California", "nettle", "$12", "20 %", "love is all around", "ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.75, "QA-F1": 0.7670138888888889}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.1, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6011", "before_prediction": "Menorca", "after_prediction": "Gibraltar"}, {"id": "mrqa_hotpotqa-validation-1884", "before_prediction": "1979", "after_prediction": "January"}, {"id": "mrqa_squad-validation-1634", "before_prediction": "formal language", "after_prediction": "decision problem"}, {"id": "mrqa_squad-validation-4877", "before_prediction": "That the plague was caused by bad air", "after_prediction": "the Miasma theory"}], "retained_ids": ["mrqa_hotpotqa-validation-152", "mrqa_squad-validation-1758", "mrqa_squad-validation-110", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-4069"], "fixed_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-4115", "mrqa_squad-validation-3060", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "unfixed_ids": ["mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-3803", "mrqa_squad-validation-6759", "mrqa_triviaqa-validation-5936"], "instant_fixing_rate": 0.8260869565217391, "instant_retention_rate": 0.5555555549382716}, {"timecode": 37, "before_eval": {"predictions": ["Southern Pacific", "three of his ribs were broken", "7 December 2000", "roughly midway between Los Angeles and San Francisco on the Central Coast", "mother-of-pearl made between 500 AD and 2000", "February 20, 1978", "india", "Ronald Reagan", "96", "De Inventione by Marcus Tullius Cicero", "japan", "a black background representing the circle with glossy gold letters", "Jericho in the Levant region, thought to be the world's first town ( settled around 8500 BC and fortified around 6800 BC )", "around 11 miles (18 km) south of San Jose", "margaret lingstrom", "Henry is fifth in line to the throne, while Rumplestiltskin, with whom she has been having an affair, offers her love", "Harry Kane", "large birds or mammals. However, the desert does sustain many types of lizard including the vulnerable great desert skink ( Egernia kintorei ) and a number of small marsupials", "events and festivals", "india", "1991", "polyphemus", "7 January 1936", "lifetime protection", "twenty- three", "Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez", "education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services, such as sewage and building code enforcement.", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Bj\u00f8rnsh\u00f8j Poulsen", "mistreatment from government officials", "labneh or strained yogurt", "Boston, Massachusetts"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2663938492063492}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.2857142857142857, 0.0, 0.13333333333333333, 0.25, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_squad-validation-5451", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_triviaqa-validation-2524"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "the Roman Empire", "koreans", "white, blue, pink, rainbow neon and glittering", "Mesopotamia", "37\u00b0 9' 58.23\"", "Woodentops", "Henry", "shared", "perentie", "events and festivals", "kabinett", "2010", "the Na'vi", "7 January 1936", "lifetime protection", "twenty-three episodes", "Carl Sagan", "Much of the city's tax base dissipated", "Republicans, who were loyal to the democratic, left - leaning and relatively urban Second Spanish Republic, in an alliance of convenience with the Anarchists and Communists", "Pierre Nlend Wom\u00e9", "allocution", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8673007246376812}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.08695652173913045, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6737", "before_prediction": "mistreatment from government officials", "after_prediction": "allocution"}], "retained_ids": ["mrqa_hotpotqa-validation-513", "mrqa_hotpotqa-validation-4154", "mrqa_squad-validation-677", "mrqa_hotpotqa-validation-85", "mrqa_naturalquestions-validation-969", "mrqa_hotpotqa-validation-5371"], "fixed_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_squad-validation-5451", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-4212", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_hotpotqa-validation-633", "mrqa_triviaqa-validation-2524"], "unfixed_ids": ["mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-1375"], "instant_fixing_rate": 0.84, "instant_retention_rate": 0.8571428559183674}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Etienne de Mestre", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "a children's story published by John Newbery in London in 1765", "243 days", "gathering money from the public", "Eden and Thorgan", "commissioned to purchase their required uniform items", "Jeff Meldrum", "1973 to 1988", "Patricia Greene", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "suez canal", "34", "laboratory", "the fact that there is no revising chamber", "1960s", "the points of algebro-geometric objects", "those were newly accessioned into the collection, probably don't show up in the computer system", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "strychnine", "California", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation.", "13 June 2003", "Eddy Shah", "Louis Prima", "first heart sound"], "metric_results": {"EM": 0.125, "QA-F1": 0.23484299375250517}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.09523809523809523, 0.0, 0.0, 0.4, 0.47058823529411764, 0.28571428571428575, 0.22222222222222224, 0.25, 0.0, 0.0, 0.15384615384615383, 0.0, 1.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.47058823529411764, 0.06451612903225806, 1.0, 0.0, 0.3846153846153846, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-1660", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "after_eval": {"predictions": ["the NP-complete knapsack problem", "Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson", "1958", "Bart Cummings", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "the colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \" Jeff\" Meldrum", "a week", "phil archer", "French and English", "The Chipettes", "Australis", "60 by West All - Stars ( 2017 )", "journalist", "take evidence from witnesses, conduct inquiries and scrutinise legislation", "beehive", "ramification", "those were newly accessioned into the collection", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "Today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8689894636015325}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [0.5714285714285715, 0.896551724137931, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1862", "before_prediction": "the NP-complete Boolean satisfiability problem", "after_prediction": "the NP-complete knapsack problem"}, {"id": "mrqa_triviaqa-validation-3118", "before_prediction": "suez canal", "after_prediction": "Australis"}], "retained_ids": ["mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-3320"], "fixed_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-1660", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-685", "mrqa_hotpotqa-validation-1116", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.8214285714285714, "instant_retention_rate": 0.49999999875}, {"timecode": 39, "before_eval": {"predictions": ["Taipei", "Dan Conner", "Checkpoint Charlie", "Lee Harvey Oswald", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "keskes", "the 1980s", "John M. Grunsfeld, geneticist James Watson, best known as one of the co-discoverers of the structure of DNA, experimental physicist Luis Alvarez, popular environmentalist David Suzuki,", "New York City", "elton john", "2003", "spring time", "Fabbrica Italiana Automobili Torino", "the second Sunday of March, and standard time restarts on the first Sunday in November", "relative units of force and mass", "woman", "Porto", "August 10, 1933", "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Vancouver", "those who already hold wealth have the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "oil", "cheagrass", "264,152", "Princeton, New Jersey", "the United States", "high pressure or an electric current"], "metric_results": {"EM": 0.34375, "QA-F1": 0.43957944288826645}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.8, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 0.47058823529411764, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.37037037037037035, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_naturalquestions-validation-3108", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["Taiwan", "Dan Conner", "east and west berlin", "The CIA Admits Covering Up JFK Assassination", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "the 1980s", "John M. Grunsfeld", "New York City", "a man who makes potions in a traveling show", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "fixed", "woman", "two", "August 10, 1933", "one - mile - wide", "Vancouver", "those who already hold wealth", "bilingual German author B. Traven", "Finding Nemo", "Fortean", "inflation", "bumblebees", "247,597", "The Institute for Advanced Study", "the German Empire", "DC electricity"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7667925824175824}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6133", "before_prediction": "Taipei", "after_prediction": "Taiwan"}, {"id": "mrqa_triviaqa-validation-5595", "before_prediction": "Porto", "after_prediction": "two"}, {"id": "mrqa_naturalquestions-validation-5272", "before_prediction": "bilingual German author B. Traven, whose identity remains unknown", "after_prediction": "bilingual German author B. Traven"}], "retained_ids": ["mrqa_hotpotqa-validation-2243", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-6554", "mrqa_naturalquestions-validation-3698", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-2332", "mrqa_triviaqa-validation-4024", "mrqa_hotpotqa-validation-489"], "fixed_ids": ["mrqa_triviaqa-validation-2890", "mrqa_hotpotqa-validation-944", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-3017", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_naturalquestions-validation-3108", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_triviaqa-validation-1438", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-2203"], "instant_fixing_rate": 0.6666666666666666, "instant_retention_rate": 0.7272727266115702}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgis", "the 14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "the foundations of the Reformation placing them on prophetic faith", "Aristotle", "Charlton Heston", "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes) peak in order to elicit an effective response against any intruding pathogens", "the Highland garb", "Kevin Kolb", "a tradeable entity used to avoid the inconveniences of a pure barter system", "may have the force of law, if based on the authority derived from statute or the Constitution", "son et lumi\u00e8re", "when the Mongols placed the Uighurs of the Kingdom of Qocho over the Koreans at the court the Korean King objected", "Sochi, Russia", "left and others on the right", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "After the cabin fire incident", "australia", "shorthand typist", "30", "the Secret Intelligence Service", "100 billion", "kai su, teknon", "the photolysis of ozone by light of short wavelength", "4.7 / 5.5 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3860736766825129}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.375, 0.7692307692307693, 0.0, 0.0, 0.6206896551724138, 0.0, 0.0, 1.0, 0.13333333333333333, 0.0, 0.09523809523809522, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "ice dancing", "Isabella (Belle) Baumfree", "corgi", "every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "placing them on prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs (cytotoxic T lymphocytes)", "tartan", "philadelphia eagles", "one of the uses of money", "express or implied Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "son et lumi\u00e8re", "the Uighurs surrendered peacefully without violently resisting", "Sochi, Russia", "south and west afghanistan", "Hudson Bay", "immediately", "australia", "stenographer", "30 Major League Baseball teams", "MI6", "neuron", "kai su, teknon", "photolysis", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.75, "QA-F1": 0.7658854166666667}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1571", "before_prediction": "sarajevo", "after_prediction": "ice dancing"}, {"id": "mrqa_squad-validation-4953", "before_prediction": "the 14th to 17th centuries", "after_prediction": "every year between 1346 and 1671"}, {"id": "mrqa_naturalquestions-validation-10265", "before_prediction": "a tradeable entity used to avoid the inconveniences of a pure barter system", "after_prediction": "one of the uses of money"}], "retained_ids": ["mrqa_squad-validation-395", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-4076", "mrqa_triviaqa-validation-4123", "mrqa_squad-validation-3617", "mrqa_hotpotqa-validation-178"], "fixed_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-1063", "mrqa_squad-validation-8247", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "unfixed_ids": ["mrqa_naturalquestions-validation-8961", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1859", "mrqa_triviaqa-validation-3280", "mrqa_triviaqa-validation-579"], "instant_fixing_rate": 0.782608695652174, "instant_retention_rate": 0.6666666659259258}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Padosan (Hindi: \"\u092a\u0921\u093c\u094b\u0938\u0928\" English: lady Neighbour )", "Gaels", "Crash", "d\u00edsabl\u00f3t", "European or Eurasian cave lion", "Russian", "delta growth", "Washington metropolitan area", "GTPase responsible for endocytosis", "User State Migration Tool ( USMT )", "Ordos City China Science Flying Universe Science and Technology Co.", "ferrisbee", "PPG Paints Arena, Pittsburgh, Pennsylvania", "Jewry Wall Museum", "Section 30 of the Teaching Council Act 2001", "agnes Moorehead as the Goose, an unnamed goose who is the one that encourages Wilbur to speak for the first time", "mid-1988", "quasars", "Monsoon or Retreating Monsoon", "Romansh", "Tudor king", "MIX 94.5", "James Bond quartermaster Q", "the Philippians", "the division of labour, productivity, and free markets", "Gerard Marenghi", "Whitney Houston", "Nebula Award", "Conservative Party", "king David of Israel", "Jean - Paul - \u00c9gide Martini"], "metric_results": {"EM": 0.0625, "QA-F1": 0.1921672077922078}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.19999999999999998, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.4, 0.0, 0.4, 1.0, 0.0, 0.5, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag", "Idisi", "lion", "The cinema of Russia", "sediment load", "FedExField in Landover, Maryland", "scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment, both at the cell surface", "Windows Easy Transfer", "Ordos City", "flying disc", "Duquesne University", "le Leicester", "Section 30", "Paul Lynde", "October 1986", "Huge-LQG", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george iii", "5AA", "Q", "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret tabled a motion of no confidence", "jonathan", "Hugo Peretti, Luigi Creatore"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8749020989974937}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8421052631578948, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7728", "before_prediction": "the Philippians", "after_prediction": "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD"}], "retained_ids": ["mrqa_squad-validation-1592"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-4320"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355", "mrqa_triviaqa-validation-684", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-8338", "mrqa_triviaqa-validation-791", "mrqa_naturalquestions-validation-9763"], "instant_fixing_rate": 0.8, "instant_retention_rate": 0.4999999975}, {"timecode": 42, "before_eval": {"predictions": ["budd", "cavatelli, acini di pepe, pastina, orzo, etc.", "boston", "independence from the Duke of Savoy", "various causes", "questions about the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "paid professionals", "explaining their actions, in allocution", "a large Danish shipping company that operates passenger and freight services across northern Europe", "a defender", "jonathan", "the side - chain of the amino acid N - terminal", "fructose is a sweet, white, odorless, crystalline solid, and is the most water - soluble of all the sugars", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "Dave Thomas", "an abbreviation used in the publications of the Myers -- Briggs Type Indicator ( MBTI ) to refer to one of sixteen personality types", "Thursday", "yellow", "drug choice, dose, route, frequency, and duration", "Olympus Mons", "navigator and expedition leader", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "jules", "The Private Education Student Financial Assistance", "gamba", "to sell indulgences to raise money to rebuild St. Peter's Basilica in Rome", "Britain", "two forces, one pointing north, and one pointing east", "Bills", "Jack Murphy Stadium", "hierarchy theorems"], "metric_results": {"EM": 0.0625, "QA-F1": 0.19810705532212886}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.9333333333333333, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.4666666666666667, 0.125, 0.375, 0.5, 0.0, 0.0, 0.0, 0.0, 0.8750000000000001, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.47058823529411764, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_squad-validation-1429", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballets", "derision", "ozone generated in contact with the skin", "American Civil War", "Chartered", "lack of remorse", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "F fructose", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "Extroverted Intuition ( Ne )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "mars", "feats of exploration", "piston", "rob lowe", "The Private Education Student Financial Assistance", "bows", "rebuild St. Peter's Basilica in Rome", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.875, "QA-F1": 0.9647321428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-7034", "mrqa_squad-validation-9452"], "fixed_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_squad-validation-1429", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-4842", "mrqa_squad-validation-2150"], "instant_fixing_rate": 0.8666666666666667, "instant_retention_rate": 0.999999995}, {"timecode": 43, "before_eval": {"predictions": ["Niagara Falls-Horseshoe Falls", "scrabble", "Indiana", "Utah", "French", "a \"homeward bounder\") a sailor coming home from a round trip", "node", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "Les Huguenots", "vegan, some contain propolis and/or beeswax sourced from bees", "fly", "Rigoletto", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally", "third-most abundant element in the universe", "IKEA", "216 countries and territories around the world", "football", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac", "Akon, T.I. Rick Ross, Fat Joe, Birdman and Lil Wayne", "the Outfield", "Croatia", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film", "railway locomotives", "Mike Todd", "at slightly different times when viewed from different points on Earth", "bresslaw", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "mitochondrial Eve", "237 square miles", "magi"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2722501301158422}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false], "QA-F1": [0.8, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.21052631578947367, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.21052631578947367, 0.0, 0.0, 0.060606060606060615, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "after_eval": {"predictions": ["bridal Veil falls", "white", "india", "salt lake city", "Italian", "sailor", "hostname", "recurring and life-threatening infections", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest", "third", "furniture", "169", "mexico", "Edward Hodges Baily, Lord Leighton, Alfred Stevens, Thomas Brock, Alfred Gilbert, George Frampton, and Eric Gill", "Plies", "English rock band the Outfield", "tennis", "Edward Furlong", "road engines", "richard burton", "when the Moon's ecliptic longitude and the Sun's EcliptIC longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "Bootsie and Snudge", "Glenn T. Seaborg", "Tennessee", "computers", "africa", "237", "matthew"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7639384920634921}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true], "QA-F1": [0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 0.5, 1.0, 0.4, 0.4, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7538", "before_prediction": "Indiana", "after_prediction": "india"}, {"id": "mrqa_triviaqa-validation-4090", "before_prediction": "IKEA", "after_prediction": "furniture"}, {"id": "mrqa_hotpotqa-validation-4624", "before_prediction": "Kentucky, Virginia, and Tennessee", "after_prediction": "Tennessee"}, {"id": "mrqa_squad-validation-3812", "before_prediction": "avionics, telecommunications, and computers", "after_prediction": "computers"}, {"id": "mrqa_triviaqa-validation-5899", "before_prediction": "mitochondrial Eve", "after_prediction": "africa"}], "retained_ids": [], "fixed_ids": ["mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "unfixed_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.0}, {"timecode": 44, "before_eval": {"predictions": ["Wakanda", "income depending on experience", "England and Wales Cricket Board ( ECB )", "cricket", "football", "campaign setting", "the `` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867 feet", "the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "Shape of You", "Yoda", "8th", "chari bari pembo", "hospitals and clinics", "increased patient health outcomes and decreased costs to the health care system", "Good Boy Deserves Favour", "G-Styles", "160 km / h", "Piazza Trinit\u00e0 dei Monti", "April 2010", "Estelle Sylvia Pankhurst", "egypt", "philosophical advocate and practitioner of the scientific method", "meyer", "The Ministry of Corporate Affairs", "Irish", "Numa Pompilius is believed to have built this temple along with the original Regia and House of the Vestal Virgins", "meyer", "oxygen", "mars", "Sanctifying Grace", "Christ lag"], "metric_results": {"EM": 0.09375, "QA-F1": 0.26342182123432123}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.22222222222222224, 0.4, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.923076923076923, 0.0, 1.0, 0.0, 0.0, 0.0, 0.39999999999999997, 0.0, 0.0, 0.7499999999999999, 0.0, 0.4, 0.8, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "2003 for the inter-county competition in England and Wales", "sweden", "sweden", "published campaign settings", "2003", "867", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Christopher Lee as Count Dooku / Darth Tyranus", "second", "chari Bari Ruchi-pip Peri Pembo", "all health care settings", "expected to become more integral within the health care system", "music", "Lecrae Devaughn Moore", "maximum speed 160 km / h", "Rome", "May 18, 2010", "Sylvia Pankhurst", "European Union (EU)", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "Hubble Space Telescope", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8646390374331551}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-10619", "before_prediction": "the `` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "after_prediction": "2003"}, {"id": "mrqa_naturalquestions-validation-5550", "before_prediction": "Yoda", "after_prediction": "Christopher Lee as Count Dooku / Darth Tyranus"}], "retained_ids": ["mrqa_hotpotqa-validation-5696"], "fixed_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_squad-validation-7067", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "unfixed_ids": ["mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-3664", "mrqa_triviaqa-validation-5022"], "instant_fixing_rate": 0.8620689655172413, "instant_retention_rate": 0.3333333322222222}, {"timecode": 45, "before_eval": {"predictions": ["spillane", "7\u20139", "tobacco", "under `` the immortal Hawke ''", "death penalty", "frail", "sweden", "chr\u00e9tien de Troyes", "Mangal Pandey of the 34th BNI", "Agrippina", "Cartwright clan", "four of the 50 states of the United States in their full official state names", "salt lake city", "eighth series", "Carmel and Pacific Grove", "St. Louis", "French", "Gareth", "LOVE Radio", "Boston Red Sox", "the court from its members for a three - year term", "richard", "David Dobkin", "brought several hundred thousand US and allied non-Muslim military personnel to Saudi Arabian soil to put an end to Saddam Hussein's occupation of Kuwait", "The Carnabeats", "Cashin' In", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "Santa Clara, California", "the official residence of the President of the Russian Federation", "Neptune", "Isthmus of Corinth"], "metric_results": {"EM": 0.25, "QA-F1": 0.36858436702186703}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.07142857142857142, 0.5, 1.0, 0.4166666666666667, 0.16666666666666669, 0.8, 0.18181818181818182, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "after_eval": {"predictions": ["mike Hammer", "Detroit Lions", "tobacco", "under `` the immortal Hawke ''", "death penalty", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum", "Lorne Greene", "Massachusetts", "belfast", "the eighth series", "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove", "St. Louis", "Canadian", "Henry Mills", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "radicalize the Islamist movement", "The Carnabeats and by several other artists, including foreign translations", "Cashin' In", "most recent Super Bowl champions", "Command/ Service Module (CSM)", "Santa Clara", "tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.75, "QA-F1": 0.8104296066252588}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6956521739130436, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1433", "before_prediction": "Gareth", "after_prediction": "Henry Mills"}], "retained_ids": ["mrqa_naturalquestions-validation-4123", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-2598", "mrqa_hotpotqa-validation-5068", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-866", "mrqa_hotpotqa-validation-3509"], "fixed_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_squad-validation-9513", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-13", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "unfixed_ids": ["mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1754", "mrqa_squad-validation-3845", "mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.7083333333333334, "instant_retention_rate": 0.8749999989062499}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That", "youngest publicly documented people to be identified as transgender", "electric lighting", "used their knowledge of Native American languages as a basis to transmit coded messages", "Galileo Galilei and Sir Isaac Newton", "the absenceistence of the ultraviolet catastrophe", "Premier League club Swansea City", "pre-Raphaelite", "Elizabeth Weber", "a spin-off of an earlier Funcom game, \"The Secret World\"", "hundreds of television and radio channels", "\"Waiting for Guffman\"", "the first round of the 1999 NFL Draft", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "partial funding", "5% abv draught beer", "production of more of at least one good without sacrificing the production of any other good", "Chu'Tsai", "Shaun of the Dead is a 2004 British horror comedy film directed by Edgar Wright, written by Wright and Simon Pegg, and starring Pegg and Nick Frost.", "least onerous", "belfast", "Grissom, White, and Chaffee", "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores", "purple", "The Natya Shastra is the foundational treatise for classical dances of India, and this text is attributed to the ancient scholar Bharata Muni", "the sand grains cause a scrubbing noise as they rub against each other when walked on", "golf", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "belfast"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3166253376652084}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.375, 1.0, 0.06666666666666667, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.15384615384615383, 0.2857142857142857, 1.0, 0.0, 0.42857142857142855, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.18181818181818182, 0.0689655172413793, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_hotpotqa-validation-5226", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "after_eval": {"predictions": ["bat-and-ball", "that continents `` ploughed '' through the sea", "Take That", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds", "The Nightmare Before Christmas", "2003", "The Watermark business park", "apples", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "lago di Como", "Grissom, White, and Chaffee", "multinational retail corporation", "passion fruit", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "inverting a vessel over a burning candle and surrounding the vessel's neck with water resulted in some water rising into the neck", "vienna"], "metric_results": {"EM": 0.875, "QA-F1": 0.875}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5221", "before_prediction": "\"Waiting for Guffman\"", "after_prediction": "The Nightmare Before Christmas"}], "retained_ids": ["mrqa_triviaqa-validation-6905", "mrqa_squad-validation-5157", "mrqa_squad-validation-7792", "mrqa_squad-validation-6271", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913"], "fixed_ids": ["mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_hotpotqa-validation-5226", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_triviaqa-validation-4430"], "unfixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-2914", "mrqa_squad-validation-3523"], "instant_fixing_rate": 0.88, "instant_retention_rate": 0.8571428559183674}, {"timecode": 47, "before_eval": {"predictions": ["George Bush", "horseracing", "Burnley and the New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "big - name lawyers", "CGI computer animation", "when they enter the army during initial entry training", "moral tale", "hiatus and re-united two years later for the release of their fourth and final studio album, Destiny Fulfilled ( 2004 )", "leeds", "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form", "260", "Heathrow Express", "face-to-face interaction", "Sylvia F. Porter in a column for the May 4, 1951, edition of the New York Post, based on the increase in the population of the U.S. of 2,357,000 in 1950", "monophyletic", "insects", "specific catechism questions", "a pH indicator, a color marker, and a dye", "about 50% oxygen composition at standard pressure or 2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "belfast", "John and Charles Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Western Kentucky University", "daredevil driver", "appearing as Jude in the musical romance drama film \" across the Universe\" (2007)", "vegan diet", "dress to wear to the neighborhood dance", "Jocelyn Flores", "downward pressure on wages"], "metric_results": {"EM": 0.25, "QA-F1": 0.35455840455840454}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.07407407407407407, 0.0, 1.0, 1.0, 0.5, 0.5384615384615384, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "longchamp", "New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "A tree - topper or treetopper is a decorative ornament placed on the top ( or `` crown '' ) of a Christmas tree or Hanukkah bush. Tree - toppers can take any form", "260", "Heathrow Express", "Neighbourhood", "The Washington Post", "tentacles", "insects", "The hymn functioned both as a liturgical setting of the Lord's Prayer and as a means of examining candidates on specific catechism questions", "a color marker", "about 50% oxygen composition at standard pressure", "belfast", "George Whitefield", "Science and Discovery", "1 were considered a prime", "Campbellsville University", "james dean", "Jude", "m Morgan Spurlock", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "less workers are required in proportion to capital inputs, increasing unemployment (the \"reserve army of labour\") This process exerts a downward pressure on wages"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7599144276775855}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.7368421052631579, 1.0, 0.3076923076923077]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-945", "before_prediction": "horseracing", "after_prediction": "longchamp"}, {"id": "mrqa_squad-validation-2346", "before_prediction": "specific catechism questions", "after_prediction": "The hymn functioned both as a liturgical setting of the Lord's Prayer and as a means of examining candidates on specific catechism questions"}], "retained_ids": ["mrqa_hotpotqa-validation-5788", "mrqa_naturalquestions-validation-2143", "mrqa_triviaqa-validation-1256", "mrqa_squad-validation-4212", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-1609"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_hotpotqa-validation-1924", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_naturalquestions-validation-2092"], "unfixed_ids": ["mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.6666666666666666, "instant_retention_rate": 0.7499999990624999}, {"timecode": 48, "before_eval": {"predictions": ["Anthony John Herrera", "Good Kid, M.A.A,D City", "Yosemite National Park", "Interventive treatment", "3", "Lloyd Christ Wicke", "Ray Charles", "During his epic battle with Frieza", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "UNESCO", "Anfernee Simons and Thon's brother, Matur Maker, are also looking to be drafted in the NBA, with Simons being a postgraduate and Maker's decision relating to him being held back a year", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "the 1964 Republican National Convention in San Francisco, California", "every good work designed to attract God's favor is a sin", "annuity", "twin sister", "Buffalo Bill", "justice resides", "semi-independent State of Vietnam", "largely determined by President Woodrow Wilson, who had shown little interest in foreign affairs before entering the White House in 1913", "cappuccino", "halal", "Arthur Russell (born Charles Arthur Russell, Jr. May 21, 1951 and April 4, 1992) was an American cellist, composer, singer, and musician whose work spanned a disparate range of styles.", "to be memorised by the people themselves", "Wylie Draper", "political role for Islam", "the university's off- Campus rental policies", "Bobby Hull", "New England Patriots", "war, famine, and weather"], "metric_results": {"EM": 0.21875, "QA-F1": 0.37587751070613973}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8571428571428571, 0.0, 1.0, 0.22222222222222218, 0.0, 1.0, 0.06451612903225806, 0.25, 1.0, 0.0, 0.18181818181818182, 0.16666666666666669, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.2857142857142857, 0.2666666666666667, 0.4, 0.6666666666666665, 0.2, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "el Capitan", "interventive", "3", "Bishop Lloyd Christ Wicke", "wurlitzer Electric Piano", "During his epic battle with Frieza", "the director's own approved edit", "shirley Williams", "boston", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "the 1964 Republican National Convention in San Francisco, California", "sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "neutrality", "coffee", "halal", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8145833333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666665, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3967", "before_prediction": "Yosemite National Park", "after_prediction": "el Capitan"}, {"id": "mrqa_triviaqa-validation-2849", "before_prediction": "UNESCO", "after_prediction": "boston"}], "retained_ids": ["mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-1834", "mrqa_squad-validation-8248", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-4774"], "fixed_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_squad-validation-7947", "mrqa_squad-validation-264"], "unfixed_ids": ["mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-2582", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-599"], "instant_fixing_rate": 0.8, "instant_retention_rate": 0.7142857132653061}, {"timecode": 49, "before_eval": {"predictions": ["vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL", "Genghis Khan", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "Ravenna", "12", "antlophobia", "1937", "improved", "biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "he had assigned them to the company in lieu of stock", "Marxist", "variation in plants", "abortion", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "3,600", "Albany Schenectady Road", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "Hepburn", "Horakhty", "Lawton Mainor Chiles Jr.", "In the episode `` Kobol's Last Gleaming ''", "Wisconsin", "uneven", "chakula cha mchana", "energy", "Nebraska", "Ruth Elizabeth \"Bette\" Davis", "jonathan lise meitner", "2004"], "metric_results": {"EM": 0.03125, "QA-F1": 0.15052378177378178}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.0, 0.0, 0.18181818181818182, 0.15384615384615385, 0.2222222222222222, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.888888888888889, 0.0, 0.0, 0.0, 0.09523809523809525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna", "Bocelli became completely blind at the age of 12", "meat", "1895", "improved markedly", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "assigned them to the company in lieu of stock", "communist", "the common edible pea", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "My Fair Lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "forcefully", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8812506937506938}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1772"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "unfixed_ids": ["mrqa_hotpotqa-validation-1364", "mrqa_squad-validation-1459", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-9807"], "instant_fixing_rate": 0.8387096774193549, "instant_retention_rate": 0.9999999900000002}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.15375, "QA-F1": 0.26570218270118146}, "overall_error_number": 1354, "overall_instant_fixing_rate": 0.8277065613688684, "final_instream_test": {"EM": 0.663125, "QA-F1": 0.7269090154790938}, "final_upstream_test": {"EM": 0.612, "QA-F1": 0.6807532965819986}}}