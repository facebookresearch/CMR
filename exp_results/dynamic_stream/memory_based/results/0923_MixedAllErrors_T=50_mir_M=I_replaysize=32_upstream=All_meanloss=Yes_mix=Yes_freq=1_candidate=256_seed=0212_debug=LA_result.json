{"model_update_steps": 1940, "method_class": "mir", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=3e-05, local_adapt_lr=3e-05, max_grad_norm=0.1, memory_key_cache_path='na', memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=0212_debug=LA_ckpts/memory_dict.pkl', memory_store_rate=1.0, mir_debug_largestloss=False, mir_debug_reverse=False, num_adapt_epochs=3, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=0212_debug=LA_ckpts/', replay_candidate_size=256, replay_frequency=1, replay_size=32, save_all_ckpts=1, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.hidden_passes.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "French 18th-century art and furnishings", "turbine", "the adaptive immune system", "Chinghiz, Chinghis, and Chingiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "the 50 fund", "ned Sherrin", "the Mandate of Heaven", "Tar- Baby", "buddha", "Poseidon", "Washington", "2009", "the direction from which the wind is blowing", "jabs at the soft underbelly of hypocrisy, pomposity and upper class twits", "oxygen", "Georges Seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "great train robbery", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "a metaphor for a burden to be carried as penance", "power blackouts across the country"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9104166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 0.1904761904761905, 1.0, 0.8]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-7017"], "unfixed_ids": ["mrqa_squad-validation-7821", "mrqa_triviaqa-validation-1551", "mrqa_naturalquestions-validation-5465", "mrqa_naturalquestions-validation-3490", "mrqa_squad-validation-7746"], "instant_fixing_rate": 0.84375, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "philanthropy", "Catherine Zeta Jones", "Virginia Wade", "Crystal Gayle and Gary Morris", "to the anterolateral corner of the spinal cord", "1966", "radioisotope thermoelectric generator", "product or policy that is open and honest", "The Stock Market crash in New York", "New York Stadium", "norman Tebbit", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "quran", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "Charlie", "acmthompson", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "the check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.125, "QA-F1": 0.20247980505333446}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.23529411764705885, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.07407407407407407, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["The idea of breaking a container filled with treats came to Europe in the 14th century, where the name, from the Italian pignatta, was introduced", "originally designated HU - 1", "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion", "mariette", "sue Barker", "Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York led people to hoard their money ; as consumption fell, the American economy steadily contracted, 1929 - 32", "rotherham united", "john Bercow", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years before his death", "islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "numb3rs", "for gallantry", "Danny DeVito", "Galileo", "superman", "2010"], "metric_results": {"EM": 0.875, "QA-F1": 0.8940202517788725}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [0.09523809523809523, 1.0, 0.06896551724137931, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10015", "before_prediction": "philanthropy", "after_prediction": "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion"}, {"id": "mrqa_naturalquestions-validation-4684", "before_prediction": "The Stock Market crash in New York", "after_prediction": "The Stock Market crash in New York led people to hoard their money ; as consumption fell, the American economy steadily contracted, 1929 - 32"}, {"id": "mrqa_triviaqa-validation-1924", "before_prediction": "norman Tebbit", "after_prediction": "john Bercow"}], "retained_ids": ["mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_hotpotqa-validation-5899", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_squad-validation-10410", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.249999999375}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "the +, -, *, and / keys", "2009", "in different parts of the globe", "red", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "a phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "the majority of the population lives in the suburbs, rather than in the cities or in rural areas", "one of the membership who is no longer an exempt", "Bothtec", "Terry Reid", "that they are of sufficient quality", "the theme of the Variations", "North America", "Andr\u00e9 3000", "one veteran as Commander", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "the Denver Broncos", "the Western Bloc ( the United States, its NATO allies and others )", "the 1970s", "is an opera in four acts by French composer Georges Bizet", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.03125, "QA-F1": 0.17300206362706363}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.16216216216216214, 0.0, 1.0, 0.0, 0.0, 0.4, 0.4444444444444445, 0.4, 0.0, 0.0, 0.4, 0.0, 0.0, 0.3636363636363636, 0.0, 0.18181818181818182, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_squad-validation-194", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "It was never affiliated with any particular denomination", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "casket letters", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Masaharu Iwata", "Spencer Davis Group", "non-peer-reviewed sources", "enigma Variations", "physiographically a part of the continent of North America", "is a song written and produced by Andr\u00e9 3000", "Jack Swigert, and Fred Haise", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the United States", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "Pacific"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "Masaharu Iwata"}], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_squad-validation-194", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.0}, {"timecode": 3, "before_eval": {"predictions": ["id", "Four Year Plan", "Parallelogram", "between 27 July and 7 August 2022", "New York", "is getting a remake", "2006", "Least of the Great Powers", "the lower motor neurons, the efferent nerves that directly innervate muscles", "babbage", "Glacier Mints", "Dettori", "death mask", "video film", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "casket letters", "cement City, Texas", "the Democratic Unionist Party", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "control purposes", "island in the Sun", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000", "modestly and cover their breasts and genitals", "proteins", "bile duct or artery", "berenice Abbott"], "metric_results": {"EM": 0.125, "QA-F1": 0.1657691814764183}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "Staten Island", "splash", "2005\u20132010", "G20", "efferent nerves", "max bygraves", "polar bear", "lester piggott", "don't disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo starr", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museums"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9678571428571429}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-5517", "before_prediction": "over 10,000", "after_prediction": "over 10,000 British and 2,000 old master works"}], "retained_ids": ["mrqa_hotpotqa-validation-5662", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-6341"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-3058", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-6800", "mrqa_triviaqa-validation-2530"], "unfixed_ids": ["mrqa_squad-validation-1539"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.7499999981250001}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Remagen", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "month of marzo pazzerello", "the man chosen to meet God on Sinai and receive the Law on behalf of God\u2019s chosen people", "museums", "tetanus disease", "bounding the time or space used by the algorithm", "museums", "Alex O'Loughlin", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "bunker", "in the middle decade of the 19th century", "the Reverse - Flash", "All Souls'Day", "the A's", "baku", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America, and Quebec", "comprehension and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "turbines", "Splodgenessabounds"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30215773809523805}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.75, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "unmanned Saturn V flights", "Gryphon", "16 April 1898", "june", "a son of Amram and Jochebed, of the tribe of Levi", "new york city", "tetanus", "bounding", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine", "a chain or screw stoking mechanism and its drive engine or motor", "Fleet Street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "azerbaijan", "new converts", "CeCe Drake", "a batting genius or a player who has frittered away his talent", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Jonathon Dutton"], "metric_results": {"EM": 0.84375, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1277", "before_prediction": "1898", "after_prediction": "16 April 1898"}, {"id": "mrqa_squad-validation-3389", "before_prediction": "bunker", "after_prediction": "a chain or screw stoking mechanism and its drive engine or motor"}, {"id": "mrqa_triviaqa-validation-5168", "before_prediction": "cricket", "after_prediction": "a batting genius or a player who has frittered away his talent"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Jonathon Dutton"}], "retained_ids": ["mrqa_squad-validation-3126", "mrqa_squad-validation-8700"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_triviaqa-validation-5231"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.33333333277777777}, {"timecode": 5, "before_eval": {"predictions": ["june and August of 1764", "International Association of Athletics Federations", "a soft wool fabric with a colorful swirled pattern of curved shapes", "Paspahegh Indians", "is a branch of the anterior internodal tract that resides on the inner wall of the left atrium", "South Dakota", "7 : 25 a.m.", "swanee or swannee whistle", "is a genetically engineered plant", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "India", "parietal cells", "placental", "September 13, 1994", "june", "Ming dynasty", "1840", "a defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "kinks", "by using net wealth (adding up assets and subtracting debts )", "entropy", "my mind is averse to wedlock because I daily expect the death of a heretic", "8.7 -- 9.2", "China", "2 November 1902", "present - day southeastern Texas", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "a way of housing a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.09375, "QA-F1": 0.15721319229446165}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.13333333333333333, 0.0, 0.47058823529411764, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "heart", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "bury their dead", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotreme", "Ready to Die", "president garfield", "imperial rule", "1787", "allocution", "Mark Twain", "sunny afternoon", "the methodology used", "nonconservative forces", "the death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9583333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-484", "before_prediction": "September 13, 1994", "after_prediction": "Ready to Die"}], "retained_ids": ["mrqa_hotpotqa-validation-2197", "mrqa_hotpotqa-validation-1718"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_triviaqa-validation-5704", "mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 6, "before_eval": {"predictions": ["zinnemann", "the draft carries more air ( oxygen ) past the flame", "Barack Hussein Obama II", "1998", "n Carolina", "mustard", "90-60's", "independent schools", "dolph Camilli", "the times sign or the dimension sign", "BAFTA Television Award", "Juice Newton", "1960", "HTTP Secure ( HTTPS )", "late summer", "kansas", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "june", "mustard", "mothflies", "universal", "left coronary artery", "1.1 \u00d7 1011 metric tonnes", "clangers", "leaf tissue", "Indian club ATK", "the amount of land that a nation has conquered and expanded", "near Grande Comore, Comoros Islands", "rupees 10 lakhs", "Norwegian", "burning of fossil fuels"], "metric_results": {"EM": 0.09375, "QA-F1": 0.16335565476190478}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.28571428571428575, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film directors", "capillary action", "2008", "2010", "north carolina", "minorca", "70", "an aided or an unaided school", "boston braves", "the symbol \u00d7", "Best Supporting Actress", "Emily Blunt", "Super Bowl LII,", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "wichita", "simplest", "beaches", "japan", "true", "red admiral", "o", "left coronary artery", "10 percent of the carbon stores in ecosystems", "buttermere", "leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9289772727272727}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6947", "before_prediction": "independent schools", "after_prediction": "an aided or an unaided school"}, {"id": "mrqa_naturalquestions-validation-1618", "before_prediction": "Juice Newton", "after_prediction": "Emily Blunt"}], "retained_ids": ["mrqa_naturalquestions-validation-5582"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "unfixed_ids": ["mrqa_squad-validation-4181"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.3333333322222222}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules, such as squalene and the carotenes", "The U.S. Army Chaplain insignia", "Kairi", "both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who want more services and more control over the central city", "film year 1945", "Armenia", "the last book accepted into the Christian biblical canon", "Bruno Mars", "% IACS", "for gallantry", "16 million", "1950s", "work oxen for haulage", "1998", "Jeff Brannigan", "23.1", "18 - season career", "family member", "long-term environmental changes", "Learjet", "the radial (centripetal ) force", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner ( 1749 -- 1817 )", "casket letters", "present-day Charleston", "taking a \"quiescent\" stance towards Israel, focusing on preaching, education and social services, and benefiting from Israel's \"indulgence\" to build up a network of mosques and charitable organizations", "Scott Dunlop", "XIX Corps"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18770667989417988}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.19999999999999998, 0.0, 0.25, 0.0, 0.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.07407407407407407, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "a few", "the right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "lost weekend", "near the Black Sea", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george vi", "the most popular show at the time", "post\u2013World War II", "as work oxen for haulage", "2011", "a priest", "most abundant", "2001", "family member", "long-term environmental changes", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george I", "the Charleston Orange district", "quiescent", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9921875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_squad-validation-1863", "mrqa_squad-validation-4318"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_squad-validation-6297", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_hotpotqa-validation-3898", "mrqa_squad-validation-358", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-3558", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3146"], "unfixed_ids": ["mrqa_naturalquestions-validation-98"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.9999999966666667}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "guseppe Antonio 'Nino'Farina", "50", "6.4 nanometers apart", "will be departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Carl Michael Edwards II", "400 games", "endocrine system", "Latin liberalia studia", "Bowland Fells", "the Lord Protector : Richard, Duke of Gloucester", "St. Louis County, Missouri, United States, 17 mi southwest of St. Lawrence and 2 mi east of Eureka", "1868", "2018", "a professional association football club based in the city Sheffield, South Yorkshire, England", "law firm", "Pottawatomie County", "orangutan", "theory of general relativity (GR )", "The church tower", "EastEnders star Danny Dyer", "Toronto, Ontario, Canada", "foreigner", "110 miles (177 km ) from the East River in New York City, along the North Shore of Long Island, to the south", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six degrees of freedom", "not guilty", "psychotherapeutic theories", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York", "acidic bogs"], "metric_results": {"EM": 0.09375, "QA-F1": 0.27156824352548037}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.2, 0.10526315789473684, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.2666666666666667, 0.5, 0.4444444444444445, 0.4, 0.0, 0.0, 0.25, 0.6666666666666666]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "after_eval": {"predictions": ["computability theory", "formula one", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidney", "artes liberales", "\"Switzerland of England\"", "Edward IV of England", "Eureka", "1828", "2018", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "theory of general relativity", "The church tower", "walford east", "Montreal", "slow", "110 miles", "Kona coast", "liberal conservative", "gold rush", "six", "no contest", "freud", "New York", "acidic"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9959239130434783}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-6991", "mrqa_squad-validation-10369", "mrqa_squad-validation-5313"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_hotpotqa-validation-5513", "mrqa_hotpotqa-validation-3789", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-187"], "unfixed_ids": ["mrqa_naturalquestions-validation-856"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.9999999966666667}, {"timecode": 9, "before_eval": {"predictions": ["I Seek You", "Argentinian", "Ear Institute at the University College London, and Widex, a Danish hearing aid manufacturer", "but not actually find the right pan", "reduces the efficiency of photosynthesis", "to celebrate Queen Victoria's diamond jubilee", "butterm governor", "The Daily Stormer", "triplet", "water", "The president", "the citizens", "George, Margrave of Brandenburg-Ansbach", "Kamba version", "3D computer-animated comedy film", "Bloomingdale Firehouse", "acting", "C. W. Grafton", "LED illuminated display", "Americans acting under orders", "iPod Classic", "is a South Korean actress", "prevent damage to the body", "The Edge of Night", "non-combustible substances that corrode, such as iron", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "the root respiration", "organic carbon", "freooth Sailing", "medium and heavy- Duty diesel trucks", "testes"], "metric_results": {"EM": 0.21875, "QA-F1": 0.31949925074925073}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentinian", "a report", "cake", "consumes ATP and oxygen, releases CO2, and produces no sugar", "images of different animals and humans performimg various actions", "White House", "The Daily Stormer", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "almost all officeholders annually", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "Worcester Cold Storage and Warehouse Co. fire", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( LCoS ) ( based on an LCo S chip from Himax ), field - sequential color system, LED illuminated display", "a British soldier", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP", "soil", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9349662162162162}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4520", "before_prediction": "the citizens", "after_prediction": "almost all officeholders annually"}, {"id": "mrqa_naturalquestions-validation-1327", "before_prediction": "Americans acting under orders", "after_prediction": "a British soldier"}], "retained_ids": ["mrqa_hotpotqa-validation-832", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-133", "mrqa_squad-validation-5940"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_naturalquestions-validation-754"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.7142857132653061}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744)", "yellow fever", "three legal systems", "Las Vegas", "optional message body", "globetrotters", "cruiserweight", "a bridge over the Merderet in the fictional town of Ramelle", "a revolver", "cake", "menhirs", "Prince and Princess Michael of Kent", "aqueous solution", "Kon-Tiki", "a special Las Vegas concert", "digital fashion gallery", "C. J. Anderson", "all-encompassing", "numb W. Boggs", "60", "Eagle Ridge Mall", "Geoffrey Hurst and Martin Peters just one season before all three went on to star in England's World Cup winning side of 1966", "reduce pressure on the public food supply", "Monastir", "the classical element fire", "Barney Fife's girlfriend", "at least 18 or 21 years old ( or have a legal guardian present )", "Sela Ward", "poet", "James Fort", "Monet", "tree growth"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3090277777777778}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.5, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.9333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["alexander", "Hampton's hump and Hampton's line", "Northern Ireland law", "Las Vegas", "A status line", "the best known globetrotters", "cruiserweight title", "over the Merderet in the fictional town of Ramelle", "mussolini", "victor hugo", "dolmen", "British Royal Family", "greater than 14", "thor heyerdahl", "Grand Garden Special Events Center", "valentino", "C. J. Anderson", "a maze of semantical problems and grammatical niceties", "joseph smith", "more than 60 percent of the state's total land surface", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "tunisia", "the classical element fire", "Barney Fife", "Typically, no", "Ann", "writer", "Virginia", "monet", "carbon related emissions"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9333333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2016", "before_prediction": "cruiserweight", "after_prediction": "cruiserweight title"}, {"id": "mrqa_triviaqa-validation-4791", "before_prediction": "menhirs", "after_prediction": "dolmen"}, {"id": "mrqa_squad-validation-3018", "before_prediction": "60", "after_prediction": "more than 60 percent of the state's total land surface"}], "retained_ids": ["mrqa_hotpotqa-validation-132", "mrqa_squad-validation-273", "mrqa_squad-validation-3525", "mrqa_triviaqa-validation-6639"], "fixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.571428570612245}, {"timecode": 11, "before_eval": {"predictions": ["1967", "Traumnovelle", "a Gender pay gap in favor of males in the labor market", "The TEU", "absolute zero", "a father, Paul Monti, whose son, Medal of Honor recipient Jared, was killed in Afghanistan while trying to save a fellow soldier", "victor hugo", "The world's longest suspension bridges are listed according to the length of their main span", "trams", "handguns", "catfood", "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "coket", "tunisia", "Dyess", "North American Free Trade Agreement ( NAFTA )", "Queen Elizabeth I", "infections", "the most - visited paid monument in the world", "the Vittorio Emanuele II Gallery and Piazza della Scala in a pedestrian area in the centre of the city", "catfish aquaculture", "at standard conditions that sublimes readily to form a violet gas", "Andy Allo, Venzella Joy Williams, and Hannah Fairlight as Calamity, Serenity, Charity, and Veracity", "Iraq", "a co-op of grape growers", "victor willsmeron", "juneppe Verdi", "1952", "Los Angeles Lakers", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "the back of the head"], "metric_results": {"EM": 0.125, "QA-F1": 0.21357787584904292}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.31578947368421056, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.08695652173913043, 0.22222222222222224, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "eat porridge", "span", "dublin", "duke of edinburgh", "king Crimson", "the Seljuk Turks", "alamo", "ferdinand porsche", "arkansas", "Canada", "britten", "irritation", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "heaviest of the stable halogens", "Evermoist", "kuw", "An agricultural cooperative", "norway", "verdi", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean Fernel", "body hair transplantation ( BHT ) on appropriate candidates who have available donor hair on the chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9717261904761905}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6442", "before_prediction": "the back of the head", "after_prediction": "body hair transplantation ( BHT ) on appropriate candidates who have available donor hair on the chest, back, shoulders, torso and / or legs"}], "retained_ids": ["mrqa_hotpotqa-validation-2852", "mrqa_squad-validation-1003", "mrqa_hotpotqa-validation-4274"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_triviaqa-validation-7703", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7499999981250001}, {"timecode": 12, "before_eval": {"predictions": ["Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Joe Turano", "fencers", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2014", "The stability, security, and predictability of British law and government", "Minoan or Mykenaian age", "29 June 1941", "ferrey", "byker grove", "Forbes", "the French", "dandy", "eata", "Orwell", "Czech Kingdom", "Gregg Popovich", "that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "the innate immune system", "under the tutelage of his uncle Juan Nepomuceno Guerra", "a musician", "ferdinand", "December 1, 1969", "american", "alexander", "The two AAA Auto Clubs of the state, the California State Automobile Association and the Automobile Club of Southern California", "\"alone\"", "Cinderella", "delayed the sealing of the hatch", "a fear of seeming rude"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29730405187061537}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.19999999999999998, 0.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.23529411764705882, 0.4, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.47058823529411764]}}, "error_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "fencing", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cuban cigars", "byker", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "rings", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \" Regnum Bohemia\"", "Bob Hill", "secularism", "creative reasons", "immunological memory", "uncle", "Originally a musician", "thumbelina", "1973", "maryland", "john buchan", "regional tourism groups", "\"alone\"", "Cinderella", "delayed the sealing of the hatch", "lack of understanding of the legal ramifications"], "metric_results": {"EM": 0.9375, "QA-F1": 0.967948717948718}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6902", "before_prediction": "byker grove", "after_prediction": "byker"}, {"id": "mrqa_hotpotqa-validation-4904", "before_prediction": "Czech Kingdom", "after_prediction": "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \" Regnum Bohemia\""}], "retained_ids": ["mrqa_hotpotqa-validation-4826", "mrqa_squad-validation-2372", "mrqa_hotpotqa-validation-4165", "mrqa_squad-validation-3935"], "fixed_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-6924"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.6666666655555555}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "former president of Guggenheim Partners", "Jason Lee", "Napoleon", "baking", "3.7 percent of the entire student population", "high and persistent unemployment, in which inequality increases", "Garthy", "Tenacious D", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni", "discipline problems with the Flight Director's orders", "maryland", "paddington", "amyotrophic lateral sclerosis", "a gimmick called \"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "Swiss made", "October 17, 1938", "Torah or Bible", "the western coast of Italy", "the first and only U.S. born world grand prix champion", "a jazz funeral without a body", "in mid November and lit in a public ceremony in late November or early December", "Facebook", "mohnbeugel", "a tribute band singer whose ascendance to the position of lead vocalist of his favorite band was inspired by the real-life story of Tim \"Ripper\" Owens, singer in a Judas Priest tribute band", "Issaquah, Washington (a suburb of Seattle)", "Treaty of Aix-la-Chapelle", "Jackson pretends to be Rico's father for two - thousand dollars so he can get money to see Siena modeling in Peru", "alternative rock", "Fort Snelling, Minnesota", "a pinhole camera", "infrequent rain and many sunny days"], "metric_results": {"EM": 0.125, "QA-F1": 0.23609642596073516}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.4444444444444445, 0.5, 0.0, 0.0, 0.0, 0.1111111111111111, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5263157894736842, 1.0, 0.0, 0.1875, 0.33333333333333337, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.5]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "sliced bread", "3.7 percent of the entire student population", "negative", "garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "nine", "michael hordern", "Lou Gehrig's Disease", "\"Odorama\"", "Swiss made", "Evel Knievel craze of the mid 1970s", "religious", "Sicily", "American-born", "The second line's style of traditional dance, in which participants walk and sometimes twirl a parasol or handkerchief in the air", "late November or early December", "Facebook", "bread", "Tim \"Ripper\" Owens", "Issaquah", "King George's War", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "henry fox talbot", "infrequent rain"], "metric_results": {"EM": 0.875, "QA-F1": 0.907967032967033}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-2037", "before_prediction": "October 17, 1938", "after_prediction": "Evel Knievel craze of the mid 1970s"}], "retained_ids": ["mrqa_hotpotqa-validation-1178", "mrqa_triviaqa-validation-2779", "mrqa_naturalquestions-validation-7310"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913", "mrqa_squad-validation-2656"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-7042", "mrqa_naturalquestions-validation-9897"], "instant_fixing_rate": 0.8928571428571429, "instant_retention_rate": 0.7499999981250001}, {"timecode": 14, "before_eval": {"predictions": ["a 2002 Hong Kong comedy film", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP.", "Chicago's first permanent non-native settler", "rother qc", "FX option", "electromagnetic waves", "a Wahhabi/ Salafi", "auspiciousness", "Dimensions in Time", "Surveyor 3 unmanned lunar probe", "January 1981", "lutein - releasing hormone ( GnRH )", "a hymnic setting of Psalm 67's prayer for grace", "a Lutheran pastor in Hochfelden used a sermon to urge his parishioners to murder Jews", "England's first \u00a31 million player", "slowing the vehicle", "Cheyenne rivers", "fossils in sedimentary rocks", "Hanna- Barbera, The Jetsons", "\"comune\"", "the efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "Death is the anthropomorphic personification of death on the Discworld", "maryland", "Kur\u00e1nyi", "the state sector", "1940", "poverty, the lack of access to education and weak government institutions", "a god of the Ammonites", "eye", "Uncle Fester, also known as Fester Addams", "the homicidal sniper Bobby Thompson"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22284663865546217}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false], "QA-F1": [0.5714285714285715, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.4, 0.5882352941176471, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575]}}, "error_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "a Wahhabi/ Salafi extremist extremist militant group", "tetraskelion (Swastika)", "Children in Need", "Apollo 12", "1981", "estrogen", "baptism", "that priest whose name was Martin Luther", "brian clough", "releasing the compressed air trapped in the cylinders, and slowing the vehicle", "belle fourche and Cheyenne", "organisms", "Hanna-Barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Timo Hildebrand", "public sector ( also called the state sector )", "February", "poverty", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8986742424242424}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-727", "before_prediction": "slowing the vehicle", "after_prediction": "releasing the compressed air trapped in the cylinders, and slowing the vehicle"}, {"id": "mrqa_hotpotqa-validation-5191", "before_prediction": "Kur\u00e1nyi", "after_prediction": "Timo Hildebrand"}, {"id": "mrqa_squad-validation-8444", "before_prediction": "poverty, the lack of access to education and weak government institutions", "after_prediction": "poverty"}], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": ["mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.0}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Part 2", "the Flatbush section of Brooklyn, New York City", "San Antonio", "Proof", "vitius ptolemy", "a friend and publicist", "l\u00e1szl\u00f3 de Alm\u00e1sy", "masons'marks", "17", "Gateshead", "It Ain't Over'til It's Over '' is a song recorded, written, and produced by American musician Lenny Kravitz", "The neck", "1898", "a former amateur wrestler", "Payaya Indians", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "vito corleone", "Curtiss jN-4", "art", "chimpanzees", "March 15, 1945", "absolute temperature", "Stratfor", "Sam Waterston", "a unique aspect of the buccal cusp of the first premolar", "his brother, Menelaus", "25 November 2015", "tallahassee", "prefabricated housing projects", "a number of British new agencies such as D.C Thomas & Co, Commonwealth Broadcasting Associatio", "WOTV"], "metric_results": {"EM": 0.125, "QA-F1": 0.1375}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Royce da 5'9\" (Bad) and Eminem (Evil)", "galileo", "editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "roof", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "after the Spanish -- American War in the 1898 Treaty of Paris", "martial artist", "Spanish", "stunt performances", "fred astaire", "postage stamp", "belgium", "chimpanzees", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolar teeth", "Aegisthus", "3 December", "florida", "an Eastern Bloc city", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.96875, "QA-F1": 0.975}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-3808", "before_prediction": "1898", "after_prediction": "after the Spanish -- American War in the 1898 Treaty of Paris"}], "retained_ids": ["mrqa_hotpotqa-validation-3456", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2957"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451", "mrqa_hotpotqa-validation-413", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7499999981250001}, {"timecode": 16, "before_eval": {"predictions": ["Georges", "bruder Basil", "benedict", "on the lateral side of the tibia", "cen\u00e9l n Gabr\u00e1in of D\u00e1l Riata", "the North Sea, through the former Meuse estuary, near Rotterdam", "bantu", "Colin Montgomerie", "October 29, 1985", "Amway", "Mauritius", "Thomas Sowell", "Speaker of the Lok Sabha or in his absence, the Deputy - Chairman of the Rajya Sabha", "Golden Globe Award", "galileo", "Chad", "florida", "an open work crown", "Crowley brought back Samuel so that they could help him find Purgatory, the afterlife of monsters", "London", "French", "galileo", "U.S. Marshals", "What's Up (TV series)", "blood", "galileo", "Stanislaw August Poniatowski", "polynomial algebra", "Michael J. Fox", "three mystic apes", "sheepskin and Merino Wool products", "Honolulu"], "metric_results": {"EM": 0.03125, "QA-F1": 0.11127344877344877}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.09090909090909091, 1.0, 0.4, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.21428571428571425, 0.33333333333333337, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "after_eval": {"predictions": ["a St. Tropez drag-show nightclub", "belgian", "blessed", "leg", "house of d\u00e1l n Gabr\u00e1in of D\u00e1l Riata", "North Sea", "Botswana", "naldo", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio's \"The Show Band Show\"", "tanganyika and zanzibar", "niger", "60mil", "top row of windows", "Sam's soul is not with him", "Fulham, Greater London, England", "French, English and Spanish", "dave lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "flowing water", "polish state", "matrices", "Michael J. Fox", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "Sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.75, "QA-F1": 0.8381798756798757}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307692, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4164", "before_prediction": "London", "after_prediction": "Fulham, Greater London, England"}], "retained_ids": [], "fixed_ids": ["mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-2445", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "unfixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-4681", "mrqa_triviaqa-validation-4055", "mrqa_naturalquestions-validation-7144", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.7741935483870968, "instant_retention_rate": 0.0}, {"timecode": 17, "before_eval": {"predictions": ["belgian", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "stable, non-radioactive rubidium - 85", "James Zeebo", "state system", "president of the United States Senate", "the pseudoscientific principle of intelligent design (ID)", "Major William Lennox and Master Sergeant Robert Epps", "Australian", "36 months for men and 24 months for women", "opportunities will vary by geographic area and subject taught", "lower", "a private liberal arts college", "Roy Spencer", "\"antiforms\"", "second half of the third season", "\"Veyyil\" (2006)", "James Weldon Johnson", "Keith Richards", "at least one prime number p with n < p < 2n \u2212 2", "Bangor International Airport", "knowledgeable in that one area", "180th meridian in a 360 \u00b0 - system", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat", "33", "dactylosphaera vitifoliae", "Annual Conference Cabinet", "clangers", "first prompted by original star William Hartnell's poor health"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4207209967320261}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 1.0, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.23529411764705882, 0.25, 0.33333333333333337, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_squad-validation-2053", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845", "rubidium - 85", "James Zeebo", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "dick cheney", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Velichko Todorov Tsochev) is a Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower", "575 acres (2.08 km\u00b2)", "Roy Spencer", "\"antiforms\"", "the fifth and sixth seasons", "Veyyil", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Adult Swim", "Presiding Officer", "the Phoenix Suns", "33-member", "vitis", "the Area Provost/ Dean (if one is appointed) and the several District Superintendents of the Districts of the Annual Conference", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.875, "QA-F1": 0.9106487148102815}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.9302325581395349, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5787", "before_prediction": "second half of the third season", "after_prediction": "the fifth and sixth seasons"}, {"id": "mrqa_hotpotqa-validation-3573", "before_prediction": "Cartoon Network", "after_prediction": "Adult Swim"}, {"id": "mrqa_squad-validation-10074", "before_prediction": "Annual Conference Cabinet", "after_prediction": "the Area Provost/ Dean (if one is appointed) and the several District Superintendents of the Districts of the Annual Conference"}], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-4868"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_squad-validation-2053", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559"], "instant_fixing_rate": 0.9545454545454546, "instant_retention_rate": 0.6999999992999999}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "social networking support", "400 metres relay", "Vili Fualaau and Mary Kay Letourneau", "the entertainment division", "curved path", "12", "Great Exhibition of 1851", "King Edward I to Henry VIII", "chagos Archipelago", "museum and heritage centre", "those at the bottom of the economic government", "casket letters", "\"Grindhouse\" fake trailer", "nena davenport", "digital transmission", "Swiss- Austrian border", "Tesla Gigafactory 1", "821", "Sky channels", "vitis", "Kim Hyun-ah", "the races of highest'social efficiency'", "interval relationships", "the \" King of Cool\"", "President Wilson and the American delegation from the Paris Peace Conference", "ring of thrones", "the fifth season", "dave dors", "Hockey Club Davos", "Robin Hawdon", "a lightning strike"], "metric_results": {"EM": 0.0625, "QA-F1": 0.1693452380952381}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.2, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666665, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "harmoniously", "500 metres", "Piper", "ABC News", "displacement", "five", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "diego garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay", "Spy Kids", "venus Williams", "MFSK", "Baden-W\u00fcrttemberg", "lithium-ion battery", "821", "the basic channels", "pressure", "Hyuna", "the races of highest'social efficiency\"", "transposed", "the \" King of Cool\"", "American delegation from the Paris Peace Conference", "socrates", "thirteenth", "violet", "HC Davos", "Michael Patrick Smith", "Qutab Ud - Din - Aibak"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-4068"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-2683", "mrqa_hotpotqa-validation-2201", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "unfixed_ids": ["mrqa_squad-validation-9841"], "instant_fixing_rate": 0.9666666666666667, "instant_retention_rate": 0.999999995}, {"timecode": 19, "before_eval": {"predictions": ["Mauritian", "director Norman Macdonnell and writer John Meston", "zaragoza", "11.1", "trans-Pacific flight from the United States to Australia", "Sharman Joshi", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "a divisor of p \u2212 1", "Ana", "White Castle in New Brunswick", "In `` Fun Run ''", "numbus", "venus", "a 1993 American comedy - drama film directed by Fred Schepisi", "blackstar", "Indian", "piety", "1889", "Nicki Minaj", "comic opera", "Huguenot", "principality", "geb. Von Haar", "Tara Lyn Charendoff", "William the Conqueror", "Tel Aviv", "two", "the Corinthian and Saronic Gulfs", "phlebotomists", "the Guinness World Records", "Southern Progress Corporation"], "metric_results": {"EM": 0.28125, "QA-F1": 0.330546418128655}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, true], "QA-F1": [0.0, 0.4444444444444445, 1.0, 0.0, 0.4444444444444445, 0.0, 0.10526315789473684, 1.0, 0.3333333333333333, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "karlagoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "david bowie", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "In 1889, following the Local Government Act 1888", "Sir Mix - a-Lot", "pirates of penzance", "surnames", "portier", "karl marx", "Teen Titans Go!", "Norman invaders", "Tel Aviv", "two", "peninsula", "taking blood", "youngest TV director ever", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.875, "QA-F1": 0.8989109848484849}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6901", "before_prediction": "zaragoza", "after_prediction": "karlagoza"}, {"id": "mrqa_naturalquestions-validation-5017", "before_prediction": "piety", "after_prediction": "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord"}, {"id": "mrqa_naturalquestions-validation-4951", "before_prediction": "1889", "after_prediction": "In 1889, following the Local Government Act 1888"}, {"id": "mrqa_hotpotqa-validation-2627", "before_prediction": "Southern Progress Corporation", "after_prediction": "Sunset Publishing Corporation"}], "retained_ids": ["mrqa_squad-validation-5538", "mrqa_hotpotqa-validation-5710", "mrqa_hotpotqa-validation-3049", "mrqa_hotpotqa-validation-5061", "mrqa_naturalquestions-validation-7881"], "fixed_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_hotpotqa-validation-2389", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.5555555549382716}, {"timecode": 20, "before_eval": {"predictions": ["reciprocating", "Michael Koman", "the Sackler Centre for arts education", "is an American hip hop recording artist, actor and activist", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "Mercury/Gemini veteran Wally Schirra, Eisele, and rookie Walter Cunningham", "ribosomal", "kookaburra", "six", "Scott Bakula as Dwayne `` King '' Cassius Pride, NCIS Supervisory Special Agent", "I Swear", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak ( Bulgarian : \u043a\u043e\u0437\u0443\u043d\u0430\u043a, Bulgarian pronunciation ) )", "alowed Gerry Adams to become the first Sinn Fein MP for 2007", "a lunar radiation environment experiment", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe nomination", "Swahili", "trust God's word", "w Faulkner", "Pantone Matching System (PMS)", "Qutab - ud - din Aibak", "\"My Love from the Star\" (2013)", "San Jose Marriott", "sea wasp", "the Hawai\u02bbi House of Representatives", "a \"teleforce\" weapon", "Thunderbird of Native American tradition", "giving Super Bowl ever", "female householder", "b.J. Hunnicutt"], "metric_results": {"EM": 0.1875, "QA-F1": 0.3569269272394272}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.48484848484848486, 0.19999999999999998, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.7499999999999999, 0.3076923076923077, 0.0, 1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.888888888888889, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-8464", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "prints and architectural drawings", "Mos Def", "Sir David Brewster", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Eisele", "Ribosomes", "kookaburra", "six-time", "Vanessa Ferlito", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "gerry adams", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "Kenya's various ethnic groups typically speak their mother tongues within their own communities", "trust God's word", "turkey", "CMYKOG process", "Firoz Shah Tughlaq", "Reunited Worlds", "Santa Clara", "jellyfish", "lower chamber", "a \"teleforce\" weapon", "Native American", "the most giving Super Bowl ever", "29.7%", "4077th MASH"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5091", "before_prediction": "kaleidoscope", "after_prediction": "Sir David Brewster"}, {"id": "mrqa_naturalquestions-validation-10509", "before_prediction": "Qutab - ud - din Aibak", "after_prediction": "Firoz Shah Tughlaq"}], "retained_ids": ["mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-2407", "mrqa_squad-validation-2280", "mrqa_squad-validation-1521"], "fixed_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-8464", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.6666666655555555}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier", "various registries", "William Harvey", "Yazoo", "1894", "black hole", "\"the soul does not sleep (anima non sic dormit) but wakes (sed vigilat) and experiences visions", "cede the former", "Willie Nelson and Kris Kristofferson", "ill. (some col.)", "Claremont Colleges (Claremont McKenna College, Harvey Mudd College, Pitzer College, Pomona College, and Scripps College)", "French pirate", "Lewis", "Charles Dickens and Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues", "carbohydrates", "2001", "exceeds any given number", "30-minute", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1969", "hulder", "in western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox Christians", "first edition", "4 in ( 10 cm )", "fillies", "eating both fish larvae and small crustaceans", "\"Menace II Society\"", "quarterback", "trio"], "metric_results": {"EM": 0.15625, "QA-F1": 0.255186522525677}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.6399999999999999, 0.0, 1.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.0, 0.43750000000000006, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.25, 0.2222222222222222]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-3627", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "blood transfusion", "alison moyet", "1926", "black hole", "dreams", "value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings, Kris Kristofferson", "auction", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "a forum in which the Nobel Peace Laureates and the Peace Laureate Organizations could come together to address global issues", "proteins", "2001", "there must be infinitely many primes", "alastair burnet", "padlocking the gates", "1969", "R\u00e5", "tribes in western portions of the Great Lakes region", "Protestant", "casino royale", "4 in", "oh so Sharp", "ctenophore Mnemiopsis leidyi", "\"Menace II Society\"", "a member of the Green Bay Packers, serving as a backup quarterback to Brett Favre and holder on placekicks", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.90625, "QA-F1": 0.95125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6399999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9020", "before_prediction": "exceeds any given number", "after_prediction": "there must be infinitely many primes"}], "retained_ids": ["mrqa_triviaqa-validation-192", "mrqa_naturalquestions-validation-5897", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_squad-validation-5345", "mrqa_squad-validation-3627", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-35"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.7999999984}, {"timecode": 22, "before_eval": {"predictions": ["Alex Skuby", "England", "Thursday in May", "MSC Crociere S. p.A.", "john mary mary qc", "Humpty Dumpty and Kitty Softpaws", "Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres", "Royalists", "cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "memento, homo, quia pulvis es, et in pulverem reverteris", "bond girl", "michael Strogoff", "Augustus Waters", "1619", "Tony Blair: The Journey", "gambling", "June 11, 1973", "Kenya", "Timeline of Shakespeare criticism", "maryland", "an active supporter of the League of Nations", "Cargill", "AMC Theatres", "The Gang", "3 October 1990", "March 1, 2018", "The weak force", "daedalus", "Martin Luther King Jr.", "Manhattan Project", "the imaginary county of Barsetshire", "vast"], "metric_results": {"EM": 0.09375, "QA-F1": 0.23765950144626613}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.5714285714285715, 0.0, 0.33333333333333337, 0.11764705882352942, 0.07692307692307691, 0.0, 0.0, 0.3636363636363636, 1.0, 0.8, 0.0, 0.0, 0.0, 0.22222222222222224, 0.0, 0.1818181818181818, 0.0, 1.0, 0.0, 0.2, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.6666666666666666]}}, "error_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_naturalquestions-validation-1328", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Kitty Softpaws", "Nationals", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "Remember that you are dust, and to dust you shall return", "smert shpionam", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "14 September 1547", "tony blair", "often damaging", "July 26, 1959", "national parks", "chronological collection of critical quotations", "edward ii", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "pig", "Dexter", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9419642857142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3944", "before_prediction": "1619", "after_prediction": "14 September 1547"}], "retained_ids": ["mrqa_hotpotqa-validation-803", "mrqa_squad-validation-10459"], "fixed_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_triviaqa-validation-1578", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_triviaqa-validation-4731", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-190", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929", "mrqa_naturalquestions-validation-1328", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "unfixed_ids": ["mrqa_naturalquestions-validation-4556"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion", "mono", "about two-thirds the size of cytoplasmic ribosomes (around 17 nm vs 25 nm)", "1937 Austin Seven Ruby Open Top Tourer", "katey Miller", "red lead primer and a lead - based topcoat", "Dreamland (amusement park)", "animated film", "European Union institutions", "American record for the most time in space (381.6 days)", "nine", "CAL IPSO satellite", "sanguinarine", "Ulbricht", "Ronnie Schell", "sesquiterpene lactone", "Mumbai, Maharashtra", "east", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "possibly 1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "southern part of Nigeria", "samedi", "Incudomalleolar joint", "bobby riggs", "Leucippus", "Santa Clara Marriott", "benjamin barenboim", "political power", "log-space reductions", "Corey Brown"], "metric_results": {"EM": 0.1875, "QA-F1": 0.35544056637806637}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.2857142857142857, 0.4444444444444445, 0.0, 0.25, 0.4, 0.25, 0.25, 0.3636363636363636, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.3636363636363636, 0.6666666666666666, 0.0, 0.2, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "after_eval": {"predictions": ["$105 billion", "mononucleosis", "17 nm vs 25 nm", "a 1934 Austin seven box saloon", "dirty dancing", "red", "Steeplechase Park", "Academy Award for Best Animated Feature", "member states", "381.6 days", "nine", "NASA", "yellow", "Khrushchev", "Jack Cassidy", "malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "till September", "live and let die", "Incudomalleolar joint ( more correctly called incudomallear joint )", "moffitt", "Leucippus", "Santa Clara Marriott", "Var. II", "the use of political power generated by wealth by certain groups to shape government policies", "the bound on the complexity of reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.84375, "QA-F1": 0.9216469482529854}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 0.0, 0.5263157894736842, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7481", "before_prediction": "political power", "after_prediction": "the use of political power generated by wealth by certain groups to shape government policies"}], "retained_ids": ["mrqa_squad-validation-7389", "mrqa_squad-validation-542", "mrqa_naturalquestions-validation-4048", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-327"], "fixed_ids": ["mrqa_triviaqa-validation-3716", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_triviaqa-validation-3420", "mrqa_squad-validation-1750", "mrqa_squad-validation-769"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-6781"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8333333319444445}, {"timecode": 24, "before_eval": {"predictions": ["the 1965 -- 66 season", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "the Duke of Cumberland", "elixir", "WBC and lineal titles", "moluccas", "the post position draw for the Kentucky Derby and Preakness Stakes", "Cordelia", "multilateral negotiations", "1990", "J.R. R. Tolkien", "John Elway", "Selena Gomez", "learn a trade such as tailoring, carpentry, motor vehicle repair, brick-laying and masonry", "bingo", "Eugene", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "primes of the form 2p + 1 with p prime", "letter series", "Fa Ze", "nine circles of Hell", "two Mongols and a Muslim", "from Nova Scotia and Newfoundland in the north, to Georgia in the south", "Friars Minor (O.F.M)", "CD Castell\u00f3n", "1789, or 1798", "12\u20134", "having colloblasts", "Jon M. Chu", "STS-51-L.", "cloudiness", "prime minister of France"], "metric_results": {"EM": 0.1875, "QA-F1": 0.28492445054945054}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false], "QA-F1": [0.0, 0.07692307692307693, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.7692307692307693, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-5399", "mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+ though sometimes they can flow back down more H+-pumping electron transport chains to transport more hydrogen ions into the thylakoid space to generate more ATP", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Albany", "multilateral negotiations", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic", "31", "He is from Pago Pago, American Samoa and played college football at Oregon.", "comparable to the seven Wonders of the World", "2p + 1 with p prime", "coupe", "FaZe Rug", "dante alighieri", "Muslim", "along the coast, the settlements were growing into the interior", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-C.", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.875, "QA-F1": 0.9239495136011528}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1814", "before_prediction": "STS-51-L.", "after_prediction": "STS-51-C."}], "retained_ids": ["mrqa_squad-validation-10261", "mrqa_squad-validation-3741", "mrqa_squad-validation-384", "mrqa_squad-validation-67", "mrqa_squad-validation-4417"], "fixed_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-5399", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_squad-validation-8876", "mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.8333333319444445}, {"timecode": 25, "before_eval": {"predictions": ["swimming", "slave girl", "over 50 million singles", "secessionists of the Confederate States, who advocated for states'rights to expand slavery", "between 1923 and 1925", "Metropolitan Statistical Area", "January 19, 1962", "Frigate", "super-villain Lex Luthor", "d'Hondt method", "belcon geese", "the move from the manufacturing sector to the service sector", "jagera", "Sylvester McCoy", "August 14, 1848", "lower rate of economic growth when human capital is neglected for high-end consumption", "juveniles", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "A Chorus Line", "2,664 rooms and 220 suites", "a specific weak point on the inside of the chassis right beneath the volume buttons", "a chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning, catering and security porterage", "Symphony No. 7 in A major, Op. 92", "25 miles (72 kilometers)", "1603", "above the two personal physicians of the Emperor", "sugar Plum Fairy", "make amends to such people wherever possible, except when to do so would injure them or others", "wrigley"], "metric_results": {"EM": 0.09375, "QA-F1": 0.30753718675545305}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.4444444444444445, 0.3333333333333333, 0.23529411764705882, 0.33333333333333337, 0.4615384615384615, 0.923076923076923, 0.0, 0.33333333333333337, 0.0, 0.2857142857142857, 0.3636363636363636, 0.888888888888889, 0.6, 0.0, 1.0, 0.10526315789473684, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastics", "abraham", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "crimson tide", "iteratively", "geese", "effect", "pacific", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "lower", "juveniles are capable of reproduction before reaching the adult size and shape", "toasted wheat bun", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "iPhone 6", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde", "1603", "status superior to all others in health-related fields", "Nutcracker", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball"], "metric_results": {"EM": 0.9375, "QA-F1": 0.96}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7200000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_naturalquestions-validation-6545", "mrqa_triviaqa-validation-6221"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-2454", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "unfixed_ids": ["mrqa_hotpotqa-validation-5762", "mrqa_squad-validation-4637"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.9999999966666667}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences, with the Romans serving as external arbiters on disputes concerning Jewish customs and law", "south of the Kancamagus Highway", "Magic formula investing", "true history of the Kelly Gang", "Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "tennis", "4,000", "Khagan", "Heathcliff", "canal", "spice", "Lisa and the 8th Commandment", "Raymond Unwin and the architect Barry Parker", "San Bernardino", "A portion of Grainger Town was demolished in the 1960s to make way for the Eldon Square Shopping Centre", "Albany School for Educating People of Color", "charbagh", "Sergeant First Class", "Anakin Skywalker", "seek jury nullification", "Cee - Lo", "Anglican", "pacific", "king george V", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "1757"], "metric_results": {"EM": 0.25, "QA-F1": 0.4055822649572649}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false], "QA-F1": [0.2222222222222222, 0.4, 0.0, 0.33333333333333337, 0.33333333333333337, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "an investment technique outlined by Joel Greenblatt", "kelly", "City and County of Honolulu", "1910\u20131940", "those who refuse vetting", "the Catch Me Who Can", "jazz", "margaret smith court", "3,677 seated", "the founder of the Yuan dynasty", "catherine and heathcliff", "birmingham", "sri lankan", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Riverside", "the Eldon Square Shopping Centre", "Albany High School", "Rashtrapati Bhavan", "Sergeant First Class", "Anakin Skywalker", "nullification", "the closing scene of the final episode of the first season", "The Church of England", "hattie smDaniel", "scharnhorst", "hypnotism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "The economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.84375, "QA-F1": 0.884375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6148", "before_prediction": "Khagan", "after_prediction": "the founder of the Yuan dynasty"}, {"id": "mrqa_naturalquestions-validation-800", "before_prediction": "charbagh", "after_prediction": "Rashtrapati Bhavan"}, {"id": "mrqa_squad-validation-7319", "before_prediction": "opportunity-based entrepreneurship", "after_prediction": "The economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth"}], "retained_ids": ["mrqa_squad-validation-7435", "mrqa_squad-validation-3176", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-7801"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_naturalquestions-validation-2214", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_hotpotqa-validation-945"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-5839"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.6249999992187499}, {"timecode": 27, "before_eval": {"predictions": ["Aquarius", "margaret smith", "red", "al Nitak", "Big Mamie", "trinidad and Tobago", "the sardonic drifter", "a light sky-blue color caused by absorption in the red", "the peasants\u2019 Revolt", "1963", "the Golden State Warriors", "the internal thylakoid system", "Renoir", "the Grand Annual Steeplechase at Warrnambool", "The channel which can get carriage on a suitable beam of a satellite", "the fourth season", "a more fundamental electroweak interaction", "the availability of skilled tradespeople", "hardness", "A simple iron boar crest", "the Newcastle Polytechnic, established in 1969 and became the University of Northumbria at Newcastle", "kelly smith", "Lofton", "on kickoffs at the 25 - yard line", "the Latin centum", "about 7,000", "the lion, leopard, buffalo, rhinoceros, and elephant", "the righteousness of Christ", "margaret smith", "possible combinations of two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "antwerp", "cete"], "metric_results": {"EM": 0.15625, "QA-F1": 0.241987247949419}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.125, 0.0, 0.0, 0.631578947368421, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6060606060606061, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "Big Mamie", "orinoco river", "Teamsters leader", "clear", "wat tyler", "2009", "Zaza Pachulia", "inner chloroplast membrane", "Renoir", "sports", "no", "third", "a more fundamental electro weak interaction", "Cost of construction", "gypsum", "A simple iron boar crest", "polytechnics became new universities", "australia", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yard lines", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "peter paul rubens", "badgers"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9871794871794872}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10312", "before_prediction": "a more fundamental electroweak interaction", "after_prediction": "a more fundamental electro weak interaction"}], "retained_ids": ["mrqa_hotpotqa-validation-994", "mrqa_triviaqa-validation-1423", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-8279"], "fixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_triviaqa-validation-5962", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_hotpotqa-validation-3949", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.7999999984}, {"timecode": 28, "before_eval": {"predictions": ["the Turk", "Chris Weidman", "inform the jury and the public of the political circumstances surrounding the case and their reasons for breaking the law via civil disobedience", "Harishchandra", "studied Arabic grammar", "Professor Eobard Thawne", "plum brandy", "US $10 a week", "1875", "contributed by member states on a voluntary basis", "clarinets", "McKinsey's offices in Silicon Valley and India", "gyrophobia", "living Doll", "Crohn's disease", "Ondemar Dias", "Raya Yarbrough", "Arizona", "cruiserweight", "wealthy Chicagoans like Silas B. Cobb who provided the funds for the campus' first building, Cobb Lecture Hall", "Old Testament", "brown trucks", "touring productions", "Football League", "2000", "Pliocene", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "John Surratt", "1349", "dodo bird", "a person can improve their own health, wealth and personal relationships", "Stan Butler"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2456694718117132}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.56, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.1, 0.0, 0.0, 1.0, 0.13793103448275862, 1.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_squad-validation-5086", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_squad-validation-8190", "mrqa_naturalquestions-validation-7821"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "plead not guilty", "Kusha", "poet, and writer", "Professor Eobard Thawne", "plum", "a US$10 a week raise", "1825", "member states", "oboe", "McKinsey's offices", "fear of public speaking", "lionel bart", "ulcerative colitis", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "Charles L. Hutchinson", "Song of Songs", "ups", "local talent", "North End Football Club", "peter davison", "canada", "contemporary accounts were exaggerations", "Lincoln assassination", "1332", "flightless bird", "the belief that by focusing on negative thoughts people can bring positive or negative experiences into their life", "Stan Butler"], "metric_results": {"EM": 0.875, "QA-F1": 0.9548611111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.9444444444444444, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-10495", "before_prediction": "contributed by member states on a voluntary basis", "after_prediction": "member states"}, {"id": "mrqa_triviaqa-validation-2953", "before_prediction": "dodo bird", "after_prediction": "flightless bird"}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-4309", "mrqa_triviaqa-validation-4308"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-7669", "mrqa_squad-validation-5086", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_squad-validation-8190"], "unfixed_ids": ["mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 29, "before_eval": {"predictions": ["public speaking", "886 AD", "to finance his own projects", "24 Hours of Le Mans", "Xbox 360", "Tokyo", "linebacker Danny Trevathan", "the parallelogram rule of vector addition", "w Jennings Bryan", "364", "a neutron source used for stable and reliable initiation of nuclear chain reaction", "canada", "the bore, and often the stroke", "performs six major functions ; support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the local administrative structure of past Chinese dynasties", "Doctor Who Theme", "National Basketball Development League (NBDL)", "gillingham", "St. Mary's County", "Ted Ginn Jr.", "2,615", "Pyeongchang", "Kaep", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes", "Homeless Man", "Charles and Ray Eames", "Brazil", "abraham lincoln", "the smallest subfield", "heartburn", "53%", "the light reactions"], "metric_results": {"EM": 0.15625, "QA-F1": 0.3021419552669553}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.33333333333333337, 0.0, 0.33333333333333337, 0.0, 1.0, 0.26666666666666666, 0.0, 0.0, 0.38095238095238093, 1.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.7272727272727273, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "His patents", "Formula One", "microsoft", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "evolution", "364", "startup neutron source", "van gogh", "cylinder", "movement", "the local administrative structure of past Chinese dynasties", "Doctorin' the Tardis", "National Basketball Development League", "kent", "Washington metropolitan area", "Emmanuel Sanders", "The population was 2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using method such as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "south kore", "arthur", "the smallest subfield", "heartburn", "53%", "normal grana and thylakoids"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9832589285714286}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-3103", "mrqa_squad-validation-8075", "mrqa_squad-validation-9036", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-7445"], "fixed_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-8653", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_naturalquestions-validation-4572", "mrqa_triviaqa-validation-1353"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.9999999980000001}, {"timecode": 30, "before_eval": {"predictions": ["the judiciary", "named for Frederick Louis, Prince of Wales, son of King George II", "an outgoing, eccentic, big - hearted, loving, sweet, and thoughtful elephant and teacher", "slavery", "arthur", "Marty Ingels", "BBC UKTV", "arthur", "demographics and economic ties", "three or more separate periods", "The Kickoff Game", "narcolepsy", "arctic monkeys", "arthur", "arthur", "usernames, passwords, commands and data", "instructions", "Nationals are strongest in Victoria's North Western and Eastern rural regional areas", "marduk", "arthur", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "kent", "South Pacific", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Easy", "Rob Kerkovich", "Nehru", "National Lottery", "arthur", "catherine of aragon", "in order to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.09375, "QA-F1": 0.149430572169059}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 1.0, 0.4, 0.12121212121212122, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3636363636363636]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "jurassic park", "all transmissions", "A computer program", "The Greens", "babylon", "surtsey", "largest source of foreign direct investment", "national network", "South Pacific", "7", "New Jersey", "Easy", "Daryl Mitchell", "indira gandhi", "state-franchised", "skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9615384615384616}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2750", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-1282"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_squad-validation-7793", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608", "mrqa_hotpotqa-validation-3333"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.9999999966666667}, {"timecode": 31, "before_eval": {"predictions": ["yolanda sald\u00edvar", "Andreas", "boston", "sports commentator", "the crossroads of the Newell Highway between Melbourne and Brisbane, and the Mid- Western Highway between Sydney and Adelaide", "numbarf", "top of her withers", "Mall of America ( commonly, locally known as `` MOA '' or `` the mall '' ) is a shopping mall located in Bloomington, Minnesota, United States ( a suburb of the Twin Cities )", "to avoid responsibility for her actions", "DreamWorks Animation", "waltz king", "a khuruldai elected Jamukha as G\u00fcr Khan, \"universal ruler\" a title used by the rulers of the Qara Khitai", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases", "marbles", "the RAF", "reduce growth in relatively poor countries but encourage growth", "Ibrium", "strictly", "Polish-Jewish", "One of the main leaders ( Spanish : Caudillo ) of the 1936 coup, General Francisco Franco", "is a song by Cole Porter, which was first sung in the 1934 Broadway musical Anything Goes, and then in the 1936 film version", "pacific", "390 billion", "Washington Street between Boylston Street and Kneeland Street", "8 November 1978", "six", "get a clue", "frustration with the atmosphere in the group at that time -- namely, Paul McCartney's over-assertiveness and criticism of his guitar playing, John Lennon's lack of engagement with the project and dismissal of Harrison as a songwriter", "dublin", "Paul the Apostle, later cited by John Smith in Jamestown, Virginia, and by Lenin during the Russian Revolution", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.15625, "QA-F1": 0.24651655622723398}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.08333333333333333, 0.2222222222222222, 0.0, 1.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.3636363636363636, 1.0, 0.5, 0.0, 0.0, 0.17391304347826084, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.45000000000000007, 0.0, 0.2222222222222222, 1.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "make a defiant speech, or a speech explaining their actions, in allocution", "Andrew Adamson", "liszt Strauss Wagner Dvorak", "Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage growth", "Ibbi-Sipish", "Strictly Come Dancing", "Polish", "the Falange", "cole albert", "1967", "16,000", "Washington Street", "8 November 1978", "2", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "barbarella", "John Smith", "lusitania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.875, "QA-F1": 0.9069444444444444}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3300", "before_prediction": "waltz king", "after_prediction": "liszt Strauss Wagner Dvorak"}, {"id": "mrqa_hotpotqa-validation-1444", "before_prediction": "Ibrium", "after_prediction": "Ibbi-Sipish"}], "retained_ids": ["mrqa_hotpotqa-validation-5585", "mrqa_hotpotqa-validation-3728", "mrqa_triviaqa-validation-4524"], "fixed_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_hotpotqa-validation-2564", "mrqa_squad-validation-6128", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-743", "mrqa_naturalquestions-validation-4500"], "unfixed_ids": ["mrqa_squad-validation-6734", "mrqa_squad-validation-3106"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 32, "before_eval": {"predictions": ["A cylindrical Service Module (SM) supported the Command Module, with a service propulsion engine and an RCS with propellants, and a fuel cell power generation system with liquid hydrogen and liquid oxygen reactants", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "beer", "gender test", "Thomas Middleditch", "kalium", "In extreme circumstances, a driver may attempt to jackknife the vehicle deliberately in order to halt it following brake failure", "T cell", "generally paid on graduated scales, with income depending on experience", "fruit, vegetables and tomatoes", "\"Point of Entry\"", "Moonraker", "Wii U", "Michael Oppenheimer", "England national team", "status of people within the four-class system was not an indication of their actual social power and wealth, but just entailed \"degrees of privilege\" to which they were entitled institutionally and legally", "No Night Today", "Convention", "5,922", "December 5, 1991", "the title character in Luc Besson's \"Valerian and the City of a Thousand Planets\"", "former Phoenix Suns owner, coach, general manager, and Los Angeles Lakers head coach Mike D'Antoni", "the historical Saint Nicholas ( a fourth - century Greek bishop and gift - giver of Myra ), the British figure of Father Christmas and the Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "the Stern-Plaza in Potsdam", "Joe Frazier", "23 March 1991", "lily-of-the-valley", "Dealey Plaza", "Nairobi", "the chalk ridge line west of the Needles breached to form the island", "Anno 2053"], "metric_results": {"EM": 0.1875, "QA-F1": 0.30733048654244305}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.08695652173913045, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.1142857142857143, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.5, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "after_eval": {"predictions": ["orbital scientific instrument", "Religiously affiliated and denominational schools", "Fomento Econ\u00f3mico Mexicano", "september", "south africa", "Thomas Middleditch", "potassium", "If a vehicle towing a trailer skids", "T cell", "relatively low salaries", "us", "\"Point of Entry\"", "bridge", "u", "Science Magazine's", "Premier League club Manchester United and the England national team", "poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Wodan", "Stern-Plaza", "Jimmy Ellis", "1991", "may", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9553571428571428}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6744", "before_prediction": "Orthodox Christians", "after_prediction": "Religiously affiliated and denominational schools"}], "retained_ids": ["mrqa_naturalquestions-validation-4761", "mrqa_squad-validation-6602", "mrqa_hotpotqa-validation-1119", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-5557"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_triviaqa-validation-7394", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_hotpotqa-validation-305", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "unfixed_ids": ["mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.8333333319444445}, {"timecode": 33, "before_eval": {"predictions": ["Napoleon", "\"Boston Herald\" Rumor Clinic", "1967", "footprints in the Sand", "the twelfth most populous city in the United States", "115", "Archibald Haddock", "is able to bind a specific ligand, a transmembrane domain, and an intracellular catalytic domain", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Bass", "Chava with Fyedka", "New Orleans, Biloxi, Mississippi, Mobile, Alabama and small settlements in the Illinois Country", "or Nihon-koku", "mizzen masts of square-rigged ships", "Spring city", "Mumbai, India", "Broken Hill and Sydney", "2005", "forgiveness was God's alone to grant", "\"Smith and Jones\"", "may", "bridge", "to prevent things that are indisputably bad", "1879", "Wolde Hanna was the niece of Empress Taitu Bitul, consort of Emperor Menelik II of Ethiopia", "staying with the same group of peers for all classes", "prevent any contaminants in the sink from flowing into the potable water system", "enthusiasm and energy", "norway", "Datsun 810", "Bill Clinton", "Oslo county"], "metric_results": {"EM": 0.21875, "QA-F1": 0.27840144230769226}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.15384615384615383, 0.08, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.39999999999999997, 0.0, 0.125, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "after_eval": {"predictions": ["Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "largest Filipino American community", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher rates", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "St. Lawrence River valley", "emperor", "oakum", "Yunnan- Fu", "London", "Broken Hill and Sydney", "2005", "all punishments", "\"Smith and Jones\"", "wagon", "illich ramirez sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "air conditioning", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-270", "before_prediction": "Spring city", "after_prediction": "Yunnan- Fu"}], "retained_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1573", "mrqa_naturalquestions-validation-6358", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-7741", "mrqa_squad-validation-1903"], "fixed_ids": ["mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-5727", "mrqa_squad-validation-2010", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8571428559183674}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "white satin wedding dress", "Threatening government officials", "Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "boulangere", "0.2 inhabitants per square kilometre", "peter carrington v.C.", "France", "Ian Richard Kyle Paisley", "Bataan Death March", "euro", "suggs", "the United States", "1973", "1886", "2008 NFL season", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Maximus Decimus Meridius", "A rotation is a circular movement of an object around a center ( or point ) of rotation. A three - dimensional object can always be rotated around an infinite number of imaginary lines called rotation axes", "Johnny Darrell", "stroke", "all margarine to be in cube shaped packages", "Euler's totient function", "earwax", "the set of all connected graphs", "second-busiest", "red", "Toyota Corona", "American writer and satirist Kurt Vonnegut", "Rapunzel"], "metric_results": {"EM": 0.09375, "QA-F1": 0.15135407127594627}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 0.0, 0.15384615384615385, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-1139", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman", "Norman Hartnell", "broadcasting", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52", "Primula Susan Rollo", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "World War II", "litas", "madness", "Taft", "late 1970s", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "relationship of the number to its corresponding value of Euler's totient function", "ear", "how graphs are encoded as binary strings", "third", "afghanistan", "large", "Lauren Oliver", "Tangled"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9583333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3408", "before_prediction": "earwax", "after_prediction": "ear"}], "retained_ids": ["mrqa_hotpotqa-validation-3982", "mrqa_naturalquestions-validation-951"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-1139", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "unfixed_ids": ["mrqa_triviaqa-validation-5496"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 35, "before_eval": {"predictions": ["up to 2% higher", "supply and demand", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "the brain, muscles, and liver", "butterfly", "Washington Redskins", "in the courtyard adjoining the Assembly Hall", "William Howard Ashton", "wyo", "high and persistent unemployment", "Lake Clarke Shores, Lake Worth, and West Palm Beach", "Song Kang-ho, Lee Byung-hun, and Jung Woo-sung", "changing display or audio settings quickly", "fought 1642-1651", "the spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "if the income share of the top 20 percent (the rich) increases, then GDP growth actually declines over the medium term, suggesting that the benefits don't trickle down", "Beautyy and the Beast", "South Africa", "Simon Waverly on \"Satisfaction\"", "alamo", "a seal illegally is broken", "the UMC", "Brian Liesegang", "Roger Allers and Rob Minkoff", "Papua New Guinea", "David Seville", "National Association for the Advancement of Colored People", "1963\u20131989", "titanic", "John Smith", "Darrin Stephens", "6500 - 1500 BC"], "metric_results": {"EM": 0.25, "QA-F1": 0.40304563492063494}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.28571428571428575, 0.14285714285714288, 0.4, 1.0, 0.0, 0.888888888888889, 1.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.0, 0.4799999999999999, 0.08333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["up to 2% higher than during outbreaks of 13- and 17-year cicadas", "capital and financial markets", "Dan Stevens", "brain", "Bucatini", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard adjoining the Assembly Hall", "William Howard Ashton", "president harding", "Unemployment", "Miami", "Best Actor prize", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "charles i", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "South Africa", "Tyler \"Ty\" Mendoza", "texas", "seal", "United Methodist Church", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "Alvin and the Chipmunks", "National Association for the Advancement of Colored People", "1963\u20131989", "Titanic", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 0.84375, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true], "QA-F1": [0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9123", "before_prediction": "up to 2% higher", "after_prediction": "up to 2% higher than during outbreaks of 13- and 17-year cicadas"}, {"id": "mrqa_triviaqa-validation-4829", "before_prediction": "butterfly", "after_prediction": "Bucatini"}, {"id": "mrqa_squad-validation-10036", "before_prediction": "the UMC", "after_prediction": "United Methodist Church"}, {"id": "mrqa_triviaqa-validation-11", "before_prediction": "David Seville", "after_prediction": "Alvin and the Chipmunks"}], "retained_ids": ["mrqa_hotpotqa-validation-2971", "mrqa_triviaqa-validation-6450", "mrqa_squad-validation-7610", "mrqa_triviaqa-validation-3860"], "fixed_ids": ["mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-4544", "mrqa_squad-validation-9400", "mrqa_triviaqa-validation-6423", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "unfixed_ids": ["mrqa_hotpotqa-validation-1720"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.49999999937499995}, {"timecode": 36, "before_eval": {"predictions": ["National Broadcasting Company", "Kevin Costner", "Uranus", "president rudolf", "Cobham\u2013Edmonds thesis", "audience surrogates", "Best Male Pop Vocal Performance", "March 2012", "New Orleans", "Muhammad Ali", "Coldplay", "Menorca", "plead guilty to one misdemeanor count and receive no jail time", "Julius Caesar", "2%", "1979", "a virtual reality simulator", "decision problem", "lecouvreur", "the right side of the heart to the lungs", "Miasma theory", "pint of 20 imperial fluid ounces ( 568 ml )", "mountain ranges", "united", "Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571, with exports to other states occurring around 1858.", "nettle", "US$3 per barrel", "a flat rate of 20 %", "love is all around", "to build a nationwide network in the UK", "roughly west through the Netherlands and extended to the southwest, through the English Channel and finally, to the Atlantic Ocean", "Sudan"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4384642998613587}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.35294117647058826, 0.4444444444444445, 0.0, 0.8, 0.0, 0.5454545454545454, 1.0, 0.0, 0.14814814814814814, 1.0, 0.0, 0.4, 1.0, 0.2222222222222222, 0.11764705882352941, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "north", "rudolph", "Cobham\u2013Edmonds thesis", "teachers", "II", "April", "b Bourbon Street", "Raymond Patterson", "Coldplay", "Menorca", "submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen", "emperors", "2", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "formal language", "conducting", "the right side of the heart", "bad air", "imperial fluid ounces", "mountain ranges", "white", "South Carolina", "perennial", "nearly $12", "20 %", "love is all around", "ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.875, "QA-F1": 0.878125}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3803", "before_prediction": "New Orleans", "after_prediction": "b Bourbon Street"}, {"id": "mrqa_squad-validation-6759", "before_prediction": "plead guilty to one misdemeanor count and receive no jail time", "after_prediction": "submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen"}, {"id": "mrqa_triviaqa-validation-4069", "before_prediction": "nettle", "after_prediction": "perennial"}], "retained_ids": ["mrqa_hotpotqa-validation-152", "mrqa_squad-validation-1758", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-3060", "mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-6290"], "fixed_ids": ["mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_naturalquestions-validation-3344", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146", "mrqa_hotpotqa-validation-452"], "unfixed_ids": ["mrqa_triviaqa-validation-4824"], "instant_fixing_rate": 0.9523809523809523, "instant_retention_rate": 0.7272727266115702}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "three of his ribs were broken", "7 December 2000", "Post Alley", "mother-of-pearl", "February", "stomach", "George H.W. Bush", "96", "De Inventione by Marcus Tullius Cicero", "japan", "a black background representing the circle with glossy gold letters", "Eridu", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Harry Kane", "small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "numerous musical venues, including the Teatr Wielki, the Polish National Opera, the Chamber Opera, The National Philharmonic Hall and the National Theatre, as well as the Roma and Buffo music theatres", "7%", "1991", "the Na'vi", "7 January 1936", "lifetime protection", "twenty- three", "astronomers Carl Sagan, a prominent contributor to the scientific research of extraterrestrial life, and Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Poulsen", "a defiant speech, or a speech explaining their actions", "normal", "Boston, Massachusetts"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2863766339869281}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35294117647058826, 0.07142857142857142, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.2777777777777778, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_hotpotqa-validation-513", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "Walter Mondale", "96", "the Roman Empire", "two", "glossy gold", "Mesopotamia", "37\u00b0 9' 58.23\"", "woodentop", "Henry", "shared", "sand goanna", "events and festivals", "kabinett", "2010", "avatar", "7 January 1936", "lifetime protection", "10", "Carl Sagan", "Much of the city's tax base dissipated", "Republicans", "Pierre Nlend Wom\u00e9", "mistreatment from government officials", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4664", "before_prediction": "George H.W. Bush", "after_prediction": "Walter Mondale"}], "retained_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-5451", "mrqa_hotpotqa-validation-4154", "mrqa_hotpotqa-validation-85", "mrqa_naturalquestions-validation-969", "mrqa_hotpotqa-validation-5371"], "fixed_ids": ["mrqa_squad-validation-1625", "mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_hotpotqa-validation-513", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "unfixed_ids": ["mrqa_hotpotqa-validation-2377"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.8571428559183674}, {"timecode": 38, "before_eval": {"predictions": ["NP-complete Boolean satisfiability problem", "Dan Stevens", "New England", "Bart Cummings", "buffalo", "Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "a children's story published by John Newbery in London in 1765", "It has the longest rotation period ( 243 days ) of any planet in the Solar System and rotates in the opposite direction to most other planets ( meaning the Sun would rise in the west and set in the east ).", "gathering money from the public", "Eden", "commissioned to purchase their required uniform items", "Jeff Meldrum", "741 weeks", "archers", "Shoshone, his mother tongue, and other western American Indian languages", "The Paris Sisters", "gisela pfab", "60", "journalist", "the fact that there is no revising chamber", "mini-skirt", "when lifted to an extension field", "most of the items in the collection, unless those were newly accessioned into the collection, probably don't show up in the computer system", "does not satisfy the criteria for a medium of exchange", "strychnine", "North Dakota", "the early 16th century", "13 June 2003", "Today", "Darleen Carr", "In healthy adults, there are two normal heart sounds, often described as a lub and a dub ( or dup ), that occur in sequence with each heartbeat"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2632109393092008}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.05714285714285714, 0.47058823529411764, 0.0, 0.22222222222222224, 0.25, 0.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.2857142857142857, 1.0, 0.6, 0.0, 0.0, 0.34782608695652173, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 0.0, 0.0625]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3893", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "after_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma", "1958", "Bart Cummings", "dragon", "slavery", "colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \"Jeff\" Meldrum (born May 24, 1958) is a Professor of Anatomy and Anthropology", "a week", "phil archer", "French and English", "The Chipettes", "suez canal", "60 by West All - Stars ( 2017 )", "journalist", "no revising chamber", "beehive hairdo", "ramification in geometry", "newly accessioned", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "Today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.90625, "QA-F1": 0.95625}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-1862", "mrqa_naturalquestions-validation-2499", "mrqa_squad-validation-1660", "mrqa_triviaqa-validation-3320", "mrqa_triviaqa-validation-2039"], "fixed_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9478", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_triviaqa-validation-1473", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.9999999980000001}, {"timecode": 39, "before_eval": {"predictions": ["Taiwan", "Dan Conner", "Berlin", "president harding", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "anti-Semitism", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "ceylon", "1977", "John M. Grunsfeld, geneticist James Watson", "San Francisco", "may be quite simple but then again, no", "2003", "a couple months of age in buck fawns", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "relative units of force and mass", "woman", "two", "August 10, 1933", "a suspension bridge spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Sochi, Russia", "those who already hold wealth", "bilingual German author B. Traven", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "too much money chasing too much goods", "lion", "264,152", "Princeton", "the United States", "high pressure"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3526348039215686}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.5, 1.0, 0.4, 0.0, 0.8, 0.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.7142857142857143, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_naturalquestions-validation-9227", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["taipei", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "1980s", "John M. Grunsfeld", "detroit", "your song", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "fixed", "agatha Christie", "porto", "August 10, 1933", "Golden Gate Bridge", "vancouver", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "Fortean", "inflation", "squirrels", "247,597", "The Institute for Advanced Study", "German service cartridge", "DC"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9975961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-2243", "mrqa_naturalquestions-validation-3698", "mrqa_hotpotqa-validation-5233", "mrqa_naturalquestions-validation-6839", "mrqa_hotpotqa-validation-2332", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-489"], "fixed_ids": ["mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_triviaqa-validation-2522", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-7269", "mrqa_triviaqa-validation-5595", "mrqa_naturalquestions-validation-3108", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.9999999985714286}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Bartle Frere", "Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgis", "1602\u201311", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "prophecy", "Aristotle", "Charlton Heston", "anti-inflammatory molecules", "h Highland garb", "Kevin Kolb", "money", "statute or the Constitution", "son et lumi\u00e8re", "the Karluk Kara-Khanid ruler, who in turn was ranked higher than the Korean King", "Sochi, Russia", "ludwig", "the Canadian Rockies continental divide east to central Saskatchewan, where it joins with another major river to make up the Saskatchewan River", "At the insistence of NASA Administrator Webb, North American removed Harrison Storms as Command Module program manager", "australia", "stenographer", "30", "Secret Intelligence Service", "100 billion", "kai su, teknon", "photolysis of ozone by light of short wavelength", "4.7 / 5.5 - inch", "Queen City", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.21875, "QA-F1": 0.2886208062770563}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.16]}}, "error_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "ice dancing", "Isabella (Belle) Baumfree", "corgi", "throughout the 14th to 17th centuries", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "placing them on prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "express or implied Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "sound and light show", "surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "central Saskatchewan", "immediately", "new zealand", "secretarial assistant", "30 Major League Baseball teams", "MI6", "neurons", "julius caesar", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.875, "QA-F1": 0.9135044642857143}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1571", "before_prediction": "sarajevo", "after_prediction": "ice dancing"}, {"id": "mrqa_triviaqa-validation-4123", "before_prediction": "stenographer", "after_prediction": "secretarial assistant"}], "retained_ids": ["mrqa_squad-validation-395", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-4076", "mrqa_squad-validation-3617", "mrqa_hotpotqa-validation-178"], "fixed_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-1063", "mrqa_squad-validation-8247", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_naturalquestions-validation-993"], "unfixed_ids": ["mrqa_naturalquestions-validation-8961", "mrqa_triviaqa-validation-6127"], "instant_fixing_rate": 0.92, "instant_retention_rate": 0.7142857132653061}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Padosan (Hindi: \"\u092a\u0921\u093c\u094b\u0938\u0928\" English: lady Neighbour )", "Gaels", "Three-card brag", "d\u00edsabl\u00f3t", "European or Eurasian cave lion", "Russian drama film directed by Ilya Khrzhanovsky after a screenplay by Vladimir Sorokin", "sediment load", "Washington metropolitan area", "GTPase responsible for endocytosis in the eukaryotic cell", "User State Migration Tool", "Ordos City China Science Flying Universe Science and Technology Co.", "pie tins", "PPG Paints Arena, Pittsburgh, Pennsylvania", "september", "Section 30", "Ron Messick as William B. White as Henry Fussy, a boy of about Fern's age, whom she soon starts spending time with while Wilbur is at the fair", "mid-1988", "quasars", "Retreating Monsoon", "Romansh", "geena ii", "Newstalk radio station 5AA (FIVEaa)", "Q Branch (or later Q Division) the fictional research and development division of the British Secret Service", "Philippi in Greece during Paul's second missionary journey, which occurred between approximately 49 and 51 AD", "the division of labour, productivity, and free markets", "Jerry Marenghi", "Pat Houston", "Hugo Award", "j James Callaghan", "king David of Israel", "Elvis Presley"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18211241883116883}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.2857142857142857, 0.0, 0.1818181818181818, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.05, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.33333333333333337, 0.125, 0.0, 0.0, 0.25, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag", "Idisi", "lion", "The cinema of Russia", "the sediment load of the Rhine has strongly increased and delta growth has sped up", "FedExField in Landover, Maryland", "the scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment", "Windows Easy Transfer", "Ordos City", "flying Disc", "Duquesne University", "leicester", "Section 30 of the Teaching Council Act 2001", "Paul Lynde", "October 1986", "4 billion", "Northeast Monsoon or Retreating Monsoon", "switzerland", "king george iii", "5AA", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret smith", "jonathan", "Luigi Creatore"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9230392707397425}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.7547169811320755, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9355", "before_prediction": "sediment load", "after_prediction": "the sediment load of the Rhine has strongly increased and delta growth has sped up"}, {"id": "mrqa_squad-validation-2142", "before_prediction": "Section 30", "after_prediction": "Section 30 of the Teaching Council Act 2001"}], "retained_ids": ["mrqa_squad-validation-1592"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_hotpotqa-validation-201", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_hotpotqa-validation-3872", "mrqa_triviaqa-validation-1585", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-8338", "mrqa_triviaqa-validation-791"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.3333333322222222}, {"timecode": 42, "before_eval": {"predictions": ["david carradine", "pasta ( usually cavatelli, acini di pepe, pastina, orzo, etc. ), lentils, or grated parmesan cheese", "bmingham Royal Ballet", "an alliance between the city-state of Geneva and the Swiss Confederation", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "the name of the war, the tariff, states'rights and the nature of Abraham Lincoln's war goals", "paid professionals", "lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "a cruiseferry operated by Moby Lines, under charter from DFDS Seaways", "a midfielder", "rommel", "the duodenum", "glucose and galactose, that are absorbed directly into blood during digestion", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "wendy", "By functions ; Introverted Sensing ( Si ), Extroverted Thinking ( Te ), Introverted Feeling ( Fi ) and Extrovert Intuition ( Ne )", "Thursday", "yellow", "all prescribed medications prior to dispensing and administration to the patient", "Mars", "navigator and expedition leader", "a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam", "Michael Bezjian", "The Private Education Student Financial Assistance", "gamba", "the Roman Catholic Church to sell indulgences to raise money to rebuild St. Peter's Basilica in Rome", "colonies", "two forces, one pointing north, and one pointing east", "a member of the Scottish Parliament can introduce a bill as a private member", "Jack Murphy Stadium", "The answer to such questions is given by the time and space hierarchy theorems respectively"], "metric_results": {"EM": 0.09375, "QA-F1": 0.20916406784005467}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.7272727272727273, 0.5, 0.0, 1.0, 0.13333333333333333, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.5, 0.0, 0.33333333333333337, 0.0, 0.0, 0.10526315789473685, 1.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.0, 0.4, 0.0, 0.19999999999999998, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "the ozone generated in contact with the skin", "the American Civil War", "Chartered", "lack of remorse", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose", "their unusual behavior", "Gainsborough Trinity Football Club is a football club based in Gainborough, Lincolnshire, England.", "portrait", "By functions ; Introverted Sensing ( Si ), Extroverted Thinking ( Te ), Introverted Feeling ( Fi ) and Extrovert Intuition ( Ne )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "olympus Mons", "feats of exploration", "piston", "rob lowe", "The Private Education Student Financial Assistance", "bow", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.875, "QA-F1": 0.9423363095238095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.9166666666666666, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7133", "before_prediction": "Mars", "after_prediction": "olympus Mons"}], "retained_ids": ["mrqa_squad-validation-1429", "mrqa_squad-validation-7034"], "fixed_ids": ["mrqa_triviaqa-validation-2952", "mrqa_naturalquestions-validation-8284", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-1586", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-4842", "mrqa_naturalquestions-validation-6706"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.6666666644444444}, {"timecode": 43, "before_eval": {"predictions": ["bridal Veil Falls", "4", "Indiana", "september", "French", "a sailor coming home from a round trip", "dots", "the immune system is less active than normal", "Py", "natural-ing Ingredients- Only personal care products", "a children's rhyme and song of a kind known as cumulative", "Rigoletto", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally", "third-most abundant element in the universe", "iKEA", "There are over 38 million Scouts and Guides worldwide", "football", "Nicholas Stone", "Algernod Lanier Washington", "the Outfield", "Croatia", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong", "railway locomotives", "eddie smith", "third quarter ( also known as last quarter )", "philadelphia trilogy", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "many areas of technology incidental to rocketry and manned spaceflight", "Mitochondrial Eve", "237 square miles", "joseph"], "metric_results": {"EM": 0.125, "QA-F1": 0.2556736510393631}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [0.4, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.11764705882352941, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.2666666666666667, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.4210526315789474, 1.0, 0.5, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "after_eval": {"predictions": ["niagara falls", "15", "Indiana", "salt lake city", "Italian", "sailor", "subdomain", "recurring and life-threatening infections", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third-most", "furniture", "169", "mexico", "George Frampton", "Plies", "English rock band the Outfield", "tennis", "Michael Edwards", "road engines", "richard burton", "when the Moon's ecliptic longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "157 x 30 minute episodes", "Yuan T. Lee", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "Mitochondrial Eve", "237", "matthew"], "metric_results": {"EM": 0.90625, "QA-F1": 0.930921052631579}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7894736842105263, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4090", "before_prediction": "iKEA", "after_prediction": "furniture"}], "retained_ids": ["mrqa_triviaqa-validation-7538", "mrqa_hotpotqa-validation-4624", "mrqa_triviaqa-validation-5899"], "fixed_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-981", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_squad-validation-5586", "mrqa_hotpotqa-validation-5370", "mrqa_naturalquestions-validation-5822", "mrqa_triviaqa-validation-7482", "mrqa_naturalquestions-validation-7641", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "unfixed_ids": ["mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 44, "before_eval": {"predictions": ["Wakanda", "high test scores", "2003", "cricket", "meyerland", "campaign setting", "2003", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal", "\"\u00f7\"", "Christopher Lee as Count Dooku / Darth Tyranus", "8th", "a 1968 picture book written by Arlene Mosel and illustrated by Blair Lent", "hospitals and clinics", "increased patient health outcomes", "treble clef", "Lecrae", "12534 New Delhi - Kanpur Shatabdi Express - maximum speed 140 km / h", "Piazza Trinit\u00e0 dei Monti", "December 1, 2009", "a prominent left communist and, later, an activist in the cause of anti-fascism", "meyer", "Lord Chancellor of England", "meyer", "The Ministry of Corporate Affairs", "Irish", "the original Regia and House of the Vestal Virgins", "Penguin Classics", "energy-storage molecules", "Hubble Space Telescope", "a genuine love of our neighbors as ourselves", "chorale cantatas"], "metric_results": {"EM": 0.125, "QA-F1": 0.26270981622544126}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, true], "QA-F1": [0.2857142857142857, 0.0, 0.19999999999999998, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.6875000000000001, 0.15384615384615385, 0.7272727272727273, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.5, 0.5000000000000001, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_squad-validation-9951"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "2003 for the inter-county competition in England and Wales", "gymnastics", "sweden", "published campaign settings", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Padm\u00e9 Amidala", "second most commonly", "well", "all health care settings", "expected to become more integral within the health care system", "music", "Lecrae Devaughn Moore", "Mumbai Rajdhani Express", "Rome", "May 18, 2010", "Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "British", "Vesta", "branwell", "energy", "Hubble Space Telescope", "Christian Perfection", "Christ lag in Todes Banden, BWV 4"], "metric_results": {"EM": 0.875, "QA-F1": 0.9044117647058824}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5696", "before_prediction": "Irish", "after_prediction": "British"}, {"id": "mrqa_squad-validation-2419", "before_prediction": "chorale cantatas", "after_prediction": "Christ lag in Todes Banden, BWV 4"}], "retained_ids": ["mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-1504"], "fixed_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_squad-validation-9951"], "unfixed_ids": ["mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.49999999875}, {"timecode": 45, "before_eval": {"predictions": ["Mickey Spillane", "the 2009 St. Louis Rams", "perique", "cut off close by the hip", "death penalty", "a stout man with a \" double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck\"", "south africa", "rich Fisher King is the son of the king who is served from the grail", "Mangal Pandey of the 34th BNI", "V Alaudae, a Celtic legion recruited from Gallia Narbonensis and XXI, possibly a Galatian legion from the other side of the empire", "Hoss", "four of the 50 states of the United States in their full official state names", "garmisch-Partenkirchen", "eighth series", "the main road through the gated community of Pebble Beach", "St. Louis", "French", "Gareth in the AMC horror drama \"The Walking Dead\"", "\"LOVE Radio\"", "the American League (AL) champion Boston Red Sox", "the court from its members for a three - year term", "john travolta", "Dan Fogelman and Jessie Nelson", "brought several hundred thousand US and allied non-Muslim military personnel to Saudi Arabian soil to put an end to Saddam Hussein's occupation of Kuwait", "The Carnabeats", "\" Cashin' In\"", "usually scheduled for the Thursday following Labor Day and since 2004, it was hosted by the most recent Super Bowl champions", "Lunar Excursion Module (LEM, later shortened to Lunar Module, LM)", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Operation Neptune", "Mediterranean Sea"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2516931852869353}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.7692307692307693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 1.0, 0.0, 0.25, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.07142857142857142, 0.5, 1.0, 0.4166666666666667, 0.16666666666666669, 0.3076923076923077, 0.07142857142857142, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-2067"], "after_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke it", "under `` the immortal Hawke ''", "death penalty statutes", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum (\"town of the Ubii\")", "Lorne Greene", "Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia ), Massachusetts, Pennsylvania, and Virginia", "Great Britain", "They were the first group to win the competition", "the main highway entrance at California State Route 1", "Canadian Football League (CFL) team", "Canadian", "Gareth", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "radicalize the Islamist movement", "People! and The Carnabeats", "\" Cashin' In\"", "the most recent Super Bowl champions", "Command/Service Module (", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8756181318681319}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.07692307692307693, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3989", "before_prediction": "death penalty", "after_prediction": "death penalty statutes"}, {"id": "mrqa_hotpotqa-validation-5068", "before_prediction": "St. Louis", "after_prediction": "Canadian Football League (CFL) team"}], "retained_ids": ["mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-3509", "mrqa_hotpotqa-validation-712"], "fixed_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4123", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-347", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_naturalquestions-validation-2067"], "unfixed_ids": ["mrqa_squad-validation-9296", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.8518518518518519, "instant_retention_rate": 0.5999999988}, {"timecode": 46, "before_eval": {"predictions": ["baseball", "convection currents in the asthenosphere, which is ductile, or plastic, and the brittle lithosphere ( crust and upper mantle )", "Take That", "youngest publicly documented people to be identified as transgender", "electric lighting", "They service improved the speed of encryption of communications at both ends in front line operations during World War II", "Galileo Galilei and Sir Isaac Newton", "the unexistence of the ultraviolet catastrophe", "Premier League club Swansea City", "june vowing to Obtain Justice for the death of His Young Brother", "Elizabeth Weber", "first-person psychological horror adventure game", "hundreds", "\"Beetlejuice\"", "June 22, 1978", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "apple", "partial funding", "5% abv draught beer", "inefficient", "Chu'Tsai", "Liz", "the least onerous", "como", "Grissom, White, and Chaffee", "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores", "yellow", "the ancient scholar Bharata Muni", "The geological properties of a white silica sand found at Basin Head are unique in the province ; the sand grains cause a scrubbing noise as they rub against each other when walked on", "golfer Samuel Ryder", "parts of the air in the vessel were converted into the classical element fire and thus were able to escape through pores in the glass", "imperial crown"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3837846121094668}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.375, 1.0, 0.9444444444444444, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.046511627906976744, 0.4, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "after_eval": {"predictions": ["cuba", "that continents `` ploughed '' through the sea", "Take That", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds", "Waiting for Guffman", "2003", "The Watermark business park", "apple", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "italy", "Grissom, White, and Chaffee", "multinational retail corporation", "maracuya", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "incorrectly", "vienna"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-6905", "mrqa_squad-validation-5157", "mrqa_squad-validation-2673", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913"], "fixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9999999988888888}, {"timecode": 47, "before_eval": {"predictions": ["al Gore", "taghrooda", "Burnley and the New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "when they enter the army during initial entry training", "moral tale", "They announced a hiatus and re-united two years later for the release of their fourth and final studio album, Destiny Fulfilled ( 2004 )", "ltd", "tree - topper or treetopper", "260", "heathrow", "often social communities with considerable face-to-face interaction among members", "William Strauss and Neil Howe", "monophyletic", "insecticide toxicology", "specific catechism questions", "a pH indicator", "2.5 times the normal sea-level O2 partial pressure of about 21 kPa", "Northern Ireland", "John and Charles Wesley", "Science and Discovery", "Euclid's fundamental theorem of arithmetic", "Campbellsville University", "jett Rink", "appearing as Jude", "25", "a dress to wear to the neighborhood dance", "Jocelyn Flores", "stagnant wages for the working class amidst rising levels of property income for the capitalist class"], "metric_results": {"EM": 0.25, "QA-F1": 0.3248172514619883}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.10526315789473682]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-3685", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "Qatar Prix de l\u2019Arc de Triomphe", "New Zealand national team", "Kumbum Monastery or Ta'er Shi near Xining", "Styal Mill", "William Jennings Bryan", "Goldie & Bear", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "piccadilly", "Neighbourhood", "The Washington Post", "tentacles", "insects", "specific catechism questions", "a pH indicator, a color marker, and a dye", "50% oxygen composition at standard pressure", "2001", "George Whitefield", "Science and Discovery", "1 were considered a prime", "Western Kentucky University", "James Byron Dean", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita", "XXXTentacion", "less workers are required in proportion to capital inputs, increasing unemployment ( the \"reserve army of labour\")"], "metric_results": {"EM": 0.84375, "QA-F1": 0.913879048582996}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7849", "before_prediction": "a pH indicator", "after_prediction": "a pH indicator, a color marker, and a dye"}, {"id": "mrqa_hotpotqa-validation-662", "before_prediction": "Campbellsville University", "after_prediction": "Western Kentucky University"}], "retained_ids": ["mrqa_hotpotqa-validation-5788", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-2143", "mrqa_squad-validation-4212", "mrqa_squad-validation-2346", "mrqa_squad-validation-1609"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_hotpotqa-validation-1924", "mrqa_squad-validation-6287", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-9061", "mrqa_triviaqa-validation-1799", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-2092"], "unfixed_ids": ["mrqa_triviaqa-validation-945", "mrqa_squad-validation-3685", "mrqa_squad-validation-7182"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.7499999990624999}, {"timecode": 48, "before_eval": {"predictions": ["James Stenbeck, St. Clair, Dixon, Munson and Montgomery", "Good Kid, M. a.A.D City (stylized as good kid, m.A,A.d city) is the second studio album by American rapper Kendrick Lamar.", "Yosemite National Park", "Interventive treatment", "3", "The Methodist Church (represented by Bishop Lloyd Christ Wicke)", "cuba", "During his epic battle with Frieza", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "Social Democratic Party", "2001", "Brandon Jennings", "a loop ( also called a self - loop or a `` buckle '' )", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California", "every good work designed to attract God's favor is a sin", "annuity", "twin sister", "Buffalo Bill", "justice", "the Viet Minh", "1917", "cappuccino", "cuba", "Arthur Russell (born Charles Arthur Russell, Jr. May 21, 1951 and April 4, 1992) was an American cellist, composer, producer, singer, and musician whose work spanned a disparate range of styles", "the people themselves", "Wylie Draper", "political role for Islam", "the university's off-campus rental policies", "hockey greats Bobby Hull and Dennis Hull", "New England Patriots", "war, famine, and weather"], "metric_results": {"EM": 0.25, "QA-F1": 0.3838460206907788}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.22222222222222218, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.18181818181818182, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.12903225806451613, 0.6666666666666666, 0.2666666666666667, 0.4, 1.0, 0.26666666666666666, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "3,000-foot rock known as El Capitan", "Interventive", "3", "Bishop Lloyd Christ Wicke", "georgia", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "unesco", "Thon Maker", "loop", "poetry", "part of a pre-recorded television program, Rendezvous with Destiny", "a sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "a place where justice resides", "France", "neutrality", "coffee", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull, as well as painter Manley MacDonald.", "Pittsburgh Steelers", "famine"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8985119047619048}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3967", "before_prediction": "Yosemite National Park", "after_prediction": "3,000-foot rock known as El Capitan"}, {"id": "mrqa_squad-validation-8248", "before_prediction": "painting, mathematics, calligraphy, poetry, and theater", "after_prediction": "poetry"}, {"id": "mrqa_squad-validation-2263", "before_prediction": "justice", "after_prediction": "a place where justice resides"}, {"id": "mrqa_squad-validation-4774", "before_prediction": "war, famine, and weather", "after_prediction": "famine"}], "retained_ids": ["mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-7947"], "fixed_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.49999999937499995}, {"timecode": 49, "before_eval": {"predictions": ["a generic term for vehicles inspired by the Jeep that are suitable for use on rough terrain", "AOL Inc", "Timur", "R.E.M.", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "the Eastern Roman (Byzantine) Empire", "12", "fear of public speaking", "World War I", "improved markedly", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "he had assigned them to the company in lieu of stock", "Marxist and a Leninist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Philadelphia Eagles, Denver Broncos, Berlin Thunder, Las Vegas Outlaws and Ottawa Renegades", "3,600 Frenchmen", "State Street", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "44 hectares", "georgia cukor", "Horus", "Lawton Mainor Chiles Jr.", "During the episode `` Kobol's Last Gleaming ''", "Massachusetts", "uneven trade agreements", "usually tea or porridge with bread, chapati, mahamri, boiled sweet potatoes or yams. Ugali with vegetables, sour milk, meat, fish or any other stew is generally eaten by much of the population", "adenosine diphosphate", "afghanistan", "Ruth Elizabeth \"Bette\" Davis", "uranium", "29 September 2014"], "metric_results": {"EM": 0.21875, "QA-F1": 0.34147276334776333}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [0.1111111111111111, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.3636363636363636, 0.888888888888889, 0.0, 1.0, 0.1111111111111111, 0.09523809523809525, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.5238095238095238, 0.5, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2032", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna (], also locally ] ; Romagnol: \"Rav\u00e8na\" ) is the capital city of the Province of Ravenna", "Bocelli became completely blind at the age of 12", "meat", "1895", "improved", "VTOL aircraft", "assigned them to the company", "communist", "the monastery's 2 hectares ( 4.9 acres ) experimental garden", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "uneven trade agreements", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "7 December 2004"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8546626984126984}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-716", "before_prediction": "improved markedly", "after_prediction": "improved"}, {"id": "mrqa_naturalquestions-validation-3663", "before_prediction": "Gregor Mendel", "after_prediction": "the monastery's 2 hectares ( 4.9 acres ) experimental garden"}, {"id": "mrqa_hotpotqa-validation-2750", "before_prediction": "29 September 2014", "after_prediction": "7 December 2004"}], "retained_ids": ["mrqa_squad-validation-6257", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1023", "mrqa_hotpotqa-validation-1772"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2032", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_triviaqa-validation-6380"], "unfixed_ids": ["mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-9807"], "instant_fixing_rate": 0.88, "instant_retention_rate": 0.571428570612245}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.16, "QA-F1": 0.26451958036032164}, "overall_error_number": 1344, "overall_instant_fixing_rate": 0.9399801057993219, "final_instream_test": {"EM": 0.8225, "QA-F1": 0.8700907621493706}, "final_upstream_test": {"EM": 0.619, "QA-F1": 0.692170258960087}}}