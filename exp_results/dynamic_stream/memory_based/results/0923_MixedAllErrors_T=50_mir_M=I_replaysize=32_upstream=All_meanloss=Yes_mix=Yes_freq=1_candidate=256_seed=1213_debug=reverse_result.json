{"model_update_steps": 1625, "method_class": "mir", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=3e-05, local_adapt_lr=3e-05, max_grad_norm=0.1, memory_key_cache_path='na', memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=1213_debug=reverse_ckpts/memory_dict.pkl', memory_store_rate=1.0, mir_debug_largestloss=False, mir_debug_reverse=True, num_adapt_epochs=3, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=1213_debug=reverse_ckpts/', replay_candidate_size=256, replay_frequency=1, replay_size=32, save_all_ckpts=1, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.hidden_passes.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances", "art and furnishings", "turbine", "adaptive", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "50 fund", "ned sherrin", "the Mandate of Heaven", "Tar Baby", "buddha", "Poseidon", "the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho ( including the communities of Parma, Wilder, Greenleaf, and Notus )", "2009", "the direction from which the wind is blowing", "john Mortimer", "oxygen", "seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "great train robbery", "Trey Parker", "omen of good or bad luck", "power blackouts"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9674107142857142}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-5465"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "Iroquois", "philanthropy", "neded on Mar 31, 2007", "Queen Elizabeth II", "Gary Morris", "to the anterolateral corner of the spinal cord", "1966", "for scientific observation", "pronseal", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "naba", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs show Summary", "great heroism or of the most conspicuous courage in circumstances of extreme danger", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "the check written by DC Comics to Jerry Siegel and Joe Shuster for the exclusive rights to their then-new character, Superman", "May and June 2010"], "metric_results": {"EM": 0.15625, "QA-F1": 0.23364713309566248}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.23529411764705885, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.5, 0.0, 0.4444444444444445, 1.0, 0.1904761904761905, 0.4]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "after_eval": {"predictions": ["from the Italian pignatta", "originally designated HU - 1", "philanthropy", "mariette", "Queen Elizabeth II", "American country music artists Crystal Gayle and Gary Morris", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York led people to hoard their money ; as consumption fell, the American economy steadily contracted, 1929 - 32", "Rotherham United", "norman tebbit", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years before", "islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "alimi Ballard", "for gallantry", "Danny DeVito", "Isaac Newton", "Superman", "2010"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8377525252525253}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5899", "before_prediction": "Gary Morris", "after_prediction": "American country music artists Crystal Gayle and Gary Morris"}, {"id": "mrqa_naturalquestions-validation-4684", "before_prediction": "The Stock Market crash in New York", "after_prediction": "The Stock Market crash in New York led people to hoard their money ; as consumption fell, the American economy steadily contracted, 1929 - 32"}, {"id": "mrqa_squad-validation-10410", "before_prediction": "Galileo", "after_prediction": "Isaac Newton"}], "retained_ids": ["mrqa_squad-validation-10015", "mrqa_squad-validation-1516"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_triviaqa-validation-7018", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_naturalquestions-validation-1864", "mrqa_triviaqa-validation-2367", "mrqa_hotpotqa-validation-3774"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-338"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.3999999992}, {"timecode": 2, "before_eval": {"predictions": ["Several motor ships have borne the name Kronprins Harald, after Harald V of Norway", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "independently in different parts of the globe", "marioneth and Llantisilly Rail Traction Company Limited", "acetate", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work via automobile or mass transit", "a student in the second year at a secondary (high) school or university", "Masaharu Iwata", "Terry Reid", "non- peer- reviewed sources", "sept Princesses", "North America", "Andr\u00e9 3000", "Commander", "the Aten, a representation of the Egyptian god, Ra", "Theodore Roosevelt", "from 2010 to 2012", "four", "the United States", "the 1970s", "liturgia", "Matt Winer", "1689", "the Pacific across the Amazonas Basin"], "metric_results": {"EM": 0.09375, "QA-F1": 0.2830744418979713}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [0.2666666666666667, 0.4444444444444445, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.9019607843137255, 0.18181818181818182, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4444444444444445, 0.4, 0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.4]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_hotpotqa-validation-3242", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "It was never affiliated with any particular denomination", "*", "2003", "eleven separate regions of the Old and New World", "idris", "polyatomic anion", "Jan Kazimierz", "casket letters", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Bothtec", "Spencer Davis Group", "non-peer-reviewed sources", "enigma Variations", "physiographically a part of the continent of North America", "OutKast", "Jack Swigert, and Fred Haise", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the Soviet Union and its satellite states", "in the very late 1980s", "bizet", "Matthew Ward Winer", "1700", "Pacific"], "metric_results": {"EM": 0.9375, "QA-F1": 0.921875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-5180", "before_prediction": "the United States", "after_prediction": "the Soviet Union and its satellite states"}], "retained_ids": ["mrqa_naturalquestions-validation-6896", "mrqa_squad-validation-194"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_hotpotqa-validation-3242", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367", "mrqa_squad-validation-3113", "mrqa_squad-validation-4283"], "unfixed_ids": ["mrqa_hotpotqa-validation-2679"], "instant_fixing_rate": 0.9655172413793104, "instant_retention_rate": 0.6666666644444444}, {"timecode": 3, "before_eval": {"predictions": ["why do Americans call it a period and the British a full stop", "south africa", "september", "between 27 July and 7 August 2022", "Staten Island", "september", "2006", "last of the Great Powers", "efferent nerves", "september", "september", "Lester Piggott", "coronary thrombosis", "bollywood", "Overtime", "Sir Henry Cole", "having trouble distinguishing between carbon dioxide and oxygen", "mike", "cement City", "the Democratic Unionist Party", "23 July 1989", "many educational institutions especially within the US", "many traditions of Hinduism - especially those common in the West", "timeslot 16 on an E1, while it is timeslot 24 for a T1", "Postcards From Paradise", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000", "hijab", "proteins", "gallbladder", "berenice Abbott"], "metric_results": {"EM": 0.25, "QA-F1": 0.2911728896103896}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3, 0.1, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "New York", "splash", "2005\u20132010", "G20", "efferent nerves", "max Bygraves", "polar bear", "jockeys", "don't disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo starr", "callable bonds", "Snapdragon 800", "over 10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museum"], "metric_results": {"EM": 0.875, "QA-F1": 0.9067460317460317}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3058", "before_prediction": "Staten Island", "after_prediction": "New York"}, {"id": "mrqa_triviaqa-validation-365", "before_prediction": "Lester Piggott", "after_prediction": "jockeys"}, {"id": "mrqa_naturalquestions-validation-6341", "before_prediction": "2.26 GHz quad - core Snapdragon 800 processor", "after_prediction": "Snapdragon 800"}], "retained_ids": ["mrqa_naturalquestions-validation-2571", "mrqa_hotpotqa-validation-5662", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_triviaqa-validation-6800"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_triviaqa-validation-7382", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-2530"], "unfixed_ids": ["mrqa_squad-validation-1539"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.6249999992187499}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "at Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "maius", "a shepherd", "at elevation 2 meters above sea level", "tetanus disease", "bounding the time or space used by the algorithm", "diamonds", "Alex O'Loughlin", "Eddie Leonski", "Jack Ridley", "a mixture of phencyclidine and cocaine", "bunker", "Fleet Street", "Reverse - Flash", "All Souls'Day", "the A's", "baku", "new converts", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "A steam turbine", "Splodgenessabounds"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3854910714285714}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 0.4, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3467"], "after_eval": {"predictions": ["Austria", "Arnhem", "30 days after the original air date", "unmanned Saturn V flights", "Gryphon", "16 April 1898", "june", "aaron", "new york city", "tetanus", "bounding", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "phencyclidine and cocaine", "a chain or screw stoking mechanism and its drive engine or motor may be included to move the fuel from a supply bin (bunker) to the firebox", "Fleet Street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "kansas city", "Azerbaijan", "new converts", "CeCe Drake", "cricket", "Tania Miller", "8 April 1912", "Quebec", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Spencer Callard, Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"], "metric_results": {"EM": 0.875, "QA-F1": 0.9088541666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.08333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1277", "before_prediction": "1898", "after_prediction": "16 April 1898"}, {"id": "mrqa_squad-validation-3389", "before_prediction": "bunker", "after_prediction": "a chain or screw stoking mechanism and its drive engine or motor may be included to move the fuel from a supply bin (bunker) to the firebox"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Spencer Callard, Lee Oakes, Hayley Bishop, Alison Mac, Thomas Nelstrop, and Jonathon Dutton"}], "retained_ids": ["mrqa_triviaqa-validation-1575", "mrqa_squad-validation-3126", "mrqa_triviaqa-validation-5168", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-3840", "mrqa_squad-validation-8700"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_squad-validation-9358", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-7253", "mrqa_squad-validation-1688", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3467"], "unfixed_ids": ["mrqa_naturalquestions-validation-5437"], "instant_fixing_rate": 0.9565217391304348, "instant_retention_rate": 0.6666666659259258}, {"timecode": 5, "before_eval": {"predictions": ["arthur", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale (FSFI)", "silk", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "2 : 44 p.m. EDT", "slide whistle", "rapeseed", "used stone tools, which they may have used to start fires, hunt, and bury their dead", "Indian origin", "parietal cells", "mammals that lay eggs ( Prototheria ) instead of giving birth to live young", "Ready to Die", "Garfield", "imperial rule", "1840", "defiant speech, or a speech explaining their actions", "Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey", "taxman", "current recession", "entropy increases", "my mind is averse to wedlock because I daily expect the death of a heretic", "The 1700 Cascadia earthquake", "China", "2 November 1902", "southeastern Texas", "May 7, 2018", "9 October 19408 December 1980", "Selden", "structural collapses", "as a way of housing a fierce half-man, half-bull creature known as the Minotaur"], "metric_results": {"EM": 0.09375, "QA-F1": 0.22963966288269694}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3157894736842105, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.47058823529411764, 1.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.33333333333333337, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "heart", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "start fires", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotreme", "September 13, 1994", "president garfield", "imperial rule", "1787", "defiant speech", "Mark Twain", "sunny afternoon", "on the basis of the methodology used: by using net wealth (adding up assets and subtracting debts", "nonconservative forces", "death of a heretic", "The 1700 Cascadia earthquake", "People's Republic of China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9527412280701755}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1718", "before_prediction": "China", "after_prediction": "People's Republic of China"}], "retained_ids": ["mrqa_naturalquestions-validation-816", "mrqa_naturalquestions-validation-2884"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020", "mrqa_squad-validation-7554"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 6, "before_eval": {"predictions": ["periodicals archive", "the draft carries more air ( oxygen ) past the flame", "Illinois State Senate", "1996", "Charlotte", "island in the Mediterranean Sea situated", "90-60's", "an aided or an unaided school", "dolph Camilli", "times sign", "BAFTA Television Award for Best Actor", "Juice Newton", "1960", "HTTP Secure", "late - September through early January", "Wichita", "monatomic", "for its popular beaches", "buddha", "frogs", "belgium", "1/2", "The anterior interventricular branch of left coronary artery", "1.1 \u00d7 1011 metric tonnes", "cobalt", "leaf tissue", "Indian club ATK", "land that a nation has conquered and expanded", "the Indian Ocean near Grande Comore, Comoros Islands", "an attributive and non-attributive noun, and with either a marked ( `` - s '' ) or unmarked plural", "Germanic", "burning of fossil fuels"], "metric_results": {"EM": 0.125, "QA-F1": 0.16458333333333336}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_squad-validation-3463", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film director", "capillary action", "2008", "2010", "north carolina", "minorca", "70", "independent", "boston Braves", "the symbol \u00d7", "Best Supporting Actress", "Juice Newton", "Super Bowl LII, 1949, and 1960", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "Wichita", "the simplest", "Palm Springs", "japan", "true", "red admiral", "o", "the left coronary artery", "10 % of the world's terrestrial primary productivity", "buttermere", "leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9395833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2584", "before_prediction": "for its popular beaches", "after_prediction": "Palm Springs"}], "retained_ids": ["mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-5795"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_squad-validation-7819", "mrqa_naturalquestions-validation-484", "mrqa_squad-validation-3463", "mrqa_triviaqa-validation-3714", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_triviaqa-validation-4966", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_hotpotqa-validation-3919", "mrqa_naturalquestions-validation-6644"], "unfixed_ids": ["mrqa_naturalquestions-validation-2190", "mrqa_squad-validation-4181"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.7499999981250001}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few common complex biomolecules", "The U.S. Army Chaplain insignia", "Kairi", "the suburbs, who wanted more services and more control over the central city", "Ray Milland", "near the Black Sea", "the last book accepted into the Christian biblical canon", "Bruno Mars", "conductivity", "George Cross", "the most popular show", "the late 1950s", "work oxen for haulage", "1998", "a priest", "23.1", "2001", "family member", "long-term environmental changes", "Bill Lear", "tangential force", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "The `` Blue Peter '' is used as a maritime signal, indicating that the vessel flying it is about to leave, and Reed chose the name to represent'a voyage of adventure'on which the programme would set out", "Abraham Gottlob Werner", "millais", "present-day Charleston", "quiescent", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.375, "QA-F1": 0.4927851577622919}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.4, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5365853658536585, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-1293", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_hotpotqa-validation-1142", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181"], "after_eval": {"predictions": ["decisions of procurement", "K'iche '", "a few", "the right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "lost weekend", "near the Black Sea", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george vi", "most popular", "post\u2013World War II", "breeding", "2011", "a priest", "most", "2001", "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting", "fish stocks to collapse by eating both fish larvae and organisms that would otherwise have fed the fish", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george i", "Charleston Orange district", "a \"quiescent\" stance", "Stephanie Boyriven", "Panzer"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8836544795783925}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true], "QA-F1": [0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8374", "before_prediction": "the wisdom and prudence of certain decisions of procurement", "after_prediction": "decisions of procurement"}, {"id": "mrqa_squad-validation-7799", "before_prediction": "the most popular show", "after_prediction": "most popular"}, {"id": "mrqa_squad-validation-1863", "before_prediction": "family member", "after_prediction": "a teacher occupying a transient or ongoing role, such as a family member, or by anyone with knowledge or skills in the wider community setting"}, {"id": "mrqa_squad-validation-4318", "before_prediction": "long-term environmental changes", "after_prediction": "fish stocks to collapse by eating both fish larvae and organisms that would otherwise have fed the fish"}, {"id": "mrqa_squad-validation-9598", "before_prediction": "quiescent", "after_prediction": "a \"quiescent\" stance"}, {"id": "mrqa_hotpotqa-validation-2902", "before_prediction": "Andy Cohen", "after_prediction": "Stephanie Boyriven"}], "retained_ids": ["mrqa_squad-validation-6297", "mrqa_triviaqa-validation-4196", "mrqa_hotpotqa-validation-3846", "mrqa_naturalquestions-validation-824", "mrqa_squad-validation-10403", "mrqa_hotpotqa-validation-3146"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_squad-validation-3625", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-1293", "mrqa_hotpotqa-validation-3898", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_squad-validation-3558", "mrqa_hotpotqa-validation-1142", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.4999999995833333}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity", "france france", "46.8", "6.4 nanometers", "in the eighth and eleventh episodes of the season", "Carl Michael Edwards II", "400", "glucocorticoids", "liberal pursuits", "Fells", "Richard, Duke of Gloucester", "St. Louis County", "1828", "2018", "wolverhampton Wanderers", "law", "Pottawatomie County", "orangutan", "theory of general relativity", "The church tower", "walford", "Toronto", "wales", "110 miles (177 km)", "the Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "liberal conservative", "largest gold rushes the world has ever seen", "six degrees of freedom", "plea of not guilty", "psychotherapeutic", "Quentin Coldwater", "acidic"], "metric_results": {"EM": 0.28125, "QA-F1": 0.3583241959064327}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.10526315789473685, 0.0, 1.0, 0.0, 0.0, 0.0, 0.25, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.2666666666666667, 1.0, 0.4444444444444445, 0.4, 0.3333333333333333, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032"], "after_eval": {"predictions": ["computability theory", "tipo 158", "won gold in the half - pipe", "6.4 nanometers apart", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400 games", "kidneys", "artes liberales", "\"Switzerland of England\"", "Edward IV of England", "Eureka", "1828", "three NFL Championships, the precursor to the Super Bowl, in four appearances", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "theory of general relativity", "The church tower", "EastEnders", "Montreal", "slow", "110 miles", "Kona coast", "Liberal conservatism", "gold rushes", "six", "creative plea", "freudian psychoanalysis", "New York", "acidic bogs"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8490489130434783}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.8, 0.8695652173913043, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8869", "before_prediction": "6.4 nanometers", "after_prediction": "6.4 nanometers apart"}, {"id": "mrqa_hotpotqa-validation-3789", "before_prediction": "400", "after_prediction": "400 games"}, {"id": "mrqa_naturalquestions-validation-6991", "before_prediction": "2018", "after_prediction": "three NFL Championships, the precursor to the Super Bowl, in four appearances"}, {"id": "mrqa_triviaqa-validation-316", "before_prediction": "walford", "after_prediction": "EastEnders"}, {"id": "mrqa_hotpotqa-validation-4812", "before_prediction": "liberal conservative", "after_prediction": "Liberal conservatism"}, {"id": "mrqa_hotpotqa-validation-187", "before_prediction": "acidic", "after_prediction": "acidic bogs"}], "retained_ids": ["mrqa_hotpotqa-validation-5401", "mrqa_squad-validation-10369", "mrqa_squad-validation-5313"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_naturalquestions-validation-6089", "mrqa_hotpotqa-validation-5513", "mrqa_triviaqa-validation-7506", "mrqa_naturalquestions-validation-1360", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_squad-validation-2987", "mrqa_naturalquestions-validation-7906", "mrqa_squad-validation-6915", "mrqa_hotpotqa-validation-1032"], "unfixed_ids": ["mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-856", "mrqa_triviaqa-validation-7767"], "instant_fixing_rate": 0.8695652173913043, "instant_retention_rate": 0.3333333329629629}, {"timecode": 9, "before_eval": {"predictions": ["The name ICQ derives from the English phrase `` I Seek You ''", "Argentinian", "The report claimed that these noise levels would have a negative long-term impact on the health of the city's residents", "ricotta cream", "photosynthesis", "a wide range of society figures of the period", "gilded maze of a place that is rumored to be haunted by a dead maid", "The Krypto Report", "antibonding", "flour and water", "The president", "the citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "Boston Cold Storage and Warehouse Co.", "Los Angeles", "C. W. Grafton", "LED illuminated display", "Americans acting under orders", "iPod Classic", "My Sassy Girl", "prevent damage to the body", "The Edge of Night", "Highly combustible materials", "pedagogy", "\u039c\u03ad\u03b3\u03b1\u03bd \u0399\u03b5\u03c1\u03cc\u03bd \u03a3\u03c5\u03bd\u03ad\u03ba\u03b4\u03b7\u03bc\u03bf\u03bd", "the root respiration", "all land - living organisms, both alive and dead, as well as carbon stored in soils", "death disease", "medium and heavy-duty diesel trucks", "sex organs, such as ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis"], "metric_results": {"EM": 0.25, "QA-F1": 0.36871550120631}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.125, 0.0, 0.0, 1.0, 0.35294117647058826, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 0.7692307692307692, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.3333333333333333, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-8474", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "Argentine", "a report", "cake", "consumes ATP and oxygen, releases CO2, and produces no sugar", "different animals and humans performimg various actions", "White House", "The Daily Stormer", "triplet", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "almost all officeholders annually", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "Worcester Cold Storage and Warehouse Co. fire", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Americans acting under orders", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP", "all land - living organisms, both alive and dead, as well as carbon stored in soils", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8794106606606606}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-832", "before_prediction": "Argentinian", "after_prediction": "Argentine"}, {"id": "mrqa_squad-validation-3442", "before_prediction": "antibonding", "after_prediction": "triplet"}, {"id": "mrqa_naturalquestions-validation-4520", "before_prediction": "the citizens", "after_prediction": "almost all officeholders annually"}], "retained_ids": ["mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-133", "mrqa_naturalquestions-validation-1327", "mrqa_squad-validation-5940", "mrqa_hotpotqa-validation-5823"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_squad-validation-5210", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-2449", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8474"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.6249999992187499}, {"timecode": 10, "before_eval": {"predictions": ["well", "yellow fever", "three legal systems", "Summerlin", "An optional message body", "globetrotters", "Anthony Bellew", "a bridge over the Merderet in the fictional town of Ramelle", "Benito Mussolini", "socrates", "menhirs", "the Duke and Duchess of Gloucester", "10 logarithm of the molar concentration, measured in units of moles per liter", "Kon-Tiki", "the MGM Grand Garden Special Events Center", "white Fairy Tale Love Ball", "Ronnie Hillman", "all-encompassing", "Mormons and the Miraculous", "more than 60 percent of the state's total land surface", "Eagle Ridge Mall", "England's World Cup winning side of 1966", "the public food supply", "Monastir", "the classical element fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present ), and must sign a waiver prior to shooting", "Ward", "an American novelist and poet", "Jamestown", "Rouen", "tree growth stages"], "metric_results": {"EM": 0.09375, "QA-F1": 0.18361742424242425}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.9333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-6389", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["alexander", "Hampton's hump and Hampton's line", "English law", "Las Vegas", "A status line", "the best known globetrotters", "cruiserweight", "over the Merderet in the fictional town of Ramelle", "Benito Mussolini", "victor Hugo quotes", "norman", "British Royal Family", "greater than 14", "thor heyerdahl", "Grand Garden Special Events Center", "valentino", "C. J. Anderson", "a maze of semantical problems and grammatical niceties", "joseph smith", "60% of the state's total land surface", "Winter Haven Mall", "Pel\u00e9", "aiding the war effort", "tunisia", "the classical element fire", "Barney Fife", "Typically, no", "Ann", "writer", "Virginia", "Claude Monet", "carbon related"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9401785714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4791", "before_prediction": "menhirs", "after_prediction": "norman"}], "retained_ids": ["mrqa_triviaqa-validation-4583", "mrqa_squad-validation-3525"], "fixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_naturalquestions-validation-8006", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-2016", "mrqa_naturalquestions-validation-5651", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_triviaqa-validation-3515", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-273", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-6119", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-1553", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6639", "mrqa_squad-validation-4506"], "unfixed_ids": ["mrqa_triviaqa-validation-6389", "mrqa_squad-validation-3018"], "instant_fixing_rate": 0.9310344827586207, "instant_retention_rate": 0.6666666644444444}, {"timecode": 11, "before_eval": {"predictions": ["1967", "\"Traumnovelle\"", "a Gender pay gap in favor of males in the labor market", "Treaty on the Functioning of the European Union (TFEU)", "absolute zero", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "joseph houdini", "The world's longest suspension bridges are listed according to the length of their main span", "Dublin", "cricket bats", "catfood", "the Bulgars, and especially the Seljuk Turks", "victorians agree on a few basic facts", "Volkswagen Beetle", "alexander", "the North American Free Trade Agreement ( NAFTA )", "jerry 1953", "infection, irritation, or allergies", "the most - visited paid monument in the world", "Galleria Vittorio Emanuele II", "catfish aquaculture", "atomic number 53", "James and D.J. Looney as Young Sparrow and DJ Dragon Nutz", "Kuwait", "a co-op of grape growers", "norway", "nabucodonosor", "1952", "the Los Angeles Lakers", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Jean F kernel ( 1497 -- 1558 ), a French physician", "chest, back, shoulders, torso and / or legs"], "metric_results": {"EM": 0.1875, "QA-F1": 0.31186732021530617}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.23529411764705882, 0.0, 0.14285714285714288, 1.0, 0.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.08695652173913043, 0.22222222222222224, 0.25]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6442"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "eat porridge", "span", "ferdinand", "duke of edinburgh", "king Crimson", "the Seljuk Turks", "alamo", "ferdinand porsche", "arkansas", "Canada", "britten", "infection", "visited paid monument", "Town House Galleria", "farm - raised catfish", "heaviest of the stable halogens", "the Bellas", "Iraq", "An agricultural cooperative", "norway", "giuseppe verdi", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean Fernel ( 1497 -- 1558 ), a French physician", "legs"], "metric_results": {"EM": 0.875, "QA-F1": 0.8995535714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6692", "before_prediction": "Dublin", "after_prediction": "ferdinand"}, {"id": "mrqa_hotpotqa-validation-3191", "before_prediction": "Galleria Vittorio Emanuele II", "after_prediction": "Town House Galleria"}, {"id": "mrqa_triviaqa-validation-7703", "before_prediction": "Kuwait", "after_prediction": "Iraq"}], "retained_ids": ["mrqa_hotpotqa-validation-2852", "mrqa_triviaqa-validation-792", "mrqa_hotpotqa-validation-4274"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-5248", "mrqa_squad-validation-1003", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-5184", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_triviaqa-validation-5526", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-6442"], "unfixed_ids": ["mrqa_naturalquestions-validation-5769"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.49999999916666665}, {"timecode": 12, "before_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "sabre", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "2013", "The stability, security, and predictability of British law and government enabled Hong Kong to flourish as a centre for international trade", "Minos and Kokalos", "29 June 1941", "cienfuegos", "a youth club", "New South Wales", "garrisons", "Edward Mordrake", "canada", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "the Czech Kingdom (Czech: \"\u010cesk\u00e9 kr\u00e1lovstv\u00ed\" ; German: \"K\u00f6nigreich B\u00f6hmen\" ; Latin: \" Regnum Bohemiae\"", "Bob Hill", "secularism and secular nationalism", "for creative reasons and `` not a reflection '' of the actress'performance", "immunological memory", "uncle", "a musician", "winter", "December 1, 1969", "maryland", "alexander", "California State Automobile Association and the Automobile Club of Southern California", "faith", "Cinderella", "The astronauts were asphyxiated before the hatch could be opened", "a fear of seeming rude"], "metric_results": {"EM": 0.34375, "QA-F1": 0.46431298318286807}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.37037037037037035, 0.6666666666666666, 0.34782608695652173, 0.0, 0.0, 0.0, 0.0, 0.4615384615384615, 1.0, 0.0, 0.0, 1.0, 0.3076923076923077, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.16666666666666666, 0.47058823529411764]}}, "error_ids": ["mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_hotpotqa-validation-4904", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "fencing", "John Major", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cigars", "byker grove", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Czech Kingdom", "Gregg Popovich", "secularism", "creative reasons", "immunological memory", "uncle", "Originally a musician", "thumbelina", "1973", "maryland", "john buchan", "AAA Auto Clubs", "alone", "Cinderella", "delayed the sealing of the hatch", "a suspect's talking to criminal investigators"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4826", "before_prediction": "Margaret Thatcher", "after_prediction": "John Major"}, {"id": "mrqa_hotpotqa-validation-2886", "before_prediction": "Bob Hill", "after_prediction": "Gregg Popovich"}], "retained_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-2737", "mrqa_squad-validation-9793", "mrqa_squad-validation-6678", "mrqa_hotpotqa-validation-4241", "mrqa_triviaqa-validation-6556", "mrqa_hotpotqa-validation-4165"], "fixed_ids": ["mrqa_triviaqa-validation-1671", "mrqa_squad-validation-568", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_triviaqa-validation-6902", "mrqa_hotpotqa-validation-1099", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_hotpotqa-validation-4904", "mrqa_naturalquestions-validation-5175", "mrqa_hotpotqa-validation-3870", "mrqa_triviaqa-validation-4402", "mrqa_naturalquestions-validation-2717", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8181818174380164}, {"timecode": 13, "before_eval": {"predictions": ["Sister, Sister ( 1982 film)", "president of Guggenheim Partners", "Buddy Pine / Incredi - Boy / Syndrome", "Napoleon's army", "savicothe baking", "3.7% of the entire student population", "a negative effect on subsequent long-run economic growth", "Garthy & Travis", "Ecumenical Award", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni", "discipline problems with the Flight Director's orders during their flight", "9", "bear", "amyotrophic lateral sclerosis (ALS)", "\"Odorama\"", "Swiss made", "the Evel Knievel craze of the mid 1970s", "religious", "the western coast of Italy", "American-born", "the quintessential New Orleans art form -- a jazz funeral without a body", "late November or early December", "the Winklevoss twins", "breadel", "the real-life story of Tim \"Ripper\" Owens, singer in a Judas Priest tribute band who was chosen to replace singer Rob Halford when he left the band", "Seattle", "King George's War", "Jackson pretends to be Rico's father for two - thousand dollars so he can get money to see Siena modeling in Peru", "alternative rock", "Fort Saint Anthony", "pinhole camera", "infrequent rain"], "metric_results": {"EM": 0.3125, "QA-F1": 0.40233585858585863}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, true], "QA-F1": [0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.4444444444444445, 0.0, 1.0, 0.4444444444444445, 0.3636363636363636, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-830", "mrqa_triviaqa-validation-7638", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-2037", "mrqa_naturalquestions-validation-150", "mrqa_naturalquestions-validation-9897", "mrqa_triviaqa-validation-2779", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-6913"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "presliced bread", "3.7", "negative", "garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "nine", "Michael Hordern", "Lou Gehrig's Disease", "Odorama", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "The second line's style of traditional dance, in which participants walk and sometimes twirl a parasol or handkerchief in the air", "late November or early December", "facebook", "bread making", "Tim \"Ripper\" Owens", "Issaquah", "King George's War", "Miley finally ends it with him", "Punk", "Fort Saint Anthony", "henry fox talbot", "infrequent rain"], "metric_results": {"EM": 0.875, "QA-F1": 0.9146634615384616}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-7310", "before_prediction": "alternative rock", "after_prediction": "Punk"}], "retained_ids": ["mrqa_hotpotqa-validation-4058", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_squad-validation-1850", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_squad-validation-10168", "mrqa_hotpotqa-validation-3669", "mrqa_squad-validation-2656"], "fixed_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_squad-validation-7042", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4301", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-2037", "mrqa_naturalquestions-validation-150", "mrqa_triviaqa-validation-2779", "mrqa_triviaqa-validation-2896", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-6913"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_triviaqa-validation-7638", "mrqa_naturalquestions-validation-9897"], "instant_fixing_rate": 0.8636363636363636, "instant_retention_rate": 0.8999999991}, {"timecode": 14, "before_eval": {"predictions": ["Beauty and the Breast", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "Chicago's first permanent non-native settler", "dark blood", "FX option", "electromagnetic waves", "Wahhabi/ Salafi", "tintraskelion (Swastika)", "Dimensions in Time", "Apollo 12", "the end of January 1981", "luteinizing hormone", "baptism in the Small Catechism", "Martin Luther", "Nottingham Forest", "A compression release engine brake", "Cheyenne rivers", "Faunal succession", "Hanna-barbera", "Northern Italy", "efficient and effective management of money ( funds )", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "Death", "1879", "Kur\u00e1nyi", "the state sector", "October", "poverty", "a god of the Ammonites", "vitreous humor", "Judge Doom", "Charles Joseph Whitman"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3627817035905271}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.16666666666666669, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.4, 0.0, 0.4, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.5714285714285715, 0.18181818181818182, 0.5882352941176471, 0.0, 0.0, 1.0, 0.5, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_hotpotqa-validation-5256"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "a foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/ Salafi extremist militant group", "swastika", "Children in Need", "the Surveyor 3 unmanned lunar probe", "1981", "estrogen", "baptism", "a Lutheran pastor in Hochfelden", "brian clough", "slowing the vehicle", "belle fourche and Cheyenne", "organisms", "Hanna-barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Kur\u00e1nyi", "public sector ( also called the state sector )", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.90625, "QA-F1": 0.925}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3999", "before_prediction": "Apollo 12", "after_prediction": "the Surveyor 3 unmanned lunar probe"}, {"id": "mrqa_squad-validation-2509", "before_prediction": "Martin Luther", "after_prediction": "a Lutheran pastor in Hochfelden"}], "retained_ids": ["mrqa_triviaqa-validation-46", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-5191", "mrqa_triviaqa-validation-2996", "mrqa_hotpotqa-validation-3877"], "fixed_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_hotpotqa-validation-5256"], "unfixed_ids": ["mrqa_squad-validation-9751"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.7142857132653061}, {"timecode": 15, "before_eval": {"predictions": ["superhuman abilities", "Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Akon", "noratosthenes", "the editor of Electrical World magazine", "l\u00e1szl\u00f3 de Alm\u00e1sy", "masons'marks", "Theodore Haynes", "a roof extension", "the Phenix Horns from Earth, Wind & Fire", "the female cervix, uterus and uterine tubes", "after the Spanish -- American War in the 1898 Treaty of Paris", "martial artist", "Spanish", "to steal the plans for the Death Star, the Galactic Empire's superweapon", "diahann Carroll", "postage stamp", "belgium", "chimpanzees", "After World War II", "absolute temperature", "the private intelligence firm Stratfor", "J. Robert Oppenheimer", "premolar teeth", "Aegisthus", "3 December", "tallahassee", "prefabricated housing projects", "1400s", "WOTV"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4348214285714286}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.19999999999999998, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome and city of San Antonio", "Royce da 5'9\" (Bad) and Eminem (Evil)", "galileo", "editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "a roof extension", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "1898", "martial artist", "Spanish", "stunt performances", "fred Astaire", "postage stamp", "belgium", "Chimpanzee (or chimps)", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolar teeth", "Aegisthus", "25 November 2015", "florida", "an Eastern Bloc city", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9151785714285714}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1479", "before_prediction": "the Alamodome", "after_prediction": "the Alamodome and city of San Antonio"}, {"id": "mrqa_hotpotqa-validation-5188", "before_prediction": "chimpanzees", "after_prediction": "Chimpanzee (or chimps)"}, {"id": "mrqa_hotpotqa-validation-413", "before_prediction": "3 December", "after_prediction": "25 November 2015"}], "retained_ids": ["mrqa_hotpotqa-validation-3456", "mrqa_squad-validation-1374", "mrqa_squad-validation-5249", "mrqa_hotpotqa-validation-4537", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-1736", "mrqa_naturalquestions-validation-9451"], "fixed_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_triviaqa-validation-5979", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-1048", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_hotpotqa-validation-573", "mrqa_triviaqa-validation-83", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-2957", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-874", "mrqa_triviaqa-validation-1588", "mrqa_squad-validation-6091"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7692307686390532}, {"timecode": 16, "before_eval": {"predictions": ["drag", "belgium", "blessed", "the back of the head of the tibia", "fergus Mor", "the North Sea, through the former Meuse estuary, near Rotterdam", "a massive area of semi-arid savanna covering parts of Namibia, Botswana, and South Africa", "Colin Montgomerie", "March 30, 1983", "Amway", "High school", "Milton Friedman", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha", "BBC Radio's \"The Show Band Show\"", "Tanzania", "Chad", "everglades", "an open work crown", "Sam's soul is not with him", "Fulham", "French, English and Spanish", "Tom Baker", "Beyond the Clouds", "What's Up (TV series)", "Supply chain management", "galileo", "poland", "the Jade Mirror of the Four Unknowns", "Michael J. Fox", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru", "sheepskin and Merino Wool", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4350503663003663}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.14285714285714288, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7692307692307692, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8095238095238095, 0.4, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_naturalquestions-validation-3483", "mrqa_triviaqa-validation-6125", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087", "mrqa_hotpotqa-validation-1250"], "after_eval": {"predictions": ["nightclub", "belgium", "illumin", "leg", "dunkeld", "North Sea", "botswana", "sandy lyle", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio", "Tanzania", "niger", "everglades", "top row of windows", "Sam's soul is not with him", "London", "French, English and Spanish", "dave lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "flowing water", "poland", "matrices", "geena davis", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "Sheepskin", "Honolulu County, Hawaii, United States,"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8940781440781441}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2324", "before_prediction": "blessed", "after_prediction": "illumin"}, {"id": "mrqa_hotpotqa-validation-1566", "before_prediction": "BBC Radio's \"The Show Band Show\"", "after_prediction": "BBC Radio"}, {"id": "mrqa_hotpotqa-validation-2287", "before_prediction": "the \"second city\" of Oahu", "after_prediction": "Honolulu County, Hawaii, United States,"}], "retained_ids": ["mrqa_triviaqa-validation-2551", "mrqa_hotpotqa-validation-2717", "mrqa_squad-validation-8037", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-4055", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-2937", "mrqa_triviaqa-validation-866"], "fixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_naturalquestions-validation-9218", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-4094", "mrqa_naturalquestions-validation-3483", "mrqa_triviaqa-validation-6125", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_hotpotqa-validation-1250"], "unfixed_ids": ["mrqa_triviaqa-validation-313", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.7272727266115702}, {"timecode": 17, "before_eval": {"predictions": ["pear", "Teenage Mutant Ninja Turtles: Out of the Shadows and 10 Cloverfield Lane", "August 6, 1845", "gamma ray emission ( energy of 514 keV )", "James Zeebo", "sovereign states", "president of the United States", "\"Teach the Controversy\" campaign", "Bumblebee", "British and American television productions", "36 months for men and 24 months for women respectively", "vary", "lower rates", "private liberal arts college", "Roy Spencer", "\"antiforms\"", "fifth season", "S Pictures' \"Veyyil\" (2006)", "James Weldon Johnson", "Keith Richards", "n > 3", "Bangor International Airport", "specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "antimeridian", "Cartoon Network", "Presiding Officer", "the Phoenix Suns", "33", "dactylosphaera vitifoliae", "The Annual Conference Cabinet", "field hockey player", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.5, "QA-F1": 0.564291410344042}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333334, 0.0, 1.0, 0.0, 0.0, 0.9473684210526316, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.4, 1.0, 0.0, 1.0, 0.25, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-validation-9171", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130"], "after_eval": {"predictions": ["pear", "Independence Day: Resurgence", "August 6, 1845 - October 6, 1931", "rubidium - 85", "James Zeebo", "sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "Dick Cheney", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower rates", "575 acres (2.08 km\u00b2)", "Roy Spencer", "\"antiforms\"", "the second half of the third season", "Veyyil", "Grace Nail Johnson", "Rocky Dzidzornu -- congas", "n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "the Phoenix Suns", "33-member", "grapevine", "Area Provost/ Dean (if one is appointed)", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8954945799457995}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8780487804878049, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5628", "before_prediction": "August 6, 1845", "after_prediction": "August 6, 1845 - October 6, 1931"}, {"id": "mrqa_hotpotqa-validation-4868", "before_prediction": "James Weldon Johnson", "after_prediction": "Grace Nail Johnson"}, {"id": "mrqa_squad-validation-9405", "before_prediction": "Presiding Officer", "after_prediction": "the Presiding Officer on the advice of the parliamentary bureau"}, {"id": "mrqa_squad-validation-10074", "before_prediction": "The Annual Conference Cabinet", "after_prediction": "Area Provost/ Dean (if one is appointed)"}], "retained_ids": ["mrqa_triviaqa-validation-1298", "mrqa_naturalquestions-validation-430", "mrqa_hotpotqa-validation-113", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_squad-validation-8966", "mrqa_naturalquestions-validation-10347", "mrqa_hotpotqa-validation-3573", "mrqa_hotpotqa-validation-613", "mrqa_squad-validation-7664"], "fixed_ids": ["mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_triviaqa-validation-314", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-1090", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_naturalquestions-validation-9171", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-1130"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_hotpotqa-validation-3440"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.74999999953125}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "Co-teaching is defined as two or more teachers working harmoniously to fulfill the needs of every student in the classroom.", "500 metres", "Piper", "entertainment", "displacement", "12", "The V&A has its origins in the Great Exhibition of 1851, with which Henry Cole, the museum's first director, was involved in planning", "King Edward I to Henry VIII", "diego garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay", "Spy Kids", "austin", "Olivia", "the Swiss cantons of Thurgau and St. Gallen", "lithium-ion battery", "821", "the basic channels", "pressure", "Kim Hyun-ah", "highest'social efficiency'", "the scale used for a composition is usually indicated by a key signature at the beginning to designate the pitches that make up that scale. As the music progresses, the pitches used may change and introduce a different scale", "King of Cool", "the American delegation from the Paris Peace Conference", "socrates", "the fifth season", "kray twins", "Eisstadion Davos", "Michael Patrick Smith", "Firoz Shah Tughlaq"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6080901983218917}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true], "QA-F1": [0.2, 0.10526315789473684, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08695652173913045, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-2715", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-1855", "mrqa_squad-validation-9841", "mrqa_naturalquestions-validation-4497", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446"], "after_eval": {"predictions": ["Rwandan genocide", "harmoniously", "500 metres", "Piper", "ABC News", "displacement", "five", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "diego garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay Castle", "Spy Kids", "venus Williams", "Olivia", "Baden-W\u00fcrttemberg", "lithium-ion battery factory", "821", "basic channels", "pressure", "Hyuna", "races of highest'social efficiency\"", "transposed", "King of Cool", "American delegation from the Paris Peace Conference", "Socrates", "thirteenth", "violet", "HC Davos", "Michael Patrick Smith", "Firoz Shah Tughlaq"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9729166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2683", "before_prediction": "fotheringhay", "after_prediction": "fotheringhay Castle"}, {"id": "mrqa_hotpotqa-validation-4415", "before_prediction": "lithium-ion battery", "after_prediction": "lithium-ion battery factory"}], "retained_ids": ["mrqa_hotpotqa-validation-523", "mrqa_hotpotqa-validation-2145", "mrqa_naturalquestions-validation-5360", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_hotpotqa-validation-2201", "mrqa_naturalquestions-validation-2222", "mrqa_hotpotqa-validation-44", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-4068", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-511", "mrqa_naturalquestions-validation-10490"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-2715", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_hotpotqa-validation-3798", "mrqa_triviaqa-validation-7100", "mrqa_hotpotqa-validation-3446"], "unfixed_ids": ["mrqa_squad-validation-9841"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.8888888883950616}, {"timecode": 19, "before_eval": {"predictions": ["a Ghanaian boxer", "Norman Macdonnell and writer John Meston", "aragon", "11.1", "trans-Pacific flight from the United States to Australia", "Soha Ali Khan Khemu", "students normally have to sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "a sufficient condition for p to be prime", "Tropical Storm Ann", "Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "mame Therese Peltier", "Six Degrees of Separation", "david bowie", "Indian", "wisdom, understanding, counsel, fortitude, knowledge, piety, and fear of the Lord", "1889", "Nicki Minaj", "slave of duty", "French Huguenot ancestry", "Monaco Grand Prix", "austin", "Teen Titans Go!", "William the Conqueror", "Tel Aviv", "two degrees of freedom", "peninsula", "taking blood", "youngest TV director ever", "Southern Progress Corporation"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5804494664692033}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.5, 0.0, 0.0, 0.4444444444444445, 0.8571428571428571, 0.10526315789473684, 1.0, 0.2857142857142857, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_hotpotqa-validation-5710", "mrqa_naturalquestions-validation-3951", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q.", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "David Bowie", "Indian", "fear", "1889", "Sir Mix - a-Lot", "slave of duty", "names", "portier", "marx", "Teen Titans Go!", "Norman invaders", "It is the largest airport in Tel Aviv proper, and the second largest in the area", "two", "peninsula", "taking blood", "youngest TV director ever", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.9375, "QA-F1": 0.95625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5061", "before_prediction": "Tel Aviv", "after_prediction": "It is the largest airport in Tel Aviv proper, and the second largest in the area"}, {"id": "mrqa_hotpotqa-validation-2627", "before_prediction": "Southern Progress Corporation", "after_prediction": "Sunset Publishing Corporation"}], "retained_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_squad-validation-5538", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-3049", "mrqa_naturalquestions-validation-4951", "mrqa_triviaqa-validation-2015", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-2064", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "fixed_ids": ["mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_squad-validation-9214", "mrqa_hotpotqa-validation-5710", "mrqa_naturalquestions-validation-3951", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-8025", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_naturalquestions-validation-1565", "mrqa_naturalquestions-validation-7881"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8666666660888889}, {"timecode": 20, "before_eval": {"predictions": ["reciprocating", "David Feldman", "the Sackler Centre for arts education", "Mos Def ( ) (born Dante Terrell Smith", "kalos", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "AS-205", "Ribosomes", "kookaburra (Dacelo novaeguineae)", "six", "Shalita Grant as Sonja Percy, ATF Agent / NCIS Special Agent ( seasons 2 -- 4 ; recurring previously )", "is the fourth studio album by American country music artist John Michael Montgomery", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "gerry adams", "Moon's surface", "Lucius Cornelius Sulla Felix ( ; c. 138 BC \u2013 78 BC) known commonly as Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "mother tongues", "my personal presence and living word", "karl marx", "a CMYKOG process", "It is known as `` Smith's Folly ''.", "\" My Love from the Star\" (2013)", "San Jose", "sea wasp", "The Hawai\u02bbi State Senate", "a \"teleforce\" weapon", "The Bridgewater Triangle refers to an area of about 200 mi2 within southeastern Massachusetts in the United States, claimed to be a site of alleged paranormal phenomena", "The Super Bowl 50 Host Committee has vowed to be \"the most giving Super Bowl ever\" and will dedicate 25 percent of all money it raises for philanthropic causes", "households were made up of individuals and 7.9% had someone living alone who was 65 years of age or older", "Margaret \"hot Lips\" Houlihan"], "metric_results": {"EM": 0.25, "QA-F1": 0.37346511994949494}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.5, 0.0, 0.48484848484848486, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.13333333333333333, 0.6666666666666666, 1.0, 1.0, 0.9090909090909091, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3125, 0.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_squad-validation-3964", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "(prints, drawings, paintings and photographs)", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Gemini and Apollo programs", "Ribosomes", "kookaburra", "six-time", "Scott Bakula", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "gerry adams", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "mother tongues", "personal presence and living word", "turkey", "Pantone Matching System (PMS)", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "upper chamber", "\"teleforce\" weapon", "Native American", "giving", "29.7%", "4077th mash"], "metric_results": {"EM": 0.90625, "QA-F1": 0.921875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4558", "before_prediction": "a CMYKOG process", "after_prediction": "Pantone Matching System (PMS)"}], "retained_ids": ["mrqa_hotpotqa-validation-2434", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_hotpotqa-validation-2795", "mrqa_squad-validation-8464", "mrqa_squad-validation-1521"], "fixed_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_naturalquestions-validation-4590", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-1210", "mrqa_naturalquestions-validation-1279", "mrqa_hotpotqa-validation-4627", "mrqa_hotpotqa-validation-2407", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "unfixed_ids": ["mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-1906"], "instant_fixing_rate": 0.9166666666666666, "instant_retention_rate": 0.8749999989062499}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "daphne du maurier - Rebecca", "domestic cat", "blood transfusion", "alison moyet", "1926", "black holes", "dreams", "as defence of their North American colonies would no longer be an issue and also because they already had ample places from which to obtain sugar", "Johnny Cash, Waylon Jennings", "ill. (some col.)", "public and private", "French", "Lewis", "Beatrix Potter", "World Summit of Nobel Peace Laureates", "proteins", "2001", "if there were only finitely many primes then \u03b6(1) would have a finite value", "ITV News at Ten", "padlocking the gates", "1950s", "skogsr\u00e5", "western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Protestant", "casino Royale", "4 in ( 10 cm )", "fillies", "eating both fish larvae and small crustaceans", "\"Menace II Society\"", "quarterback", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5526383757525999}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, true], "QA-F1": [0.14285714285714288, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3111111111111111, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.41379310344827586, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.25, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_squad-validation-10502", "mrqa_triviaqa-validation-2961", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-10177", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "rebecca", "domestic cat", "transfusion of blood", "alison moyet", "1926", "black holes", "dreams", "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auctioneers", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "Organizations could come together to address global issues", "proteins", "2001", "exceeds any given number", "alastair burnet", "padlocking the gates", "1969", "R\u00e5", "western portions of the Great Lakes region (an area not directly subject to the conflict between the French and British) including the Huron, Mississauga, Ojibwa, Winnebago, and Potawatomi", "Orthodox", "casino Royale", "4 in", "oh so Sharp", "ctenophore Mnemiopsis leidyi", "\"Menace II Society\"", "starting quarterback for the Eagles and Cleveland Browns", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9191810344827587}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.41379310344827586, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8456", "before_prediction": "Protestant", "after_prediction": "Orthodox"}], "retained_ids": ["mrqa_hotpotqa-validation-3780", "mrqa_triviaqa-validation-751", "mrqa_triviaqa-validation-4383", "mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-192", "mrqa_squad-validation-2412", "mrqa_hotpotqa-validation-5480", "mrqa_squad-validation-5345", "mrqa_squad-validation-3627", "mrqa_naturalquestions-validation-5897", "mrqa_squad-validation-6844", "mrqa_triviaqa-validation-6950", "mrqa_hotpotqa-validation-2642", "mrqa_hotpotqa-validation-4676"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_triviaqa-validation-5239", "mrqa_squad-validation-10502", "mrqa_squad-validation-2709", "mrqa_hotpotqa-validation-4950", "mrqa_naturalquestions-validation-5439", "mrqa_hotpotqa-validation-35", "mrqa_squad-validation-9020", "mrqa_triviaqa-validation-1954", "mrqa_naturalquestions-validation-8689", "mrqa_hotpotqa-validation-2399", "mrqa_naturalquestions-validation-6832", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758"], "unfixed_ids": ["mrqa_triviaqa-validation-2961", "mrqa_squad-validation-10177"], "instant_fixing_rate": 0.8823529411764706, "instant_retention_rate": 0.9333333327111111}, {"timecode": 22, "before_eval": {"predictions": ["Doug Pruzan", "England", "Thursday in May", "MSC Crociere S. p.A.", "brian marx", "Kitty Softpaws", "National Party of Australia", "Parliamentarians", "the presence of correctly oriented P waves", "either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "smert shpionam", "michael Strogoff", "Augustus Waters", "14 September 1547", "Tony Blair", "\u2018 Often damaging\u2019, along with alcohol, tobacco and gambling", "July 26, 1959", "Kenya", "a chronological collection of critical quotations about William Shakespeare and his works", "boudicca", "long - standing policy of neutrality", "Cargill", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "March 1, 2018", "heavy", "Blandings", "Dexter and Bernice", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5204308712121213}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.15, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 0.1818181818181818, 1.0, 0.0, 0.625, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-2769", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_triviaqa-validation-6872", "mrqa_hotpotqa-validation-2511", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Kitty Softpaws", "National Party of Australia", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "smersh", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1619", "benjamin frank, open, revealing and written in an intimate and accessible style", "often damaging", "July 26, 1959", "national parks", "chronological collection of critical quotations", "ethelbald I", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "pig", "Dexter", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4731", "before_prediction": "Tony Blair", "after_prediction": "benjamin frank, open, revealing and written in an intimate and accessible style"}], "retained_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-7346", "mrqa_squad-validation-2884", "mrqa_naturalquestions-validation-7731", "mrqa_triviaqa-validation-1578", "mrqa_hotpotqa-validation-482", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-1328", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1883", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-2797", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_squad-validation-2769", "mrqa_squad-validation-8280", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-2511", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_triviaqa-validation-2179", "mrqa_hotpotqa-validation-1929"], "unfixed_ids": ["mrqa_triviaqa-validation-6872"], "instant_fixing_rate": 0.9444444444444444, "instant_retention_rate": 0.9285714279081632}, {"timecode": 23, "before_eval": {"predictions": ["$105 billion", "mono", "about two-thirds the size", "austin seven", "dirty dancing", "zinc silicate primer and vinyl topcoats", "Steeplechase Park", "Academy Award for Best Animated Feature", "European Convention on Human Rights", "381.6 days", "nine other contenders from across the United States", "NASA", "celandine", "James `` Scotty '' Reston", "Ronald Ralph \"Ronnie\" Schell", "falciparum malaria", "Mumbai", "Leinster", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "possibly 1707, in his second annual cycle (1724 to 1725) Ach Gott, vom Himmel sieh darein", "Sunnyside", "till September", "live and let die", "Incudomalleolar joint", "bobby riggs", "Leucippus", "Santa Clara Marriott", "benjamin barenboim", "political power generated by wealth", "bound on the complexity of reductions", "Sanders"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5957692736185383}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 0.11764705882352941, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3716", "mrqa_squad-validation-8850", "mrqa_naturalquestions-validation-1617", "mrqa_squad-validation-542", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-769"], "after_eval": {"predictions": ["$105 billion", "kissing disease", "17 nm vs 25 nm", "austin seven", "dirty dancing", "red", "Steeplechase Park", "Academy Award for Best Animated Feature", "the European Convention on Human Rights", "(381.6 days)", "nine", "NASA", "yellow", "Khrushchev", "Jack Cassidy", "falciparum malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "till September", "live and let die", "Incudomalleolar joint", "moffitt", "Leucippus", "Santa Clara Marriott", "ludwig van beethoven", "political power generated by wealth", "the bound on the complexity of reductions", "Ted Ginn Jr."], "metric_results": {"EM": 0.9375, "QA-F1": 0.9657738095238095}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-7389", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_hotpotqa-validation-2741", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-validation-4048", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_hotpotqa-validation-2340", "mrqa_squad-validation-327", "mrqa_squad-validation-7481", "mrqa_squad-validation-1750"], "fixed_ids": ["mrqa_triviaqa-validation-3716", "mrqa_naturalquestions-validation-1617", "mrqa_squad-validation-542", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-769"], "unfixed_ids": ["mrqa_squad-validation-8850", "mrqa_naturalquestions-validation-1731"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.9999999994444444}, {"timecode": 24, "before_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemy", "WBO lightweight title", "spice islands", "Saturday", "Albany", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "1971", "The title comes from a quote from the book \"The Lord of the Rings: The Return of the King\"", "John Elway", "Instagram", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "31", "Eugene", "comparable to the seven Wonders of the World", "(primes of the form 2p + 1 with p prime) primorial primes, Fermat primes and Mersenne primes", "coupe", "Fa Ze YouTubers", "dante Alighieri", "the Muslim", "along the eastern coast of the continent, from Nova Scotia and Newfoundland in the north, to Georgia in the south", "the Friars Minor Conventual", "CD Castell\u00f3n", "between 1770 and 1848", "12\u20134", "having colloblasts", "Jon M. Chu", "STS-51-C", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather", "mitterr"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6516559829059829}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.7307692307692308, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3080", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Albany", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights", "1971", "J. R. Tolkien", "John Elway", "Instagram", "four years in high school", "31", "Eugene", "comparable to the seven Wonders of the World", "2p + 1 with p prime", "coupe", "FaZe Rug", "dante alighieri", "Muslim", "along the coast", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather, it will retreat to its den and winter will", "france"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9617242388758782}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9180327868852458, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_hotpotqa-validation-4444", "mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-309", "mrqa_naturalquestions-validation-2164", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_squad-validation-67", "mrqa_squad-validation-4417"], "fixed_ids": ["mrqa_triviaqa-validation-3678", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-3297", "mrqa_squad-validation-10148", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_naturalquestions-validation-3504", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-1814", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3080", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.7692307692307693, "instant_retention_rate": 0.9999999994736841}, {"timecode": 25, "before_eval": {"predictions": ["swimming", "amhmael", "over 50 million singles", "states'rights to expand slavery", "1923 and 1925", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "Frigate", "Buck Barrow", "iteratively", "red", "effect", "moreton bay", "Peter Davison, Colin Baker, Sylvester McCoy and Paul McGann", "August 14, 1848", "lower in more unequal countries", "juveniles are capable of reproduction before reaching the adult size and shape", "a breaded chicken patty", "John Wesley ( 1703 -- 1791 ) and his younger brother Charles ( 1707 -- 1788 )", "book of the musical \"A Chorus Line\"", "2,664", "iphone 6", "a chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning, support services, property services, catering services, security services and facility management services", "Symphony No. 7 in A major, Op. 92", "gironde", "1603", "above the two personal physicians of the Emperor", "flute", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4869854804960262}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.25, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8750000000000001, 0.3333333333333333, 0.33333333333333337, 0.7200000000000001, 1.0, 0.08, 0.33333333333333337, 1.0, 1.0, 0.2857142857142857, 0.3636363636363636, 0.47058823529411764, 0.6, 1.0, 1.0, 0.10526315789473684, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6941", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221"], "after_eval": {"predictions": ["gymnastic", "abram", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "crimson tide", "iteratively", "goose", "effect", "pacific", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "a lower level of economic growth when human capital is neglected for high-end consumption", "In at least some species, juveniles are capable of reproduction before reaching the adult size and shape", "a breaded chicken patty", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "a specific weak point on the inside of the chassis right beneath the volume buttons", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde", "1603", "status superior to all others in health-related fields such as physicians and acupuncturists", "nutcracker", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9427696078431372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-2454", "before_prediction": "iphone 6", "after_prediction": "a specific weak point on the inside of the chassis right beneath the volume buttons"}], "retained_ids": ["mrqa_hotpotqa-validation-3369", "mrqa_squad-validation-9532", "mrqa_squad-validation-7382", "mrqa_naturalquestions-validation-390", "mrqa_hotpotqa-validation-4282", "mrqa_triviaqa-validation-2098", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "fixed_ids": ["mrqa_triviaqa-validation-6059", "mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-5762", "mrqa_hotpotqa-validation-3977", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6941", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221"], "unfixed_ids": ["mrqa_squad-validation-7301", "mrqa_squad-validation-4637"], "instant_fixing_rate": 0.9090909090909091, "instant_retention_rate": 0.8999999991}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences, with the Romans serving as external arbiters on disputes concerning Jewish customs and law", "north of the Lakes Region and south of the Kancamagus Highway", "an investment technique outlined by Joel Greenblatt that uses the principles of value investing", "true history", "Honolulu", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz", "maryland", "4,000", "Khagan", "spain", "sweden", "kasia", "He was voiced by Phil Hartman and first appeared in the second season episode \"Homer vs. Lisa and the 8th Commandment\"", "The planner Raymond Unwin and the architect Barry Parker", "San Bernardino", "an extensive neoclassical centre referred to as Tyneside Classical largely developed in the 1830s by Richard Grainger and John Dobson, and recently extensively restored", "Albany High School", "Lalbagh Fort at Dhaka", "a non-commissioned officer in the United States Army's premier special operations unit", "an unmasked and redeemed Anakin Skywalker ( formerly Darth Vader )", "seek jury nullification", "Cee - Lo", "Anglican", "1955", "maryland", "abram", "located within nine coastal southern Nigerian states", "economic impact of the former type of entrepreneurialism tends to be redistributive while the latter is expected to foster technological progress and thus have a more positive impact on economic growth", "January 11, 1755 or 1757July 12, 1804"], "metric_results": {"EM": 0.1875, "QA-F1": 0.2928819444444445}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2222222222222222, 0.19999999999999998, 0.5, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.08333333333333334, 1.0, 0.0, 0.0, 0.4, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8333333333333333]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_naturalquestions-validation-800", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_naturalquestions-validation-7801", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "after_eval": {"predictions": ["to Jewish audiences", "south", "the principles of value investing", "kelly", "City and County of Honolulu", "1910\u20131940", "those who refuse vetting", "Catch Me Who Can", "blues", "margaret smith Court", "3,677 seated", "the founder of the Yuan dynasty", "catherine and heathcliff", "birmingham", "cinnamomum", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "Shopping Centre", "Albany High School", "charbagh", "Sergeant First Class", "Anakin Skywalker", "jury nullification", "the closing scene of the final episode of the first season", "The Church of England", "hattie mcdaniel", "scharnhorst", "hypnotic", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8645833333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3384", "before_prediction": "jazz", "after_prediction": "blues"}, {"id": "mrqa_squad-validation-6148", "before_prediction": "Khagan", "after_prediction": "the founder of the Yuan dynasty"}], "retained_ids": ["mrqa_squad-validation-7435", "mrqa_squad-validation-3176", "mrqa_naturalquestions-validation-2214", "mrqa_hotpotqa-validation-1446"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_hotpotqa-validation-2436", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_naturalquestions-validation-800", "mrqa_hotpotqa-validation-4585", "mrqa_naturalquestions-validation-3658", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_naturalquestions-validation-7801", "mrqa_squad-validation-7319", "mrqa_hotpotqa-validation-945"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6224", "mrqa_triviaqa-validation-3393"], "instant_fixing_rate": 0.8846153846153846, "instant_retention_rate": 0.6666666655555555}, {"timecode": 27, "before_eval": {"predictions": ["l.A. producer", "margaret smith", "blackberry", "horsehead", "\" Big Mamie\"", "orinoco river", "Teamsters leader", "a light sky-blue color caused by absorption in the red", "the Tower of London", "2013", "Zaza Pachulia", "inner chloroplast membrane", "ludwig degas", "sports", "no", "third", "the more fundamental electro weak interaction", "the availability of skilled tradespeople", "gypsum", "A simple iron boar crest", "new universities", "margaret", "David", "a touchback on kickoffs at the 25 - yard line", "the Latin centum", "about 7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "lives by faith", "margaret smith", "two goods ( such as butter and guns ) that can be produced with constant technology and resources per unit of time", "the Cathedral of Antwerp", "group"], "metric_results": {"EM": 0.46875, "QA-F1": 0.584375}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666665, 0.28571428571428575, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.7000000000000001, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "\" Big Mamie\"", "orinoco river", "Teamsters leader", "clear substances with a light sky-blue color caused by absorption in the red", "wat tyler", "2009", "Zaza Pachulia", "inner chloroplast membrane", "renoir", "sports", "no", "third", "electroweak interaction", "Cost of construction", "gypsum", "A simple iron boar crest", "polytechnics became new universities", "australian", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - yards line", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "lives by faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "rubens", "badgers"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9884049773755657}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-348", "mrqa_triviaqa-validation-2899", "mrqa_hotpotqa-validation-994", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_squad-validation-2966", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_hotpotqa-validation-3949", "mrqa_squad-validation-8279", "mrqa_squad-validation-2313"], "fixed_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-10312", "mrqa_squad-validation-6855", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-1507"], "unfixed_ids": ["mrqa_squad-validation-3539", "mrqa_naturalquestions-validation-9105"], "instant_fixing_rate": 0.8823529411764706, "instant_retention_rate": 0.9999999993333333}, {"timecode": 28, "before_eval": {"predictions": ["the Turk", "Anderson Silva", "nullification", "Kusha", "poet", "Professor Eobard Thawne", "plum", "US$10 a week raise", "1825", "member states", "oboe", "McKinsey's offices", "spider", "living doll", "Crohn's disease", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "Charles L. Hutchinson", "Song of Songs", "brown", "local talent", "Preston North End Football Club", "tARDIS", "meager", "that contemporary accounts were exaggerations", "commonwealth of maryland", "1332", "dodo bird", "a person can improve their own health, wealth and personal relationships", "rez Varney"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6295583607006021}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.13793103448275862, 0.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_squad-validation-6835", "mrqa_hotpotqa-validation-5637", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_triviaqa-validation-7669", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-7821", "mrqa_triviaqa-validation-4308"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "inform the jury and the public of the political circumstances", "Kusha", "poet, and writer", "Professor Eobard Thawne", "plum", "US$10 a week raise", "1825", "contributed by member states on a voluntary basis", "oboe", "McKinsey's offices", "fear of public speaking", "lionel Bart", "gastroschisis", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "Charles L. Hutchinson", "the Old Testament", "Pullman Brown", "local talent", "North End Football Club", "peter davison", "canada", "contemporary accounts were exaggerations", "lincoln", "1332", "dodo bird", "based on the idea that people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "stan butler"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9133254716981132}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22641509433962262, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-10687", "before_prediction": "Song of Songs", "after_prediction": "the Old Testament"}], "retained_ids": ["mrqa_hotpotqa-validation-1390", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-4919", "mrqa_triviaqa-validation-4827", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_squad-validation-4309", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_squad-validation-8031", "mrqa_squad-validation-5086", "mrqa_squad-validation-8190", "mrqa_triviaqa-validation-2953"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_squad-validation-6835", "mrqa_hotpotqa-validation-5637", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-4308"], "unfixed_ids": ["mrqa_triviaqa-validation-7669", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.8666666666666667, "instant_retention_rate": 0.941176470034602}, {"timecode": 29, "before_eval": {"predictions": ["holly", "the 1960s", "His patents", "Formula One", "Xbox 360", "Tokyo", "DeMarcus Ware", "parallelogram", "june raulston", "364", "Startup neutron source", "starry starry night", "the bore, and often the stroke, are increased in low-pressure cylinders resulting in larger cylinders", "storage of minerals", "Imperial Secretariat", "Doctorin' the Tardis", "National Basketball Development League", "gillingham", "St. Mary's County", "Ted Ginn Jr.", "The population was 2,615", "Pyeongchang", "an American football quarterback", "a password recovery tool for Microsoft Windows", "The Man", "husband and wife", "sarrenis", "olympic gold medal", "the smallest subfield", "heartburn", "53% in Botswana to -40% in Bahrain", "light reactions"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5513174019607843}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.058823529411764705, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-3344", "mrqa_squad-validation-8075", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-4572", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-7445", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "His patents", "Formula One", "microsoft", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram rule of vector addition", "evolution", "364", "Startup neutron source", "vincent", "cylinder", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "local administrative structure of past Chinese dynasties", "\" Doctorin' the Tardis\"", "National Basketball Development League", "kent", "Washington metropolitan area", "Emmanuel Sanders", "The population was 2,615 at the 2010 census", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods so as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "husband and wife", "south korea", "arthur", "the smallest subfield of a field F containing both 0 and 1", "heartburn", "53%", "normal grana and thylakoids"], "metric_results": {"EM": 0.8125, "QA-F1": 0.9146314775910365}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.9642857142857143, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-10408", "before_prediction": "parallelogram", "after_prediction": "parallelogram rule of vector addition"}, {"id": "mrqa_naturalquestions-validation-5826", "before_prediction": "storage of minerals", "after_prediction": "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation"}, {"id": "mrqa_hotpotqa-validation-3031", "before_prediction": "The population was 2,615", "after_prediction": "The population was 2,615 at the 2010 census"}, {"id": "mrqa_squad-validation-9036", "before_prediction": "the smallest subfield", "after_prediction": "the smallest subfield of a field F containing both 0 and 1"}], "retained_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_hotpotqa-validation-3497", "mrqa_squad-validation-814", "mrqa_triviaqa-validation-3103", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-7567", "mrqa_hotpotqa-validation-5709", "mrqa_triviaqa-validation-814"], "fixed_ids": ["mrqa_triviaqa-validation-6632", "mrqa_naturalquestions-validation-6610", "mrqa_triviaqa-validation-3603", "mrqa_squad-validation-3344", "mrqa_squad-validation-8075", "mrqa_triviaqa-validation-1280", "mrqa_naturalquestions-validation-5961", "mrqa_squad-validation-772", "mrqa_naturalquestions-validation-9765", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-2709", "mrqa_squad-validation-7445", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_triviaqa-validation-7032", "mrqa_naturalquestions-validation-4572"], "instant_fixing_rate": 0.8666666666666667, "instant_retention_rate": 0.7647058819031142}, {"timecode": 30, "before_eval": {"predictions": ["judiciary", "Fort Albany", "Steve Carell as Mayor Ned McDodd, the mayor of Whoville", "arpers Ferry Raid", "prunella Scales", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "SyFy", "co-release screenings occurred in London, New York City, and Stockholm", "demographics and economic ties", "three or more separate periods in office", "The Kickoff Game", "narcolepsy", "arctic monkeys", "monza", "Jurassic Park", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "A computer program is a collection of instructions that performs a specific task when executed by a computer. A computer requires programs to function.", "National Party of Australia", "king of Babylon", "geyser", "largest source of foreign direct investment, and... bilateral trade", "pike", "off the northeast coast of Australia", "Article 7, Paragraph 4", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Easy", "Sebastian Lund ( Rob Kerkovich ), a criminalist turned forensics agent and the team's newest member", "Prime Minister of India", "National Lottery", "Skylab", "catherine of aragon", "to facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.125, "QA-F1": 0.21710633116883116}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.1904761904761905, 0.0, 0.5, 0.0, 0.8, 0.0, 0.0, 0.4, 0.12121212121212122, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.4000000000000001]}}, "error_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "ABC", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "june park", "all transmissions", "A computer program", "The Greens", "babylon", "surtsey", "largest source of foreign direct investment", "national network", "South Pacific", "7", "New Jersey", "Netflix", "Shalita Grant", "indira gandhi", "state-franchised", "skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9459134615384616}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7793", "before_prediction": "SyFy", "after_prediction": "ABC"}, {"id": "mrqa_triviaqa-validation-1722", "before_prediction": "Jurassic Park", "after_prediction": "june park"}], "retained_ids": ["mrqa_triviaqa-validation-2750", "mrqa_triviaqa-validation-7530"], "fixed_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-3920", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_triviaqa-validation-1921", "mrqa_squad-validation-2577", "mrqa_hotpotqa-validation-4578", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-6888", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7090", "mrqa_squad-validation-8451", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608"], "instant_fixing_rate": 0.9642857142857143, "instant_retention_rate": 0.49999999875}, {"timecode": 31, "before_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "cybermen", "a horse is 15 hands, 4", "shopping", "explaining their actions", "Andrew Adamson", "waltz", "Naimans", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "parthenon", "the RAF", "encourage", "Ibrium", "strictly come dancing", "Polish", "the Falange", "is a song by Cole Porter", "1967", "16,000", "Washington Street", "May 10, 1976", "two", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "polly", "John Smith", "lusitania", "economic separation"], "metric_results": {"EM": 0.71875, "QA-F1": 0.779431216931217}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.37037037037037035, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-8589", "mrqa_naturalquestions-validation-954", "mrqa_triviaqa-validation-3286", "mrqa_hotpotqa-validation-3728", "mrqa_squad-validation-932", "mrqa_triviaqa-validation-743"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "explaining their actions", "Andrew Adamson", "waltz king", "Naimans", "additional warming of the Earth's surface", "parthenon", "Britain", "encourage", "Ibbi-Sipish", "strictly come dancing", "Polish", "the Falange", "cole albert porter", "1967", "16,000", "Washington Street", "8 November 1978", "five", "\"Fudge\"", "frustration with the atmosphere in the group at that time", "birmingham", "John Smith", "lusitania", "economic separation"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9356617647058824}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1444", "before_prediction": "Ibrium", "after_prediction": "Ibbi-Sipish"}, {"id": "mrqa_naturalquestions-validation-4148", "before_prediction": "his frustration with the atmosphere in the group at that time", "after_prediction": "frustration with the atmosphere in the group at that time"}], "retained_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-4209", "mrqa_triviaqa-validation-1050", "mrqa_hotpotqa-validation-2762", "mrqa_naturalquestions-validation-5604", "mrqa_squad-validation-6734", "mrqa_hotpotqa-validation-2564", "mrqa_squad-validation-6128", "mrqa_triviaqa-validation-5513", "mrqa_squad-validation-7469", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-5307", "mrqa_naturalquestions-validation-4500", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "fixed_ids": ["mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-8589", "mrqa_naturalquestions-validation-954", "mrqa_triviaqa-validation-3286", "mrqa_hotpotqa-validation-3728", "mrqa_squad-validation-932"], "unfixed_ids": ["mrqa_triviaqa-validation-743"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.9130434778638941}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "otoberfest", "south africa", "Majandra Delfino", "potassium hydroxide", "If a vehicle towing a trailer skids", "alternative T cell receptor (TCR)", "relatively low salaries", "genetically engineered corn or soybeans", "Heading Out to the Highway", "bridge", "u", "Michael Oppenheimer", "Premier League club Manchester United and the England national team", "poor and well socially standing Chinese", "No Night Today", "France's Legislative Assembly", "5,922", "June 4, 1931", "a 2016 science fiction psychological horror", "76ers", "Dutch figure of Sinterklaas ( himself also based on Saint Nicholas )", "Stern-Plaza", "Jimmy Ellis", "1991", "lily-of-the-valley", "Dallas", "Dar es Salaam", "During the last Ice Age", "Neon City"], "metric_results": {"EM": 0.5, "QA-F1": 0.583198051948052}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 0.0, 0.5714285714285715, 1.0, 1.0, 0.9090909090909091, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_squad-validation-8617", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-5557"], "after_eval": {"predictions": ["orbital scientific instrument", "the Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "september", "south africa", "Thomas Middleditch", "potassium", "If a vehicle towing a trailer skids", "T cell receptor (TCR)", "relatively low salaries", "us", "Point of Entry", "bridge", "u", "Science Magazine", "Premier League club Manchester United and the England national team", "lived in poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Wodan", "Stern-Plaza", "Jimmy Ellis", "1991", "may", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9866071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-6744", "mrqa_hotpotqa-validation-572", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_squad-validation-2234", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2245", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-4221", "mrqa_naturalquestions-validation-5960"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_triviaqa-validation-7156", "mrqa_hotpotqa-validation-1119", "mrqa_squad-validation-8617", "mrqa_squad-validation-8095", "mrqa_naturalquestions-validation-5631", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-5557"], "unfixed_ids": ["mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.999999999375}, {"timecode": 33, "before_eval": {"predictions": ["defeat of Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker, or \"bookie\" for taking a bet from a gambler", "largest Filipino American community", "Roger Maris", "jonathan", "a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus, causing changes in gene expression", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "Biloxi, Mississippi", "emperor", "oakum", "Spring city", "London, United Kingdom", "Broken Hill and Sydney", "2005", "punishments", "\"Smith and Jones\"", "wagons", "ilich ramirez sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "port Arthur", "power windows", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8196130952380952}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 0.0, 0.11428571428571427, 0.08, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2092", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_squad-validation-10180", "mrqa_hotpotqa-validation-5727", "mrqa_triviaqa-validation-2812"], "after_eval": {"predictions": ["defeat of Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "largest Filipino American community", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher rates", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "along the St. Lawrence River valley, with some also in Acadia", "emperor", "oakum", "Spring city", "London", "Broken Hill and Sydney", "2005", "punishments", "The Doctor's Daughter", "wagons", "illich ramirez sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "power windows", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9659090909090909}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-7741", "before_prediction": "\"Smith and Jones\"", "after_prediction": "The Doctor's Daughter"}], "retained_ids": ["mrqa_squad-validation-9984", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-1573", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_naturalquestions-validation-6358", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-2010", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-6186", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_hotpotqa-validation-2588", "mrqa_squad-validation-1903", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-2147", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "fixed_ids": ["mrqa_hotpotqa-validation-2092", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_squad-validation-7571", "mrqa_hotpotqa-validation-5727", "mrqa_triviaqa-validation-2812"], "unfixed_ids": ["mrqa_squad-validation-10180"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.959999999616}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "norman hartnell", "sending an email", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts", "Britain", "onions", "0.52", "Primula Susan Rollo", "France", "retired senior minister in the Free Presbyterian Church of Ulster and a former Democratic Unionist Party politician", "World War II", "litas", "madness", "Taft", "1973", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Johnny Darrell", "head and neck", "motorcycles or mopeds pulling trailers", "the sum of divisors function", "ear canal", "how graphs are encoded as binary strings", "Busiest airports in the United States by international passenger volume", "yellow", "large", "Lauren Oliver", "healing incantation"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7271634615384615}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_hotpotqa-validation-3982", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-1139", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184"], "after_eval": {"predictions": ["Chairman", "norman hartnell", "sending an email", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52", "separate tables", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "World War II", "lTL", "madness", "Taft", "late 1970s", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "the sum of divisors function", "earwax", "how graphs are encoded as binary strings", "third", "afghanistan", "large", "Lauren Oliver", "healing incantation"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-7248", "mrqa_squad-validation-6673", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_hotpotqa-validation-3072", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-4366", "mrqa_hotpotqa-validation-3002", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-3708", "mrqa_squad-validation-8034", "mrqa_triviaqa-validation-1198"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_hotpotqa-validation-3982", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-3107", "mrqa_hotpotqa-validation-1139", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-2751", "mrqa_triviaqa-validation-7184"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9999999995454545}, {"timecode": 35, "before_eval": {"predictions": ["2%", "capital and financial markets", "Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "brain, muscles, and liver", "ear-shaped", "Atlanta Falcons, the San Francisco 49ers, the Dallas Cowboys, the Washington Redskins and the Baltimore Ravens", "courtyard", "William Howard Ashton", "teapot", "Unemployment", "Miami", "Best Actor prize", "a modifier key on many keyboards, especially on laptops, used in a compact layout to combine keys which are usually kept separate", "casket letters", "spectroscopic notation for the associated atomic orbitals : sharp, principal, diffuse and fundamental, and then g which follows f in the alphabet", "declines", "Beauty and the Beast", "New Zealand national rugby union team", "Scotty Grainger", "texas", "seal", "UMC", "Geno Lenardo", "Roger Allers and Rob Minkoff, produced by Don Hahn, and has a screenplay credited to Irene Mecchi, Jonathan Roberts, and Linda Woolverton.", "Papua New Guinea", "david seville", "National Association for the Advancement of Colored People", "1963\u20131989", "titanic", "margaret beckett", "bewitched", "6500 - 1500 BC"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6075609037701428}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.15384615384615385, 0.4, 0.0, 0.34782608695652173, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.13636363636363635, 0.0, 0.4799999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 0.7499999999999999, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_triviaqa-validation-6423", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_triviaqa-validation-6450", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "after_eval": {"predictions": ["2%", "capital and financial markets", "Dan Stevens", "liver", "butterfly", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard", "William Howard Ashton", "president harding", "Unemployment", "Miami", "Best Actor prize", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "king charles i", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "south africa", "Tyler \"Ty\" Mendoza", "texas", "a seal", "the UMC", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "NAACP", "1963\u20131989", "titanic", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-25", "mrqa_squad-validation-9400", "mrqa_hotpotqa-validation-2971", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_hotpotqa-validation-2947", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_triviaqa-validation-2999", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_triviaqa-validation-11", "mrqa_squad-validation-7610", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746"], "fixed_ids": ["mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_triviaqa-validation-4829", "mrqa_naturalquestions-validation-4544", "mrqa_triviaqa-validation-6423", "mrqa_naturalquestions-validation-1587", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_triviaqa-validation-6450", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-430", "mrqa_hotpotqa-validation-1720", "mrqa_triviaqa-validation-6969", "mrqa_triviaqa-validation-1812"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9999999994117647}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "McG", "Uranus is larger in diameter but smaller in mass than Neptune", "president rudolf", "Cobham\u2013Edmonds thesis", "teachers", "II", "April", "New Orleans", "Raymond Patterson", "Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "Menorca", "plead guilty to one misdemeanor count and receive no jail time", "Julius Caesar", "2%", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "the set of all connected graphs", "Bluebird's Castle", "the right side of the heart", "Miasma theory", "imperial fluid ounces", "mountain ranges", "white", "Georgia", "nettle", "$12", "20 %", "love is all around", "to build a nationwide network in the UK", "west", "Sudan"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7006944444444444}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-4115", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_squad-validation-4877", "mrqa_squad-validation-4626", "mrqa_hotpotqa-validation-452"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "sir william herschel", "rudolph", "Cobham\u2013Edmonds thesis", "teachers", "II", "April", "New Orleans", "Raymond Patterson", "Coldplay", "Gibraltar", "plead guilty to one misdemeanor count and receive no jail time", "emperors", "2%", "January 28, 1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "formal language", "conducting", "the right side of the heart", "bad air", "imperial fluid ounces", "mountain ranges", "white", "The U.S. state of Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571, with exports to other states occurring around 1858", "nettle", "$12", "20 %", "love is all around", "ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9260416666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6011", "before_prediction": "Menorca", "after_prediction": "Gibraltar"}, {"id": "mrqa_hotpotqa-validation-1884", "before_prediction": "1979", "after_prediction": "January 28, 1979"}, {"id": "mrqa_naturalquestions-validation-3344", "before_prediction": "Georgia", "after_prediction": "The U.S. state of Georgia is known as the `` Peach State '' due to its significant production of peaches as early as 1571, with exports to other states occurring around 1858"}], "retained_ids": ["mrqa_hotpotqa-validation-652", "mrqa_squad-validation-1758", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_triviaqa-validation-3803", "mrqa_hotpotqa-validation-2936", "mrqa_squad-validation-6759", "mrqa_squad-validation-3060", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-5552", "mrqa_naturalquestions-validation-8525", "mrqa_hotpotqa-validation-1118", "mrqa_triviaqa-validation-199", "mrqa_triviaqa-validation-4069", "mrqa_squad-validation-3635", "mrqa_naturalquestions-validation-2323", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-9146"], "fixed_ids": ["mrqa_hotpotqa-validation-152", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-110", "mrqa_naturalquestions-validation-4115", "mrqa_squad-validation-1634", "mrqa_triviaqa-validation-5936", "mrqa_squad-validation-4877", "mrqa_squad-validation-4626", "mrqa_hotpotqa-validation-452"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8636363632438017}, {"timecode": 37, "before_eval": {"predictions": ["Union Pacific Railroad", "three of his ribs were broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "the Roman Empire", "japan", "gold", "Jericho in the Levant region, thought to be the world's first town ( settled around 8500 BC and fortified around 6800 BC )", "around 11 miles (18 km) south of San Jose", "woodentop", "Henry", "shared", "sandhill dunnart", "events and festivals", "kabinett", "2010", "avatar", "7 January 1936", "lifetime protection", "It contains twenty-three episodes, starting with \"Lard of the Dance\"", "Carl Sagan", "Much of the city's tax base dissipated", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Pierre Nlend Wom\u00e9", "the judge increased her sentence from 40 to 60 days", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.75, "QA-F1": 0.7975045787545787}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [0.28571428571428575, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.13333333333333333, 1.0, 0.19999999999999998, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-1375", "mrqa_squad-validation-6737"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "The first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "two", "gold", "Mesopotamia", "37\u00b0 9' 58.23\"", "woodentop", "Henry", "shared", "sandhill dunnart", "events and festivals", "kabinett", "2010", "the Na'vi", "7 January 1936", "ten years", "It contains twenty-three episodes", "Carl Sagan", "Much of the city's tax base dissipated", "Republicans", "Poulsen", "mistreatment from government officials", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.875, "QA-F1": 0.875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4212", "before_prediction": "the Roman Empire", "after_prediction": "The first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term"}, {"id": "mrqa_triviaqa-validation-3876", "before_prediction": "avatar", "after_prediction": "the Na'vi"}, {"id": "mrqa_naturalquestions-validation-969", "before_prediction": "lifetime protection", "after_prediction": "ten years"}, {"id": "mrqa_hotpotqa-validation-633", "before_prediction": "Pierre Nlend Wom\u00e9", "after_prediction": "Poulsen"}], "retained_ids": ["mrqa_squad-validation-4108", "mrqa_hotpotqa-validation-104", "mrqa_squad-validation-5451", "mrqa_hotpotqa-validation-513", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4664", "mrqa_hotpotqa-validation-4154", "mrqa_squad-validation-5702", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_hotpotqa-validation-85", "mrqa_squad-validation-8069", "mrqa_squad-validation-7246", "mrqa_triviaqa-validation-2524", "mrqa_hotpotqa-validation-5371"], "fixed_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-1625", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-1375", "mrqa_squad-validation-6737"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8333333329861111}, {"timecode": 38, "before_eval": {"predictions": ["NP-complete Boolean satisfiability problem", "Dan Stevens", "1958", "Bart Cummings", "dragon", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "American Indian allies", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Jeff Meldrum", "a week", "phil Archer", "French and English", "The Chipettes", "suez canal", "60 by West All - Stars ( 2017 )", "Tesla rarely slept", "there is no revising chamber", "norman william herschel", "ramification in geometry", "newly accessioned", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.75, "QA-F1": 0.7879026610644257}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.09523809523809523, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_hotpotqa-validation-1116", "mrqa_squad-validation-1660", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473", "mrqa_naturalquestions-validation-2100"], "after_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen, and Emma Thompson", "1958", "the trainer Etienne de Mestre won his fourth Melbourne Cup with Chester owned by Hon. James White", "dragon", "slavery", "the colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \"Jeff\" Meldrum", "a week", "david will be able to hear his last episode on Sunday, November 22", "English", "The Chipettes", "suez canal", "60 by West All - Stars ( 2017 )", "journalist", "take evidence from witnesses, conduct inquiries and scrutinise legislation", "beehive", "ramification in geometry", "newly accessioned", "fiat money", "strychnine", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8700311302681992}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.896551724137931, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-2499", "before_prediction": "Bart Cummings", "after_prediction": "the trainer Etienne de Mestre won his fourth Melbourne Cup with Chester owned by Hon. James White"}, {"id": "mrqa_triviaqa-validation-4762", "before_prediction": "phil Archer", "after_prediction": "david will be able to hear his last episode on Sunday, November 22"}, {"id": "mrqa_hotpotqa-validation-2682", "before_prediction": "French and English", "after_prediction": "English"}], "retained_ids": ["mrqa_squad-validation-1862", "mrqa_naturalquestions-validation-3893", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-10255", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4067", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-3320", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "fixed_ids": ["mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-3492", "mrqa_squad-validation-1660", "mrqa_squad-validation-9478", "mrqa_triviaqa-validation-1473"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_hotpotqa-validation-1116", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.625, "instant_retention_rate": 0.8749999996354166}, {"timecode": 39, "before_eval": {"predictions": ["taipei", "Dan Conner", "checkpoint Charlie", "abraham lincoln", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "the 1980s", "John M. Grunsfeld", "detroit", "your song", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the first Sunday in November", "fixed", "lady", "porto", "August 10, 1933", "spanning the Golden Gate, the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "Vancouver", "those who already hold wealth", "bilingual German author B. Traven", "Finding Nemo", "unidentified flying objects (UFOs) the extraterrestrial hypothesis (ETH) as well as paranormal and Fortean subjects in general", "inflation", "squirrel", "247,597", "The Institute for Advanced Study", "the German service cartridge", "oxygen"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7912749740584493}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.7142857142857143, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_naturalquestions-validation-9227", "mrqa_naturalquestions-validation-6839", "mrqa_triviaqa-validation-7269", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_squad-validation-3650"], "after_eval": {"predictions": ["taipei", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "violence", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "1977", "John M. Grunsfeld", "detroit", "your song", "2003", "every year", "NTV", "the second Sunday of March", "fixed", "agatha christie", "porto", "August 10, 1933", "Golden Gate Bridge", "Vancouver", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "Fortean", "inflation", "squirrel", "247,597", "The Institute for Advanced Study", "the German service cartridge", "DC"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9350961538461539}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9230769230769231, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6554", "before_prediction": "the 1980s", "after_prediction": "1977"}, {"id": "mrqa_hotpotqa-validation-5233", "before_prediction": "Fabbrica Italiana Automobili Torino", "after_prediction": "NTV"}], "retained_ids": ["mrqa_triviaqa-validation-6133", "mrqa_hotpotqa-validation-2243", "mrqa_hotpotqa-validation-944", "mrqa_squad-validation-2493", "mrqa_triviaqa-validation-2522", "mrqa_squad-validation-8070", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-5595", "mrqa_hotpotqa-validation-2332", "mrqa_triviaqa-validation-4024", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-489", "mrqa_triviaqa-validation-2808", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-2203"], "fixed_ids": ["mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_naturalquestions-validation-6839", "mrqa_triviaqa-validation-7269", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-5272", "mrqa_hotpotqa-validation-1607", "mrqa_squad-validation-3650"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227"], "instant_fixing_rate": 0.8888888888888888, "instant_retention_rate": 0.9130434778638941}, {"timecode": 40, "before_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "Sarajevo", "Isabella (Belle) Baumfree", "stubby", "in every year between 1346 and 1671", "five starting pitchers, seven relief pitchers, two catchers, six infielders, and five outfielders", "he broadened the foundations of the Reformation placing them on prophetic faith", "Bacon", "Yul Brynner", "anti-inflammatory molecules", "Highland garb", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "may have the force of law, if based on the authority derived from statute or the Constitution itself", "sound and light", "surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "the Hudson Bay", "immediately", "new zealand", "shorthand typist", "30 Major League Baseball teams", "the Secret Intelligence Service", "100", "kai su, teknon", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "Bangor ( ) is a city along the Penobscot River in the U.S. state of Maine", "a qui tam provision that allows people who are not affiliated with the government, called `` relators '' under the law, to file actions on behalf of the government"], "metric_results": {"EM": 0.625, "QA-F1": 0.6712660256410257}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.375, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.15384615384615385, 0.16]}}, "error_ids": ["mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_naturalquestions-validation-1063", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_hotpotqa-validation-178", "mrqa_naturalquestions-validation-993"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgi", "throughout the 14th to 17th centuries", "seven relief pitchers", "placing them on prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "Constitution", "sound and light", "surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "Hudson Bay", "immediately", "new zealand", "doreen", "30 Major League Baseball teams", "MI6", "neurons", "caesar", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "\"Queen City\"", "qui tam"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4123", "before_prediction": "shorthand typist", "after_prediction": "doreen"}], "retained_ids": ["mrqa_squad-validation-395", "mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-1571", "mrqa_hotpotqa-validation-1453", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-8247", "mrqa_hotpotqa-validation-4076", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-3151", "mrqa_squad-validation-3617", "mrqa_naturalquestions-validation-6848"], "fixed_ids": ["mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-2249", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-3814", "mrqa_naturalquestions-validation-1063", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_hotpotqa-validation-178", "mrqa_naturalquestions-validation-993"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9499999995249999}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Indian", "Gaelic", "Brag", "Idisi", "lion", "The cinema of Russia", "sediment load", "Washington metropolitan area", "eukaryotic cell", "User State Migration Tool", "Ordos City", "franscioni", "Boise State University", "leicester", "Section 30", "Paul Lynde as Templeton, a care - free, egotistical rat who lives on a web in a corner of Homer's barn above Wilbur's pig pen", "October 1986", "4 billion", "Retreating Monsoon", "Romansh", "lisabeth II", "MIX 94.5", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award", "margaret Thatcher", "jonathan", "Luigi Creatore"], "metric_results": {"EM": 0.59375, "QA-F1": 0.654298418972332}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 0.05714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-1391", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-434"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag", "Idisi", "lion", "The cinema of Russia", "sediment load", "FedExField in Landover, Maryland", "newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment, both at the cell surface ( particularly caveolae internalization ) as well as at the Golgi apparatus", "Windows Easy Transfer", "Ordos City", "flying disc", "Boise State University", "leicester", "Section 30 of the Teaching Council Act 2001", "Paul Lynde", "October 1986", "4 billion", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george iii", "5AA", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920) known as Jerry Maren", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret casket letters", "jonathan", "Luigi Creatore"], "metric_results": {"EM": 0.84375, "QA-F1": 0.9417069692460318}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.7499999999999999, 1.0, 1.0, 0.4, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2142", "before_prediction": "Section 30", "after_prediction": "Section 30 of the Teaching Council Act 2001"}, {"id": "mrqa_hotpotqa-validation-3872", "before_prediction": "Gerard Marenghi (born January 24, 1920)", "after_prediction": "Gerard Marenghi (born January 24, 1920) known as Jerry Maren"}, {"id": "mrqa_triviaqa-validation-791", "before_prediction": "margaret Thatcher", "after_prediction": "margaret casket letters"}], "retained_ids": ["mrqa_squad-validation-1592", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_squad-validation-9355", "mrqa_hotpotqa-validation-201", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-684", "mrqa_naturalquestions-validation-5007", "mrqa_triviaqa-validation-2384", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "fixed_ids": ["mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-1391", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-4955", "mrqa_naturalquestions-validation-6151", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_triviaqa-validation-2181", "mrqa_hotpotqa-validation-3176", "mrqa_hotpotqa-validation-434"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-8338"], "instant_fixing_rate": 0.8461538461538461, "instant_retention_rate": 0.8421052627146814}, {"timecode": 42, "before_eval": {"predictions": ["kill bill", "meat ( usually meatballs and / or sausage some times chicken containing Italian parsley and parmesan cheese ) in a clear chicken - based broth", "ballet", "derision", "various causes", "the American Civil War", "Chartered", "the judge increased her sentence", "Danish", "centre-back", "rommel", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "F fructose", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "Introverted Sensing ( Si )", "the first Thursday in May", "white", "reviewing all prescribed medications prior to dispensing and administration to the patient", "Mars", "feats of exploration", "piston", "bobby kirby keger", "financial assistance for tuition and other school fees of students turned away from public high schools because of enrollment overflows", "bow", "rebuild St. Peter's Basilica in Rome", "colonies", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.625, "QA-F1": 0.7375892857142856}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.07142857142857144, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9047619047619047, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 0.09999999999999999, 1.0, 1.0, 1.0, 0.0, 0.16000000000000003, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8284", "mrqa_squad-validation-1429", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-7233", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-4842", "mrqa_squad-validation-9569", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-7034", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid", "the American Civil War", "Chartered", "the judge increased her sentence", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose", "their unusual behavior", "Gainsborough Trinity Football Club is a football club based in Gainsboro, Lincolnshire, England.", "portrait", "Introverted Sensing ( Si )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "mars", "feats of exploration", "piston", "rob lowe", "Private Education Student Financial Assistance", "bow", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9944196428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2952", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-680", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "fixed_ids": ["mrqa_naturalquestions-validation-8284", "mrqa_squad-validation-1429", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-4185", "mrqa_squad-validation-9569", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-7034", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-4842"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.9999999995}, {"timecode": 43, "before_eval": {"predictions": ["niagara falls", "15", "Indiana", "Mormonism", "Italian", "sailor coming home from a round trip", "hostname", "the immune system is less active than normal, resulting in recurring and life-threatening infections", "soprano Laura Aikin", "organic, some contain propolis and/or beeswax sourced from bees.", "horse", "Sparafucile in Verdi's \"Rigoletto\"", "Russia is the largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally.", "third-most abundant element in the universe", "ikea", "169", "mexico", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers, Sir Henry Cheere,", "Plies", "the Outfield", "tennis", "Michael Edwards ( briefly as the older Connor ) and then by teenage actor Edward Furlong throughout the remainder of the film", "road engines", "eddie Fisher", "when the Moon's ecliptic longitude and the Sun's EcliptIC longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "snudge", "chemists Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "technology incidental to rocketry and manned spaceflight", "mitochondrial Eve", "237", "matthew"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6697529669762643}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.47058823529411764, 0.0, 0.0, 1.0, 0.4, 0.11764705882352941, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.21052631578947367, 1.0, 0.0, 0.8571428571428572, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-981", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5822", "mrqa_naturalquestions-validation-7641", "mrqa_triviaqa-validation-2803", "mrqa_naturalquestions-validation-5968", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812"], "after_eval": {"predictions": ["niagara falls", "15", "Indiana", "salt lake city", "Italian", "sailor", "hostname", "recurring and life-threatening infections", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third-most", "ikea", "169", "mexico", "Agostino Carlini", "Plies", "English rock band the Outfield", "tennis", "Michael Edwards", "road engines", "richard burton", "when the Moon's ecliptic longitude and the Sun's EcliptIC longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "snudge", "Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "africa", "237", "matthew"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9642857142857143}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5899", "before_prediction": "mitochondrial Eve", "after_prediction": "africa"}], "retained_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_hotpotqa-validation-2403", "mrqa_naturalquestions-validation-2663", "mrqa_triviaqa-validation-5087", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-7215", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "fixed_ids": ["mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-981", "mrqa_squad-validation-6442", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-518", "mrqa_hotpotqa-validation-4101", "mrqa_hotpotqa-validation-850", "mrqa_squad-validation-3671", "mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5822", "mrqa_naturalquestions-validation-7641", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_squad-validation-3812"], "unfixed_ids": ["mrqa_naturalquestions-validation-5968"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.941176470034602}, {"timecode": 44, "before_eval": {"predictions": ["The new Vibranium sample was used to make Captain America's circular shield and his triangular one was retired", "greater benefits (like health insurance) compared to other occupations.", "2003 for the inter-county competition in England and Wales", "cricket", "sweden", "campaign setting", "2003", "867", "the Hebrew name Immanu'el ( \u05e2\u05b4\u05de\u05b8\u05bc\u05e0\u05d5\u05bc\u05d0\u05b5\u05dc \u202c, which means `` God with us. '' )", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Ewan McGregor", "second most commonly named \"dream college\" both for students and parents in 2013", "well", "in all health care settings, but the clinical pharmacy movement initially began inside hospitals and clinics", "expected to become more integral within the health care system.", "music", "Lecrae Devaughn Moore (born October 9, 1979)", "56719 Nagercoil -- Kanyakumari Passenger", "Piazza Trinit\u00e0 dei Monti", "May 18, 2010", "Sylvia Pankhurst", "schengen", "philosophical advocate and practitioner of the scientific method during the scientific revolution", "belfast", "Indian government", "Irish", "Vesta", "bront\u00eb Sisters", "energy", "Hubble Space Telescope", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6212526951570101}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.9411764705882353, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.375, 1.0, 0.4210526315789474, 1.0, 1.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_naturalquestions-validation-10612", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_squad-validation-6319", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-4027"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "in 2003 for the inter-county competition in England and Wales", "paris", "sweden", "published campaign settings", "`` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867 feet", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "R2 - D2", "second most commonly", "well", "all health care settings", "expected to become more integral within the health care system", "music", "Lecrae Devaughn Moore", "Mumbai Rajdhani Express", "Rome", "May 18, 2010", "Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "Hubble Space Telescope", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-910", "before_prediction": "867", "after_prediction": "867 feet"}], "retained_ids": ["mrqa_triviaqa-validation-6579", "mrqa_hotpotqa-validation-4649", "mrqa_triviaqa-validation-3664", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_naturalquestions-validation-2169", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_hotpotqa-validation-5696", "mrqa_naturalquestions-validation-1725", "mrqa_squad-validation-8625", "mrqa_triviaqa-validation-1504", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "fixed_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_naturalquestions-validation-10612", "mrqa_naturalquestions-validation-5550", "mrqa_squad-validation-7067", "mrqa_squad-validation-6319", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-4027"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.941176470034602}, {"timecode": 45, "before_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke it", "under `` the immortal Hawke ''", "death penalty", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum", "Lorne Greene", "Virginia", "1998", "They were the first group to win the competition", "the main highway entrance at California State Route 1", "St. Louis", "French", "Gareth", "\"LOVE Radio\"", "The Rockies are one of two MLB franchises to have never won a division title (the other team is the Miami Marlins)", "the court", "Travolta", "Donald Henkel", "radicalize the Islamist movement", "The Carnabeats", "Cashin' In", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8491071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.09999999999999999, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_hotpotqa-validation-1754", "mrqa_naturalquestions-validation-4905"], "after_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke it", "served in the Royal Navy and lost his leg under `` the immortal Hawke ''", "executed", "frail", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "Ubiorum", "lorne greene", "Massachusetts", "1998", "They were the first group to win the competition", "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove", "St. Louis", "Canadian", "Gareth", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "radicalize the Islamist movement", "People! and The Carnabeats", "Cashin' In", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9592391304347826}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-4123", "before_prediction": "under `` the immortal Hawke ''", "after_prediction": "served in the Royal Navy and lost his leg under `` the immortal Hawke ''"}, {"id": "mrqa_naturalquestions-validation-3363", "before_prediction": "the main highway entrance at California State Route 1", "after_prediction": "the main highway entrance at California State Route 1, and entrances in Carmel and Pacific Grove"}], "retained_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_naturalquestions-validation-8728", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1433", "mrqa_squad-validation-5852", "mrqa_naturalquestions-validation-9931", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-3509", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "fixed_ids": ["mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-5149", "mrqa_triviaqa-validation-455", "mrqa_hotpotqa-validation-866", "mrqa_hotpotqa-validation-1754"], "unfixed_ids": ["mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.8333333333333334, "instant_retention_rate": 0.9230769227218935}, {"timecode": 46, "before_eval": {"predictions": ["cuba", "that continents `` ploughed '' through the sea.", "take That, East 17 and Boyzone", "youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "pre-Raphaelite", "Joel", "massively multiplayer online role-playing video game", "hundreds of television and radio channels", "\"Beetlejuice\"", "2003", "a new facility on The Watermark business park next to the MetroCentre in Gateshead", "pearmain", "partial funding for the 20th anniversary special The Five Doctors in 1983", "pale lager", "not be produced using currently available resources", "Chu'Tsai", "Liz", "least onerous", "como", "Grissom, White, and Chaffee", "multinational retail corporation", "purple granadilla", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "golf", "incorrectly", "vienna"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7214400183150184}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.5384615384615384, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.42857142857142855, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_triviaqa-validation-4081", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-5221", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2873"], "after_eval": {"predictions": ["cuba", "that continents `` ploughed '' through the sea", "take that", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds", "Waiting for Guffman", "2003", "The Watermark business park", "apple tree", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "italy", "Grissom, White", "multinational retail corporation", "purple granadilla", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "incorrectly", "vienna"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3913", "before_prediction": "Grissom, White, and Chaffee", "after_prediction": "Grissom, White"}], "retained_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_squad-validation-5157", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-73", "mrqa_hotpotqa-validation-5239", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_naturalquestions-validation-3616", "mrqa_triviaqa-validation-1128", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-2808", "mrqa_squad-validation-3523", "mrqa_triviaqa-validation-4430"], "fixed_ids": ["mrqa_triviaqa-validation-6905", "mrqa_hotpotqa-validation-5251", "mrqa_triviaqa-validation-4081", "mrqa_squad-validation-2673", "mrqa_hotpotqa-validation-5221", "mrqa_squad-validation-5464", "mrqa_triviaqa-validation-7350", "mrqa_squad-validation-7792", "mrqa_naturalquestions-validation-2890", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2873"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9523809519274377}, {"timecode": 47, "before_eval": {"predictions": ["florida", "horseracing", "New Zealand national team", "at the'Lord's Enclosure' (Mongolian: Edsen Khoroo) in Mongolia", "Styal Mill", "big - name lawyers", "Goldie & Bear", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "piccadilly", "Neighbourhood", "The Washington Post", "tentacles", "insects", "specific catechism questions", "a dye", "about 50% oxygen composition at standard pressure", "63,182,000", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "Campbellsville University", "James Dean", "James Anthony Sturgess", "300", "Maria works in a bridal shop with Anita", "Jocelyn Flores", "less workers are required"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8125}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-2092"], "after_eval": {"predictions": ["florida", "horseracing", "New Zealand national team", "Kumbum Monastery or Ta'er Shi near Xining", "Styal Mill", "William Jennings Bryan", "Goldie & Bear", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "piccadilly Circus", "Neighbourhood", "The Washington Post", "tentacles", "insect", "specific catechism questions", "a dye", "about 50% oxygen composition at standard pressure", "2001", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "WKU", "james dean", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita", "XXXTentacion", "less workers are required"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9583333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1516", "before_prediction": "piccadilly", "after_prediction": "piccadilly Circus"}, {"id": "mrqa_hotpotqa-validation-662", "before_prediction": "Campbellsville University", "after_prediction": "WKU"}], "retained_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-1924", "mrqa_hotpotqa-validation-5788", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_hotpotqa-validation-5086", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_squad-validation-2346", "mrqa_naturalquestions-validation-7849", "mrqa_squad-validation-3685", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-1609", "mrqa_squad-validation-9061", "mrqa_triviaqa-validation-1799", "mrqa_naturalquestions-validation-5241", "mrqa_squad-validation-7182"], "fixed_ids": ["mrqa_squad-validation-6287", "mrqa_naturalquestions-validation-930", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-4173", "mrqa_triviaqa-validation-7477", "mrqa_naturalquestions-validation-2092"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9230769227218935}, {"timecode": 48, "before_eval": {"predictions": ["James Stenbeck", "Section.80", "Yosemite", "\"interventive\"", "3", "Bishop Reuben H. Mueller", "georgia", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "UNESCO", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California", "a sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "American foreign policy", "coffee", "halal", "Arthur Russell", "people", "Wylie Draper", "political", "the university's off- campuses rental policies", "Manley MacDonald", "Pittsburgh Steelers", "conditions such as war, famine, and weather"], "metric_results": {"EM": 0.75, "QA-F1": 0.8352272727272727}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.6666666666666665, 0.4, 1.0, 0.7272727272727273]}}, "error_ids": ["mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-4774"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "al Capitan", "\"interventive\"", "3", "Bishop Reuben H. Mueller", "georgia", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "the United Nations Educational, Scientific and Cultural Organization", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "part of a pre-recorded television program, Rendezvous with Destiny", "sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "neutrality", "half steamed milk and half foam", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull, as well as painter Manley MacDonald.", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.875, "QA-F1": 0.8958333333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3967", "before_prediction": "Yosemite", "after_prediction": "al Capitan"}, {"id": "mrqa_triviaqa-validation-2849", "before_prediction": "UNESCO", "after_prediction": "the United Nations Educational, Scientific and Cultural Organization"}, {"id": "mrqa_triviaqa-validation-1197", "before_prediction": "coffee", "after_prediction": "half steamed milk and half foam"}], "retained_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_squad-validation-5665", "mrqa_naturalquestions-validation-49", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-2607", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_squad-validation-8248", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-3789", "mrqa_hotpotqa-validation-4075", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_hotpotqa-validation-962", "mrqa_squad-validation-2337", "mrqa_squad-validation-9518", "mrqa_squad-validation-264"], "fixed_ids": ["mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-7947", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-4774"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.8749999996354166}, {"timecode": 49, "before_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Attar of Nishapur and many other notable Muslims", "R.E.M.", "between the Eastern Ghats and the Bay of Bengal", "Ravenna (], also locally ] ; Romagnol: \"Rav\u00e8na\" ) is the capital city of the Province of Ravenna, in the Emilia-Romagna region of Northern Italy.", "Bocelli became completely blind at the age of 12", "meat", "1895", "improved", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "work at various electrical repair jobs and even as a ditch digger for $2 per day", "communist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Las Vegas Outlaws", "3,600", "Route 5", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles Jr.", "`` Kobol's Last Gleaming ''", "Wisconsin v. Yoder", "Informal rule", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.5625, "QA-F1": 0.671708152958153}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3636363636363636, 0.0, 1.0, 1.0, 0.1111111111111111, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-7049"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna (], also locally ] ; Romagnol: \"Rav\u00e8na\" ) is the capital city of the Province of Ravenna", "Bocelli became completely blind at the age of 12", "fear of public speaking", "1895", "improved markedly", "VTOL aircraft", "assigned them to the company in lieu of stock", "communist", "Gregor Mendel", "Reserved matters", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "\"informal\" imperialism", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9553571428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6073", "before_prediction": "meat", "after_prediction": "fear of public speaking"}], "retained_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2941", "mrqa_hotpotqa-validation-987", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-9013", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_squad-validation-9807", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-5876", "mrqa_hotpotqa-validation-1772", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "fixed_ids": ["mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_squad-validation-716", "mrqa_squad-validation-1459", "mrqa_squad-validation-1306", "mrqa_squad-validation-9489", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-1023", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049"], "unfixed_ids": ["mrqa_naturalquestions-validation-5283"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.944444443919753}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.44875, "QA-F1": 0.530619865288147}, "overall_error_number": 882, "overall_instant_fixing_rate": 0.9184036892515328, "final_instream_test": {"EM": 0.8925, "QA-F1": 0.9302400018816586}, "final_upstream_test": {"EM": 0.679, "QA-F1": 0.7427068918539987}}}