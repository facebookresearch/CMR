{"model_update_steps": 1645, "method_class": "mir", "base_model_args": "Namespace(base_model_path='out/mrqa_naturalquestions_bart-base_0617v4/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, gradient_accumulation_steps=1, inference_query_size=1, learning_rate=3e-05, local_adapt_lr=3e-05, max_grad_norm=0.1, memory_key_cache_path='na', memory_key_encoder='facebook/bart-base', memory_path='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=42_debug=reverse_ckpts/memory_dict.pkl', memory_store_rate=1.0, mir_debug_largestloss=False, mir_debug_reverse=True, num_adapt_epochs=3, num_epochs=5.0, overtime_ckpt_dir='exp_results/dynamic_stream/memory_based/ckpt_dir/0923_MixedAllErrors_T=50_mir_M=I_replaysize=32_upstream=All_meanloss=Yes_mix=Yes_freq=1_candidate=256_seed=42_debug=reverse_ckpts/', replay_candidate_size=256, replay_frequency=1, replay_size=32, save_all_ckpts=1, total_steps=10000, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, bug_stream_json_path='bug_data/mrqa_naturalquestions_dev.static_bug_stream.json', data_stream_json_path='exp_results/data_streams/mrqa.mixed.data_stream.test.json', do_lowercase=False, max_input_length=888, max_output_length=50, max_timecode=50, num_beams=4, pass_pool_jsonl_path='exp_results/data_streams/mrqa.mixed.hidden_passes.jsonl', predict_batch_size=16, replay_stream_json_path='', sampled_upstream_json_path='data/mrqa_naturalquestions/mrqa_naturalquestions_train.jsonl', task_name='mrqa_naturalquestions', train_batch_size=8, use_sampled_upstream=False)", "online_eval_results": [{"timecode": 0, "before_eval": {"predictions": ["Raymond Briggs' 1978 children's book 'The Snowman", "the acceleration due to gravity decreased as an inverse square law", "a marquetry commode by the \u00e9b\u00e9niste Jean Henri Riesener dated c1780", "a rotary mechanical device that extracts energy from a fluid flow and converts it into useful work", "lymphocyte", "Chinghiz", "Doctor Who and the Daleks in the Seven Keys to Doomsday", "Super Bowl 50 Host Committee", "a satirical television comedy programme on BBC Television in 1962 and 1963", "dynasty", "Br'er Rabbit", "Bodhi Natural Health Products", "Amphitrite Goddess of the Sea", "the Hallertau in Germany ( more hop - growing area than any other country as of 2006 ), the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho", "March 14 ( 3 / 14 in the month / day format ) since 3, 1, and 4 are the first three significant digits of \u03c0", "the head of the arrow or cockerel ( or equivalent depending on the chosen design ) will indicate the direction from which the wind is blowing", "Horace Rumpole", "combustion", "A Sunday Afternoon on the Island of La Grande Jatte", "nobody knows for sure how a do-over in golf came to be called a mulligan", "Captain Meriwether Lewis's 30th birthday", "An elevator with a counterbalance approximates an ideal Atwood machine and thereby relieves the driving motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "2011", "electric eels", "before the first year begins", "New Jerusalem", "Samantha Spiro", "2013", "Ronnie Biggs", "Steve Carell as Felonious Gru, the former villain turned Anti-Villain League agent, Margo, Edith, and Agnes'adoptive father, and Lucy's husband", "an allusion to Samuel Taylor Coleridge's poem The Rime of the Ancient Mariner ( 1798 )", "the assassination of US President John F. Kennedy"], "metric_results": {"EM": 0.0, "QA-F1": 0.0812722081839729}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.4799999999999999, 0.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1904761904761905, 0.11764705882352942, 0.15384615384615383]}}, "error_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-3915", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-2248", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5937", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_triviaqa-validation-7369", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "after_eval": {"predictions": ["The Snowman", "at larger distances.", "art and furnishings", "impulse turbine", "the adaptive immune system", "Chinghiz, Chinghis, and Chingiz", "Doctor Who \u2013 The Ultimate Adventure", "50 fund", "ned sherrin", "the Mandate of Heaven", "Tar- Baby", "enlightenment", "Poseidon", "the Yakima ( Washington ) and Willamette ( Oregon ) valleys, and western Canyon County, Idaho ( including the communities of Parma, Wilder, Greenleaf, and Notus )", "2009", "the direction from which the wind is blowing", "john Mortimer", "oxygen", "gees seurat", "golf", "the Missouri River", "An elevator with a counterbalance", "137th", "piranha", "the student's transition from the study of preclinical to clinical health sciences", "prague", "Geoffrey Hutchings", "1998", "john Stratford", "Miranda Cosgrove", "a metaphor for a burden to be carried as penance", "a series of power blackouts across the country"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8944940476190476}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": [], "fixed_ids": ["mrqa_hotpotqa-validation-1968", "mrqa_squad-validation-10322", "mrqa_squad-validation-5622", "mrqa_triviaqa-validation-2376", "mrqa_squad-validation-6677", "mrqa_squad-validation-6303", "mrqa_squad-validation-7821", "mrqa_squad-validation-392", "mrqa_triviaqa-validation-4054", "mrqa_naturalquestions-validation-6157", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-671", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-9688", "mrqa_triviaqa-validation-1551", "mrqa_squad-validation-3478", "mrqa_triviaqa-validation-5972", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-2730", "mrqa_hotpotqa-validation-409", "mrqa_squad-validation-4185", "mrqa_triviaqa-validation-6351", "mrqa_hotpotqa-validation-2970", "mrqa_hotpotqa-validation-3241", "mrqa_naturalquestions-validation-3490", "mrqa_naturalquestions-validation-7017", "mrqa_squad-validation-7746"], "unfixed_ids": ["mrqa_triviaqa-validation-3915", "mrqa_naturalquestions-validation-2248", "mrqa_triviaqa-validation-5937", "mrqa_naturalquestions-validation-5465", "mrqa_triviaqa-validation-7369"], "instant_fixing_rate": 0.84375, "instant_retention_rate": 0.0}, {"timecode": 1, "before_eval": {"predictions": ["the town of Acolman, just north of Mexico City", "The Iroquois", "a natural extension of capitalism that arose from need for capitalist economies to constantly expand investment, material resources and manpower in such a way that necessitated colonial expansion", "ned", "Virginia Wade", "Gary Morris", "the anterolateral system", "1966", "for scientific observation", "john Cameron", "The Stock Market crash in New York", "New York Stadium", "john Bercow", "continental units", "john Forster", "Comptroller General of the Receipt and Issue of Her Majesty's Exchequer", "Sergio P\u00e9rez", "River Welland", "The Concubine", "1543", "naba", "Vigor", "a policeman who investigates a series of mysterious killings and illnesses", "light bulbs within 100 feet of the lab glowed even when turned off", "Florence Nightingale", "Budweiser", "numb3rs", "acmthompson", "Michael Douglas", "Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object", "Superman", "2010"], "metric_results": {"EM": 0.1875, "QA-F1": 0.23243026224770647}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 0.06896551724137931, 0.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.5882352941176471, 0.0, 0.0, 1.0, 0.0, 1.0, 0.07407407407407407, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10680", "mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_squad-validation-1516", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_squad-validation-10410"], "after_eval": {"predictions": ["The idea of breaking a container filled with treats came to Europe in the 14th century, where the name, from the Italian pignatta, was introduced", "originally designated HU - 1", "philanthropy", "mariette", "sue barker", "makin' Up for Lost Time", "usually occurs 1 - 2 spinal nerve segments above the point of entry", "current denomination of U.S. currency", "either small fission systems or radioactive decay for electricity or heat", "ronseal", "The Stock Market crash in New York", "Rotherham United", "norman tebbit", "Pangaea or Pangea", "red", "The comptroller ( who is also auditor general and head of the National Audit Office )", "Pedro Rodr\u00edguez", "65 mi", "an obsessed and tormented king", "three years before his death", "islam", "Honda Ballade", "illnesses", "glowed even when turned off", "Sister Anthony, S.C.", "Stroh's", "alimi Ballard", "for gallantry", "Michael Douglas, Kathleen Turner, and Danny DeVito", "Galileo", "for the exclusive rights to Superman", "2010"], "metric_results": {"EM": 0.84375, "QA-F1": 0.871031746031746}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true], "QA-F1": [0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.33333333333333337, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5899", "before_prediction": "Gary Morris", "after_prediction": "makin' Up for Lost Time"}, {"id": "mrqa_triviaqa-validation-338", "before_prediction": "numb3rs", "after_prediction": "alimi Ballard"}, {"id": "mrqa_naturalquestions-validation-1864", "before_prediction": "Michael Douglas", "after_prediction": "Michael Douglas, Kathleen Turner, and Danny DeVito"}, {"id": "mrqa_triviaqa-validation-2367", "before_prediction": "Superman", "after_prediction": "for the exclusive rights to Superman"}], "retained_ids": ["mrqa_naturalquestions-validation-4684", "mrqa_hotpotqa-validation-3774"], "fixed_ids": ["mrqa_naturalquestions-validation-5144", "mrqa_squad-validation-10015", "mrqa_triviaqa-validation-7018", "mrqa_triviaqa-validation-5406", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-2753", "mrqa_naturalquestions-validation-3828", "mrqa_triviaqa-validation-5026", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-1924", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1437", "mrqa_naturalquestions-validation-1364", "mrqa_hotpotqa-validation-14", "mrqa_hotpotqa-validation-1201", "mrqa_hotpotqa-validation-3971", "mrqa_squad-validation-2629", "mrqa_triviaqa-validation-2210", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-5325", "mrqa_squad-validation-1516", "mrqa_hotpotqa-validation-1626", "mrqa_hotpotqa-validation-5802", "mrqa_triviaqa-validation-2096", "mrqa_squad-validation-10410"], "unfixed_ids": ["mrqa_naturalquestions-validation-10680"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.33333333277777777}, {"timecode": 2, "before_eval": {"predictions": ["MS Kronprins Harald", "rugby union", "Puritanism", "+, -, *, and / keys", "2009", "in different parts of the globe", "wales", "acetic acid", "John II Casimir Vasa", "marries Lord Darnley", "A55 North Wales Expressway", "a phylum with relatively few species", "`` Everywhere '' is a song by British - American rock band Fleetwood Mac from their fourteenth studio album Tango in the Night ( 1987 )", "the first country in which the majority of the population lives in the suburbs", "is not yet a senior", "Bothtec", "Terry Reid", "non- peer- reviewed sources", "Elgar", "North America", "Andr\u00e9 3000", "rookies", "Akhenaten", "President Theodore Roosevelt", "the fourth season", "four", "the Western Bloc ( the United States, its NATO allies and others )", "1970s", "afghanistan", "Matt Winer", "1700", "Pacific"], "metric_results": {"EM": 0.15625, "QA-F1": 0.2783511627261627}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true], "QA-F1": [0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.0, 0.0, 0.4, 0.28571428571428575, 0.1, 0.18181818181818182, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.4, 0.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.4, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-893", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_triviaqa-validation-1935", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367"], "after_eval": {"predictions": ["motor ships", "cricket, rallying, football, rugby union and boxing", "It was never affiliated with any particular denomination", "*", "2003", "eleven separate regions of the Old and New World", "a children's animation created by Oliver Postgate and Peter Firmin", "polyatomic anion", "Jan Kazimierz", "catherine de\u2019 Medici", "A55", "oceanic species", "Everywhere", "Many residents of metropolitan regions work within the central urban area, and choose to live in satellite communities called suburbs and commute to work", "second", "Masaharu Iwata", "Spencer Davis Group", "non-peer-reviewed sources", "Enigma Variations", "physiographically a part of the continent of North America", "is a song written and produced by Andr\u00e9 3000", "two rookies", "the Aten, a representation of the Egyptian god, Ra", "Monroe Doctrine", "2010 to 2012", "four", "the United States", "in the very late 1980s", "bizet", "Matthew Ward Winer", "as late as 1700", "Pacific"], "metric_results": {"EM": 0.875, "QA-F1": 0.85625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3242", "before_prediction": "Bothtec", "after_prediction": "Masaharu Iwata"}, {"id": "mrqa_squad-validation-3113", "before_prediction": "1700", "after_prediction": "as late as 1700"}], "retained_ids": ["mrqa_squad-validation-4019", "mrqa_squad-validation-194", "mrqa_squad-validation-4283"], "fixed_ids": ["mrqa_hotpotqa-validation-5699", "mrqa_squad-validation-8542", "mrqa_squad-validation-7149", "mrqa_naturalquestions-validation-10364", "mrqa_squad-validation-4253", "mrqa_naturalquestions-validation-8119", "mrqa_naturalquestions-validation-1202", "mrqa_hotpotqa-validation-3632", "mrqa_hotpotqa-validation-1888", "mrqa_squad-validation-4456", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-8448", "mrqa_triviaqa-validation-2136", "mrqa_naturalquestions-validation-539", "mrqa_squad-validation-8513", "mrqa_triviaqa-validation-4729", "mrqa_naturalquestions-validation-5502", "mrqa_hotpotqa-validation-2679", "mrqa_naturalquestions-validation-6896", "mrqa_naturalquestions-validation-2501", "mrqa_hotpotqa-validation-1376", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-683", "mrqa_triviaqa-validation-2722", "mrqa_hotpotqa-validation-4367"], "unfixed_ids": ["mrqa_triviaqa-validation-893", "mrqa_triviaqa-validation-1935"], "instant_fixing_rate": 0.9259259259259259, "instant_retention_rate": 0.5999999988}, {"timecode": 3, "before_eval": {"predictions": ["Why do Americans call it a period and the British a full stop", "Four Year Plan", "quadrilaterals", "between 27 July and 7 August 2022", "Staten Island", "Splash", "2006 British Academy Television Award for Best Drama Series", "the least of the Great Powers", "the lower motor neurons, the efferent nerves that directly innervate muscles", "a British television game", "Glacier Mints", "Epson Derby", "death mask", "video film", "Overtime", "Sir Henry Cole", "trouble distinguishing between carbon dioxide and oxygen", "The Young Ones", "Bonnie Parker and Clyde Barrow", "the Democratic Unionist Party", "23 July 1989", "many educational institutions especially within the US", "gurus often exercising a great deal of control over the lives of their disciples", "timeslot 16 on an E1", "Postcards from Paradise", "Callability", "2.26 GHz quad - core Snapdragon 800 processor", "over 10,000 British and 2,000 old master works", "Wearing Quran, or al - khimar", "proteins", "gallbladder", "400"], "metric_results": {"EM": 0.15625, "QA-F1": 0.21520099965823647}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false], "QA-F1": [0.18181818181818182, 0.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.10526315789473685, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_squad-validation-1539", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-2530"], "after_eval": {"predictions": ["period", "qpr", "360", "2022", "New York", "arthur Criss", "2005\u20132010", "G20", "efferent nerves", "max Bygraves", "polar bear", "lester piggott", "don't disturb\" sign", "nigeria", "the shootout", "commissioned by Sir Henry Cole and illustrated by John Callcott Horsley in London on 1st May 1843", "at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "adrian edmondson", "1934", "Northern Ireland Assembly for Fermanagh and South Tyrone", "23 July 1989", "US", "the West", "data", "ringo starr", "callable bonds", "2.26 GHz quad - core Snapdragon 800 processor", "10,000", "hijab", "The results of the Avery -- MacLeod -- McCarty experiment", "gallbladder", "museums"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9241071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3058", "before_prediction": "Staten Island", "after_prediction": "New York"}, {"id": "mrqa_triviaqa-validation-7382", "before_prediction": "Splash", "after_prediction": "arthur Criss"}], "retained_ids": ["mrqa_hotpotqa-validation-5662", "mrqa_naturalquestions-validation-6341", "mrqa_triviaqa-validation-6800"], "fixed_ids": ["mrqa_triviaqa-validation-1792", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-5362", "mrqa_naturalquestions-validation-5647", "mrqa_squad-validation-7816", "mrqa_hotpotqa-validation-4825", "mrqa_naturalquestions-validation-2571", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2327", "mrqa_triviaqa-validation-365", "mrqa_triviaqa-validation-3901", "mrqa_hotpotqa-validation-2263", "mrqa_naturalquestions-validation-3189", "mrqa_squad-validation-8832", "mrqa_triviaqa-validation-3339", "mrqa_triviaqa-validation-6683", "mrqa_hotpotqa-validation-2150", "mrqa_squad-validation-2191", "mrqa_squad-validation-2069", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-6402", "mrqa_naturalquestions-validation-2385", "mrqa_squad-validation-5517", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-5818", "mrqa_triviaqa-validation-2530"], "unfixed_ids": ["mrqa_squad-validation-1539"], "instant_fixing_rate": 0.9629629629629629, "instant_retention_rate": 0.5999999988}, {"timecode": 4, "before_eval": {"predictions": ["United Kingdom", "Arnhem", "December 9, 2016", "NASA discontinued the manned Block I program, using the Block I spacecraft only for unmanned Saturn V flights", "British progressive folk-rock band Gryphon", "1898", "month", "a shepherd", "southmost part of Brooklyn", "tetanus", "bounding", "gem", "Lieutenant Commander Steve McGarrett", "Eddie Leonski", "Jack", "a mixture of phencyclidine and cocaine", "a chain or screw stoking mechanism and its drive engine or motor", "no barber", "Reverse - Flash", "All Souls'Day", "A's", "arthur", "Protestants", "Mona Vanderwaal", "cricket", "Pyotr Ilyich Tchaikovsky", "2001 or 2010", "the English colonies of North America", "comprehend and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Splodgenessabounds"], "metric_results": {"EM": 0.28125, "QA-F1": 0.35684523809523816}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.4, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-6399", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-5654", "mrqa_squad-validation-3126", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021"], "after_eval": {"predictions": ["Austria", "Nijmegen", "30 days after the original air date", "unmanned Saturn V flights", "Gryphon", "1898", "june", "aaron", "new york city", "juranospasmin", "bounding", "facets", "Steve McGarrett", "Edward Joseph Leonski", "Lynwood", "cocaine", "bunker", "fleet street", "Professor Eobard Thawne", "All Saints ( or All Hallows )", "A's", "azerbaijan", "new converts", "CeCe Drake", "bridge", "Tania Miller", "8 April 1912", "Quebec", "comprehension and formulate language", "Michael E. Mann, Raymond S. Bradley and Malcolm K. Hughes", "rotating discs", "Jonathon Dutton"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8359375}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9358", "before_prediction": "Arnhem", "after_prediction": "Nijmegen"}, {"id": "mrqa_triviaqa-validation-7253", "before_prediction": "tetanus", "after_prediction": "juranospasmin"}, {"id": "mrqa_triviaqa-validation-5168", "before_prediction": "cricket", "after_prediction": "bridge"}, {"id": "mrqa_naturalquestions-validation-3840", "before_prediction": "comprehend and formulate language", "after_prediction": "comprehension and formulate language"}, {"id": "mrqa_naturalquestions-validation-220", "before_prediction": "Splodgenessabounds", "after_prediction": "Jonathon Dutton"}], "retained_ids": ["mrqa_naturalquestions-validation-1277", "mrqa_squad-validation-1688", "mrqa_squad-validation-8700", "mrqa_squad-validation-3467"], "fixed_ids": ["mrqa_squad-validation-6399", "mrqa_naturalquestions-validation-5146", "mrqa_squad-validation-3971", "mrqa_squad-validation-5360", "mrqa_triviaqa-validation-1085", "mrqa_triviaqa-validation-5231", "mrqa_triviaqa-validation-3647", "mrqa_triviaqa-validation-3808", "mrqa_hotpotqa-validation-1168", "mrqa_hotpotqa-validation-1289", "mrqa_hotpotqa-validation-2944", "mrqa_naturalquestions-validation-5437", "mrqa_squad-validation-3389", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-8545", "mrqa_triviaqa-validation-5654", "mrqa_squad-validation-3126", "mrqa_naturalquestions-validation-2900", "mrqa_hotpotqa-validation-4734", "mrqa_hotpotqa-validation-3978", "mrqa_squad-validation-3021"], "unfixed_ids": ["mrqa_triviaqa-validation-93"], "instant_fixing_rate": 0.9565217391304348, "instant_retention_rate": 0.4444444439506172}, {"timecode": 5, "before_eval": {"predictions": ["tranto", "F\u00e9d\u00e9ration Sportive F\u00e9minine Internationale", "a soft wool fabric with a colorful swirled pattern of curved shapes", "Paspahegh Indians", "a delay or obstruction along the pathway that electrical impulses travel in your heart to make it beat", "South Dakota", "7 : 25 a.m. HST", "slide whistle", "iphone", "used to start fires, hunt, and bury their dead", "Columbia", "the stomach", "placental", "released on September 13, 1994", "a revolver", "Ming", "1840", "a defiant speech, or a speech explaining their actions", "George Sylvester Viereck", "iphone", "by using net wealth (adding up assets and subtracting debts )", "entropy", "celibacy", "8.7 -- 9.2", "China", "2 November 1902", "Inez", "May 7, 2018", "9 October 1940", "Selden", "structural collapses", "as a way of housing a fierce half-man, half-bull creature"], "metric_results": {"EM": 0.03125, "QA-F1": 0.11768555178481649}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.15384615384615385, 0.0, 0.7499999999999999, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-2020", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-7554", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "after_eval": {"predictions": ["horace walpole", "International Association of Athletics Federations", "paisley", "uninhabited", "cardiac", "Idaho", "6 : 44 p.m. UTC", "clangers", "mustard", "bury their dead", "Indian", "gastric glands found in the lining of the fundus and in the body of the stomach", "monotreme", "September 13, 1994", "president garfield", "imperial rule", "1787", "allocution", "Mark Twain", "sunny afternoon", "on the basis of the methodology used: by using net wealth (adding up assets and subtracting debts )", "nonconservative forces", "death of a heretic", "The 1700 Cascadia earthquake", "China", "11 November 1869", "near Arenosa Creek and Matagorda Bay", "January 15, 2018", "19408", "Brookhaven", "property damage", "daedalus"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9714912280701754}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1718"], "fixed_ids": ["mrqa_triviaqa-validation-4725", "mrqa_hotpotqa-validation-2197", "mrqa_triviaqa-validation-2368", "mrqa_naturalquestions-validation-3962", "mrqa_triviaqa-validation-3074", "mrqa_naturalquestions-validation-4506", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-1540", "mrqa_naturalquestions-validation-6736", "mrqa_hotpotqa-validation-3625", "mrqa_naturalquestions-validation-4513", "mrqa_triviaqa-validation-1550", "mrqa_hotpotqa-validation-484", "mrqa_triviaqa-validation-5704", "mrqa_naturalquestions-validation-816", "mrqa_hotpotqa-validation-4621", "mrqa_squad-validation-6733", "mrqa_squad-validation-1612", "mrqa_triviaqa-validation-254", "mrqa_squad-validation-10423", "mrqa_squad-validation-2757", "mrqa_naturalquestions-validation-2884", "mrqa_hotpotqa-validation-984", "mrqa_naturalquestions-validation-9327", "mrqa_naturalquestions-validation-1489", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-5848", "mrqa_squad-validation-2531", "mrqa_triviaqa-validation-4560"], "unfixed_ids": ["mrqa_naturalquestions-validation-2020", "mrqa_squad-validation-7554"], "instant_fixing_rate": 0.9354838709677419, "instant_retention_rate": 0.9999999900000002}, {"timecode": 6, "before_eval": {"predictions": ["periodicals archive", "prevent the flame from being blown out", "2008", "2010", "n Carolina", "Euro. Beer", "90-60's", "unaided independent school", "Philadelphia Phillies", "times sign", "Best Supporting Actress", "Juice Newton's", "1960", "HTTP Secure ( HTTPS )", "typically closes for two and half weeks in late summer so it can be converted into the Haunted Mansion Holiday", "wichita", "monatomic", "Palm Springs is popular for its resort feel and nearby open spaces", "japan", "toads", "butterfly conservation", "donate", "The anterior interventricular branch of left coronary artery, ( also left anterior descending artery ( LAD ), or anterior descending branch )", "1.1 \u00d7 1011 metric tonnes", "buttermere", "mainly found in the mesophyll layers of a leaf", "Indian club ATK", "empire", "near Grande Comore, Comoros Islands", "India English, the word is used both as an attributive and non-attributive noun, and with either a marked ( `` - s '' ) or unmarked plural", "Norwegian language", "burning of fossil fuels"], "metric_results": {"EM": 0.21875, "QA-F1": 0.3080729166666667}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 0.08333333333333333, 1.0, 0.0, 0.375, 1.0, 0.0, 0.0, 0.0, 0.3, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-6644"], "after_eval": {"predictions": ["film director", "capillary action", "2008", "2010", "north carolina", "menorca", "70", "independent", "boston braves", "the symbol \u00d7", "Best Supporting Actress", "Juice Newton", "Super Bowl LII,", "Hypertext Transfer Protocol ( HTTP ) for secure communication", "late - September through early January", "chisholm trail", "simplest", "for its popular beaches", "japan", "true", "red admiral", "o", "the left coronary artery", "10%", "meyer", "concentrated in the leaves", "Republic of Ireland national team", "distinction", "23 November 1996", "lakh", "Norwegian language", "Carbon dioxide"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5795", "before_prediction": "wichita", "after_prediction": "chisholm trail"}, {"id": "mrqa_triviaqa-validation-4966", "before_prediction": "buttermere", "after_prediction": "meyer"}], "retained_ids": ["mrqa_hotpotqa-validation-5810", "mrqa_naturalquestions-validation-1679", "mrqa_squad-validation-7819", "mrqa_triviaqa-validation-3714", "mrqa_hotpotqa-validation-3919"], "fixed_ids": ["mrqa_triviaqa-validation-2465", "mrqa_naturalquestions-validation-4165", "mrqa_triviaqa-validation-6887", "mrqa_triviaqa-validation-5261", "mrqa_squad-validation-2659", "mrqa_squad-validation-6947", "mrqa_triviaqa-validation-105", "mrqa_naturalquestions-validation-10356", "mrqa_naturalquestions-validation-1618", "mrqa_naturalquestions-validation-2190", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-226", "mrqa_squad-validation-3463", "mrqa_squad-validation-2584", "mrqa_triviaqa-validation-7021", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-227", "mrqa_naturalquestions-validation-5582", "mrqa_squad-validation-4181", "mrqa_squad-validation-8821", "mrqa_hotpotqa-validation-4977", "mrqa_squad-validation-10042", "mrqa_naturalquestions-validation-6733", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-6644"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7142857132653061}, {"timecode": 7, "before_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "The Q'eqchi '", "a few", "The U.S. Army Chaplain insignia", "Kairi", "the traditional old boy network", "Ray Milland", "the Black Sea", "the last book accepted into the Christian biblical canon", "Bruno Mars", "172.41 / resistivity = % IACS", "gallantry", "most", "post\u2013World War II", "work oxen for haulage", "1998", "a priest", "most", "18 - season", "family member", "long-term environmental changes", "the 8-track cartridge", "The unbalanced force that accelerates the object", "Terrell Suggs", "decide on all the motions and amendments that have been moved that day", "a voyage of adventure", "Abraham Gottlob Werner", "George of Hanover", "present-day Charleston", "\"quiescent\"", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Panzer"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4506317110177404}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 1.0, 0.23529411764705882, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_hotpotqa-validation-2902"], "after_eval": {"predictions": ["the wisdom and prudence of certain decisions of procurement", "K'iche '", "a few", "right", "Kairi in the video game series \" Kingdom Hearts\".", "high schools lost their accreditation", "Lost Weekend", "Kalka River", "last book", "Beyonc\u00e9 and Bruno Mars", "conductivity", "george vi", "the most popular show", "1950s", "as work oxen", "2011", "a priest", "most", "2001", "family member", "long-term environmental changes", "8-track", "tangential force", "Mike Czerwien, Waynesburg University, 2002 -- 04", "vote", "a maritime signal, indicating that the vessel flying it is about to leave", "James Hutton", "george i", "Charleston Orange district", "\"quiescent\"", "Andy Cohen", "Panzer"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6297", "before_prediction": "the Black Sea", "after_prediction": "Kalka River"}, {"id": "mrqa_hotpotqa-validation-3898", "before_prediction": "post\u2013World War II", "after_prediction": "1950s"}], "retained_ids": ["mrqa_squad-validation-8374", "mrqa_squad-validation-3625", "mrqa_hotpotqa-validation-3846", "mrqa_squad-validation-3558", "mrqa_squad-validation-1863", "mrqa_squad-validation-4318", "mrqa_squad-validation-9598", "mrqa_hotpotqa-validation-3146"], "fixed_ids": ["mrqa_naturalquestions-validation-5522", "mrqa_naturalquestions-validation-5538", "mrqa_hotpotqa-validation-983", "mrqa_squad-validation-7296", "mrqa_triviaqa-validation-7415", "mrqa_naturalquestions-validation-859", "mrqa_squad-validation-108", "mrqa_triviaqa-validation-4196", "mrqa_triviaqa-validation-1293", "mrqa_squad-validation-7799", "mrqa_naturalquestions-validation-98", "mrqa_squad-validation-358", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-1142", "mrqa_squad-validation-10403", "mrqa_naturalquestions-validation-3474", "mrqa_squad-validation-9281", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-291", "mrqa_triviaqa-validation-781", "mrqa_squad-validation-3181", "mrqa_hotpotqa-validation-2902"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.7999999992}, {"timecode": 8, "before_eval": {"predictions": ["computational complexity theory", "george franklin", "44.0", "6.4 nanometers apart", "the eighth and eleventh episodes", "Carl Michael Edwards II", "400", "adrenals", "artes liberales", "Bowland Fells", "Edward V, King of England and Richard of Shrewsbury, Duke of York", "St. Louis County", "1918", "2018", "george smith", "circuit courts", "Pottawatomie County", "orangutan", "Albert Einstein", "The church tower", "Bromley-By-Bow", "Toronto", "foreigner", "110 miles (177 km )", "Kona coast of the island of Hawai\u02bb i about 12 mi south of Kailua-Kona", "Liberal conservatism", "largest gold rushes the world has ever seen", "six", "not guilty", "psychotherapeutic", "Quentin Coldwater", "acidic"], "metric_results": {"EM": 0.1875, "QA-F1": 0.29539930555555555}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [0.4, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2666666666666667, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_naturalquestions-validation-856", "mrqa_hotpotqa-validation-5513", "mrqa_triviaqa-validation-7506", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032"], "after_eval": {"predictions": ["computability theory", "formula one", "won gold in the half - pipe", "6.4 nanometers", "departing the show to star in CBS's upcoming sci - fi drama Intelligence", "Kyle Busch", "400", "kidneys", "liberal pursuits", "\"Switzerland of England\"", "Edward IV of England", "Eureka", "1828", "2018", "blades", "to ensure wide visibility and understanding of cases in a region", "Shawnee", "tortoise", "general relativity", "The church tower", "walford", "Montreal", "slow", "110 miles", "Kona coast", "liberal conservative", "gold rushes", "six degrees of freedom", "creative plea", "freudian", "New York", "acidic"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9459239130434782}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8695652173913043, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1360", "before_prediction": "artes liberales", "after_prediction": "liberal pursuits"}, {"id": "mrqa_naturalquestions-validation-7906", "before_prediction": "six", "after_prediction": "six degrees of freedom"}], "retained_ids": ["mrqa_hotpotqa-validation-3789", "mrqa_naturalquestions-validation-6991", "mrqa_squad-validation-5313", "mrqa_hotpotqa-validation-187"], "fixed_ids": ["mrqa_squad-validation-1705", "mrqa_triviaqa-validation-1521", "mrqa_naturalquestions-validation-6089", "mrqa_squad-validation-8869", "mrqa_hotpotqa-validation-5513", "mrqa_triviaqa-validation-7506", "mrqa_hotpotqa-validation-3161", "mrqa_naturalquestions-validation-8744", "mrqa_hotpotqa-validation-4212", "mrqa_hotpotqa-validation-5401", "mrqa_triviaqa-validation-7157", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-1934", "mrqa_naturalquestions-validation-3309", "mrqa_squad-validation-10369", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-582", "mrqa_triviaqa-validation-4268", "mrqa_hotpotqa-validation-1021", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-4812", "mrqa_squad-validation-2987", "mrqa_squad-validation-6915", "mrqa_triviaqa-validation-7767", "mrqa_hotpotqa-validation-1032"], "unfixed_ids": ["mrqa_naturalquestions-validation-856"], "instant_fixing_rate": 0.9615384615384616, "instant_retention_rate": 0.6666666655555555}, {"timecode": 9, "before_eval": {"predictions": ["the English phrase `` I Seek You ''", "Argentinian", "a report", "ricotta", "photosynthesis", "to celebrate Queen Victoria's diamond jubilee", "the Willard Hotel", "\"The Krypto Report\" a podcast produced by the white supremacist site \"The Daily Stormer\"", "spin triplet", "flour", "president", "citizens", "George, Margrave of Brandenburg-Ansbach", "a corruption of the Kamba version", "3D computer-animated comedy film", "Worcester Cold Storage and Warehouse Co.", "acting", "C. W. Grafton", "LED illuminated display", "Americans acting under orders", "IPod Classic", "My Sassy Girl", "prevent damage to the body", "The Edge of Night", "Highly combustible materials", "pedagogy", "envy", "root respiration", "soil", "death", "medium and heavy- Duty diesel trucks", "penis"], "metric_results": {"EM": 0.25, "QA-F1": 0.40611055611055613}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.13333333333333333, 0.4, 1.0, 1.0, 0.18181818181818182, 0.8571428571428571, 0.923076923076923, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.3333333333333333, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7272727272727272, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "after_eval": {"predictions": ["an instant messaging client", "an Argentinian professional tennis player", "Ear Institute at the University College London", "cake", "consumes ATP and oxygen, releases CO2, and produces no sugar", "animals and humans performimg various actions", "the White House", "The Daily Stormer", "antibonding", "shortcrust pastry ; however, more recently recipes have recommended a paste consisting of flour and water", "the President of the United States", "the citizens", "George, Margrave of Brandenburg-Ansbach", "a very precise notation of a correct African pronunciation", "3D computer-animated comedy", "Worcester Cold Storage and Warehouse Co. fire", "an acting career", "C. W. Grafton", "a liquid crystal on silicon ( L CoS ) ( based on an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "the first shot of the battle or the war", "iPod+HP", "\" That Bizarre Girl\"", "removes excess, unnecessary materials from the body fluids of an organism", "The Edge of Night", "phlogiston", "field trips", "vaskania ( \u03b2\u03b1\u03c3\u03ba\u03b1\u03bd\u03af\u03b1 )", "ATP", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "1987", "medium and heavy-duty diesel trucks", "Reproductive system"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8915451635846372}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.918918918918919, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-832", "before_prediction": "Argentinian", "after_prediction": "an Argentinian professional tennis player"}, {"id": "mrqa_squad-validation-5210", "before_prediction": "a report", "after_prediction": "Ear Institute at the University College London"}, {"id": "mrqa_naturalquestions-validation-1327", "before_prediction": "Americans acting under orders", "after_prediction": "the first shot of the battle or the war"}, {"id": "mrqa_naturalquestions-validation-8474", "before_prediction": "soil", "after_prediction": "in all land - living organisms, both alive and dead, as well as carbon stored in soils"}], "retained_ids": ["mrqa_naturalquestions-validation-4520", "mrqa_squad-validation-2582", "mrqa_hotpotqa-validation-133", "mrqa_squad-validation-5940"], "fixed_ids": ["mrqa_naturalquestions-validation-6844", "mrqa_triviaqa-validation-3387", "mrqa_squad-validation-8924", "mrqa_squad-validation-5618", "mrqa_triviaqa-validation-2703", "mrqa_hotpotqa-validation-3428", "mrqa_squad-validation-3442", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-321", "mrqa_squad-validation-8259", "mrqa_hotpotqa-validation-2673", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-1436", "mrqa_naturalquestions-validation-1294", "mrqa_squad-validation-3490", "mrqa_squad-validation-1879", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-1682", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-5823", "mrqa_naturalquestions-validation-3677"], "unfixed_ids": ["mrqa_naturalquestions-validation-754"], "instant_fixing_rate": 0.9583333333333334, "instant_retention_rate": 0.49999999937499995}, {"timecode": 10, "before_eval": {"predictions": ["Pope, Alexander (1688-1744) (DNB00)", "Hampton's hump and Hampton's line", "English law", "Las Vegas", "A status line", "the best known globetrotters", "cruiserweight", "the Merderet and Douve formed a natural defensive line protecting the western end of the Allied landing zone and at the same time limiting the Allies'potential to break out of the beachhead", "1987", "victor hugo", "monolith", "Queen Victoria", "10 logarithm", "Thor Heyerdahl", "the MGM Grand Garden Special Events Center", "3D Virtual Fashion Museum", "C. J. Anderson", "extremely difficult", "joseph smith", "60%", "Eagle Ridge Mall", "Pel\u00e9", "pressure on the public food supply", "Monastir / Tunisia / Africa", "the classical element fire", "Gomer Pyle", "at least 18 or 21 years old ( or have a legal guardian present )", "Ann Ward", "an American novelist and poet", "Jamestown", "Claude Monet", "tree growth stages"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5291903409090909}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.9090909090909091, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1860", "mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-3419", "mrqa_naturalquestions-validation-10205", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-6811", "mrqa_hotpotqa-validation-897", "mrqa_naturalquestions-validation-4837", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_naturalquestions-validation-8617", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "after_eval": {"predictions": ["portrait", "Hampton's hump and Hampton's line", "Scots law", "Las Vegas", "optional message body", "globetrotters", "cruiserweight title", "over the Merderet in the fictional town of Ramelle", "benito mussolini", "victor hugo", "menhir", "British Royal Family", "neither an acid nor a base", "Thor Heyerdahl", "Grand Garden Special Events Center", "valentino", "C. J. Anderson", "impossible", "joseph smith", "60%", "Winter Haven Mall", "Pel\u00e9", "indirectly aiding the war effort", "tunisia", "that parts of the air in the vessel were converted into the classical element fire", "Barney Fife", "usually required for using a shooting range in the United States ; the only common requirement is that the shooter must be at least 18 or 21 years old ( or have a legal guardian present ), and must sign a waiver prior to shooting", "Ann", "writer", "Virginia", "Claude Monet", "carbon related emissions"], "metric_results": {"EM": 0.75, "QA-F1": 0.8257440476190476}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-8006", "before_prediction": "A status line", "after_prediction": "optional message body"}, {"id": "mrqa_hotpotqa-validation-4162", "before_prediction": "the best known globetrotters", "after_prediction": "globetrotters"}, {"id": "mrqa_hotpotqa-validation-2016", "before_prediction": "cruiserweight", "after_prediction": "cruiserweight title"}, {"id": "mrqa_squad-validation-3525", "before_prediction": "the classical element fire", "after_prediction": "that parts of the air in the vessel were converted into the classical element fire"}], "retained_ids": ["mrqa_hotpotqa-validation-3149", "mrqa_naturalquestions-validation-1085", "mrqa_hotpotqa-validation-132", "mrqa_triviaqa-validation-6389", "mrqa_triviaqa-validation-3515", "mrqa_squad-validation-273", "mrqa_triviaqa-validation-6119", "mrqa_squad-validation-3018", "mrqa_hotpotqa-validation-1553", "mrqa_triviaqa-validation-6639"], "fixed_ids": ["mrqa_naturalquestions-validation-5651", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-4791", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-5682", "mrqa_triviaqa-validation-681", "mrqa_squad-validation-6811", "mrqa_hotpotqa-validation-897", "mrqa_triviaqa-validation-1451", "mrqa_hotpotqa-validation-3976", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1864", "mrqa_naturalquestions-validation-4803", "mrqa_squad-validation-4506"], "unfixed_ids": ["mrqa_triviaqa-validation-1860", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-4837", "mrqa_naturalquestions-validation-8617"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.7142857137755102}, {"timecode": 11, "before_eval": {"predictions": ["vincent Thomas \"Vince\" Lombardi", "Traumnovelle", "a Gender pay gap in favor of males in the labor market", "Treaty on the Functioning of the European Union", "absolute zero", "the narrator driving a truck owned by his brother, who died in action in the United States Army", "menace's dog Gnasher", "longer", "light rail system", "bowie", "king crimson", "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "killed in battle", "car", "arkansas", "North American Technate", "Queen Elizabeth II", "irritation", "the most - visited paid monument in the world", "Town House Galleria", "catfish aquaculture", "atomic number 53", "Evermoist", "2003", "An agricultural cooperative", "victor willsmeron", "nabucodonosor", "July 25, 1951", "Los Angeles Lakers", "the words `` speed limit '' omitted", "Jean Fernel ( 1497 -- 1558 ), a French physician", "the back of the head"], "metric_results": {"EM": 0.25, "QA-F1": 0.34213378533231475}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.7272727272727272, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.5, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_triviaqa-validation-7703", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "after_eval": {"predictions": ["american football", "Traumnovelle", "women not taking jobs due to marriage or pregnancy", "Treaty on European Union (TEU)", "100 \u00b0 C", "his brother", "eat porridge", "span", "dublin", "duke of edinburgh", "king crimson", "Pechenegs", "alamo", "ferdinand porsche", "arkansas", "Canada", "britten", "irritation", "visited paid monument", "Galleria Vittorio Emanuele II", "farm - raised catfish", "heaviest of the stable halogens", "Evermoist", "kuwait", "An agricultural cooperative", "norway", "Giuseppe Verdi", "1952", "Charlotte Hornets of the National Basketball Association ( NBA )", "advisory speed signs are classified as warning signs, not regulatory signs", "Jean Fernel", "back of the head"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9776785714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-1003", "before_prediction": "the Pechenegs, the Bulgars, and especially the Seljuk Turks", "after_prediction": "Pechenegs"}], "retained_ids": ["mrqa_hotpotqa-validation-2852", "mrqa_triviaqa-validation-5248", "mrqa_triviaqa-validation-7179", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-3921", "mrqa_naturalquestions-validation-6442"], "fixed_ids": ["mrqa_triviaqa-validation-5078", "mrqa_squad-validation-7447", "mrqa_squad-validation-4169", "mrqa_naturalquestions-validation-9194", "mrqa_naturalquestions-validation-9499", "mrqa_triviaqa-validation-7300", "mrqa_naturalquestions-validation-8877", "mrqa_triviaqa-validation-6692", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-5487", "mrqa_naturalquestions-validation-441", "mrqa_triviaqa-validation-6699", "mrqa_naturalquestions-validation-5184", "mrqa_hotpotqa-validation-3191", "mrqa_naturalquestions-validation-9031", "mrqa_naturalquestions-validation-9054", "mrqa_triviaqa-validation-7703", "mrqa_triviaqa-validation-792", "mrqa_triviaqa-validation-5526", "mrqa_hotpotqa-validation-4274", "mrqa_naturalquestions-validation-4653", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-5769"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8749999989062499}, {"timecode": 12, "before_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "fencing", "Margaret Thatcher", "Kevin Harlan as play-by-play announcer, Boomer Esiason and Dan Fouts as color analysts, and James Lofton and Mark Malone as sideline reporters", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "Cuban cigars", "byker grove", "Forbes", "Fort Williams (the latter two located on the Oneida Carry between the Mohawk River and Wood Creek at present-day Rome, New York", "Dandy", "spain", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Czech Kingdom", "Gregg Charles Popovich", "that not only would secularism and secular nationalism weaken the spiritual foundations of Islam and Muslim society, but that India's Hindu-majority population would crowd out Muslim heritage, culture and political influence", "for creative reasons and `` not a reflection '' of the actress'performance", "innate immune system", "uncle", "Originally a musician", "tulip", "1973", "maryland", "a perfect thriller", "California State Automobile Association", "faith", "Cinderella", "asphyxiated", "a fear of seeming rude"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5830647157853039}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.37037037037037035, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.47058823529411764]}}, "error_ids": ["mrqa_squad-validation-568", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_triviaqa-validation-4402", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "after_eval": {"predictions": ["Coldplay", "Frederick in a duet with Teresa James", "fencing", "Margaret Thatcher", "James Lofton and Mark Malone", "December 2013", "a centre for international trade", "Minoan civilization", "18 November", "cigars", "youth club", "Forbes in the Central West region of New South Wales, Australia", "garrisons", "Bonnie Lipton ( portrayed by Skyler Samuels )", "ring", "possibly Orwell himself, called upon to shoot an aggressive elephant while working as a police officer in Burma", "Kingdom of Bohemia", "Bob Hill", "secularism and secular nationalism", "creative reasons", "immunological memory", "uncle", "Originally a musician", "thumbelina", "1973", "Maryland's Catoctin Mountains", "john buchan", "regional tourism groups", "alone", "Cinderella", "communications problems", "lack of understanding of the legal ramifications, or due to a fear of seeming rude"], "metric_results": {"EM": 0.90625, "QA-F1": 0.91875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6902", "before_prediction": "byker grove", "after_prediction": "youth club"}, {"id": "mrqa_hotpotqa-validation-4904", "before_prediction": "Czech Kingdom", "after_prediction": "Kingdom of Bohemia"}, {"id": "mrqa_triviaqa-validation-6556", "before_prediction": "maryland", "after_prediction": "Maryland's Catoctin Mountains"}], "retained_ids": ["mrqa_squad-validation-93", "mrqa_naturalquestions-validation-6167", "mrqa_triviaqa-validation-1671", "mrqa_hotpotqa-validation-4826", "mrqa_hotpotqa-validation-2680", "mrqa_naturalquestions-validation-7224", "mrqa_hotpotqa-validation-1758", "mrqa_hotpotqa-validation-4263", "mrqa_triviaqa-validation-5852", "mrqa_naturalquestions-validation-2737", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-3870", "mrqa_naturalquestions-validation-2717", "mrqa_hotpotqa-validation-4165"], "fixed_ids": ["mrqa_squad-validation-568", "mrqa_hotpotqa-validation-1099", "mrqa_squad-validation-10202", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-444", "mrqa_hotpotqa-validation-2886", "mrqa_squad-validation-9793", "mrqa_naturalquestions-validation-5175", "mrqa_squad-validation-6678", "mrqa_triviaqa-validation-4402", "mrqa_triviaqa-validation-7371", "mrqa_squad-validation-2812", "mrqa_squad-validation-2372", "mrqa_squad-validation-3935", "mrqa_squad-validation-6924"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8235294112802768}, {"timecode": 13, "before_eval": {"predictions": ["The Omega Man", "president", "Jason Lee", "Napoleon's", "sliced bread", "3.7%", "high and persistent unemployment, in which inequality increases, has a negative effect on subsequent long-run economic growth", "Garthy &\u00a0T Travis", "Little Golden Lion", "Jerry Ekandjo ( until February 2018 ), Erastus Utoni   Deputy : Agnes Tjongarero", "discipline problems with the Flight Director's orders during their flight", "nine", "bear", "amyotrophic lateral sclerosis (ALS)", "\"Odorama\" whereby viewers could smell what they saw on screen through scratch and sniff cards", "a pioneer in watch design, manufacturing and distribution", "mid 1970s", "Torah or Bible", "Sicily", "American-born", "a jazz funeral without a body", "late November or early December", "Facebook", "bread", "Tim \"Ripper\" Owens", "Issaquah", "Nova Scotia and Acadia in the north", "cheated on Miley", "Punk", "Fort Snelling, Minnesota", "pinhole camera", "infrequent rain"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4874921085858586}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0, 0.33333333333333337, 0.3636363636363636, 1.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.3333333333333333, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1135", "mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-9897", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913"], "after_eval": {"predictions": ["The Omega Man", "president", "Dashiell Robert Parr / Dash, the Parrs'second child", "Napoleon's", "garthur Frederick Rohwedder", "3.7%", "negative effect", "garth", "Ecumenical Award", "Erastus Utoni", "discipline problems", "nine", "michael hordern", "Lou Gehrig's Disease", "\"Odorama\"", "Swiss made", "October 17, 1938", "religious", "Sicily", "American-born", "Those who follow the band just to enjoy the music", "late November or early December", "winklevoss twins", "beugel", "Tim \"Ripper\" Owens", "Issaquah", "King George's War", "Miley finally ends it with him", "alternative rock", "Fort Saint Anthony", "fox talbot", "infrequent rain"], "metric_results": {"EM": 0.875, "QA-F1": 0.8990384615384616}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-7638", "before_prediction": "sliced bread", "after_prediction": "garthur Frederick Rohwedder"}, {"id": "mrqa_triviaqa-validation-2779", "before_prediction": "Facebook", "after_prediction": "winklevoss twins"}, {"id": "mrqa_triviaqa-validation-2896", "before_prediction": "bread", "after_prediction": "beugel"}], "retained_ids": ["mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1509", "mrqa_squad-validation-830", "mrqa_squad-validation-7042", "mrqa_triviaqa-validation-4301", "mrqa_naturalquestions-validation-150", "mrqa_hotpotqa-validation-800", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-5716", "mrqa_hotpotqa-validation-1932", "mrqa_squad-validation-2656"], "fixed_ids": ["mrqa_squad-validation-7351", "mrqa_triviaqa-validation-6944", "mrqa_hotpotqa-validation-4058", "mrqa_naturalquestions-validation-6445", "mrqa_squad-validation-4060", "mrqa_triviaqa-validation-4486", "mrqa_hotpotqa-validation-1355", "mrqa_hotpotqa-validation-1591", "mrqa_hotpotqa-validation-1178", "mrqa_hotpotqa-validation-2037", "mrqa_squad-validation-1850", "mrqa_naturalquestions-validation-9897", "mrqa_squad-validation-10168", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7310", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-6913"], "unfixed_ids": ["mrqa_naturalquestions-validation-1135"], "instant_fixing_rate": 0.9444444444444444, "instant_retention_rate": 0.7857142851530612}, {"timecode": 14, "before_eval": {"predictions": ["Hong Kong", "on the property of the University of Hawai\u02bbi at M\u0101noa in Honolulu CDP", "Bronzeville", "river Phoenix", "FX option", "electromagnetic waves", "Islamic State of Iraq and the Levant", "fredic", "Dimensions in Time", "Surveyor 3", "January 1981", "gonadotropin - releasing hormone ( GnRH )", "a hymnic setting of Psalm 67's prayer for grace", "a Lutheran pastor in Hochfelden", "garren clough", "releasing the compressed air trapped in the cylinders, and slowing the vehicle", "Cheyenne rivers", "fossilization", "Hanna-barbera, The Jetsons", "\"comune\" in the heart of the southern (Dolomitic) Alps in the Veneto region of Northern Italy", "efficient and effective management of money ( funds ) in such a manner as to accomplish the objectives of the organization", "Alba Longa", "fredations of the Auditors", "ferris Strait", "Timo Hildebrand", "the state sector", "February 1940", "poverty", "a god of the Ammonites", "sclera", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.09375, "QA-F1": 0.26937680375180373}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 0.3636363636363636, 0.3333333333333333, 0.0, 0.6666666666666666, 0.5555555555555556, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_triviaqa-validation-116", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996"], "after_eval": {"predictions": ["Hong Kong", "Honolulu", "the British military", "dark blood", "foreign exchange option ( commonly shortened to just FX option or currency option )", "radio and microwave frequencies", "Wahhabi/Salafi extremist militant", "good luck", "Children in Need", "Apollo 12", "1981", "estrogen", "baptism", "Martin Luther", "brian clough", "slowing the vehicle", "Cheyenne", "organisms", "Hanna-Barbera", "the Veneto region of Northern Italy", "accomplish the objectives of the organization", "12 mi southeast of Rome", "binky", "tasmania", "Kur\u00e1nyi", "public sector ( also called the state sector )", "February", "poverty, the lack of access to education and weak government institutions", "king", "vitreous humor", "Judge Doom", "Texas Tower Sniper"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9455357142857144}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-970", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-5256"], "fixed_ids": ["mrqa_hotpotqa-validation-3757", "mrqa_hotpotqa-validation-3253", "mrqa_triviaqa-validation-46", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10046", "mrqa_squad-validation-7836", "mrqa_squad-validation-3999", "mrqa_naturalquestions-validation-5944", "mrqa_naturalquestions-validation-8180", "mrqa_squad-validation-2448", "mrqa_squad-validation-2509", "mrqa_triviaqa-validation-7153", "mrqa_naturalquestions-validation-727", "mrqa_squad-validation-5178", "mrqa_squad-validation-6023", "mrqa_hotpotqa-validation-1920", "mrqa_naturalquestions-validation-3302", "mrqa_hotpotqa-validation-1244", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-6019", "mrqa_hotpotqa-validation-241", "mrqa_squad-validation-8444", "mrqa_naturalquestions-validation-2085", "mrqa_triviaqa-validation-2996"], "unfixed_ids": ["mrqa_squad-validation-9751", "mrqa_triviaqa-validation-2442", "mrqa_triviaqa-validation-116"], "instant_fixing_rate": 0.896551724137931, "instant_retention_rate": 0.9999999966666667}, {"timecode": 15, "before_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome and city of San Antonio", "Bad Meets Evil", "Jupiter", "a friend and publicist", "afghanistan", "the name of a work gang", "Theodore Haynes ( 1986) and Julia Rose (1989)", "Gateshead", "inspired by Motown, Philly soul, and Earth, Wind & Fire ( particularly `` That's the Way of the World '' )", "The neck", "after the Spanish -- American War in the 1898 Treaty of Paris", "martial artist", "Payaya Indians", "stunt performances", "Godfather, Part II", "u.S. Parcel Post stamps", "art", "the common chimpanzee and the bonobo", "After World War II", "absolute temperature", "the private intelligence firm Stratfor", "Sam Waterston", "bicuspid", "Aegisthus", "3 December", "tallahassee", "an Eastern Bloc city", "fleet river", "WWSB and WOTV"], "metric_results": {"EM": 0.375, "QA-F1": 0.42351190476190476}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.2857142857142857, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333]}}, "error_ids": ["mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_triviaqa-validation-7512", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-6091"], "after_eval": {"predictions": ["comic", "Harry Potter and the Deathly Hallows", "the Flatbush section of Brooklyn, New York City", "the Alamodome", "Royce da 5'9\" ( Bad) and Eminem (Evil)", "galilei", "the editor of Electrical World magazine", "english patient", "the name of a work gang", "James Taylor", "a roof extension", "based on a Yogiism, or quotation from Yogi Berra", "midpiece", "1898", "martial artist", "Spanish", "stunt performances", "fred astaire", "postage stamp", "belgium", "Chimpanzees", "After World War II", "volume", "Jeremy Hammond", "Sam Waterston", "premolar", "Aegisthus", "25 November 2015", "florida", "prefabricated housing projects", "fleet river", "KMBC-TV and KQTV"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9270833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-413", "before_prediction": "3 December", "after_prediction": "25 November 2015"}, {"id": "mrqa_squad-validation-874", "before_prediction": "an Eastern Bloc city", "after_prediction": "prefabricated housing projects"}], "retained_ids": ["mrqa_hotpotqa-validation-2612", "mrqa_naturalquestions-validation-10416", "mrqa_hotpotqa-validation-3456", "mrqa_naturalquestions-validation-10439", "mrqa_hotpotqa-validation-4537", "mrqa_hotpotqa-validation-573", "mrqa_naturalquestions-validation-6266", "mrqa_hotpotqa-validation-2957", "mrqa_naturalquestions-validation-9451", "mrqa_triviaqa-validation-1588"], "fixed_ids": ["mrqa_naturalquestions-validation-1479", "mrqa_hotpotqa-validation-335", "mrqa_squad-validation-1374", "mrqa_triviaqa-validation-5979", "mrqa_hotpotqa-validation-1048", "mrqa_squad-validation-5249", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-5877", "mrqa_triviaqa-validation-7578", "mrqa_hotpotqa-validation-5188", "mrqa_naturalquestions-validation-365", "mrqa_hotpotqa-validation-1714", "mrqa_triviaqa-validation-1736", "mrqa_triviaqa-validation-1166", "mrqa_squad-validation-6091"], "unfixed_ids": ["mrqa_triviaqa-validation-7512"], "instant_fixing_rate": 0.95, "instant_retention_rate": 0.8333333326388889}, {"timecode": 16, "before_eval": {"predictions": ["albin", "cow's milk cheese", "benedict", "the back of the head of the tibia, below the level of the knee joint, and excluded from the formation of this joint", "fergus Mor of Dalriada", "the North Sea, through the former Meuse estuary, near Rotterdam", "Kalahari Desert", "afghanistan", "October 29, 1985", "Amway", "secondary school study", "Thomas Sowell", "the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha", "Golden Globe Award for Best Supporting Actor", "tanzibar", "Republic of Chad", "60-mile-wide river", "an open work crown", "using a baby as bait", "Fulham, Greater London, England", "French, English and Spanish", "come dine with me", "U.S. Marshals", "What's Up (TV series)", "supply chain management", "mars rover", "Stanislaw August Poniatowski", "modern matrices", "George", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.125, "QA-F1": 0.20753968253968252}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.888888888888889, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_triviaqa-validation-313", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_triviaqa-validation-4681", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_naturalquestions-validation-7144", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298", "mrqa_naturalquestions-validation-9087"], "after_eval": {"predictions": ["nightclub", "belgian", "blessed", "leg", "dunkeld", "North Sea", "Botswana", "sandy faldo", "March 30, 1983", "American Way", "secondary school study", "Milton Friedman", "President", "BBC Radio's \"The Show Band Show\"", "republic of tanzania", "niger", "tip of florida", "top row of windows", "Sam's soul is not with him", "London", "French, English and Spanish", "dave lamb", "Beyond the Clouds", "\"The Heirs\" (2013)", "blood, platelets, and plasma", "flowing water", "poland", "matrices", "geena Davis", "The three wise monkeys ( Japanese : \u4e09\u733f, Hepburn : san'en or sanzaru, alternatively \u4e09 \u5339 \u306e \u733f sanbiki no saru, literally `` three monkeys", "sheepskin", "the \"second city\" of Oahu"], "metric_results": {"EM": 0.875, "QA-F1": 0.9632745726495726}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-4094", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-2287"], "fixed_ids": ["mrqa_triviaqa-validation-123", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-9218", "mrqa_squad-validation-9319", "mrqa_triviaqa-validation-5997", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-2771", "mrqa_squad-validation-8037", "mrqa_naturalquestions-validation-3483", "mrqa_hotpotqa-validation-1566", "mrqa_triviaqa-validation-3238", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-4055", "mrqa_squad-validation-5407", "mrqa_hotpotqa-validation-4164", "mrqa_triviaqa-validation-639", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-1001", "mrqa_triviaqa-validation-1770", "mrqa_triviaqa-validation-866", "mrqa_squad-validation-8223", "mrqa_triviaqa-validation-298"], "unfixed_ids": ["mrqa_triviaqa-validation-313", "mrqa_triviaqa-validation-4681", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-9087"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.9999999975}, {"timecode": 17, "before_eval": {"predictions": ["belgian soft cheese", "Deadpool, X-Men: Apocalypse, Independence Day: Resurgence and Eddie the Eagle", "August 6, 1845", "isotopes", "Lula", "sovereign states", "president of the United States Senate", "intelligent design movement", "Bumblebee", "Bulgarian-Canadian", "30 months and for women 18 months ( although in accordance with a temporary order from January 10, 1968, six additional months were added to the mandatory service, 36 months for men and 24 months for women respectively", "opportunities will vary by geographic area and subject taught", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "Colgate University", "Roy Warren Spencer", "\"antiforms\" or where it buckles downwards, creating \"synforms\"", "fifth season", "V. Prakash Kumar", "Grace Nail Johnson", "Charlie Watts", "at least one prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "Bangor International Airport", "teachers who specialize in one subject and who tend to be more knowledgeable in that one area than a teacher who teaches many subjects", "180th meridian in a 360 \u00b0 - system", "Cartoon Network", "the Presiding Officer on the advice of the parliamentary bureau", "Miami Heat of the National Basketball Association (NBA)", "33", "grapevines", "District Superintendents of the Districts of the Annual Conference", "field hockey player Hannah Macleod", "William Hartnell's poor health"], "metric_results": {"EM": 0.0625, "QA-F1": 0.2168621188594015}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 0.0, 0.08333333333333334, 0.0, 0.0, 0.0, 0.33333333333333337, 0.40909090909090906, 0.19999999999999998, 0.16, 0.0, 0.8, 0.2222222222222222, 0.28571428571428575, 0.0, 0.3333333333333333, 0.0, 0.4347826086956522, 0.25, 0.08333333333333333, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3559", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_squad-validation-8966", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "after_eval": {"predictions": ["pear", "Independence Day", "August 6, 1845", "rubidium - 85", "James Zeebo", "the emerging norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "Dick Cheney", "\"Teach the Controversy\" campaign", "Ravage and the Decepticon Rampage", "Velichko Todorov Tsochev) is a Bulgarian-Canadian", "36 months for men and 24 months for women", "vary", "lower rates", "private liberal arts college", "Roy Spencer", "antiforms", "the second half of the third season", "Veyyil", "James Weldon Johnson", "Rocky Dzidzornu -- congas", "at least one prime number p with n < p < 2n \u2212 2, for any natural number n > 3", "Bangor Air National Guard Base", "knowledgeable", "antimeridian", "Cartoon Network", "Presiding Officer", "the Phoenix Suns", "33-member", "vitis", "Annual Conference Cabinet", "olympic bronze medals", "the Doctor's third on-screen regeneration"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9482460474308301}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4347826086956522, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-5628", "mrqa_hotpotqa-validation-3573"], "fixed_ids": ["mrqa_triviaqa-validation-1298", "mrqa_squad-validation-608", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-430", "mrqa_triviaqa-validation-314", "mrqa_hotpotqa-validation-113", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-1090", "mrqa_squad-validation-2053", "mrqa_squad-validation-7572", "mrqa_hotpotqa-validation-1895", "mrqa_squad-validation-5110", "mrqa_hotpotqa-validation-5787", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-4868", "mrqa_naturalquestions-validation-9171", "mrqa_hotpotqa-validation-2782", "mrqa_squad-validation-1904", "mrqa_naturalquestions-validation-10347", "mrqa_squad-validation-9405", "mrqa_hotpotqa-validation-613", "mrqa_hotpotqa-validation-4463", "mrqa_triviaqa-validation-3071", "mrqa_squad-validation-10074", "mrqa_triviaqa-validation-1130", "mrqa_squad-validation-7664"], "unfixed_ids": ["mrqa_naturalquestions-validation-3559", "mrqa_hotpotqa-validation-501", "mrqa_squad-validation-8966"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.999999995}, {"timecode": 18, "before_eval": {"predictions": ["The Rwandaandan genocide, also known as the genocide against the Tutsi", "Co-teachers work in sync with one another to create a climate of learning", "500 metres", "Vili Fualaau and Mary Kay Letourneau, a student and teacher who made news for their sexual relationship", "entertainment division", "distance covered by a vehicle ( for example as recorded by an odometer ), person, animal, or object along a curved path from a point A to a point B", "12", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "diego garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay Castle", "Spy Kids", "tennis", "MFSK and Olivia", "Baden-W\u00fcrttemberg", "Tesla Motors and Panasonic", "821", "basic channels", "pressure", "Hyuna", "highest'social efficiency'", "transposed", "the \" King of Cool\"", "American delegation from the Paris Peace Conference", "Socrates", "thirteenth", "r Ronnie kray twins", "HC Davos", "Michael Patrick Smith", "Qutab Ud - Din - Aibak, founder of the Delhi Sultanate"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6787202380952381}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false], "QA-F1": [0.2, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "error_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_triviaqa-validation-2683", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_hotpotqa-validation-4415", "mrqa_squad-validation-9841", "mrqa_triviaqa-validation-7100", "mrqa_naturalquestions-validation-10490"], "after_eval": {"predictions": ["Rwandan genocide", "in sync", "500 metres", "Piper", "ABC News", "displacement", "five", "Museum of Manufactures", "Edward Longshanks and the Hammer of the Scots", "diego garcia", "dundee", "the person compelled to pay for reformist programs", "fotheringhay", "Spy Kids", "venus williams", "Olivia", "Baden-W\u00fcrttemberg", "lithium-ion battery", "821", "basic channels", "pressure", "Hyuna", "races of highest'social efficiency'", "transposed", "King of Cool", "American delegation from the Paris Peace Conference", "socrates", "thirteenth", "violet", "HC Davos", "Michael Patrick Smith", "Iltutmish"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9895833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-523", "mrqa_squad-validation-5257", "mrqa_hotpotqa-validation-2993", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-5036", "mrqa_naturalquestions-validation-5215", "mrqa_hotpotqa-validation-2201", "mrqa_squad-validation-9074", "mrqa_hotpotqa-validation-44", "mrqa_squad-validation-2862", "mrqa_triviaqa-validation-4279", "mrqa_hotpotqa-validation-1855", "mrqa_naturalquestions-validation-4497", "mrqa_hotpotqa-validation-4068", "mrqa_squad-validation-9827", "mrqa_triviaqa-validation-1764", "mrqa_hotpotqa-validation-3798", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-511"], "fixed_ids": ["mrqa_hotpotqa-validation-1441", "mrqa_squad-validation-1914", "mrqa_hotpotqa-validation-2145", "mrqa_squad-validation-6029", "mrqa_naturalquestions-validation-5360", "mrqa_naturalquestions-validation-3300", "mrqa_triviaqa-validation-2683", "mrqa_triviaqa-validation-2715", "mrqa_naturalquestions-validation-2222", "mrqa_hotpotqa-validation-4415", "mrqa_triviaqa-validation-7100", "mrqa_naturalquestions-validation-10490"], "unfixed_ids": ["mrqa_squad-validation-9841"], "instant_fixing_rate": 0.9230769230769231, "instant_retention_rate": 0.9999999994736841}, {"timecode": 19, "before_eval": {"predictions": ["a Ghanaian boxer", "Norman Macdonnell", "aragon", "percent", "trans-Pacific flight from the United States to Australia", "Sharman Joshi", "sit in a classroom and do work, write lines or a punishment essay, or sit quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q", "Ana", "New Brunswick", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "david bowie", "Indian", "fortitude", "1889", "Nicki Minaj", "comic opera", "surname", "venus", "friedrich", "Teen Titans Go!", "Norman invaders", "Tel Aviv", "two degrees of freedom", "peninsula", "taking blood", "youngest TV director ever", "Southern Progress Corporation"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6243055555555556}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_naturalquestions-validation-7881"], "after_eval": {"predictions": ["a Ghanaian boxer", "John Meston", "zaragoza", "7.8", "trans-Pacific flight", "Soha Ali Khan", "quietly", "Forster I, Forster II, and Forster III", "p is not a prime factor of q", "Ana", "in Cherry Hill", "`` Goodbye Toby ''", "call me ishmael", "amelia earhart", "Six Degrees of Separation", "david bowie", "Star Plus", "fortitude", "1889", "Sir Mix - a-Lot", "slave of duty", "surnames", "portier", "marx", "Teen Titans Go!", "Norman invaders", "Tel Aviv", "two", "peninsulas", "taking blood", "youngest TV director ever", "Sunset Publishing Corporation"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9166666666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-3049", "before_prediction": "Indian", "after_prediction": "Star Plus"}, {"id": "mrqa_naturalquestions-validation-2064", "before_prediction": "peninsula", "after_prediction": "peninsulas"}, {"id": "mrqa_hotpotqa-validation-2627", "before_prediction": "Southern Progress Corporation", "after_prediction": "Sunset Publishing Corporation"}], "retained_ids": ["mrqa_hotpotqa-validation-2262", "mrqa_squad-validation-5538", "mrqa_squad-validation-9214", "mrqa_hotpotqa-validation-5710", "mrqa_naturalquestions-validation-9284", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-6935", "mrqa_naturalquestions-validation-4354", "mrqa_triviaqa-validation-1995", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-4951", "mrqa_hotpotqa-validation-57", "mrqa_naturalquestions-validation-1565", "mrqa_hotpotqa-validation-5061", "mrqa_triviaqa-validation-3552", "mrqa_hotpotqa-validation-4020"], "fixed_ids": ["mrqa_hotpotqa-validation-2389", "mrqa_triviaqa-validation-6901", "mrqa_squad-validation-6963", "mrqa_hotpotqa-validation-2943", "mrqa_hotpotqa-validation-303", "mrqa_squad-validation-1942", "mrqa_naturalquestions-validation-3951", "mrqa_naturalquestions-validation-8025", "mrqa_triviaqa-validation-2015", "mrqa_squad-validation-3151", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-4068", "mrqa_naturalquestions-validation-7881"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8421052627146814}, {"timecode": 20, "before_eval": {"predictions": ["gas turbines", "Robert Smigel", "drawings", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas", "Mercury astronaut", "Ribosomes", "kookaburra", "six", "Scott Bakula", "\"I Miss You a Little\"", "Pentecost", "b Belfast", "in heliocentric orbits", "Sulla", "Super Bowl LII, following the 2017 season", "Golden Globe", "Swahili", "to bring about necessary change", "novelist", "Pantone Matching System (PMS)", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "sea wasp", "lower chamber", "\"teleforce\" weapon", "Thunderbird of Native American tradition", "giving Super Bowl ever", "29.7%", "4077th mash"], "metric_results": {"EM": 0.5, "QA-F1": 0.608008658008658}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 0.4, 1.0, 1.0, 0.48484848484848486, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.888888888888889, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_naturalquestions-validation-4590", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393"], "after_eval": {"predictions": ["gas turbines", "Robert Smigel, Michael Koman and David Feldman", "prints and architectural drawings", "Mos Def", "kaleidoscope", "British Columbia, in the Abbotsford, Vancouver and Langley areas in August 2017, with a mansion in the Aldergrove area of Langely serving as the property at the centre of the story", "Mercury astronaut", "Ribosomes", "kookaburra", "six-time", "Scott Bakula as Dwayne `` King '' Cassius Pride, NCIS Supervisory Special Agent", "\"Ain't Got Nothin' on Us\"", "Cozonac ( Romanian pronunciation : ( kozo\u02c8nak ) ) or Kozunak", "gerry adams", "Moon's surface", "Sulla", "Super Bowl LII", "Golden Globe", "Kenya's various ethnic groups typically speak their mother tongues within their own communities", "trust God's word", "turkey", "CMYKOG process", "Qutab - ud - din Aibak", "Reunited Worlds", "Santa Clara", "jellyfish", "lower chamber", "\"teleforce\" weapon", "Native American", "giving Super Bowl", "29.7%", "4077th mash"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9783653846153846}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1279", "before_prediction": "Scott Bakula", "after_prediction": "Scott Bakula as Dwayne `` King '' Cassius Pride, NCIS Supervisory Special Agent"}], "retained_ids": ["mrqa_squad-validation-3368", "mrqa_hotpotqa-validation-3547", "mrqa_triviaqa-validation-5091", "mrqa_squad-validation-3964", "mrqa_hotpotqa-validation-2434", "mrqa_triviaqa-validation-3486", "mrqa_hotpotqa-validation-2407", "mrqa_hotpotqa-validation-2795", "mrqa_naturalquestions-validation-10509", "mrqa_hotpotqa-validation-4015", "mrqa_squad-validation-315", "mrqa_hotpotqa-validation-1906", "mrqa_squad-validation-1521", "mrqa_squad-validation-7272", "mrqa_triviaqa-validation-935"], "fixed_ids": ["mrqa_hotpotqa-validation-779", "mrqa_squad-validation-5273", "mrqa_naturalquestions-validation-4590", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-4627", "mrqa_naturalquestions-validation-5168", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3623", "mrqa_naturalquestions-validation-2448", "mrqa_squad-validation-8464", "mrqa_squad-validation-2280", "mrqa_triviaqa-validation-6721", "mrqa_hotpotqa-validation-4558", "mrqa_triviaqa-validation-1453", "mrqa_hotpotqa-validation-2064", "mrqa_squad-validation-393"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9374999994140625}, {"timecode": 21, "before_eval": {"predictions": ["a Czech word, robota, meaning `` forced labor ''", "rebecca", "various registries", "blood transfusion", "alison moyet", "1926", "black hole", "John Jortin", "cede the former", "Waylon Jennings", "auction", "research universities and other public and private institutions", "Scottish", "Smith Jerrod", "Beatrix Potter", "World Summit of Nobel Peace Laureates", "proteins", "2000", "exceeds any given number", "ITV News at Ten", "padlocking the gates and using sickles to deflate one of the large domes covering two satellite dishes", "1960s", "R\u00e5", "western portions of the Great Lakes region", "Protestant", "casino Royale", "4 in", "george marx", "Western Atlantic ctenophore Mnemiopsis leidyi", "Menace II Society", "quarterback", "Steve and Rudy"], "metric_results": {"EM": 0.5, "QA-F1": 0.602380309641339}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false], "QA-F1": [0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2222222222222222, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693, 1.0, 0.25, 0.5454545454545454]}}, "error_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_hotpotqa-validation-3780", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_squad-validation-2709", "mrqa_naturalquestions-validation-5439", "mrqa_hotpotqa-validation-35", "mrqa_naturalquestions-validation-5897", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_naturalquestions-validation-8689", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "after_eval": {"predictions": ["a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "dust jacket", "domestic cat", "dog", "Yazoo", "1926", "sun", "dreams", "They viewed the economic value of the Caribbean islands' sugar cane to be greater and easier to defend than the furs from the continent", "Johnny Cash, Waylon Jennings", "auction", "private", "Scottish", "waiter turned emerging young actor Smith Jerrod", "Beatrix Potter", "World Summit of Nobel Peace Laureates", "proteins", "2001", "exceeds any given number", "alastair burnet", "padlocking the gates", "1969", "R\u00e5", "the Iroquoian-speaking Cherokee tribes", "Protestant", "casino royale", "4 in", "oh so Sharp", "ctenophore Mnemiopsis leidyi", "Menace II Society", "a member of the Green Bay Packers, serving as a backup quarterback to Brett Favre and holder on placekicks", "trio with his younger brothers Steve and Rudy"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8181818181818181}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-5239", "before_prediction": "rebecca", "after_prediction": "dust jacket"}, {"id": "mrqa_triviaqa-validation-751", "before_prediction": "blood transfusion", "after_prediction": "dog"}, {"id": "mrqa_triviaqa-validation-4383", "before_prediction": "alison moyet", "after_prediction": "Yazoo"}, {"id": "mrqa_triviaqa-validation-192", "before_prediction": "black hole", "after_prediction": "sun"}, {"id": "mrqa_squad-validation-10177", "before_prediction": "western portions of the Great Lakes region", "after_prediction": "the Iroquoian-speaking Cherokee tribes"}], "retained_ids": ["mrqa_hotpotqa-validation-4430", "mrqa_triviaqa-validation-2961", "mrqa_hotpotqa-validation-4950", "mrqa_squad-validation-5345", "mrqa_squad-validation-3627", "mrqa_squad-validation-9020", "mrqa_hotpotqa-validation-2399", "mrqa_squad-validation-8456", "mrqa_triviaqa-validation-6950", "mrqa_naturalquestions-validation-6832", "mrqa_hotpotqa-validation-2642"], "fixed_ids": ["mrqa_naturalquestions-validation-3609", "mrqa_hotpotqa-validation-3780", "mrqa_squad-validation-2412", "mrqa_squad-validation-10502", "mrqa_hotpotqa-validation-5480", "mrqa_squad-validation-2709", "mrqa_naturalquestions-validation-5439", "mrqa_naturalquestions-validation-5897", "mrqa_triviaqa-validation-1954", "mrqa_squad-validation-6844", "mrqa_naturalquestions-validation-8689", "mrqa_triviaqa-validation-1555", "mrqa_squad-validation-4648", "mrqa_naturalquestions-validation-2758", "mrqa_hotpotqa-validation-4676"], "unfixed_ids": ["mrqa_hotpotqa-validation-35"], "instant_fixing_rate": 0.9375, "instant_retention_rate": 0.6874999995703125}, {"timecode": 22, "before_eval": {"predictions": ["Doug Pruzan", "England", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "his friends, Humpty Dumpty and Kitty Softpaws", "National Party", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "are ceremonially placed on the heads of Christians on Ash Wednesday, either by being sprinkled over their heads or, in English - speaking countries, more often by being marked on their foreheads as a visible cross", "red Army", "jules verne", "Augustus Waters", "1547", "Tony Blair", "often damaging", "June 11, 1973", "Kenya", "chronological collection of critical quotations", "ethelbald I", "long - standing policy of neutrality", "Cargill", "Cineplex Entertainment in Canada", "It's Always Sunny in Philadelphia", "1990", "September 21, 2017", "The weak force", "Blandings", "Dexter", "Manhattan Project", "the Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6005650252525252}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.16, 0.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-1883", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_triviaqa-validation-6872", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_naturalquestions-validation-661", "mrqa_triviaqa-validation-2179", "mrqa_naturalquestions-validation-1328"], "after_eval": {"predictions": ["Doug Pruzan", "English language patronymic surname", "Thursday", "Mediterranean Shipping Company", "benjamin franklin", "Kitty Softpaws", "National Party", "Parliamentarians (\"Roundheads\") and Royalists (\"Cavaliers\")", "the presence of correctly oriented P waves", "reminds worshippers of their sinfulness and mortality and thus, implicitly, of their need to repent in time", "smersh", "jules verne", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1619", "Tony Blair: The Journey", "often damaging", "July 26, 1959", "Masai Mara", "chronological collection of critical quotations", "edward ii", "long - standing policy of neutrality", "United Healthcare", "AMC Theatres", "It's Always Sunny in Philadelphia", "summer of 1990 and continued until 1992", "September 21, 2017", "weak force", "pig", "Dexter", "Development of Substitute Materials", "Chronicles of Barsetshire", "vast areas"], "metric_results": {"EM": 0.96875, "QA-F1": 0.99375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4731", "before_prediction": "Tony Blair", "after_prediction": "Tony Blair: The Journey"}], "retained_ids": ["mrqa_naturalquestions-validation-1719", "mrqa_squad-validation-9568", "mrqa_naturalquestions-validation-9789", "mrqa_triviaqa-validation-5698", "mrqa_squad-validation-2884", "mrqa_hotpotqa-validation-2959", "mrqa_naturalquestions-validation-7731", "mrqa_triviaqa-validation-2797", "mrqa_squad-validation-2769", "mrqa_hotpotqa-validation-5655", "mrqa_naturalquestions-validation-7356", "mrqa_hotpotqa-validation-1435", "mrqa_naturalquestions-validation-190", "mrqa_squad-validation-10459", "mrqa_hotpotqa-validation-1929", "mrqa_hotpotqa-validation-2448", "mrqa_squad-validation-2828"], "fixed_ids": ["mrqa_naturalquestions-validation-1883", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4556", "mrqa_triviaqa-validation-1578", "mrqa_naturalquestions-validation-3859", "mrqa_hotpotqa-validation-3944", "mrqa_hotpotqa-validation-482", "mrqa_squad-validation-8280", "mrqa_triviaqa-validation-6872", "mrqa_hotpotqa-validation-2511", "mrqa_hotpotqa-validation-803", "mrqa_naturalquestions-validation-661", "mrqa_triviaqa-validation-2179", "mrqa_naturalquestions-validation-1328"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.944444443919753}, {"timecode": 23, "before_eval": {"predictions": ["an additional $105 billion in growth to the country's economy over five years", "mononucleosis", "about two-thirds the size", "1937 Austin Seven Ruby Open Top Tourer", "Havana Nights", "red lead primer and a lead - based topcoat", "Luna Park", "Best Animated Feature", "European Union institutions", "(381.6 days)", "Death Wish Coffee", "NASA's CAL IPSO satellite", "lesser celandine", "Ulbricht", "Ronald Ralph \"Ronnie\" Schell", "artemisinin- Based therapy", "Mumbai, Maharashtra", "the east of Ireland", "1940", "2017 / 18 Divisional Round game against the New Orleans Saints", "possibly 1707", "on Fresno's far southeast side, bounded by Chestnut Avenue to the West", "the south western escarpment of the Jos Plateau", "bobby samedi", "Incudomalleolar joint ( more correctly called incudomallear joint )", "tennis", "Democritus", "Santa Clara Marriott", "Appassionata", "political power generated by wealth", "polynomial-time reductions", "Ted Ginn Jr"], "metric_results": {"EM": 0.21875, "QA-F1": 0.39810320398555693}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true, false, true], "QA-F1": [0.3076923076923077, 1.0, 0.0, 0.4444444444444445, 0.0, 0.25, 0.5, 0.6666666666666666, 0.25, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.3636363636363636, 0.6666666666666666, 0.0, 0.0, 0.0, 0.8235294117647058, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0]}}, "error_ids": ["mrqa_squad-validation-7389", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-542", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750"], "after_eval": {"predictions": ["$105 billion", "mono", "25 nm", "austin seven", "dirty dancing", "red", "Steeplechase Park", "Academy Award for Best Animated Feature", "the European Convention on Human Rights in 1950 and the establishment of the European Court of Human Rights", "American record for the most time in space (381.6 days)", "nine", "NASA", "yellow", "Khrushchev", "Jack Cassidy", "malaria", "Mumbai", "the east of Ireland", "1940", "2017 / 18", "1707", "Sunnyside", "till September", "live and let die", "Incudomalleolar joint ( more correctly called incudomallear joint )", "moffitt", "Leucippus", "Santa Clara Marriott", "beethoven", "the use of political power generated by wealth by certain groups to shape government policies", "the bound on the complexity of reductions", "Ted Ginn Jr"], "metric_results": {"EM": 0.875, "QA-F1": 0.9285462989023361}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 0.5263157894736842, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-3716", "before_prediction": "mononucleosis", "after_prediction": "mono"}, {"id": "mrqa_hotpotqa-validation-2741", "before_prediction": "(381.6 days)", "after_prediction": "American record for the most time in space (381.6 days)"}, {"id": "mrqa_squad-validation-7481", "before_prediction": "political power generated by wealth", "after_prediction": "the use of political power generated by wealth by certain groups to shape government policies"}], "retained_ids": ["mrqa_hotpotqa-validation-220", "mrqa_naturalquestions-validation-4048", "mrqa_squad-validation-327", "mrqa_squad-validation-769"], "fixed_ids": ["mrqa_squad-validation-7389", "mrqa_squad-validation-8850", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3933", "mrqa_naturalquestions-validation-1617", "mrqa_hotpotqa-validation-4348", "mrqa_hotpotqa-validation-789", "mrqa_squad-validation-4118", "mrqa_squad-validation-542", "mrqa_squad-validation-4228", "mrqa_triviaqa-validation-6107", "mrqa_naturalquestions-validation-3714", "mrqa_hotpotqa-validation-1782", "mrqa_triviaqa-validation-3595", "mrqa_hotpotqa-validation-26", "mrqa_naturalquestions-validation-3052", "mrqa_squad-validation-2420", "mrqa_squad-validation-4662", "mrqa_naturalquestions-validation-2212", "mrqa_triviaqa-validation-571", "mrqa_triviaqa-validation-3420", "mrqa_hotpotqa-validation-2340", "mrqa_triviaqa-validation-6781", "mrqa_squad-validation-1750"], "unfixed_ids": ["mrqa_naturalquestions-validation-1731"], "instant_fixing_rate": 0.96, "instant_retention_rate": 0.571428570612245}, {"timecode": 24, "before_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemists", "WBO lightweight title", "Maluku", "Saturday", "Albany", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights.", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "graduateuates from the polytechnics and colleges can then join the workforce and later obtain a specialised higher diploma qualification after a further one to two years of training, or join the university", "bingo", "Eugene", "comparable to the seven Wonders of the World", "2p + 1", "coupe", "Fa Ze YouTubers", "the nine circles of Hell", "the Khwarezmian city of Otrar", "along the coast, the settlements were growing into the interior", "the Friars Minor Conventual (O.F.M. Conv)", "CD Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts, which are sticky and adhere to prey", "Patrick Wachsberger and Erik Feig of Summit Entertainment produced with Adam Shankman and Jennifer Gibgot of Offspring Entertainment", "STS-51-L", "a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather", "president Fran\u00e7ois"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6294847309553192}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.10256410256410256, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 0.7058823529411764, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3340", "mrqa_hotpotqa-validation-3247", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_squad-validation-4417", "mrqa_hotpotqa-validation-4542", "mrqa_naturalquestions-validation-6508", "mrqa_triviaqa-validation-1306"], "after_eval": {"predictions": ["2003", "NADP+", "Pitt", "alchemists", "WBO lightweight title", "spice islands", "Saturday", "Kent", "They arranged for Israel to pull back from the Sinai Peninsula and the Golan Heights.", "1971", "J.R. R. Tolkien", "John Elway", "Instagram", "join a vocational youth/village polytechnic or make their own arrangements for an apprenticeship program", "31", "He is from Pago Pago, American Samoa and played college football at Oregon.", "comparable to the seven Wonders of the World", "2p + 1", "coupe", "FaZe Rug", "dante alighieri", "Muslim", "along the coast, the settlements were growing into the interior", "poor clares", "Club Deportivo Castell\u00f3n", "1780 -- 1830", "12\u20134", "having colloblasts", "Anne Fletcher", "STS-51-L", "if a groundhog ( Deitsch : Grundsau, Grunddax, Dax ) emerging from its burrow on this day sees a shadow due to clear weather", "france"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9781936813186813}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7307692307692308, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_squad-validation-8876", "mrqa_squad-validation-10261", "mrqa_triviaqa-validation-3678", "mrqa_hotpotqa-validation-4444", "mrqa_hotpotqa-validation-3290", "mrqa_naturalquestions-validation-9011", "mrqa_squad-validation-3741", "mrqa_squad-validation-5399", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-10381", "mrqa_hotpotqa-validation-309", "mrqa_squad-validation-8979", "mrqa_naturalquestions-validation-2164", "mrqa_squad-validation-10148", "mrqa_naturalquestions-validation-3504", "mrqa_squad-validation-67", "mrqa_hotpotqa-validation-1814"], "fixed_ids": ["mrqa_triviaqa-validation-3340", "mrqa_squad-validation-8473", "mrqa_triviaqa-validation-667", "mrqa_hotpotqa-validation-3080", "mrqa_naturalquestions-validation-3297", "mrqa_triviaqa-validation-3847", "mrqa_squad-validation-6204", "mrqa_triviaqa-validation-5304", "mrqa_hotpotqa-validation-5588", "mrqa_squad-validation-4417", "mrqa_hotpotqa-validation-4542", "mrqa_triviaqa-validation-1306"], "unfixed_ids": ["mrqa_hotpotqa-validation-3247", "mrqa_naturalquestions-validation-6508"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.9999999994444444}, {"timecode": 25, "before_eval": {"predictions": ["gymnastic", "Sarah's slave, Abraham's concubine", "40 million", "loyalty to the U.S. Constitution", "1923", "Winter Park is a suburban city in Orange County, Florida, United States.", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "Bonnie and Clyde", "iteratively", "geese", "effect", "Brisbane", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "lower rates of economic growth when human capital is neglected for high-end consumption", "In at least some species, juveniles are capable of reproduction before reaching the adult size and shape", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "the way they used `` rule '' and `` method '' to go about their religious affairs", "A Chorus Line", "2,664 rooms", "iPhone 6 Plus", "a chute", "Claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "cleaning, catering and security porterage business", "Symphony No. 7 in A major, Op. 92", "gironde estuary", "1603", "ranked above the two personal physicians of the Emperor", "marzipan", "make direct amends to such people wherever possible, except when to do so would injure them or others", "Chicago Cubs"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5986921575156869}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.9333333333333333, 0.4615384615384615, 0.923076923076923, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.3636363636363636, 0.8, 0.6, 0.6666666666666666, 1.0, 0.22222222222222224, 0.0, 0.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-5788", "mrqa_hotpotqa-validation-5762", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7301", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "after_eval": {"predictions": ["gymnastic", "abram", "40 million", "loyalty to the U.S. Constitution", "1923", "Orlando\u2013Kissimmee\u2013 Sanford", "January 19, 1962", "PPA, Pattugliatore Polivalente d'Altura", "crimson tide", "iteratively", "geese", "effect", "pacific", "Peter Davison, Colin Baker and Sylvester McCoy", "February 14, 1859", "lower", "juveniles are capable of reproduction before reaching the adult size", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "musical", "2,664", "iPhone 6 Plus", "a chute beneath his or her feet", "Claims adjuster", "cleaning, catering and security", "Symphony No. 7", "gironde d\u00e9partement", "uncertain, though a performance at Wilton House in 1603 has been suggested as a possibility", "Ranked positions", "sugar Plum Fairy", "We admitted we were powerless over alcohol -- that our lives had become unmanageable.", "baseball team"], "metric_results": {"EM": 0.875, "QA-F1": 0.9183438843764931}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.782608695652174, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6545", "before_prediction": "1603", "after_prediction": "uncertain, though a performance at Wilton House in 1603 has been suggested as a possibility"}], "retained_ids": ["mrqa_triviaqa-validation-6059", "mrqa_hotpotqa-validation-1818", "mrqa_naturalquestions-validation-10169", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-3369", "mrqa_hotpotqa-validation-3977", "mrqa_squad-validation-9532", "mrqa_triviaqa-validation-6941", "mrqa_squad-validation-7382", "mrqa_squad-validation-7677", "mrqa_hotpotqa-validation-4720", "mrqa_triviaqa-validation-2454"], "fixed_ids": ["mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-7336", "mrqa_squad-validation-7301", "mrqa_naturalquestions-validation-5939", "mrqa_hotpotqa-validation-859", "mrqa_hotpotqa-validation-4282", "mrqa_naturalquestions-validation-4996", "mrqa_naturalquestions-validation-7309", "mrqa_hotpotqa-validation-1414", "mrqa_hotpotqa-validation-499", "mrqa_triviaqa-validation-2098", "mrqa_squad-validation-6328", "mrqa_triviaqa-validation-6221", "mrqa_naturalquestions-validation-2481", "mrqa_triviaqa-validation-1259"], "unfixed_ids": ["mrqa_hotpotqa-validation-5762", "mrqa_squad-validation-4637", "mrqa_naturalquestions-validation-390"], "instant_fixing_rate": 0.8421052631578947, "instant_retention_rate": 0.9230769223668639}, {"timecode": 26, "before_eval": {"predictions": ["Jewish audiences", "north of the Lakes Region and south of the Kancamagus Highway", "Magic formula investing", "true history", "Haleiwa Ali'i Beach Park", "1910\u20131940", "non-teaching posts", "Catch Me Who Can", "jazz saxophonist", "tennis", "4,000", "the founder of the Yuan dynasty", "wuthering Heights", "canal", "spice", "The Simpsons Spin-Off Showcase", "The planner Raymond Unwin and the architect Barry Parker", "San Bernardino", "The city has an extensive neoclassical centre referred to as Tyneside Classical largely developed in the 1830s by Richard Grainger and John Dobson, and recently extensively restored.", "Albany High School (AHS)", "charbagh", "Sergeant First Class", "Anakin Skywalker", "seek jury nullification", "Cee - Lo", "Anglican", "mammy two Shoes", "battleship", "magnetism", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "redistributive", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.25, "QA-F1": 0.3562728937728938}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, false, true], "QA-F1": [0.8, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.07692307692307693, 0.8571428571428571, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_squad-validation-6148", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6224", "mrqa_hotpotqa-validation-2436", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319"], "after_eval": {"predictions": ["to Jewish audiences", "south", "an investment technique outlined by Joel Greenblatt", "kelly", "City and County of Honolulu", "1910\u20131940", "those who refuse vetting", "the Catch Me Who Can in 1808", "jazz", "margaret smith court", "3,677 seated", "Khagan", "catherine and heathcliff", "birmingham", "cassia", "the Simpson family", "The planner Raymond Unwin and the architect Barry Parker", "Los Angeles", "the Eldon Square Shopping Centre", "Albany High School", "the Government House at New Delhi ( now known as Rashtrapati Bhavan )", "First Class", "Anakin Skywalker", "nullification", "the closing scene of the final episode of the first season", "The Church of England", "h Hattie McDaniel", "scharnhorst", "hypnosis", "sitting directly on the Gulf of Guinea on the Atlantic Ocean in Nigeria", "opportunity-based entrepreneurship", "January 11, 1755 or 1757July"], "metric_results": {"EM": 0.8125, "QA-F1": 0.9125}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-3176", "before_prediction": "Catch Me Who Can", "after_prediction": "the Catch Me Who Can in 1808"}, {"id": "mrqa_naturalquestions-validation-800", "before_prediction": "charbagh", "after_prediction": "the Government House at New Delhi ( now known as Rashtrapati Bhavan )"}, {"id": "mrqa_hotpotqa-validation-4585", "before_prediction": "Sergeant First Class", "after_prediction": "First Class"}], "retained_ids": ["mrqa_squad-validation-7435", "mrqa_naturalquestions-validation-2214", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-7801", "mrqa_hotpotqa-validation-945"], "fixed_ids": ["mrqa_naturalquestions-validation-3027", "mrqa_hotpotqa-validation-1426", "mrqa_triviaqa-validation-6772", "mrqa_hotpotqa-validation-4553", "mrqa_squad-validation-1994", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-6689", "mrqa_hotpotqa-validation-5", "mrqa_squad-validation-6148", "mrqa_triviaqa-validation-3472", "mrqa_triviaqa-validation-7304", "mrqa_hotpotqa-validation-2436", "mrqa_squad-validation-2428", "mrqa_squad-validation-5184", "mrqa_hotpotqa-validation-1446", "mrqa_squad-validation-6837", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7581", "mrqa_triviaqa-validation-5050", "mrqa_triviaqa-validation-3393", "mrqa_squad-validation-7319"], "unfixed_ids": ["mrqa_hotpotqa-validation-2184", "mrqa_triviaqa-validation-6224", "mrqa_triviaqa-validation-5839"], "instant_fixing_rate": 0.875, "instant_retention_rate": 0.6249999992187499}, {"timecode": 27, "before_eval": {"predictions": ["hair", "henry geldof", "blackberry", "horsehead Nebula", "\" Big Mamie\"", "margaret Caribs", "Teamsters leader Jimmy Hoffa", "a light sky-blue color caused by absorption in the red", "London", "1963", "Zaza Pachulia", "inner chloroplast membrane", "Renoir", "the Bright Autumn Festival", "no", "third", "a more fundamental electro weak interaction", "Cost of construction", "hardness", "A simple iron boar crest adorns the top of this helmet", "the University of Northumbria at Newcastle in 1992 as part of the UK-wide process in which polytechnics became new universities", "pacific war", "David", "on kickoffs at the 25 - yard line", "the Latin centum", "7,000 out of 20,000 inhabitants", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "antwerp", "badgers"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6053907715091925}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.42857142857142855, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666665, 1.0, 0.0, 0.6153846153846153, 0.3636363636363636, 0.0, 1.0, 0.631578947368421, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_squad-validation-2966", "mrqa_squad-validation-10312", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_triviaqa-validation-622"], "after_eval": {"predictions": ["hair", "2000", "blackberry", "horsehead", "Big Mamie", "orinoco river", "Teamsters leader", "clear", "wat tyler", "2009", "Zaza Pachulia", "inner chloroplast membrane", "Renoir", "sports tourism", "no", "third", "fundamental electroweak interaction", "Cost of construction", "gypsum", "A simple iron boar crest", "polytechnics became new universities", "australian", "David", "a touchback on kickoffs at the 25 - yard line instead of the previous 20 - Yard line", "named after the Swedish astronomer Anders Celsius", "7,000", "lion, leopard, buffalo, rhinoceros, and elephant", "faith", "cliff thorburn", "produced with constant technology and resources per unit of time", "rubenesque", "badgers"], "metric_results": {"EM": 1.0, "QA-F1": 1.0}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-2635", "mrqa_triviaqa-validation-348", "mrqa_hotpotqa-validation-994", "mrqa_hotpotqa-validation-4022", "mrqa_squad-validation-8739", "mrqa_triviaqa-validation-1423", "mrqa_squad-validation-2733", "mrqa_hotpotqa-validation-158", "mrqa_squad-validation-6855", "mrqa_hotpotqa-validation-3949", "mrqa_squad-validation-8279", "mrqa_squad-validation-2313", "mrqa_triviaqa-validation-388", "mrqa_naturalquestions-validation-2893", "mrqa_triviaqa-validation-1507"], "fixed_ids": ["mrqa_triviaqa-validation-2007", "mrqa_triviaqa-validation-2899", "mrqa_triviaqa-validation-6331", "mrqa_hotpotqa-validation-2428", "mrqa_squad-validation-3539", "mrqa_triviaqa-validation-2980", "mrqa_squad-validation-7711", "mrqa_squad-validation-2966", "mrqa_squad-validation-10312", "mrqa_triviaqa-validation-5962", "mrqa_hotpotqa-validation-1226", "mrqa_squad-validation-5337", "mrqa_triviaqa-validation-1034", "mrqa_naturalquestions-validation-9105", "mrqa_naturalquestions-validation-3771", "mrqa_squad-validation-5125", "mrqa_triviaqa-validation-622"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9999999993333333}, {"timecode": 28, "before_eval": {"predictions": ["The Turk", "Michael Bisping", "jury nullification", "Harishchandra", "A\u1e25mad ibn \u02bfAbd All\u0101h ibn Sulaim\u0101n al-Tan\u016b\u1e96\u012b al-Ma\u02bfarr\u012b", "Professor Eobard Thawne", "plum", "a US$10 a week raise over Tesla's US$18 per week salary", "1875", "contributed by member states on a voluntary basis", "clarinets", "McKinsey's offices in Silicon Valley and India", "clown", "Serious Charge", "Crohn's disease or ulcerative colitis", "Ondemar Dias", "Raya Yarbrough", "Cincinnati and No. 3 seed Tennessee", "australian", "Charles L. Hutchinson", "Old Testament", "UPS", "local talent", "the Deepdale area", "fifth Doctor", "pacific region", "that contemporary accounts were exaggerations", "Lincoln", "1332", "dodo bird", "people and their thoughts are both made from `` pure energy '', and that through the process of `` like energy attracting like energy '' a person can improve their own health, wealth and personal relationships", "Stan Butler"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4356930272108843}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, true], "QA-F1": [0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.2040816326530612, 1.0]}}, "error_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_hotpotqa-validation-1251", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921", "mrqa_naturalquestions-validation-7821"], "after_eval": {"predictions": ["Islam", "Anderson Silva", "inform the jury and the public of the political circumstances", "Kusha", "poet, and writer", "Professor Eobard Thawne", "slivovitz", "a US$10 a week raise", "1825", "member states", "oboe", "McKinsey's offices", "fear of public speaking", "lionel bart", "gastroschisis", "Ondemar Dias", "Bear McCreary", "UMBC", "riddick bowe", "John D. Rockefeller", "Song of Songs", "UPS", "local talent", "Preston North End Football Club", "peter davison", "canada", "contemporary accounts were exaggerations", "john, Jr.", "1332", "dodo bird", "the belief that by focusing on positive or positive thoughts people can bring positive or negative experiences into their life", "Stan Butler"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8837719298245614}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9473684210526315, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-4827", "before_prediction": "plum", "after_prediction": "slivovitz"}, {"id": "mrqa_naturalquestions-validation-10495", "before_prediction": "contributed by member states on a voluntary basis", "after_prediction": "member states"}, {"id": "mrqa_squad-validation-8031", "before_prediction": "Charles L. Hutchinson", "after_prediction": "John D. Rockefeller"}, {"id": "mrqa_triviaqa-validation-5810", "before_prediction": "Lincoln", "after_prediction": "john, Jr."}], "retained_ids": ["mrqa_naturalquestions-validation-4919", "mrqa_squad-validation-4309", "mrqa_triviaqa-validation-7669", "mrqa_squad-validation-5086", "mrqa_squad-validation-8190", "mrqa_triviaqa-validation-2953", "mrqa_triviaqa-validation-4308"], "fixed_ids": ["mrqa_squad-validation-2291", "mrqa_hotpotqa-validation-1390", "mrqa_squad-validation-6835", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-5637", "mrqa_squad-validation-1276", "mrqa_hotpotqa-validation-4352", "mrqa_triviaqa-validation-5237", "mrqa_hotpotqa-validation-5110", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-6250", "mrqa_naturalquestions-validation-4127", "mrqa_naturalquestions-validation-9185", "mrqa_naturalquestions-validation-7110", "mrqa_triviaqa-validation-1347", "mrqa_naturalquestions-validation-10687", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-6881", "mrqa_squad-validation-4921"], "unfixed_ids": ["mrqa_hotpotqa-validation-1251", "mrqa_naturalquestions-validation-7821"], "instant_fixing_rate": 0.9047619047619048, "instant_retention_rate": 0.6363636357851239}, {"timecode": 29, "before_eval": {"predictions": ["holly", "the 1960s", "patents", "Le Mans", "Xbox 360", "Tokyo for the 2020 Summer Olympics", "defensive end Kony Ealy", "the parallelogram rule of vector addition", "John Thomas Scopes", "coolly birds", "Startup neutron source", "starry starry night", "cylinder volume", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "the Imperial Secretariat", "Doctorin' the Tardis", "National Basketball Development League", "gillingham", "Washington metropolitan area", "T. J. Ward", "2,615", "Beijing", "an American football quarterback", "a password recovery tool for Microsoft Windows", "The Man", "husband and wife", "south korea", "pawel Kopczynski", "the smallest subfield", "ginger", "53%", "light reactions"], "metric_results": {"EM": 0.5, "QA-F1": 0.5425857843137255}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 0.47058823529411764, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.058823529411764705, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-3103", "mrqa_triviaqa-validation-7032", "mrqa_naturalquestions-validation-5826", "mrqa_squad-validation-8075", "mrqa_triviaqa-validation-1280", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_naturalquestions-validation-4572", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-8873"], "after_eval": {"predictions": ["holly", "the 1960s", "patents", "Formula One", "microsoft", "Tokyo for the 2020 Summer Olympics", "DeMarcus Ware", "parallelogram", "teaching evolution", "364", "Startup neutron source", "van gogh", "cylinder volume", "movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "local administrative structure", "Doctorin' the Tardis", "National Basketball Development League", "kent", "Washington metropolitan area", "Sanders", "The population was 2,615", "Beijing", "an American football quarterback", "recover many kinds of passwords using methods such as network packet sniffing, cracking various password hashes by using methods so as dictionary attacks, brute force and cryptanalysis attacks", "The Man", "significant historical contributions to the development of modern architecture and furniture", "south korea", "arthur", "the smallest subfield", "heartburn", "53%", "grana and thylakoids"], "metric_results": {"EM": 0.875, "QA-F1": 0.9463999542124543}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-5709", "before_prediction": "husband and wife", "after_prediction": "significant historical contributions to the development of modern architecture and furniture"}], "retained_ids": ["mrqa_triviaqa-validation-4708", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1249", "mrqa_naturalquestions-validation-6610", "mrqa_naturalquestions-validation-8653", "mrqa_squad-validation-3344", "mrqa_squad-validation-7914", "mrqa_hotpotqa-validation-2928", "mrqa_naturalquestions-validation-5961", "mrqa_naturalquestions-validation-9765", "mrqa_hotpotqa-validation-5383", "mrqa_naturalquestions-validation-7567", "mrqa_triviaqa-validation-1353", "mrqa_squad-validation-9036", "mrqa_squad-validation-7445"], "fixed_ids": ["mrqa_hotpotqa-validation-3497", "mrqa_triviaqa-validation-6632", "mrqa_squad-validation-814", "mrqa_squad-validation-10408", "mrqa_triviaqa-validation-3103", "mrqa_triviaqa-validation-7032", "mrqa_squad-validation-8075", "mrqa_triviaqa-validation-1280", "mrqa_squad-validation-772", "mrqa_hotpotqa-validation-3031", "mrqa_triviaqa-validation-2709", "mrqa_triviaqa-validation-814", "mrqa_squad-validation-8873"], "unfixed_ids": ["mrqa_triviaqa-validation-3603", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-4572"], "instant_fixing_rate": 0.8125, "instant_retention_rate": 0.9374999994140625}, {"timecode": 30, "before_eval": {"predictions": ["judges", "named for Frederick Louis, Prince of Wales, son of King George II", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "Basil Fawlty", "Erick Avari, Michael McKean, Amy D. Jacobson, Marty Ingels, Earl Boen, Jordana Capra, Dirk Benedict, and Rip Taylor", "SyFy", "mikael blomkvist", "historical political divisions", "3 or more", "the most recent Super Bowl champion", "a rapid drop in your blood sugar", "arctic Monkeys", "imola", "jurassic park", "usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "A computer program", "The Greens", "babylon", "hekla", "largest source of foreign direct investment", "national network", "South Pacific", "7", "Delaware to the southeast, Maryland to the south, West Virginia to the southwest, Ohio to the west, Lake Erie and the Canadian province of Ontario to the northwest, New York to the north, and New Jersey to the east", "Netflix", "Scott Bakula", "Jawaharlal Nehru", "National Lottery", "skylab", "katherine of aragon", "facilitate compliance with the Telephone Consumer Protection Act of 1991"], "metric_results": {"EM": 0.53125, "QA-F1": 0.604101011378972}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.125, 0.7692307692307692, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.3157894736842105]}}, "error_ids": ["mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_triviaqa-validation-1921", "mrqa_hotpotqa-validation-4578", "mrqa_triviaqa-validation-2750", "mrqa_triviaqa-validation-5266", "mrqa_naturalquestions-validation-3533", "mrqa_triviaqa-validation-7090", "mrqa_hotpotqa-validation-4604", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "after_eval": {"predictions": ["judges", "Dutch House of Orange-Nassau", "Jesse McCartney as JoJo, the Mayor's son", "john brown", "polly", "Martin Ingerman", "SyFy", "daniel craig", "historical political divisions", "3", "the most recent Super Bowl champion", "narcolepsy", "alex turner", "imola", "jurassic park", "all transmissions", "A computer program", "The Greens", "babylon", "surtsey", "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda", "national network", "South Pacific", "7", "New Jersey", "Netflix", "Scott Bakula", "indira gandhi", "state-franchised", "skylab", "spain", "to comply with the Do - Not - Call Implementation Act of 2003"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9648279352226721}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-8451", "before_prediction": "largest source of foreign direct investment", "after_prediction": "a planned $2.5 billion railway from the southern Kenyan port of Mombasa to neighboring Uganda"}], "retained_ids": ["mrqa_naturalquestions-validation-4645", "mrqa_triviaqa-validation-3920", "mrqa_squad-validation-7793", "mrqa_squad-validation-2577", "mrqa_naturalquestions-validation-3209", "mrqa_triviaqa-validation-6888", "mrqa_triviaqa-validation-1722", "mrqa_naturalquestions-validation-9852", "mrqa_squad-validation-2885", "mrqa_triviaqa-validation-6207", "mrqa_triviaqa-validation-7684", "mrqa_naturalquestions-validation-4710", "mrqa_squad-validation-6961", "mrqa_hotpotqa-validation-3333", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-7530"], "fixed_ids": ["mrqa_hotpotqa-validation-2559", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-4079", "mrqa_triviaqa-validation-1921", "mrqa_hotpotqa-validation-4578", "mrqa_triviaqa-validation-2750", "mrqa_triviaqa-validation-5266", "mrqa_naturalquestions-validation-3533", "mrqa_triviaqa-validation-7090", "mrqa_hotpotqa-validation-4604", "mrqa_triviaqa-validation-3134", "mrqa_hotpotqa-validation-5604", "mrqa_triviaqa-validation-2091", "mrqa_naturalquestions-validation-10328"], "unfixed_ids": ["mrqa_naturalquestions-validation-9608"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.941176470034602}, {"timecode": 31, "before_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Thiel", "sarajevo", "sports commentator", "Newell Highway", "tenth planet", "4", "shopping", "make a defiant speech, or a speech explaining their actions, in allocution", "Andrew Adamson", "Liszt Strauss Wagner Dvorak", "the Naimans", "emissions resulting from human activities are substantially increasing the atmospheric concentrations of the greenhouse gases, resulting on average in an additional warming of the Earth's surface", "marbles", "the RAF", "encourage growth", "Ibbi-Sipish", "peterborough", "Polish-Jewish", "the Falange", "cole albert", "1967", "16,000", "Washington Street", "8 November 1978", "six", "100 Deeds for Eddie McDowd", "his frustration with the atmosphere in the group at that time", "birmingham", "John Smith", "surtania", "the variety of occupations necessary to sustain the community as distinct from the indigenous population"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5747685185185185}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.37037037037037035, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333]}}, "error_ids": ["mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-1050", "mrqa_squad-validation-6734", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_hotpotqa-validation-1444", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_squad-validation-932", "mrqa_hotpotqa-validation-5307", "mrqa_triviaqa-validation-743", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "after_eval": {"predictions": ["Guadalupe \"Lupe\" Ontiveros", "Andreas", "sarajevo", "football", "Newell Highway", "tenth planet", "4", "shopping", "explaining their actions", "Andrew Adamson", "waltz king", "the Naimans", "warming of the Earth's surface", "parthenon", "Britain", "encourage growth", "Ibrium", "strictly come dancing", "Polish", "the Falange", "cole albert", "1967", "16,000", "Washington Street", "8 November 1978", "5", "\"Fudge\"", "his frustration with the atmosphere in the group at that time", "barbarella", "John Smith", "lusitania", "worked as weavers"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_hotpotqa-validation-1385", "mrqa_triviaqa-validation-4209", "mrqa_hotpotqa-validation-2762", "mrqa_triviaqa-validation-457", "mrqa_triviaqa-validation-5071", "mrqa_naturalquestions-validation-5604", "mrqa_hotpotqa-validation-2564", "mrqa_squad-validation-6128", "mrqa_squad-validation-7469", "mrqa_naturalquestions-validation-9825", "mrqa_triviaqa-validation-3286", "mrqa_triviaqa-validation-2609", "mrqa_squad-validation-4415", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-3728", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-4500"], "fixed_ids": ["mrqa_hotpotqa-validation-5585", "mrqa_triviaqa-validation-1050", "mrqa_squad-validation-6734", "mrqa_triviaqa-validation-3300", "mrqa_squad-validation-8589", "mrqa_triviaqa-validation-5513", "mrqa_naturalquestions-validation-954", "mrqa_hotpotqa-validation-1444", "mrqa_triviaqa-validation-5378", "mrqa_hotpotqa-validation-2493", "mrqa_hotpotqa-validation-5307", "mrqa_triviaqa-validation-743", "mrqa_triviaqa-validation-4524", "mrqa_squad-validation-3106"], "unfixed_ids": ["mrqa_squad-validation-932"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.9999999994117647}, {"timecode": 32, "before_eval": {"predictions": ["A high-gain S-band antenna", "Orthodox Christians", "Fomento Econ\u00f3mico Mexicano", "sept september", "south afghanistan", "Thomas Middleditch", "potassium", "A jackknife event of a heavy vehicle", "T cell receptor", "relatively low salaries", "non-GMO", "\"Point of Entry\"", "Moonraker", "u", "Science Magazine", "England national team", "poverty and were ill treated", "Space is the Place", "France's Legislative Assembly", "5,922", "June 4, 1931", "psychological horror", "sandy lyle", "Dutch figure of Sinterklaas", "Frankfurt (Oder) Germany", "Jimmy Ellis", "1991", "Sunday", "Dallas", "Nairobi, Kenya", "During the last Ice Age", "Neon City ( also known as Anno 2053 in Italy, Neonski Grad in Serbia)"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6706845238095238}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.20000000000000004, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.5, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667]}}, "error_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-946", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-10311", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-5557"], "after_eval": {"predictions": ["scientific instrument package", "Religiously affiliated and denominational schools", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "september", "south africa", "Thomas Middleditch", "potassium", "If a vehicle towing a trailer skids", "T cell receptor (TCR)", "relatively low salaries", "us", "\"Point of Entry\"", "bridge", "u", "Science Magazine", "Premier League club Manchester United and the England national team", "lived in poverty and were ill treated", "Jumping on the Moon", "France's Legislative Assembly", "5,922", "June 4, 1931", "is a 2016 science fiction psychological horror", "leg injury", "Sinterklaas", "Stern-Plaza", "Jimmy Ellis", "1991", "may", "Dealey Plaza, in the historic West End district of downtown Dallas", "Nairobi, Kenya", "During the last Ice Age", "Anno 2053"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8881222943722944}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6744", "before_prediction": "Orthodox Christians", "after_prediction": "Religiously affiliated and denominational schools"}, {"id": "mrqa_hotpotqa-validation-572", "before_prediction": "Fomento Econ\u00f3mico Mexicano", "after_prediction": "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V."}, {"id": "mrqa_naturalquestions-validation-5631", "before_prediction": "Space is the Place", "after_prediction": "Jumping on the Moon"}, {"id": "mrqa_hotpotqa-validation-4221", "before_prediction": "Dallas", "after_prediction": "Dealey Plaza, in the historic West End district of downtown Dallas"}], "retained_ids": ["mrqa_naturalquestions-validation-4761", "mrqa_triviaqa-validation-7394", "mrqa_squad-validation-2234", "mrqa_hotpotqa-validation-1119", "mrqa_triviaqa-validation-2245", "mrqa_squad-validation-8617", "mrqa_squad-validation-8095", "mrqa_hotpotqa-validation-3508", "mrqa_hotpotqa-validation-2910", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3557", "mrqa_naturalquestions-validation-5960"], "fixed_ids": ["mrqa_squad-validation-3887", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-3066", "mrqa_naturalquestions-validation-5510", "mrqa_squad-validation-6602", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-946", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-3618", "mrqa_hotpotqa-validation-1660", "mrqa_naturalquestions-validation-7049", "mrqa_hotpotqa-validation-5335", "mrqa_triviaqa-validation-1079", "mrqa_hotpotqa-validation-5557"], "unfixed_ids": ["mrqa_naturalquestions-validation-10311"], "instant_fixing_rate": 0.9333333333333333, "instant_retention_rate": 0.7647058819031142}, {"timecode": 33, "before_eval": {"predictions": ["Habsburg control of the First Empire, the Spanish throne, and other royal houses", "Boston Herald", "1967", "amount charged by a bookmaker", "largest Filipino American community", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "lower rates of social goods (life expectancy by country, educational performance, trust among strangers, women's status, social mobility, even numbers of patents issued)", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "Biloxi", "emperor", "oakum", "Spring city", "London", "Broken Hill and Sydney", "2005", "punishments", "Smith and Jones", "wagons", "ilich ramirez", "things that are a matter of custom or expectation", "Paris", "niece of Emperor Haile Selassie of Ethiopia", "staying with the same group of peers for all classes", "backflow prevention", "enthusiasm and energy of the teacher", "Russo-Japanese War", "air conditioning", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8210267857142857}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true], "QA-F1": [0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9984", "mrqa_squad-validation-7571", "mrqa_squad-validation-10180", "mrqa_triviaqa-validation-6186", "mrqa_hotpotqa-validation-2588", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812"], "after_eval": {"predictions": ["Napoleon", "Boston Herald", "1967", "amount charged by a bookmaker", "largest", "Roger Maris", "tintin", "a hyper - active kinase, that confers an aberrant, ligand - independent, non-regulated growth stimulus to the cancer cells", "higher", "J\u0101nis Strazdi\u0146\u0161", "Hodel", "Biloxi", "japan", "oakum", "Spring city", "London", "Broken Hill", "2005", "punishments", "Smith and Jones", "wagons", "ilich ramirez sanchez", "things that are a matter of custom or expectation", "Paris", "niece", "staying with the same group of peers for all classes", "backflow prevention", "emotional contagion", "japan", "air conditioning", "William Jefferson Clinton", "Buskerud"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9270833333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1975", "before_prediction": "emperor", "after_prediction": "japan"}, {"id": "mrqa_naturalquestions-validation-6358", "before_prediction": "Broken Hill and Sydney", "after_prediction": "Broken Hill"}], "retained_ids": ["mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-1573", "mrqa_hotpotqa-validation-2092", "mrqa_squad-validation-7278", "mrqa_naturalquestions-validation-8203", "mrqa_triviaqa-validation-1410", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-6499", "mrqa_hotpotqa-validation-270", "mrqa_hotpotqa-validation-5727", "mrqa_hotpotqa-validation-2161", "mrqa_squad-validation-2010", "mrqa_squad-validation-7741", "mrqa_triviaqa-validation-7348", "mrqa_squad-validation-6878", "mrqa_naturalquestions-validation-7387", "mrqa_squad-validation-1903", "mrqa_naturalquestions-validation-5297", "mrqa_squad-validation-3733", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-1211"], "fixed_ids": ["mrqa_squad-validation-9984", "mrqa_squad-validation-7571", "mrqa_triviaqa-validation-6186", "mrqa_hotpotqa-validation-2588", "mrqa_squad-validation-2147", "mrqa_triviaqa-validation-2812"], "unfixed_ids": ["mrqa_squad-validation-10180"], "instant_fixing_rate": 0.8571428571428571, "instant_retention_rate": 0.919999999632}, {"timecode": 34, "before_eval": {"predictions": ["Speaker", "norman hartnell", "Threatening government officials", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52", "separate Tables", "France", "Ian Paisley", "World War II", "euro", "suggs", "Taft", "late 1970s", "first published in 1890", "75th", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Johnny Darrell", "head and neck", "motorcycles or mopeds pulling trailers", "the sum of divisors function", "ear canal", "how graphs are encoded as binary strings", "third", "afghanistan", "Honda Accord", "Lauren Oliver", "Rapunzel"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7391826923076923}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_squad-validation-6673", "mrqa_hotpotqa-validation-3107", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-3708", "mrqa_triviaqa-validation-1198"], "after_eval": {"predictions": ["Chairman", "norman hartnell", "sending an email", "neither issue made it clear whether Archie was married to Betty or Veronica", "Victorian College of the Arts and Melbourne Conservatorium of Music", "Britain", "onions", "0.52/sq mi", "separate Tables", "It was held in France from 10 June to 12 July 1998.", "Ian Paisley", "World War II", "litas", "madness", "Taft -- Katsura Agreement", "late 1970s", "first published in 1890", "the Rams starting quarterback as two torn ACLs sidelined him for much of the next season and the entire 2014 season", "Manhattan", "Lucius Verus", "revolution or orbital revolution", "Kenny Rogers and The First Edition", "head and neck", "motorcycles or mopeds pulling trailers", "the sum of divisors function", "earwax", "how graphs are encoded as binary strings", "third", "succulent orange", "large", "Lauren Oliver", "healing incantation"], "metric_results": {"EM": 0.90625, "QA-F1": 0.921875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-8990", "before_prediction": "Taft", "after_prediction": "Taft -- Katsura Agreement"}, {"id": "mrqa_hotpotqa-validation-3002", "before_prediction": "75th", "after_prediction": "the Rams starting quarterback as two torn ACLs sidelined him for much of the next season and the entire 2014 season"}, {"id": "mrqa_triviaqa-validation-7184", "before_prediction": "afghanistan", "after_prediction": "succulent orange"}], "retained_ids": ["mrqa_triviaqa-validation-7248", "mrqa_naturalquestions-validation-6787", "mrqa_hotpotqa-validation-3982", "mrqa_naturalquestions-validation-951", "mrqa_triviaqa-validation-5516", "mrqa_squad-validation-4369", "mrqa_triviaqa-validation-5496", "mrqa_hotpotqa-validation-1139", "mrqa_hotpotqa-validation-3072", "mrqa_naturalquestions-validation-5740", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-10676", "mrqa_naturalquestions-validation-4192", "mrqa_triviaqa-validation-7592", "mrqa_squad-validation-4255", "mrqa_squad-validation-9063", "mrqa_squad-validation-1635", "mrqa_squad-validation-2751", "mrqa_squad-validation-8034"], "fixed_ids": ["mrqa_naturalquestions-validation-2962", "mrqa_squad-validation-6673", "mrqa_hotpotqa-validation-3107", "mrqa_triviaqa-validation-1220", "mrqa_triviaqa-validation-3324", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-3408", "mrqa_squad-validation-3708", "mrqa_triviaqa-validation-1198"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.8695652170132325}, {"timecode": 35, "before_eval": {"predictions": ["2% higher", "capital and financial markets", "Emma Watson, Dan Stevens, Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Nathan Mack, Ian McKellen, and Emma Thompson", "the brain, muscles, and liver", "butterfly", "the Dallas Cowboys", "courtyard adjoining the Assembly Hall", "William Howard Ashton", "teapot", "Unemployment", "Miami", "\" Inside Men\" (2015)", "changing display or audio settings quickly", "king charles I", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "South Africa", "Scotty Grainger Jr.", "alamo", "seal", "UMC", "Geno Lenardo", "Roger Allers and Rob Minkoff", "Port Moresby, Papua New Guinea", "david seville", "NAACP", "1963\u20131989", "titanic", "Margaret Beckett", "Darrin Stephens", "india"], "metric_results": {"EM": 0.65625, "QA-F1": 0.706547619047619}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.14285714285714288, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-4544", "mrqa_triviaqa-validation-6423", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-1136", "mrqa_triviaqa-validation-6969"], "after_eval": {"predictions": ["up to 2% higher", "capital and financial markets", "Dan Stevens", "muscles", "butterfly", "New York Yankees, the Atlanta Braves, the Cincinnati Reds and the San Francisco Giants", "courtyard adjoining the Assembly Hall", "William Howard Ashton", "president harding", "Unemployment", "Miami", "Best Actor prize", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "king charles I", "the spectroscopic notation for the associated atomic orbitals", "declines", "Beauty and the Beast", "New Zealand national rugby union team", "Tyler \"Ty\" Mendoza", "texas state", "seal", "UMC", "Geno Lenardo", "Don Hahn", "Port Moresby, Papua New Guinea", "david seville", "NAACP", "1963\u20131989", "titanic", "margaret beckett", "elizabeth montgomery", "india"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-6450", "before_prediction": "South Africa", "after_prediction": "New Zealand national rugby union team"}], "retained_ids": ["mrqa_naturalquestions-validation-25", "mrqa_triviaqa-validation-4829", "mrqa_squad-validation-9400", "mrqa_hotpotqa-validation-2971", "mrqa_squad-validation-7352", "mrqa_hotpotqa-validation-4447", "mrqa_triviaqa-validation-3767", "mrqa_naturalquestions-validation-585", "mrqa_squad-validation-7495", "mrqa_hotpotqa-validation-5690", "mrqa_squad-validation-3408", "mrqa_squad-validation-10036", "mrqa_hotpotqa-validation-3853", "mrqa_hotpotqa-validation-430", "mrqa_triviaqa-validation-11", "mrqa_hotpotqa-validation-1720", "mrqa_squad-validation-7610", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-5746", "mrqa_triviaqa-validation-1812"], "fixed_ids": ["mrqa_squad-validation-9123", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-4544", "mrqa_triviaqa-validation-6423", "mrqa_hotpotqa-validation-2947", "mrqa_naturalquestions-validation-1587", "mrqa_hotpotqa-validation-1475", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-1136", "mrqa_triviaqa-validation-6969"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9523809519274377}, {"timecode": 36, "before_eval": {"predictions": ["NBC", "Kevin Costner, Amber Heard, Hailee Steinfeld, Connie Nielsen, Richard Sammel, and Eriq Ebouaney", "Uranus", "president rudolph", "Cobham\u2013Edmonds thesis", "a mysterious father figure", "Best Male Pop Vocal Performance", "March 2012", "New Orleans", "Muhammad Ali", "Coldplay", "Gibraltar", "to civil disobedients", "Julius Caesar", "2%", "1979", "Easter egg", "formal language", "conductor", "lungs", "That the plague was caused by bad air", "imperial fluid ounces", "mountain ranges (sub-ranges of the Rocky Mountains)", "white", "The U.S. state of Georgia", "nettle", "nearly $12", "a flat rate of 20 %", "love is all around", "use in the ARPANET", "west", "Republic of Chad"], "metric_results": {"EM": 0.46875, "QA-F1": 0.534672619047619}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-4824", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_hotpotqa-validation-1118", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-2323"], "after_eval": {"predictions": ["National Broadcasting Company", "McG", "jupiter", "rudolph", "Cobham\u2013Edmonds thesis", "teachers", "II", "April", "New Orleans", "Raymond Patterson", "Coldplay", "Menorca", "receive no jail time", "emperors", "2%", "1979", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "The formal language", "conducting", "the right side of the heart", "That the plague was caused by bad air", "imperial fluid ounces", "mountain ranges", "white", "California", "nettle", "nearly $12", "20 %", "love is all around", "use in the ARPANET", "west", "Nigeria"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9375}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-452", "before_prediction": "Republic of Chad", "after_prediction": "Nigeria"}], "retained_ids": ["mrqa_squad-validation-1758", "mrqa_triviaqa-validation-3803", "mrqa_squad-validation-110", "mrqa_squad-validation-3060", "mrqa_hotpotqa-validation-1884", "mrqa_squad-validation-1634", "mrqa_squad-validation-4877", "mrqa_naturalquestions-validation-8525", "mrqa_triviaqa-validation-199", "mrqa_triviaqa-validation-4069", "mrqa_squad-validation-3635", "mrqa_triviaqa-validation-6290", "mrqa_squad-validation-4626", "mrqa_squad-validation-9146"], "fixed_ids": ["mrqa_hotpotqa-validation-152", "mrqa_hotpotqa-validation-652", "mrqa_triviaqa-validation-37", "mrqa_squad-validation-7720", "mrqa_hotpotqa-validation-4427", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-2936", "mrqa_naturalquestions-validation-6011", "mrqa_squad-validation-6759", "mrqa_naturalquestions-validation-4115", "mrqa_naturalquestions-validation-3993", "mrqa_triviaqa-validation-5936", "mrqa_naturalquestions-validation-5552", "mrqa_hotpotqa-validation-1118", "mrqa_naturalquestions-validation-3344", "mrqa_naturalquestions-validation-2323"], "unfixed_ids": ["mrqa_triviaqa-validation-4824"], "instant_fixing_rate": 0.9411764705882353, "instant_retention_rate": 0.9333333327111111}, {"timecode": 37, "before_eval": {"predictions": ["San Joaquin Valley Railroad", "his back was severely wrenched and three of his ribs were broken", "2007", "San Luis Obispo", "mother-of-pearl", "February 20, 1978", "haggis", "George H.W. Bush", "96", "The first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term.", "south korea", "white, blue, pink, rainbow neon and glittering dotted lines", "the alluvial plain", "around 11 miles (18 km) south of San Jose", "Spotty Dog", "Rumplestiltskin", "Carlos Tevez", "small marsupials including the endangered sandhill dunnart ( Sminthopsis psammophila ) and the crest - tailed mulgara ( Dasycercus cristicauda )", "many events and festivals", "tafelwein", "1991", "norway", "7 January 1936", "lifetime protection", "twenty-four", "Carl Sagan", "Many of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Holb\u00e6k", "allocution", "sour cream", "Boston, Massachusetts"], "metric_results": {"EM": 0.3125, "QA-F1": 0.42591894931049346}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8750000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35294117647058826, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.39999999999999997, 0.13333333333333333, 0.0, 0.0, 0.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-1625", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_naturalquestions-validation-9058", "mrqa_squad-validation-2660", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-1698", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-7246", "mrqa_naturalquestions-validation-1375", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "after_eval": {"predictions": ["San Joaquin Valley Railroad", "broken", "2007", "San Luis Obispo, California", "mother-of-pearl", "February 20, 1978", "sheep", "George H.W. Bush", "96", "The first recorded use of the term `` liberal arts '' ( artes liberales ) occurs in De Inventione by Marcus Tullius Cicero, but it is unclear if he created the term", "World War I", "white, blue, pink, rainbow neon and glittering dotted lines", "Mesopotamia", "37\u00b0 9' 58.23\" latitude", "woodentop", "Henry", "shared", "the southern marsupial mole ( Notoryctes typhlops )", "events and festivals", "kabinett", "2010", "avatar", "7 January 1936", "lifetime protection", "It contains twenty-three episodes", "Carl Sagan", "tax base dissipated", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Pierre Nlend Wom\u00e9", "sentence", "whey", "Boston, Massachusetts"], "metric_results": {"EM": 0.8125, "QA-F1": 0.894233630952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8750000000000001, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_squad-validation-4768", "mrqa_squad-validation-4108", "mrqa_squad-validation-5451", "mrqa_hotpotqa-validation-513", "mrqa_naturalquestions-validation-4664", "mrqa_hotpotqa-validation-4154", "mrqa_hotpotqa-validation-85", "mrqa_naturalquestions-validation-969", "mrqa_squad-validation-8069", "mrqa_hotpotqa-validation-5371"], "fixed_ids": ["mrqa_squad-validation-1625", "mrqa_hotpotqa-validation-104", "mrqa_triviaqa-validation-1015", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-5258", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-4032", "mrqa_squad-validation-677", "mrqa_triviaqa-validation-7134", "mrqa_naturalquestions-validation-10554", "mrqa_triviaqa-validation-3876", "mrqa_hotpotqa-validation-2377", "mrqa_squad-validation-7246", "mrqa_hotpotqa-validation-633", "mrqa_squad-validation-6737", "mrqa_triviaqa-validation-2524"], "unfixed_ids": ["mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-3479", "mrqa_squad-validation-5702", "mrqa_squad-validation-2660", "mrqa_naturalquestions-validation-1698", "mrqa_naturalquestions-validation-1375"], "instant_fixing_rate": 0.7272727272727273, "instant_retention_rate": 0.9999999989999999}, {"timecode": 38, "before_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Dan Stevens", "1958", "Bart Cummings", "dragon", "slavery", "military units from their parent countries of Great Britain and France", "The History of Little Goody Two - Shoes", "224.7 Earth days", "gathering money from the public", "Thorgan Ganael Francis Hazard", "commissioned to purchase their required uniform items", "Jeff Meldrum", "a week", "Phil Archer", "Shoshone, his mother tongue, and other western American Indian languages", "The Chipettes", "Suez Canal", "60 by West All - Stars ( 2017 )", "journalist", "take evidence from witnesses, conduct inquiries and scrutinise legislation", "beehive", "ramification", "newly accessioned", "fiat money", "strychnine", "California", "The early modern period began approximately in the early 16th century ; notable historical milestones included the European Renaissance, the Age of Discovery, and the Protestant Reformation.", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7728828871292106}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.47058823529411764, 1.0, 0.22222222222222224, 0.25, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3846153846153846, 0.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-2100"], "after_eval": {"predictions": ["the NP-complete Boolean satisfiability problem", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen,", "1958", "Bart Cummings", "dragon", "slavery", "the colonies of British America", "The History of Little Goody Two - Shoes", "224.7 Earth days", "crowdfunding platforms for gathering money from the public, which circumvents traditional avenues of investment", "Thorgan Ganael Francis Hazard", "when commissioned", "Don Jeffrey \"Jeff\" Meldrum (born May 24, 1958) is a Professor of Anatomy and Anthropology", "a week", "Phil Archer", "French and English", "The Chipettes", "Suez Canal", "60 by West All - Stars ( 2017 )", "journalist", "take evidence from witnesses, conduct inquiries and scrutinise legislation. Committee meetings take place on Tuesday, Wednesday and Thursday morning when Parliament is sitting. Committees can also meet at other locations throughout Scotland.", "beehive", "ramification", "newly accessioned", "fiat money", "glycine receptor", "Iowa", "approximately in the early 16th century", "Lord's", "today", "Hathi Jr.", "the closing of the atrioventricular valves and semilunar valves, respectively"], "metric_results": {"EM": 0.875, "QA-F1": 0.9167367535744323}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.896551724137931, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43902439024390244, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9478", "before_prediction": "take evidence from witnesses, conduct inquiries and scrutinise legislation", "after_prediction": "take evidence from witnesses, conduct inquiries and scrutinise legislation. Committee meetings take place on Tuesday, Wednesday and Thursday morning when Parliament is sitting. Committees can also meet at other locations throughout Scotland."}, {"id": "mrqa_triviaqa-validation-3320", "before_prediction": "strychnine", "after_prediction": "glycine receptor"}], "retained_ids": ["mrqa_squad-validation-1862", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-2499", "mrqa_triviaqa-validation-4677", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-8418", "mrqa_naturalquestions-validation-9728", "mrqa_hotpotqa-validation-727", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-4762", "mrqa_naturalquestions-validation-3707", "mrqa_triviaqa-validation-3118", "mrqa_naturalquestions-validation-6210", "mrqa_squad-validation-1660", "mrqa_triviaqa-validation-1473", "mrqa_squad-validation-9032", "mrqa_squad-validation-5505", "mrqa_naturalquestions-validation-10279", "mrqa_triviaqa-validation-2039", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2555"], "fixed_ids": ["mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-4067", "mrqa_hotpotqa-validation-1116", "mrqa_hotpotqa-validation-2682", "mrqa_naturalquestions-validation-7630", "mrqa_naturalquestions-validation-3006"], "unfixed_ids": ["mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-2100"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.9130434778638941}, {"timecode": 39, "before_eval": {"predictions": ["capital of taiwan", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee, and Jean Parker", "violence", "Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "1977", "Edwin Hubble, known for \"Hubble's Law\" NASA astronaut John M. Grunsfeld, geneticist James Watson", "detroit", "your song", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the first Sunday in November", "relative units of force and mass", "agatha Christie", "FC Porto", "August 10, 1933", "Golden Gate Bridge", "Sochi, Russia", "those who already hold wealth", "bilingual German author B. Traven", "Finding Nemo", "Fortean", "inflation", "swunks", "247,597", "Princeton, New Jersey", "German service cartridge", "DC electricity"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7682466736694678}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-9227", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_naturalquestions-validation-6839", "mrqa_squad-validation-10428", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4298"], "after_eval": {"predictions": ["taipei", "Dan Conner", "east and west berlin", "warren commission", "Katharine Hepburn, Joan Bennett, Frances Dee", "anti-Semitism", "Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father", "couscous", "1980s", "John M. Grunsfeld", "detroit", "your song", "2003", "every year", "Fabbrica Italiana Automobili Torino", "the second Sunday of March", "the relative units of force and mass then are fixed", "agatha Christie", "porto", "August 10, 1933", "The Golden Gate Bridge", "vancouver", "those who already hold wealth", "bilingual German author B. Traven, whose identity remains unknown", "Finding Nemo", "Fortean", "inflation", "squirrels", "247,597", "The Institute for Advanced Study", "German service cartridge", "DC electricity"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9413461538461538}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-2493", "before_prediction": "violence", "after_prediction": "anti-Semitism"}], "retained_ids": ["mrqa_triviaqa-validation-6133", "mrqa_hotpotqa-validation-2243", "mrqa_triviaqa-validation-2890", "mrqa_triviaqa-validation-1438", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-7195", "mrqa_naturalquestions-validation-3698", "mrqa_triviaqa-validation-3017", "mrqa_hotpotqa-validation-5233", "mrqa_triviaqa-validation-7269", "mrqa_hotpotqa-validation-2332", "mrqa_naturalquestions-validation-3108", "mrqa_squad-validation-7547", "mrqa_hotpotqa-validation-489", "mrqa_hotpotqa-validation-1607", "mrqa_triviaqa-validation-2808", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-2203", "mrqa_squad-validation-3650"], "fixed_ids": ["mrqa_hotpotqa-validation-944", "mrqa_naturalquestions-validation-6554", "mrqa_squad-validation-8070", "mrqa_naturalquestions-validation-6839", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-4024", "mrqa_naturalquestions-validation-5272", "mrqa_triviaqa-validation-1276", "mrqa_hotpotqa-validation-4298"], "unfixed_ids": ["mrqa_naturalquestions-validation-9227", "mrqa_squad-validation-10428"], "instant_fixing_rate": 0.8181818181818182, "instant_retention_rate": 0.9523809519274377}, {"timecode": 40, "before_eval": {"predictions": ["The Super Bowl 50 Host Committee has vowed to be \"the most giving Super Bowl ever\" and will dedicate 25 percent of all money it raises for philanthropic causes in the Bay Area", "Cetshwayo", "on the road back to Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgi", "14th to 17th centuries", "four", "placing them on prophetic faith", "Bacon", "Yul Brynner", "anti-inflammatory molecules", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "express or implied Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "son et lumi\u00e8re", "the Uighurs surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "central Saskatchewan", "After the determination of responsibility for the accident was complex, the review board concluded that \"deficiencies existed in Command Module design, workmanship and quality control\"", "Australian suffragettes", "stenographer", "30 Major League Baseball teams", "the Secret Intelligence Service", "nerve cells", "caesar", "photolysis of ozone by light of short wavelength", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.78125, "QA-F1": 0.783203125}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_squad-validation-395", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-1791"], "after_eval": {"predictions": ["50 fund", "Cetshwayo", "on the road back to Samarkand", "sarajevo", "Isabella (Belle) Baumfree", "corgi", "throughout the 14th to 17th centuries", "seven relief pitchers", "placing them on prophetic faith", "Bacon", "Yul Brynner", "cytotoxic natural killer cells and CTLs", "tartan", "philadelphia eagles", "a tradeable entity used to avoid the inconveniences of a pure barter system", "Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "sound and light", "surrendered peacefully without violently resisting", "Sochi, Russia", "sweden", "central Saskatchewan", "immediately", "new zealand", "shorthand typist", "30 Major League Baseball teams", "MI6", "nerve cells", "caesar", "photosynthesis", "4 - inch screen size", "Queen City", "qui tam"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9657258064516129}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9032258064516129, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-1063", "before_prediction": "express or implied Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )", "after_prediction": "Acts of Congress that delegate to the President some degree of discretionary power ( delegated legislation )"}, {"id": "mrqa_squad-validation-3617", "before_prediction": "photolysis of ozone by light of short wavelength", "after_prediction": "photosynthesis"}], "retained_ids": ["mrqa_naturalquestions-validation-6212", "mrqa_squad-validation-6248", "mrqa_triviaqa-validation-1571", "mrqa_hotpotqa-validation-1453", "mrqa_triviaqa-validation-2475", "mrqa_squad-validation-4953", "mrqa_squad-validation-2249", "mrqa_naturalquestions-validation-4330", "mrqa_naturalquestions-validation-7457", "mrqa_triviaqa-validation-3814", "mrqa_triviaqa-validation-3213", "mrqa_naturalquestions-validation-10265", "mrqa_squad-validation-8247", "mrqa_hotpotqa-validation-4076", "mrqa_triviaqa-validation-1859", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-4123", "mrqa_hotpotqa-validation-3151", "mrqa_triviaqa-validation-1877", "mrqa_triviaqa-validation-579", "mrqa_naturalquestions-validation-6848", "mrqa_hotpotqa-validation-178", "mrqa_naturalquestions-validation-993"], "fixed_ids": ["mrqa_squad-validation-395", "mrqa_naturalquestions-validation-8961", "mrqa_squad-validation-6588", "mrqa_triviaqa-validation-6127", "mrqa_squad-validation-3932", "mrqa_triviaqa-validation-3280", "mrqa_hotpotqa-validation-1791"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.919999999632}, {"timecode": 41, "before_eval": {"predictions": ["all war", "Hindi", "Gaelic", "Three-card brag", "Idisi", "lion", "The cinema of Russia", "sediment load", "FedExField in Landover, Maryland", "GTPase responsible for endocytosis in the eukaryotic cell", "Windows Easy Transfer", "Ordos City China Science Flying Universe Science and Technology Co.", "frisbee", "PPG Paints Arena, Pittsburgh, Pennsylvania", "leicester", "Section 30", "Paul Lynde", "October 1986", "quasars", "Northeast Monsoon or Retreating Monsoon", "switzerland", "george iii", "5AA", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi", "bobby brown", "Nebula Award", "margaret titanic", "jonathan", "George David Weiss"], "metric_results": {"EM": 0.71875, "QA-F1": 0.796881764069264}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 0.3636363636363636, 0.5, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-1391", "mrqa_naturalquestions-validation-10355", "mrqa_hotpotqa-validation-201", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-2384", "mrqa_naturalquestions-validation-8338", "mrqa_hotpotqa-validation-3872", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791"], "after_eval": {"predictions": ["all war", "Hindi", "Gaelic", "In Crash, there is no betting, as in Brag", "Idisi", "lion", "The cinema of Russia", "the sediment load of the Rhine has strongly increased", "FedExField in Landover, Maryland", "the scission of newly formed vesicles from the membrane of one cellular compartment and their targeting to, and fusion with, another compartment", "Windows Easy Transfer", "Ordos City", "frisbee", "Boise State University", "leicester", "Section 30", "Paul Lynde as Templeton, a care - free, egotistical rat who lives on a web in a corner of Homer's barn above Wilbur's pig pen", "October 1986", "4 billion", "Northeast Monsoon or Retreating Monsoon", "switzerland", "geena", "Newstalk radio station 5AA (FIVEaa)", "Q", "Philippians", "what builds nations'wealth", "Gerard Marenghi (born January 24, 1920)", "bobby brown", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "margaret thatcher", "jonathan", "George David Weiss"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8836823866817715}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.7547169811320755, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-9355", "before_prediction": "sediment load", "after_prediction": "the sediment load of the Rhine has strongly increased"}, {"id": "mrqa_naturalquestions-validation-6151", "before_prediction": "Paul Lynde", "after_prediction": "Paul Lynde as Templeton, a care - free, egotistical rat who lives on a web in a corner of Homer's barn above Wilbur's pig pen"}, {"id": "mrqa_triviaqa-validation-2181", "before_prediction": "george iii", "after_prediction": "geena"}, {"id": "mrqa_hotpotqa-validation-3176", "before_prediction": "5AA", "after_prediction": "Newstalk radio station 5AA (FIVEaa)"}], "retained_ids": ["mrqa_squad-validation-1592", "mrqa_hotpotqa-validation-629", "mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-4955", "mrqa_triviaqa-validation-684", "mrqa_squad-validation-2142", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-774", "mrqa_triviaqa-validation-6751", "mrqa_hotpotqa-validation-4823", "mrqa_naturalquestions-validation-7728", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-4320", "mrqa_naturalquestions-validation-9763"], "fixed_ids": ["mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-201", "mrqa_naturalquestions-validation-3058", "mrqa_triviaqa-validation-2384", "mrqa_hotpotqa-validation-3872", "mrqa_hotpotqa-validation-434", "mrqa_triviaqa-validation-791"], "unfixed_ids": ["mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-8338"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.8260869561625709}, {"timecode": 42, "before_eval": {"predictions": ["kill bill", "cavatelli, acini di pepe, pastina, orzo, etc. ), lentils, or grated parmesan cheese", "ballet", "derision", "ozone generated in contact with the skin", "American Civil War", "Chartered", "the judge increased her sentence", "Danish", "second vice-captain", "egypt", "the side - chain of the amino acid N - terminal", "Fructose", "the number of men killed and the manner of the attacks", "Gainsborough Trinity Football Club", "portrait", "Introverted Feeling ( Fi )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "mars", "feats of exploration", "a piston", "bobby", "financial assistance for tuition and other school fees of students turned away from public high schools because of enrollment overflows", "bows", "rebuild St. Peter's Basilica", "Algeria", "two forces, one pointing north, and one pointing east", "new laws or amendments to existing laws as a bill", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7820833333333334}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.7000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4666666666666667, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16000000000000003, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-8284", "mrqa_hotpotqa-validation-5731", "mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-3308", "mrqa_hotpotqa-validation-4842", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-7034", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452"], "after_eval": {"predictions": ["kill bill", "usually cavatelli, acini di pepe, pastina, orzo, etc.", "ballet", "derision", "ozone generated in contact with the skin", "American Civil War", "Chartered", "the judge increased her sentence", "Danish", "centre-back", "egypt", "where the side - chain of the amino acid N - terminal to the scissile amide bond ( the P position ) is a large hydrophobic amino acid", "Fructose", "their unusual behavior", "Gainsborough Trinity Football Club", "portrait", "By functions ; Introverted Sensing ( Si ), Extroverted Thinking ( Te ), Introverted Feeling ( Fi ) and Extrovert Intuition ( Ne )", "May", "white", "drug choice, dose, route, frequency, and duration of therapy", "mars", "feats of exploration", "a piston", "rob Lowe", "Private Education Student Financial Assistance", "bows", "rebuild St. Peter's Basilica", "Algeria", "two", "Bills", "Qualcomm", "DTIME(n2)"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9605654761904763}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-6706", "before_prediction": "Introverted Feeling ( Fi )", "after_prediction": "By functions ; Introverted Sensing ( Si ), Extroverted Thinking ( Te ), Introverted Feeling ( Fi ) and Extrovert Intuition ( Ne )"}], "retained_ids": ["mrqa_triviaqa-validation-2952", "mrqa_triviaqa-validation-3261", "mrqa_squad-validation-3044", "mrqa_squad-validation-1429", "mrqa_naturalquestions-validation-9093", "mrqa_squad-validation-1841", "mrqa_squad-validation-6735", "mrqa_hotpotqa-validation-3899", "mrqa_triviaqa-validation-4137", "mrqa_naturalquestions-validation-4185", "mrqa_hotpotqa-validation-680", "mrqa_squad-validation-9569", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-6369", "mrqa_triviaqa-validation-7133", "mrqa_hotpotqa-validation-4130", "mrqa_squad-validation-3385", "mrqa_triviaqa-validation-289", "mrqa_squad-validation-2150", "mrqa_squad-validation-9792", "mrqa_hotpotqa-validation-5522", "mrqa_squad-validation-1808"], "fixed_ids": ["mrqa_naturalquestions-validation-8284", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-3308", "mrqa_triviaqa-validation-1586", "mrqa_squad-validation-7034", "mrqa_squad-validation-10395", "mrqa_squad-validation-9452"], "unfixed_ids": ["mrqa_naturalquestions-validation-7233", "mrqa_hotpotqa-validation-4842"], "instant_fixing_rate": 0.7777777777777778, "instant_retention_rate": 0.9565217387145557}, {"timecode": 43, "before_eval": {"predictions": ["niagara falls", "15", "Indiana", "salt lake city", "Italian and French", "sailor", "sub domain of the domain to the right", "a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication", "meyerbeer", "personal care products", "is a children's rhyme and song of a kind known as cumulative", "Sparafucile", "largest country on Earth by land area, distances within Russia can be very long, and air travel is frequently needed for the President to travel across the country as well as internationally", "third-most", "ikea", "169", "south korea", "George Frampton", "Algernod Lanier Washington", "English rock band the Outfield", "ualatin Hills Tennis Center", "Michael Edwards", "almost universal for marine engines after 1880", "richard burton", "when the Moon's ecliptic longitude and the Sun's EcliptIC longitude differ by 0 \u00b0, 90 \u00b0, and 270 \u00b0, respectively", "Private \" Excused Boots\" Bisley", "Yuan T. Lee", "Kentucky, Virginia, and Tennessee", "many areas of technology incidental to rocketry and manned spaceflight, including avionics, telecommunications, and computers", "africa", "237", "matthew"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6902223005430241}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.2222222222222222, 0.21052631578947367, 1.0, 0.8571428571428571, 0.0, 1.0, 0.125, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.22222222222222224, 1.0, 0.7999999999999999, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2403", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899"], "after_eval": {"predictions": ["niagara falls", "15", "Indiana", "salt lake city", "Italian", "sailor", "top - level domain", "genetic disease", "meyerbeer", "natural-ingredients-only personal care products", "horse", "Sparafucile", "largest country", "third-most", "ikea", "169", "mexico", "George Frampton", "Plies", "English rock band the Outfield", "lawn tennis", "Michael Edwards", "road engines", "richard burton", "when the Moon's ecliptic longitude and the Sun's EcliptIC longitude differ by 0 \u00b0, 90 \u00b0, 180 \u00b0, and 270 \u00b0, respectively", "snudge", "Glenn T. Seaborg", "Kentucky, Virginia, and Tennessee", "avionics, telecommunications, and computers", "mitochondrial Eve", "237", "matthew"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9955357142857143}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-4314", "mrqa_triviaqa-validation-7538", "mrqa_triviaqa-validation-6916", "mrqa_hotpotqa-validation-981", "mrqa_triviaqa-validation-5580", "mrqa_hotpotqa-validation-4101", "mrqa_squad-validation-3671", "mrqa_triviaqa-validation-4090", "mrqa_naturalquestions-validation-10118", "mrqa_squad-validation-5586", "mrqa_naturalquestions-validation-5822", "mrqa_naturalquestions-validation-7641", "mrqa_triviaqa-validation-2803", "mrqa_squad-validation-8054", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-5541", "mrqa_triviaqa-validation-305"], "fixed_ids": ["mrqa_hotpotqa-validation-2403", "mrqa_naturalquestions-validation-2663", "mrqa_squad-validation-6442", "mrqa_hotpotqa-validation-518", "mrqa_triviaqa-validation-5087", "mrqa_hotpotqa-validation-850", "mrqa_triviaqa-validation-5160", "mrqa_hotpotqa-validation-5370", "mrqa_triviaqa-validation-7482", "mrqa_squad-validation-3330", "mrqa_triviaqa-validation-7215", "mrqa_squad-validation-3812", "mrqa_triviaqa-validation-5899"], "unfixed_ids": ["mrqa_naturalquestions-validation-5968"], "instant_fixing_rate": 0.9285714285714286, "instant_retention_rate": 0.9999999994444444}, {"timecode": 44, "before_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "in 2003 for the inter-county competition in England and Wales", "cricket", "football match", "published campaign settings", "the `` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "It was possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (album)", "Ewan McGregor as Obi - Wan Kenobi", "second", "little brother", "all health care settings", "expected to become more integral within the health care system", "music", "Lecrae Devaughn Moore (born October 9, 1979)", "average speed 112 km / h", "Rome", "December 1, 2009", "Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "Hubble Space Telescope", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.75, "QA-F1": 0.8283414502164502}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9545454545454545, 0.2857142857142857, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_triviaqa-validation-3664", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-2169"], "after_eval": {"predictions": ["King T'Chaka of the African nation Wakanda", "more experience and higher education", "in 2003 for the inter-county competition in England and Wales", "paris", "sweden", "published campaign settings", "the `` Fourth Revised Edition '' ISBN 0 - 06 - 015547 - 7", "867", "possibly brought from the Byzantine Empire ( as \u039c\u03b1\u03bd\u03bf\u03c5\u03ae\u03bb ) to Spain and Portugal, where it has been used since at least the 13th century", "\u00f7 (pronounced \"divide\") is the third studio album by English singer-songwriter Ed Sheeran.", "Padm\u00e9 Amidala", "second", "well", "all health care settings", "expected to become more integral within the health care system", "music", "Lecrae Devaughn Moore", "average speed 112 km / h", "Rome", "May 18, 2010", "Sylvia Pankhurst", "schengen", "Lord Chancellor of England", "belfast", "Indian government", "Irish", "Vesta", "branwell", "energy", "mars", "Christian Perfection", "chorale cantatas"], "metric_results": {"EM": 0.96875, "QA-F1": 0.96875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_triviaqa-validation-1504", "before_prediction": "Hubble Space Telescope", "after_prediction": "mars"}], "retained_ids": ["mrqa_naturalquestions-validation-6015", "mrqa_squad-validation-2236", "mrqa_naturalquestions-validation-2119", "mrqa_hotpotqa-validation-5305", "mrqa_naturalquestions-validation-10619", "mrqa_hotpotqa-validation-910", "mrqa_squad-validation-7067", "mrqa_squad-validation-6319", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-2406", "mrqa_naturalquestions-validation-3459", "mrqa_naturalquestions-validation-8491", "mrqa_hotpotqa-validation-4794", "mrqa_triviaqa-validation-5022", "mrqa_hotpotqa-validation-389", "mrqa_triviaqa-validation-3617", "mrqa_naturalquestions-validation-6057", "mrqa_hotpotqa-validation-5696", "mrqa_naturalquestions-validation-1725", "mrqa_triviaqa-validation-4027", "mrqa_squad-validation-8625", "mrqa_squad-validation-9951", "mrqa_squad-validation-2419"], "fixed_ids": ["mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-6579", "mrqa_naturalquestions-validation-10612", "mrqa_hotpotqa-validation-4649", "mrqa_naturalquestions-validation-5550", "mrqa_triviaqa-validation-3664", "mrqa_hotpotqa-validation-4278", "mrqa_naturalquestions-validation-2169"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9583333329340278}, {"timecode": 45, "before_eval": {"predictions": ["mike hammer", "Detroit Lions", "perique", "under `` the immortal Hawke ''", "execution", "frail Catholic saints", "gulf stream", "grail", "Sergeant - Major James Hewson", "V Alaudae, a Celtic legion recruited from Gallia Narbonensis", "Cartwright clan", "Massachusetts", "clangers", "the eighth series", "the main highway entrance at California State Route 1", "Los Angeles", "Canadian", "Henry Mills", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "Don Henkel", "worked to radicalize the Islamist movement", "People! and The Carnabeats", "Cashin' In", "most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "is a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.6875, "QA-F1": 0.6896551724137931}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06896551724137932, 1.0, 1.0]}}, "error_ids": ["mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-866", "mrqa_naturalquestions-validation-4905"], "after_eval": {"predictions": ["mike hammer", "Detroit Lions", "smoke it", "under `` the immortal Hawke ''", "execution", "frail Catholic saints", "gulf stream", "grail", "29 - year - old Mangal Pandey of the 34th BNI", "oppidum Ubiorum", "Lorne Greene", "Massachusetts", "1998", "They were the first group to win the competition", "the main highway entrance at California State Route 1", "St. Louis", "Canadian", "Gareth", "\"LOVE Radio\"", "Colorado Rockies", "the court", "tony manero", "David Dobkin", "worked to radicalize the Islamist movement", "People! and The Carnabeats", "\" Cashin' In\"", "the most recent Super Bowl champions", "Command/Service Module", "Santa Clara", "the tsar's Moscow residence", "Operation Neptune", "peninsular"], "metric_results": {"EM": 0.96875, "QA-F1": 0.9866071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "forgotten_examples": [], "retained_ids": ["mrqa_triviaqa-validation-7473", "mrqa_hotpotqa-validation-1907", "mrqa_naturalquestions-validation-4123", "mrqa_triviaqa-validation-3989", "mrqa_squad-validation-2598", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-5587", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-3363", "mrqa_hotpotqa-validation-1909", "mrqa_squad-validation-5852", "mrqa_hotpotqa-validation-5149", "mrqa_naturalquestions-validation-9931", "mrqa_triviaqa-validation-455", "mrqa_squad-validation-9513", "mrqa_hotpotqa-validation-1754", "mrqa_hotpotqa-validation-3509", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-3845", "mrqa_squad-validation-13", "mrqa_hotpotqa-validation-712", "mrqa_naturalquestions-validation-2067"], "fixed_ids": ["mrqa_triviaqa-validation-2201", "mrqa_naturalquestions-validation-4097", "mrqa_squad-validation-9296", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-3335", "mrqa_naturalquestions-validation-347", "mrqa_hotpotqa-validation-5068", "mrqa_hotpotqa-validation-1433", "mrqa_hotpotqa-validation-866"], "unfixed_ids": ["mrqa_naturalquestions-validation-4905"], "instant_fixing_rate": 0.9, "instant_retention_rate": 0.9999999995454545}, {"timecode": 46, "before_eval": {"predictions": ["suez state", "the seafloor itself moves ( and also carries the continents with it ) as it expands from a central axis", "take that", "youngest publicly documented people to be identified as transgender", "electric lighting", "They service improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds of television and radio channels", "Waiting for Guffman", "2003", "a new facility", "eat raw without cooking", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "mexico", "Grissom, White, and Chaffee", "multinational retail corporation", "passion fruit", "The Natya Shastra", "The geological properties of a white silica sand found at Basin Head are unique in the province ; the sand grains cause a scrubbing noise as they rub against each other when walked on", "ryder cup", "incorrectly", "almighty habsburgs"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7734896986895534}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false], "QA-F1": [0.0, 0.1, 1.0, 0.375, 1.0, 0.9444444444444444, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.046511627906976744, 1.0, 1.0, 0.0]}}, "error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-2673", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-4430"], "after_eval": {"predictions": ["cuba", "that continents `` ploughed '' through the sea.", "take that", "youngest person to become a national transgender figure", "electric lighting", "improved the speed of encryption of communications at both ends in front line operations during World War II", "Einstein", "electromagnetic theory", "Swansea City", "millais", "Joel", "massively multiplayer online role-playing video game", "hundreds", "Waiting for Guffman", "2003", "a new facility", "apple tree", "partial funding", "pale lager", "unattainable", "Chu'Tsai", "Liz", "least onerous", "italy", "Grissom, White, and Chaffee", "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores", "passion fruit flower", "The Natya Shastra", "sedimentary rock and other material with a high iron concentration which oxidizes upon exposure to the air", "ryder cup", "incorrectly", "vienna"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9729166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_naturalquestions-validation-3616", "before_prediction": "multinational retail corporation", "after_prediction": "an American multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores"}, {"id": "mrqa_triviaqa-validation-1128", "before_prediction": "passion fruit", "after_prediction": "passion fruit flower"}], "retained_ids": ["mrqa_triviaqa-validation-6905", "mrqa_squad-validation-5157", "mrqa_squad-validation-10341", "mrqa_squad-validation-10489", "mrqa_hotpotqa-validation-1831", "mrqa_triviaqa-validation-4081", "mrqa_naturalquestions-validation-3284", "mrqa_hotpotqa-validation-1074", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-73", "mrqa_squad-validation-5464", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5239", "mrqa_naturalquestions-validation-2890", "mrqa_squad-validation-6271", "mrqa_hotpotqa-validation-5226", "mrqa_squad-validation-4064", "mrqa_squad-validation-3913", "mrqa_naturalquestions-validation-988", "mrqa_triviaqa-validation-2873", "mrqa_squad-validation-3523"], "fixed_ids": ["mrqa_triviaqa-validation-3929", "mrqa_naturalquestions-validation-8204", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-5352", "mrqa_squad-validation-2673", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-2914", "mrqa_naturalquestions-validation-2808", "mrqa_triviaqa-validation-4430"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9130434778638941}, {"timecode": 47, "before_eval": {"predictions": ["egypt", "horse racing", "New Zealand national team", "Tibetan monastery of Kumbum Monastery", "Styal Mill", "William Jennings Bryan", "Milk Barn Animation", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "tree - topper or treetopper", "74 per cent", "piccadilly", "Neighbourhood", "William Strauss and Neil Howe", "tentacles", "insects", "catechism questions", "a pH indicator", "50% oxygen composition at standard pressure", "2001", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "Campbellsville University", "james dean", "appearing as Jude in the musical romance drama film \" Beyond the Universe\" (2007)", "morgan spurlock", "Maria works in a bridal shop with Anita", "Jocelyn Flores", "raises the productivity of each worker, resulting in a situation of relatively stagnant wages for the working class amidst rising levels of property income for the capitalist class"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7448303492484527}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.3448275862068966]}}, "error_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-2346", "mrqa_squad-validation-3685", "mrqa_hotpotqa-validation-4173", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "after_eval": {"predictions": ["florida", "horseracing", "New Zealand national team", "a Buddhist monastery, the Dongshan Dafo Dian", "Styal Mill", "William Jennings Bryan", "Goldie & Bear", "during initial entry training", "moral tale", "Franklin quit after five months, leaving the group as a trio", "leeds", "a star ( representing either the Star of Bethlehem or the star of David ), finials, angels ( `` Christmas angel '' ), or fairies", "260", "piccadilly", "Neighbourhood", "The Washington Post", "tentacles", "insects", "specific catechism questions", "a color marker", "about 50% oxygen composition at standard pressure", "2001", "George Whitefield", "Science and Discovery", "if 1 were considered a prime", "Campbellsville University", "james dean", "Jude", "morgan spurlock", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "XXXTentacion", "raises the productivity of each worker,"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9694548872180451}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_squad-validation-6287", "before_prediction": "Tibetan monastery of Kumbum Monastery", "after_prediction": "a Buddhist monastery, the Dongshan Dafo Dian"}, {"id": "mrqa_naturalquestions-validation-5241", "before_prediction": "Maria works in a bridal shop with Anita", "after_prediction": "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo"}], "retained_ids": ["mrqa_hotpotqa-validation-1924", "mrqa_hotpotqa-validation-5788", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-2864", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-1516", "mrqa_hotpotqa-validation-5086", "mrqa_squad-validation-4479", "mrqa_triviaqa-validation-3868", "mrqa_naturalquestions-validation-7849", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2801", "mrqa_squad-validation-1609", "mrqa_squad-validation-9061", "mrqa_hotpotqa-validation-662", "mrqa_triviaqa-validation-1799", "mrqa_triviaqa-validation-7477"], "fixed_ids": ["mrqa_triviaqa-validation-2770", "mrqa_triviaqa-validation-945", "mrqa_hotpotqa-validation-5877", "mrqa_naturalquestions-validation-5305", "mrqa_squad-validation-4212", "mrqa_naturalquestions-validation-8582", "mrqa_squad-validation-2346", "mrqa_squad-validation-3685", "mrqa_hotpotqa-validation-4173", "mrqa_naturalquestions-validation-2092", "mrqa_squad-validation-7182"], "unfixed_ids": [], "instant_fixing_rate": 1.0, "instant_retention_rate": 0.9047619043310657}, {"timecode": 48, "before_eval": {"predictions": ["a heroine who experienced many tragedies, mostly at the hands of her controlling ex-husband, the villainous James Stenbeck ( Anthony Herrera)", "The album is a song by American hip hop recording artist Kendrick Lamar, taken from his major label debut studio album", "el Capitan", "interventive", "3", "The Methodist Church", "blues", "During his epic battle with Frieza", "the director's own approved edit", "Social Democratic Party", "italy", "Anfernee Simons and Thon's brother, Matur Maker", "a loop ( also called a self - loop or a `` buckle '' ) is an edge that connects a vertex to itself", "painting, mathematics, calligraphy, poetry, and theater", "at the 1964 Republican National Convention in San Francisco, California as a nomination speech for presidential candidate Senator Barry Goldwater", "good work", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter", "Buffalo Bill", "justice", "France", "It insisted on neutrality, which included allowing private corporations and banks to sell or loan money to either side", "cappuccino", "meat that is permissible", "Arthur Russell (born Charles Arthur Russell, Jr. May 21, 1951 \u2013 April 4, 1992) was an American cellist, composer, producer, singer, and musician whose work spanned a disparate range of styles", "the people", "Wylie Draper", "political role", "the university's off-campus rental policies", "hockey greats Bobby Hull and Dennis Hull, as well as painter Manley MacDonald", "the defending Super Bowl XLIX champion New England Patriots", "a protracted siege, during which the Mongol army under Jani Beg was suffering from the disease, the army catapulted the infected corpses over the city walls of Kaffa to infect the inhabitants."], "metric_results": {"EM": 0.34375, "QA-F1": 0.4549068403535721}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false], "QA-F1": [0.21052631578947367, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666665, 0.0, 0.0, 0.22222222222222224, 0.13333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.0, 0.4, 0.12903225806451613, 1.0, 0.2666666666666667, 0.6666666666666666, 1.0, 0.761904761904762, 0.0, 0.0]}}, "error_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "after_eval": {"predictions": ["James Stenbeck", "Section.80", "yosemite national park", "interventive", "3", "Bishop Lloyd Christ Wicke", "georgia state", "During his epic battle with Frieza", "the director's own approved edit", "shirley williams", "unesco", "Thon Maker", "loop", "painting, mathematics, calligraphy, poetry, and theater", "part of a pre-recorded television program, Rendezvous with Destiny", "a sin", "whether they wish to collect a jackpot prize in cash or annuity", "Vader's daughter and the twin sister of Luke Skywalker", "Buffalo Bill", "justice", "France", "neutrality", "coffee", "permissible", "Arthur Russell", "the people", "Alex Burrall, Jason Weaver and Wylie Draper played Michael Jackson in different eras", "political", "the university's off-campus rental policies", "Dennis Hull, as well as painter Manley MacDonald.", "Pittsburgh Steelers", "war, famine, and weather"], "metric_results": {"EM": 0.9375, "QA-F1": 0.9708333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-4075", "before_prediction": "Vader's daughter", "after_prediction": "Vader's daughter and the twin sister of Luke Skywalker"}], "retained_ids": ["mrqa_squad-validation-5665", "mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-1834", "mrqa_squad-validation-8248", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-4043", "mrqa_squad-validation-2263", "mrqa_naturalquestions-validation-3614", "mrqa_squad-validation-2337", "mrqa_squad-validation-7947"], "fixed_ids": ["mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5165", "mrqa_triviaqa-validation-3967", "mrqa_squad-validation-9860", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-2607", "mrqa_triviaqa-validation-2849", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-2445", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-2259", "mrqa_naturalquestions-validation-1649", "mrqa_triviaqa-validation-1197", "mrqa_triviaqa-validation-4384", "mrqa_hotpotqa-validation-962", "mrqa_naturalquestions-validation-1531", "mrqa_squad-validation-9518", "mrqa_hotpotqa-validation-599", "mrqa_squad-validation-264", "mrqa_squad-validation-4774"], "unfixed_ids": ["mrqa_naturalquestions-validation-3342"], "instant_fixing_rate": 0.9523809523809523, "instant_retention_rate": 0.9090909082644627}, {"timecode": 49, "before_eval": {"predictions": ["suitable for use on rough terrain", "Sesame Street", "Genghis Khan", "\"Losing My Religion\" or \"The One I Love\"", "between the Eastern Ghats and the Bay of Bengal", "Ravenna (], also locally ] ; Romagnol: \"Rav\u00e8na\" ) is the capital city of the Province of Ravenna, in the Emilia- Romagna region of Northern Italy.", "12", "meat", "1895", "improved markedly", "a biplane capable of taking off vertically (VTOL aircraft) and then be \"gradually tilted through manipulation of the elevator devices\" in flight until it was flying like a conventional plane", "assigned them to the company in lieu of stock.", "communist", "Gregor Mendel", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "State Street", "the Saudi Arab kingdom", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "imperialism", "vegetables, sour milk, meat, fish or any other stew", "ATP energy", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7726378124563609}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.6, 0.18181818181818182, 0.7741935483870968, 0.2222222222222222, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "error_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_squad-validation-1459", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-5283", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906"], "after_eval": {"predictions": ["light utility vehicles", "Sesame Street", "Timur", "\"Losing My Religion\"", "from Tamil Nadu in the south to West Bengal in the north through Andhra Pradesh and Odisha", "Ravenna (], also locally ] ; Romagnol: \"Rav\u00e8na\" ) is the capital city of the Province of Ravenna", "Bocelli became completely blind at the age of 12", "meat", "1895", "improved markedly", "VTOL aircraft", "assigned them to the company in lieu of stock", "communist", "Gregor Mendel", "Reserved matters", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "18,000 regulars, militia and Native American allies", "Central Avenue", "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah", "110", "my fair lady", "falcon", "Lawton Chiles", "`` Kobol's Last Gleaming ''", "McCrary", "imperialism", "Ugali with vegetables, sour milk, meat, fish or any other stew", "adenosine triphosphate", "stonehenge", "Ruth Elizabeth \"Bette\" Davis", "cobalt", "29 September 2014"], "metric_results": {"EM": 0.90625, "QA-F1": 0.9241071428571428}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "forgotten_examples": [{"id": "mrqa_hotpotqa-validation-1023", "before_prediction": "State Street", "after_prediction": "Central Avenue"}, {"id": "mrqa_naturalquestions-validation-9013", "before_prediction": "the Saudi Arab kingdom", "after_prediction": "al - Mamlakah al - \u02bbArab\u012byah as - Su\u02bb\u016bd\u012byah"}], "retained_ids": ["mrqa_hotpotqa-validation-5452", "mrqa_triviaqa-validation-6073", "mrqa_hotpotqa-validation-987", "mrqa_squad-validation-716", "mrqa_squad-validation-1306", "mrqa_hotpotqa-validation-2810", "mrqa_naturalquestions-validation-3663", "mrqa_hotpotqa-validation-3964", "mrqa_squad-validation-10291", "mrqa_hotpotqa-validation-4530", "mrqa_triviaqa-validation-3250", "mrqa_triviaqa-validation-6475", "mrqa_hotpotqa-validation-1315", "mrqa_squad-validation-7049", "mrqa_squad-validation-9807", "mrqa_triviaqa-validation-5876", "mrqa_hotpotqa-validation-1772", "mrqa_triviaqa-validation-6380", "mrqa_hotpotqa-validation-2750"], "fixed_ids": ["mrqa_naturalquestions-validation-2272", "mrqa_squad-validation-6257", "mrqa_hotpotqa-validation-2032", "mrqa_naturalquestions-validation-2275", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2941", "mrqa_squad-validation-1459", "mrqa_squad-validation-9489", "mrqa_squad-validation-8518", "mrqa_squad-validation-8906"], "unfixed_ids": ["mrqa_naturalquestions-validation-5283"], "instant_fixing_rate": 0.9090909090909091, "instant_retention_rate": 0.9047619043310657}], "final_eval_results": {"overall_oncoming_test": {"EM": 0.441875, "QA-F1": 0.5283131570929158}, "overall_error_number": 893, "overall_instant_fixing_rate": 0.9222241800720434, "final_instream_test": {"EM": 0.865625, "QA-F1": 0.9013079439514908}, "final_upstream_test": {"EM": 0.681, "QA-F1": 0.7487305121006159}}}